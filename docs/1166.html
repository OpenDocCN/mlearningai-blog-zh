<html>
<head>
<title>Augmented Reality Sudoku Solver: Reading Puzzle Values from Image</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增强现实数独解算器:从图像中读取谜题值</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/augmented-reality-sudoku-solver-part-iii-d2370a9cbace?source=collection_archive---------2-----------------------#2021-10-16">https://medium.com/mlearning-ai/augmented-reality-sudoku-solver-part-iii-d2370a9cbace?source=collection_archive---------2-----------------------#2021-10-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8f49d760c0b526b6592b22b5ecc3776c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hjFBFylKAXxZHH-VkPFMiQ.png"/></div></div></figure><p id="1ad9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi jn translated">这篇文章是增强现实数独解算器的延续，我们将构建一个基于GUI的增强现实数独解算器。在本文中，我们了解了如何从处理过的拼图图像中提取数字。我们实现了在Char74k数据集上训练的卷积神经网络，以使用PyTorch识别来自每个方块的数字。</p><p id="a50c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们的目标是解决任何N维的数独，其中N是一个非素数。该项目将以两种形式实施-</p><ul class=""><li id="4900" class="jw jx hh ir b is it iw ix ja jy je jz ji ka jm kb kc kd ke bi translated">一个选项来加载保存在系统上的图像或使用网络摄像头将图像馈送到程序，然后在系统上玩游戏。</li><li id="fccc" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated">一个选项，使用增强现实和解决数独显示的网络摄像头的难题。</li></ul><p id="a90f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">项目以<a class="ae kk" href="https://en.wikipedia.org/wiki/Knuth%27s_Algorithm_X" rel="noopener ugc nofollow" target="_blank"> <em class="kl">算法X </em> </a>的形式使用<a class="ae kk" href="https://en.wikipedia.org/wiki/Dancing_Links" rel="noopener ugc nofollow" target="_blank"> <em class="kl">跳舞环节</em> </a>寻找数独难题的解。数独是一个众所周知的NP完全问题，算法X是实现一种贪婪的深度优先搜索来找到合适的解决方案的一种手段。该项目将分为4个部分</p><ul class=""><li id="60ee" class="jw jx hh ir b is it iw ix ja jy je jz ji ka jm kb kc kd ke bi translated">第一部分<strong class="ir hi"> <em class="kl"> — </em> </strong> <a class="ae kk" rel="noopener" href="/mlearning-ai/augmented-reality-sudoku-solver-part-i-8e29e59cecab">了解数独解算器，即用于解数独的算法。</a></li><li id="0d2b" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated">第二部分— <a class="ae kk" rel="noopener" href="/mlearning-ai/augmented-reality-sudoku-solver-part-ii-cdfc035a415c">处理来自相机的图像，以便能够提取数独的网格。</a></li><li id="a540" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated">第三部分—处理图像和相应的模型，以检测每个单元中的数值。</li><li id="b6b6" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated">第四部分— <a class="ae kk" href="https://shashank-goyal-blogs.medium.com/augmented-reality-sudoku-solver-part-iv-65afe2231e46" rel="noopener">使用PyGame构建GUI。</a></li></ul><h2 id="9b50" class="km kn hh bd ko kp kq kr ks kt ku kv kw ja kx ky kz je la lb lc ji ld le lf lg bi translated">第三部分:识别数字单元格值-</h2><p id="8f72" class="pw-post-body-paragraph ip iq hh ir b is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji ll jk jl jm ha bi translated">为了检测单元格中的数值，我们将使用PyTorch库。我们将实现一个基于卷积神经网络(CNN)的模型，在<a class="ae kk" href="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/" rel="noopener ugc nofollow" target="_blank"> char74k数据集</a>上训练我们的网络。我在这里使用的架构给了我<strong class="ir hi"> 99.61% </strong>的精度，并且受到了这个<a class="ae kk" href="https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracy" rel="noopener ugc nofollow" target="_blank">模型</a>的启发。</p><p id="b2a7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先让我们了解卷积神经网络的基础知识</p><p id="10b3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在一个简单的前馈神经网络中，我们通常将图像展平为一个线性向量，然后我们用一些权重和偏差进行点积，以获得输出数组的一个元素。在收敛到最终输出层之前，该输出数组遵循几个隐藏层的相同模式。</p><p id="6758" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这种方法的主要限制是它不能捕捉像素位置之间的空间关系，因此在2-D平面中的局部区域上展开的图案可以表示也可以位于图像平面中任何其他地方的特征。例如，可以在图像的左上角或右下角找到代表鼻子的区域。这种特性被称为空间不变性，即表示特征的图像的小区域可以在图像平面中的任何地方移动。现在让我们理解卷积运算的真正含义</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/968ea9e5872a363078abdfde1608303b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/0*7z9ch7Y23EoN1OZA.gif"/></div></figure><p id="10bb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">简单地说，我们运行一个更小的矩阵，称为图像平面上的核心。内核本质上是一个二维权重矩阵。从上面的图像中可以明显看出，我们将核与矩阵上每个核位置的图像部分进行点积。<br/>在继续讨论一些与卷积相关的术语之前-</p><ul class=""><li id="1c1f" class="jw jx hh ir b is it iw ix ja jy je jz ji ka jm kb kc kd ke bi translated"><strong class="ir hi">步幅:</strong>是内核移动的像素数。在每次迭代的内核上方的图像中，内核向右移动一个像素，类似地向下移动一个像素，这被称为步幅。</li><li id="71ea" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated"><strong class="ir hi">填充:</strong>在上面的图片中我们可以看到内核在矩阵内部元素上运行的次数比在最外层元素上运行的次数多。这导致图像从5x5缩小到3x3。我们可以通过在原始矩阵周围提供零元素的边界来补充原始矩阵，以避免尺寸减小。</li><li id="7c2e" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated"><strong class="ir hi">膨胀:</strong>这是内核内点距离，即从内核乘法矩阵中提取的元素之间的距离。</li></ul><p id="9db9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了更好地理解上述术语，我建议看一下这个<a class="ae kk" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md#convolution-animations" rel="noopener ugc nofollow" target="_blank">自述文件</a>，它为这些解释提供了很好的可视化效果。</p><p id="a651" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们来看看神经网络的架构，我们将使用我们的解决方案-</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="8637" class="km kn hh ls b fi lw lx l ly lz">+----------+--------------------------------------------+----------+<br/>|  Input   |                 Operation                  |  Output  |   <br/>|   Size   |                                            |   Size   |<br/>+----------+--------------------------------------------+----------+<br/>|                         Feature Extraction                       |<br/>+----------+--------------------------------------------+----------+<br/>| 1x28x28  | Conv2d(1, 32, kernel_size=3, stride=1,     | 32x28x28 |<br/>|          |               padding=1),                  |          |<br/>|          | BatchNorm2d(32),                           |          |<br/>|          | ReLU(inplace=True)                         |          |<br/>+----------+--------------------------------------------+----------+<br/>| 32x28x28 | nn.Conv2d(32, 32, kernel_size=3, stride=1, | 32x14x14 |<br/>|          |                   padding=1),              |          |<br/>|          | BatchNorm2d(32),                           |          |<br/>|          | ReLU(inplace=True),                        |          |<br/>|          | MaxPool2d(kernel_size=2, stride=2)         |          |<br/>+----------+--------------------------------------------+----------+<br/>| 32x14x14 | Conv2d(32, 64, kernel_size=3, padding=1),  | 64x14x14 |<br/>|          | BatchNorm2d(64),                           |          |<br/>|          | ReLU(inplace=True)                         |          |<br/>+----------+--------------------------------------------+----------+<br/>| 64x14x14 | Conv2d(64, 64, kernel_size=3, padding=1),  |  64x7x7  |<br/>|          | BatchNorm2d(64),                           |          |<br/>|          | ReLU(inplace=True),                        |          |<br/>|          | MaxPool2d(kernel_size=2, stride=2)         |          |<br/>+----------+--------------------------------------------+----------+<br/>|                          Classification                          |<br/>+----------+--------------------------------------------+----------+<br/>|  64x7x7  | Dropout(p=0.5),                            |    512   |<br/>|          | Linear(64 * 7 * 7, 512),                   |          |<br/>|          | BatchNorm1d(512),                          |          |<br/>|          | ReLU(inplace=True),                        |          |<br/>|          | Dropout(p=0.5)                             |          |<br/>+----------+--------------------------------------------+----------+<br/>|    512   | Linear(512, 512),                          |    512   |<br/>|          | BatchNorm1d(512),                          |          |<br/>|          | ReLU(inplace=True)                         |          |<br/>+----------+--------------------------------------------+----------+<br/>|    512   | Dropout(p=0.5),                            |    10    |  <br/>|          | Linear(512, 10)                            |          |<br/>+----------+--------------------------------------------+----------+</span></pre><p id="b685" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">尽管上面的架构看起来令人望而生畏，但在代码中实现起来并不困难。<br/>没有任何进一步的延迟，现在让我们看看代码-</p><p id="cb81" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> PyTorch GPU实用函数- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="33a5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi"> get_default_device </strong>”方法用于检查系统上是否有支持Cuda的GPU。因此，它将返回“<strong class="ir hi"> torch.device('cuda') </strong>”或“<strong class="ir hi"> torch.device('cpu') </strong>”，这将返回一个对象，该对象表示将在其上分配张量变量以进行计算的设备。<br/><strong class="ir hi">to _ device</strong>方法用于在可用设备上分配对象。</p><p id="f943" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> PyTorch GPU实用设备数据加载器类- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="6232" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该类用于补充“<strong class="ir hi">torch . utils . data . data loader</strong>”类。它用于将整个DataLoader对象转移到可用设备。但是分配给设备操作仅在产生元素时发生。</p><p id="5e46" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">准确度方法- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="fab7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi">准确性</strong>方法用于确定正确预测的百分比。"<strong class="ir hi"> torch.max </strong>"方法从输出数组中返回具有最高值的索引。示例-</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="e997" class="km kn hh ls b fi lw lx l ly lz">X = [<br/>      [0.42, 0.72, 0.86, 0.87, 0.29, 0.19, 0.59, 0.99, 0.65, 0.94],<br/>      [0.49, 0.76, 0.77, 0.66, 0.35, 0.41, 0.79, 0.72, 0.04, 0.31]<br/>    ]</span><span id="bafc" class="km kn hh ls b fi mc lx l ly lz">torch.max(X) =&gt; [7, 6]</span></pre><p id="7ec0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，我们将正确预测的总数除以预测的总数，得到正确率。</p><p id="7663" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> Char74k模型初始化- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="aa17" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是类的初始化方法。这里我们从“<strong class="ir hi"> torch.nn.Module </strong>继承了我们的类，并定义了特征提取和分类器序列。然后，我们初始化特征提取网络的权重，如下一个函数中所解释的。</p><p id="6f7e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">层权重初始化- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="26d5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，我们对卷积层的核值进行归一化，并对批归一化层分别将权重和偏差设置为1和0。</p><p id="ffe6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">前馈计算- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="5272" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">"<strong class="ir hi"> forward </strong>"方法是"<strong class="ir hi"> torch.nn.module </strong>"类的一个特殊方法，它定义了从一层(或者在我们的例子中，一系列层)到另一层的向前传递步骤。定义这个方法使我们能够在正向传递中执行必要的步骤。这里，我们将“1×28×28”图像，即28×28图像矩阵输入特征提取层。注意，这里的1表示单通道图像，即灰度图像。“<strong class="ir hi"> x.view </strong>用于将矢量展平为二维矢量。示例-</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="2ecf" class="km kn hh ls b fi lw lx l ly lz">a = torch.random.torch.randint(size=(2,5,2), low=0, high=10)<br/>a =&gt;<br/>tensor([[[9, 2],<br/>         [2, 8],<br/>         [2, 2],<br/>         [3, 4],<br/>         [5, 8]],<br/>        <br/>        [[0, 3],<br/>         [3, 5],<br/>         [3, 1],<br/>         [8, 7],<br/>         [5, 6]]])</span><span id="3bc4" class="km kn hh ls b fi mc lx l ly lz">a.view(a.size(0), -1) =&gt;<br/>tensor([[9, 2, 2, 8, 2, 2, 3, 4, 5, 8],<br/>        [0, 3, 3, 5, 3, 1, 8, 7, 5, 6]])</span></pre><p id="e161" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，我们将这个二维向量提供给分类器，分类器返回图像的预测分数。这个预测分数是一个一维向量，包含每个类别的百分比可能性(在我们的例子中是0-9位数)。</p><p id="9b98" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">训练步骤- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="c1a4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi"> training_step </strong>”方法定义了训练周期单次迭代的过程。每个迭代或步骤接受一批图像以及相关联的标签。然后将图像传递给模型。然后，我们计算批量预测的交叉熵损失。交叉熵损失是一种结合了对数软最大损失和负对数似然损失的度量，用于N类分类问题。然后，在将损失函数对象移动到可用的计算设备并将其返回之后，我们计算损失。</p><p id="2ad8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">验证步骤- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="6cd0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi">验证_步骤</strong>”方法与“<strong class="ir hi">训练_步骤</strong>”相同，不同之处在于前者额外计算精度并返回损耗和精度，仅用于显示，而后者仅返回损耗，用于将其反向传播到网络。</p><p id="4b90" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">验证时期结束- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="bb36" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi"> validation_epoch_end </strong>”方法在训练时期结束时运行，结合所有验证步骤的数据，计算该时期的平均验证精度和验证损失。</p><p id="3146" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">历元结束- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="f5a8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">此方法用于打印一个时期的平均验证损失和准确度。</p><h2 id="240a" class="km kn hh bd ko kp kq kr ks kt ku kv kw ja kx ky kz je la lb lc ji ld le lf lg bi translated">模型训练和评估方法-</h2><p id="b62b" class="pw-post-body-paragraph ip iq hh ir b is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji ll jk jl jm ha bi translated"><strong class="ir hi">评估模型- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="d3a9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">此方法用于在验证或测试数据集(以Dataloader对象的形式)上运行模型，并在训练期间确定模型指标。</p><p id="2901" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">根据训练数据拟合模型- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="c192" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，我们在指定的时期数的训练数据上拟合模型。我们使用Adam优化器进行一阶梯度优化。我们还使用了一个学习率调度器，特别是StepLR调度器。这里，step_size=7，gamma为0.1，这意味着每7个历元学习率将是当前值的0.1倍。<br/>然后，我们通过迭代每个时期的成批训练数据来开始模型拟合。</p><p id="1b6f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">培训模式- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="4f67" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">此方法是为数据集定型的驱动程序方法。我们首先创建一个转换序列。这个序列首先将图像转换为灰度，然后将它们的大小调整为28x28，最后将它们转换为张量。我们使用“<strong class="ir hi">torch vision . datasets . image folder</strong>”方法加载数据目录，该方法输入目录路径和加载数据时运行的转换。然后，我们指定批量大小，将数据集分成80-20个训练验证比率，并将它们加载到各自的“<strong class="ir hi"> DeviceDataLoaders </strong>”中。</p><p id="b0e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，我们将模型移动到可用的计算设备，并为20个时期拟合模型。然后，我们评估模型并将模型权重保存到一个文件中。</p><blockquote class="md me mf"><p id="b7fc" class="ip iq kl ir b is it iu iv iw ix iy iz mg jb jc jd mh jf jg jh mi jj jk jl jm ha bi translated">我在这个模型上实现的最终损失和精度是- <br/>模型结果= val_loss: 0.0076，val_acc: 0.9961</p></blockquote><p id="2cf7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">评估加载的模型- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="4880" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该方法帮助我们加载保存的模型文件，并确定整个数据集的准确性和损失。</p><p id="13ed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">负荷模型- </strong></p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="5d06" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该方法有助于从保存的文件中加载模型。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/46d2fcd7423339bdc83151754f8b2cec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wwBbcqwqQz8irkZAVGymFw.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/9365591faf0730972e20e52f136210d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BKwomqTt9zEGHv5F1QuUnQ.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a9c92ebe918df46424348fbe1c690d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E_r20_MQtl0ASN7pQzmdDA.png"/></div></div></figure></div><div class="ab cl mj mk go ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ha hb hc hd he"><p id="73fb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="kl">你可以在这里</em>  <em class="kl">找到完整的python实现</em> <a class="ae kk" href="https://github.com/shashank3199/VisioNxN-Sudoku/blob/master/Image_Processing/classifier.py" rel="noopener ugc nofollow" target="_blank"> <em class="kl">。如果你觉得这篇文章很有帮助，请跟我上</em> </a><a class="ae kk" href="https://shashank-goyal-blogs.medium.com/" rel="noopener"> <em class="kl">中</em> </a> <em class="kl">和</em><a class="ae kk" href="https://github.com/shashank3199/" rel="noopener ugc nofollow" target="_blank"><em class="kl">GitHub</em></a><em class="kl">和star</em><a class="ae kk" href="https://github.com/shashank3199/VisioNxN-Sudoku" rel="noopener ugc nofollow" target="_blank"><em class="kl">项目库</em> </a> <em class="kl">。</em></p></div><div class="ab cl mj mk go ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ha hb hc hd he"><p id="016d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您可以在此处找到此项目<a class="ae kk" rel="noopener" href="/mlearning-ai/augmented-reality-sudoku-solver-part-i-8e29e59cecab">的完整详细实施说明。</a></p></div><div class="ab cl mj mk go ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ha hb hc hd he"><p id="609d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请查看本系列文章的其他部分</p><ul class=""><li id="badb" class="jw jx hh ir b is it iw ix ja jy je jz ji ka jm kb kc kd ke bi translated"><a class="ae kk" rel="noopener" href="/mlearning-ai/augmented-reality-sudoku-solver-part-i-8e29e59cecab">增强现实数独解算器——第一部分</a>。</li><li id="6412" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated"><a class="ae kk" rel="noopener" href="/mlearning-ai/augmented-reality-sudoku-solver-part-ii-cdfc035a415c">增强现实数独解算器——第二部分。</a></li><li id="e3c4" class="jw jx hh ir b is kf iw kg ja kh je ki ji kj jm kb kc kd ke bi translated"><a class="ae kk" href="https://shashank-goyal-blogs.medium.com/augmented-reality-sudoku-solver-part-iv-65afe2231e46" rel="noopener">增强现实数独解算器——第四部分。</a></li></ul></div></div>    
</body>
</html>
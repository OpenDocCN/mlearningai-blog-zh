<html>
<head>
<title>From cats and dogs to polyps in the colon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从猫狗到结肠息肉</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/from-cats-and-dogs-to-polyps-in-the-colon-3e139aafe030?source=collection_archive---------6-----------------------#2022-01-10">https://medium.com/mlearning-ai/from-cats-and-dogs-to-polyps-in-the-colon-3e139aafe030?source=collection_archive---------6-----------------------#2022-01-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="255d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结肠直肠癌是世界上最致命和最普遍的癌症类型之一，结肠镜检查是用于检测和诊断结肠中这些息肉的优选方法。另一方面，今天的检测率显示了影响诊断和治疗的显著错误率。2021年<a class="ae jc" href="https://www.simulamet.no/" rel="noopener ugc nofollow" target="_blank"> Simula大都会数字工程中心</a>和新的人工智能杂志；<a class="ae jc" href="https://journals.uio.no/NMI/" rel="noopener ugc nofollow" target="_blank">北欧机器智能</a>，用3个任务组织了一次机器学习挑战赛。前两项任务是从结肠镜检查图像中分割息肉和器械。在息肉分割任务中使用了由1000幅带注释图像组成的<a class="ae jc" href="https://datasets.simula.no/kvasir/" rel="noopener ugc nofollow" target="_blank">训练集</a>，在仪器分割任务中使用了由590幅带注释图像组成的<a class="ae jc" href="https://datasets.simula.no/kvasir-instrument/" rel="noopener ugc nofollow" target="_blank">训练集</a>。息肉和器械分割模型最终在各自包含300个图像的两个独立测试集上被评分。</p><div class="jd je jf jg fd ab cb"><figure class="jh ji jj jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/e9435897a43e0b7da64440b1bf16d4ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*hAYk6vversP5inSl2EqXXg.png"/></div></figure><figure class="jh ji ju jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/ac24be45f0dd8d5c6d41fb8108979d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*g_p88RqDjKBahww_TeCsnQ.png"/></div></figure><figure class="jh ji jv jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/9d3abca323382c71c7203235a076f507.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*B_R09HJmYDtO8Pqjrrsk-g.png"/></div><figcaption class="jw jx et er es jy jz bd b be z dx ka di kb kc">Segmented polyps — the predicted masks are shown as a transparent white overlay over the colonoscopy images, highlighting the polyps shown in the images</figcaption></figure></div><div class="ab cb"><figure class="jh ji kd jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/638dd6e9de49f80f35c47bb4fa666433.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*j1qZ53fGds-_cK_Qi0qrGQ.png"/></div></figure><figure class="jh ji ke jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/1bc8a71e7ea7be4d6c1cf7c1f7d66138.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*Gbldm4UIW0V-yNGRsEu9hg.png"/></div></figure><figure class="jh ji kf jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/2905bce14f83d3a6e3e5dd454ec9fa77.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*uuIZnOrQLOhHQpXtajjuyw.png"/></div><figcaption class="jw jx et er es jy jz bd b be z dx kg di kh kc">Segmented instruments — the predicted masks are shown as a transparent white overlay over the colonoscopy images, highlighting the instruments shown in the images</figcaption></figure></div><p id="9006" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第三个也是最后一个任务是使模型和预测更加透明。由于没有具体要求，参与者可以对这项任务进行解释，一个多学科小组根据提交材料的透明度和可理解性对提交材料进行了评估。最后，16个团队在由<a class="ae jc" href="https://journals.uio.no/NMI/" rel="noopener ugc nofollow" target="_blank">Nordic Machine Intelligence</a>发表的<a class="ae jc" href="https://journals.uio.no/NMI/issue/view/787" rel="noopener ugc nofollow" target="_blank"> 16篇不同的科学论文</a>中描述了他们的方法和结果，在所有3项任务中取得最佳总体成绩的团队将获得5000欧元的奖金。</p><figure class="jd je jf jg fd ji er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es ki"><img src="../Images/22a6dba2b555d630424daac49d3ceab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QKHUxfqquBYa-_QLP8Wi2w.jpeg"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx">Nordic Machine intelligence logo</figcaption></figure></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><p id="0009" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的团队；团队Polypixel在这次机器学习挑战中获得了第6名(你可以在这里阅读我们的完整论文<a class="ae jc" href="https://journals.uio.no/NMI/article/view/9132" rel="noopener ugc nofollow" target="_blank">)。我们发现，在包含像猫和狗这样的图像的ImageNet上预训练分割模型，在息肉和仪器分割上的性能都有显著提高。通过交叉验证，我们发现息肉模型在没有预训练的情况下达到0.65±0.07的DICE分数，而在预训练的情况下达到0.87±0.01的DICE分数。仪器模型在没有预训练的情况下获得了0.89±0.03的骰子分数，在预训练的情况下获得了0.94±0.02的骰子分数。</a></p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><p id="594e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你对这些数据集感到好奇，但不知道从哪里开始，你可以看看这两个笔记本:<a class="ae jc" href="https://www.kaggle.com/bjoernjostein/hyperkvasir-starter-code" rel="noopener ugc nofollow" target="_blank">息肉分割</a>和<a class="ae jc" href="https://www.kaggle.com/bjoernjostein/kvasir-instrument-starter-code" rel="noopener ugc nofollow" target="_blank">仪器分割</a>，在这里你可以找到附加的数据集和带有增强和其他预处理步骤的机器学习管道。</p><div class="kq kr ez fb ks kt"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ku ab dw"><div class="kv ab kw cl cj kx"><h2 class="bd hi fi z dy ky ea eb kz ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="la l"><h3 class="bd b fi z dy ky ea eb kz ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lb l"><p class="bd b fp z dy ky ea eb kz ed ef dx translated">medium.com</p></div></div><div class="lc l"><div class="ld l le lf lg lc lh js kt"/></div></div></a></div></div></div>    
</body>
</html>
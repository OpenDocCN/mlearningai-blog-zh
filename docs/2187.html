<html>
<head>
<title>Image classification with transfer learning on tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流的迁移学习图像分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/image-classification-with-transfer-learning-on-tensorflow-68b6bc87ef4b?source=collection_archive---------0-----------------------#2022-03-21">https://medium.com/mlearning-ai/image-classification-with-transfer-learning-on-tensorflow-68b6bc87ef4b?source=collection_archive---------0-----------------------#2022-03-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ea39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我之前的<a class="ae jc" rel="noopener" href="/mlearning-ai/transfer-learning-with-transformers-trainer-and-pipeline-for-nlp-8b1d2c1a8c3d">迁移学习帖子</a>中，我们回顾了NLP的迁移学习。<a class="ae jc" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> Huggingface </a>让NLP迁移学习变得非常容易。然而，到目前为止，我还没有找到针对各种计算机视觉任务的类似框架。让我们回顾一下图像分类任务，看看是什么样的模式。本帖我们将重点关注tensorflow。</p><p id="c6f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用著名的猫狗图像分类任务(辨别图像是猫图像还是狗图像)。Tensorflow为初学者提供了一个很好的教程(带有colab notebook ),我们将用进一步的解释来补充它。</p><div class="jd je ez fb jf jg"><a href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">迁移学习和微调| TensorFlow核心</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">此外，您应该尝试微调一小部分顶层，而不是整个MobileNet模型。在大多数情况下…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">www.tensorflow.org</p></div></div><div class="jp l"><div class="jq l jr js jt jp ju jv jg"/></div></div></a></div><p id="1a50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过上面的例子，你会看到两种定制预训练模型的方法:</p><ol class=""><li id="62ca" class="jw jx hh ig b ih ii il im ip jy it jz ix ka jb kb kc kd ke bi translated">特征提取:使用前一个网络学习的表示从新样本中提取有意义的特征。您只需在预训练模型的顶部添加一个新的分类器，该分类器将从头开始训练，以便您可以重新调整之前为数据集学习的特征映射。<br/>你不需要(重新)训练整个模型。基本的卷积网络已经包含了通常用于分类图片的特征。然而，预训练模型的最终分类部分特定于原始分类任务，并且随后特定于模型被训练的类别集。</li><li id="6792" class="jw jx hh ig b ih kf il kg ip kh it ki ix kj jb kb kc kd ke bi translated">微调:解冻冻结模型库的几个顶层，并联合训练新添加的分类器层和基础模型的最后几层。这允许我们“微调”基础模型中的高阶特征表示，以便使它们与特定任务更相关。</li></ol><p id="41c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">目前，计算机视觉的主要模型架构是卷积神经网络/CNN架构。有关CNN的更多信息，请参考附录，但现在只需了解该模型被训练为自动捕捉边缘、轮廓、方向、纹理等特征，这些特征可用于上层任务。</p><h1 id="6f82" class="kk kl hh bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">图像分类迁移学习的一般步骤</h1><ol class=""><li id="b7c4" class="jw jx hh ig b ih li il lj ip lk it ll ix lm jb kb kc kd ke bi translated">数据加载器</li><li id="4355" class="jw jx hh ig b ih kf il kg ip kh it ki ix kj jb kb kc kd ke bi translated">预处理</li><li id="ad61" class="jw jx hh ig b ih kf il kg ip kh it ki ix kj jb kb kc kd ke bi translated">加载预训练模型，根据需要冻结模型层</li><li id="f5c6" class="jw jx hh ig b ih kf il kg ip kh it ki ix kj jb kb kc kd ke bi translated">根据需要添加额外的层，以形成最终的模型</li><li id="4fab" class="jw jx hh ig b ih kf il kg ip kh it ki ix kj jb kb kc kd ke bi translated">编译模型，设置优化器和损失函数</li><li id="1768" class="jw jx hh ig b ih kf il kg ip kh it ki ix kj jb kb kc kd ke bi translated">使用model.fit训练模型</li></ol><h1 id="71db" class="kk kl hh bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">特征抽出</h1><p id="3aa8" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">在主模型训练之前，一些代码加载数据集，设置预处理。您可以直接跳到“创建基础模型”部分。</p><h2 id="da0e" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">导入图库并下载图像</h2><p id="e0a1" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">这个步骤只是导入库和下载训练图像到“训练”和“验证”文件夹</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="df66" class="lq kl hh mj b fi mn mo l mp mq">import matplotlib.pyplot as plt<br/>import numpy as np<br/>import os<br/>import tensorflow as tf</span><span id="4c44" class="lq kl hh mj b fi mr mo l mp mq">_URL = '<a class="ae jc" href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</a><br/>path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)<br/>PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')</span><span id="6b71" class="lq kl hh mj b fi mr mo l mp mq">train_dir = os.path.join(PATH, 'train')<br/>validation_dir = os.path.join(PATH, 'validation')</span></pre><p id="964b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以在keras下载文件夹下看到以下文件夹，/root/。keras/datasets/cats _ and _ dogs _ filtered</p><p id="0595" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">火车</p><p id="10f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">—猫</p><p id="eafb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">—狗</p><p id="e0c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">确认</p><p id="6cba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">—猫</p><p id="181b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">—狗</p><p id="941c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以使用linux工具来检查原始图像大小</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="64e1" class="lq kl hh mj b fi mn mo l mp mq">!apt install file<br/>!apt install -y imagemagick</span><span id="9d75" class="lq kl hh mj b fi mr mo l mp mq">!file /root/.keras/datasets/cats_and_dogs_filtered/train/cats/cat.199.jpg</span><span id="fac8" class="lq kl hh mj b fi mr mo l mp mq">!identify /root/.keras/datasets/cats_and_dogs_filtered/train/cats/cat.199.jpg</span></pre><p id="cd5f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">原始图像大小为270x319。</p><h2 id="284f" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">加载训练和验证数据集</h2><p id="eb0c" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">我们将从训练文件夹加载训练数据集，从验证文件夹加载验证数据集。注意两个<a class="ae jc" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory" rel="noopener ugc nofollow" target="_blank">参数</a> : shuffle，是否对数据进行洗牌。默认值:True。如果设置为False，则按字母数字顺序对数据进行排序。image_size，从磁盘中读取图像后将图像调整到的大小。由于管道处理的成批图像必须具有相同的大小，因此必须提供这一点。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="ed49" class="lq kl hh mj b fi mn mo l mp mq">BATCH_SIZE = 32<br/>IMG_SIZE = (160, 160)</span><span id="3364" class="lq kl hh mj b fi mr mo l mp mq">train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,<br/>                                                            shuffle=True,<br/>                                                            batch_size=BATCH_SIZE,<br/>                                                            image_size=IMG_SIZE)<br/></span><span id="c79f" class="lq kl hh mj b fi mr mo l mp mq">validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,<br/>                                                                 shuffle=True,<br/>                                                                 batch_size=BATCH_SIZE,<br/>                                                                 image_size=IMG_SIZE)</span></pre><p id="03cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于原始数据集不包含测试集，您将创建一个测试集。为此，使用TF . data . experimental . cardinality确定验证集中有多少批数据可用，然后将其中的20%移到测试集中。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="abbb" class="lq kl hh mj b fi mn mo l mp mq">val_batches = tf.data.experimental.cardinality(validation_dataset)<br/>test_dataset = validation_dataset.take(val_batches // 5)<br/>validation_dataset = validation_dataset.skip(val_batches // 5)</span></pre><h2 id="cb12" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">数据扩充和预处理</h2><p id="f1dd" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">您可以向图像添加一些数据扩充以增加数据集大小，从而防止过拟合，例如水平或垂直翻转、旋转以增加训练图像的多样性</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="18ae" class="lq kl hh mj b fi mn mo l mp mq">data_augmentation = tf.keras.Sequential([<br/>  # A preprocessing layer which randomly flips images during training.<br/>  tf.keras.layers.RandomFlip('horizontal_and_vertical'),<br/>  # A preprocessing layer which randomly rotates images during training.<br/>  tf.keras.layers.RandomRotation(0.2),<br/>])</span></pre><p id="3b77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">重新缩放像素值<br/>TF . keras . applications . mobilenetv2模型期望像素值在[-1，1]内，但此时，图像中的像素值在[0，255]内。要重新缩放它们，请使用模型中包含的预处理方法。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="bef7" class="lq kl hh mj b fi mn mo l mp mq">preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input</span></pre><h2 id="346f" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">创建基础模型</h2><p id="6f28" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">我们将使用MobileNetV2，它在移动设备上表现很好。我们将把训练图像传递给基本模型，并由基本模型输出特征。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="3097" class="lq kl hh mj b fi mn mo l mp mq"># Create the base model from the pre-trained model MobileNet V2<br/>IMG_SHAPE = IMG_SIZE + (3,)<br/>base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,<br/>                                               include_top=False,<br/>                                               weights='imagenet')</span><span id="5661" class="lq kl hh mj b fi mr mo l mp mq">image_batch, label_batch = next(iter(train_dataset))<br/>feature_batch = base_model(image_batch)<br/># 32 images, since our batch_size is 32<br/>print(feature_batch.shape)</span></pre><h2 id="f658" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">冻结基础模型</h2><p id="9855" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">当使用基模型作为特征提取层时，在编译和训练模型之前冻结卷积基是很重要的。冻结(通过设置layer.trainable = False)防止给定层中的权重在训练期间被更新。MobileNet V2有许多层，因此将整个模型的可训练标志设置为False将冻结所有层。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="4541" class="lq kl hh mj b fi mn mo l mp mq">base_model.trainable = False</span></pre><h2 id="cd3b" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">设置模型架构</h2><p id="6cdc" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">当您定义模型时，您需要告诉Keras如何将输入映射到输出，在我们的场景中，输入-&gt;数据扩充层-&gt;预处理(重新缩放)层-&gt; mobile v2 net-&gt; globaveragepool2d层-&gt; Dropout层-&gt; Dense层。</p><p id="edd0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要从要素块中生成预测，请在空间5x5空间位置上进行平均，使用TF . keras . layers . globalaveragepooling2d图层将要素转换为每个影像的单个1280元素矢量。这就像GlobalAveragePooling2D在空间维度上应用平均池，直到每个空间维度都是一个。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="a398" class="lq kl hh mj b fi mn mo l mp mq">global_average_layer = tf.keras.layers.GlobalAveragePooling2D()<br/>feature_batch_average = global_average_layer(feature_batch)<br/># (32, 5, 5, 1280) -&gt; (32, 1280)<br/>print(feature_batch_average.shape)</span></pre><p id="5e01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">应用tf.keras.layers.Dense图层将这些要素转换为每个影像的单个预测。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="8143" class="lq kl hh mj b fi mn mo l mp mq">prediction_layer = tf.keras.layers.Dense(1)<br/>prediction_batch = prediction_layer(feature_batch_average)<br/>print(prediction_batch.shape)</span></pre><p id="9109" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">链接各层</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="2ca4" class="lq kl hh mj b fi mn mo l mp mq">inputs = tf.keras.Input(shape=(160, 160, 3))<br/>x = data_augmentation(inputs)<br/>x = preprocess_input(x)<br/>x = base_model(x, training=False)<br/>x = global_average_layer(x)<br/>x = tf.keras.layers.Dropout(0.2)(x)<br/>outputs = prediction_layer(x)<br/>model = tf.keras.Model(inputs, outputs)</span></pre><h2 id="aeae" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">编译模型</h2><p id="29c6" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">指定<a class="ae jc" href="https://data-flair.training/blogs/compile-evaluate-predict-model-in-keras/" rel="noopener ugc nofollow" target="_blank">优化器</a>和<a class="ae jc" href="https://data-flair.training/blogs/compile-evaluate-predict-model-in-keras/" rel="noopener ugc nofollow" target="_blank">损失函数</a></p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="63c6" class="lq kl hh mj b fi mn mo l mp mq">base_learning_rate = 0.0001<br/>model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),<br/>              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),<br/>              metrics=['accuracy'])</span></pre><h2 id="e6a0" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">训练模型</h2><p id="3ac6" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">我们记录了训练的历史，所以以后我们可以继续训练</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="9b88" class="lq kl hh mj b fi mn mo l mp mq">initial_epochs = 10<br/>history = model.fit(train_dataset,<br/>                    epochs=initial_epochs,<br/>                    validation_data=validation_dataset)</span></pre><h1 id="0cbc" class="kk kl hh bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">微调</h1><p id="0c9f" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">微调的主要思想是希望调整预训练模型中的某些权重，尤其是最后几个图层中的权重，以便将一般要素地图的权重调整为与数据集特定关联的要素。您应该尝试微调一小部分顶层，而不是整个MobileNet模型。在大多数卷积网络中，层越高，它就越专门化。前几层学习非常简单和通用的功能，可以推广到几乎所有类型的图像。随着越往上，要素越来越特定于模型所基于的数据集。微调的目标是调整这些专门的功能以适应新的数据集，而不是覆盖一般的学习。</p><h2 id="d746" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">取消冻结模型的顶层</h2><p id="5f8e" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">现在我们想调整预训练模型的权重，但只是在某一层之后。以下代码首先将基本模型设置为可训练的，然后将第100层之前的所有层设置为不可训练的(冻结包含简单和通用功能的早期层)。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="871e" class="lq kl hh mj b fi mn mo l mp mq">base_model.trainable = True</span><span id="7367" class="lq kl hh mj b fi mr mo l mp mq"># Fine-tune from this layer onwards<br/>fine_tune_at = 100</span><span id="0164" class="lq kl hh mj b fi mr mo l mp mq"># Freeze all the layers before the `fine_tune_at` layer<br/>for layer in base_model.layers[:fine_tune_at]:<br/>  layer.trainable = False</span></pre><h2 id="a350" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">设置模型架构</h2><p id="492f" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">我们将使用相同的模型架构，如特征提取案例。</p><h2 id="081a" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">编译模型</h2><p id="7217" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">由于您正在训练一个大得多的模型，并且希望重新调整预训练的权重，因此在此阶段使用较低的学习速率非常重要。否则，您的模型可能会很快过度拟合。</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="ad38" class="lq kl hh mj b fi mn mo l mp mq">model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),<br/>              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),<br/>              metrics=['accuracy'])</span></pre><h2 id="2de7" class="lq kl hh bd km lr ls lt kq lu lv lw ku ip lx ly ky it lz ma lc ix mb mc lg md bi translated">训练模型</h2><p id="b68b" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip ln ir is it lo iv iw ix lp iz ja jb ha bi translated">这里，我们从先前特征提取模型停止的地方继续训练</p><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="411b" class="lq kl hh mj b fi mn mo l mp mq">fine_tune_epochs = 10<br/>total_epochs =  initial_epochs + fine_tune_epochs</span><span id="2699" class="lq kl hh mj b fi mr mo l mp mq">history_fine = model.fit(train_dataset,<br/>                         epochs=total_epochs,<br/>                         initial_epoch=history.epoch[-1],<br/>                         validation_data=validation_dataset)</span></pre><h1 id="f902" class="kk kl hh bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">预言；预测；预告</h1><pre class="me mf mg mh fd mi mj mk ml aw mm bi"><span id="73d7" class="lq kl hh mj b fi mn mo l mp mq"># Retrieve a batch of images from the test set<br/>image_batch, label_batch = test_dataset.as_numpy_iterator().next()<br/>predictions = model.predict_on_batch(image_batch).flatten()</span><span id="a4d9" class="lq kl hh mj b fi mr mo l mp mq"># Apply a sigmoid since our model returns logits<br/>predictions = tf.nn.sigmoid(predictions)<br/>predictions = tf.where(predictions &lt; 0.5, 0, 1)</span><span id="1c62" class="lq kl hh mj b fi mr mo l mp mq">print('Predictions:\n', predictions.numpy())<br/>print('Labels:\n', label_batch)</span><span id="6154" class="lq kl hh mj b fi mr mo l mp mq">plt.figure(figsize=(10, 10))<br/>for i in range(9):<br/>  ax = plt.subplot(3, 3, i + 1)<br/>  plt.imshow(image_batch[i].astype("uint8"))<br/>  plt.title(class_names[predictions[i]])<br/>  plt.axis("off")</span></pre><h1 id="5c86" class="kk kl hh bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">附录</h1><div class="jd je ez fb jf jg"><a href="https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480" rel="noopener follow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">CNN最直观、最简单的指南</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">揭开卷积神经网络的神秘面纱</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">towardsdatascience.com</p></div></div><div class="jp l"><div class="ms l jr js jt jp ju jv jg"/></div></div></a></div><div class="jd je ez fb jf jg"><a href="https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">卷积神经网络架构| CNN架构</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">从事图像识别或物体检测项目，但不具备构建架构的基础？在…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="jp l"><div class="mt l jr js jt jp ju jv jg"/></div></div></a></div><div class="jd je ez fb jf jg"><a href="https://cs231n.github.io/convolutional-networks/" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">用于视觉识别的CS231n卷积神经网络</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">目录:卷积神经网络非常类似于以前的普通神经网络…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">cs231n.github.io</p></div></div><div class="jp l"><div class="mu l jr js jt jp ju jv jg"/></div></div></a></div><div class="jd je ez fb jf jg"><a href="https://sagarsonwane230797.medium.com/transfer-learning-from-pre-trained-model-for-image-facial-recognition-8b0c2038d5f0" rel="noopener follow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">用于图像(面部)识别的预训练模型的迁移学习</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">本文的目的是用迁移学习的方法快速简单地解决图像识别问题。对于…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">sagarsonwane230797.medium.com</p></div></div><div class="jp l"><div class="mv l jr js jt jp ju jv jg"/></div></div></a></div><div class="jd je ez fb jf jg"><a href="https://puneet166.medium.com/how-to-implement-transfer-learning-using-keras-696775a907d5" rel="noopener follow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">如何利用keras实现迁移学习？</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">什么是迁移学习？为什么有用。</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">puneet166.medium.com</p></div></div><div class="jp l"><div class="mw l jr js jt jp ju jv jg"/></div></div></a></div><div class="jd je ez fb jf jg"><a href="https://towardsdatascience.com/4-pre-trained-cnn-models-to-use-for-computer-vision-with-transfer-learning-885cb1b2dfc" rel="noopener follow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">4个预训练的CNN模型，用于具有迁移学习的计算机视觉</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">使用最先进的预训练神经网络模型，通过迁移学习解决计算机视觉问题</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">towardsdatascience.com</p></div></div><div class="jp l"><div class="mx l jr js jt jp ju jv jg"/></div></div></a></div><figure class="me mf mg mh fd my"><div class="bz dy l di"><div class="mz na l"/></div></figure><div class="jd je ez fb jf jg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">medium.com</p></div></div><div class="jp l"><div class="nb l jr js jt jp ju jv jg"/></div></div></a></div></div></div>    
</body>
</html>
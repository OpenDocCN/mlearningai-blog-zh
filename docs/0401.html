<html>
<head>
<title>Painting like Van Gogh using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用深度学习画梵高</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/painting-like-van-goh-using-deep-learning-625ae6678706?source=collection_archive---------2-----------------------#2021-04-05">https://medium.com/mlearning-ai/painting-like-van-goh-using-deep-learning-625ae6678706?source=collection_archive---------2-----------------------#2021-04-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="db02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为一个不太伟大的艺术家，我需要另一种方式来创作艺术。幸运的是，凭借一点张量流和一点数学知识，我能够创作出自己的梵高画作。</p><div class="jc jd je jf fd ab cb"><figure class="jg jh ji jj jk jl jm paragraph-image"><img src="../Images/1a5e30b393a7555e52ae49515d22110b.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*XCxXYGk3X4614IJHzxzAGA.png"/></figure><figure class="jg jh jp jj jk jl jm paragraph-image"><img src="../Images/a9301f5c77c306b375797cc94105eb5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*f30l95Y0oMsv-2HxCwygEQ.png"/><figcaption class="jq jr et er es js jt bd b be z dx ju di jv jw">Toronto stylized with Starry Night and Lake Louise stylized with The Kiss</figcaption></figure></div><h1 id="d8f5" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">怎么会？</h1><h1 id="40ea" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">神经类型转移</h1><blockquote class="kv kw kx"><p id="12d4" class="ie if ky ig b ih ii ij ik il im in io kz iq ir is la iu iv iw lb iy iz ja jb ha bi translated">它通过组合两个图像来创建一个产品图像，该图像具有一个图像的内容和另一个图像的风格。</p></blockquote><p id="f8ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该技术在论文<a class="ae lc" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">艺术风格的神经算法(Gatys等人)中示出。</a></p><p id="cb0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它的工作原理是使用深度神经网络从一个图像中提取风格表示，并从另一个照片中提取内容表示，然后将两者融合在一起，以创建一个匹配内容表示和风格表示的新图像。这就用原来的内容创建了一个新的图像，但是用了新的颜色和纹理。</p><h1 id="b114" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">我们究竟如何提取风格和内容？</h1><h2 id="51a3" class="ld jy hh bd jz le lf lg kd lh li lj kh ip lk ll kl it lm ln kp ix lo lp kt lq bi translated">卷积神经网络</h2><figure class="jc jd je jf fd jh er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/6bc7312c706e718862e33cfe99358754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TbMDtQcPpwAPuFqO.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">CNN | <a class="ae lc" href="https://commons.wikimedia.org/wiki/File:Typical_cnn.png" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></figcaption></figure><p id="45be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积神经网络擅长处理图像。他们能够很容易地将它们分类并识别它们的内容。要达到如此高的性能，CNN对图像有着深刻的理解。在引擎盖下，CNN构建复杂的图像表示来识别独特的特征。它们的许多层协同工作，提取最重要的信息，以正确识别和检测物体。表面层检测一般的直线和曲线，而更深层次的层使用以前的发现来定位更明确的一般对象，如眼睛或四肢。这种处理层次使输入图像能够被转换成捕获关于它的详细信息的表示，包括我们需要知道的提取和表达图像的风格和内容的所有信息。</p><h1 id="8c59" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">履行</h1><p id="21fe" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip ly ir is it lz iv iw ix ma iz ja jb ha bi translated">完整的<a class="ae lc" href="https://colab.research.google.com/drive/1EuR75oG8hcmgEKQ0nAVDLw73kPEPuQAn?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab </a></p><h2 id="8aa0" class="ld jy hh bd jz le lf lg kd lh li lj kh ip lk ll kl it lm ln kp ix lo lp kt lq bi translated">我们的CNN，VGG 19台</h2><figure class="jc jd je jf fd jh er es paragraph-image"><div class="er es mb"><img src="../Images/88890814768a20c00d19941fc5b4dd5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*6H4N_WGdomuMnXnG.jpg"/></div><figcaption class="jq jr et er es js jt bd b be z dx">Architechture of VGG-19 | <a class="ae lc" href="https://www.researchgate.net/figure/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means_fig2_325137356" rel="noopener ugc nofollow" target="_blank">researchgate</a></figcaption></figure><p id="5a63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，需要一个强大的CNN来捕捉错综复杂的绘画和照片。我们可以利用预训练网络的力量，而不是浪费时间训练一个全新的网络。VGG-19是在ImageNet数据集上训练的19层CNN，对图像有很强的理解能力。它可以检测和提取我们需要的所有直线、曲线和图案。</p><p id="ad77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们不训练网络，也不使用它来进行预测，我们可以将trainable设置为false，并删除完全连接的层。</p><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="91e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们从网络中挑选中间层来使用。由于它们来自不同的区块，我们可以理解图像的不同部分，并恰当地捕捉内容和风格。</p><p id="ae52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于风格，我们使用多层来捕捉不同特征图之间的相关性。这些特征相关性允许我们获得输入图像的多级表示，以捕捉纹理信息，而不是特定的全局排列。</p><h2 id="a58d" class="ld jy hh bd jz le lf lg kd lh li lj kh ip lk ll kl it lm ln kp ix lo lp kt lq bi translated">要素制图表达</h2><p id="fcbc" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip ly ir is it lz iv iw ix ma iz ja jb ha bi translated">为了捕获内容特征，我们只需将内容图像传递到模型中，并保存我们选择的中间层的特征映射。</p><p id="f41e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，对于样式表示，我们通过模型传递样式图像，并获取我们为样式选择的中间层的特征图。</p><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><h2 id="987f" class="ld jy hh bd jz le lf lg kd lh li lj kh ip lk ll kl it lm ln kp ix lo lp kt lq bi translated">失败</h2><p id="5079" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip ly ir is it lz iv iw ix ma iz ja jb ha bi translated">为了能够组合两个图像并且都优化以捕捉一个图像的风格和另一个图像的内容，我们需要两个单独的损失。一个用来捕捉风格的差异，另一个用来捕捉内容的差异。</p><p id="e9df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算内容损失相当简单，我们只需计算原始内容图像和我们正在创建的图像的特征之间的均方误差。我们得到特定<strong class="ig hi">局部</strong>形状的精确差异。</p><p id="b177" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于风格损失，它变得有点棘手。由于艺术风格由色彩和纹理等组成，我们不能只找到特征图之间的差异。我们需要一种方法来捕捉更多关于图像的一般<strong class="ig hi">非本地化</strong>信息。</p><h2 id="f749" class="ld jy hh bd jz le lf lg kd lh li lj kh ip lk ll kl it lm ln kp ix lo lp kt lq bi translated">介绍格拉姆矩阵</h2><p id="0d08" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip ly ir is it lz iv iw ix ma iz ja jb ha bi translated">gram矩阵允许我们捕捉图像的更一般的画面，而不是特定的局部信息。格拉姆矩阵是由张量乘以它的转置矩阵得到的。</p><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="5d32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过将一个张量乘以它自己的转置，gram矩阵有效地将原始信息扩散和重新分布到它本身，以去除局部化的数据点。</p><p id="253a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算样式损失，我们测量参考样式图像的样式表示的gram矩阵和正在创建的图像的样式表示的gram矩阵之间的均方误差。由于我们使用了多个层，我们为不同的层分配不同的权重，以强调某些层的特征。</p><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="7c40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着训练的进行，产品图像的内容和风格损失被减少和最小化，以创建具有原始内容但具有新风格的图像。</p><h2 id="e723" class="ld jy hh bd jz le lf lg kd lh li lj kh ip lk ll kl it lm ln kp ix lo lp kt lq bi translated">培养</h2><p id="3065" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip ly ir is it lz iv iw ix ma iz ja jb ha bi translated">现在一起。</p><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="34d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的训练循环中，我们加载样式图像一次，内容图像两次。一个将用于提取内容特征，另一个将是我们的产品图像。在训练过程中，我们将对产品图像执行梯度下降，以最大限度地减少这两种损失。</p><p id="b87e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在开始训练之前，我们提取原始图像的内容和风格特征，并计算风格的gram矩阵。</p><p id="39e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于每个训练步骤，我们计算梯度，然后将它们应用于产品图像。在每一步，如果损失最低，我们保存产品图像。</p><figure class="jc jd je jf fd jh"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="7888" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最终，我们将拥有损失最小化的产品形象，这是我们原始内容和风格形象的融合。</p><h1 id="6810" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">结果</h1><p id="fcac" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip ly ir is it lz iv iw ix ma iz ja jb ha bi translated">我们可以很容易地将风景与著名的绘画和建筑结合起来</p><figure class="jc jd je jf fd jh er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es me"><img src="../Images/43293377ce1e6369cf534acde0041be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MoJTzXyKoVXQA5m2B46PLA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae lc" href="https://www.britannica.com/place/Toronto" rel="noopener ugc nofollow" target="_blank">Toronto landscape</a> stylized with P<a class="ae lc" href="https://www.nasa.gov/image-feature/the-pillars-of-creation/" rel="noopener ugc nofollow" target="_blank">illars of Creation</a>, <a class="ae lc" href="https://en.wikipedia.org/wiki/The_Scream" rel="noopener ugc nofollow" target="_blank">The Scream</a>, and <a class="ae lc" href="https://www.vangoghgallery.com/painting/starry-night.html" rel="noopener ugc nofollow" target="_blank">Starry Night</a></figcaption></figure><p id="7451" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它也适用于肖像</p><figure class="jc jd je jf fd jh er es paragraph-image"><div class="er es mf"><img src="../Images/5446e9cf408293e04b808fcec2e636b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*P_CZg4m1l8CSXektzo9q-Q.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae lc" href="https://en.wikipedia.org/wiki/Mona_Lisa" rel="noopener ugc nofollow" target="_blank">Mona Lisa</a> and American Gothic stylized with <a class="ae lc" href="https://en.wikipedia.org/wiki/American_Gothic" rel="noopener ugc nofollow" target="_blank">The Scream</a></figcaption></figure><h1 id="56ca" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">结论</h1><ol class=""><li id="9bca" class="mg mh hh ig b ih lw il lx ip mi it mj ix mk jb ml mm mn mo bi translated">神经艺术风格转移可以将来自单独图像的风格和内容组合起来，并创建一个新的图像。它告诉我们，风格和内容是可以分离和抽象的。</li><li id="04da" class="mg mh hh ig b ih mp il mq ip mr it ms ix mt jb ml mm mn mo bi translated">CNN可以从图像中提取抽象表示</li><li id="441a" class="mg mh hh ig b ih mp il mq ip mr it ms ix mt jb ml mm mn mo bi translated">gram矩阵允许我们捕捉关于图像的非本地化信息</li></ol><p id="0401" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">在你离开之前，一定要查看一下</strong><a class="ae lc" href="https://colab.research.google.com/drive/1EuR75oG8hcmgEKQ0nAVDLw73kPEPuQAn?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">Google Colab</strong></a><strong class="ig hi">的完整代码</strong></p></div></div>    
</body>
</html>
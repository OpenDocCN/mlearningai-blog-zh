<html>
<head>
<title>Live Webcam with Streamlit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带Streamlit的实时网络摄像头</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/live-webcam-with-streamlit-f32bf68945a4?source=collection_archive---------0-----------------------#2022-06-01">https://medium.com/mlearning-ai/live-webcam-with-streamlit-f32bf68945a4?source=collection_archive---------0-----------------------#2022-06-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="9107" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">一个用于手部跟踪和其他实时视觉任务的web演示应用程序</h2></div><p id="a330" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Streamlit是一个非常好的创建网络演示的工具:今天我们很好地看到了T2的streamlit-webrtc库，它可以从浏览器获得一个网络摄像头组件(也可以在移动设备上，我在Android和Chrome上测试过)。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es jt"><img src="../Images/1845042a3bebb36fcead3be976f299bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*eWGKDzeMkpr3cBX5ozvARw.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx">Hand tracking <a class="ae js" href="https://share.streamlit.io/nicolalandro/hand_tracking_streamlit/main/app.py" rel="noopener ugc nofollow" target="_blank">demo</a></figcaption></figure><p id="8db2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">深度学习有一些有趣的实时视觉任务，特别是本文重点关注的<a class="ae js" href="https://z-uo.medium.com/hand-tracking-with-opencv-and-mediapipe-on-python-991dfae615d6" rel="noopener">手跟踪</a>和<a class="ae js" rel="noopener" href="/ml-research-lab/what-is-object-detection-51f9d872ece7">物体检测</a>。</p><h2 id="0086" class="kf kg hh bd kh ki kj kk kl km kn ko kp jf kq kr ks jj kt ku kv jn kw kx ky kz bi translated">手跟踪</h2><p id="6058" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">我选择<a class="ae js" href="https://google.github.io/mediapipe/solutions/hands" rel="noopener ugc nofollow" target="_blank"> Mediapipe </a>作为实现实时手部跟踪的库，所以我用下面的代码创建了一个Streamlit演示(<a class="ae js" href="https://github.com/nicolalandro/hand_tracking_streamlit" rel="noopener ugc nofollow" target="_blank"> full repo </a>和<a class="ae js" href="https://share.streamlit.io/nicolalandro/hand_tracking_streamlit/main/app.py" rel="noopener ugc nofollow" target="_blank"> demo </a>)，我将一步一步地解释:</p><p id="a514" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们首先需要定义我们的进口:</p><pre class="ju jv jw jx fd lf lg lh li aw lj bi"><span id="c55a" class="kf kg hh lg b fi lk ll l lm ln">import cv2<br/>import numpy as np<br/>import av<br/>import mediapipe as mp<br/>from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration</span></pre><p id="a30e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以通过创建一个使用网络摄像头的虚拟工作流应用程序来继续:</p><pre class="ju jv jw jx fd lf lg lh li aw lj bi"><span id="2321" class="kf kg hh lg b fi lk ll l lm ln">mp_drawing = mp.solutions.drawing_utils<br/>mp_drawing_styles = mp.solutions.drawing_styles<br/>mp_hands = mp.solutions.hands<br/>hands = mp_hands.Hands(<br/>    model_complexity=0,<br/>    min_detection_confidence=0.5,<br/>    min_tracking_confidence=0.5<br/>)</span><span id="e0d8" class="kf kg hh lg b fi lo ll l lm ln">RTC_CONFIGURATION = RTCConfiguration(<br/>    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}<br/>)</span><span id="c06a" class="kf kg hh lg b fi lo ll l lm ln">webrtc_ctx = webrtc_streamer(<br/>    key="TEST",<br/>    mode=WebRtcMode.SENDRECV,<br/>    rtc_configuration=RTC_CONFIGURATION,<br/>    media_stream_constraints={"video": True, "audio": False},<br/>    async_processing=True,<br/>)</span></pre><p id="f86e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们也只需要<em class="lp"> webrtc_streamer </em>指令，但是当我们在远程服务器上部署它时，我们也需要指定iceServer(参见<a class="ae js" href="https://github.com/whitphx/streamlit-webrtc/issues/832" rel="noopener ugc nofollow" target="_blank">本期</a>)。</p><p id="63ec" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们可以定义虚拟图像处理类(VideoProcessor ),它返回相同的图像而不进行处理:</p><pre class="ju jv jw jx fd lf lg lh li aw lj bi"><span id="18e0" class="kf kg hh lg b fi lk ll l lm ln">class VideoProcessor:<br/>    def recv(self, frame):<br/>        img = frame.to_ndarray(format="bgr24")</span><span id="4e8f" class="kf kg hh lg b fi lo ll l lm ln">        # img = process(img)</span><span id="40e6" class="kf kg hh lg b fi lo ll l lm ln">        return av.VideoFrame.from_ndarray(img, format="bgr24")</span><span id="1bdf" class="kf kg hh lg b fi lo ll l lm ln">webrtc_ctx = webrtc_streamer(<br/>    key="WYH",<br/>    mode=WebRtcMode.SENDRECV,<br/>    rtc_configuration=RTC_CONFIGURATION,<br/>    media_stream_constraints={"video": True, "audio": False},<br/>    video_processor_factory=VideoProcessor,<br/>    async_processing=True,<br/>)</span></pre><p id="da34" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在我们可以实现process函数来获得完整的代码(<strong class="iy hi"> app.py </strong>):</p><pre class="ju jv jw jx fd lf lg lh li aw lj bi"><span id="8201" class="kf kg hh lg b fi lk ll l lm ln">import cv2<br/>import numpy as np<br/>import av<br/>import mediapipe as mp<br/>from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration</span><span id="ba79" class="kf kg hh lg b fi lo ll l lm ln">mp_drawing = mp.solutions.drawing_utils<br/>mp_drawing_styles = mp.solutions.drawing_styles<br/>mp_hands = mp.solutions.hands<br/>hands = mp_hands.Hands(<br/>    model_complexity=0,<br/>    min_detection_confidence=0.5,<br/>    min_tracking_confidence=0.5<br/>)</span><span id="0914" class="kf kg hh lg b fi lo ll l lm ln">def process(image):<br/>    image.flags.writeable = False<br/>    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>    results = hands.process(image)</span><span id="9914" class="kf kg hh lg b fi lo ll l lm ln"># Draw the hand annotations on the image.<br/>    image.flags.writeable = True<br/>    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)<br/>    if results.multi_hand_landmarks:<br/>      for hand_landmarks in results.multi_hand_landmarks:<br/>        mp_drawing.draw_landmarks(<br/>            image,<br/>            hand_landmarks,<br/>            mp_hands.HAND_CONNECTIONS,<br/>            mp_drawing_styles.get_default_hand_landmarks_style(),<br/>            mp_drawing_styles.get_default_hand_connections_style())<br/>    return cv2.flip(image, 1)</span><span id="5028" class="kf kg hh lg b fi lo ll l lm ln">RTC_CONFIGURATION = RTCConfiguration(<br/>    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}<br/>)</span><span id="4182" class="kf kg hh lg b fi lo ll l lm ln">class VideoProcessor:<br/>    def recv(self, frame):<br/>        img = frame.to_ndarray(format="bgr24")</span><span id="f959" class="kf kg hh lg b fi lo ll l lm ln">img = process(img)</span><span id="4622" class="kf kg hh lg b fi lo ll l lm ln">return av.VideoFrame.from_ndarray(img, format="bgr24")</span><span id="9eec" class="kf kg hh lg b fi lo ll l lm ln">webrtc_ctx = webrtc_streamer(<br/>    key="WYH",<br/>    mode=WebRtcMode.SENDRECV,<br/>    rtc_configuration=RTC_CONFIGURATION,<br/>    media_stream_constraints={"video": True, "audio": False},<br/>    video_processor_factory=VideoProcessor,<br/>    async_processing=True,<br/>)</span></pre><h2 id="4a79" class="kf kg hh bd kh ki kj kk kl km kn ko kp jf kq kr ks jj kt ku kv jn kw kx ky kz bi translated">在Streamlit上部署</h2><p id="576c" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">web演示可以在这个<a class="ae js" href="https://share.streamlit.io/nicolalandro/hand_tracking_streamlit/main/app.py" rel="noopener ugc nofollow" target="_blank">链接</a>使用，我使用<a class="ae js" href="https://share.streamlit.io/" rel="noopener ugc nofollow" target="_blank"> share.streamlit.io </a>来部署它，这对公共github项目是免费的。</p><p id="9fc2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以第一步提交github上的conde，包括含有所需python库列表的<strong class="iy hi"> requirements.txt </strong>文件</p><pre class="ju jv jw jx fd lf lg lh li aw lj bi"><span id="59a2" class="kf kg hh lg b fi lk ll l lm ln">streamlit                             <br/>streamlit_webrtc                                                           opencv-python                             <br/>mediapipe==0.8.9.1</span></pre><p id="8c9a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后是包含我们需要的(ubuntu apt install)系统库列表的<strong class="iy hi"> packages.txt </strong>文件:</p><pre class="ju jv jw jx fd lf lg lh li aw lj bi"><span id="f661" class="kf kg hh lg b fi lk ll l lm ln">python3-opencv</span></pre><p id="ae4d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">登录<a class="ae js" href="https://share.streamlit.io/" rel="noopener ugc nofollow" target="_blank"> share.streamlit.io </a>创建新应用并按照步骤操作，记住选择正确的回购和正确的streamlit应用名称。</p><p id="0ade" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">手部追踪<a class="ae js" href="https://share.streamlit.io/nicolalandro/hand_tracking_streamlit/main/app.py" rel="noopener ugc nofollow" target="_blank">试玩</a>上线！</p><h2 id="6704" class="kf kg hh bd kh ki kj kk kl km kn ko kp jf kq kr ks jj kt ku kv jn kw kx ky kz bi translated">目标检测</h2><p id="d15b" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">在对象检测的情况下，我做了同样的事情:用对象检测库(<a class="ae js" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> yolov5 </a>)构建一个streamlit脚本，创建requirements.txt和packages.txt，但为了获得在streamlit上部署的实时性，我必须缩小很多图像，因为它可以实时处理最大的图像，但使用了<a class="ae js" href="https://share.streamlit.io/" rel="noopener ugc nofollow" target="_blank">共享的GPU。</a></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lq"><img src="../Images/598a1824d0f9f5f6a279c83d394c2ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*cmuYifGHqnBhEiDM3IJXxA.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx">Objecct Detection <a class="ae js" href="https://share.streamlit.io/nicolalandro/yolov5_streamlit/main" rel="noopener ugc nofollow" target="_blank">demo</a></figcaption></figure><p id="c547" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">完整的代码可以在<a class="ae js" href="https://github.com/nicolalandro/yolov5_streamlit" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae js" href="https://share.streamlit.io/nicolalandro/yolov5_streamlit/main" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="7e3d" class="kf kg hh bd kh ki kj kk kl km kn ko kp jf kq kr ks jj kt ku kv jn kw kx ky kz bi translated">结论</h2><p id="aec5" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">Streamlit每天都在增长，更多的库的到来使ti更加强大和易于使用:是的，拥有一个完全定制的应用程序并不是一个好的选择，但用几行代码创建好的演示应用程序是可能的，我们也可以将其免费放到网上。</p><p id="bc1c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">多亏了开源，这才成为可能！因此，使用它来创建您的美丽和创新的演示和分享！</p><div class="lr ls ez fb lt lu"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lv ab dw"><div class="lw ab lx cl cj ly"><h2 class="bd hi fi z dy lz ea eb ma ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mb l"><h3 class="bd b fi z dy lz ea eb ma ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mc l"><p class="bd b fp z dy lz ea eb ma ed ef dx translated">medium.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi jz lu"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>The Experiment of Forest Fires Prediction using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的森林火灾预测实验</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/the-experiment-of-forest-fires-prediction-using-deep-learning-d537e8c8e3a2?source=collection_archive---------0-----------------------#2022-02-13">https://medium.com/mlearning-ai/the-experiment-of-forest-fires-prediction-using-deep-learning-d537e8c8e3a2?source=collection_archive---------0-----------------------#2022-02-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="40d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">森林火灾是重要的灾害性事件之一，对环境、基础设施和人类生活都有很大影响。针对森林火灾预警探测系统的需求，已经采用了多种方法，包括:基于物理的模型、统计模型、机器学习模型和深度学习模型。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/6deb5d24394d217b263e0de4ebcebb8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1iwVlEE6KGw-VzX9.jpg"/></div></div></figure><p id="3466" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文旨在通过深度学习，根据发现火灾的空间、时间和天气变量，进行超参数调整实验，以预测葡萄牙东北部地区森林火灾的烧毁面积。</p><p id="0ddc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用来自UCI机器学习资源库的公共数据集:<a class="ae jo" href="http://archive.ics.uci.edu/ml/datasets/Forest+Fires" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/datasets/Forest+Fires</a>。这一预测可用于计算派往事故现场的部队，并确定局势的紧迫性。我们将使用的方法是具有分类问题的人工神经网络/深度学习来预测森林火灾。</p><p id="7ad9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">人工神经网络概述:</strong> <br/>人工神经网络由具有输入和输出维度的层组成。后者由<strong class="ig hi">神经元</strong>(也称为“节点”)的数量决定，计算单元通过<strong class="ig hi">激活函数</strong>连接加权输入(帮助神经元打开/关闭)。与大多数机器学习算法一样，<strong class="ig hi">权重和</strong>权重在训练期间被随机初始化和优化，以最小化损失函数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/c4981a819ee9b955dbebd66e60e4c7ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/0*NZ_-MWNWB4vfkQYk.gif"/></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae jo" href="https://towardsdatascience.com/deep-learning-with-python-neural-networks-complete-tutorial-6b53c0b06af0" rel="noopener" target="_blank">Deep Learning with Python: Neural Networks (complete tutorial)</a></figcaption></figure><p id="9ddc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是进行实验的步骤:</p><h1 id="adc8" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第1步:理解数据集</h1><p id="9654" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">在导入数据集之前，必须导入所需的库。</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="d24b" class="lc jv hh ky b fi ld le l lf lg">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>plt.style.use('seaborn')<br/>import seaborn as sns<br/>from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler</span><span id="cbfe" class="lc jv hh ky b fi lh le l lf lg">from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import r2_score<br/>import tensorflow as tensorflow<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout<br/>from tensorflow import keras<br/>from tensorflow.keras import layers<br/>from tensorflow.keras.optimizers import SGD<br/>from tensorflow.keras.utils import to_categorical<br/>from keras.callbacks import EarlyStopping<br/>from keras.callbacks import ModelCheckpoint<br/>from keras.utils.vis_utils import plot_model</span></pre><p id="777c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文使用的数据集来自UCI机器学习资源库:<a class="ae jo" href="http://archive.ics.uci.edu/ml/datasets/Forest+Fires" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/datasets/Forest+Fires</a></p><p id="aa0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要导入数据集，请执行以下步骤:</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="ae5c" class="lc jv hh ky b fi ld le l lf lg">df = pd.read_csv('dataset.csv')<br/>df.head(10)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es li"><img src="../Images/6fefe49761467b6dfa2ab146dffc5c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OOK9gD9_n1MD85k7pxwPgg.png"/></div></div></figure><p id="809c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">属性信息:</strong></p><ul class=""><li id="12a6" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated"><strong class="ig hi"> X </strong>:蒙特辛霍公园地图内X轴空间坐标:1-9</li><li id="4762" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi"> Y </strong>:蒙特辛霍公园地图内的Y轴空间坐标:2-9</li><li id="58a8" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">月</strong>:一年中的月份:“1月”至“12月”</li><li id="6d0b" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">日</strong>:周一至周日</li><li id="117b" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">FFMC</strong>:FWI系统FFMC(精细燃料水分代码)指数:18.7 ~ 96.20</li><li id="85b5" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi"> DMC </strong>:来自FWI系统的DMC(Duff weather Code)指数:1.1至291.3</li><li id="f342" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">DC</strong>:FWI系统DC(旱情代码)指数:7.9 ~ 860.6</li><li id="66b5" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">ISI</strong>:FWI系统ISI(初始利差指数)指数:0.0 ~ 56.10</li><li id="be15" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">温度</strong>:摄氏温度:2.2至33.30度</li><li id="8c31" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">相对湿度</strong>:相对湿度百分比:15.0至100</li><li id="9533" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">风</strong>:风速以千米/小时为单位:0.40至9.40</li><li id="549e" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">雨</strong>:室外雨，单位为毫米/平方米:0.0至6.4</li><li id="d536" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">面积</strong>:森林过火面积(公顷):0.00-1090.84</li></ul><h1 id="5851" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤2:数据预处理</h1><h2 id="f9e1" class="lc jv hh bd jw lx ly lz ka ma mb mc ke ip md me ki it mf mg km ix mh mi kq mj bi translated">1)添加新列= size_category</h2><p id="c2c1" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">对于分类问题，我们尝试添加一个新列，即<code class="du mk ml mm ky b">size_category</code>来将数据分为两类:</p><ul class=""><li id="b360" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated">如果<code class="du mk ml mm ky b">area</code> &lt;的值为6那么<code class="du mk ml mm ky b">size_category</code>将被标记为0(小火)</li><li id="ec7a" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated">如果<code class="du mk ml mm ky b">area</code>的值≥ 6，那么<code class="du mk ml mm ky b">size_category</code>将被标记为1(宽火)</li></ul><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="9775" class="lc jv hh ky b fi ld le l lf lg">df['size_category'] = np.where(df['area']&gt;6, '1', '0')<br/>df['size_category']= pd.to_numeric(df['size_category'])<br/>df.tail(10)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mn"><img src="../Images/4b138f4400dec889b13415d672dfce0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aTNDDXEyLoRjNkId6zgI_Q.png"/></div></div></figure><h2 id="fb88" class="lc jv hh bd jw lx ly lz ka ma mb mc ke ip md me ki it mf mg km ix mh mi kq mj bi translated">2)数天的数据预处理</h2><p id="cecb" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated"><code class="du mk ml mm ky b">day</code>的分布看起来很漂亮。我们将不编码7个变量，而是将它们分成周末(<code class="du mk ml mm ky b">True</code>)或非周末(<code class="du mk ml mm ky b">False</code>)。假设火灾中燃烧的面积也与消防员对火焰的反应有关。在周末，消防队员的数量或总体反应可能与工作日不同。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/8f8216e35a7806e8ae6b40a4e5429edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/0*8vRSFWy7wadlV-Qu"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="eed7" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># converting to is weekend</strong><br/>df['day'] = ((df['day'] == 'sun') | (df['day'] == 'sat'))</span><span id="ee02" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># renaming column</strong><br/>df = df.rename(columns = {'day' : 'is_weekend'})</span><span id="3f12" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># visualizing</strong><br/>sns.countplot(df['is_weekend'])<br/>plt.title('Count plot of weekend vs weekday')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mp"><img src="../Images/3ecdc1a06ac28ed40cf2d4850e06b70e.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/0*pqMVWNXSdlJkhbxw"/></div></figure><p id="198a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">偏斜不是太大，所以我们对这种转换很满意。</p><h2 id="f491" class="lc jv hh bd jw lx ly lz ka ma mb mc ke ip md me ki it mf mg km ix mh mi kq mj bi translated">3)结垢区域和雨水</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mq"><img src="../Images/a0be7cf77d7708f6b81a55d8e634d9ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*neB73_M12k6iqRMS3qfhsg.png"/></div></figure><p id="0d10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du mk ml mm ky b">rain</code>和<code class="du mk ml mm ky b">area</code>的分布过于倾斜，有很大的异常值，因此我们将对其进行缩放，以使分布均匀。</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="fe24" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># natural logarithm scaling (+1 to prevent errors at 0)</strong><br/>df.loc[:, ['rain', 'area']] = df.loc[:, ['rain', 'area']].apply(lambda x: np.log(x + 1), axis = 1)</span><span id="2579" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># visualizing</strong><br/>fig, ax = plt.subplots(2, figsize = (5, 8))<br/>ax[0].hist(df['rain'])<br/>ax[0].title.set_text('histogram of rain')<br/>ax[1].hist(df['area'])<br/>ax[1].title.set_text('histogram of area')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mr"><img src="../Images/c27c1a91fc640fb3e932071e0f88cd2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/0*7C6pw0D2mr6YHQtQ"/></div></figure><p id="0711" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du mk ml mm ky b">rain</code>的分布不好，但<code class="du mk ml mm ky b">area</code>的分布有很大改善。现在我们缩放整个数据集。请注意，我们计划在数据集上测试一个神经网络，因此我们将缩放该区域，作为应对爆炸梯度的预防措施。</p><p id="65dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们将数据分割成<strong class="ig hi">训练和测试分割</strong>，这样我们可以缩放训练集，然后基于训练集缩放测试集。然后我们将扩展一切。</p><h2 id="54a0" class="lc jv hh bd jw lx ly lz ka ma mb mc ke ip md me ki it mf mg km ix mh mi kq mj bi translated"><strong class="ak"> 4)列车试分裂</strong></h2><p id="7bec" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">数据被随机分成训练数据(80 %)和测试数据(20%)。</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="3c62" class="lc jv hh ky b fi ld le l lf lg">features = df.drop(['size_category'], axis = 1)<br/>labels = df['size_category'].values.reshape(-1, 1)</span><span id="fda7" class="lc jv hh ky b fi lh le l lf lg">X_train, X_test, y_train, y_test = train_test_split(features,labels, test_size = 0.2, random_state = 42)</span></pre><h2 id="6711" class="lc jv hh bd jw lx ly lz ka ma mb mc ke ip md me ki it mf mg km ix mh mi kq mj bi translated">5)特征缩放:标准缩放器</h2><p id="9999" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">对数据应用特征缩放:标准缩放器</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="5713" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># fitting scaler</strong><br/>sc_features = StandardScaler()</span><span id="6440" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># transforming features</strong><br/>X_test = sc_features.fit_transform(X_test)<br/>X_train = sc_features.transform(X_train)</span><span id="ae1d" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># features</strong><br/>X_test = pd.DataFrame(X_test, columns = features.columns)<br/>X_train = pd.DataFrame(X_train, columns = features.columns)</span><span id="9220" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># labels</strong><br/>y_test = pd.DataFrame(y_test, columns = ['size_category'])<br/>y_train = pd.DataFrame(y_train, columns = ['size_category'])</span><span id="5ed9" class="lc jv hh ky b fi lh le l lf lg">X_train.head()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ms"><img src="../Images/8fe863f15bceb800be49f26a2be0064b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aY0Tl0EoVYu0K1gHOQqZkA.png"/></div></div></figure><h1 id="31d5" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤3:超参数/实验结果</h1><h1 id="509a" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">1)实验1:基础模型</h1><p id="196e" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">在这里，我们将通过使用某个名为Sequential的Keras类来创建我们的ANN对象。一旦我们初始化我们的人工神经网络，我们现在要创建层。在这里，我们将创建一个基础模型网络，它将具有:</p><ul class=""><li id="4750" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated">1个输入层</li><li id="0f9b" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated">2个隐藏层</li><li id="111f" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated">1个脱落层</li><li id="f505" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated">1个输出层</li></ul><p id="c36b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我们已经创建了我们的第一个隐藏层，使用的是层模块中的密集类。该类接受2个输入:</p><ul class=""><li id="197d" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated"><strong class="ig hi">单位</strong>:将出现在相应层中的神经元数量</li><li id="e587" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">激活</strong>:指定使用哪个激活功能</li></ul><p id="3876" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们创建一系列层来定义神经网络，并通过初始化权重、定义激活函数和选择每个隐藏层的节点来定义每一层。</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="d8ad" class="lc jv hh ky b fi ld le l lf lg">model = Sequential()</span><span id="8da4" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># input layer + 1st hidden layer</strong><br/>model.add(Dense(6, input_dim=13, activation='relu'))</span><span id="fc3a" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># 2nd hidden layer</strong><br/>model.add(Dense(6, activation='relu'))</span><span id="5dbf" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># output layer</strong><br/>model.add(Dense(6, activation='sigmoid'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(1, activation = 'relu'))</span><span id="2f92" class="lc jv hh ky b fi lh le l lf lg">model.summary()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mt"><img src="../Images/0b79b51c19e53da879ec9a83599055fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*fTPzLsCBFrHURmsvS8H60w.png"/></div></figure><p id="86ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步，我们将使用下面的超参数编译我们的ANN:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl mu"><img src="../Images/9977525ffe3e77e45cfd081475e5e01c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*SORgaiMZjsvXfP6OwtDXFA.png"/></div></figure><ul class=""><li id="c9a4" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated"><strong class="ig hi">纪元</strong>:神经网络将被训练多少次</li><li id="e1ee" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">批次大小</strong>:批次中应该有多少个观察值。</li><li id="e724" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">激活函数</strong>:激活函数的主要作用是将来自节点的总加权输入转换成输出值，以馈送到下一个隐藏层或作为输出。</li><li id="96c6" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">损失函数</strong>:损失函数用于确定我们算法的输出与给定目标值之间的误差。</li><li id="6c75" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">学习率:</strong>学习率是一个超参数，它控制每次更新模型权重时，根据估计误差改变模型的程度。</li><li id="8c02" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">优化器</strong>:优化器是用于最小化误差函数(损失函数)或最大化生产效率的算法或方法。</li></ul><p id="53d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了检查这些方法的性能，我们计算了精度度量。</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="e815" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># Compile Model</strong><br/>model.compile(optimizer = 'adam', metrics=['accuracy'], loss ='binary_crossentropy')</span><span id="c088" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Train Model<br/></strong>history = model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 10, epochs = 100)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mv"><img src="../Images/25e1466c347c158f9c1925f592f65fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35knwzm806Rid1gGhgAvzg.png"/></div></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="0f67" class="lc jv hh ky b fi ld le l lf lg">_, train_acc = model.evaluate(X_train, y_train, verbose=0)<br/>_, valid_acc = model.evaluate(X_test, y_test, verbose=0)<br/>print('Train: %.3f, Valid: %.3f' % (train_acc, valid_acc))</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mw"><img src="../Images/e043b3669923eeb1908f787a4b3869c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*26Z9RTRlEDZYi5JOOL0_WQ.png"/></div></figure><p id="4db3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于使用基础模型的超参数的实验1的结果，训练数据的准确度分数是96%，有效或测试数据的准确度分数是92%。</p><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="c52e" class="lc jv hh ky b fi ld le l lf lg">plt.figure(figsize=[8,5])<br/>plt.plot(history.history['accuracy'], label='Train')<br/>plt.plot(history.history['val_accuracy'], label='Valid')<br/>plt.legend()<br/>plt.xlabel('Epochs', fontsize=16)<br/>plt.ylabel('Accuracy', fontsize=16)<br/>plt.title('Accuracy Curves Epoch 100, Batch Size 10', fontsize=16)<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mx"><img src="../Images/0934b090617149d9215a4b8ca70fe815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tyMQwubEprU9jxOpYbVnZw.png"/></div></figure><p id="8dd4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于准确度图的输出，模型开始显示在时期60到100的稳定性。</p><h1 id="a0b3" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">2)实验二:批量:4，6，10，16，32，64，128，260</h1><p id="8bea" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">对于实验2，我们将使用如下超参数细节进行人工神经网络建模:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es my"><img src="../Images/06ddbb526be68f25e28d09ac8d822a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*FrUfkSKy7-wqfE2h1BXg-Q.png"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="5c2c" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># Fit a model and plot learning curve<br/></strong>def fit_model(X_train, y_train, X_test, y_test, n_batch):</span><span id="c0a1" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Define Model<br/></strong>model = Sequential()<br/>model.add(Dense(6, input_dim=13, activation='relu'))<br/>model.add(Dense(6, activation='relu'))<br/>model.add(Dense(6, activation='sigmoid'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(1, activation = 'relu'))</span><span id="0f75" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Compile Model</strong><br/>model.compile(optimizer = 'adam',<br/>metrics=['accuracy'],<br/>loss = 'binary_crossentropy')</span><span id="8e1a" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Fit Model</strong><br/>history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0, batch_size=n_batch)</span><span id="9e08" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Plot Learning Curves<br/></strong>plt.plot(history.history['accuracy'], label='train')<br/>plt.plot(history.history['val_accuracy'], label='test')<br/>plt.title('batch='+str(n_batch))<br/>plt.legend()</span><span id="2412" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Create learning curves for different batch sizes<br/></strong>batch_sizes = [4, 6, 10, 16, 32, 64, 128, 260]</span><span id="8c84" class="lc jv hh ky b fi lh le l lf lg">plt.figure(figsize=(10,15))<br/>for i in range(len(batch_sizes)):</span><span id="cd93" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Determine the Plot Number<br/></strong>plot_no = 420 + (i+1)<br/>plt.subplot(plot_no)</span><span id="a2a1" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Fit model and plot learning curves for a batch size<br/></strong>fit_model(X_train, y_train, X_test, y_test, batch_sizes[i])</span><span id="6edb" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Show learning curves</strong><br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mz"><img src="../Images/5ccf061fde216fb4910f9c97e94aac76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*XXnnLLdvd32_b9LYlvjl4A.png"/></div></figure><p id="c3be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据上面的精度图，足以显示稳定性的型号是<strong class="ig hi"> batch = 6的型号。</strong></p><h1 id="49fe" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">3)实验3:批量= 6，时期= 20，50，100，120，150，200，300，400</h1><p id="f170" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">对于实验3，我们将使用如下超参数细节进行人工神经网络建模:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es na"><img src="../Images/aeaefa26fd68b4f329b92f5415d74c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*sRsFB4QyykQGlklTe66pqg.png"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="d8c4" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># fit a model and plot learning curve<br/></strong>def fit_model(trainX, trainy, validX, validy, n_epoch):</span><span id="b853" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># define model<br/></strong>model = Sequential()<br/>model.add(Dense(6, input_dim=13, activation='relu'))<br/>model.add(Dense(6, activation='relu'))<br/>model.add(Dense(6, activation='sigmoid'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(1, activation = 'relu'))</span><span id="e96b" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># compile model<br/></strong>model.compile(optimizer ='adam', metrics=['accuracy'], loss = 'binary_crossentropy')</span><span id="cf23" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># fit model<br/></strong>history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=n_epoch, verbose=0, batch_size=6)</span><span id="aa23" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># plot learning curves<br/></strong>plt.plot(history.history['accuracy'], label='train')<br/>plt.plot(history.history['val_accuracy'], label='test')<br/>plt.title('epoch='+str(n_epoch))<br/>plt.legend()</span><span id="5f1d" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Create learning curves for different batch sizes<br/></strong>epochs = [20, 50, 100, 120, 150, 200, 300, 400]</span><span id="6d40" class="lc jv hh ky b fi lh le l lf lg">plt.figure(figsize=(10,15))<br/>for i in range(len(batch_sizes)):</span><span id="9879" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Determine the Plot Number</strong><br/>plot_no = 420 + (i+1)<br/>plt.subplot(plot_no)</span><span id="5cc9" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Fit model and plot learning curves for a batch size</strong><br/>fit_model(X_train, y_train, X_test, y_test, epochs[i])</span><span id="d79e" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># Show learning curves</strong><br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mz"><img src="../Images/0bc972c847134962c45abadafc6f7fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*LVZtU6HKQn5T2_MsfD99kg.png"/></div></figure><p id="00ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据上面的精度图，足以显示稳定性的模型是epoch = 200、300和400 <strong class="ig hi">的模型。</strong></p><h1 id="0f11" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4)实验四</h1><h2 id="d073" class="lc jv hh bd jw lx ly lz ka ma mb mc ke ip md me ki it mf mg km ix mh mi kq mj bi translated">批量= 6，<strong class="ak">提前停止(耐心，模型检查点)</strong></h2><p id="ef93" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">对于实验4，我们将使用如下超参数细节进行人工神经网络建模:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nb"><img src="../Images/55c4f28670880f84750e146bed2d4327.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*t8DHKH9yuIu491XYHvA9JQ.png"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="88e0" class="lc jv hh ky b fi ld le l lf lg">def init_model():</span><span id="e111" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># define model<br/></strong>model = Sequential()<br/>model.add(Dense(6, input_dim=13, activation='relu'))<br/>model.add(Dense(6, activation='relu'))model.add(Dense(6, activation='sigmoid'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(1, activation = 'relu'))<br/>model.compile(optimizer ='adam',<br/>metrics=['accuracy'],<br/>loss = 'binary_crossentropy')</span><span id="4af9" class="lc jv hh ky b fi lh le l lf lg">return model</span><span id="e692" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># init model</strong><br/>model = init_model()</span><span id="9bc6" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># simple early stopping<br/></strong>es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)</span><span id="f576" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># model checkpoint<br/></strong>mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)</span><span id="31fa" class="lc jv hh ky b fi lh le l lf lg"><strong class="ky hi"># fitting model<br/></strong>history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=250, verbose=0, batch_size=6, callbacks=[es, mc])</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nc"><img src="../Images/079d0bab2ea8edc5e87500ea12d8c3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*rsPGz2dLyGZ_MrpV0qCLvQ.png"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="9f15" class="lc jv hh ky b fi ld le l lf lg"><strong class="ky hi"># plot training history</strong><br/>plt.plot(history.history['loss'], label='train')<br/>plt.plot(history.history['val_loss'], label='valid')<br/>plt.legend()<br/>plt.xlabel('Epochs', fontsize=14)<br/>plt.ylabel('Loss', fontsize=14)<br/>plt.title('Loss Curves', fontsize=16)<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nd"><img src="../Images/c2272735e1cff5acfdafc3cd8d0deb7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*-w_mAzuzLilVMm9jdAHrtQ.png"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="7656" class="lc jv hh ky b fi ld le l lf lg">plt.figure(figsize=[8,5])<br/>plt.plot(history.history['accuracy'], label='Train')<br/>plt.plot(history.history['val_accuracy'], label='Valid')<br/>plt.legend()<br/>plt.xlabel('Epochs', fontsize=16)<br/>plt.ylabel('Accuracy', fontsize=16)<br/>plt.title('Accuracy Curves', fontsize=16)<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ne"><img src="../Images/8c04cf2511558248a4ffb4337e3787a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*AQ9YGrPvhziaCl0J6iLqoQ.png"/></div></figure><pre class="jd je jf jg fd kx ky kz la aw lb bi"><span id="4e62" class="lc jv hh ky b fi ld le l lf lg">_, train_acc = model.evaluate(X_train, y_train, verbose=0)<br/>_, valid_acc = model.evaluate(X_test, y_test, verbose=0)<br/>print('Train: %.3f, Valid: %.3f' % (train_acc, valid_acc))</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nf"><img src="../Images/47beff2d1cf12a46abc743fb7e30d15d.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*BT_1WJ6-OUHOqC7dLeaw4Q.png"/></div></figure><p id="97b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于实验4的结果，使用有耐心的早期停止和模型检查点方法，训练数据的准确度分数是97%，有效或测试数据的准确度分数是99%。</p><h1 id="8fcc" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论和讨论</h1><p id="7be0" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">控制森林火灾的关键成功之一是早期发现火灾。在本文中，我们进行了超参数调整实验，以预测葡萄牙东北部地区的森林火灾燃烧面积，基于使用深度学习发现火灾的空间、时间和天气变量。</p><p id="9def" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了找到另一种最佳方法，我们建议使用数据预处理的其他选项，并尝试使用机器学习算法，如支持向量机(SVM)、决策树、随机森林分类器、朴素贝叶斯分类器等。</p><h1 id="eabf" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考资料:</h1><p id="07d2" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated"><a class="ae jo" href="http://archive.ics.uci.edu/ml/datasets/Forest+Fires" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/datasets/Forest+Fires</a></p><div class="ng nh ez fb ni nj"><a href="https://github.com/psohn/Only-You-Can-Prevent-Forest-Fires/blob/master/1.0_prs_preprocessing_eda.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hi fi z dy no ea eb np ed ef hg bi translated">只有你能预防森林火灾/1.0 _ PRS _ preprocessing _ EDA . ipynb at master…</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">葡萄牙森林火灾回归模型预测火灾损失…</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">github.com</p></div></div><div class="ns l"><div class="nt l nu nv nw ns nx jm nj"/></div></div></a></div><div class="ng nh ez fb ni nj"><a href="https://github.com/psohn/Only-You-Can-Prevent-Forest-Fires/blob/master/3.0_prs_artificial_neural_network.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hi fi z dy no ea eb np ed ef hg bi translated">只有你能预防森林火灾/3.0 _ PRS _ artificial _ neural _ network . ipynb at master…</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">葡萄牙森林火灾回归模型预测火灾损失…</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">github.com</p></div></div><div class="ns l"><div class="ny l nu nv nw ns nx jm nj"/></div></div></a></div><div class="ng nh ez fb ni nj"><a href="https://www.kaggle.com/psvishnu/forestfire-impact-prediction-stats-and-ml" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hi fi z dy no ea eb np ed ef hg bi translated">森林火灾影响预测(统计和ml)</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自森林火灾数据集的数据</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">www.kaggle.com</p></div></div><div class="ns l"><div class="nz l nu nv nw ns nx jm nj"/></div></div></a></div><div class="ng nh ez fb ni nj"><a href="https://towardsdatascience.com/deep-learning-with-python-neural-networks-complete-tutorial-6b53c0b06af0" rel="noopener follow" target="_blank"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hi fi z dy no ea eb np ed ef hg bi translated">Python深度学习:神经网络(完整教程)</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">用TensorFlow建立、绘制和解释人工神经网络</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="oa l nu nv nw ns nx jm nj"/></div></div></a></div><div class="ng nh ez fb ni nj"><a href="https://www.analyticsvidhya.com/blog/2021/10/implementing-artificial-neural-networkclassification-in-python-from-scratch/" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hi fi z dy no ea eb np ed ef hg bi translated">从零开始用Python实现人工神经网络</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">神经网络。21世纪蓬勃发展的技术突破之一。你有兴趣创造…</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="ns l"><div class="ob l nu nv nw ns nx jm nj"/></div></div></a></div><div class="ng nh ez fb ni nj"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hi fi z dy no ea eb np ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">medium.com</p></div></div><div class="ns l"><div class="oc l nu nv nw ns nx jm nj"/></div></div></a></div><p id="2de9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🟠在MLearning.ai  成为<a class="ae jo" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"> <strong class="ig hi">作家</strong></a></p></div></div>    
</body>
</html>
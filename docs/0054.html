<html>
<head>
<title>Multiclass Classification with Image Augmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像增强的多类分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/multiclass-classification-with-image-augmentation-834c16122a3b?source=collection_archive---------3-----------------------#2020-10-11">https://medium.com/mlearning-ai/multiclass-classification-with-image-augmentation-834c16122a3b?source=collection_archive---------3-----------------------#2020-10-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="f693" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">这篇文章解释了多类图像分类的基础知识以及如何执行图像增强。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/feb686705c64e4d569605ad16dae6ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qkhQmX6qEs17A4Rca54pIg.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@marcus_wallis" rel="noopener ugc nofollow" target="_blank">Marcus Wallis</a><strong class="bd jn"> </strong>on <a class="ae jm" href="https://unsplash.com/s/photos/rock-paper-scissors" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="38db" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">什么是图像增强？</p><p id="5a23" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi kk translated"><span class="l kl km kn bm ko kp kq kr ks di">我</span>法师增强，解决了<strong class="jq hi">数据有限的问题</strong>。图像增强是一种技术，可用于通过在数据集中创建图像的修改版本来人工<strong class="jq hi">扩展训练数据集</strong>的大小。图像增强包括一套增强训练图像的大小和质量的技术，以便可以使用它们建立更好的深度学习模型。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es kt"><img src="../Images/331950f3ef6c61eb556b10698c6c53dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*VUaSURSH3jUk6eEu9x7F9Q.gif"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image Augmentation</figcaption></figure><h1 id="0ca0" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">张量流的安装</h1><h1 id="6f75" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">先决条件</h1><ul class=""><li id="fe19" class="ll lm hh jq b jr ln ju lo jx lp kb lq kf lr kj ls lt lu lv bi translated">Linux，macOS，Windows</li><li id="29f0" class="ll lm hh jq b jr lw ju lx jx ly kb lz kf ma kj ls lt lu lv bi translated">Python ≥ 3.7</li></ul><h1 id="ce32" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">安装TensorFlow</h1><p id="50ce" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated"><strong class="jq hi">纯CPU</strong></p><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="a92b" class="mj kv hh mf b fi mk ml l mm mn">pip install “tensorflow&gt;=1.15.2,&lt;2.0”<br/><strong class="mf hi">or</strong> <br/>conda install tensorflow’&gt;=1.15.2,&lt;2.0.0'</span></pre><p id="0913" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated"><strong class="jq hi"> GPU支持</strong></p><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="593a" class="mj kv hh mf b fi mk ml l mm mn">pip install “tensorflow-gpu&gt;=1.15.2,&lt;2.0”<br/><strong class="mf hi">or</strong> <br/>conda install tensorflow-gpu’&gt;=1.15.2,&lt;2.0.0'</span></pre><h1 id="8b88" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">健全性检查</h1><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="19f5" class="mj kv hh mf b fi mk ml l mm mn"><strong class="mf hi">&gt;&gt; </strong>import<strong class="mf hi"> tensorflow </strong>as<strong class="mf hi"> tf<br/></strong>&gt;&gt; <strong class="mf hi">tf</strong>.__version__<br/>'2.3.0'</span></pre><p id="46f4" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">现在，我们将使用来自Kaggle的<a class="ae jm" href="https://www.kaggle.com/sanikamal/rock-paper-scissors-dataset" rel="noopener ugc nofollow" target="_blank">石头剪刀布数据集</a>来执行多类图像分类。</p><h1 id="9763" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">让我们投入进去吧！！！</h1><h1 id="d064" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">1.数据集探索</h1><p id="56b3" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">数据集有三个目录，即训练、测试和验证。这里，train和test有三类图像，validation有一个要测试的图像列表。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="1280" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">输出是，</p><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="9c90" class="mj kv hh mf b fi mk ml l mm mn">Train set --&gt;  ['paper', 'scissors', 'rock']<br/>Test set --&gt;  ['paper', 'scissors', 'rock']<br/>Validation set --&gt;  ['paper8.png', 'paper1.png', 'scissors-hires1.png']</span></pre><h1 id="ab97" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">2.数据集示例</h1><p id="4b9a" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">让我们显示数据集中每个类的随机图像。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="8acb" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">所以，这些图像是，</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mq"><img src="../Images/093d4607451061e8a656596228574508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3cvnM7UffgdwL4Uk_nL4bg.png"/></div></div></figure><h1 id="bd62" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">3.定义CNN模型</h1><p id="5530" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">该模型包括五种不同类型的层，</p><ul class=""><li id="4b6f" class="ll lm hh jq b jr js ju jv jx mr kb ms kf mt kj ls lt lu lv bi translated"><strong class="jq hi">卷积层</strong>:该层将从图像中提取重要特征</li><li id="0beb" class="ll lm hh jq b jr lw ju lx jx ly kb lz kf ma kj ls lt lu lv bi translated"><strong class="jq hi">汇集层</strong> r:该层通过隔离重要特征，减少卷积后输入图像的空间体积</li><li id="6917" class="ll lm hh jq b jr lw ju lx jx ly kb lz kf ma kj ls lt lu lv bi translated"><strong class="jq hi">展平层:</strong>将输入展平成一维数组</li><li id="5fb4" class="ll lm hh jq b jr lw ju lx jx ly kb lz kf ma kj ls lt lu lv bi translated"><strong class="jq hi">隐藏层</strong>:也称为密集层，将网络从一层连接到另一层</li><li id="afa1" class="ll lm hh jq b jr lw ju lx jx ly kb lz kf ma kj ls lt lu lv bi translated"><strong class="jq hi">输出层</strong>:是由神经元组成的最后一层，与类别数相等</li></ul><p id="81af" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">这里，我们有三类图像，因此，输出层应该有三个神经元。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="7c12" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">这个模型的总结是，</p><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="003c" class="mj kv hh mf b fi mk ml l mm mn">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 148, 148, 32)      896       <br/>_________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     <br/>_________________________________________________________________<br/>max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    <br/>_________________________________________________________________<br/>max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 6272)              0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 512)               3211776   <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 1)                 513       <br/>=================================================================<br/>Total params: 3,453,121<br/>Trainable params: 3,453,121<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><h1 id="a326" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">4.模型编译和回调函数</h1><p id="dc13" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">对于这个模型，我们使用<em class="mu"> adam </em>优化器和<em class="mu">分类_交叉熵</em>作为损失函数。<br/>这里的回调函数将在达到准确率&gt; 95%时，在历元结束时停止模型的训练。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h1 id="bd08" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">5.发电机</h1><h2 id="bb29" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">具有图像增强的训练生成器</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="5ace" class="mj kv hh mf b fi mk ml l mm mn">Found 2520 images belonging to 3 classes.</span></pre><h2 id="9215" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">验证生成器</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="057a" class="mj kv hh mf b fi mk ml l mm mn">Found 372 images belonging to 3 classes.</span></pre><h1 id="2166" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">6.拟合模型</h1><p id="65cf" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">因为我们使用发电机代替<em class="mu">型号。fit </em>我们需要使用<em class="mu">型号。拟合_生成器</em>功能</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="ccb1" class="mj kv hh mf b fi mk ml l mm mn">Epoch 1/10<br/>126/126 - 46s - loss: 1.0141 - accuracy: 0.4591 - val_loss: 0.4937 - val_accuracy: 0.9301<br/>Epoch 2/10<br/>126/126 - 27s - loss: 0.5067 - accuracy: 0.7968 - val_loss: 0.0886 - val_accuracy: 0.9785<br/>Epoch 3/10<br/>126/126 - 27s - loss: 0.2712 - accuracy: 0.9056 - val_loss: 0.1290 - val_accuracy: 0.9624<br/>Epoch 4/10<br/>126/126 - 27s - loss: 0.1608 - accuracy: 0.9393 - val_loss: 0.1045 - val_accuracy: 0.9597<br/>Epoch 5/10<br/><br/>Reached &gt;95% accuracy so cancelling training!<br/>126/126 - 26s - loss: 0.1408 - accuracy: 0.9512 - val_loss: 0.0784 - val_accuracy: 0.9677</span></pre><h1 id="b764" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">7.可视化模型训练</h1><p id="e601" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">让我们将模型的准确性和损失分布在整个时期</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="cbd7" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">得到的图形是，</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ni"><img src="../Images/d70d47d58d4f7392153e23eb7c84913a.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*ary8ye3WZjhf-ZmUrN6Cdw.png"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ni"><img src="../Images/a011e3aaac29741e04d51e3b4697d133.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*T2-Q8lTKIEy9Kgb1IJZfsQ.png"/></div></figure><p id="84ca" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">我们可以看到，对于每个历元，精度增加，损耗下降</p><h1 id="879d" class="ku kv hh bd jn kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">8.预言；预测；预告</h1><h2 id="62cc" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">测试数据的准备</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nj"><img src="../Images/0ec32ad499d2c1a2d35efc37798e6a11.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*qCWH3klTsFV8cQFka0ildQ.png"/></div></figure><h2 id="51b1" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">测试生成器</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="3bc8" class="mj kv hh mf b fi mk ml l mm mn">Found 33 validated image filenames.</span></pre><h2 id="349f" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">模型预测法</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="d3b7" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">标签映射</h2><p id="ff2e" class="pw-post-body-paragraph jo jp hh jq b jr ln ii jt ju lo il jw jx mb jz ka kb mc kd ke kf md kh ki kj ha bi translated">为了识别图像的标签，使用了<em class="mu">class _ indexes</em>函数</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="4d53" class="mj kv hh mf b fi mk ml l mm mn">{0: 'paper', 1: 'rock', 2: 'scissors'}</span></pre><h2 id="bf62" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">绘制预测图</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nk"><img src="../Images/e99797d01c49f6b76c3a658ed1bcd2e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*GQatFtcQ7h9MP4tgWmETOQ.png"/></div></figure><h2 id="3984" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">在看不见的图像上模拟性能</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nl"><img src="../Images/c2d13e02e7c5165c86030687e7b93ac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MxfWCzkPfwBh6SpZ_YGPtA.png"/></div></div></figure><h2 id="2bbe" class="mj kv hh bd jn mv mw mx kz my mz na ld jx nb nc lf kb nd ne lh kf nf ng lj nh bi translated">看不见的图像上的模型精度</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mo mp l"/></div></figure><pre class="ix iy iz ja fd me mf mg mh aw mi bi"><span id="554e" class="mj kv hh mf b fi mk ml l mm mn">Accuracy of the model on test data is 93.94%</span></pre><p id="0dce" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">完整的代码可在<a class="ae jm" href="https://www.kaggle.com/kamalkhumar/multiclass-classification-with-image-augmentation" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="4662" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">感谢阅读！！！</p></div></div>    
</body>
</html>
<html>
<head>
<title>Various Computer Vision Architectures — What’s the difference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">各种计算机视觉架构——有何不同</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/various-computer-vision-architectures-whats-the-difference-db123df23865?source=collection_archive---------0-----------------------#2021-11-27">https://medium.com/mlearning-ai/various-computer-vision-architectures-whats-the-difference-db123df23865?source=collection_archive---------0-----------------------#2021-11-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/f3f6bb70137220164f0cb68b3d9a06b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1nH0MLCgtQYI42TN.jpg"/></div></div></figure><p id="7ee0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">计算机视觉作为一个话题开始于20世纪60年代末。计算机视觉的目标是模仿人类的视觉和理解。计算机视觉的基础是图像处理。在现代，图像处理与人工智能算法相结合，以模仿人脑对图像的功能。与数字数据不同，图像需要以不同的方式进行处理和解释，以便计算机做出任何有意义的输出。很长一段时间以来，CNN一直是机器学习领域的趋势。但是传统的CNN在大规模思考时有很多缺点。为了克服这一点，已经设计了许多架构。在这篇文章中，我们将看看各种流行的计算机视觉体系结构，它们的设计和特点。</p><p id="9581" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">AlexNet </p><p id="9801" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">AlexNet是在2012年为大规模图像分类设计的，准确地说是1000个类别。设计从11x11卷积层开始，移动到5x5，并缩小到3x3。AlexNet总共包含8层——5层CNN和3层Pooling。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es jn"><img src="../Images/e523287eb622959a3b3610b263f39004.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*RZXF-vH4ZQf7uhoi3P7UyA.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx"><a class="ae jw" href="https://en.wikipedia.org/wiki/AlexNet" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/AlexNet</a></figcaption></figure><p id="c769" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于在GPU上训练大数据集(ImageNet ), Alex net获得了良好的准确性。</p><p id="16c4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> ResNet </strong></p><p id="6823" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">非常深的网络可能会提供良好的结果，但在某些时候，可能会导致梯度消失的问题。这是因为要更新大量的权重，随着算法到达网络的早期层，梯度不断变小(反向传播从后面开始)。ResNet是一个大规模深度神经网络，它使用跳过连接来防止消失梯度，并增加网络的整体性能。ResNet跳过几层，一般是2、3层。这确保了在训练网络时，在较早的层上梯度不会下降到0。为了更好地理解，请看一下设计:</p><figure class="jo jp jq jr fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="a6ce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> VGG </strong></p><p id="41f6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">类似于AlexNet，VGG是基于传统CNN架构的大规模图像分类。VGG也有其他变体——VGG-16和VGG-19是普遍使用的变体，分别有16层和19层。VGG和AlexNet的区别在于，与AlexNet相比，VGG专注于更小的内核和更大的跨度，并且拥有更深层次的架构。此外，与AlexNet相比，VGG拥有更多的ReLU单元，因为其架构更深，因此映射功能更具识别性，性能也更好。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es jz"><img src="../Images/fd2db1e4ae1147010ba677a568ea6c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:286/format:webp/1*Y8jS2ookOeFFiequ89FZdg.png"/></div></figure><p id="d658" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">谷歌网</p><p id="6a96" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">GoogeNet是由Google研究人员使用Inception模块的修改版本开发的CNN架构。inception模块并排使用多个过滤器，并将它们的输出合并到一个层中。</p><p id="30cb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Inception的优点是图像内信息的位置不会影响网络，因为多个过滤器被组合，并且信息被全部组合成一个。这避免了对任何深度网络和消失梯度下降的需要，同时保持了任何网络的准确性。此外，与深度网络相比，更宽的网络更容易训练。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ka"><img src="../Images/707010ddf4e88e6f3070aad1bab91acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7ePRwsHL1SDmqAyh.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx"><a class="ae jw" href="https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-22_at_3.28.59_PM.png" rel="noopener ugc nofollow" target="_blank">https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-22_at_3.28.59_PM.png</a></figcaption></figure><p id="e7e5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">仔细观察该架构，您可以看到网络中间有两个softmax层。在训练阶段考虑来自这两者的损失，以防止任何消失梯度。这被建议在训练结束时发挥作用，此时损失和准确性达到饱和。</p><p id="5ff1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> DenseNet </strong></p><p id="e8d1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">到目前为止，我们看到的网络是以连续的方式将一层的输出传送到另一层。DenseNet的工作与此完全相反。DenseNet是一个紧密连接的神经网络，其中每一层的输出都被发送到其他每一层，以实现特征重用。这样，网络可以是浅层的，但同时由于其密集的性质，可以有效地学习特征。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kb"><img src="../Images/3512fe43f66eff273a82fd154c4a14d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UbAZS4XX5Ie0sOP-.jpg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx"><a class="ae jw" href="https://cloud.githubusercontent.com/assets/8370623/17981494/f838717a-6ad1-11e6-9391-f0906c80bc1d.jpg" rel="noopener ugc nofollow" target="_blank">https://cloud.githubusercontent.com/assets/8370623/17981494/f838717a-6ad1-11e6-9391-f0906c80bc1d.jpg</a></figcaption></figure><p id="9571" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">DenseNet主要由两部分组成——dense block和过渡层。DenseBlock具有卷积、批量标准化和具有密集连接的ReLU，而过渡层使用1x1卷积降低了模型的复杂性，并使用2步最大池降低了输出的高度和宽度。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kc"><img src="../Images/0debf48077e633da80b58e4701a2f400.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0EwtkMj4zxh7Ld4t.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx"><a class="ae jw" href="https://miro.medium.com/max/1400/1*qg5cCnke3684W1w5z32ddg.png" rel="noopener">https://miro.medium.com/max/1400/1*qg5cCnke3684W1w5z32ddg.png</a></figcaption></figure><p id="4f7a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">高效网</strong></p><p id="eaa4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">高效网络考虑了CNN的缩放。根据实验研究，已经证明随着图像分辨率的增加，增加深度和高度对于带来良好的精度是必要的。但是扩展任何一个都只有有限的好处，因此有了复合扩展的概念。复合缩放设计了一个原则，即<em class="kd">深度</em>、<em class="kd">宽度</em>和<em class="kd">分辨率</em>必须以平衡的方式进行缩放。在对定义深度、宽度和分辨率应该发生多少缩放的参数α、β和γ执行网格搜索时，得出结论:为了缩放CNN，深度应该增加20%，宽度应该增加10%，分辨率应该增加15%。这些值在缩放比例之间保持平衡，并提供有效的结果。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ke"><img src="../Images/112da51064d62dea41091793aa571147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UPPlVgKC_pBvkqXY.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx"><a class="ae jw" href="https://1.bp.blogspot.com/-Cdtb97FtgdA/XO3BHsB7oEI/AAAAAAAAEKE/bmtkonwgs8cmWyI5esVo8wJPnhPLQ5bGQCLcBGAs/s1600/image4.png" rel="noopener ugc nofollow" target="_blank">https://1.bp.blogspot.com/-Cdtb97FtgdA/XO3BHsB7oEI/AAAAAAAAEKE/bmtkonwgs8cmWyI5esVo8wJPnhPLQ5bGQCLcBGAs/s1600/image4.png</a></figcaption></figure><p id="8cf3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">感谢您的阅读！</p></div><div class="ab cl kf kg go kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ha hb hc hd he"><h2 id="a463" class="km kn hh bd ko kp kq kr ks kt ku kv kw ja kx ky kz je la lb lc ji ld le lf lg bi translated">有用的链接:</h2><p id="4988" class="pw-post-body-paragraph ip iq hh ir b is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji ll jk jl jm ha bi translated">在LinkedIn上找到我:<a class="ae jw" href="https://linkedin.com/in/vishnuu0399" rel="noopener ugc nofollow" target="_blank">https://linkedin.com/in/vishnuu0399</a></p><p id="0e97" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">更了解我:<a class="ae jw" href="https://bit.ly/vishnu-u" rel="noopener ugc nofollow" target="_blank">https://bit.ly/vishnu-u</a></p><div class="lm ln ez fb lo lp"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lq ab dw"><div class="lr ab ls cl cj lt"><h2 class="bd hi fi z dy lu ea eb lv ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lw l"><h3 class="bd b fi z dy lu ea eb lv ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lx l"><p class="bd b fp z dy lu ea eb lv ed ef dx translated">medium.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md in lp"/></div></div></a></div></div></div>    
</body>
</html>
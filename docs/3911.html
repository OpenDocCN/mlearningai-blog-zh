<html>
<head>
<title>DeepxG Tutorial Part 2: Train your own Deep Learning Model to predict Expected Goals (xG)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepxG教程第2部分:训练自己的深度学习模型，预测预期目标(xG)</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/deepxg-tutorial-part-2-train-your-own-deep-learning-model-to-predict-expected-goals-xg-425e4e9636bd?source=collection_archive---------3-----------------------#2022-11-09">https://medium.com/mlearning-ai/deepxg-tutorial-part-2-train-your-own-deep-learning-model-to-predict-expected-goals-xg-425e4e9636bd?source=collection_archive---------3-----------------------#2022-11-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="c742" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">使用Pytorch和Pytorch-lightning训练深度学习模型</h2></div><h1 id="a021" class="iw ix hh bd iy iz ja jb jc jd je jf jg in jh io ji iq jj ir jk it jl iu jm jn bi translated"><strong class="ak">简介</strong></h1><p id="2f2e" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">欢迎回到DeepxG教程的第2部分！在<a class="ae kk" rel="noopener" href="/mlearning-ai/deep-xg-training-your-own-expected-goals-xg-deep-learning-model-cbb9b9eb5465">第一部分</a>中，我们了解到<a class="ae kk" href="https://en.wikipedia.org/wiki/Expected_goals" rel="noopener ugc nofollow" target="_blank"> xG </a>是一个度量标准，它告诉我们射门得分的概率是多少。我们还介绍了创建数据集的步骤。今天，我们将浏览一些代码，利用这些数据集来训练我们自己的深度学习模型。我们将触及如何嵌入和自我关注层可以用来处理分类和序列数据。我们将主要使用的库是<a class="ae kk" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> pytorch </a>、<a class="ae kk" href="https://www.pytorchlightning.ai/" rel="noopener ugc nofollow" target="_blank"> pytorch-lightning </a>和<a class="ae kk" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn </a>。本文将分为以下几个部分:</p><ul class=""><li id="136d" class="kl km hh jq b jr kn ju ko jx kp kb kq kf kr kj ks kt ku kv bi translated"><strong class="jq hi"> DataModules: </strong>在PyTorch-lightning中，DataModules负责以一种我们的模型可以使用的格式加载和转换数据集。数据模块执行的一些常见操作是将数据集分成小批、填充任何顺序数据、数据扩充等。在这一节中，我们将单步执行一些代码来创建我们的数据模块。</li><li id="17a1" class="kl km hh jq b jr kw ju kx jx ky kb kz kf la kj ks kt ku kv bi translated"><strong class="jq hi">嵌入和关注:</strong>在本节中，我们将简要介绍什么是嵌入和关注，以及我们如何在足球赛事数据中使用它们。</li><li id="a706" class="kl km hh jq b jr kw ju kx jx ky kb kz kf la kj ks kt ku kv bi translated"><strong class="jq hi">模型架构和训练:</strong>在这一部分，我们将遍历一些代码来创建我们的深度学习模型，解释在模型的正向传递中会发生什么，以及我们如何训练模型。</li></ul><p id="8d7b" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated"><em class="le">编辑:在与计算各种指标相关的代码中发现了一个bug。需要通过应用sigmoid函数将模型向前传递的logit得分转换为概率得分。测试集上的代码要点、图像和最终度量已经更新，以反映该修复。</em></p></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><h1 id="8251" class="iw ix hh bd iy iz lm jb jc jd ln jf jg in lo io ji iq lp ir jk it lq iu jm jn bi translated">数据模块</h1><h2 id="b936" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated"><strong class="ak">数据集</strong></h2><p id="a63a" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">让我们开始创建数据模块。前几行代码导入了我们需要的所有库和函数。</p><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="c815" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">创建数据模块的第一步是创建PyTorch <a class="ae kk" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html" rel="noopener ugc nofollow" target="_blank">数据集</a>。在构造器中(第11-19行)，我们从<a class="ae kk" rel="noopener" href="/mlearning-ai/deep-xg-training-your-own-expected-goals-xg-deep-learning-model-cbb9b9eb5465">第1部分</a>加载训练/验证/测试数据集。模式变量决定了我们将哪个数据集加载到内存中。在第12行中，我们用-1替换任何nan变量。预测xG可以被<strong class="jq hi">视为一个二元分类</strong> <strong class="jq hi">任务</strong>。即，给定关于射门的一些特征，我们预测射门是否会导致进球。第13–14行创建了一个变量，该变量根据原始事件数据存储射门是否导致进球。这将是我们分类任务的标签。</p><p id="ba51" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">我们的数据集包含四种类型的特征，第15–19行提取了这些不同的特征:</p><ul class=""><li id="ec58" class="kl km hh jq b jr kn ju ko jx kp kb kq kf kr kj ks kt ku kv bi translated"><strong class="jq hi">分类:</strong>投篮技术名称、身体部位名称、位置名称、传球技术名称、投篮区域</li><li id="97a9" class="kl km hh jq b jr kw ju kx jx ky kb kz kf la kj ks kt ku kv bi translated"><strong class="jq hi">分类顺序:</strong>传递顺序</li><li id="3c37" class="kl km hh jq b jr kw ju kx jx ky kb kz kf la kj ks kt ku kv bi translated"><strong class="jq hi">布尔:</strong>欠压特征可以是真也可以是假。</li><li id="4ebe" class="kl km hh jq b jr kw ju kx jx ky kb kz kf la kj ks kt ku kv bi translated"><strong class="jq hi">连续:</strong>拍摄角度，拍摄距离</li></ul><p id="46d8" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">第21–24行处理向数据加载器返回数据集的长度，并在数据加载器提供索引(<em class="le"> item) </em>时返回相应的数据行。需要注意的关键是，我们批处理中的每个条目将由5个项目组成<em class="le"> pass_sequence、shot_zone、categorical _ features、continouns+boolean features和label。当我们解释我们的模型架构时，这种格式的原因将变得更加清楚。</em></p><h2 id="9dc0" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated">数据模块</h2><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="6ebd" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">这个模块非常简单，但是非常有用。pytorch-lightning根据我们是否处于模型训练管道的训练、验证或测试阶段，计算出它需要使用哪个数据加载器。我们创建了一个<em class="le"> custom_collate </em>函数(第9-12行)来处理我们的顺序数据。</p><p id="07bd" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">我们的序列特征/变量是投篮前传球区域的序列。<strong class="jq hi">需要注意的是，不同的传递序列可以有不同的长度。</strong>然而，如果批量大于1 ，我们就不能拥有长度可变的张量<strong class="jq hi">。为此，我们填充所有的通过序列，以匹配批次</strong>中最长通过序列的<strong class="jq hi">长度。我们的pad token id是80，这是第81个区域，即一个不存在的区域。我们已经在第1部分的<a class="ae kk" rel="noopener" href="/mlearning-ai/deep-xg-training-your-own-expected-goals-xg-deep-learning-model-cbb9b9eb5465">中介绍了原因。我们的collate函数被所有的数据加载器调用来处理<em class="le"> pass_sequence </em>特性。</a></strong></p></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><h1 id="0037" class="iw ix hh bd iy iz lm jb jc jd ln jf jg in lo io ji iq lp ir jk it lq iu jm jn bi translated">嵌入和自我关注</h1><p id="0491" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">分类变量给只能接受数字数据作为输入的机器学习算法带来了一个独特的问题。用于处理分类变量的一些常见技术有标签编码、一键编码、二进制编码等。这个<a class="ae kk" href="https://contrib.scikit-learn.org/category_encoders/" rel="noopener ugc nofollow" target="_blank">库</a>是学习更多分类数据编码技术的好资源。然而，深度学习的扩散使得利用<strong class="jq hi">嵌入层</strong>来处理分类数据变得非常流行。</p><h2 id="1f0b" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated"><strong class="ak">嵌入图层</strong></h2><p id="4996" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">嵌入层将唯一的id映射到n维向量。嵌入层的一个主要优点是<strong class="jq hi">它是机器学习模型的一个参数，它的权重(n维向量的值)可以通过任何优化算法更新，例如SGD或Adam </strong>。在<a class="ae kk" rel="noopener" href="/mlearning-ai/deep-xg-training-your-own-expected-goals-xg-deep-learning-model-cbb9b9eb5465">第1部分</a>中，我们通过利用<em class="le">标签编码器将每个分类变量的值映射到一个唯一的id。</em>这背后的原因是将分类变量的每个值映射到我们嵌入空间中的一个n维向量。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div class="er es mm"><img src="../Images/a5459a0730dc1e31c75bbc28a41f7d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*X94dVpWUJq4uSiIk30tmhw.png"/></div><figcaption class="mp mq et er es mr ms bd b be z dx">The embedding layer maps an ID to an N-dimensional Vector</figcaption></figure><h2 id="f38b" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated">注意力</h2><p id="feb1" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated"><em class="le"> pass_sequence </em>特征由分类变量的<strong class="jq hi">序列组成。当通过嵌入层时，我们将获得一系列嵌入。由于不同的序列在不同的批次</strong>中可以有不同的长度<strong class="jq hi">，我们需要找到一种方法来获得包含序列</strong>中所有嵌入的<strong class="jq hi">摘要的单个向量。这是自然语言处理中常见的一个问题，在自然语言处理中，表示文档的标记数量可能是可变的。处理这种情况的一些常见技术是取所有嵌入的平均值(平均值池)、取所有嵌入的总和、取所有嵌入的最大值(最大池)等。然而，使用<a class="ae kk" href="https://lilianweng.github.io/posts/2018-06-24-attention/" rel="noopener ugc nofollow" target="_blank">注意力</a>(这个博客很神奇)层已经被证明在不同的深度学习架构中极其有效。</strong></p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="er es mt"><img src="../Images/b52e2582be5de75450eb0cddf2f012e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iPtKqEiuFhUONsi_ciMHXg.png"/></div></div><figcaption class="mp mq et er es mr ms bd b be z dx">Illustration of how Attention Weights can be used to obtain sequence summary</figcaption></figure><p id="1ee9" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">【attention背后的思想是找到序列中所有嵌入的加权表示以有效地概括序列的内容。注意层将为序列中的每个向量提供权重。然后，这些权重可以用于计算序列的加权和。</p><p id="850d" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">在上图中，我们展示了注意力是如何被利用的。假设你有一个两个向量的序列。每个向量是n维的(在我们的例子中n是3)。注意力层将提供序列中每个向量的注意力权重。然后，我们计算该序列的加权和，以获得概括该序列的单个n维向量(0.25*1 + 0.75*2 = 1.75)。</p><p id="e6cc" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">通过马尔可夫模型对足球事件进行建模是很常见的，在马尔可夫模型中，当前状态仅依赖于先前状态，或者假设所有事件彼此独立。<strong class="jq hi">注意力机制提供了一种有效的方式，可以避免做出如此强烈的假设</strong>毕竟，在一次进攻行动中可能会有多次关键传球或运球，从而导致进球。最终，它是所有项目(传球、运球等)的组合。)这导致了一个目标。</p><p id="ac94" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">我们的模型将利用一种称为<a class="ae kk" href="https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a" rel="noopener" target="_blank">自我关注</a>的关注来处理<em class="le"> pass_sequence </em>特征<em class="le">。</em>自我关注已经成为深度学习中最受欢迎的关注类型。为了简洁起见，我们不会深入自我关注的细节，但是已经有很多关于它的文章了。</p></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><h1 id="10b0" class="iw ix hh bd iy iz lm jb jc jd ln jf jg in lo io ji iq lp ir jk it lq iu jm jn bi translated">模型架构和培训</h1><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="er es my"><img src="../Images/bd73358726a570806ac64e4d0c535f59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vu_YnaeGYA0re2QKx8ax8w.png"/></div></div><figcaption class="mp mq et er es mr ms bd b be z dx">Model Architecture</figcaption></figure><h2 id="f1b9" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated">体系结构</h2><p id="85ac" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">我们的每个分类变量都经过一个嵌入层(蓝色)。<strong class="jq hi">为了利用关于传球顺序的信息</strong>，我们创建了<em class="le">位置嵌入</em>，并将它们与<em class="le">传球区域嵌入相加。</em>嵌入的结果序列被发送到自我关注层。自关注层的输出被求和以获得单个n维向量来表示每个经过的序列。</p><p id="fa42" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated"><em class="le"> shot_technique、body_part、position和pass_technique </em>嵌入被发送到一个线性层，然后是一个GELU <a class="ae kk" href="https://machinelearningmastery.com/using-activation-functions-in-neural-networks/#:~:text=Activation%20functions%20play%20an%20integral,a%20simple%20linear%20regression%20model." rel="noopener ugc nofollow" target="_blank">激活函数</a>。<em class="le"> pass_zones和shot _ zone</em><strong class="jq hi"><em class="le"/></strong>嵌入分别<strong class="jq hi">发送到另一个线性层。最后一步是连接来自线性层<em class="le">压力下</em>(布尔)特征、<em class="le">发射角度、</em>和<em class="le">发射距离</em>(连续变量)的投影，并将它们通过多层感知器(MLP)。实现如下所示。</strong></p><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="e6d8" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">我们进行必要的导入，并设置我们的随机种子，以确保我们的实验和结果的可重复性。第24–28行实例化了我们所有的嵌入层。第31行添加了自我关注层。第34–36行创建线性层。第39–43行创建了我们的MLP。</p><p id="d956" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">第46行声明我们的分类阈值是什么，即大于0.5的概率得分<strong class="jq hi">将被视为预测给定射门</strong>的进球。第47–49行创建了必要的对象来跟踪我们想要监控的不同指标。Torchmetrics 与torch-lightning模块完美集成，使得记录和计算不同指标变得非常简单。我们最感兴趣的指标是<a class="ae kk" href="https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f" rel="noopener" target="_blank">宏观F1得分</a>这是因为宏观F1得分<strong class="jq hi">将预测进球的F1得分视为与未预测进球的F1得分同等重要。</strong>尽管阶级不平衡。</p><h2 id="09c6" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated">前进传球</h2><p id="c7c2" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">神经网络中的正向传递是将输入数据发送到模型时发生的事情。<strong class="jq hi">它决定了深度学习模型的不同组件/层被调用的顺序，以及它们如何相互连接</strong>。我们的流程如上图所示，实现如下。</p><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="ba17" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">第5–7行处理通过不同的嵌入层传递我们的分类数据。第7-15行显示了我们如何处理<em class="le"> pass_sequence </em>数据。首先，我们将它通过一个嵌入层。接下来，我们创建一个张量来捕捉通道的顺序。我们假设位置id 0对应于区域80，即处理所有nan区域或填充区域。</p><p id="bd00" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">在第8行中，我们创建了一个掩码，以找出我们应该屏蔽掉每个传递序列的哪些索引<strong class="jq hi">，因为它们是nan或填充标记</strong>。在第13行，我们确保对应于nan/padded区域的所有<em class="le"> pass_zone </em>嵌入被置零。这是一种教导模型不要注意填充标记或nan区域的方法。在第15行，我们对自关注层产生的所有传递嵌入求和，以获得单个n维向量来表示我们的传递序列。</p><p id="a540" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">线(17–21)通过线性层传递嵌入。第24行将投影嵌入传递给我们的MLP，以获得最终得分/logit。通过sigmoid函数传递logit得分，我们可以从logit中获得概率得分。</p><h2 id="c84f" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated">培训和评估</h2><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="bac6" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">接下来，我们指定每个训练/验证和测试步骤的逻辑。基本上我们所做的就是调用forward函数，然后计算我们的损失。因为我们正在处理二进制分类问题，所以我们使用<em class="le">二进制_交叉_熵_with_logits </em>损失函数。</p><p id="3135" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated"><strong class="jq hi">我们的数据是不平衡的，因为更多的射门没有进球，而不是进球</strong>。从训练数据集中，我们发现导致进球的射门与不导致进球的射门之间的比率(正标签:负标签)是1:7.25。在计算损失时，我们使用该信息为我们的阳性标签提供一个<a class="ae kk" href="https://stackoverflow.com/questions/68611397/pos-weight-in-binary-cross-entropy-calculation" rel="noopener ugc nofollow" target="_blank">增加的权重(第3行和第10行)。这意味着正标签上的损失乘以7.25倍。<strong class="jq hi">这使得该模型比没有权重因子时更关注于提高召回率。</strong></a></p><p id="6c05" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">代码中的其他步骤包括记录不同的指标。在计算指标之前，我们需要通过应用sigmoid函数(第12行)将原始logit分数转换为概率。默认情况下，火炬闪电记录到<a class="ae kk" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">张量板上</a>。第29–31行定义了我们将使用的优化器。第33–42行处理对我们的测试集进行预测，并打印出性能。</p><h2 id="0c77" class="lr ix hh bd iy ls lt lu jc lv lw lx jg jx ly lz ji kb ma mb jk kf mc md jm me bi translated">配置教练</h2><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="8a67" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">最后一步包括配置我们的训练对象，以确定我们要训练多少个时期，多久验证一次等等。早期停止(第3-4行)确保如果我们正在监控的指标(在这种情况下是一个时期结束时的验证损失)在超过<strong class="jq hi">n</strong>(n的值由耐心参数决定)<strong class="jq hi">连续</strong>验证步骤后没有改善，我们将停止训练模型。</p><p id="13e2" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">我们的模型检查点(第5-9行)确保我们保存的模型<strong class="jq hi">对应于最佳的f1-分数</strong>。请注意，良好的准确性分数可能会产生误导<strong class="jq hi">,因为大多数射门不会导致进球，而总是预测射门不会进球的模型仍然会有良好的准确性分数</strong>。</p><h1 id="5c23" class="iw ix hh bd iy iz ja jb jc jd je jf jg in jh io ji iq jj ir jk it jl iu jm jn bi translated">结论</h1><p id="deed" class="pw-post-body-paragraph jo jp hh jq b jr js ii jt ju jv il jw jx jy jz ka kb kc kd ke kf kg kh ki kj ha bi translated">这是我们在tensorboard上训练模型的一些图。我们看到，随着我们继续训练模型，我们的验证损失稳步下降。未达到峰值或稳定水平的验证损失是一个信号，表明我们可以为我们的模型训练更多的步骤/时期。我们的模型在验证集上的性能也遵循相同的模式。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="er es mz"><img src="../Images/2955713f4935ce57a736c48e8bfb8e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-XsgkkYceaRXT_r1vWeXA.png"/></div></div><figcaption class="mp mq et er es mr ms bd b be z dx">Mean Validation Loss Over An Epoch</figcaption></figure><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="er es na"><img src="../Images/26cebfc58f2f006529ba274a21209ef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXwloszaG4j_fUEbtO8fVg.png"/></div></div><figcaption class="mp mq et er es mr ms bd b be z dx">Validation F1 Macro Score</figcaption></figure><p id="0005" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">我们在验证集上保存对应于最佳宏F1分数的模型，并针对我们的测试集运行它。我们获得0.55的宏观F1分数。要知道这是不是一个好成绩，还是不要调到第3部分！</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="er es nb"><img src="../Images/77c48f87d964e3667e76cb3da28e062d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aA1Cb1t2S650rGlyTeH4yw.png"/></div></div><figcaption class="mp mq et er es mr ms bd b be z dx">Results of our trained model on the test set.</figcaption></figure><p id="2b31" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">谢谢你能走到这一步！今天，我们介绍了如何利用嵌入层来处理分类特征，利用关注层来处理足球比赛中的序列数据。我们展示了如何使用pytorch-lightning在笔记本电脑上创建和训练深度学习模型。</p><p id="d3f6" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated">在本系列的第3部分中，我们将介绍一些评估和使用DeepxG模型的酷方法。我们将展示如何用它来预测比赛结果，预测比赛的最佳得分者，等等。我们还将比较我们的模型与Statsbomb官方使用的模型的性能。如果您希望我们在未来涵盖任何其他主题，请给我们留下评论。</p><p id="3b17" class="pw-post-body-paragraph jo jp hh jq b jr kn ii jt ju ko il jw jx lb jz ka kb lc kd ke kf ld kh ki kj ha bi translated"><em class="le">如果你有兴趣继续了解更多关于数据科学和机器学习如何应用于足球世界的信息，请关注</em> <a class="ae kk" rel="noopener" href="/@buildingblocks"> <em class="le">关注</em> </a> <em class="le">我们，查看我们之前的一些文章！</em></p><div class="nc nd ez fb ne nf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hi fi z dy nk ea eb nl ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt mn nf"/></div></div></a></div></div></div>    
</body>
</html>
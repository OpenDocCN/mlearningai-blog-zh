<html>
<head>
<title>Leveraging the power of graph theory in NLP and big corpora</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在自然语言处理和大型语料库中利用图论的力量</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/introducing-a-new-approach-to-large-corpus-processing-in-nlp-fe5cbcbc901a?source=collection_archive---------4-----------------------#2021-10-30">https://medium.com/mlearning-ai/introducing-a-new-approach-to-large-corpus-processing-in-nlp-fe5cbcbc901a?source=collection_archive---------4-----------------------#2021-10-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/29c86ce243a929e97ca63e1f5b6f53ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ejA7N69Aqmnefh3T"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@borodinanadi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">nadi borodina</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="77f7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">机器学习算法在人工智能领域变得越来越强大。机器学习中令人着迷的分支之一是自然语言处理领域。</p><p id="a2a2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">NLP可以用来解决人类以其有限的技能和能力无法解决的问题。它可以帮助我们说出我们需要知道的东西，消除对某些群体的偏见，或者揭开隐藏在我们眼前的模式。</p><p id="fca7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用任何NLP相关的管道或算法的第一步是定义一个代表文本的语料库或数据集。您可以通过将数据导入数据库/数据结构，对其进行清理，然后根据手头的任务将其放入您选择的算法中。虽然在处理大型语料库的过程中有许多高端解决方案，但似乎在这个过程中错过了一些令人惊讶的替代方案，我和我的研究同事探索了将大型语料库表示为“图”的好处，并研究了不同的图论属性揭示了关于给定语料库的哪些故事，以及如何利用这些属性来解决相当复杂的问题，并为语言建模和计算语言学领域带来新的相似系数。</p><h1 id="30b2" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">二元图属性</strong></h1><p id="095b" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">本文介绍了将大型语料库表示为图的好处，其中单词表示图的节点，加权边是语料库中的语义关系。这些差异是从抽象的角度来看的——因为不同的图有不同的属性和语义关系。我们展示了定义这样的图如何允许用户利用它们的属性，通过使用传统的基于优化学习的技术来获得各种既定问题的解决方案。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kv"><img src="../Images/68c4b31f9e0b90877f68d0b143e62005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rQQEHVe8WS4q6bJzn1QUTw.jpeg"/></div></div></figure><h1 id="3bea" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">色度相似系数</strong></h1><p id="df3e" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">本文提出的新的相似系数(或称之为<em class="la">色相似系数</em>ψ),是一种新的基于色数来度量两个或多个图表示的语料库之间关系的方法。它是两个图形之间相似程度的定量度量。ψ(G1，G2)的值描述了两个图在表示节点的组件颜色和指定节点颜色之间的相交程度方面彼此有多接近。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lb"><img src="../Images/e6aa7219577ceb34342cb53d9a82ad32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0cTt-ppCZtAHJBthAKGR6w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">The formula for Ψ as seen in the paper</figcaption></figure><h1 id="e011" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">随机彩色步行者</strong></h1><p id="cb45" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">随机色度行走是一种简单而有效的基于给定语料库的语义和出现频率生成大规模文本的方法。通过首先给图着色，我们可以画出一组随机的色数，并找到满足这种“行走”的两个初始状态之间的路径，并基于对应于这些颜色的单词生成一个句子或一个段落。</p><p id="8342" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了补偿不均匀的颜色标签分布，我们提出一个随机选择J的阵列，使得1 J(BGx)和beta分布。根据在第一随机颜色标签阵列中生成的颜色标签，两个随机选择的单词之间的路径的连接。</p><p id="e8a4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">根据用于计算的协议，使用这种方法可以获得许多独特的结果。我们成功测试的协议包括:</p><p id="502a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 1。</strong>最优权重路径。</p><p id="8757" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 2。</strong>最小权重路径。</p><p id="2cf0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 3。</strong>密度最高的路径。</p><p id="e598" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 4。</strong>密度最低的一个。</p><h1 id="504d" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">彩色句子嵌入</strong></h1><p id="a202" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">当处理文本和机器学习时，通常我们的第一步是通过任何成熟的矢量化/嵌入算法和方法，如TF-IDF、词袋、GLoVe、BERT嵌入等，用一些向量空间来表示文本。</p><p id="edce" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们在本文中提出的新方法是<em class="la">色向量化</em>，它使用类似于单词包方法的方法将语料库中的单词嵌入到向量空间中。唯一的主要区别在于，我们不使用每个单词的相对频率，而是在给图形着色时使用分配给该单词的色数。</p><p id="20ec" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用具有用于色彩矢量化的期望上下文的语料库二元图可以为用户提供嵌入不同文本的服务，甚至在原始语料库中给出的样本之外，类似于我们通常在深度学习中所做的，我们在这里称之为<em class="la">迁移学习</em>，而不是训练模型，我们给图着色。</p><p id="201f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">延伸阅读</strong></p><p id="ae09" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">康斯坦丁诺夫斯基，t .，&amp;米茨拉奇，M. (2021年7月29日)。<em class="la">关于二元图属性</em>。计算机和信息科学。检索到2021年10月30日。</p></div></div>    
</body>
</html>
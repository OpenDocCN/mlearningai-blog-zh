<html>
<head>
<title>“Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads” Summary</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《面向DNN培训工作负载的大规模多租户GPU集群分析》摘要</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/analysis-of-large-scale-multi-tenant-gpu-clusters-for-dnn-training-workloads-88bb2bec0c01?source=collection_archive---------2-----------------------#2021-11-09">https://medium.com/mlearning-ai/analysis-of-large-scale-multi-tenant-gpu-clusters-for-dnn-training-workloads-88bb2bec0c01?source=collection_archive---------2-----------------------#2021-11-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="cd96" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="d014" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">机器学习(<strong class="je hi"> ML </strong>)的广泛采用，尤其是深度学习在广泛应用中的广泛采用，要求促进其模型的训练。为此，企业由来自不同制作团队的用户共享大型图形处理单元集群(<strong class="je hi">GPU</strong>)。使用共享集群提供了<strong class="je hi">更高的资源利用率</strong>和<strong class="je hi">更少的开发开销</strong>。深度学习工作负载对集群管理系统的几个新挑战。这些工作负载是浮点(<strong class="je hi"> FP </strong>)计算密集型的，需要GPU加速。但是，GPU缺乏细粒度共享[ <strong class="je hi"> 3 </strong> ]，软件机制开销很大[ <strong class="je hi"> 4，5 </strong> ]。此外，大型数据集上的训练需要使用几个GPU，ML框架通常需要同时调度每个GPU上的任务，就像<strong class="je hi"> Gang Scheduling </strong>机制中发生的那样。这增加了共享集群中资源碎片和低利用率的风险。像上一个一样，多GPU训练也意味着跨GPU的模型参数的同步，因此在调度时实现更好的局部性是很重要的，以允许使用更快的互连进行机器内和机器间的通信。Myeongjae Jeon等人在[ <strong class="je hi"> 1 </strong>中提到，还没有对用于训练机器学习模型的多租户GPU集群进行系统研究，他们使用<strong class="je hi">微软Philly </strong>(微软的一种服务，用于训练机器学习模型，为集群上运行的作业执行资源调度和集群管理)进行了为期<strong class="je hi">两个月</strong>的广泛研究，使用了由<strong class="je hi">运行的大约<strong class="je hi"> 100，000个作业</strong>使用来自上述系统的数据，作者呈现了详细的工作负载特征，并研究了诸如<strong class="je hi">组调度</strong>、<strong class="je hi">位置要求、</strong>和<strong class="je hi">故障</strong>等因素如何影响集群利用率。然后，他们研究了位置感知调度如何影响性能和利用率的两个主要方面。首先，他们强调放松位置限制可以减少排队延迟。其次，他们研究了位置感知调度如何影响分布式训练作业的GPU利用率。他们发现了导致GPU利用率低的两个原因:(1)各个作业在服务器之间的分布，忽略了位置约束，增加了同步开销；(2)不同作业在同一台服务器上的打包会导致因争用共享资源而产生的干扰。他们通过研究工作失败的原因来完成论文，并详细描述了他们集群中失败的原因。最后，根据他们从研究中获得的经验，他们提供了三个准则来改进下一代DNN工作负载集群调度程序。这些指导方针可以在本文下面的章节中找到。</strong></p><h1 id="fde9" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">背景</h1><h2 id="e151" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">调度的一般思想</h2><p id="0203" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">调度器是决定选择和运行哪个任务的组件(硬件或软件)。从操作系统(OS)的角度来看，它是一个决定选择和运行哪个任务的软件组件。下图显示了调度程序如何选择不同的任务在CPU上执行。请注意，每个CPU遵循其挑选任务的顺序，任务放置和迁移(从一个CPU到另一个CPU)取决于CPU的负载。更重要的是，接任务没有考虑任务的相互依赖性。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/6456f12b2499eae80ba1660711e2288a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*dxoUA-8vmMIgBO8UWri_Tw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx"><a class="ae la" href="https://www.youtube.com/watch?v=4SdzmT9gfQI" rel="noopener ugc nofollow" target="_blank">A Scheduler Selecting Tasks for Execution</a> (<strong class="bd ig">SMP </strong>stands for <strong class="bd ig">S</strong>ymmetric <strong class="bd ig">M</strong>ulti-<strong class="bd ig">P</strong>rocessor)</figcaption></figure><h2 id="4d4d" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">团伙调度</h2><p id="8286" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">成组调度是一种在不同的CPU上同时调度一组相关/相互依赖的任务的方法。下图显示了这种调度方法的严格模式的示例。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/9c3364ba6408457de6512135af0273a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*eid05Y83AWGLa-noZR6TGQ.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx"><a class="ae la" href="https://www.youtube.com/watch?v=4SdzmT9gfQI" rel="noopener ugc nofollow" target="_blank">Gang Scheduling Method</a></figcaption></figure><p id="e6a4" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">下图是一个宽松版本的团队调度方法的示例。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/f80a1aebec19a64561a8d2f0c57c5a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*Ot5DsyO2_eTXs-6JYPMh0g.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">Relaxed Version of Gang Scheduling</figcaption></figure><p id="56a5" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">群组调度方法的使用案例是高性能计算(HPC)工作负载和虚拟化。HPC使用联合调度方法来提高协作任务的并行作业性能。可以在<a class="ae la" href="https://www.youtube.com/watch?v=blvC0DA96dI" rel="noopener ugc nofollow" target="_blank">连接机CM-5 </a>超级计算机和风暴资源管理框架[ <strong class="je hi"> 2 </strong>中找到。</p><h1 id="def6" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">系统概况</h1><p id="ee2d" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">本节介绍工作负载、集群的硬件特征、作业的生命周期以及收集数据的管道。</p><h2 id="0b0b" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">工作量</h2><p id="0b7d" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">费城支持执行<strong class="je hi">监督的ML </strong>的工作负载。该系统支持使用任何机器学习框架编写的作业，如Tensorflow、CNTK、Caffe和PyTorch。Jobs基于最近提出的学习架构，如卷积神经网络(CNN)、LSTMs和RNNs。工作负载依赖于迭代优化方法，如<strong class="je hi">随机梯度下降(SGD) </strong>。为了在更大的数据集上扩展训练，几个作业在机器上使用<strong class="je hi">分布式训练</strong>。在这个培训中，每个工人将模型的完整副本加载到其内存中。然后，在每次迭代中，每个工人使用输入数据的子集执行<strong class="je hi">训练，并且<strong class="je hi">在迭代结束时，所有工人交换梯度以同步模型更新</strong>。使用参数服务器[ <strong class="je hi"> 6 </strong> ]或高性能库(如MPI、NCCL等)进行同步。</strong></p><h2 id="ccec" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">集群架构</h2><p id="a0ed" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">集群中的服务器和GPU之间存在高速网络连接。这是为了加速分布式培训，在分布式培训中，工作人员需要为每次迭代及时交换模型更新。GPU之间的通信有一个网络链接层次。同一机架内的机器通过100 Gbps<a class="ae la" href="https://bit.ly/3bUQIkc" rel="noopener ugc nofollow" target="_blank">RDMA</a>(<a class="ae la" href="https://en.wikipedia.org/wiki/InfiniBand" rel="noopener ugc nofollow" target="_blank">InfiniBand</a>)网络(<a class="ae la" href="https://bit.ly/3bUQIkc" rel="noopener ugc nofollow" target="_blank">一种允许网络中的计算机在不涉及处理器</a>的情况下交换主内存中的数据的技术)连接，而跨机架的流量则通过以太网传输。为了提高通信性能，分布式培训工作中的工作人员必须在同一台机器上协同工作，或者最好通过高速网络(比如InfiniBand)进行通信。<strong class="je hi">因此,[1]使用的框架同时考虑了GPU和网络连接的调度</strong>。</p><h2 id="5f70" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated"><strong class="ak">作业调度和执行工作流程</strong></h2><p id="58ae" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">下图显示了费城深度学习工作的生命周期以及它所经历的不同执行阶段。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lg"><img src="../Images/99be2a31340a1b2d59c122258cd01ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*wZGquVsK6pMYWSm8v6Ph5w.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">The Lifecycle of Deep Learning Jobs in Philly</figcaption></figure><ol class=""><li id="87a7" class="lh li hh je b jf lb jj lc jn lj jr lk jv ll jz lm ln lo lp bi translated"><strong class="je hi">接收任务和排队</strong></li></ol><p id="40ba" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">用户指定所需的GPU数量，为了便于主机资源分配，CPU内核和内存容量的分配与请求的GPU数量成比例。为了支持多个生产组，为每个生产组构建了一个虚拟集群，它在Apache YARN中有一个单独的分配队列。为了管理这些队列，使用了<strong class="je hi">公平调度器</strong>。</p><p id="71fb" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">对于分布式训练，深度学习框架要求所有GPU同时可用。因此，调度程序需要在执行联合调度的同时具有位置意识，比如将作业的GPU打包到最少数量的服务器上，并且在RDMA域内。尊重局部性通过减少参数同步所需的时间来改进训练时间。为了促进位置感知GPU调度，我们的作业调度程序跟踪集群中所有空闲的GPU，并对相应的机架和服务器进行排序。</p><p id="10eb" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">2.<strong class="je hi">工作安置和利用</strong></p><p id="6a8f" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">当调度程序试图最大化分布式作业的局部性时，同时试图通过将较小的作业打包到较少的服务器中来避免资源碎片。然而，在同一台服务器上打包不同的作业可能会导致GPU利用率降低，因为会干扰共享的系统资源，如PCIe总线。作者也对此进行了研究。</p><p id="6ac6" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">3.<strong class="je hi">培训进度及完成情况</strong></p><p id="a47e" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">作业以三种状态完成:通过(~成功完成)、终止(~被用户终止)或不成功。系统中失败的作业被退役固定的次数。这对于克服非确定性故障非常有用，如果作业在重试后仍未成功，则它会被标记为不成功。</p><h1 id="6fc3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">观察结果</h1><h2 id="6a67" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">位置意识的影响</h2><p id="cafc" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">调度程序牺牲了局部性以获得更短的等待时间。调度器做出的放置选择以两种方式影响DNN训练的效率:排队延迟(在作业执行之前)和正在使用的GPU的硬件利用率(在作业执行之后)。排队延迟的发生有两个原因:<strong class="je hi">公平性</strong>，当虚拟集群使用其资源时会发生，资源<strong class="je hi">碎片化</strong>，这是因为资源碎片化使得很难找到足够多的具有高局部性的GPU。下表显示了排队延迟的频率。<strong class="je hi">结果显示大部分延迟是因为资源碎片</strong>！<strong class="je hi">不过，同时也要考虑重新考虑两人的调度！</strong></p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lq"><img src="../Images/ce9c7f1fd59370fff033a87318a7cfe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s-h8_sJqNORkOW1qfHktSw.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="129d" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated"><strong class="je hi">这项研究的观点是，公平共享延迟很容易通过<em class="lv">抢占</em>来减少，但是由于网络的架构，碎片延迟在该系统中很难克服！</strong></p><p id="800a" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">此外，作者尝试无序调度，他们没有观察到重要的改进。这一部分是他们对从这项研究中学到的东西的总结。他们说，他们了解了为什么应该放松本地加班，以减少分布式培训的排队延迟。此外，除了公平共享排队延迟，对<strong class="je hi">群组调度</strong>和<strong class="je hi">位置</strong>的需求为机器学习作业引入了碎片延迟。</p><h2 id="f0e3" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">GPU利用率</h2><p id="1cdd" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">注意[ <strong class="je hi"> 1 </strong>的使用报告是粗粒度的。它的纹路是SM。它没有显示正在使用SMs的哪一部分。</p><p id="3677" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">下图显示了不同作业规模的GPU利用率。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lw"><img src="../Images/dbc0f897a02cb898ee84cfa8c14de49e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cEOo8QHWogUAPXEhxApWVw.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="c047" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">此外，分布会对GPU利用率产生负面影响，如下图所示。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lx"><img src="../Images/2db52a58549959765d8e630e20ec6fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*4i43E2NKVQr7qXANzoSAjA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="6fe7" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">洞察力:给定一个分布式训练设置，对共享资源(如RDMA和PCIe)的争夺进一步降低了GPU的利用效率。</p><p id="6871" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">在许多共享服务器上分配作业会进一步降低GPU的利用率。利用率的降低不仅是由于网络开销，也是由于来自不相关但位于同一位置的作业的<strong class="je hi">干扰</strong>。</p><h2 id="1d0a" class="ka if hh bd ig kb kc kd ik ke kf kg io jn kh ki is jr kj kk iw jv kl km ja kn bi translated">培训进度和完成情况</h2><p id="1b17" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">该研究表明，很大一部分作业要么未成功终止，要么被用户终止。它们约占GPU总时间的55%。下表显示了研究结果。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es ly"><img src="../Images/82685b09386d7bdde8be87940c1ce829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mW0mlqqrW-5ynjI0vKwWCw.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="a2db" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">虽然作者没有提供来自用户调查的数据，但该论文提到，当损失变化在连续时期内小于特定阈值时，机器学习实践者可以提前终止作业，以节省大量GPU时间。</p><p id="8dc0" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">在开始了解失败之前，作者强调了在他们的集群调度器中，一个任务在失败后被<strong class="je hi">重试</strong>。如果作业重复失败，它将被标记为不成功，因为进一步的重试将不再有效。下图显示了故障是如何发生的。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lz"><img src="../Images/0be300833fe190150d31ac30fbc8b6aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJhyoXJmCJ73yo8JWlnQ0Q.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="6a34" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">作者根据故障的来源将故障分为三类:</p><ol class=""><li id="737e" class="lh li hh je b jf lb jj lc jn lj jr lk jv ll jz lm ln lo lp bi translated"><strong class="je hi">基础设施故障(如果)</strong>包括纱线、HDFS和其他框架</li><li id="2aa0" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated"><strong class="je hi"> AI引擎(AE) </strong>包括TensorFlow、Torch等平台</li><li id="d2a9" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated"><strong class="je hi">用户(U) </strong>包括程序员</li><li id="1e4a" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated">[ <strong class="je hi"> 1 </strong>中的下表给出了故障分析。</li></ol><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es mf"><img src="../Images/29b0c92f5993d7ef2f59afa80ab226ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6cMqBBYsk1LyabrlZVZv4w.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="a3dc" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">分析表明:</p><ol class=""><li id="8eab" class="lh li hh je b jf lb jj lc jn lj jr lk jv ll jz lm ln lo lp bi translated"><strong class="je hi">同一作业/用户重复出现故障</strong>。例如，一名工程师发布了几个培训任务，所有这些任务都遇到了相同的内存不足问题。</li><li id="30b0" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated"><strong class="je hi">用户或程序员错误导致大量故障</strong>。</li><li id="ea05" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated">故障前运行时间(RTF)显示出高度可变性，主要是短RTF。用户驱动的故障具有较短的rtf。<strong class="je hi">注意，这些故障中的大多数是确定性的，并且在运行时开始执行程序时被捕获</strong>。由于数据不一致而导致的故障。</li><li id="2d33" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated"><strong class="je hi">基础设施故障不常发生，但故障前运行时间(RTF)要长得多</strong>。</li><li id="6ecc" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated">有编程语义错误的大型作业在执行后往往会失败。</li></ol><h1 id="bbdf" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">根据从研究中获得的经验教训提供了三项指导方针</h1><ol class=""><li id="7fca" class="lh li hh je b jf jg jj jk jn mg jr mh jv mi jz lm ln lo lp bi translated"><strong class="je hi">优先考虑局部性</strong>:因为缺少局部性会影响利用率和作业运行时间，<strong class="je hi"> <em class="lv">因为DNN培训作业需要很长时间来运行</em> </strong>，<strong class="je hi">调度器应该用排队延迟来换取遵守局部性约束</strong>。<em class="lv">另一种策略是，如果资源在执行过程中变得可用，则将作业迁移到位置更好的机器上</em>。</li><li id="452e" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated"><strong class="je hi">减轻干扰:共享一台服务器的不同工作可能会相互干扰，并对他们的培训时间产生不利影响</strong>。调度器应该旨在隔离专用服务器上的作业，同时实现碎片整理的迁移等技术，以支持需要更多GPU的作业的位置约束。</li><li id="cbba" class="lh li hh je b jf ma jj mb jn mc jr md jv me jz lm ln lo lp bi translated"><strong class="je hi">改进故障处理</strong>:研究表明，大多数故障是由用户在代码和配置中的错误造成的。使用简单的语法检查可以防止许多错误。此外，一些更复杂的运行时故障可以通过运行第一次迭代训练来捕获。一个可能的解决方案是为预运行作业设置一个虚拟机池。即使运行多GPU也可以在大型集群上运行这些错误之前捕捉到它们，从而防止在这些集群上浪费GPU周期。正如前面在故障研究中提到的，训练错误是由错误的数据格式引起的。让<strong class="je hi">为ML </strong>中使用的数据集定义良好的模式，并在访问数据时进行模式检查，将会减少这样的错误。制作GPU集群调度程序的另一个想法是设计一个系统来检测和防止某些失败的任务重试。</li></ol><h1 id="a794" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结论</h1><p id="6dc7" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">随着机器学习变得无处不在，由于当前的低效率，资源管理变得更加重要。Jeon Myeongjae等人在[ <strong class="je hi"> 1 </strong> ]中通过分析运行在大型多租户GPU集群上的深度学习作业的轨迹，研究了影响利用率的不同因素。此外，他们对各种故障进行了详细分析，并展示了来自堆栈不同层的错误是如何导致故障的。最后，基于他们的数据分析和经验，他们提出了可以帮助机器学习调度器未来研究和开发的指导方针。最重要的是，他们的踪迹可以在<a class="ae la" href="https://github.com/msr-fiddle/philly-traces" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><h1 id="0917" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">未来阅读</h1><p id="eeab" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">亚历山德罗斯·科利乌西斯、皮伊卡·瓦查拉皮查特、马蒂亚斯·魏德利希、罗迈、保罗·科斯塔和彼得·皮兹乌奇。"<strong class="je hi"> Crossbow:在多GPU服务器上用小批量扩展深度学习."过程。<strong class="je hi"> VLDB </strong> ( <strong class="je hi"> 2019 </strong>)，1399–1412。</strong></p><h1 id="475c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="d151" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">【<strong class="je hi">1</strong>】Jeon，Myeongjae等人《<strong class="je hi">DNN训练工作负载的大规模多租户GPU集群分析，</strong>》(<strong class="je hi">2019</strong>)。</p><p id="c033" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">[<strong class="je hi">2</strong>Frachtenberg，Eitan &amp; Petrini，Fabrizio &amp; Fernández，Juan &amp; Pakin，Scott &amp; Coll，Salvador。"<strong class="je hi">风暴:快如闪电的资源管理。</strong>第46—46页。10.1109/sc . 2002.10057(<strong class="je hi">2002</strong>)。</p><p id="89aa" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated"><strong class="je hi"> 3 </strong>顾、&amp;刘、桓&amp;周、&amp;王、辛。"<strong class="je hi"> DeepProf:通过挖掘GPU执行模式对深度学习应用进行性能分析。</strong>”(<strong class="je hi">2017</strong>)</p><p id="7712" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">[<strong class="je hi">4</strong>m . Rhu，N. Gimelshein，J. Clemons，A. Zulfiqar，S. W. Keckler，<strong class="je hi"> vDNN:虚拟化深度神经网络，用于可扩展、内存高效的神经网络设计</strong>，<em class="lv">第49届IEEE/ACM微体系结构国际研讨会(</em><strong class="je hi"><em class="lv"/></strong><em class="lv">)</em>，<strong class="je hi"> 2016) </strong>，第页</p><p id="3a15" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">余、和克里斯托夫·j·罗斯巴赫。"<strong class="je hi">重新考虑GPU的完全虚拟化。</strong> " ( <strong class="je hi"> 2017 </strong>)。</p><p id="f356" class="pw-post-body-paragraph jc jd hh je b jf lb jh ji jj lc jl jm jn ld jp jq jr le jt ju jv lf jx jy jz ha bi translated">【<strong class="je hi"> 6 </strong>李牧，大卫·g·安德森等】<strong class="je hi">用参数服务器缩放分布式机器学习。</strong>《第11届USENIX操作系统设计与实现会议论文集》(OSDI'14)。美国USENIX协会，583–598(<strong class="je hi">2014</strong>)。</p><div class="mj mk ez fb ml mm"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mn ab dw"><div class="mo ab mp cl cj mq"><h2 class="bd hi fi z dy mr ea eb ms ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mt l"><h3 class="bd b fi z dy mr ea eb ms ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mu l"><p class="bd b fp z dy mr ea eb ms ed ef dx translated">medium.com</p></div></div><div class="mv l"><div class="mw l mx my mz mv na ku mm"/></div></div></a></div></div></div>    
</body>
</html>
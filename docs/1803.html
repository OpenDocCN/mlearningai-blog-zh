<html>
<head>
<title>Brain Tumor Detection &amp; Transfer Learning using VGG16</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用VGG16进行脑肿瘤检测和迁移学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/brain-tumor-detection-transfer-learning-using-vgg16-a0d0a31f2e9?source=collection_archive---------3-----------------------#2022-01-31">https://medium.com/mlearning-ai/brain-tumor-detection-transfer-learning-using-vgg16-a0d0a31f2e9?source=collection_archive---------3-----------------------#2022-01-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="cb7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">CNN中使用自定义VGG变量和迁移学习检测脑瘤</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/0aea286b184b26de22c2779869a4ece5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wf6Be10EWYbpsWe-90mhLg.png"/></div></div></figure><p id="2666" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博客中，我将谈论在深度学习中使用CNN(卷积神经网络)进行脑肿瘤检测。我还会解释迁移学习的一点一滴，同时在旅途中解决问题。这篇博客要求你对CNN有一个清晰的了解，因为我不会在这里深入CNN。如果你已经忘记了一些，打开你的笔记本&amp;只是扫一扫那些笔记。我们都有或多或少忘记概念的问题。😉</p><p id="e507" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">也就是说，我写这篇博客更多的是为了记录我忘记迁移学习概念的时候。但是我确信&amp;我真的希望这也能帮助你。😃</p><p id="1bd2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我第一次遇到这个问题是在Edureka的一个视频中:<a class="ae jo" href="https://www.youtube.com/watch?v=7MceDfpnP8k" rel="noopener ugc nofollow" target="_blank">利用深度学习进行癌症检测</a>。他们使用了一个脑肿瘤数据集，该数据集由多个健康的&amp;肿瘤人脑的MRI扫描图像组成。他们使用CNN架构&amp;转移学习在这个数据集中对健康的&amp;肿瘤大脑进行分类。接下来，我进一步看到了一个很棒的博客:<a class="ae jo" href="https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/" rel="noopener ugc nofollow" target="_blank">如何对狗和猫的照片进行分类(准确率97%)</a>作者是一位了不起的作家<em class="jp">杰森·布朗利。如果你还没有看过他的博客，现在是个好时机。永远都不晚！⏰ 😃</em></p><p id="124e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我这篇文章的大部分内容都是受上述2个来源的启发。我用于训练和验证的数据集来自上面提到的Edureka的视频。为了进行测试，我使用了来自完全不同来源的数据:Kaggle的<a class="ae jo" href="https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection" rel="noopener ugc nofollow" target="_blank">用于脑瘤检测的脑MRI图像</a>。我故意这样做，以便查看我的模型执行起来有多健壮。事不宜迟，我们先来看一些CNN的模型。</p><p id="5e3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在训练数据集中，我们有2513个肿瘤脑图像和2087个健康脑图像，我从其中分离出80:20的分割用于训练:验证。数据集相当平衡。测试数据集有155张肿瘤图像和98张健康大脑图像。</p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><p id="b0b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这一点经常被忽略，但我认为EDA是非常必要的“初始步骤”，不仅在机器学习中，在深度学习中也是如此。为了能够将数据输入CNN，首先对数据进行预处理是很重要的。例如，在这个问题中，我们有不同形状的图像(准确地说是宽度和高度)。在每个图像中，通道的数量是相同的，即这里是3。现在，在机器学习中，我们通过标准化，规范化等进行预处理，对吗？有印象吗？😜</p><p id="5838" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在图像数据的情况下也需要这样做。我快速绘制了所有图像的高度和宽度的pdf，发现250(像素，如果你不知道的话)是我们数据集中所有图像最常出现的高度和宽度。所以，第一步完成了:我们要把每张图片的形状做成(250，250)的形状。</p><p id="a804" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来是在Tensorflow/Keras中使用<a class="ae jo" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>类。它帮助您创建一个批量图像的生成器(如果您想用简单的术语思考，可以用迭代器),带有实时数据扩充。</p><p id="fdf9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jp">注意:我将在本文的稍后部分触及这个数据扩充部分</em>。</p><p id="182c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们专注于完成预处理。首先，我们需要规范化图像(这里只是(250，250)形状的数组)。为此，我们可以使用ImageDataGenerator的rescale参数，并指定1/255来将像素值的比例降低到0–1。</p><p id="9da6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在来看第一款<strong class="ig hi">车型</strong> →一个简单的架构:-</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jx"><img src="../Images/1e9874968576d06f452455c63982a639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*Iy52CckRsiQtd4nGzeJOKw.png"/></div></figure><p id="e82b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个简单的模型，没有正规化，什么都没有。但是在完全看不见的测试数据集上仍然给出了99.605%的准确率。</p><p id="e0d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于第二个模型，我使用了退出正则化。</p><pre class="jd je jf jg fd jy jz ka kb aw kc bi"><span id="686e" class="kd ke hh jz b fi kf kg l kh ki"># defining 2nd model architecture<br/>model2=Sequential()</span><span id="94ac" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Conv2D(filters=32,kernel_size=(3,3),activation=”relu”,kernel_initializer=”he_uniform”,padding=”same”,input_shape=(250,250,3)))</span><span id="4d96" class="kd ke hh jz b fi kj kg l kh ki">model2.add(MaxPooling2D(pool_size=(2,2)))</span><span id="e578" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Dropout(0.2))</span><span id="69e8" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Conv2D(filters=64,kernel_size=(3,3),activation=”relu”,kernel_initializer=”he_uniform”,padding=”same”))</span><span id="2e65" class="kd ke hh jz b fi kj kg l kh ki">model2.add(MaxPooling2D(pool_size=(2,2)))</span><span id="710a" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Dropout(0.3))</span><span id="846a" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Conv2D(filters=128,kernel_size=(3,3),activation=”relu”,kernel_initializer=”he_uniform”,padding=”same”))</span><span id="041b" class="kd ke hh jz b fi kj kg l kh ki">model2.add(MaxPooling2D(pool_size=(2,2)))</span><span id="77c3" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Dropout(0.3))</span><span id="79e8" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Flatten())</span><span id="1111" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Dense(units=128,activation=”relu”,kernel_initializer=”he_uniform”))</span><span id="f65d" class="kd ke hh jz b fi kj kg l kh ki">model2.add(Dense(units=1,activation=”sigmoid”))</span><span id="1422" class="kd ke hh jz b fi kj kg l kh ki"># compile the model</span><span id="48c4" class="kd ke hh jz b fi kj kg l kh ki">model2.compile(optimizer=”adam”,loss=”binary_crossentropy”,metrics=[“accuracy”])</span></pre><p id="929b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这也给出了99.605%的准确度。</p><p id="96fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在来谈谈数据扩充。它是人工创建图像并扩展训练数据集的过程。这样做是为了让模型在学习实际输入图像的同时，学习其他多种不同的图像。这在数据集很小时尤其重要，但在数据集很大时也应该这样做。如果不是改进，增强不会对你的模型造成任何伤害。这也可以使用ImageDataGenerator来完成。看一下它的文档，它真的🆒！</p><p id="1427" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意:你不应该增加你的验证和测试数据集。绝不！这是强制性的，以便使模型在非增强图像上进行预测，非增强图像具有尽可能低的变化。</p><p id="dc8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一个模型增加了数据，架构与模型2相似，准确率为90.514 %。</p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><p id="c855" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来转学…</p><p id="6605" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">迁移学习是一种采用神经网络模型的技术，该模型已经在不同的数据集上进行了预训练&amp;使用该知识将学习“迁移”到不同的数据集任务。它有许多用例:-</p><p id="e267" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">情况1:使用预先训练好的模型，如VGG16，使用<a class="ae jo" href="https://en.wikipedia.org/wiki/ImageNet" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>权重进行特征提取。</p><p id="ca7b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">案例二:微调VGG16的最后几层，同时保持较低的学习速率。</p><p id="ecad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">情况3:在用ImageNet的权重初始化权重之后，微调整个网络。</p><p id="6d27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">案例4:从头开始重新培训整个网络。</p><p id="ed9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">什么时候可以使用哪个用例:-</p><ol class=""><li id="4476" class="kk kl hh ig b ih ii il im ip km it kn ix ko jb kp kq kr ks bi translated">您的数据集<strong class="ig hi"> D </strong>很小，类似于ImageNet👉使用预训练的模型进行特征提取，并将这些提取的特征输入到更简单的模型中，如逻辑回归，甚至是简单的展平+密集+输出图层(任意数量和类型的图层)。</li><li id="868e" class="kk kl hh ig b ih kt il ku ip kv it kw ix kx jb kp kq kr ks bi translated"><strong class="ig hi"> D </strong>大&amp;类似ImageNet👉微调预训练模型的整个架构。</li><li id="dc5e" class="kk kl hh ig b ih kt il ku ip kv it kw ix kx jb kp kq kr ks bi translated"><strong class="ig hi"> D </strong>是类似ImageNet的中型&amp;👉只微调最后几层。</li><li id="bfe8" class="kk kl hh ig b ih kt il ku ip kv it kw ix kx jb kp kq kr ks bi translated"><strong class="ig hi"> D </strong>小&amp;与ImageNet不相似👉使用预训练模型的前2-3个块的权重进行特征提取&amp;将它们添加到您自己的层或模型中以获得最终结果。</li><li id="0221" class="kk kl hh ig b ih kt il ku ip kv it kw ix kx jb kp kq kr ks bi translated"><strong class="ig hi"> D </strong>较大&amp;与ImageNet不相似👉用预定义的权重初始化架构，如ImageNet的权重，然后继续训练整个网络。</li></ol><p id="60e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jp">注意:在以上几点中，预先训练好的模型可以是任何东西。可以是像VGG16，ResNet，InceptionNet等最臭名昭著的CNN机型。它也可以是您自己的预训练模型，您之前可能已经在另一个数据集上进行了训练&amp;希望现在用于不同的数据集。</em></p><p id="b43e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意:对于迁移学习，您需要以这些预训练模型期望的方式预处理您的图像。您可以使用ImageDataGenerator中的参数“preprocessing_function”来完成此操作。</p><p id="1625" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个问题，我使用权重从2个不同的层提取特征，并形成了2个不同的模型。</p><pre class="jd je jf jg fd jy jz ka kb aw kc bi"><span id="3386" class="kd ke hh jz b fi kf kg l kh ki"># loading the base-model<br/>model4=VGG16(weights=’imagenet’,include_top=False,input_shape=(224,224,3))</span><span id="f24a" class="kd ke hh jz b fi kj kg l kh ki"># mark the loaded layers as not-trainable<br/>for layer in model4.layers:<br/>  layer.trainable=False</span><span id="53ad" class="kd ke hh jz b fi kj kg l kh ki"># adding new classifier layers<br/>flat = Flatten()(model4.layers[-1].output)</span><span id="5eed" class="kd ke hh jz b fi kj kg l kh ki">classifier = Dense(units=128,activation=’relu’,kernel_initializer=”he_uniform”)(flat)</span><span id="83c6" class="kd ke hh jz b fi kj kg l kh ki">output = Dense(units=1,activation=”sigmoid”)(classifier)</span><span id="dedd" class="kd ke hh jz b fi kj kg l kh ki"># define the model<br/>model4 = Model(inputs=model4.inputs,outputs=output)</span></pre><p id="7e67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我使用最后一个max-pooling层的输出进行特征提取。这也给出了99.605%的准确度。</p><p id="c703" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jp">如果您不想让预训练模型的权重在训练期间更新，请记住将预训练模型的层设为不可训练。</em></p><p id="4814" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于下一个模型，我使用第三块的输出进行特征提取。</p><pre class="jd je jf jg fd jy jz ka kb aw kc bi"><span id="b99f" class="kd ke hh jz b fi kf kg l kh ki">base_model = VGG16(weights=’imagenet’,include_top=False,input_shape=(224,224,3))</span><span id="c5bf" class="kd ke hh jz b fi kj kg l kh ki"># mark the loaded layers as not-trainable<br/>for layer in base_model.layers:<br/>  layer.trainable=False</span><span id="8f1c" class="kd ke hh jz b fi kj kg l kh ki"># adding new classifier layers<br/>flat = Flatten()(base_model.get_layer(‘block3_pool’).output)</span><span id="aa03" class="kd ke hh jz b fi kj kg l kh ki">dense1 = Dense(units=128,activation=’relu’,kernel_initializer=”he_uniform”)(flat)</span><span id="231a" class="kd ke hh jz b fi kj kg l kh ki">drp = Dropout(0.3)(dense1)</span><span id="d380" class="kd ke hh jz b fi kj kg l kh ki">dense2 = Dense(units=64,activation=’relu’,kernel_initializer=”he_uniform”)(drp)</span><span id="6514" class="kd ke hh jz b fi kj kg l kh ki">dense3 = Dense(units=32,activation=’relu’,kernel_initializer=”he_uniform”)(dense2)</span><span id="8798" class="kd ke hh jz b fi kj kg l kh ki">output = Dense(units=1,activation=”sigmoid”)(dense3)</span><span id="53c9" class="kd ke hh jz b fi kj kg l kh ki"># define the model<br/>model5 = Model(inputs=base_model.inputs,outputs=output)</span></pre><p id="abe6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型的精确度非常低，为62.055 %，而第四个模型的精确度更高，这可能是因为这里使用了更早的图层权重来提取特征。这表明最好使用后面层的权重，因为它们已经在非常好的资源和非常强大的数据集ImageNet上进行了训练。</p><p id="060b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我喜欢创建端到端的项目。下面是我的web应用程序的GIF，它是我使用Flask API创建的，部署在本地:-</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="cd39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意:我在这里主要是在玩模型。您可以&amp;更确切地说，肯定应该使用上述模型或其他架构进行更多的实验。😃 😏</p><p id="8078" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想知道我实验的更详细的方法，请访问这个问题的GitHub Repo。</p><p id="11a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我将向您介绍一些非常好的资源，我接受了他们的帮助</p><div class="la lb ez fb lc ld"><a href="https://keras.io/guides/transfer_learning/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hi fi z dy li ea eb lj ed ef hg bi translated">Keras文档:迁移学习和微调</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">作者:fchollet创建日期:2020/04/15最后修改时间:2020/05/12描述:迁移学习的完整指南&amp;…</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">keras.io</p></div></div><div class="lm l"><div class="ln l lo lp lq lm lr jm ld"/></div></div></a></div><div class="la lb ez fb lc ld"><a href="https://keras.io/api/applications/#extract-features-with-vgg16" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hi fi z dy li ea eb lj ed ef hg bi translated">Keras文档:Keras应用程序</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">Keras应用程序是深度学习模型，可与预训练的权重一起使用。这些型号可以是…</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">keras.io</p></div></div><div class="lm l"><div class="ls l lo lp lq lm lr jm ld"/></div></div></a></div><div class="la lb ez fb lc ld"><a href="https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hi fi z dy li ea eb lj ed ef hg bi translated">如何对狗和猫的照片进行分类(准确率97%)-机器学习掌握</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">逐步开发一个深度卷积神经网络来对狗和猫的照片进行分类</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">machinelearningmastery.com</p></div></div><div class="lm l"><div class="lt l lo lp lq lm lr jm ld"/></div></div></a></div><p id="6396" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其他:-</p><div class="la lb ez fb lc ld"><a href="https://www.appliedaicourse.com/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hi fi z dy li ea eb lj ed ef hg bi translated">应用根</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">我们知道转行是多么具有挑战性。我们的应用人工智能/机器学习课程被设计为整体学习…</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">www.appliedaicourse.com</p></div></div><div class="lm l"><div class="lu l lo lp lq lm lr jm ld"/></div></div></a></div><div class="la lb ez fb lc ld"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hi fi z dy li ea eb lj ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">medium.com</p></div></div><div class="lm l"><div class="lv l lo lp lq lm lr jm ld"/></div></div></a></div></div></div>    
</body>
</html>
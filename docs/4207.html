<html>
<head>
<title>Yolov5 inferencing on ONNXRuntime and OpenCV DNN.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ONNXRuntime和OpenCV DNN上的Yolov5推理。</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/yolov5-inferencing-on-onnxruntime-and-opencv-dnn-d20e4c52dc31?source=collection_archive---------1-----------------------#2022-12-26">https://medium.com/mlearning-ai/yolov5-inferencing-on-onnxruntime-and-opencv-dnn-d20e4c52dc31?source=collection_archive---------1-----------------------#2022-12-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c203" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们来探讨一下yolov5模型推断。</p><p id="eb30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在搜索在CPU上部署对象检测模型的方法时，我遇到了ONNX格式。ONNX是一种开放的神经网络交换，一种统一的模型表示格式。它支持在任何框架中训练的模型在任何部署目标上部署。ONNX图显示了为获得预测值而对要素进行的逐步变换。ONNX型号针对任何部署目标进行了优化。</p><p id="a97f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要将<a class="ae jc" href="https://github.com/ultralytics/yolov5/issues/251" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> yolov5 PyTorch模型导出到ONNX </strong> </a>。<strong class="ig hi"/><a class="ae jc" href="https://netron.app/" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">Netron app</strong></a>用于可视化ONNX模型图形、输入和输出节点及其名称和大小。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ac93e7c516faeaa31f4d00b65e6923a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9PKDAVcEMvim74hh0DUjeQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Yolov5s ONNX model graph visualization in Netron app.</figcaption></figure><p id="638d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了加载和运行ONNX模型，使用了OpenCV DNN和ONNXRuntime模块。</p><h2 id="60af" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ip ke kf kg it kh ki kj ix kk kl km kn bi translated"><strong class="ak"> ONNXRuntime和OpenCV DNN模块</strong></h2><ul class=""><li id="d00a" class="ko kp hh ig b ih kq il kr ip ks it kt ix ku jb kv kw kx ky bi translated">ONNXRuntime是一个跨平台的模型加速器。它执行与提供者无关的优化，并将模型图划分为子图，这些子图由硬件上的<strong class="ig hi">执行提供者</strong>使用执行环境中预安装的执行提供者库来执行。</li><li id="21b8" class="ko kp hh ig b ih kz il la ip lb it lc ix ld jb kv kw kx ky bi translated">OpenCV DNN使用OpenCV实现深度学习推理。它可以从不同的框架中加载不同的模型。它针对CPU进行了高度优化。</li></ul><h1 id="cb95" class="le ju hh bd jv lf lg lh jz li lj lk kd ll lm ln kg lo lp lq kj lr ls lt km lu bi translated"><strong class="ak">约洛夫5推论</strong></h1><p id="e3d5" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip lv ir is it lw iv iw ix lx iz ja jb ha bi translated">为了执行推理，使用导出到ONNX的yolov5s模型。</p><h2 id="7e7e" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ip ke kf kg it kh ki kj ix kk kl km kn bi translated"><span class="l ly lz ma bm mb mc md me mf di">W</span><strong class="ak">with onnx runtime</strong></h2><p id="0ddc" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip lv ir is it lw iv iw ix lx iz ja jb ha bi translated">ONNX模型由计算和运算符的图形组成。它们针对不同的硬件目标进行了优化。使用特定于执行目标(CPU、GPU、IoT等)的执行提供者来执行这些操作符。).使用参数<strong class="ig hi">提供者</strong>配置执行提供者。</p><ol class=""><li id="cc32" class="ko kp hh ig b ih ii il im ip mg it mh ix mi jb mj kw kx ky bi translated">在下面的例子中，如果CUDA执行提供程序ONNX运行时在GPU上执行内核。如果不是，内核就在CPU上执行。</li></ol><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="dbcb" class="mp ju hh ml b be mq mr l ms mt">providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if ort.get_device()=='GPU' else ['CPUExecutionProvider']<br/>session = ort.InferenceSession('yolov5s.onnx', providers=providers)</span></pre><p id="52b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.<strong class="ig hi">。get_outputs() </strong>和<strong class="ig hi">。get_inputs() </strong>方法用于获取节点的输入和输出元数据。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="6c72" class="mp ju hh ml b be mq mr l ms mt">outname = [i.name for i in session.get_outputs()] <br/>inname = [i.name for i in session.get_inputs()]</span></pre><p id="9bff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.若要计算预测，请运行ONNX模型。该函数采用输出名称和输入字典{输入名称:输入值}。输出是一个结果列表，其中的结果是一个数组或张量。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="5a55" class="mp ju hh ml b be mq mr l ms mt">inp = {inname[0]:im}<br/>outputs = session.run(outname, inp)</span></pre><p id="ba34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.为了避免多个重叠的边界框，实现了非最大值抑制。基于置信度和IOU阈值，边界框被过滤掉。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="6b46" class="mp ju hh ml b be mq mr l ms mt">output= torch.from_numpy(outputs)<br/>out = non_max_suppression(output, conf_thres=0.7, iou_thres=0.5)</span></pre><p id="d3b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.在图像上绘制边界框以进行最终检测。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="dbff" class="mp ju hh ml b be mq mr l ms mt">for i,(x0,y0,x1,y1,score,cls_id) in enumerate(out):<br/>      box = np.array([x0,y0,x1,y1])<br/>      box -= np.array(dwdh*2)<br/>      box /= ratio<br/>      box = box.round().astype(np.int32).tolist()<br/>      cls_id = int(cls_id)<br/>      score = round(float(score),3)<br/>      name = names[cls_id]<br/>      color = colors[name]<br/>      name += ' '+str(score)<br/>      cv2.rectangle(img,box[:2],box[2:],color,2)<br/>      cv2.putText(img,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2) </span></pre><h2 id="a9bb" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ip ke kf kg it kh ki kj ix kk kl km kn bi translated"><strong class="ak">与OpenCV DNN </strong></h2><ol class=""><li id="0703" class="ko kp hh ig b ih kq il kr ip ks it kt ix ku jb mj kw kx ky bi translated">加载ONNX模型。</li></ol><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="57cf" class="mp ju hh ml b be mq mr l ms mt">net = cv2.dnn.readNetFromONNX('yolov5s.onnx')</span></pre><p id="446a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.将图像转换为斑点，并将其设置为网络的输入。函数<strong class="ig hi">getUnconnectedOutLayersNames()</strong>给出输出层的名称，图像通过该输出层向前传播到检测。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="b231" class="mp ju hh ml b be mq mr l ms mt">blob = cv2.dnn.blobFromImage(img, 1/255 , (640, 640), swapRB=True, mean=(0,0,0), crop= False)<br/>net.setInput(blob)<br/>outputs= net.forward(net.getUnconnectedOutLayersNames())</span></pre><p id="7572" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.循环检测，并根据置信度阈值和类分值筛选出好的检测。每个检测包含<strong class="ig hi"> x，y，w，h，置信度得分，以及取决于类别数量的类别分数值</strong>。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="1404" class="mp ju hh ml b be mq mr l ms mt">for i in range(n_detections):<br/>  detect=out[0][i]<br/>  confidence= detect[4]<br/>  if confidence &gt;= conf_threshold:<br/>    class_score= detect[5:]<br/>    class_id= np.argmax(class_score)<br/>    if (class_score[class_id]&gt; score_threshold):<br/>      score.append(confidence)<br/>      class_ids.append(class_id)<br/>      x, y, w, h = detect[0], detect[1], detect[2], detect[3]<br/>      left= int((x - w/2)* x_scale )<br/>      top= int((y - h/2)*y_scale)<br/>      width = int(w * x_scale)<br/>      height = int( y*y_scale)<br/>      box= np.array([left, top, width, height])<br/>      boxes.append(box)</span></pre><p id="64eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.应用非最大抑制来移除多个重叠检测。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="e8e8" class="mp ju hh ml b be mq mr l ms mt">indices = cv2.dnn.NMSBoxes(boxes, np.array(score), conf_threshold, nms_threshold)</span></pre><p id="b416" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.基于最终检测在图像上绘制边界框。</p><pre class="je jf jg jh fd mk ml mm bn mn mo bi"><span id="ba8e" class="mp ju hh ml b be mq mr l ms mt">for i in indices:<br/>    box = boxes[i]<br/>    left = box[0]<br/>    top = box[1]<br/>    width = box[2]<br/>    height = box[3] <br/>    cv2.rectangle(img, (left, top), (left + width, top + height), (0, 0, 255), 3)<br/>    label = "{}:{:.2f}".format(classes[class_ids[i]], score[i])<br/>    text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 1)<br/>    dim, baseline = text_size[0], text_size[1]<br/>    cv2.rectangle(img, (left, top), (left + dim[0], top + dim[1] + baseline), (0,0,0), cv2.FILLED)<br/>    cv2.putText(img, label, (left, top + dim[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 1, cv2.LINE_AA)</span></pre><p id="ecb1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这将有助于您在CPU上部署定制的yolov5型号。在<a class="ae jc" href="https://github.com/poojatambe/Yolov5-inference-on-ONNXRuntime-and-opencv-DNN" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> my GitHub </strong> </a>上查看完整代码。</p><h2 id="9b86" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ip ke kf kg it kh ki kj ix kk kl km kn bi translated">参考</h2><ol class=""><li id="cc7e" class="ko kp hh ig b ih kq il kr ip ks it kt ix ku jb mj kw kx ky bi translated"><a class="ae jc" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a></li><li id="5c37" class="ko kp hh ig b ih kz il la ip lb it lc ix ld jb mj kw kx ky bi translated"><a class="ae jc" href="https://learnopencv.com/object-detection-using-yolov5-and-opencv-dnn-in-c-and-python/" rel="noopener ugc nofollow" target="_blank">https://learnopencv . com/object-detection-using-yolov 5-and-opencv-dnn-in-c-and-python/</a></li><li id="bcac" class="ko kp hh ig b ih kz il la ip lb it lc ix ld jb mj kw kx ky bi translated"><a class="ae jc" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank">https://onnx.ai/</a></li><li id="6cb5" class="ko kp hh ig b ih kz il la ip lb it lc ix ld jb mj kw kx ky bi translated"><a class="ae jc" href="https://onnxruntime.ai/" rel="noopener ugc nofollow" target="_blank">https://onnxruntime.ai/</a></li></ol><p id="08a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">以前的故事，</strong></p><ol class=""><li id="ff66" class="ko kp hh ig b ih ii il im ip mg it mh ix mi jb mj kw kx ky bi translated"><a class="ae jc" rel="noopener" href="/geekculture/everything-about-focal-loss-f2d8ab294133">关于焦损的一切</a>。</li><li id="5fc4" class="ko kp hh ig b ih kz il la ip lb it lc ix ld jb mj kw kx ky bi translated"><a class="ae jc" rel="noopener" href="/geekculture/image-classifier-with-streamlit-887fc186f60">带Streamlit的图像分类器</a>。</li><li id="2067" class="ko kp hh ig b ih kz il la ip lb it lc ix ld jb mj kw kx ky bi translated"><a class="ae jc" rel="noopener" href="/towards-artificial-intelligence/decision-tree-splitting-entropy-vs-misclassification-error-27fdf2f5e3bf">决策树分裂:熵与误分类误差</a>。</li></ol><p id="1679" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">快乐学习！！！</p><div class="mu mv ez fb mw mx"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="my ab dw"><div class="mz ab na cl cj nb"><h2 class="bd hi fi z dy nc ea eb nd ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ne l"><h3 class="bd b fi z dy nc ea eb nd ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nf l"><p class="bd b fp z dy nc ea eb nd ed ef dx translated">medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl jn mx"/></div></div></a></div></div></div>    
</body>
</html>
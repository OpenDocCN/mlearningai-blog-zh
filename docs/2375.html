<html>
<head>
<title>Machine Learning: How to Analyse Model Performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:如何分析模型性能</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/machine-learning-how-to-analyse-model-performance-f58658a20482?source=collection_archive---------2-----------------------#2022-04-23">https://medium.com/mlearning-ai/machine-learning-how-to-analyse-model-performance-f58658a20482?source=collection_archive---------2-----------------------#2022-04-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/31cacba2a42dff22cba207410ec34ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*XgUtTBjadEcAahmq3c3G2g.jpeg"/></div></figure><p id="72a2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们用准确性来测试我们的模型工作得有多好。事实证明，准确性本身可能会误导人。在本课中，我们首先研究为什么精确度本身不一定是模型性能的良好指标，然后我们将了解模型性能的一些其他度量。</p><blockquote class="jj jk jl"><p id="98bb" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">#为了方便起见在一个地方进行所有导入<br/>从sklearn导入matplotlib.pyplot作为sklearn.datasets导入fetch _ 20newsgroups _矢量化<br/>导入numpy作为np <br/>导入pandas作为pd <br/>导入seaborn作为sns <br/>从sklearn.linear_model导入LogisticRegression <br/>从sklearn.model_selection导入train_test_split，cross_val_score <br/>从sklearn.dummy导入DummyClassifier <br/>从sklearn.metrics导入混淆</p></blockquote><h1 id="9252" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">20个新闻组数据集</h1><p id="2053" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">在本例中，我们将使用20个新闻组数据集，这些数据集可以通过scikit-learn的数据集库加载。20个新闻组数据集包含20个主题的大约18000个新闻组帖子。</p><blockquote class="jj jk jl"><p id="fb32" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">dataset = fetch _ 20 news groups _ vectorized()<br/>X，y = dataset.data，dataset.target</p></blockquote><p id="9ddb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">接下来，我们可以计算每个类的实例数量。</p><blockquote class="jj jk jl"><p id="734a" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">对于class_name，zip中的class_count(dataset . target _ names，NP . bin count(dataset . target)):<br/>print(class _ name，class _ count)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="df53" class="lc jr hh ky b fi ld le l lf lg">alt.atheism 480<br/>comp.graphics 584<br/>comp.os.ms-windows.misc 591<br/>comp.sys.ibm.pc.hardware 590<br/>comp.sys.mac.hardware 578<br/>comp.windows.x 593<br/>misc.forsale 585<br/>rec.autos 594<br/>rec.motorcycles 598<br/>rec.sport.baseball 597<br/>rec.sport.hockey 600<br/>sci.crypt 595<br/>sci.electronics 591<br/>sci.med 594<br/>sci.space 593<br/>soc.religion.christian 599<br/>talk.politics.guns 546<br/>talk.politics.mideast 564<br/>talk.politics.misc 465<br/>talk.religion.misc 377</span></pre><p id="634d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们看到这是一个平衡的数据集。也就是说，每个阶层都相当平均地被代表。不幸的是，我们在现实生活中并不总能找到如此均匀分布的数据。因此，为了查看不平衡数据集的影响，让我们将该数据集简化为两个类:sci.space和everything。首先，复制目标数据，然后用0替换所有非sci.space类的实例，用1替换所有sci.space类的实例。</p><p id="9325" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">要查看此更改的效果，请再次查看每个类的计数:</p><blockquote class="jj jk jl"><p id="46c3" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">y_2 = y.copy() <br/> y_2[y_2！= 14]= 0<br/>y _ 2[y _ 2 = = 14]= 1<br/>NP . bin count(y _ 2)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="93b7" class="lc jr hh ky b fi ld le l lf lg">array([10721,   593])</span></pre><p id="d47c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们有一个类别不平衡的数据集:也就是说，在表示与空间无关的帖子的负类别中，我们有10，721个实例，而在表示关于空间的帖子的正类别中，我们只有593个实例。现在我们可以训练一个分类器来预测一个帖子是否是关于空间的。让我们使用逻辑回归分类器。</p><blockquote class="jj jk jl"><p id="0d77" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">X_train，X_test，y_train，y_test = train_test_split(X，y_2，random _ state = 82)<br/>lr = LogisticRegression(solver = ' lbfgs ')<br/>lr . fit(X _ train，y_train) <br/> lr.score(X_test，y_test)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="0b04" class="lc jr hh ky b fi ld le l lf lg">0.9671261930010604</span></pre><p id="3b56" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">还不错！没有任何调整，我们得到了0.967的精度。96.7%的准确率相当不错，但在我们庆祝我们的数据科学技能之前，让我们看看这在不平衡的数据集环境中意味着什么。</p><p id="820e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">假设我们写了一个分类器，它根本不工作，甚至不看特征，只是简单地返回所有的预测作为主导类。在这种情况下，占主导地位的阶级就是消极阶级。因此，我们的虚拟分类器将100%的时间预测负类。虚拟分类器的准确性如何？花点时间想一想。</p><p id="a0cb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">回想一下</p><blockquote class="jj jk jl"><p id="7a7b" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">精确度= # correctpredictions all predictions精确度= # correctpredictions all predictions</p></blockquote><p id="5d81" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">由于我们有10，721个阴性样本，我们的虚拟分类器将正确10，721次，错误593次。</p><blockquote class="jj jk jl"><p id="6a34" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">准确度=1072110721+593=0.94759准确度= 1072110721+593 = 0.94759</p></blockquote><p id="acf4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">还是蛮厉害的！</p><p id="57c4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Scikit-learn实际上有一个虚拟分类器来帮助说明这个确切的场景。</p><blockquote class="jj jk jl"><p id="056b" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">dummy = dummy classifier(strategy = ' most _ frequency ')<br/>dummy . fit(X _ train，y_train) <br/> dummy.score(X_test，y_test)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="5a9b" class="lc jr hh ky b fi ld le l lf lg">0.9568752209261223</span></pre><p id="4ae8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请记住，虚拟分类器实际上并不使用特征来进行预测，它只是查看哪个类占主导地位，并每次都返回该类。这里，在我们的测试数据上，我们得到了超过95%的准确率，几乎与我们的真实分类器一样好。考虑到这两个结果的接近程度，我们真的有信心我们的分类器做得这么好吗？</p><p id="0cbf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这个伪分类器非常有用，原因有很多。它给出了一个零精度基线，您可以用它来比较模型的性能。这样我们就知道我们的分类器是否比随机猜测做得更好。</p><p id="527e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果模型的精度接近零精度基线，这可能意味着:</p><ul class=""><li id="5d70" class="lh li hh in b io ip is it iw lj ja lk je ll ji lm ln lo lp bi translated">你的特征不能很好地预测你的问题。</li><li id="b610" class="lh li hh in b io lq is lr iw ls ja lt je lu ji lm ln lo lp bi translated">您的算法参数可能需要调整。</li><li id="9028" class="lh li hh in b io lq is lr iw ls ja lt je lu ji lm ln lo lp bi translated">你有很大的阶级不平衡。</li></ul><h1 id="8b59" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">混淆矩阵</h1><p id="2b88" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">混淆矩阵只是一个显示预测值和实际值的每个组合的表格。它可以很容易地看到您的模型正在犯什么类型的错误，并允许生成许多描述您的模型性能的指标。Scikit-learn附带了一个函数，可以在给定一组实际值和一组预测值的情况下计算混淆矩阵。</p><h1 id="6de0" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">为什么我们要使用混淆矩阵？</h1><p id="7ae1" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">虽然具有良好的准确性很重要，但这并不能说明全部情况。混淆矩阵通过向我们展示事物是如何分类的，让我们对分类模型的性能有了更深入的了解。它向我们揭示了哪些数据点是正确的，哪些是错误的。</p><p id="f6d2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们稍后会对此进行更多的解释。</p><blockquote class="jj jk jl"><p id="e725" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">预测= lr.predict(X_test) <br/>混淆=混淆_矩阵(y_test，预测，标签=[1，0]) <br/>打印(混淆)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="e52b" class="lc jr hh ky b fi ld le l lf lg">[[  29   93]<br/> [   0 2707]]</span></pre><p id="4edc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们一会儿会解释这个。</p><p id="747a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">虽然这给了我们所需要的所有信息，但阅读起来并不容易。为了得到混乱矩阵的更漂亮的图片，我们可以使用<a class="ae lv" href="https://www.kaggle.com/grfiv4/plot-a-confusion-matrix" rel="noopener ugc nofollow" target="_blank">这个来自这里的函数</a>，或者任何一个你可以在网上找到的类似函数。</p><blockquote class="jj jk jl"><p id="bd8b" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">def plot_confusion_matrix(cm，<br/> target_names，<br/> title='Confusion matrix '，<br/> cmap=None，<br/> normalize=True): <br/> """ <br/>给定一个sklearn混淆矩阵(cm)，制作一个漂亮的plot<br/>Arguments<br/>————————-<br/>cm:来自sk learn . metrics . Confusion _ matrix的混淆矩阵<br/> target_names:给定分类类如[0，1，2] <br/>类名，例如:['high '，' low'] <br/>标题:显示在矩阵顶部的文本<br/>cmap:matplotlib . py plot . cm中显示的值的渐变<br/>参见http://matplotlib . org/examples/color/color maps _ reference . html<br/>PLT . get _ cmap(' jet ')或plt.cm.Blues <br/> normalize:如果为False，则绘制原始数字<br/>如果为True，则绘制比例<br/>用法<br/>—<br/> #类名称列表<br/>title = best _ estimator _ name)#图标题<br/>citation<br/>———<br/>http://scikit-learn . org/stable/auto _ examples/model _ selection/plot _ confusion _ matrix . html<br/>" " "<br/>import matplotlib . py plot as PLT<br/>import numpy as NP<br/>import ITER tools<br/>accuracy = NP . trace(cm)/float(NP cmap = cmap)<br/>PLT . title(title)<br/>PLT . color bar()<br/>if target_names not None:<br/>tick _ marks = NP . arange(len(target _ names))<br/>PLT . x ticks(tick _ marks，target _ names，rotation = 45)<br/>PLT . y ticks(tick _ marks，target _ names)<br/>if normalize:<br/>cm = cm . astype(' float ')/cm . sum(axis) format(cm[i，j])、<br/>horizontal alignment = " center "、<br/> color="white" if cm[i，j]&gt;thresh else " black ")<br/>else:<br/>PLT . text(j，I，" {:，} "。format(cm[i，j])、<br/>horizontal alignment = " center "、<br/> color="white" if cm[i，j]&gt;thresh else " black ")<br/>PLT . tight _ layout()<br/>PLT . y label(' True label ')<br/>PLT . xlabel(' Predicted label \ nacuracy = {:0.4f }；misclass={:0.4f} '。format(accuracy，misclass)) <br/> plt.show()</p><p id="e77d" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">plot _ Confusion _ Matrix(cm =混淆，target_names = ['Space '，' Not Space']，title = '混淆矩阵'，normalize=False)</p></blockquote><p id="f6d7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意，上图方框中出现的数字与scikit-learn生成的基于文本的矩阵中的数字相同。但是这个带标签的图更适合用来直观地评估一个混淆矩阵。</p><h1 id="961e" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">解读矩阵</h1><p id="b9d2" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">但是这些数字意味着什么呢？假设我们训练了一个二进制分类模型来识别有猫和没有猫的图像。我们建立了一个图像数据集，这些图像在一张照片中被正确地标记为猫，而在其他照片中没有猫。然后，我们在一个带有标签的测试集上运行这个模型，测试集上有几幅图像，有些是猫，有些没有猫。一些图像被正确地预测为图像中真正的猫，但是一些猫的图像被错误地预测为不是猫。相反的情况会发生，照片被真正归类为不是猫，但有些照片被漏掉了，照片里有一只猫。</p><p id="7bf1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然后，我们可以计算我们的模型正确预测猫、正确预测没有猫、错误预测有猫和错误预测没有猫的次数。这些是我们插入混淆矩阵的数字。</p><p id="74ee" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">根据上图，我们可以将真阳性(TP)定义为模型正确预测阳性类别(cat)的次数，将真阴性(TN)定义为模型正确预测阴性类别(无cat)的次数。</p><p id="35cc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">假阳性(FP)是模型错误预测阳性类别的次数，假阴性(FN)是模型错误预测阴性类别的次数。在统计学中，假阳性被称为I型错误，假阴性被称为II型错误。</p><p id="75dd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这意味着真阳性和真阴性是正确预测的总数，而假阳性和假阴性是错误预测的总数。</p><p id="92d1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">从这个矩阵中可以计算出许多重要的指标。第一，准确性:</p><p id="a86a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">准确度= TP+TNTP+TN+FP+FN = 29+270729+2707+0+93 = 0.967准确度= TP+TNTP+TN+FP+FN = 29+270729+2707+0+93 = 0.967</p><h2 id="64f9" class="lc jr hh bd js lw lx ly jw lz ma mb ka iw mc md ke ja me mf ki je mg mh km mi bi translated">精确</h2><p id="a0fb" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">精度是一个值，它告诉我们有多少比例的正面预测是正确的。也就是说，如果模型的精度为0.5，那么其50%的正面预测是正确的。让我们计算模型的精度。</p><p id="2f21" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">精度=TPTP+FP=2929+0=1.0精度= TPTP+FP = 2929+0 = 1.0</p><p id="be25" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当我们的模型预测一个帖子在组sci.space中时，它只有24%的正确率！</p><p id="2996" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果不看精度分数，我们会因为简单地接受表面上的精度分数而错过这一点。</p><h2 id="ddd5" class="lc jr hh bd js lw lx ly jw lz ma mb ka iw mc md ke ja me mf ki je mg mh km mi bi translated">回忆</h2><p id="12e2" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">回忆是一个值，它告诉我们正确预测的阳性比例。这是一个很好的指标，表明有多少积极的实例被错过。</p><blockquote class="jj jk jl"><p id="e528" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">回忆=TPTP+FN=2929+93=0.24回忆= TPTP+FN = 2929+93 = 0.24</p></blockquote><p id="d56a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们发现100%的帖子都是关于太空的。</p><h1 id="62aa" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">权衡取舍</h1><p id="b56b" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">在精确度和召回率之间经常要进行权衡。我们也许可以调整我们的模型来提高精确度；也就是说，做出更少的假阳性预测，但这是以更低的召回率为代价的。类似地，如果我们调整模型来提高召回率，那么精度可能会受到影响。</p><p id="0306" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">没有一种正确的方法来调整您的模型。你已经根据具体情况作出了决定。给定20个新闻组数据集和我们训练的模型，我们对我们的精确度和召回分数满意吗？这取决于我们计划如何使用这个模型和业务用例。假设我们使用这个模型作为自动确定新帖子标签的系统的一部分，这样我们就可以向对空间感兴趣的人推荐帖子。</p><p id="b328" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">给定24%的精度，超过75%的推荐将是错误的。而且召回率100%，所有关于太空的帖子都会被正确识别。我们的用户可能会很恼火，因为我们推荐了太多不相关的帖子(误报)。对于这种情况，如果我们提高精确度，使我们的推荐更相关，但可能会错过更多的空间帖子，我们的用户会更高兴。</p><p id="c3a8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在考虑人群中特定疾病的筛查测试。假设我们训练一个模型，在给定病人一些症状的情况下检测疾病。如果我们的模型预测阳性，我们会立即送病人去做进一步的测试和治疗。如果模型预测错误，那么我们假设患者是安全的。这种情况下的低精确度意味着许多预测的阳性病例将被证明没有患病。高召回将意味着大多数阳性病例被发现。这似乎是对的。想象一下，如果召回率低，许多患有该疾病的人将被错误地归类为没有患病。</p><p id="6a2c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是一个召回比精确更重要的案例，因为我们不想让需要治疗的人从缝隙中溜走(假阴性)。</p><h1 id="f713" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">f分数</h1><p id="62f9" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">当评估分类器时，将精确度和召回率结合成称为F1分数的单个值是方便的。我们使用F-score来看这两个指标结合起来是如何达到平衡的。</p><p id="4178" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是通过以下公式完成的:</p><blockquote class="jj jk jl"><p id="3f95" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">f1 = 2×precision×recall precision+recall = 2×tp2×TP+FN+FP f1 = 2×precision×recall precision+recall = 2×tp2×TP+FN+FP</p></blockquote><p id="b625" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在计算该值时，精确度和召回率的贡献是相等的。</p><p id="59e9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">F1分数有一个更一般的情况，叫做F-beta分数。为了计算该分数，使用参数ββ来调整召回率和精确度的贡献。为了提高精度，使用β &lt;1β&lt;1 is used and to favor recall a value of β&gt; 1β&gt;1的值。这样，如果您正在构建一个精度比召回更重要的模型，则将ββ的值设置为小于1。公式是:</p><blockquote class="jj jk jl"><p id="f23c" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">fβ=(1+β2)×精度×召回率(β2×精度)+召回率=(1+β2)×TP(1+β2)×TP+β×FN+FPFβ=(1+β2)×精度×召回率(β2×精度)+召回率=(1+β2)×TP(1+β2)×TP+β×FN+FP</p></blockquote><p id="cf4c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们不必手工进行这些计算。Scikit-learn在sklearn.metrics库中提供了计算这些值的函数。这些函数中的每一个都将实际目标值和模型做出的预测作为输入。</p><blockquote class="jj jk jl"><p id="6ffa" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">准确度=精确度_分数(y _测试，预测)<br/>精确度=精确度_分数(y _测试，预测)<br/>召回=召回_分数(y _测试，预测)<br/>f1 = f1 _分数(y _测试，预测)<br/>fbeta _精确度= fbeta _分数(y _测试，预测，0.5)<br/>fbeta _召回= fbeta _分数(y _测试，预测，2) <br/>打印('精确度分数:{:.2f} '。格式(精度))<br/>打印('精度分数:{:.2f} '。format(precision)) <br/>打印('召回分数:{:.2f} '。格式(回忆))<br/>打印(' F1分数:{:.2f} '。format(f1)) <br/> print('Fbeta分数偏向精度:{:.2f} '。format(FBeta _ precision))<br/>print(' FBeta评分偏向召回:{:.2f} '。格式(fbeta_recall))</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="bbcf" class="lc jr hh ky b fi ld le l lf lg">Accuracy score: 0.97<br/>Precision score: 1.00<br/>Recall score: 0.24<br/>F1 score: 0.38<br/>Fbeta score favoring precision: 0.61<br/>FBeta score favoring recall: 0.28</span></pre><p id="3b9d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意，FβFβ得分的β &lt;1β&lt;1 scored higher than the FβFβ with β&gt; 1β&gt;1。这是因为我们有比召回分数更高的精确度分数。</p><p id="6b51" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">classification_report函数对于通过一次调用给出这些指标的摘要也很有用。</p><blockquote class="jj jk jl"><p id="ca42" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">report = class ification _ report(y _ test，predictions，target_names=['Not Space '，' Space']) <br/>打印(报告)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="071f" class="lc jr hh ky b fi ld le l lf lg">precision    recall  f1-score   support</span><span id="7a0a" class="lc jr hh ky b fi mj le l lf lg">   Not Space       0.97      1.00      0.98      2707<br/>       Space       1.00      0.24      0.38       122</span><span id="d969" class="lc jr hh ky b fi mj le l lf lg">    accuracy                           0.97      2829<br/>   macro avg       0.98      0.62      0.68      2829<br/>weighted avg       0.97      0.97      0.96      2829</span></pre><p id="d390" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们可以将该报告与关于虚拟分类器的报告进行比较。虚拟分类器可以用于以与真实分类器相似的方式进行预测，除了我们将得到所有作为主导类的结果。在这个例子中，我们知道主导类是否定类，所以我们的虚拟分类器将0个实例预测为肯定类。</p><blockquote class="jj jk jl"><p id="b620" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">dummy _ report = class ification _ report(y _ test，dummy.predict(X_test)，target_names=['Not Space '，' Space '])<br/>print(dummy _ report)</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="972c" class="lc jr hh ky b fi ld le l lf lg">precision    recall  f1-score   support</span><span id="7104" class="lc jr hh ky b fi mj le l lf lg">   Not Space       0.96      1.00      0.98      2707<br/>       Space       0.00      0.00      0.00       122</span><span id="9ec6" class="lc jr hh ky b fi mj le l lf lg">    accuracy                           0.96      2829<br/>   macro avg       0.48      0.50      0.49      2829<br/>weighted avg       0.92      0.96      0.94      2829</span><span id="afa6" class="lc jr hh ky b fi mj le l lf lg">/Users/karenfarbman/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.<br/>  _warn_prf(average, modifier, msg_start, len(result))</span></pre><p id="5466" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">未定义的度量警告是由于TP + FP == 0的事实。这是一个很好的指示，表明即使精度很高，分类器的性能也不好。即使我们的分类器确实有一些FP，对于那个类来说，精度和召回率也是相当低的。</p><h1 id="d2a2" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">决策函数—改变概率阈值</h1><p id="33ad" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">给定一些输入，模型为每个输入生成一些概率。这是由predict_proba()方法给出的。该方法给出了该实例是否属于正类的概率，而不是给出实际的预测。</p><p id="f905" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在下面的代码中，生成了测试数据的概率列表，并打印出前30个值。</p><blockquote class="jj jk jl"><p id="0b6b" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">probs = lr . predict _ proba(X _ test)[:，1] <br/> print(probs[1:30])</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="7443" class="lc jr hh ky b fi ld le l lf lg">[0.01364891 0.05711429 0.03494059 0.03348212 0.02932255 0.02216111<br/> 0.45071078 0.01932676 0.07011708 0.08472435 0.03919031 0.02427247<br/> 0.01909561 0.02652153 0.06818679 0.02653776 0.09209324 0.03810381<br/> 0.01464452 0.02377862 0.02685651 0.05803195 0.03221372 0.02388465<br/> 0.0661609  0.06428845 0.04730358 0.0219367  0.03626409]</span></pre><p id="89f3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们在上一课中已经看到，概率阈值是0.5:也就是说，如果概率大于0.5，我们将预测为正，如果小于0.5，我们将预测为负。在下图中，所有测试样本的概率绘制在两个分布图中。红色地块为负类，绿色地块为正类。蓝线是概率阈值。</p><p id="e339" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意，在阈值的两边都有积极的实例。这意味着阈值左边的所有阳性实例将被错误地分类为阴性，从而给出假阴性。</p><blockquote class="jj jk jl"><p id="22ae" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">pos = [i for i，j in zip(probs，y_test) if j == 1] <br/> neg = [i for i，j in zip(probs，y _ test)if j = = 0]<br/>with PLT . xkcd():<br/>fig = PLT . fig(figsize =(8，4)) <br/> sns.distplot(pos，hist = False，kde = True，color='g '，<br/> kde_kws = {'shade': True，'线宽</p></blockquote><p id="dbb3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通过调整阈值，我们可以影响召回和精度值。假设我们想确保没有误报:也就是说，我们不想将任何与空间无关的帖子归类为空间。我们可以将阈值向右移动，直到该行右侧没有红色实例。这相应地将意味着更少的阳性实例将被正确识别。或者，换句话说，更多的阳性实例将在阈值的左边结束，并且将被错误地分类为阴性。</p><h1 id="cb6b" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">受试者工作特征曲线</h1><p id="1eaf" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">如果我们将阈值设置为0(将阈值一直向左移动)，那么模型预测所有样本为1。我们将获得1的真实阳性率(tpr ),即所有阳性实例都将被正确预测。我们还会得到1的假阳性率(fpr ),因为所有阴性样本都会被错误地预测为阳性。</p><p id="a1c4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们将阈值设置为1，那么模型预测所有样本为0。我们得到tpr为0，因为没有一个实际的阳性样本将被正确预测，并且得到fpr为0，因为没有一个阴性类别将被预测为阳性。</p><p id="af75" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当我们在这两个极端之间改变阈值时，我们得到不同的tpr和fpr值。我们可以绘制这些值，以查看阈值移动时这些值之间的关系。</p><p id="94cb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当我们将阈值从0改变到1时，我们得到的一组点可以被连接来描述一条穿过空间的曲线，该曲线被称为接收器工作特性(ROC)曲线。</p><p id="ebe4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">sklearn.metrics.roc_curve函数计算我们可以用来绘制roc曲线的fpr、tpr和阈值。下面打印前30个值。</p><blockquote class="jj jk jl"><p id="d2e6" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">fpr，tpr，thresholds = roc_curve(y_test，probs)<br/>print(FPR[1:30])<br/>print(TPR[1:30])<br/>print(thresholds[1:30])</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="97fb" class="lc jr hh ky b fi ld le l lf lg">[0.         0.         0.00036941 0.00036941 0.00073883 0.00073883<br/> 0.00110824 0.00110824 0.00147765 0.00147765 0.00184706 0.00184706<br/> 0.00221648 0.00221648 0.00258589 0.00258589 0.00332471 0.00332471<br/> 0.00369413 0.00369413 0.00480236 0.00480236 0.0059106  0.0059106<br/> 0.00628001 0.00628001 0.00664943 0.00664943 0.00775767]<br/>[0.00819672 0.46721311 0.46721311 0.48360656 0.48360656 0.5<br/> 0.5        0.59016393 0.59016393 0.6147541  0.6147541  0.62295082<br/> 0.62295082 0.64754098 0.64754098 0.68852459 0.68852459 0.70491803<br/> 0.70491803 0.74590164 0.74590164 0.7704918  0.7704918  0.77868852<br/> 0.77868852 0.78688525 0.78688525 0.80327869 0.80327869]<br/>[0.98462604 0.3446592  0.34283523 0.3311512  0.32653259 0.32153467<br/> 0.31893541 0.27469392 0.27468563 0.24375424 0.24159574 0.23921165<br/> 0.23860809 0.21948719 0.20223596 0.18165188 0.17696934 0.16373987<br/> 0.16369255 0.15575538 0.15284347 0.1478981  0.13727432 0.13693788<br/> 0.13573329 0.13529207 0.13304517 0.13221123 0.12896697]</span></pre><blockquote class="jj jk jl"><p id="ced2" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">fig = plt.figure(figsize = (6，6)) <br/> plt.plot([0，1]，[0，1]，' k — ') <br/> plt.plot(fpr，tpr) <br/> plt.xlabel('假阳性率')<br/> plt.ylabel('真阳性率')<br/>PLT . title(' Logistic回归模型的ROC曲线')<br/> plt.show()</p></blockquote><p id="9d09" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">该图的左上角是理想点:它使假阳性率最小化，使真阳性率最大化。因此，接近该拐角的陡峭曲线比保持接近虚线基线的浅曲线更好。虚线代表50%概率分类器。也就是说，任何像掷硬币一样有效的分类器都会有一条接近那条线的曲线。但这和随机一样好。所以这条线上的曲线比随机曲线好。这个分类器的特殊曲线非常好，因为你可以看到它在变平之前急剧上升。</p><h1 id="c081" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">精确回忆曲线</h1><p id="67d9" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">另一个有用的可视化工具是精确回忆曲线。类似于ROC曲线，它显示了当阈值从0到1变化时，精确度与回忆的关系。同样，sklearn.metrics库提供了一个有帮助的函数。</p><blockquote class="jj jk jl"><p id="5e7f" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">pres，rec，thresholds = Precision _ Recall _ Curve(y _ test，predictions)<br/>fig = PLT . figure(fig size =(6，6)) <br/> plt.plot(rec，pres)<br/>PLT . xlabel(' Recall ')<br/>PLT . ylabel(' Precision ')<br/>PLT . title(' Precision-Recall Curve ')<br/>PLT . show()</p></blockquote><p id="0c5e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这种情况下，我们看到随着召回率的增加，准确率平稳下降。我们并不总是有如此平滑的曲线，但总体下降趋势是预料之中的。</p><p id="c922" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请记住，这两种可视化服务略有不同的目的。</p><ul class=""><li id="1f8c" class="lh li hh in b io ip is it iw lj ja lk je ll ji lm ln lo lp bi translated">当类别或多或少平衡时使用ROC曲线。</li><li id="4036" class="lh li hh in b io lq is lr iw ls ja lt je lu ji lm ln lo lp bi translated">当存在类别不平衡时，使用精确召回曲线。</li></ul><h1 id="ba09" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">ROC曲线下面积</h1><p id="a49c" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">给定ROC曲线，我们可以从中计算出一个有用的指标。因为左上角是理想的，我们希望曲线尽可能靠近那个角。如果我们测量曲线下的面积，我们会得到一个有用的度量，告诉我们离理想有多近。在下图中，我们给曲线下的区域加了阴影。请注意，如果曲线越来越接近基线，面积将越来越小。</p><blockquote class="jj jk jl"><p id="602e" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">fig = plt.figure(figsize = (6，6)) <br/> plt.plot([0，1]，[0，1]，' k — ') <br/> plt.plot(fpr，tpr) <br/> plt.fill(fpr，tpr，' grey '，alpha=0.3) <br/> plt.xlabel('假阳性率')<br/> plt.ylabel('真阳性率')<br/> plt.title('逻辑回归模型的ROC曲线')<br/></p></blockquote><p id="990d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了计算曲线下面积(AUC ),我们使用sklearn.metrics中的roc_auc_score函数。该函数将实际标签和预测概率作为输入。</p><blockquote class="jj jk jl"><p id="37e0" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">auc = roc_auc_score(y_test，probs)<br/>print(' ROC曲线下面积:{:.3f} '。格式(auc))</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="6a1b" class="lc jr hh ky b fi ld le l lf lg">Area under the ROC curve: 0.990</span></pre><h1 id="5feb" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">交互效度分析</h1><p id="f948" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">到目前为止，我们一直使用训练测试分割来保留一部分数据进行测试。我们这样做是为了让我们有一些以前看不到的数据来测试模型。如果我们使用相同的数据进行训练和测试，我们将面临模型过度适应训练数据的风险。</p><p id="a37f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">但是仍然存在过度适应测试数据本身的风险。如果我们调整我们的模型以在测试数据上表现良好，我们有什么保证它将在新数据上继续表现良好？此外，我们知道，训练算法容易受到数据微小变化的影响。回想一下关于线性分类器的讨论，我们正在寻找一组优化成本函数的参数值。这样的搜索没有绝对正确的答案。我们找到的值取决于我们用来训练模型的数据。</p><p id="1efc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通过将数据分为训练和测试，我们大大减少了可用于学习模型的样本数量，并且结果可以取决于对集合对的特定随机选择。</p><p id="7339" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们可以通过多次调用train_test_split并用每次的结果训练一个模型来说明这一点。train_test_split函数将数据随机分配给训练集和测试集。这意味着每次你调用这个函数时，不同的数据集被分配给测试集。</p><blockquote class="jj jk jl"><p id="4aee" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">X_train，X_test，y_train，y_test = train_test_split(X，y _ 2)<br/>lr = LogisticRegression(solver = ' lbfgs ')<br/>lr . fit(X _ train，y_train) <br/> print('第一次拆分得分:{:.3f} '。format(lr.score(X_test，y _ test))<br/>X _ train，X_test，y_train，y_test = train_test_split(X，y _ 2)<br/>lr = LogisticRegression(solver = ' lbfgs ')<br/>lr . fit(X _ train，y_train) <br/> print('第二次拆分分数:{:.3f} '。格式(lr.score(X_test，y_test)))</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="60ee" class="lc jr hh ky b fi ld le l lf lg">First split score: 0.960<br/>Second split score: 0.955</span></pre><p id="857a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在上面的代码中，train_test_split被调用了两次，并使用结果对两个模型进行了训练。请注意，不同型号的精确度不同。这意味着，我们冒着随机选择有偏见的训练或测试数据集的风险，最终得到的模型不能很好地概括看不见的数据。</p><p id="d51d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这就是交叉验证的由来。</p><p id="3093" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们探索交叉验证之前，先简要说明一下train_test_split的随机性。如果我们每次都得到不同的测试集，并且每次都得到不同的准确度分数，那么我们如何知道任何观察到的改进是参数调整的结果还是随机的呢？在模型构建过程中，创建一个保持稳定的测试分割是很有用的。为此，我们使用random_state参数(我们在本笔记开始时使用过)。此参数接受一个整数，并将其用作随机生成器的种子。这意味着您可以指定相同的数字，以每次获得相同的分割。在下面的代码中，两个模型再次针对两个数据分割进行训练，这次使用相同的random_state。</p><blockquote class="jj jk jl"><p id="e827" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">X_train，X_test，y_train，y_test = train_test_split(X，y_2，random _ state = 40)<br/>lr = LogisticRegression(solver = ' lbfgs ')<br/>lr . fit(X _ train，y_train) <br/> print('第一次拆分得分:{:.3f} '。format(lr.score(X_test，y _ test))<br/>X _ train，X_test，y_train，y_test = train_test_split(X，y_2，random _ state = 40)<br/>lr = LogisticRegression(solver = ' lbfgs ')<br/>lr . fit(X _ train，y_train) <br/> print('第二次拆分分数:{:.3f} '。格式(lr.score(X_test，y_test)))</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="7ace" class="lc jr hh ky b fi ld le l lf lg">First split score: 0.964<br/>Second split score: 0.964</span></pre><p id="9d6f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在回到交叉验证。交叉验证的工作原理是将数据集分成指定数量(k)的不同集合，称为折叠。通常k = 5或10倍，但你可以随意使用任何数量的折叠。然后，我们迭代折叠，用k-1个折叠训练一个模型，并使用剩余的折叠作为验证的测试集。在每次迭代中，不同的折叠被用作测试集。</p><p id="4403" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这为创建和训练的k个模型产生了k个准确度分数。但是，每个模型都是在不同的数据集上训练和测试的。此外，每个数据样本都有机会出现在一个模型的测试集中。然后，我们可以找到分数的平均值，以获得模型的整体值。</p><p id="8d01" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">sk learn . model _ selection . cross _ val _ score函数执行这个交叉验证过程，为创建的每个模型提供一个分数数组。请记住，这可能是一个昂贵的(就时间而言)过程，因为你必须创建和训练k个不同的模型。通常，您首先使用train_test_split将数据拆分为训练集和测试集，就像我们在上面所做的那样，交叉验证在训练集上完成，而测试集用于对所选模型的最终评估。</p><blockquote class="jj jk jl"><p id="9ffb" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated">X_train，X_test，y_train，y_test = train_test_split(X，y_2，random _ state = 40)<br/>clf = logistic regression(solver = ' lbfgs ')<br/>cv _ scores = cross _ val _ score(clf，X_train，y_train，cv = 5)<br/>print(' 5倍的准确度分数: '，cv_scores) <br/> print('平均交叉验证分数:{:.3f})。格式(np.mean(cv_scores)))</p></blockquote><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="6cb9" class="lc jr hh ky b fi ld le l lf lg">Accuracy scores for the 5 folds:  [0.95167943 0.96169711 0.95816146 0.95639364 0.95875074]<br/>Mean cross validatiion score: 0.957</span></pre><p id="526c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">基于分数，模型能够在数据集的所有5个折叠上一致地预测高。这让我们确信，该模型在看不见的数据上多次表现良好，这不仅仅是因为在最初的数据分割中运气好。</p><h1 id="00cb" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论:</h1><p id="e837" class="pw-post-body-paragraph il im hh in b io ko iq ir is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji ha bi translated">准确度分数并不能说明全部情况，因此我们使用各种技术来更好地了解我们的分类模型的执行情况。</p><p id="1219" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">有了不同的评估度量，我们可以识别模型的错误分类，并使用这些信息在进一步的迭代中改进模型。</p><p id="8686" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们还想考虑权衡，以便更好地将我们的时间和精力集中在下一个模型迭代上。如何使用该模型将推动这些决策。</p><p id="0336" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们现在可以使用上面描述的各种模型评估技术以及交叉验证来为我们的下一个项目选择性能最佳的模型。</p><div class="mk ml ez fb mm mn"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mo ab dw"><div class="mp ab mq cl cj mr"><h2 class="bd hi fi z dy ms ea eb mt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mu l"><h3 class="bd b fi z dy ms ea eb mt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mv l"><p class="bd b fp z dy ms ea eb mt ed ef dx translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb ij mn"/></div></div></a></div></div></div>    
</body>
</html>
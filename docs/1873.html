<html>
<head>
<title>Measuring objects with Computer Vision and 3D reconstruction.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用计算机视觉和三维重建测量物体。</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/measuring-objects-with-computer-vision-and-3d-reconstruction-fb91600cb237?source=collection_archive---------1-----------------------#2022-02-07">https://medium.com/mlearning-ai/measuring-objects-with-computer-vision-and-3d-reconstruction-fb91600cb237?source=collection_archive---------1-----------------------#2022-02-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="8ab4" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated"><em class="iw">在这篇文章中，你将学习如何使用Meshroom从一组图像中生成3D重建，并使用它进行真实世界的测量</em></h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/e5dd9eb5d8eae276594e1c5335294f44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9W6wi89zhp49Nhw-6FsP4Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Real-world picture vs 3D reconstructed chair scene</figcaption></figure><p id="3906" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在开发基于计算机视觉的系统或应用时，测量距离是一个常见的挑战。您可能想要测量检测到的对象的大小、场景中某些元素之间的距离，甚至是跟踪的对象移动的速度。</p><p id="ba61" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">解决这个问题的一个简单而常用的方法是选择一个大小已知的参考对象，然后通过它与该对象的关系计算场景中的任何距离。这是一个简单快捷的解决方案，你可以跟随<a class="ae kj" href="https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/" rel="noopener ugc nofollow" target="_blank">这篇</a> PyImageSearch教程来学习如何用OpenCV来做这件事。但是这种简单的方法有一个很大的缺点，那就是这种方法只适用于被测物体和它们的参照物在同一个视角、同一个平面和同摄像机的距离上的受限情况。如果参照物离你要测量的物体很远，引入的失真会导致错误的测量。这很直观，你不能用手指去测量埃菲尔铁塔。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kk"><img src="../Images/edd1d3675b01a41d07cdf7ab5d0a226d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*xXdKXfJu4OtC81ua9c6S8g.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Measuring iconic Montevideo’s Palacio Salvo by a unfortunated choice of reference object can led to a lot of distortion.</figcaption></figure><p id="a97b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在必须对固定场景进行多次测量的情况下，可以使用3D重建。从多个角度和位置扫描您的环境，并使用适当的软件，可以重建具有足够细节的3D重建，以非常精确地测量场景中任何点之间的距离。</p><p id="96e0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">三维重建是捕捉真实形状和尺寸的过程，在这种情况下，是从一组2D图像中捕捉的，这些图像取自普通的RGB手机摄像头。计算机视觉算法能够通过执行由两个主要步骤组成的流水线来构建解释图像的3D似是而非的几何图形:</p><ul class=""><li id="fe64" class="kl km hh jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated">来自运动的结构:用特征提取方法(SIFT/ ORB / KAZE)分析这组图像，并且这些特征用于匹配不同图像上的点。估计每个图像的相机参数、照片位置和方向，并且检测图像中可见的一组3D点。</li><li id="9c8e" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki kq kr ks kt bi translated">多视图立体:获取该位置和方向信息，并生成3D密集点云。</li></ul><p id="b039" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这篇文章解释了在没有任何图像处理知识的情况下从2D图像构建3D模型的过程。我们测试了现有的3D重建工具，以了解其当前的质量，并检查对象测量的准确性。要了解更多关于管道背后的理论以及每个过程是如何工作的，可以从阅读<a class="ae kj" href="https://alicevision.org/#photogrammetry/" rel="noopener ugc nofollow" target="_blank">爱丽丝视觉网站</a>开始，它做了很好的总结，并链接了关于每个步骤的文献。图像处理很难理解，但幸运的是，合适的软件已经开发并发布，3D重建的整个过程不再需要复杂的代码，而只需要点击按钮。</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="faf4" class="lg lh hh bd li lj lk ll lm ln lo lp lq in lr io ls iq lt ir lu it lv iu lw lx bi translated">动手操作</h1><p id="d67e" class="pw-post-body-paragraph jn jo hh jp b jq ly ii js jt lz il jv jw ma jy jz ka mb kc kd ke mc kg kh ki ha bi translated">有像Meshroom和COLMAP这样的3D场景重建开源选项，也有像Photomodeler和RealityCapture这样的付费选项。Meshroom之所以被选来发表这篇文章，是因为它是开源的，有一个直观的界面，它足够快，不需要修改就可以得到一个好的初始结果，而不需要实际的尺寸测量。</p><p id="23c4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">因为场景本身是无量纲的，所以用真实测量值重建3D场景需要一些额外的步骤。这是由工作空间缩放设置的。获得绝对精确缩放的方法是在我们的场景照片中有已知距离的目标标记，并缩放3D模型，直到它与这些距离匹配。缩放过程可以在Meshroom上完成，也可以使用外部软件，如Blender。</p><h1 id="31b4" class="lg lh hh bd li lj md ll lm ln me lp lq in mf io ls iq mg ir lu it mh iu lw lx bi translated">设置场景</h1><p id="585a" class="pw-post-body-paragraph jn jo hh jp b jq ly ii js jt lz il jv jw ma jy jz ka mb kc kd ke mc kg kh ki ha bi translated">在开始从场景中拍照之前，有一些注意事项需要考虑:</p><p id="0c9d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于amera:</p><ol class=""><li id="26fe" class="kl km hh jp b jq jr jt ju jw kn ka ko ke kp ki mi kr ks kt bi translated">分辨率高，越高越好。</li><li id="55be" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki mi kr ks kt bi translated">将白平衡设定为固定值，不要使用自动白平衡。</li><li id="6129" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki mi kr ks kt bi translated">大镜头光圈，你希望整个场景都在焦点上，以提高特征匹配。</li><li id="1db0" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki mi kr ks kt bi translated">低ISO消除噪音。</li><li id="cf6a" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki mi kr ks kt bi translated">快速快门速度，以避免运动模糊。</li></ol><p id="548f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于场景:</p><ol class=""><li id="d5eb" class="kl km hh jp b jq jr jt ju jw kn ka ko ke kp ki mi kr ks kt bi translated">漫射照明:你不希望你的场景被其中的物体投射出很大的阴影。自然光照通常效果很好。</li><li id="7c16" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki mi kr ks kt bi translated">移动空间:你将在场景中四处走动，从尽可能多的角度和距离获取图像，所以要确保有足够的空间来这样做。</li><li id="7d54" class="kl km hh jp b jq ku jt kv jw kw ka kx ke ky ki mi kr ks kt bi translated">CCTAG3标记:缩放过程中最重要的部分是为目标标记使用正确的大小、位置和模式。更多信息请参见CCTAG3标记部分。</li></ol><p id="19d2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">CCTAG代表同心圆目标。顾名思义，它由不同半径的同心圆组成的目标。这些圆圈形成一个由三个黑色圆环组成的图像，圆环的大小模式将决定标记的ID。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/e2acb4723df4f8f675387d33d333b293.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*Tyg4DcW4eL7NduC3ALG84w.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">CCTAG3</figcaption></figure><p id="0cdf" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">Alice Vision提供了一个带有代码的<a class="ae kj" href="https://github.com/alicevision/CCTag" rel="noopener ugc nofollow" target="_blank"> repo </a>来生成您自己的标记以及一些预制的样本(关于如何生成标记的更多信息可以在<a class="ae kj" href="https://cctag.readthedocs.io/en/latest/markers/markers.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到)。这是相关的，因为您希望标记足够大，能够被相机正确捕捉，而不会占据如此大的表面部分。标记应该打印出来并放置在场景中的平面上。</p><p id="53cb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">至于标记的实际放置，它们应该以场景包含在其中的方式排列。最后，了解放置在场景中的标记的正确ID及其位置非常重要(标记生成脚本提供了在标记中心打印ID和十字准线的选项)。在这种情况下，我将它们放在边长为1米的正方形中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mk"><img src="../Images/0a78d530b527aa0c1123479b39f80564.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*LY_y0DiUi7zPYFwCIKG4BQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">The scene and its measurements</figcaption></figure><p id="0939" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">一旦相机和场景设置完成，是时候捕捉我们的图像了！在这个过程中，建议在场景中走动，从不同的角度拍摄照片，以获得尽可能多的细节。没有一个推荐的照片数量，因为这取决于场景，但如果你的照片少于40张，你可能不会得到一个很好的结果。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/f788e8976e4e4d31272cf1e05afdc706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*IaqgdYv1ZfQAcxaYlhnoRQ.gif"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Images we took from the scene</figcaption></figure><p id="7b00" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">拍摄完照片后，在不破坏文件元数据的情况下将文件移动到电脑是非常重要的。Meshroom使用图片的元数据来获取有关相机的重要信息(如焦距)，这对正确的输出至关重要。</p><h1 id="f5be" class="lg lh hh bd li lj md ll lm ln me lp lq in mf io ls iq mg ir lu it mh iu lw lx bi translated">从网络空间开始</h1><p id="886b" class="pw-post-body-paragraph jn jo hh jp b jq ly ii js jt lz il jv jw ma jy jz ka mb kc kd ke mc kg kh ki ha bi translated">当启动程序时，您将会看到以下界面:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/30a60c8bfc2bca7305026e9b6bd20ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9ZyTfKCtHYAP7XE5"/></div></div></figure><p id="8afd" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在界面的左侧是放置场景照片的地方，在底部是一系列由白线连接的矩形，代表3D重建的管道。导入图像后，它看起来会像这样:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/ae6e32ff37d674c7e9bd9490ccdc83b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cdQegnouxA30X8Kp"/></div></div></figure><p id="da74" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">注意到每个微缩图像左上角的绿色圆圈了吗？这意味着图像的元数据足以从相机(在这种情况下是iPhone XS)获得重建所需的所有信息。根据相机和它的元数据，圆圈的颜色也可以是黄色(可能还不错)或红色(不好，会有误差。在这种情况下，你应该尝试其他相机或使用<a class="ae kj" href="http://analogexif.sourceforge.net/help/" rel="noopener ugc nofollow" target="_blank"> AnalogExif </a>来编辑照片的元数据)</p><p id="e1da" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">添加照片并保存项目后，您应该能够通过单击绿色的“开始”按钮运行3D重建管道，并获得一个良好的3D模型，该模型不会有现实生活中的措施。我建议这样做，并在继续改变管道之前确保它能够工作。如果出现错误，您可以使用<a class="ae kj" href="https://github.com/alicevision/dataset_monstree/tree/master/full" rel="noopener ugc nofollow" target="_blank">官方样本数据集</a>，并且您需要知道问题是在图像中还是在其他地方。</p><h1 id="a7c7" class="lg lh hh bd li lj md ll lm ln me lp lq in mf io ls iq mg ir lu it mh iu lw lx bi translated">变大</h1><p id="fe7b" class="pw-post-body-paragraph jn jo hh jp b jq ly ii js jt lz il jv jw ma jy jz ka mb kc kd ke mc kg kh ki ha bi translated">默认的图像处理管道输出可能没有真实大小，但它肯定与真实场景具有相同的距离关系。这意味着我们需要做的就是对模型进行比例变换，以匹配一组已知的距离。这是通过检测图像中的CCTAGs，将“SfMTransform”节点添加到管道中，并手动设置该节点中每个标记的位置来实现的。</p><p id="7717" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">要检测CCTAG3标记，我们需要修改“FeatureExtracion”、“FeatureMatching”和“StructureFromMotion”节点中的“Descryber Types”字段，方法是选择“cctag3”和默认的“sift ”,如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mo"><img src="../Images/c46e9ae51f11dce5193a503b68f962f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/0*jkjW8DQ717GxDxyS"/></div></figure><p id="f73d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">此外，添加“akaze”描述符以及“sift”和“cctag3”可以改善3D重建。</p><p id="f5dc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">既然CCTAG标记检测是管道的一部分，我们需要添加一个节点，该节点将使用该信息来应用转换，该转换将使我们的模型达到真实大小。这是通过添加名为“SfMTransform”的节点来完成的(要添加一个节点，右键单击空白区域并写下其名称)，方法如下:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/b2f18576f43a77d39ccfdaa0416bb902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ylrVJRPXMhzPphZ-"/></div></div></figure><p id="14a2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在只需要修改“SfMTransform”节点，使其看起来像这样:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/b6ae2103aaacb54509bc663df19fb114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7UJWv0-vK5AfJfMf"/></div></div></figure><p id="045d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在一切都准备好了，只需要点击绿色的“开始”按钮，这个过程就开始了。</p><h1 id="5ee1" class="lg lh hh bd li lj md ll lm ln me lp lq in mf io ls iq mg ir lu it mh iu lw lx bi translated">验证3D模型</h1><p id="22f4" class="pw-post-body-paragraph jn jo hh jp b jq ly ii js jt lz il jv jw ma jy jz ka mb kc kd ke mc kg kh ki ha bi translated">完成管道的所有节点后，您可以通过双击“纹理”节点在Meshroom中浏览带有纹理的模型:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mr"><img src="../Images/65bf331f4966b81c304c93a49960b14b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*T3NephCWAfbkSqEW"/></div></figure><p id="88d8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果这个阶段的结果不够好，你可以在“特征提取”节点中增加“描述符质量”和“描述符密度”。如果仍然不够好，添加更多/更好的照片可能会有所帮助。</p><p id="d618" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这种特殊情况下，可以看到椅子的腿不能重建，这是因为材料的油漆涂层的无模式特性以及腿的复杂几何形状。表面缺乏特色，这也是为什么地板、椅背和椅座可以重建得很体面，但周围的白墙却不行的原因。</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="e9b1" class="lg lh hh bd li lj lk ll lm ln lo lp lq in lr io ls iq lt ir lu it lv iu lw lx bi translated">在3D场景中测量</h1><p id="d417" class="pw-post-body-paragraph jn jo hh jp b jq ly ii js jt lz il jv jw ma jy jz ka mb kc kd ke mc kg kh ki ha bi translated">现在，对于最后一部分，我们需要验证的措施是正确的，为此我们将打开我们的OBJ模型(可以在项目的保存目录中找到“纹理”文件夹)在Blender中，并使用测量工具:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/3952ffcd0faab2d669eae9bbbfc859b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1qaz8uc-dHEEbpvZEL2bA.png"/></div></div></figure><p id="3b5b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">根据Blender的测量，椅子的靠背高26.5厘米，座位宽43.9厘米。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/c07e8b7537f81491e067bc69bd8280ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yZROWEf1YxO9AOO5"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/62195c14950366577d48d65b700cca7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VP_C6tiYe-0k8QCN"/></div></div></figure><p id="dec2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">实际尺寸分别为27厘米和45厘米。这是相当准确的！</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><p id="5e92" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">基于SfM结果，我们可以使用“摄像机定位”节点执行摄像机定位并检索3D重建场景中动画摄像机的运动。这对于在其他软件中作为纹理清理管道的一部分进行纹理重投影非常有用。也可用于利用Meshroom作为3D摄像机跟踪器。</p><p id="7d79" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果我想找到一个不属于原始场景的物体的位置，该怎么办？已知相机在3D场景中的位置和方向及其固有参数，3D世界坐标可以与该相机拍摄的图像的每个像素相关联。通过设置一些约束，如对象大小(与场景相比较小)和位置(对象停留在表面上，而不是漂浮在场景中间)，可以利用现代2D对象检测管道来实现3D真实世界比例的对象检测系统。通过这样做，像检测汽车和测量它们之间的距离甚至速度这样的应用程序就可以开发出来。</p><p id="24ea" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">三维重建能有多精确？</strong>我们想看看这种技术能恢复多少细节。我们从一个小物体上拍摄了70张照片，结果令人印象深刻。表面上的每个细节都在3D模型上被正确地重建，证明了3D数字化的真正敌人是像墙壁一样颜色一致的平面，而不是充满细节的小毛利雕刻图腾。</p><p id="0541" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">你可以在</strong><a class="ae kj" href="https://totem.eidos.ai" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi">totem . eidos . ai</strong></a><strong class="jp hi">查看生成的3D模型。</strong>我们将它加载到Three.js上，以便您可以在浏览器上移动它，欣赏细节捕捉。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/290a7867994412b75ef7181557231ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kgd4SCT4jbr2wm1yLtpZWA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Real Vs Digitalized Totem. Check it out at <a class="ae kj" href="https://totem.eidos.ai" rel="noopener ugc nofollow" target="_blank">totem.eidos.ai</a> !</figcaption></figure></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/f74fa655386684c493edfac38a8ba396.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*Wi-65WVz7YnWSLnM8s52JA.png"/></div></figure><p id="09ce" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">我们是eidos.ai，这是一个与创业公司和前瞻性公司合作的人工智能开发实验室。</strong></p><p id="aef7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">更多了解我们的服务请访问</strong><a class="ae kj" href="https://eidos.ai/" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi">https://eidos . ai</strong></a></p><div class="mu mv ez fb mw mx"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="my ab dw"><div class="mz ab na cl cj nb"><h2 class="bd hi fi z dy nc ea eb nd ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ne l"><h3 class="bd b fi z dy nc ea eb nd ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nf l"><p class="bd b fp z dy nc ea eb nd ed ef dx translated">medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl jh mx"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Paper Summary [Rethinking Segmentation from a Sequence-to-Sequence Perspective with Transfromers]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文摘要[从序列到序列的角度用转换子重新思考分段]</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/paper-summary-rethinking-segmentation-from-a-sequence-to-sequence-perspective-with-transfromers-26868efacc52?source=collection_archive---------2-----------------------#2022-01-03">https://medium.com/mlearning-ai/paper-summary-rethinking-segmentation-from-a-sequence-to-sequence-perspective-with-transfromers-26868efacc52?source=collection_archive---------2-----------------------#2022-01-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="ad86" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated"><strong class="ik hi">请注意，这篇帖子是为了我将来可能的研究在没有完全阅读</strong> <a class="ae jg" href="https://arxiv.org/pdf/2012.15840" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi">论文</strong> </a> <strong class="ik hi">的情况下，回看和复习关于这个题目的材料。</strong></p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/0e8633fa8f04923eb3ee9eed076a738b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFzjaNEV9ZlCnrCkB4FNLg.png"/></div></div></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es jt"><img src="../Images/e07cf4e2a0be785c0abaa05f609c52b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*r2Qya9dt1QYuo7imY7WrLA.png"/></div></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es ju"><img src="../Images/cdbbc7cb6f56b4194b9b7d6b6afb98ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*QSmO1ju-aNXIhaaKkWSH9w.png"/></div></figure><p id="d50c" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">大多数分段方法采用全卷积网络(FCN)。编码器降低空间分辨率，并学习具有更大感受域的更抽象/语义的视觉概念。由于上下文建模对分割至关重要，增加感受野成为关注的核心。然而，架构保持不变(基于编码器-解码器的FCN)。</p><p id="2af4" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">作者试图通过将语义分割视为一种顺序预测来实现本文中的替代。开发了纯变换器(没有卷积或分辨率降低)来将图像编码为一系列片。由于在所有层中建模的全局上下文，该编码器可以与简单的解码器混合以提供分段转换器(SETR)。最终，这个模型在几个流行的数据集上运行(<a class="ae jg" href="https://groups.csail.mit.edu/vision/datasets/ADE20K/" rel="noopener ugc nofollow" target="_blank"> ADE20K </a>、<a class="ae jg" href="https://www.cs.stanford.edu/~roozbeh/pascal-context/" rel="noopener ugc nofollow" target="_blank"> Pascal Context </a>和<a class="ae jg" href="https://www.cityscapes-dataset.com/" rel="noopener ugc nofollow" target="_blank"> Cityscapes </a>)。</p><h1 id="8f81" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">介绍</h1><p id="62cc" class="pw-post-body-paragraph ih ii hh ik b il kw in io ip kx ir is jv ky iv iw jw kz iz ja jx la jd je jf ha bi translated">标准FCN分割模型具有编码器-解码器架构:</p><ul class=""><li id="c497" class="lb lc hh ik b il im ip iq jv ld jw le jx lf jf lg lh li lj bi translated"><em class="ij">编码器</em>:用于特征表示学习</li><li id="8191" class="lb lc hh ik b il lk ip ll jv lm jw ln jx lo jf lg lh li lj bi translated"><em class="ij">解码器</em>:对编码器产生的特征表示进行像素级分类</li></ul><p id="255c" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">编码器在这两者(编码器/解码器)中起着最关键的作用。编码器(如CNN)是为图像理解而设计的。由于计算成本，我们降低了特征图的分辨率；因此，随着感受域的不断缩小，编码器可以学习更多的抽象/语义视觉概念。这有两个好处:1。翻译等值和局部性。</p><p id="489c" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">一些问题限制了模型预测长期相关性的性能，而这是至关重要的。有一些努力来解决这个问题，例如改变卷积(扩展内核大小、atrous卷积和图像/特征金字塔)的操作，或者将注意力模块集成到FCN架构中。标准编码器-解码器FCN模型的体系结构不会因采用前面提到的每一种/两种方法而改变。因此，研究人员决定消除卷积的基础来解决这个问题，并开发了单独注意力模型(你可以看到我以前的两篇文章，题为'<a class="ae jg" rel="noopener" href="/mlearning-ai/paper-summary-axial-deeplab-stand-alone-axial-attention-for-panoptic-segmentation-bae2d8f35015">Axial-deep lab:Stand-Alone Axial-Attention for panopic Segmentation '，</a>，<a class="ae jg" rel="noopener" href="/mlearning-ai/paper-summary-attention-augmented-convolutional-network-ca6e8ee50469">注意力增强卷积网络</a>和'<a class="ae jg" href="https://rezayazdanfar.medium.com/non-local-neural-network-f8b3f9b888e" rel="noopener">非局部神经网络</a>)然而，FCN模型的本质并没有改变。</p><p id="a986" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">本文的三个贡献可以总结如下:</p><ol class=""><li id="7131" class="lb lc hh ik b il im ip iq jv ld jw le jx lf jf lp lh li lj bi translated">改造图像语义分割问题</li><li id="78fa" class="lb lc hh ik b il lk ip ll jv lm jw ln jx lo jf lp lh li lj bi translated">利用转换器框架</li><li id="4cdb" class="lb lc hh ik b il lk ip ll jv lm jw ln jx lo jf lp lh li lj bi translated">介绍三种不同的解码器设计</li></ol><h1 id="2c10" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">方法</h1><h2 id="af9b" class="lq jz hh bd ka lr ls lt ke lu lv lw ki jv lx ly km jw lz ma kq jx mb mc ku md bi translated">1.基于FCN的语义分割</h2><p id="fd29" class="pw-post-body-paragraph ih ii hh ik b il kw in io ip kx ir is jv ky iv iw jw kz iz ja jx la jd je jf ha bi translated">FCN编码器包括一叠卷积层。输入层捕获输入图像。此外，张量在随后层中的位置是基于先前层的张量位置计算的，这些层是连接的(定义为感受野)。其他一些研究人员已经表明，FCN和注意力的结合可以表现得很好。因此，这些模型将注意力学习限制在具有较小输入大小的较高层，因为其二次复杂度与特征张量的像素数量有关。在这项研究中，SETR(分段变压器)作为一个纯粹的自我关注为基础的编码器已经开发出来，以打击这种限制。</p><h2 id="2dd0" class="lq jz hh bd ka lr ls lt ke lu lv lw ki jv lx ly km jw lz ma kq jx mb mc ku md bi translated">分段变压器(SETR)</h2><p id="4f9b" class="pw-post-body-paragraph ih ii hh ik b il kw in io ip kx ir is jv ky iv iw jw kz iz ja jx la jd je jf ha bi translated">输入-输出结构与1D序列之间的NLP相同(因此，在2D图像和1D序列之间存在不匹配)。因此，我们必须使图像序列采用SETR，这可以通过将图像像素值展平成1D向量来实现。SETR可以如下图所示:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es ju"><img src="../Images/a8ec79d96cd094876e1982ff79e251a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*Yjkvqdox5GiJHaWrKewCCA.png"/></div><figcaption class="me mf et er es mg mh bd b be z dx"><strong class="bd ka">Schematic illustration of the proposed SEgmentation TRansformer (SETR);</strong> Authors first split an image into fixed-size patches, linearly embed each of them, plus position embeddings, and fee the resulting sequence of vectors to a standard Transformer encoder.</figcaption></figure><p id="f240" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">通过给定1D嵌入序列E(输入)，使用纯变换器。换句话说，每一层都有一个全局感受野(解决了FCN编码器的限制)。</p><h2 id="0645" class="lq jz hh bd ka lr ls lt ke lu lv lw ki jv lx ly km jw lz ma kq jx mb mc ku md bi translated">解码器设计</h2><p id="f164" class="pw-post-body-paragraph ih ii hh ik b il kw in io ip kx ir is jv ky iv iw jw kz iz ja jx la jd je jf ha bi translated">以下解码器的主要目的是在原始2D图像空间(HxW)中产生分割结果。</p><ul class=""><li id="fdb0" class="lb lc hh ik b il im ip iq jv ld jw le jx lf jf lg lh li lj bi translated">朴素上采样(朴素)</li><li id="53f5" class="lb lc hh ik b il lk ip ll jv lm jw ln jx lo jf lg lh li lj bi translated">渐进式上采样(PUP)</li><li id="a924" class="lb lc hh ik b il lk ip ll jv lm jw ln jx lo jf lg lh li lj bi translated">多级特征聚合</li></ul><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mi"><img src="../Images/4a91c59cedcf378f11d52c7efc7bf8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*-IKWnXXXbIuORFCVBiGiTA.png"/></div></figure><p id="b43b" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">主要特点是采用了简单的二层网络，其架构是1×1 conv+同步批量标准(w/ReLU)+1×1 conv。作者将这种解码器命名为“SETR天真”。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mj"><img src="../Images/338b8e2fcb43bea870285991721496d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*yqvFkj0VQjSxRB1rY4tjDQ.png"/></div></figure><p id="260a" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">该解码器替代卷积层和上采样操作。作者将这种解码器命名为“SETR-PUP ”,如下所示:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mk"><img src="../Images/2dab098555a7151897f83b267841eb24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QdnTS1JJ_7m1ge0QFuo3Cg.png"/></div></div><figcaption class="me mf et er es mg mh bd b be z dx"><strong class="bd ka">Progressive upsampling</strong></figcaption></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es ml"><img src="../Images/901938666fa4c9e88995a72299fa7e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*uVCZzQn4VzCcN1fPdCjcRw.png"/></div></figure><p id="0a85" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">这种解码器的特点是多级特征聚合。由于每个模型图层的要素表示共享相同的分辨率，而没有金字塔形状，因此它完全不同，如下图所示:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mm"><img src="../Images/3545d14dc05b79d72289a030fe1bcfd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nfh8O4KlLtUo3ljqkcQEg.png"/></div></div><figcaption class="me mf et er es mg mh bd b be z dx"><strong class="bd ka">Multi-level feature aggregation (a variant known as SETR-MLA)</strong></figcaption></figure><blockquote class="ie if ig"><p id="e0d9" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated"><strong class="ik hi">请注意，本文中没有提到“实验”这一节。本节提供了所提出的模型在各种数据集上的几次尝试。</strong></p></blockquote><h1 id="dff8" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结论:</h1><p id="f923" class="pw-post-body-paragraph ih ii hh ik b il kw in io ip kx ir is jv ky iv iw jw kz iz ja jx la jd je jf ha bi translated">总之，作者表示，他们改变了建筑的层次，以完全消除对FCN的依赖，解决有限感受野的挑战。然后，在几个数据集(<a class="ae jg" href="https://groups.csail.mit.edu/vision/datasets/ADE20K/" rel="noopener ugc nofollow" target="_blank"> ADE20 </a>、<a class="ae jg" href="https://www.cs.stanford.edu/~roozbeh/pascal-context/" rel="noopener ugc nofollow" target="_blank"> Pascal Context </a>和<a class="ae jg" href="https://www.cityscapes-dataset.com/" rel="noopener ugc nofollow" target="_blank"> Cityscapes </a>)上使用现代提出的模型，并取得了令人喜爱的结果(尤其是在ADE20K上)。</p><blockquote class="ie if ig"><p id="d00e" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">如果发现任何错误，请发电子邮件到rezayazdanfar1111@gmail.com找我。同时，在我的Twitter <a class="ae jg" href="https://twitter.com/reza__yazdanfar" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，在这里访问我的LinkedIn <a class="ae jg" href="https://www.linkedin.com/in/reza-yazdanfar-b69055156/" rel="noopener ugc nofollow" target="_blank">。最后，如果你觉得它有用，并想继续写文章，请在</a><a class="ae jg" href="https://rezayazdanfar.medium.com/" rel="noopener">媒体中关注我。</a>最后，如果你有任何想法或建议，我很乐意接受，你只需要在LinkedIn上给我发消息。🙂</p></blockquote><p id="b1c9" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jv iu iv iw jw iy iz ja jx jc jd je jf ha bi translated">参考:</p><ol class=""><li id="76b7" class="lb lc hh ik b il im ip iq jv ld jw le jx lf jf lp lh li lj bi translated">郑，s .等人<em class="ij">用变形金刚从序列到序列的角度重新思考语义分割</em>。在<em class="ij">IEEE/CVF计算机视觉和模式识别会议论文集</em>中。2021.</li></ol><div class="mn mo ez fb mp mq"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hi fi z dy mv ea eb mw ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jr mq"/></div></div></a></div></div></div>    
</body>
</html>
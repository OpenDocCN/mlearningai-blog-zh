<html>
<head>
<title>Vision Transformers from Scratch (PyTorch): A step-by-step guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">è§†è§‰å˜å½¢é‡‘åˆšä»é›¶å¼€å§‹(PyTorch):ä¸€æ­¥ä¸€æ­¥çš„æŒ‡å—</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c?source=collection_archive---------0-----------------------#2022-02-03">https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c?source=collection_archive---------0-----------------------#2022-02-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d898" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è§†è§‰å˜å½¢é‡‘åˆš(ViT)ï¼Œè‡ªDosovitskiyç­‰äººæ¨å‡ºä»¥æ¥ã€‚è‰¾å°”ã€‚<a class="ae jc" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">å‚è€ƒæ–‡çŒ®</a>2020å¹´ï¼Œåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå æ®ä¸»å¯¼åœ°ä½ï¼Œé¦–å…ˆåœ¨å›¾åƒåˆ†ç±»æ–¹é¢è·å¾—æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œéšååœ¨å…¶ä»–ä»»åŠ¡ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p><p id="058e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶è€Œï¼Œä¸å…¶ä»–æ¶æ„ä¸åŒï¼Œå®ƒä»¬æœ‰ç‚¹éš¾ä»¥ç†è§£ï¼Œå°¤å…¶æ˜¯å¦‚æœæ‚¨è¿˜ä¸ç†Ÿæ‚‰è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä¸­ä½¿ç”¨çš„è½¬æ¢å™¨æ¨¡å‹çš„è¯ã€‚</p><p id="f28a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¦‚æœæ‚¨å¯¹è®¡ç®—æœºè§†è§‰(CV)æ„Ÿå…´è¶£ï¼Œä½†ä»ç„¶ä¸ç†Ÿæ‚‰ViTæ¨¡å‹ï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼æˆ‘ä¹Ÿæ˜¯ï¼</p><p id="59be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨è¿™æ®µç®€çŸ­çš„æ–‡å­—ä¸­ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºæˆ‘æ˜¯å¦‚ä½•ä»å¤´å¼€å§‹å®ç°æˆ‘çš„ç¬¬ä¸€ä¸ªViTçš„(ä½¿ç”¨PyTorch)ï¼Œå¹¶ä¸”æˆ‘å°†æŒ‡å¯¼æ‚¨å®Œæˆä¸€äº›è°ƒè¯•ï¼Œè¿™å°†å¸®åŠ©æ‚¨æ›´å¥½åœ°å¯è§†åŒ–ViTä¸­åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆã€‚</p><p id="ee46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è™½ç„¶è¿™ç¯‡æ–‡ç« æ˜¯ä¸“é—¨é’ˆå¯¹ViTçš„ï¼Œä½†æ˜¯ä½ åœ¨è¿™é‡Œä¼šå‘ç°ä¸€äº›æ¦‚å¿µï¼Œä¾‹å¦‚å¤šå¤´è‡ªæˆ‘æ³¨æ„(MSA)å—ï¼Œå®ƒä»¬åœ¨äººå·¥æ™ºèƒ½çš„å„ä¸ªå­é¢†åŸŸä¸­éƒ½å­˜åœ¨ï¼Œå¹¶ä¸”å½“å‰éå¸¸ç›¸å…³ï¼Œä¾‹å¦‚CVã€NLPç­‰</p><h1 id="d7cc" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">å®šä¹‰ä»»åŠ¡</h1><p id="51d2" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">å› ä¸ºç›®æ ‡åªæ˜¯å­¦ä¹ æ›´å¤šå…³äºViTæ¶æ„çš„çŸ¥è¯†ï¼Œæ‰€ä»¥æ˜æ™ºçš„åšæ³•æ˜¯é€‰æ‹©ä¸€ä¸ªç®€å•ä¸”ä¼—æ‰€å‘¨çŸ¥çš„ä»»åŠ¡å’Œæ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œä»»åŠ¡æ˜¯ç”±ä¼Ÿå¤§çš„<strong class="ig hi"> LeCunç­‰äººå¯¹æµè¡Œçš„MNISTæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚è‰¾å°”ã€‚</strong><a class="ae jc" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">å‚è€ƒ</a>ã€‚</p><p id="b0e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¦‚æœä½ è¿˜ä¸çŸ¥é“ï¼ŒMNISTæ˜¯ä¸€ä¸ªæ‰‹å†™æ•°å­—([0â€“9])çš„æ•°æ®é›†ï¼Œå…¨éƒ¨åŒ…å«åœ¨28x28äºŒè¿›åˆ¶åƒç´ å›¾åƒä¸­ã€‚è¿™ä¸ªä»»åŠ¡å¯¹äºä»Šå¤©çš„ç®—æ³•æ¥è¯´æ˜¯å¾®ä¸è¶³é“çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é¢„æœŸä¸€ä¸ªæ­£ç¡®çš„å®ç°å°†ä¼šæ‰§è¡Œå¾—å¾ˆå¥½ã€‚</p><p id="f4c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®©æˆ‘ä»¬ä»è¿›å£å¼€å§‹:</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="b2f3" class="kp je hh kl b be kq kr l ks kt">import numpy as np<br/><br/>from tqdm import tqdm, trange<br/><br/>import torch<br/>import torch.nn as nn<br/>from torch.optim import Adam<br/>from torch.nn import CrossEntropyLoss<br/>from torch.utils.data import DataLoader<br/><br/>from torchvision.transforms import ToTensor<br/>from torchvision.datasets.mnist import MNIST<br/><br/>np.random.seed(0)<br/>torch.manual_seed(0)</span></pre><p id="273d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª<strong class="ig hi">ä¸»å‡½æ•°</strong>ï¼Œå®ƒå‡†å¤‡MNISTæ•°æ®é›†ï¼Œå®ä¾‹åŒ–ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶ä¸ºå…¶è®­ç»ƒ5ä¸ªæ—¶æœŸã€‚ä¹‹åï¼Œåœ¨æµ‹è¯•é›†ä¸Šæµ‹é‡æŸè€—å’Œç²¾åº¦ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="4303" class="kp je hh kl b be kq kr l ks kt">def main():<br/>    # Loading data<br/>    transform = ToTensor()<br/><br/>    train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)<br/>    test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)<br/><br/>    train_loader = DataLoader(train_set, shuffle=True, batch_size=128)<br/>    test_loader = DataLoader(test_set, shuffle=False, batch_size=128)<br/><br/>    # Defining model and training options<br/>    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")<br/>    print("Using device: ", device, f"({torch.cuda.get_device_name(device)})" if torch.cuda.is_available() else "")<br/>    model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)<br/>    N_EPOCHS = 5<br/>    LR = 0.005<br/><br/>    # Training loop<br/>    optimizer = Adam(model.parameters(), lr=LR)<br/>    criterion = CrossEntropyLoss()<br/>    for epoch in trange(N_EPOCHS, desc="Training"):<br/>        train_loss = 0.0<br/>        for batch in tqdm(train_loader, desc=f"Epoch {epoch + 1} in training", leave=False):<br/>            x, y = batch<br/>            x, y = x.to(device), y.to(device)<br/>            y_hat = model(x)<br/>            loss = criterion(y_hat, y)<br/><br/>            train_loss += loss.detach().cpu().item() / len(train_loader)<br/><br/>            optimizer.zero_grad()<br/>            loss.backward()<br/>            optimizer.step()<br/><br/>        print(f"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}")<br/><br/>    # Test loop<br/>    with torch.no_grad():<br/>        correct, total = 0, 0<br/>        test_loss = 0.0<br/>        for batch in tqdm(test_loader, desc="Testing"):<br/>            x, y = batch<br/>            x, y = x.to(device), y.to(device)<br/>            y_hat = model(x)<br/>            loss = criterion(y_hat, y)<br/>            test_loss += loss.detach().cpu().item() / len(test_loader)<br/><br/>            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()<br/>            total += len(x)<br/>        print(f"Test loss: {test_loss:.2f}")<br/>        print(f"Test accuracy: {correct / total * 100:.2f}%")</span></pre><p id="2a2c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç°åœ¨æˆ‘ä»¬æœ‰äº†è¿™ä¸ªæ¨¡æ¿ï¼Œä»ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥åªå…³æ³¨æ¨¡å‹(ViT)ï¼Œå®ƒå¿…é¡»ç”¨å½¢çŠ¶(<strong class="ig hi"> N </strong> x 1 x 28 x 28)å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚</p><p id="0041" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®©æˆ‘ä»¬ä»å®šä¹‰ä¸€ä¸ªç©ºçš„<em class="ku"> nnå¼€å§‹ã€‚æ¨¡å—</em>ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†é€æ­¥å¡«å……è¿™ä¸ªç±»ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="b9b7" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>  def __init__(self):<br/>    # Super constructor<br/>    super(MyViT, self).__init__()<br/><br/>  def forward(self, images):<br/>    pass</span></pre><h1 id="0966" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">å‰è¿›ä¼ çƒ</h1><p id="2c22" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">ç”±äºPytorchå’Œå¤§å¤šæ•°DLæ¡†æ¶éƒ½æä¾›äº†<em class="ku">è‡ªåŠ¨ç­¾åçš„</em>è®¡ç®—ï¼Œæˆ‘ä»¬åªå…³å¿ƒå®ç°ViTæ¨¡å‹çš„å‘å‰ä¼ é€’ã€‚å› ä¸ºæˆ‘ä»¬å·²ç»å®šä¹‰äº†æ¨¡å‹çš„ä¼˜åŒ–å™¨ï¼Œæ‰€ä»¥æ¡†æ¶å°†è´Ÿè´£åå‘ä¼ æ’­æ¢¯åº¦å’Œè®­ç»ƒæ¨¡å‹çš„å‚æ•°ã€‚</p><p id="6121" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å½“å®ç°ä¸€ä¸ªæ–°çš„æ¨¡å‹æ—¶ï¼Œæˆ‘å–œæ¬¢åœ¨æŸä¸ªæ ‡ç­¾ä¸Šä¿å­˜ä¸€ä¸ªæ¶æ„çš„å›¾ç‰‡ã€‚è¿™æ˜¯æˆ‘ä»¬ä»<strong class="ig hi"> Bazi etå¾—åˆ°çš„ViTçš„å‚è€ƒå›¾ç‰‡ã€‚é“</strong> (2021)[ <a class="ae jc" href="https://www.researchgate.net/publication/348947034_Vision_Transformers_for_Remote_Sensing_Image_Classification" rel="noopener ugc nofollow" target="_blank">å‚è€ƒ</a>:</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kv"><img src="../Images/3f9f0e3248e7dd9154e0f4b4ee5a8827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tA7xE2dQA_dfzA0Bub5TVw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">The architecture of the ViT with specific details on the transformer encoder and the MSA block. Keep this picture in mind. Picture from <a class="ae jc" href="https://www.researchgate.net/publication/348947034_Vision_Transformers_for_Remote_Sensing_Image_Classification" rel="noopener ugc nofollow" target="_blank">Bazi et. al.</a></figcaption></figure><p id="bb9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">é€šè¿‡è¯¥å›¾ï¼Œæˆ‘ä»¬çœ‹åˆ°è¾“å…¥å›¾åƒ(a)è¢«â€œåˆ‡å‰²â€æˆå¤§å°ç›¸ç­‰çš„å­å›¾åƒã€‚</p><p id="c2cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ¯ä¸ªè¿™æ ·çš„å­å›¾åƒç»å†çº¿æ€§åµŒå…¥ã€‚ä»é‚£æ—¶èµ·ï¼Œæ¯ä¸ªå­å›¾åƒåªæ˜¯ä¸€ä¸ªä¸€ç»´å‘é‡ã€‚</p><p id="63a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶åå°†ä½ç½®åµŒå…¥æ·»åŠ åˆ°è¿™äº›å‘é‡(è®°å·)ä¸­ã€‚ä½ç½®åµŒå…¥å…è®¸ç½‘ç»œçŸ¥é“æ¯ä¸ªå­å›¾åƒæœ€åˆåœ¨å›¾åƒä¸­çš„ä½ç½®ã€‚æ²¡æœ‰è¿™äº›ä¿¡æ¯ï¼Œç½‘ç»œå°†æ— æ³•çŸ¥é“æ¯ä¸ªè¿™æ ·çš„å›¾åƒå°†è¢«æ”¾ç½®åœ¨å“ªé‡Œï¼Œä»è€Œå¯¼è‡´æ½œåœ¨çš„é”™è¯¯é¢„æµ‹ï¼</p><p id="f80b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶åï¼Œè¿™äº›ä»¤ç‰Œä¸ç‰¹æ®Šçš„åˆ†ç±»ä»¤ç‰Œä¸€èµ·è¢«ä¼ é€’åˆ°å˜æ¢å™¨ç¼–ç å™¨å—ï¼Œæ¯ä¸ªç¼–ç å™¨å—åŒ…æ‹¬:å±‚æ ‡å‡†åŒ–(LN ),éšåæ˜¯å¤šå¤´è‡ªå…³æ³¨(MSA)å’Œæ®‹å·®è¿æ¥ã€‚ç„¶åæ˜¯ç¬¬äºŒä¸ªLNï¼Œä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥å™¨(MLP)ï¼Œå†æ¬¡æ˜¯ä¸€ä¸ªå‰©ä½™è¿æ¥ã€‚è¿™äº›ç§¯æœ¨æ˜¯èƒŒé èƒŒè¿æ¥çš„ã€‚</p><p id="22ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æœ€åï¼Œåˆ†ç±»MLPå—ä»…ç”¨äºç‰¹æ®Šåˆ†ç±»æ ‡è®°ä¸Šçš„æœ€ç»ˆåˆ†ç±»ï¼Œè¯¥ç‰¹æ®Šåˆ†ç±»æ ‡è®°åœ¨è¯¥è¿‡ç¨‹ç»“æŸæ—¶å…·æœ‰å…³äºå›¾åƒçš„å…¨å±€ä¿¡æ¯ã€‚</p><p id="5760" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®©æˆ‘ä»¬æŒ‰ç…§<strong class="ig hi">çš„6ä¸ªä¸»è¦æ­¥éª¤æ¥æ„å»ºViTã€‚</strong></p><h2 id="39bd" class="lh je hh bd jf li lj lk jj ll lm ln jn ip lo lp jr it lq lr jv ix ls lt jz lu bi translated">æ­¥éª¤1:ä¿®è¡¥å’Œçº¿æ€§æ˜ å°„</h2><p id="be9e" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">transformerç¼–ç å™¨çš„å¼€å‘è€ƒè™‘åˆ°äº†åºåˆ—æ•°æ®ï¼Œä¾‹å¦‚è‹±è¯­å¥å­ã€‚ç„¶è€Œï¼Œå›¾åƒä¸æ˜¯åºåˆ—ã€‚å®ƒåªæ˜¯ï¼Œå—¯â€¦ä¸€ä¸ªå›¾åƒâ€¦é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•å¯¹ä¸€ä¸ªå›¾åƒâ€œæ’åºâ€ï¼Ÿæˆ‘ä»¬æŠŠå®ƒåˆ†è§£æˆå¤šä¸ªå­å›¾ï¼ŒæŠŠæ¯ä¸ªå­å›¾æ˜ å°„æˆä¸€ä¸ªå‘é‡ï¼</p><p id="b705" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬é€šè¿‡ç®€å•åœ°å°†å¤§å°ä¸º(Nï¼ŒCï¼ŒHï¼ŒW)(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ä¸º(Nï¼Œ1ï¼Œ28ï¼Œ28))çš„è¾“å…¥æ•´å½¢ä¸ºå¤§å°ä¸º(Nï¼Œ#é¢ç‰‡ï¼Œé¢ç‰‡ç»´æ•°)çš„è¾“å…¥æ¥å®ç°ï¼Œå…¶ä¸­é¢ç‰‡çš„ç»´æ•°è¢«ç›¸åº”åœ°è°ƒæ•´ã€‚</p><p id="533b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†æ¯ä¸ª(1ï¼Œ28ï¼Œ28)åˆ†æˆ<strong class="ig hi"> 7x7ä¸ªå°å—</strong>(å› æ­¤ï¼Œæ¯ä¸ªå¤§å°ä¸º4x4)ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å°†ä»å•ä¸ªå›¾åƒä¸­è·å¾—7Ã—7 = 49ä¸ªå­å›¾åƒã€‚</p><p id="7e76" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å› æ­¤ï¼Œæˆ‘ä»¬å°†è¾“å…¥(Nï¼Œ1ï¼Œ28ï¼Œ28)æ•´å½¢ä¸º:</p><blockquote class="lv"><p id="c4cb" class="lw lx hh bd ly lz ma mb mc md me jb dx translated"><em class="mf"> (Nï¼ŒPxPï¼ŒHxC/P x WxC/P) = (Nï¼Œ7x7ï¼Œ4x4) = (Nï¼Œ49ï¼Œ16) </em></p></blockquote><p id="4a12" class="pw-post-body-paragraph ie if hh ig b ih mg ij ik il mh in io ip mi ir is it mj iv iw ix mk iz ja jb ha bi translated">è¯·æ³¨æ„ï¼Œè™½ç„¶æ¯ä¸ªå°å—éƒ½æ˜¯å¤§å°ä¸º1x4x4çš„å›¾ç‰‡ï¼Œä½†æˆ‘ä»¬å°†å…¶å±•å¹³ä¸º16ç»´å‘é‡ã€‚æ­¤å¤–ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªå•ä¸€çš„é¢œè‰²é€šé“ã€‚å¦‚æœæˆ‘ä»¬æœ‰å¤šä¸ªé¢œè‰²é€šé“ï¼Œè¿™äº›é€šé“ä¹Ÿä¼šè¢«å±•å¹³åˆ°çŸ¢é‡ä¸­ã€‚</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es ml"><img src="../Images/8e9405e6a9975e637f6e8f4bc9d56f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*CFbOxEuvo-Pgq7ETIrt0Eg.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Raffiguration of how an image is split into patches. The 1x28x28 image is split into 49 (7x7) patches, each of size 16 (4x4x1)</figcaption></figure><p id="9561" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ä¿®æ”¹æˆ‘ä»¬çš„<strong class="ig hi"> MyViT </strong>ç±»ï¼Œåªå®ç°ä¿®è¡¥ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä»å¤´å¼€å§‹æ“ä½œçš„æ–¹æ³•ã€‚è¯·æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ç§æ‰§è¡Œæ“ä½œçš„ä½æ•ˆæ–¹å¼ï¼Œä½†æ˜¯å¯¹äºå­¦ä¹ æ ¸å¿ƒæ¦‚å¿µæ¥è¯´ï¼Œä»£ç æ˜¯ç›´è§‚çš„ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="de84" class="kp je hh kl b be kq kr l ks kt">def patchify(images, n_patches):<br/>    n, c, h, w = images.shape<br/><br/>    assert h == w, "Patchify method is implemented for square images only"<br/><br/>    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)<br/>    patch_size = h // n_patches<br/><br/>    for idx, image in enumerate(images):<br/>        for i in range(n_patches):<br/>            for j in range(n_patches):<br/>                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]<br/>                patches[idx, i * n_patches + j] = patch.flatten()<br/>    return patches</span></pre><pre class="mm kk kl km bn kn ko bi"><span id="f964" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>  def __init__(self, chw=(1, 28, 28), n_patches=7):<br/>    # Super constructor<br/>    super(MyViT, self).__init__()<br/><br/>    # Attributes<br/>    self.chw = chw # (C, H, W)<br/>    self.n_patches = n_patches<br/><br/>    assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/><br/>  def forward(self, images):<br/>    patches = patchify(images, self.n_patches)<br/>    return patches</span></pre><p id="63bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç±»æ„é€ å‡½æ•°ç°åœ¨è®©ç±»çŸ¥é“æˆ‘ä»¬çš„è¾“å…¥å›¾åƒçš„å¤§å°(é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦)ã€‚æ³¨æ„ï¼Œåœ¨è¿™ä¸ªå®ç°ä¸­ï¼Œ<em class="ku"> n_patches </em>å˜é‡æ˜¯æˆ‘ä»¬å°†åœ¨å®½åº¦å’Œé«˜åº¦ä¸Šæ‰¾åˆ°çš„é¢ç‰‡æ•°(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯7ï¼Œå› ä¸ºæˆ‘ä»¬å°†å›¾åƒåˆ†æˆ7x7ä¸ªé¢ç‰‡)ã€‚</p><p id="b9ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªç®€å•çš„ä¸»ç¨‹åºæ¥æµ‹è¯•æˆ‘ä»¬çš„ç±»çš„åŠŸèƒ½:</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="3721" class="kp je hh kl b be kq kr l ks kt">if __name__ == '__main__':<br/>  # Current model<br/>  model = MyViT(<br/>    chw=(1, 28, 28),<br/>    n_patches=7<br/>  )<br/><br/>  x = torch.randn(7, 1, 28, 28) # Dummy images<br/>  print(model(x).shape) # torch.Size([7, 49, 16])</span></pre><p id="79ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç°åœ¨æˆ‘ä»¬æœ‰äº†å±•å¹³çš„é¢ç‰‡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡çº¿æ€§æ˜ å°„æ¥æ˜ å°„å®ƒä»¬ã€‚è™½ç„¶æ¯ä¸ªå°å—æ˜¯4Ã—4 = 16ç»´å‘é‡ï¼Œä½†æ˜¯çº¿æ€§æ˜ å°„å¯ä»¥æ˜ å°„åˆ°ä»»ä½•ä»»æ„å¤§å°çš„å‘é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç»™æˆ‘ä»¬çš„ç±»æ„é€ å‡½æ•°æ·»åŠ äº†ä¸€ä¸ªå‚æ•°ï¼Œç§°ä¸º<em class="ku"> hidden_d </em>è¡¨ç¤ºâ€œéšè—ç»´åº¦â€ã€‚</p><p id="4732" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨8ä¸ªéšè—ç»´åº¦ï¼Œä½†æ˜¯åŸåˆ™ä¸Šï¼Œä»»ä½•æ•°å­—éƒ½å¯ä»¥æ”¾åœ¨è¿™é‡Œã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†æŠŠæ¯ä¸ª16ç»´çš„é¢ç‰‡æ˜ å°„åˆ°ä¸€ä¸ª8ç»´çš„é¢ç‰‡ã€‚</p><p id="639c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ç®€å•åœ°åˆ›å»ºä¸€ä¸ª<em class="ku">ç¥ç»ç½‘ç»œã€‚çº¿æ€§</em>å±‚ï¼Œå¹¶åœ¨æˆ‘ä»¬çš„æ­£å‘å‡½æ•°ä¸­è°ƒç”¨å®ƒã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="1b0c" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>  def __init__(self, chw=(1, 28, 28), n_patches=7):<br/>    # Super constructor<br/>    super(MyViT, self).__init__()<br/><br/>    # Attributes<br/>    self.chw = chw # (C, H, W)<br/>    self.n_patches = n_patches<br/><br/>    assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)<br/><br/>    # 1) Linear mapper<br/>    self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])<br/>    self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)<br/><br/>  def forward(self, images):<br/>    patches = patchify(images, self.n_patches)<br/>    tokens = self.linear_mapper(patches)<br/>    return tokens</span></pre><p id="3ddd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¯·æ³¨æ„ï¼Œæˆ‘ä»¬é€šè¿‡(16ï¼Œ8)çº¿æ€§æ˜ å°„å™¨(æˆ–çŸ©é˜µ)è¿è¡Œ(Nï¼Œ49ï¼Œ16)å¼ é‡ã€‚çº¿æ€§è¿ç®—åªå‘ç”Ÿåœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šã€‚</p><h2 id="cb65" class="lh je hh bd jf li lj lk jj ll lm ln jn ip lo lp jr it lq lr jv ix ls lt jz lu bi translated">æ­¥éª¤2:æ·»åŠ åˆ†ç±»ä»¤ç‰Œ</h2><p id="1aa7" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">å¦‚æœæ‚¨ä»”ç»†è§‚å¯Ÿæ¶æ„å›¾ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°è¿˜æœ‰ä¸€ä¸ªâ€œ<em class="ku"> v_class </em>â€ä»¤ç‰Œè¢«ä¼ é€’ç»™äº†Transformerç¼–ç å™¨ã€‚è¿™æ˜¯ä»€ä¹ˆï¼Ÿ</p><p id="7915" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç®€å•åœ°è¯´ï¼Œè¿™æ˜¯æˆ‘ä»¬æ·»åŠ åˆ°æ¨¡å‹ä¸­çš„ä¸€ä¸ªç‰¹æ®Šä»¤ç‰Œï¼Œå®ƒçš„ä½œç”¨æ˜¯æ•è·å…³äºå…¶ä»–ä»¤ç‰Œçš„ä¿¡æ¯ã€‚è¿™å°†åœ¨MSAå—ä¸­å‘ç”Ÿ(ç¨å)ã€‚å½“å…³äºæ‰€æœ‰å…¶ä»–æ ‡è®°çš„ä¿¡æ¯å°†å‡ºç°åœ¨è¿™é‡Œæ—¶ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿä»…ä½¿ç”¨è¿™ä¸ªç‰¹æ®Šçš„æ ‡è®°æ¥å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚ç‰¹æ®Šä»¤ç‰Œçš„åˆå§‹å€¼(é¦ˆé€ç»™å˜æ¢å™¨ç¼–ç å™¨çš„é‚£ä¸ª)æ˜¯éœ€è¦å­¦ä¹ çš„æ¨¡å‹çš„å‚æ•°ã€‚</p><p id="4d93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™æ˜¯ä¸€ä¸ªå¾ˆé…·çš„å˜å½¢é‡‘åˆšæ¦‚å¿µï¼å¦‚æœæˆ‘ä»¬æƒ³åšå¦ä¸€ä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸ºå¦ä¸€ä¸ªä¸‹æ¸¸ä»»åŠ¡æ·»åŠ å¦ä¸€ä¸ªç‰¹æ®Šçš„ä»¤ç‰Œ(ä¾‹å¦‚ï¼Œå°†ä¸€ä¸ªæ•°å­—åˆ†ç±»ä¸ºé«˜äº5æˆ–ä½äº5)å’Œä¸€ä¸ªæ¥å—è¿™ä¸ªæ–°ä»¤ç‰Œä½œä¸ºè¾“å…¥çš„åˆ†ç±»å™¨ã€‚å¾ˆèªæ˜ï¼Œå¯¹å§ï¼Ÿ</p><p id="8d74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ç°åœ¨å¯ä»¥å‘æˆ‘ä»¬çš„æ¨¡å‹æ·»åŠ ä¸€ä¸ªå‚æ•°ï¼Œå¹¶å°†æˆ‘ä»¬çš„(Nï¼Œ49ï¼Œ8)ä»¤ç‰Œå¼ é‡è½¬æ¢ä¸º(Nï¼Œ50ï¼Œ8)å¼ é‡(æˆ‘ä»¬å‘æ¯ä¸ªåºåˆ—æ·»åŠ ç‰¹æ®Šä»¤ç‰Œ)ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="c91c" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>  def __init__(self, chw=(1, 28, 28), n_patches=7):<br/>    # Super constructor<br/>    super(MyViT, self).__init__()<br/><br/>    # Attributes<br/>    self.chw = chw # (C, H, W)<br/>    self.n_patches = n_patches<br/><br/>    assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)<br/><br/>    # 1) Linear mapper<br/>    self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])<br/>    self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)<br/><br/>    # 2) Learnable classifiation token<br/>    self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))<br/><br/>  def forward(self, images):<br/>    patches = patchify(images, self.n_patches)<br/>    tokens = self.linear_mapper(patches)<br/><br/>    # Adding classification token to the tokens<br/>    tokens = torch.stack([torch.vstack((self.class_token, tokens[i])) for i in range(len(tokens))])<br/>    return tokens</span></pre><p id="288e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¯·æ³¨æ„ï¼Œåˆ†ç±»æ ‡è®°ä½œä¸ºæ¯ä¸ªåºåˆ—çš„ç¬¬ä¸€ä¸ªæ ‡è®°ã€‚å½“æˆ‘ä»¬éšåæ£€ç´¢åˆ†ç±»ä»¤ç‰Œä»¥æä¾›ç»™æœ€ç»ˆçš„MLPæ—¶ï¼Œè®°ä½è¿™ä¸€ç‚¹å¾ˆé‡è¦ã€‚</p><h2 id="b8cd" class="lh je hh bd jf li lj lk jj ll lm ln jn ip lo lp jr it lq lr jv ix ls lt jz lu bi translated">æ­¥éª¤3:ä½ç½®ç¼–ç </h2><p id="430e" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œä½ç½®ç¼–ç å…è®¸æ¨¡å‹ç†è§£æ¯ä¸ªè¡¥ç‰‡åœ¨åŸå§‹å›¾åƒä¸­çš„ä½ç½®ã€‚è™½ç„¶ç†è®ºä¸Šæœ‰å¯èƒ½å­¦ä¹ è¿™æ ·çš„ä½ç½®åµŒå…¥ï¼Œä½†æ˜¯Vaswaniç­‰äººä»¥å‰çš„å·¥ä½œã€‚è‰¾å°”ã€‚ã€<a class="ae jc" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">å‚è€ƒæ–‡çŒ®</a>å»ºè®®æˆ‘ä»¬å¯ä»¥åªæŠŠæ­£å¼¦å’Œä½™å¼¦æ³¢ç›¸åŠ ã€‚</p><p id="5bff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å…·ä½“æ¥è¯´ï¼Œä½ç½®ç¼–ç å°†ä½é¢‘å€¼æ·»åŠ åˆ°ç¬¬ä¸€ç»´åº¦ï¼Œå°†é«˜é¢‘å€¼æ·»åŠ åˆ°åä¸€ç»´åº¦ã€‚</p><p id="11f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨æ¯ä¸ªåºåˆ—ä¸­ï¼Œå¯¹äºä»¤ç‰Œ<em class="ku"> i </em>,æˆ‘ä»¬å‘å…¶<em class="ku">ç¬¬jä¸ª</em>åæ ‡æ·»åŠ ä»¥ä¸‹å€¼:</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mn"><img src="../Images/ef81de628b5880f367482e1d7bdb2ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lpRYHE0XjVkxRVKFrWkzuw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Value to be added to the i-th tensor in its j-th coordinate. <a class="ae jc" href="https://blogs.oracle.com/ai-and-datascience/post/multi-head-self-attention-in-nlp" rel="noopener ugc nofollow" target="_blank">Image source</a>.</figcaption></figure><p id="3fd0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™ç§ä½ç½®åµŒå…¥æ˜¯åºåˆ—ä¸­å…ƒç´ æ•°é‡å’Œæ¯ä¸ªå…ƒç´ ç»´æ•°çš„å‡½æ•°ã€‚å› æ­¤ï¼Œå®ƒæ€»æ˜¯ä¸€ä¸ªäºŒç»´å¼ é‡æˆ–â€œçŸ©å½¢â€ã€‚</p><p id="adba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œåœ¨ç»™å®šè®°å·çš„æ•°é‡å’Œæ¯ä¸ªè®°å·çš„ç»´æ•°çš„æƒ…å†µä¸‹ï¼Œè¾“å‡ºä¸€ä¸ªçŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸ªåæ ‡(Iï¼Œj)æ˜¯è¦æ·»åŠ åˆ°ç»´åº¦jä¸­çš„è®°å·Içš„å€¼ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="9c7e" class="kp je hh kl b be kq kr l ks kt">def get_positional_embeddings(sequence_length, d):<br/>    result = torch.ones(sequence_length, d)<br/>    for i in range(sequence_length):<br/>        for j in range(d):<br/>            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))<br/>    return result<br/><br/>if __name__ == "__main__":<br/>  import matplotlib.pyplot as plt<br/><br/>  plt.imshow(get_positional_embeddings(100, 300), cmap="hot", interpolation="nearest")<br/>  plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es mo"><img src="../Images/8d109c34551aec340e5a852727793e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*erwsFgn3I-FGzUKOIeQSAw.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Heatmap of Positional embeddings for one hundred 300-dimensional samples. Samples are on the y-axis, whereas the dimensions are on the x-axis. Darker regions show higher values.</figcaption></figure><p id="1cd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»æˆ‘ä»¬ç»˜åˆ¶çš„çƒ­å›¾ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°æ‰€æœ‰çš„â€œæ°´å¹³çº¿â€éƒ½äº’ä¸ç›¸åŒï¼Œå› æ­¤å¯ä»¥åŒºåˆ†æ ·å“ã€‚</p><p id="e296" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨çº¿æ€§æ˜ å°„å’Œæ·»åŠ ç±»æ ‡è®°ä¹‹åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥å°†è¿™ç§ä½ç½®ç¼–ç æ·»åŠ åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="003a" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>  def __init__(self, chw=(1, 28, 28), n_patches=7):<br/>    # Super constructor<br/>    super(MyViT, self).__init__()<br/><br/>    # Attributes<br/>    self.chw = chw # (C, H, W)<br/>    self.n_patches = n_patches<br/><br/>    assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>    self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)<br/><br/>    # 1) Linear mapper<br/>    self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])<br/>    self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)<br/><br/>    # 2) Learnable classifiation token<br/>    self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))<br/><br/>    # 3) Positional embedding<br/>    self.pos_embed = nn.Parameter(torch.tensor(get_positional_embeddings(self.n_patches ** 2 + 1, self.hidden_d)))<br/>    self.pos_embed.requires_grad = False<br/><br/>  def forward(self, images):<br/>    patches = patchify(images, self.n_patches)<br/>    tokens = self.linear_mapper(patches)<br/><br/>    # Adding classification token to the tokens<br/>    tokens = torch.stack([torch.vstack((self.class_token, tokens[i])) for i in range(len(tokens))])<br/><br/>    # Adding positional embedding<br/>    pos_embed = self.pos_embed.repeat(n, 1, 1)<br/>    out = tokens + pos_embed<br/>    return out</span></pre><p id="fa88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å°†ä½ç½®åµŒå…¥å®šä¹‰ä¸ºæ¨¡å‹çš„ä¸€ä¸ªå‚æ•°(æˆ‘ä»¬ä¸ä¼šé€šè¿‡å°†å…¶requires_gradè®¾ç½®ä¸ºFalseæ¥æ›´æ–°å®ƒ)ã€‚æ³¨æ„ï¼Œåœ¨å‰å‘æ–¹æ³•ä¸­ï¼Œç”±äºè®°å·çš„å¤§å°ä¸º(Nï¼Œ50ï¼Œ8)ï¼Œæˆ‘ä»¬å¿…é¡»é‡å¤Næ¬¡(50ï¼Œ8)ä½ç½®ç¼–ç çŸ©é˜µã€‚</p><h2 id="4982" class="lh je hh bd jf li lj lk jj ll lm ln jn ip lo lp jr it lq lr jv ix ls lt jz lu bi translated">æ­¥éª¤4:ç¼–ç å™¨æ¨¡å—(ç¬¬1/2éƒ¨åˆ†)</h2><p id="a15b" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">è¿™å¯èƒ½æ˜¯æœ€éš¾çš„ä¸€æ­¥ã€‚ç¼–ç å™¨æ¨¡å—å°†æˆ‘ä»¬çš„å½“å‰å¼ é‡[Nï¼ŒSï¼ŒD]ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºç›¸åŒç»´æ•°çš„å¼ é‡ã€‚</p><p id="cb28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç¼–ç å™¨æ¨¡å—çš„ç¬¬ä¸€éƒ¨åˆ†å¯¹æˆ‘ä»¬çš„ä»¤ç‰Œåº”ç”¨å±‚æ ‡å‡†åŒ–ï¼Œç„¶åæ˜¯å¤šå¤´è‡ªæˆ‘å…³æ³¨ï¼Œæœ€åæ·»åŠ ä¸€ä¸ªæ®‹å·®è¿æ¥ã€‚</p><p id="1754" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">å›¾å±‚å½’ä¸€åŒ–</strong></p><p id="ec30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å›¾å±‚å½’ä¸€åŒ–æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„æ¨¡å—ï¼Œå®ƒåœ¨ç»™å®šä¸€ä¸ªè¾“å…¥çš„æƒ…å†µä¸‹ï¼Œå‡å»å…¶å¹³å‡å€¼ï¼Œç„¶åé™¤ä»¥æ ‡å‡†å·®ã€‚</p><p id="f917" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶è€Œï¼Œæˆ‘ä»¬é€šå¸¸å¯¹(Nï¼Œd)è¾“å…¥åº”ç”¨å±‚å½’ä¸€åŒ–ï¼Œå…¶ä¸­dæ˜¯ç»´åº¦ã€‚å¹¸è¿çš„æ˜¯ï¼Œå›¾å±‚è§„èŒƒåŒ–æ¨¡å—ä¹Ÿå¯ä»¥æ¨å¹¿åˆ°å¤šä¸ªç»´åº¦ï¼Œè¯·çœ‹:</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es mp"><img src="../Images/59614d0b8f462de843a99ddcf2d06b55.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*7bLT6Fwt59CLYbuVY_hbXQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">nn.LayerNorm can be applied in multiple dimensions. We can normalize fifty 8-dimensional vectors, but we can also normalize sixteen by fifty 8-dimensional vectors.</figcaption></figure><p id="0ec7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å›¾å±‚è§„èŒƒåŒ–ä»…é€‚ç”¨äºæœ€åä¸€ä¸ªå°ºå¯¸ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿æˆ‘ä»¬çš„æ¯ä¸ª50Ã—8çŸ©é˜µ(ä»£è¡¨å•ä¸ªåºåˆ—)çš„å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ã€‚åœ¨æˆ‘ä»¬é€šè¿‡LNè¿è¡Œæˆ‘ä»¬çš„(Nï¼Œ50ï¼Œ8)å¼ é‡ä¹‹åï¼Œæˆ‘ä»¬ä»ç„¶å¾—åˆ°ç›¸åŒçš„ç»´æ•°ã€‚</p><p id="29f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">å¤šå¤´è‡ªæˆ‘å…³æ³¨</strong></p><p id="f243" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ç°åœ¨éœ€è¦å®ç°æ¶æ„å›¾çš„å­å›¾<em class="ku"> c </em>ã€‚é‚£é‡Œå‘ç”Ÿäº†ä»€ä¹ˆäº‹ï¼Ÿ</p><p id="27ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç®€è€Œè¨€ä¹‹:å¯¹äºå•ä¸ªå›¾åƒï¼Œæˆ‘ä»¬å¸Œæœ›åŸºäºä¸å…¶ä»–å›¾åƒçš„ç›¸ä¼¼æ€§åº¦é‡æ¥æ›´æ–°æ¯ä¸ªå›¾åƒå—ã€‚æˆ‘ä»¬é€šè¿‡å°†æ¯ä¸ªé¢ç‰‡(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ç°åœ¨æ˜¯ä¸€ä¸ª8ç»´å‘é‡)çº¿æ€§æ˜ å°„åˆ°3ä¸ªä¸åŒçš„å‘é‡æ¥åšåˆ°è¿™ä¸€ç‚¹:<strong class="ig hi"> q </strong>ã€<strong class="ig hi"> k </strong>å’Œ<strong class="ig hi"> v </strong>(æŸ¥è¯¢ã€é”®ã€å€¼)ã€‚</p><p id="7950" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶åï¼Œå¯¹äºå•ä¸ªè¡¥ä¸ï¼Œæˆ‘ä»¬å°†è®¡ç®—å…¶<strong class="ig hi"> q </strong>å‘é‡ä¸æ‰€æœ‰<strong class="ig hi"> k </strong>å‘é‡ä¹‹é—´çš„ç‚¹ç§¯ï¼Œé™¤ä»¥è¿™äº›å‘é‡çš„ç»´æ•°çš„å¹³æ–¹æ ¹(sqrt(8))ï¼Œsoftmaxè¿™äº›æ‰€è°“çš„<em class="ku">æ³¨æ„åŠ›çº¿ç´¢</em>ï¼Œæœ€åå°†æ¯ä¸ªæ³¨æ„åŠ›çº¿ç´¢ä¹˜ä»¥ä¸ä¸åŒçš„<strong class="ig hi"> k </strong>å‘é‡ç›¸å…³è”çš„<strong class="ig hi"> v </strong>å‘é‡ï¼Œå¹¶æ±‚å’Œã€‚</p><p id="a7aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»¥è¿™ç§æ–¹å¼ï¼Œæ¯ä¸ªå°å—é‡‡ç”¨åŸºäºå…¶ä¸å…¶ä»–å°å—çš„ç›¸ä¼¼æ€§(åœ¨çº¿æ€§æ˜ å°„åˆ°<strong class="ig hi"> q </strong>ã€<strong class="ig hi"> k </strong>å’Œ<strong class="ig hi"> v </strong>ä¹‹å)çš„æ–°å€¼ã€‚ç„¶è€Œï¼Œè¿™æ•´ä¸ªè¿‡ç¨‹æ˜¯åœ¨æˆ‘ä»¬å½“å‰8ç»´é¢ç‰‡çš„<strong class="ig hi"> H </strong>å­å‘é‡ä¸Šæ‰§è¡Œ<strong class="ig hi"> H </strong>æ¬¡ï¼Œå…¶ä¸­<strong class="ig hi"> H </strong>æ˜¯<strong class="ig hi">å¤´çš„æ•°é‡ã€‚</strong>å¦‚æœä½ å¯¹æ³¨æ„åŠ›å’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸ç†Ÿæ‚‰ï¼Œæˆ‘å»ºè®®ä½ é˜…è¯»<a class="ae jc" href="https://data-science-blog.com/blog/2021/04/07/multi-head-attention-mechanism/" rel="noopener ugc nofollow" target="_blank">è¿™ä¸ªç”±<a class="ae jc" href="https://data-science-blog.com/blog/author/yasuto/" rel="noopener ugc nofollow" target="_blank"> Yasuto Tamura </a>å†™çš„</a>å¥½å¸–å­ã€‚</p><p id="2daf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸€æ—¦è·å¾—æ‰€æœ‰ç»“æœï¼Œå®ƒä»¬å°±è¢«è¿æ¥åœ¨ä¸€èµ·ã€‚æœ€åï¼Œç»“æœé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚(ä¸ºäº†æ›´å¥½çš„æµ‹é‡)ã€‚</p><p id="1a4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ³¨æ„åŠ›èƒŒåçš„ç›´è§‚æƒ³æ³•æ˜¯ï¼Œå®ƒå…è®¸å¯¹è¾“å…¥ä¹‹é—´çš„å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚ä½¿â€œ0â€æˆä¸ºé›¶çš„ä¸æ˜¯å•ä¸ªåƒç´ å€¼ï¼Œè€Œæ˜¯å®ƒä»¬å¦‚ä½•ç›¸äº’å…³è”ã€‚</p><p id="8cbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç”±äºæ‰§è¡Œäº†ç›¸å½“å¤šçš„è®¡ç®—ï¼Œå› æ­¤æœ‰å¿…è¦ä¸ºMSAåˆ›å»ºä¸€ä¸ªæ–°ç±»:</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="e7e9" class="kp je hh kl b be kq kr l ks kt">class MyMSA(nn.Module):<br/>    def __init__(self, d, n_heads=2):<br/>        super(MyMSA, self).__init__()<br/>        self.d = d<br/>        self.n_heads = n_heads<br/><br/>        assert d % n_heads == 0, f"Can't divide dimension {d} into {n_heads} heads"<br/><br/>        d_head = int(d / n_heads)<br/>        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])<br/>        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])<br/>        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])<br/>        self.d_head = d_head<br/>        self.softmax = nn.Softmax(dim=-1)<br/><br/>    def forward(self, sequences):<br/>        # Sequences has shape (N, seq_length, token_dim)<br/>        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)<br/>        # And come back to    (N, seq_length, item_dim)  (through concatenation)<br/>        result = []<br/>        for sequence in sequences:<br/>            seq_result = []<br/>            for head in range(self.n_heads):<br/>                q_mapping = self.q_mappings[head]<br/>                k_mapping = self.k_mappings[head]<br/>                v_mapping = self.v_mappings[head]<br/><br/>                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]<br/>                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)<br/><br/>                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))<br/>                seq_result.append(attention @ v)<br/>            result.append(torch.hstack(seq_result))<br/>        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])</span></pre><p id="9c4c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ³¨æ„ï¼Œå¯¹äºæ¯ä¸ªå¤´éƒ¨ï¼Œæˆ‘ä»¬åˆ›å»ºä¸åŒçš„Qã€Kå’ŒVæ˜ å°„å‡½æ•°(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯å¤§å°ä¸º4x4çš„æ–¹é˜µ)ã€‚</p><p id="9e39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç”±äºæˆ‘ä»¬çš„è¾“å…¥å°†æ˜¯å¤§å°ä¸º(Nï¼Œ50ï¼Œ8)çš„åºåˆ—ï¼Œå¹¶ä¸”æˆ‘ä»¬åªä½¿ç”¨2ä¸ªå¤´ï¼Œæˆ‘ä»¬å°†åœ¨æŸä¸ªç‚¹æœ‰ä¸€ä¸ª(Nï¼Œ50ï¼Œ2ï¼Œ4)å¼ é‡ï¼Œä½¿ç”¨ä¸€ä¸ª<em class="ku"> nnã€‚çº¿æ€§(4ï¼Œ4) </em>æ¨¡ä¸Šï¼Œç„¶åå›æ¥ï¼Œä¸²è”åï¼Œå¾—åˆ°ä¸€ä¸ª(Nï¼Œ50ï¼Œ8)å¼ é‡ã€‚</p><p id="0179" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿˜è¦æ³¨æ„ï¼Œä½¿ç”¨å¾ªç¯å¹¶ä¸æ˜¯è®¡ç®—å¤šå¤´è‡ªæˆ‘å…³æ³¨çš„æœ€æœ‰æ•ˆæ–¹å¼ï¼Œä½†å®ƒä½¿ä»£ç æ›´æ¸…æ™°ï¼Œä¾¿äºå­¦ä¹ ã€‚</p><p id="9150" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">æ®‹ç•™è¿æ¥</strong></p><p id="f97f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å‰©ä½™è¿æ¥åªæ˜¯å°†åŸå§‹è¾“å…¥æ·»åŠ åˆ°ä¸€äº›è®¡ç®—çš„ç»“æœä¸­ã€‚è¿™ç›´è§‚åœ°å…è®¸ç½‘ç»œå˜å¾—æ›´å¼ºå¤§ï¼ŒåŒæ—¶è¿˜ä¿ç•™äº†æ¨¡å‹å¯ä»¥è¿‘ä¼¼çš„ä¸€ç»„å¯èƒ½çš„å‡½æ•°ã€‚</p><p id="fe97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªå‰©ä½™è¿æ¥ï¼Œå®ƒå°†æŠŠæˆ‘ä»¬åŸæ¥çš„(Nï¼Œ50ï¼Œ8)å¼ é‡æ·»åŠ åˆ°LNå’ŒMSAä¹‹åè·å¾—çš„(Nï¼Œ50ï¼Œ8)å¼ é‡ä¸­ã€‚æ˜¯æ—¶å€™åˆ›å»ºtransformer encoder blockç±»äº†ï¼Œå®ƒå°†æ˜¯MyViTç±»çš„ä¸€ä¸ªç»„ä»¶:</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="3d74" class="kp je hh kl b be kq kr l ks kt">class MyViTBlock(nn.Module):<br/>    def __init__(self, hidden_d, n_heads, mlp_ratio=4):<br/>        super(MyViTBlock, self).__init__()<br/>        self.hidden_d = hidden_d<br/>        self.n_heads = n_heads<br/><br/>        self.norm1 = nn.LayerNorm(hidden_d)<br/>        self.mhsa = MyMSA(hidden_d, n_heads)<br/><br/>    def forward(self, x):<br/>        out = x + self.mhsa(self.norm1(x))<br/>        return out</span></pre><p id="52b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å”·ï¼Œé‚£æ˜¯ç›¸å½“å¤šçš„å·¥ä½œï¼ä½†æˆ‘ä¿è¯è¿™æ˜¯æœ€éš¾çš„éƒ¨åˆ†ã€‚ä»ç°åœ¨å¼€å§‹ï¼Œä¸€åˆ‡éƒ½åœ¨èµ°ä¸‹å¡è·¯ã€‚</p><p id="9040" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æœ‰äº†è¿™ç§è‡ªæˆ‘å…³æ³¨æœºåˆ¶ï¼Œç±»æ ‡è®°(Nä¸ªåºåˆ—ä¸­æ¯ä¸ªåºåˆ—çš„ç¬¬ä¸€ä¸ªæ ‡è®°)ç°åœ¨æœ‰äº†å…³äºæ‰€æœ‰å…¶ä»–æ ‡è®°çš„ä¿¡æ¯ï¼</p><h2 id="b050" class="lh je hh bd jf li lj lk jj ll lm ln jn ip lo lp jr it lq lr jv ix ls lt jz lu bi translated">æ­¥éª¤5:ç¼–ç å™¨æ¨¡å—(ç¬¬2/2éƒ¨åˆ†)</h2><p id="5f7c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">æ‰€æœ‰ç•™ç»™å˜æ¢å™¨ç¼–ç å™¨çš„åªæ˜¯æˆ‘ä»¬å·²ç»æ‹¥æœ‰çš„å’Œæˆ‘ä»¬é€šè¿‡å¦ä¸€ä¸ªLNå’ŒMLPä¼ é€’å½“å‰å¼ é‡åå¾—åˆ°çš„ä¹‹é—´çš„ç®€å•å‰©ä½™è¿æ¥ã€‚MLPç”±ä¸¤ä¸ªå›¾å±‚ç»„æˆï¼Œå…¶ä¸­éšè—å›¾å±‚é€šå¸¸æ˜¯å…¶å››å€å¤§(è¿™æ˜¯ä¸€ä¸ªå‚æ•°)</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="e40e" class="kp je hh kl b be kq kr l ks kt">class MyViTBlock(nn.Module):<br/>    def __init__(self, hidden_d, n_heads, mlp_ratio=4):<br/>        super(MyViTBlock, self).__init__()<br/>        self.hidden_d = hidden_d<br/>        self.n_heads = n_heads<br/><br/>        self.norm1 = nn.LayerNorm(hidden_d)<br/>        self.mhsa = MyMSA(hidden_d, n_heads)<br/>        self.norm2 = nn.LayerNorm(hidden_d)<br/>        self.mlp = nn.Sequential(<br/>            nn.Linear(hidden_d, mlp_ratio * hidden_d),<br/>            nn.GELU(),<br/>            nn.Linear(mlp_ratio * hidden_d, hidden_d)<br/>        )<br/><br/>    def forward(self, x):<br/>        out = x + self.mhsa(self.norm1(x))<br/>        out = out + self.mlp(self.norm2(out))<br/>        return out</span></pre><p id="7bcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ç¡®å®å¯ä»¥çœ‹åˆ°ï¼Œç¼–ç å™¨æ¨¡å—è¾“å‡ºç›¸åŒç»´æ•°çš„å¼ é‡:</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="0020" class="kp je hh kl b be kq kr l ks kt">if __name__ == '__main__':<br/>  model = MyVitBlock(hidden_d=8, n_heads=2)<br/><br/>  x = torch.randn(7, 50, 8)  # Dummy sequences<br/>  print(model(x).shape)      # torch.Size([7, 50, 8])</span></pre><p id="21d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ—¢ç„¶ç¼–ç å™¨æ¨¡å—å·²ç»å‡†å¤‡å¥½äº†ï¼Œæˆ‘ä»¬åªéœ€è¦å°†å®ƒæ’å…¥åˆ°æˆ‘ä»¬æ›´å¤§çš„ViTæ¨¡å‹ä¸­ï¼Œå®ƒè´Ÿè´£åœ¨å˜å‹å™¨æ¨¡å—ä¹‹å‰è¿›è¡Œä¿®è¡¥ï¼Œå¹¶åœ¨ä¹‹åè¿›è¡Œåˆ†ç±»ã€‚</p><p id="d1bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å¯ä»¥æœ‰ä»»æ„æ•°é‡çš„å˜å‹å™¨æ¨¡å—ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘å°†åªä½¿ç”¨2ã€‚æˆ‘ä»¬è¿˜æ·»åŠ äº†ä¸€ä¸ªå‚æ•°ï¼Œä»¥äº†è§£æ¯ä¸ªç¼–ç å™¨æ¨¡å—å°†ä½¿ç”¨å¤šå°‘å¤´ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="69ae" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>    def __init__(self, chw, n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10):<br/>        # Super constructor<br/>        super(MyViT, self).__init__()<br/>        <br/>        # Attributes<br/>        self.chw = chw # ( C , H , W )<br/>        self.n_patches = n_patches<br/>        self.n_blocks = n_blocks<br/>        self.n_heads = n_heads<br/>        self.hidden_d = hidden_d<br/>        <br/>        # Input and patches sizes<br/>        assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>        assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)<br/><br/>        # 1) Linear mapper<br/>        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])<br/>        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)<br/>        <br/>        # 2) Learnable classification token<br/>        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))<br/>        <br/>        # 3) Positional embedding<br/>        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)<br/>        <br/>        # 4) Transformer encoder blocks<br/>        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])<br/><br/>    def forward(self, images):<br/>        # Dividing images into patches<br/>        n, c, h, w = images.shape<br/>        patches = patchify(images, self.n_patches).to(self.positional_embeddings.device)<br/>        <br/>        # Running linear layer tokenization<br/>        # Map the vector corresponding to each patch to the hidden size dimension<br/>        tokens = self.linear_mapper(patches)<br/>        <br/>        # Adding classification token to the tokens<br/>        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)<br/>        <br/>        # Adding positional embedding<br/>        out = tokens + self.positional_embeddings.repeat(n, 1, 1)<br/>        <br/>        # Transformer Blocks<br/>        for block in self.blocks:<br/>            out = block(out)<br/>            <br/>        return out</span></pre><p id="810d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬é€šè¿‡æˆ‘ä»¬çš„æ¨¡å‹è¿è¡Œä¸€ä¸ªéšæœºçš„(7ï¼Œ1ï¼Œ28ï¼Œ28)å¼ é‡ï¼Œæˆ‘ä»¬ä»ç„¶å¾—åˆ°ä¸€ä¸ª(7ï¼Œ50ï¼Œ8)å¼ é‡ã€‚</p><h2 id="6895" class="lh je hh bd jf li lj lk jj ll lm ln jn ip lo lp jr it lq lr jv ix ls lt jz lu bi translated">æ­¥éª¤6:MLPåˆ†ç±»</h2><p id="d9d3" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä»æˆ‘ä»¬çš„Nä¸ªåºåˆ—ä¸­æå–åˆ†ç±»æ ‡è®°(ç¬¬ä¸€ä¸ªæ ‡è®°)ï¼Œå¹¶ä½¿ç”¨æ¯ä¸ªæ ‡è®°è·å¾—Nä¸ªåˆ†ç±»ã€‚</p><p id="2d63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç”±äºæˆ‘ä»¬å†³å®šæ¯ä¸ªè®°å·æ˜¯ä¸€ä¸ª8ç»´å‘é‡ï¼Œå¹¶ä¸”ç”±äºæˆ‘ä»¬æœ‰10ä¸ªå¯èƒ½çš„æ•°å­—ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆ†ç±»MLPå®ç°ä¸ºä¸€ä¸ªç®€å•çš„8Ã—10çŸ©é˜µï¼Œç”¨SoftMaxå‡½æ•°æ¿€æ´»ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="5f82" class="kp je hh kl b be kq kr l ks kt">class MyViT(nn.Module):<br/>    def __init__(self, chw, n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10):<br/>        # Super constructor<br/>        super(MyViT, self).__init__()<br/>        <br/>        # Attributes<br/>        self.chw = chw # ( C , H , W )<br/>        self.n_patches = n_patches<br/>        self.n_blocks = n_blocks<br/>        self.n_heads = n_heads<br/>        self.hidden_d = hidden_d<br/>        <br/>        # Input and patches sizes<br/>        assert chw[1] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>        assert chw[2] % n_patches == 0, "Input shape not entirely divisible by number of patches"<br/>        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)<br/><br/>        # 1) Linear mapper<br/>        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])<br/>        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)<br/>        <br/>        # 2) Learnable classification token<br/>        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))<br/>        <br/>        # 3) Positional embedding<br/>        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)<br/>        <br/>        # 4) Transformer encoder blocks<br/>        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])<br/>        <br/>        # 5) Classification MLPk<br/>        self.mlp = nn.Sequential(<br/>            nn.Linear(self.hidden_d, out_d),<br/>            nn.Softmax(dim=-1)<br/>        )<br/><br/>    def forward(self, images):<br/>        # Dividing images into patches<br/>        n, c, h, w = images.shape<br/>        patches = patchify(images, self.n_patches).to(self.positional_embeddings.device)<br/>        <br/>        # Running linear layer tokenization<br/>        # Map the vector corresponding to each patch to the hidden size dimension<br/>        tokens = self.linear_mapper(patches)<br/>        <br/>        # Adding classification token to the tokens<br/>        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)<br/>        <br/>        # Adding positional embedding<br/>        out = tokens + self.positional_embeddings.repeat(n, 1, 1)<br/>        <br/>        # Transformer Blocks<br/>        for block in self.blocks:<br/>            out = block(out)<br/>            <br/>        # Getting the classification token only<br/>        out = out[:, 0]<br/>        <br/>        return self.mlp(out) # Map to output dimension, output category distribution</span></pre><p id="87d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬æ¨¡å‹çš„è¾“å‡ºç°åœ¨æ˜¯ä¸€ä¸ª(Nï¼Œ10)å¼ é‡ã€‚ä¸‡å²ï¼Œæˆ‘ä»¬å®Œæˆäº†ï¼</p><h1 id="bdba" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">ç»“æœ</h1><p id="5191" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">æˆ‘ä»¬ä¿®æ”¹äº†ä¸»ç¨‹åºä¸­å”¯ä¸€ä¸€è¡Œä¹‹å‰æ²¡æœ‰å®šä¹‰çš„ä»£ç ã€‚</p><pre class="kg kh ki kj fd kk kl km bn kn ko bi"><span id="1058" class="kp je hh kl b be kq kr l ks kt">model = MyVit((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)</span></pre><p id="65ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ç°åœ¨åªéœ€è¦è¿è¡Œè®­ç»ƒå’Œæµ‹è¯•å¾ªç¯ï¼Œçœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°å¦‚ä½•ã€‚å¦‚æœæ‚¨å·²ç»æ‰‹åŠ¨è®¾ç½®äº†torch seed(è®¾ç½®ä¸º0)ï¼Œæ‚¨åº”è¯¥æ‰“å°å‡ºä»¥ä¸‹å†…å®¹:</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mq"><img src="../Images/02110057745bed8e0eb3f5e64fe70b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bd6tOT0VZ8PAIHCLc7irbA.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Training losses, test loss, and test accuracy obtained.</figcaption></figure><p id="4f62" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å°±æ˜¯è¿™æ ·ï¼æˆ‘ä»¬ç°åœ¨å·²ç»ä»å¤´å¼€å§‹åˆ›å»ºäº†ä¸€ä¸ªViTã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä»…ä»…5ä¸ªå†å…ƒå’Œå¾ˆå°‘çš„å‚æ•°ä¸‹å°±è¾¾åˆ°äº†80%çš„å‡†ç¡®ç‡ã€‚</p><p id="4011" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½ å¯ä»¥åœ¨ä¸‹é¢çš„<a class="ae jc" href="https://github.com/BrianPulfer/PapersReimplementations/blob/master/vit/vit_torch.py" rel="noopener ugc nofollow" target="_blank">é“¾æ¥</a>æ‰¾åˆ°å®Œæ•´çš„è„šæœ¬ã€‚è€ƒè™‘é¼“æŒğŸ‘å¦‚æœä½ è§‰å¾—è¿™ä¸ªæ•…äº‹æœ‰ç”¨ï¼Œè®©æˆ‘çŸ¥é“ä½ æ˜¯å¦è®¤ä¸ºæœ‰ä»€ä¹ˆä¸æ¸…æ¥šçš„åœ°æ–¹ï¼</p><div class="mr ms ez fb mt mu"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">Mlearning.aiæäº¤å»ºè®®</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">å¦‚ä½•æˆä¸ºMlearning.aiä¸Šçš„ä½œå®¶</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">medium.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni lb mu"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>DBSCAN easily explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DBSCAN很容易解释</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/dbscan-easily-explained-9f47aa2e1df6?source=collection_archive---------4-----------------------#2022-08-08">https://medium.com/mlearning-ai/dbscan-easily-explained-9f47aa2e1df6?source=collection_archive---------4-----------------------#2022-08-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/e5b7e1a1a4638d1be15fb6d14f8d992b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G20h27Ktd4sctZdugLi2Gw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@eddyvanduijn?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Ed van duijn</a> on <a class="ae it" href="https://unsplash.com/s/photos/cluster?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="259f" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h2><p id="f907" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">聚类分析是一种无监督的机器学习方法，它将数据点分组为称为聚类的几个组，使得相同聚类中的数据点彼此非常相似，而不同聚类中的数据点彼此不同。</p><p id="9e3f" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">两种最流行的聚类算法是“k均值聚类”和“层次聚类”。也许在这篇文章中，我们将讨论一种不同类型的聚类算法。</p><h2 id="6bd6" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">数据库扫描</strong></h2><p id="e52c" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">DBSCAN代表对有噪声的应用进行基于密度的空间聚类。由Martin Easter在1996年提出的DBSCAN是一种基于密度的聚类算法，它基于这样的假设工作，即簇是由较低密度区域分隔的空间中的密集区域。</p><p id="6055" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">因此，基本上它测量整个空间的密度，然后将密集分组的数据点分配到单个簇中。DBSCAN的最佳特性是对异常值具有鲁棒性。这意味着它可以识别数据中的异常值并相应地工作。稍后会有更多关于这个的报道。</p><h2 id="06e9" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">需要另一种聚类算法</strong></h2><p id="53ff" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">在开始之前，让我们先修改一下前面提到的两个算法。</p><p id="de8b" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi"> K-means算法</strong></p><p id="8ac9" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">k均值算法是一种划分算法。在这种方法中，我们首先构建数据库D的一个分区</p><p id="1ba1" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">n个物体组成一组k个集群。k是该算法的输入参数。如何选择k值是另一篇文章的主题。因此，在初始划分D之后，它使用迭代控制策略来优化目标函数。每个集群由集群的重心来表示。它采用了两步程序。首先，确定k个代表最小化优化函数。其次，将每个对象分配到其代表最接近所考虑的对象的聚类中。</p><p id="c32b" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi">层次聚类</strong></p><p id="70cc" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">层次聚类创建数据的层次分解，层次分解用树状图表示。树形图是一棵树，它迭代地将D分成更小子集，直到每个子集只包含一个对象。它有两种方法。凝聚法和分裂法。它不需要k作为输入。然而，需要定义终止条件。</p><p id="b801" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">好了，现在我们知道了k是什么意思，聚类和层次聚类是什么，我们现在可以进一步讨论为什么我们需要另一个聚类算法。</p><p id="6082" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">k均值和层次聚类都不能创建任意形状的聚类。它们不能基于变化的密度来构建聚类。</p><p id="6c1a" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">传统算法的另一个问题是，它们确保每个观察值都是任何聚类的一部分，即使该点离质心非常远。数据点的微小变化可能会影响聚类结果。</p><p id="988c" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">DBSCAN的另一个优点是您不必预先指定集群的数量。所以没有领域知识在这里不是问题。</p><p id="3fe0" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">K均值和层次聚类都是多次计算数据点之间和聚类中心之间的距离，而在DBSCAN中只计算一次。</p><p id="ba67" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">现在我们知道了为什么我们需要另一种聚类算法，让我们深入研究算法的工作原理。</p><h2 id="050e" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">DBS can如何工作</strong></h2><p id="a4c6" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">当查看图1 2和图3中的样本点集时，我们可以很容易地检测出点的聚类和不属于任何聚类的噪声点。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es ks"><img src="../Images/4a89c3a156fd08f03c9ddf06e65c2507.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*LkmpV0_QkK_kSs4PQPao-A.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">figure 1</figcaption></figure><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/5344383eb370554f54f86f3232a8c51f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*OfmZn9Tjkn763UMykZVUzA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">figure 2</figcaption></figure><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ky"><img src="../Images/b64beddc37a9bcec07549879343d2548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*StOFNAAUi5f36pMqDy92aw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">figure 3</figcaption></figure><p id="4f3a" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">我们可以识别聚类，因为在每个聚类内，我们有一个典型的点密度，该密度高于聚类外的密度。此外，噪声区域内的密度比簇内的密度低得多。</p><p id="cdbf" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">现在让我们形式化我们最初的“<strong class="ju hi">簇</strong>和“<strong class="ju hi">噪声</strong>”的概念。</p><p id="6faa" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">该算法可以应用于2D、3D或任何更高维度的空间。</p><p id="5cb0" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">因此，关键的思想是，对于一个簇中的每个点，给定半径的邻域必须包含最小数量的点。邻域的形状由两点p和q之间的距离函数决定。例如，当在2D空间中使用欧几里得距离时，它将是圆形，在3D空间中它将是球形。</p><p id="d864" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi"> <em class="kz"> ε </em>邻域</strong>:点p的<em class="kz"> ε </em>邻域用N <em class="kz"> ε </em> (p)表示，定义为</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es la"><img src="../Images/77907ca5d83cc64b7ef866806735007a.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*LV3wtkHd8PLBvL1JRn9CTQ.png"/></div></figure><p id="0844" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">现在基于<em class="kz"> ε </em>邻域DBSCAN将数据库D中的每个点分成三类。</p><p id="d0a9" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi">核心点:</strong>如果p的<em class="kz"> ε </em>邻域至少包含数据库的一个极小点，则称点p为核心点。最小点是一个超参数，我们将在文章的后面部分解释。</p><p id="eceb" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi">边界点:</strong>如果q的<em class="kz"> ε </em>邻域包含至少一个但小于最小个数的点，则称点q为边界点。</p><p id="0fd3" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi">噪声:</strong>若r的<em class="kz"> ε </em>邻域不包含点，则称r为噪声。看下图直观理解。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/1611a1a17d1142ac9f596fd4e33a08f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*xCYJquAam7AMTGcozL9txw.png"/></div></figure><p id="c824" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">蓝色的点是噪音。红色点是核心点，绿色点是边界。这里取最小值3。</p><p id="ea1e" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">该算法从数据集中的随机数据点开始。然后，如果在邻域内存在最小数量的点，则它认为所有点都是同一聚类的一部分。通过递归地重复每个相邻点的邻域计算来扩展聚类。</p><h2 id="c929" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">可达性和连通性</strong></h2><p id="1d4b" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">在继续之前，你需要理解两个重要的概念。可达性表明一个数据点是否可以从另一个数据点直接或间接访问。连通性表明两个数据点是否属于同一个聚类。就可达性和连通性而言，DBSCAN中的两点可以称为:</p><p id="dabd" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">1.直接密度可达</p><p id="7471" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">2.密度可达的</p><p id="4600" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">3.密度相关的</p><p id="fdd5" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">让我们详细说明一下。</p><p id="903a" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi">直接密度可达</strong>:点p是从点q wrt直接密度可达的。<em class="kz"> ε </em>，<em class="kz"> minpts </em>如果</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/c823d909e2a05d2bbf284bbd388f0c50.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*KcSAbskYYj9nm3C6c8-7Zw.png"/></div></figure><p id="1a79" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">显然，直接密度可达性对于成对核心点是对称的，但是当涉及一个核心点和一个边界点时则不是。</p><p id="03d2" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">密度可达:点p是从点q wrt密度可达的。<em class="kz"> ε </em>和<em class="kz"> minpts </em>如果存在一个点链p_1，p_2，…，p_n .其中p_1 = p，p_n =q使得p_i+1是从p_i直接密度可达的。</p><p id="6497" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">这种关系是传递的，但不是对称的。在核心点的情况下，密度-可达性是对称的。</p><p id="bc20" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi">密度连通:</strong>点p与点q wrt是密度连通的。<em class="kz"> ε </em>和m <em class="kz">输入</em>如果有一点o使得p和q都是从o wrt密度可达的。<em class="kz"> ε </em>和<em class="kz"> minpts </em>。</p><p id="030d" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">借助这些术语，我们可以定义集群。</p><p id="672a" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">Def。(聚类):设D是点的数据库，关于<em class="kz"> ε </em>和<em class="kz"> minpts </em>的聚类C是满足以下条件的D的非空子集</p><ol class=""><li id="3f84" class="ld le hh ju b jv kn jz ko jf lf jj lg jn lh km li lj lk ll bi translated">∀ p和q:如果p ∈ C和q是从p wrt密度可达的。<em class="kz"> ε </em>和<em class="kz"> minpts </em>然后q ∈ C。</li></ol><p id="5a0f" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">2.∀ p，q ∈ C : p与q wrt密度相关。<em class="kz"> ε </em>和<em class="kz"> minpts </em>。</p><h2 id="b335" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">算法的参数</strong></h2><p id="3300" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">DBSCAN有两个参数。<em class="kz"> ε </em>和<em class="kz"> minpts </em>。该算法对这两个参数非常敏感。这些参数中的微小变化都会极大地改变分析结果。</p><ol class=""><li id="38cb" class="ld le hh ju b jv kn jz ko jf lf jj lg jn lh km li lj lk ll bi translated"><strong class="ju hi"> <em class="kz"> ε </em> : </strong>指定邻居的距离。如果两点之间的距离小于或等于<em class="kz"> ε </em>，则认为这两点是相邻的。如果选择的ε值太小，那么将创建更多的聚类，并且更多的数据点将被视为噪声。反之，如果选择得太大，那么各种小集群将合并成一个大集群，我们将丢失细节。</li></ol><p id="2436" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><strong class="ju hi"> <em class="kz"> Minpts </em> : </strong>定义一个聚类的最小数据点数。根据经验，最小<em class="kz"> minpts </em>可以从数据集中的维数D中导出，因为<em class="kz"> minpts </em> ≥ D + 1。低值<em class="kz"> minpts </em> = 1是没有意义的，因为这样的话每个点本身就已经是一个集群了。在<em class="kz"> minpts </em> ≤ 2的情况下，结果将与具有单链路度量的分层聚类相同，在高度ε处切割树状图。因此，<em class="kz"> minpts </em>必须至少选择3个。但是，对于有噪声的数据集，较大的值通常更好，并且会产生更重要的聚类。根据经验，可以使用<em class="kz"> minpts </em> = 2 dim，但对于非常大的数据、噪声数据或包含许多重复数据的数据，可能需要选择更大的值。</p><p id="42d0" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">这都是为了这篇文章。我希望你们喜欢读这篇文章。</p><p id="a8ba" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">请在评论区提出你的想法。</p><p id="efa2" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">跟着我去其他地方</p><p id="4058" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated"><a class="ae it" href="https://github.com/shubhendu-ghosh-DS" rel="noopener ugc nofollow" target="_blank"> Github </a>，<a class="ae it" href="https://www.linkedin.com/in/shubhendu-ghosh-423092205/" rel="noopener ugc nofollow" target="_blank"> linkedin </a>，<a class="ae it" href="https://twitter.com/shubhendubro" rel="noopener ugc nofollow" target="_blank"> twitter </a></p><p id="ccc4" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">谢谢你</p><div class="lm ln ez fb lo lp"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lq ab dw"><div class="lr ab ls cl cj lt"><h2 class="bd hi fi z dy lu ea eb lv ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lw l"><h3 class="bd b fi z dy lu ea eb lv ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lx l"><p class="bd b fp z dy lu ea eb lv ed ef dx translated">medium.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md in lp"/></div></div></a></div></div></div>    
</body>
</html>
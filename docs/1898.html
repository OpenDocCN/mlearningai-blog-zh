<html>
<head>
<title>Suspicious Human Activity Recognition from CCTV with LRCN model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于LRCN模型的CCTV可疑人体活动识别</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/suspicious-human-activity-detection-95b870dae688?source=collection_archive---------1-----------------------#2022-02-09">https://medium.com/mlearning-ai/suspicious-human-activity-detection-95b870dae688?source=collection_archive---------1-----------------------#2022-02-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="7f50" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">了解如何使用带有Keras的LRCN模型和Python中的TensorFlow对闭路电视录像中的人类活动进行分类</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/ca2afdc2b6adf954fd897322640e1f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*blhdwOt6gQNrmGwq"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@theblowup?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">the blowup</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="2acc" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">介绍</h1><p id="f551" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">在当今世界，闭路电视监控是一个场所可以拥有的最基本和最有效的安全功能。它可以在医院、商场、大学等地方找到。这是防止和检测有害活动的最著名的方法。但是想象一个学术校园，在多栋建筑中有超过100个闭路电视，如宿舍、教室、食堂、运动场、礼堂等。手动监控闭路电视摄像机上的所有事件是不可能的。即使事件已经发生，在录制的视频中手动搜索相同的事件也会浪费很多时间。</p><p id="8d91" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">我们将为大学校园创建一个基于<strong class="kh hi">长期循环卷积网络(LRCN)的系统，以监控闭路电视镜头</strong> <strong class="kh hi">，并检测非可疑活动，如跑步、散步&amp;，可疑活动，如打架</strong>。该系统可用于创建警报，如果检测到任何可疑活动，该警报将通知用户。</p><h1 id="c574" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">这个计划</h1><ul class=""><li id="0702" class="lg lh hh kh b ki kj kl km ko li ks lj kw lk la ll lm ln lo bi translated">加载可疑人员活动识别数据。</li><li id="c759" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated">预处理数据。</li><li id="9a1c" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated">为分类建立LRCN模型。</li><li id="c654" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated">评估模型。</li></ul><blockquote class="lu lv lw"><p id="f0c8" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><a class="ae jm" href="https://github.com/kunaltulsidasani/Suspicious-Human-Activity-Detection-LRCN" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi">这个完整的项目在Github上</strong> </a> <strong class="kh hi">。</strong></p><p id="1a3a" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><a class="ae jm" href="https://colab.research.google.com/drive/1U4tqj7kDk4eIfzJeK9TQlbMsk4qooTrB?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi">在浏览器上运行代码。</strong>T13】</a></p></blockquote><h1 id="0d31" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">可疑人类活动识别数据</h1><p id="e0e2" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">这些数据是从两个不同的数据集编译而来的——KTH动作数据集<a class="ae jm" href="https://www.csc.kth.se/cvap/actions/" rel="noopener ugc nofollow" target="_blank"><strong class="kh hi"/></a><a class="ae jm" href="https://www.kaggle.com/naveenk903/movies-fight-detection-dataset" rel="noopener ugc nofollow" target="_blank"><strong class="kh hi">视频打斗检测数据集</strong> </a></p><ul class=""><li id="10af" class="lg lh hh kh b ki lb kl lc ko mb ks mc kw md la ll lm ln lo bi translated"><a class="ae jm" href="https://www.csc.kth.se/cvap/actions/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi"> KTH数据集</strong> </a> <strong class="kh hi"> </strong> —包含六类<em class="lx">人体动作(行走、慢跑、跑步、拳击、挥手和拍手)</em>的数据库，由<em class="lx"> 25名受试者多次执行。</em>所有的序列都是用静态摄像机以<em class="lx"> 25fps帧速率</em>在同质背景上拍摄的。这些序列被下采样到空间分辨率为<em class="lx">160×120像素</em>，并且平均长度为<em class="lx"> 4秒</em>。</li><li id="fb0d" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated"><a class="ae jm" href="https://www.kaggle.com/naveenk903/movies-fight-detection-dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi">视频打斗检测数据集</strong> </a> <strong class="kh hi"> — </strong> Kaggle数据集由超过<em class="lx">个从电影和YouTube视频中获取的视频</em>组成，可用于训练可疑行为(打斗)。</li></ul><blockquote class="lu lv lw"><p id="f068" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><strong class="kh hi">每个动作拍摄了100个视频——从KTH数据集行走&amp;，从Kaggle数据集打斗。</strong></p><p id="c8ae" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><strong class="kh hi">最终编译的数据集使用:</strong> <a class="ae jm" href="https://drive.google.com/file/d/1n-wc8ebopNacuTNdtGrkn7A7r7UOjBj7/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi">驱动链接</strong> </a></p></blockquote><h1 id="99e3" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">设置数据集变量</h1><p id="83ba" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">数据集变量是指将在整个代码中使用的变量，如要加载的帧的高度和宽度、序列长度——视频中要考虑的帧数、数据集目录和分类类别。以及设置将在训练测试数据分割时使用随机变量。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="8ff0" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">数据预处理</h1><p id="285d" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">将单个视频转换为numpy数组的过程，以便它可以用于训练模型。</p><ul class=""><li id="64f2" class="lg lh hh kh b ki lb kl lc ko mb ks mc kw md la ll lm ln lo bi translated"><strong class="kh hi">提取帧:</strong>使用OpenCV库读取每个视频，以相等的时间间隔从视频中提取30帧，每个帧被读取为3D numpy数组维度—(高度，宽度，3)最后一个维度是指RGB，即该单元的颜色。</li><li id="88ac" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated"><strong class="kh hi">调整大小:</strong>当我们需要增加或减少像素总数时，调整帧大小是必要的。因此，我们将所有帧的尺寸调整为<strong class="kh hi">宽:64px </strong>和<strong class="kh hi">高:64px </strong>，以保持输入到架构的图像的一致性。</li><li id="0a5e" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated"><strong class="kh hi">归一化:</strong>它将帮助学习算法更快地学习，并从图像中捕捉必要的特征。因此，我们通过用255 除<strong class="kh hi">来标准化调整后的帧，使得每个像素值位于0 &amp; 1之间。</strong></li><li id="2ef1" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated"><strong class="kh hi">存储在numpy数组中:</strong>30个调整大小和标准化的帧存储在一个Numpy数组中，作为模型的输入。</li></ul><p id="2d45" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">该函数执行上述任务，并将视频位置作为参数。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="5080" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">为了预处理整个数据集并将其加载到一个numpy数组中，使用了以下函数，该函数返回每个视频的特征、加载的每个文件的标签和路径。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="6ea8" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">最后一个预处理步骤是类别编码:</p><pre class="ix iy iz ja fd mg mh mi mj aw mk bi"><span id="4a92" class="ml jo hh mh b fi mm mn l mo mp"># Using Keras's to_categorical method to convert labels <br/># into one-hot-encoded vectors<br/>one_hot_encoded_labels = to_categorical(labels)</span></pre><h1 id="35e4" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">数据形状</h1><pre class="ix iy iz ja fd mg mh mi mj aw mk bi"><span id="38f2" class="ml jo hh mh b fi mm mn l mo mp"># Returns shape of features &amp; labels<br/>print(features.shape, labels.shape)</span></pre><p id="164b" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">特征—(视频数量、每个视频的帧数、高度、宽度、RGB)</p><p id="205d" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">标签—(#视频，)</p><pre class="ix iy iz ja fd mg mh mi mj aw mk bi"><span id="ceee" class="ml jo hh mh b fi mm mn l mo mp">(300, 30, 64, 64, 3) (300,)</span></pre><h1 id="7d5b" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">训练测试分割数据</h1><p id="6a45" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">拆分预处理后的数据用于训练和测试:</p><ul class=""><li id="7f6e" class="lg lh hh kh b ki lb kl lc ko mb ks mc kw md la ll lm ln lo bi translated">75%的数据用于训练</li><li id="8762" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated">25%的数据用于测试</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="d2fc" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">LRCN模型</h1><p id="1242" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated"><strong class="kh hi">长期递归卷积网络(LRCN): </strong>一组作者在2016年5月提出了<strong class="kh hi"> LRCNs </strong>，这是一类利用<strong class="kh hi">CNN</strong>在视觉识别问题上快速进展的优势，以及将这种模型应用于时变输入和输出的日益增长的愿望的架构。LRCN用一个<strong class="kh hi"> CNN(中左)</strong>处理可变长度的<strong class="kh hi">视觉输入(左)</strong>，其输出被送入一个递归序列模型<strong class="kh hi"> (LSTMs，中右)</strong>的堆栈，最终产生一个<strong class="kh hi">可变长度预测(右)</strong>。CNN和LSTM权重都是跨时间共享的，这导致了一种可缩放至任意长序列的表示。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mq"><img src="../Images/4c5e746d0958b2a2eeb2f17c955fda59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3EZuURGurCiAJsCnntStng.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Long-term Recurrent Convolutional Networks for Visual Recognition and Description, Jeff Donahue, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, Sergio Guadarrama, Kate Saenko, Trevor Darrell, 2016</figcaption></figure><h1 id="0802" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">建筑模型</h1><p id="461c" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">我们将创建一个基本的LRCN模型，有4个CNN层，然后是一个LSTM层。你可以自己增加模型的复杂性。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="e009" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">模特培训</h1><p id="a50e" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">该模型将在数据的训练分割上被训练，具有早期停止回调。</p><blockquote class="lu lv lw"><p id="910d" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><strong class="kh hi">提前停止回调</strong> —可以理解为当模型的改善停止或开始减少时，停止模型训练的功能。</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="62ca" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">估价</h1><p id="e06d" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">这是训练时的准确度图:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mr"><img src="../Images/db6d8aeaea3c2485f1a850c25a89df2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*JOaNvMVFhvndWunkE_rbBw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Kunal</figcaption></figure><blockquote class="lu lv lw"><p id="0474" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated">可以通过一些超参数调整来提高模型性能。</p></blockquote><p id="e4df" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><strong class="kh hi">测试数据的准确性:</strong></p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><pre class="ix iy iz ja fd mg mh mi mj aw mk bi"><span id="645a" class="ml jo hh mh b fi mm mn l mo mp">Accuracy = 82.66666666666667</span></pre><p id="26b6" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">模型达到了83%左右的准确率，对于300条记录的数据来说已经不错了。</p><h1 id="7192" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">未来的工作</h1><p id="fd65" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">该模型不训练进一步的可疑行为，如昏厥，盗窃等。该模型还可以通过对更多可疑行为进行训练来改进。如果代码在高端GPU上运行，它也可以用于近实时处理闭路电视镜头。</p><h1 id="ce2f" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">结论</h1><p id="6480" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">我们创建了一个LRCN模型，用于从CCTV镜头中检测像打斗、行走和奔跑这样的活动，该模型在<strong class="kh hi"> 300个视频</strong>上进行训练，并实现了大约83%的<strong class="kh hi">准确率。</strong></p><blockquote class="lu lv lw"><p id="1764" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><a class="ae jm" href="https://github.com/kunaltulsidasani/Suspicious-Human-Activity-Detection-LRCN" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi">这个完整的项目在Github上</strong> </a> <strong class="kh hi">。</strong></p><p id="f86a" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><a class="ae jm" href="https://colab.research.google.com/drive/1U4tqj7kDk4eIfzJeK9TQlbMsk4qooTrB?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi">在浏览器上运行代码。</strong> </a></p></blockquote><h1 id="9246" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">参考</h1><ul class=""><li id="7349" class="lg lh hh kh b ki kj kl km ko li ks lj kw lk la ll lm ln lo bi translated"><a class="ae jm" href="https://www.csc.kth.se/cvap/actions/" rel="noopener ugc nofollow" target="_blank"> KTH行动数据集</a></li><li id="090a" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated"><a class="ae jm" href="https://www.kaggle.com/naveenk903/movies-fight-detection-dataset" rel="noopener ugc nofollow" target="_blank">视频打斗检测数据集</a></li><li id="f294" class="lg lh hh kh b ki lp kl lq ko lr ks ls kw lt la ll lm ln lo bi translated"><a class="ae jm" href="https://www.tensorflow.org/guide/keras/sequential_model" rel="noopener ugc nofollow" target="_blank">张量流序列模型</a></li></ul><blockquote class="lu lv lw"><p id="718c" class="kf kg lx kh b ki lb ii kk kl lc il kn ly ld kq kr lz le ku kv ma lf ky kz la ha bi translated"><strong class="kh hi">可以在</strong> <a class="ae jm" href="https://www.linkedin.com/in/kunal-tulsidasani/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh hi"> LinkedIn </strong> </a> <strong class="kh hi">上联系我，或者在</strong><a class="ae jm" href="https://github.com/kunaltulsidasani" rel="noopener ugc nofollow" target="_blank"><strong class="kh hi">Github</strong></a><strong class="kh hi">上关注我。</strong></p></blockquote></div><div class="ab cl ms mt go mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ha hb hc hd he"><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mz"><img src="../Images/6e4d93e108c736ad4b4ffe6d689ea7e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a3rIZK6lowncR2Xz"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kelly Sikkema</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class="na nb ez fb nc nd"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hi fi z dy ni ea eb nj ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">medium.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr jg nd"/></div></div></a></div><p id="1e25" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><a class="ae jm" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb">成为作家</a></p></div></div>    
</body>
</html>
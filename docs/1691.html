<html>
<head>
<title>Growth Modelling in Ruminants</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反刍动物的生长模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/growth-modeling-in-ruminants-fbeb08fa58ab?source=collection_archive---------7-----------------------#2022-01-19">https://medium.com/mlearning-ai/growth-modeling-in-ruminants-fbeb08fa58ab?source=collection_archive---------7-----------------------#2022-01-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="2b76" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">在R中使用协方差矩阵</h2></div><p id="da52" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，我将向你展示我是如何使用商业数据集上的统计模型来模拟反刍动物的生长的。因此，我不能分享数据集和数据已经有点增加，但我会尽量使我的工作流程尽可能透明。如果你了解我，你就会知道我喜欢混合模型，所以要利用我在这里使用的代码，你只需要有一个纵向数据集。</p><p id="0c7b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们开始吧。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="dd09" class="kc kd hh jy b fi ke kf l kg kh">rm(list = ls())<br/>#### LIBRARIES ####<br/>library(foreign)<br/>library(lme4)<br/>library(ggplot2)<br/>library(rms)<br/>library(plyr)<br/>library(Hmisc)<br/>library(reshape2)<br/>library(boot)<br/>library(sjPlot)<br/>library(sjstats)<br/>library(sjmisc)<br/>library(AICcmodavg)<br/>require(parallel) <br/>library(gridExtra)<br/>library(coefplot) <br/>library(coda)     <br/>library(aods3)     <br/>library(plotMCMC) <br/>library(bbmle)     <br/>library(nlme)<br/>library(merTools)<br/>library(RLRsim) <br/>library(pbkrtest)<br/>library(multcomp)<br/>library(lsmeans)<br/>library(multcompView)<br/>library(lattice)<br/>library(splines)<br/>library(lmtest)<br/>library(car)<br/>library(corrplot)<br/>library(PerformanceAnalytics)<br/>library(eqs2lavaan)</span><span id="8a78" class="kc kd hh jy b fi ki kf l kg kh">Growth_all &lt;- read.csv("Growth_all.csv")<br/>str(Growth_all)<br/>Growth_all$Treat&lt;-as.factor(Growth_all$Treat)<br/>Growth_wide&lt;-reshape(Growth_all, <br/>                     idvar = c("Pen", "Treat","Block"), <br/>                     timevar = "Week", <br/>                     direction = "wide")<br/>#### Exploratory summaries ####<br/># Not the same baseline growth<br/>Growth_melt&lt;-ddply(Growth_all, c("Week", "Treat"), summarise,<br/>      N = sum(!is.na(BW)),<br/>      Mis = sum(is.na(BW)),<br/>      Mean = round(mean(BW, na.rm=T),3),<br/>      Median = round(median(BW, na.rm=T),3),<br/>      SD = round(sd(BW, na.rm=T),3),<br/>      SE = round(sd(BW, na.rm=T) / sqrt(N),5),<br/>      LCI = round(Mean - (2*SE),3), <br/>      HCI = round(Mean + (2*SE),3))</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es kj"><img src="../Images/96733657d6115ea1eac680bcfe7b9f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*6KXgdmMMbyaZgCSxpQGnlw.png"/></div></figure><p id="a6a6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当您在纵向数据集中寻找治疗差异时，这也意味着您正在寻找一种方法来处理该数据集中的协方差矩阵。纵向数据是嵌套数据，嵌套数据具有互相关性。这些互相关减少了研究的有效样本量，因此需要建模。不考虑它们意味着你会低估数据中的标准误差，发现不正确的p值(<a class="ae js" rel="noopener" href="/mlearning-ai/inference-estimates-p-values-and-confidence-limits-a-frequentist-approach-acdd45d94bd5">，这与对p值的严厉批评是分开的</a></p><p id="2ba6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们来看看可以从原始数据本身推导出的相关和协方差矩阵。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="f522" class="kc kd hh jy b fi ke kf l kg kh">cormatrix&lt;-as.data.frame(cor(Growth_wide[,4:25])) # lot of autocorrelation<br/>covmatrix&lt;-as.data.frame(cov(Growth_wide[,4:25])) # Covariance not homogenous --&gt; heterogeneity of variance <br/>cor&lt;- rcorr(as.matrix(Growth_wide[,4:25]))<br/>corrplot(cor$r)<br/>chart.Correlation(Growth_wide[,4:25], histogram=TRUE, pch=19)<br/>plotCov(cov(Growth_wide[,4:25]))</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kn"><img src="../Images/46ee7baa7429fccc259269996829c826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqKy4a5hH4-qEuwdCSar2A.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">All positive correlations.</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kn"><img src="../Images/ad22fc17234822ae0d346d29338f5c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zCENfOaXAyogFavxBBmAHg.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">A lot of positive correlations.</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kw"><img src="../Images/f5da8f23cda8fade380ce298f3f36be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qd2PWmysjF_F2y9Ps5CLqw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">And the same here.</figcaption></figure><p id="61f0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，当你有一个包含纵向数据的数据集时，你可以期待一个巨大的协方差/相关矩阵。重量取决于所选择的测量时间，因此也取决于观测时间之间的距离。</p><p id="14c1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们用图表表示这些数据。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="7eab" class="kc kd hh jy b fi ke kf l kg kh">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,18,20,22,24,26,28,30))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 400, by = 50))<br/>ggplot(Growth_all, aes(x=Week, y=BW, group=Pen, colour=Treat))+<br/>  myx+<br/>  myy+<br/>  geom_line() +<br/>  stat_summary(aes(group=Treat), fun.y=mean, geom="point", size=3.5)+<br/>  stat_summary(aes(group=Treat), fun.y=mean, geom="line", lwd=1.5)<br/>## Growth boxplot<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,18,20,22,24,26,28,30))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 400, by = 50))<br/>ggplot(Growth_all, aes(x=Week, y=BW, group=Week, colour=Treat))+<br/>  myx+<br/>  myy+<br/>  geom_boxplot()<br/>## Growth boxplot - Treatment<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,18,20,22,24,26,28,30))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 400, by = 50))<br/>ggplot(Growth_melt, aes(x=Week, y=Mean, colour=Treat))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=LCI, ymax=HCI, fill=Treat), alpha=0.1)<br/>## Growth lineplot<br/>sjp.poly(Growth_all$BW, Growth_all$Week, 1)<br/>sjp.poly(Growth_all$BW, Growth_all$Week, 2)<br/>sjp.poly(Growth_all$BW, Growth_all$Week, 3)</span></pre><div class="jt ju jv jw fd ab cb"><figure class="kx kk ky kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/c5b099b1d089544a6211a4fd908334c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*KYCM2-lAqpo9xESlhB9X1Q.png"/></div></figure><figure class="kx kk ld kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/a981585f973a88561b6ac37cc17c74fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*Tgy0p7n_f4Uu8Nf8R1QMOA.png"/></div></figure><figure class="kx kk ld kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1ff8b368950193cc390472f2f76b691c.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*0GnCCpWtiJxe26z9BTQEGQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx le di lf lg">As time passes on the variance increases which is a function of the weight increase.</figcaption></figure></div><div class="ab cb"><figure class="kx kk lh kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/7354d4f215591846ae82dbaf32abac8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*E__UuzkiJpHGvs82alB0gA.png"/></div></figure><figure class="kx kk li kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/5b5d6b3ccb210ae5d555bf6fe13a4ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*1cJAZ0Q6FLGwG8_ckqYOlQ.png"/></div></figure><figure class="kx kk lj kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f19d4ecf4d0bb22017cf752fb01e06cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*daK50paeqkLeaPxdxt61Wg.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx lk di ll lg">Can be fitted with a straight line, although a quadratic is better. Cubic is overkill.</figcaption></figure></div><p id="5e72" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在我们可以开始制作我们的第一套模型，单独评估它们并进行比较，以了解重要的预测因素。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3f80" class="kc kd hh jy b fi ke kf l kg kh">mix1&lt;-lmer(BW~ns(Week,2)+Treat+(ns(Week,2)|Block), data=Growth_all) # perfect correlation intercept + Week <br/>summary(mix1)<br/>plot(mix1)<br/>mix0&lt;-lmer(BW~Week+Treat+(Week|Block), data=Growth_all, REML=FALSE)<br/>mix1&lt;-lmer(BW~ns(Week,2)+Treat+(ns(Week,2)|Block), data=Growth_all, REML=FALSE)<br/>mix2&lt;-lmer(BW~ns(Week,2)*Treat+(ns(Week,2)|Block), data=Growth_all, REML=FALSE)<br/>anova(mix1, mix2) # no treatment interaction<br/>mix3&lt;-lmer(BW~ns(Week,3)+Treat+(ns(Week,3)|Block), data=Growth_all, REML=FALSE)<br/>anova(mix1,mix3) # not significant change in loglik and devianc<br/>anova(mix0, mix1)<br/>mix4&lt;-lmer(BW~ns(Week,2)+Treat+(ns(Week,2)|Block/Pen), data=Growth_all, REML=FALSE)<br/>summary(mix4) # huge variance for Week<br/>anova(mix1, mix4) # does show a way better fit but not sure if okay <br/>mix5&lt;-lmer(BW~ns(Week,2)+Treat+(ns(Week,2)|Block:Pen), data=Growth_all, REML=FALSE)<br/>anova(mix4, mix5) # huge variance for Week<br/>summary(mix5)</span><span id="1ebb" class="kc kd hh jy b fi ki kf l kg kh">anova(mix1,mix2,mix3,mix4,mix5)<br/>ICtab(mix1,mix2,mix3,mix4,mix5)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es lm"><img src="../Images/e918a14028d0ef8e90f75f209c15bfc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U1jVlEgkK67t_1Iaz43H2w.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">First mixed model shows the fan of the residuals hinting at less predictability as the animal grows.</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ln"><img src="../Images/88aeeba45d2fb360af86f40acf96b1d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W0irmmOwnvRtUjXhreN46g.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Mix5 is the best model according to the AIC</figcaption></figure><p id="9f17" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们也应用一下<strong class="iy hi"> lme </strong>软件包，我发现它非常适合于<strong class="iy hi"> lme4 </strong>软件包。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="f88f" class="kc kd hh jy b fi ke kf l kg kh">Growth_group_pen&lt;-groupedData(BW~Week|Pen,<br/>                      data=Growth_all,<br/>                      FUN=mean)<br/>Growth_group_blockpen&lt;-groupedData(BW~Week|Block/Pen,<br/>                              data=Growth_all,<br/>                              FUN=mean)<br/>Growth_group_block&lt;-groupedData(BW~Week|Block,<br/>                                   data=Growth_all,<br/>                                   FUN=mean)<br/>mix1_nlme_pen&lt;-lme(BW~ns(Week,2)+Treat, <br/>               data=Growth_group_pen,<br/>               random=~ns(Week,2),<br/>               method="ML", <br/>               control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>summary(mix1_nlme_pen)<br/>plot(mix1_nlme_pen); plot(mix1)<br/>plot(augPred(mix1_nlme_pen, level = 0:1))</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es lo"><img src="../Images/00cdcd970980cc3d5d5faa9205b74b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*Bt7D5DNX_lWQekVdRuV0KQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Grouped data to be inserted in the lme model</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es lp"><img src="../Images/fb09de6e7b26025f1690a56b8844f1a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*r5ltEMb1wgnJFhp8oXVKBQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Model summary</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es lq"><img src="../Images/e28b80db59f514ab0a4c69328d89240f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*XGQLQTVSQTrGo_hWQqivsA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Looking better, but the curves are not modeled correctly yet. Could be due to incomplete fixed effects modelling or the error term which I did not model here.</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kw"><img src="../Images/29d012ece9ea86367a116c1dca0945af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zxxkFfVqz7GuF9jYQwMyNA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Predictions look good!</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="b987" class="kc kd hh jy b fi ke kf l kg kh">mix1_nlme_blockpen&lt;-lme(BW~ns(Week,2)+Treat, <br/>                   data=Growth_group_blockpen,<br/>                   random=~ns(Week,2),<br/>                   method="ML", <br/>                   control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>anova(mix1_nlme_pen,mix1_nlme_blockpen) <br/>intervals(mix1_nlme_pen)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es lr"><img src="../Images/49340c6ea1c4ee43cba76d9120a29589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ti4OLDgT_5ekjSxf_BjsTA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">First model is best.</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="d40d" class="kc kd hh jy b fi ke kf l kg kh">plot(acf(resid(mix1_nlme_pen)))<br/>plot(pacf(resid(mix1_nlme_pen))) </span></pre><div class="jt ju jv jw fd ab cb"><figure class="kx kk ls kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ce4c327deec00c5c6e634a1825cde543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*EEWy98iN-Hsn1yEWM1QmHg.png"/></div></figure><figure class="kx kk ls kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1876c7dffca87cb394bc0d4b335fe2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*kuBB_HZosb5Zrh3KWNb2kA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx lt di lu lg">Autocorrelation seems to be at the boundary. It is there, but not blatantly clear.</figcaption></figure></div><p id="4abc" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对自相关进行统计测试的一种方法是在标准线性回归中使用<a class="ae js" href="https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic" rel="noopener ugc nofollow" target="_blank"> Durbin Watson测试</a>，我将在下面做这个测试。该测试所做的是寻找一个值与其滞后值之间的显著相关性。这就是自相关。检验的零假设是没有自相关。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="e4aa" class="kc kd hh jy b fi ke kf l kg kh">fit&lt;-lm(BW~Week, data=Growth_all)<br/>summary(fit)<br/>dbtest&lt;-durbinWatsonTest(fit, max.lag=10, simulate=TRUE, method="resample")<br/>dbtest</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es lv"><img src="../Images/2c62bb475584c8be7b68a66032f51260.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Jse5UHkEtN8m_lIGZeNE3Q.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Significant values indicate the presence of autocorrelation.</figcaption></figure><p id="5d58" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">AR(rho)矩阵是最简单但通常非常适合在您的模型中实现来处理自相关的协方差矩阵。它是一个相关矩阵，假设两个相邻时间点之间的相关性为ρ值。在这里，我指定0.9。这意味着相关矩阵看起来像这样:</p><ol class=""><li id="1ce1" class="lw lx hh iy b iz ja jc jd jf ly jj lz jn ma jr mb mc md me bi translated">时间1 —时间2 = 0.9</li><li id="e2a9" class="lw lx hh iy b iz mf jc mg jf mh jj mi jn mj jr mb mc md me bi translated">时间1 —时间3 = 0.9*09</li><li id="517d" class="lw lx hh iy b iz mf jc mg jf mh jj mi jn mj jr mb mc md me bi translated">时间1 —时间4 = 0.9*0.9*0.9</li><li id="2d2a" class="lw lx hh iy b iz mf jc mg jf mh jj mi jn mj jr mb mc md me bi translated">时间2 —时间3 = 0.9</li></ol><p id="d34b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">等等。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="574a" class="kc kd hh jy b fi ke kf l kg kh">ARmatrix &lt;- corAR1(0.9,form=~Week|Pen) <br/>ARmatrix &lt;- Initialize(ARmatrix, data=Growth_all) <br/>cor_ARmatrix&lt;-as.data.frcorMatrix(ARmatrix)<br/>str(cor_ARmatrix)<br/>par(mfrow = c(2, 2))<br/>heatmap(cor_ARmatrix$`602`, main="Correlation Matrix for cow 602")</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mk"><img src="../Images/16ee4f4e1c7804e21bc96296b0eec99b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8TcQsdmT8ORis_iMH3wJQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">AR(rho)n correlation matrix as applied to all Cows. If you want to have a different correlation matrix, you can chose for a heterogenous variant which releases the assumption of distance = correlation.</figcaption></figure><p id="b586" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们在混合模型中应用，找到不同的结构，允许或不允许异质性。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5e26" class="kc kd hh jy b fi ke kf l kg kh">mix2_nlme_pen&lt;-lme(BW~ns(Week,2)+Treat, <br/>               data=Growth_group_pen,<br/>               random=~ns(Week,2),<br/>               correlation=corAR1(0.8,form=~1),<br/>               method="ML", <br/>               control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>mix2_nlme_blockpen&lt;-lme(BW~ns(Week,2)+Treat, <br/>                   data=Growth_group_blockpen,<br/>                   random=~ns(Week,2),<br/>                   correlation=corAR1(0.8,form=~Week),<br/>                   method="ML", <br/>                   control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>mix2.1_nlme_blockpen&lt;-lme(BW~ns(Week,2)+Treat, <br/>                        data=Growth_group_blockpen,<br/>                        random=~0+Week,<br/>                        correlation=corAR1(0.8,form=~Week),<br/>                        method="ML", <br/>                        control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>mix2.2_nlme_pen&lt;-lme(BW~ns(Week,2)+Treat+Block, <br/>                        data=Growth_all,<br/>                        random=~0+Week|Pen,<br/>                        correlation=corAR1(0.8,form=~Week|Pen),<br/>                        method="ML", <br/>                        control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>mix2.3_nlme_pen&lt;-lme(BW~ns(Week,2)+Treat+Baseline+Block, <br/>                        data=Growth_group_blockpen,<br/>                        random=~0+Week,<br/>                        correlation=corAR1(0.95, form=~Week),<br/>                        method="ML", <br/>                        control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>mix2.4_nlme_pen&lt;-lme(BW~ns(Week,2)+Treat+Baseline+as.factor(Block), <br/>                        data=Growth_group_pen,<br/>                        random=~0+Week,<br/>                        correlation=corAR1(0.95, form=~Week),<br/>                        method="ML", <br/>                        control=lmeControl(opt="optim", maxIter=10000, msMaxIter = 1000))<br/>mix2.5_nlme_pen&lt;-lme(BW~ns(Week,2)+Treat+Baseline+as.factor(Block), <br/>                     data=Growth_group_pen,<br/>                     random=~0+Week,<br/>                     correlation=corAR1(0.95, form=~Week),<br/>                     method="ML", <br/>                     control=lmeControl(maxIter=10000, msMaxIter = 1000))<br/>mix2.6_nlme_pen&lt;-lme(BW~ns(Week,3)+Treat+Baseline+as.factor(Block), <br/>                     data=Growth_group_pen,<br/>                     random=~0+Week,<br/>                     correlation=corAR1(0.95, form=~Week),<br/>                     method="ML", <br/>                     control=lmeControl(maxIter=10000, msMaxIter = 1000))<br/>mix2.7_nlme_pen&lt;-lme(BW~ns(Week,3)+Treat+Baseline, <br/>                     data=Growth_group_pen,<br/>                     random=~0+Week,<br/>                     correlation=corAR1(0.95, form=~Week),<br/>                     method="ML", <br/>                     control=lmeControl(maxIter=10000, msMaxIter = 1000))<br/>anova(mix2.3_nlme_pen,mix2.5_nlme_pen, mix2.6_nlme_pen, mix2.7_nlme_pen) <br/>plot(mix2.4_nlme_pen)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es ml"><img src="../Images/c358d803dbee2b9f3f86e4e1eb601769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*g00yBDkyG_jAxhMA--Rt3A.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">The <strong class="bd mm">mix2.6</strong> model seems to be the best, but the <strong class="bd mm">mix2.7</strong> has the lowest AIC. Choises need to be made. I chose the last model but it is debatable.</figcaption></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mn"><img src="../Images/cdf2fff743eb446c56eb9d08a1179e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iF5kCTY6OUr9KqQGMeMmZg.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">However, the plot is still not how I want it to be.</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="a5cc" class="kc kd hh jy b fi ke kf l kg kh">plot(augPred(mix2.7_nlme_pen, level=0:1), grid=T)<br/>plot(augPred(mix2.4_nlme_pen),aspect="xy",grid=T)<br/></span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mo"><img src="../Images/9998f9dd551d6bf4aced2858b77d0237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*znFM2ORuJjLePYJQuauAmA.png"/></div></div></figure><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mo"><img src="../Images/b274b81e5dac111d10f80961229eff00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tHWGOuoHEWLKAJbmauX-xA.png"/></div></div></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="bfd8" class="kc kd hh jy b fi ke kf l kg kh">pred&lt;-augPred(mix2.4_nlme_pen, level=0:1)<br/>anova(mix2.2_nlme_pen,mix2.4_nlme_pen) # even worse fit specyifying block<br/>summary(mix2.4_nlme_pen)<br/>plot(acf(resid(mix2.7_nlme_pen)))<br/>plot(pacf(resid(mix2.7_nlme_pen)))<br/>intervals(mix2.7_nlme_pen)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es mp"><img src="../Images/56d677cc629634014b9fc66e263b99aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*RxQoXTzlNbJF9Zqcget-og.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx"><strong class="bd mm">Mix2.2</strong> is best.</figcaption></figure><p id="214b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">自相关图对模型的误差部分建模非常有帮助。<a class="ae js" href="https://towardsdatascience.com/significance-of-acf-and-pacf-plots-in-time-series-analysis-2fa11a5d10a8" rel="noopener" target="_blank">有两种类型的图</a>:</p><ol class=""><li id="e417" class="lw lx hh iy b iz ja jc jd jf ly jj lz jn ma jr mb mc md me bi translated">ACF:ACF测量并绘制一个时间序列中的数据点与为不同滞后长度测量的该序列的先前值之间的平均相关性。例如，第一个滞后时的相关性测量为时间t时测量的时间序列值与时间t1时测量的所有序列值之间的相关性。第二个滞后的相关性测量时间t测量的时间序列值与时间T2测量的所有序列值之间的相关性。</li><li id="731b" class="lw lx hh iy b iz mf jc mg jf mh jj mi jn mj jr mb mc md me bi translated">pACF:PACF类似于ACF，除了每个相关控制一个较短滞后长度的观测值之间的任何相关。因此，第一个滞后时的ACF和PACF值是相同的，因为两者都测量时间t的数据点与时间t1的数据点之间的相关性。然而，在第二个滞后时，在控制了时间t的数据点与时间t1的数据点之间的相关性之后，PACF测量时间t的数据点与时间T2的数据点之间的相关性。</li></ol><div class="jt ju jv jw fd ab cb"><figure class="kx kk ls kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/7b4619a350ed225cf87d5462e726e7da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*-ynEa1Ii_ttdsALi9pbq2g.png"/></div></figure><figure class="kx kk ls kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/05c2fdc58b9453c07e0984a3ad427bc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sD6A-7eYSOz6y-Fr7_k6tw.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx lt di lu lg">ACF does not look well, pACF looks good. So, what to do here?</figcaption></figure></div><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es mq"><img src="../Images/770f7836b92815e6d51febffd19896d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*DzyamRYSmP50FwE_fE-jkg.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Estimates seem to be O.K.</figcaption></figure><p id="4958" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们更深入地研究这个模型，对它进行诊断。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="aad5" class="kc kd hh jy b fi ke kf l kg kh">plot(ranef(mix2.4_nlme_pen))<br/>qqnorm(residuals(mix2.7_nlme_pen))<br/>qqline(residuals(mix2.7_nlme_pen))<br/>plot(augPred(mix2.4_nlme_pen))<br/>pairs(mix2.3_nlme_pen)<br/>vario&lt;-Variogram(mix2_nlme_blockpen)<br/>plot(vario)<br/>plot(fitted(mix2.7_nlme_pen), residuals(mix2.7_nlme_pen)); abline(h=0)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mr"><img src="../Images/ef5b52b5ab7b71c8c6712af17f1c0aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AWKNbX3GYzY5Ru6IumepMw.png"/></div></div></figure><div class="jt ju jv jw fd ab cb"><figure class="kx kk ms kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0157857c34c2548e10c30a10ae8dc215.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*DF8SzaZKgIGZL_0TekqqXQ.png"/></div></figure><figure class="kx kk ms kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ea9f9fcdadce127cfe144c05c12dc635.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*6xdJdDVnj7hOAAL6GG6s0w.png"/></div></figure><figure class="kx kk ms kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/06c88c8b1a4305d83d2c8cb3a283f0d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*52ZPr4OjcCM6jn-TuWDurg.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx mt di mu lg">Looks goed, except the beginning. In fact, the spread in the middle and the end of the last plot is not worrying byut the beginning is, which is most likely due to me using a baseline value. Using a baseline value fixes all other values at the first point which often causes more harm than good when you want to model mixed-level data.</figcaption></figure></div><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3cfc" class="kc kd hh jy b fi ke kf l kg kh">plot(compareFits(coef(mix2.4_nlme_pen), coef(mix2.5_nlme_pen)))</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mv"><img src="../Images/a5e5226a2b4da530027f68abc6c3d149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GPERCpv9TO4bI0vtEi03yw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Well, what dom we have here?? I am not even sure HOW to interpret this.</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3e16" class="kc kd hh jy b fi ke kf l kg kh">VarCorr(mix2.2_nlme_pen)<br/>VarCorr(mix2.3_nlme_pen)<br/>VarCorr(mix2.4_nlme_pen)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es mw"><img src="../Images/8703d7a35d3f533f2f41373b8c3099a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*7CPvF8gQorM289DvTm4eXQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Covariance matrix on the error applied across different models</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="02a3" class="kc kd hh jy b fi ke kf l kg kh">mix2.7_ranef&lt;-ranef(mix2.7_nlme_pen,augFrame = T, level=1) # works for levels 1,2,3 (if in model present) but not 0<br/>plot(mix2.7_ranef, grid=TRUE)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mn"><img src="../Images/8c9b6c0a9e5a9e0811a8110d58cc7e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fuJmE_CyFO3d5Xx_0tITOA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">For sure, the random effect of Pen is warranted.</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="da0b" class="kc kd hh jy b fi ke kf l kg kh"># Shows variance per Pen / Block<br/>bwplot(Growth_all$Pen ~ resid(mix2.7_nlme_pen)) <br/>bwplot(Growth_all$Block ~ resid(mix2.7_nlme_pen))</span></pre><div class="jt ju jv jw fd ab cb"><figure class="kx kk mx kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1993adc752cf9aea2f84c95fb164a46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*0EOwXskhdHY7-T5QnTksGA.png"/></div></figure><figure class="kx kk my kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/c89c1ef2ed4f8c11b84208dfb88af60d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*uZ0vT_I7Q5f2eFZFQA95Ug.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx mz di na lg">The models <strong class="bd mm">mix2.7</strong> seems to handle the data well across pens and blocks.</figcaption></figure></div><p id="c53b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">具体检查嵌套对于随机效应是否必要的一种方法是建立嵌套模型，并让bootstrapping模拟似然比测试。这里，我正在检查一个具有相同固定效果和不同随机效果的模型:</p><ol class=""><li id="4a4d" class="lw lx hh iy b iz ja jc jd jf ly jj lz jn ma jr mb mc md me bi translated"><em class="nb">(0+周|块)</em>+<em class="nb">(0+周|笔:块)</em></li><li id="cd8e" class="lw lx hh iy b iz mf jc mg jf mh jj mi jn mj jr mb mc md me bi translated"><em class="nb">(0+周|笔:块)</em></li><li id="e0b3" class="lw lx hh iy b iz mf jc mg jf mh jj mi jn mj jr mb mc md me bi translated"><em class="nb">(0+周|块)</em></li></ol><p id="4894" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如您所见，模型是嵌套的。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="be8d" class="kc kd hh jy b fi ke kf l kg kh">(nc &lt;- detectCores())<br/>cl &lt;- makeCluster(rep("localhost", nc))<br/>mA&lt;-lmer(BW~ns(Week,3)+Treat+(0+Week|Block)+(0+Week|Pen:Block), data=Growth_all, REML=TRUE)<br/>m.block&lt;-update(mA,.~.-(0+Week|Pen:Block))<br/>m.0&lt;-update(mA,.~.,-(0+Week|Block))<br/>anova(mA, m.block, m.0)<br/>exactRLRT(m.block) </span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es nc"><img src="../Images/65099b6d300cbc8da34ac9f09f6a5aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JaAVSjSeWkgNFg4U5QkEdw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">And sore sure, some are better than others. Here, the <strong class="bd mm">mA </strong>is better then <strong class="bd mm">m.Block</strong>, and <strong class="bd mm">mA </strong>equals <strong class="bd mm">m.0</strong>.</figcaption></figure><p id="89ec" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但这是一个非常适合的模型。那么，如果我坚持使用我的<strong class="iy hi"> m.block </strong>模型，而是包含一个基线，会怎么样呢？是的，选择并不容易，对许多人来说，更容易理解一个包含基线协变量而不是复杂误差成分的模型。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3538" class="kc kd hh jy b fi ke kf l kg kh"># Random blocks or baseline covariate?<br/>blockvar&lt;-lmer(BW~ns(Week,3)+Treat+(0+Week|Pen:Block), data=Growth_all, REML=FALSE)<br/>baselinecovar&lt;-lmer(BW~ns(Week,3)+Treat+Baseline+(0+Week|Pen), data=Growth_all, REML=FALSE)<br/>anova(blockvar, baselinecovar) # best to have a baseline covariate<br/>plot(blockvar)<br/>plot(baselinecovar)<br/>VarCorr(baselinecovar)<br/>VarCorr(blockvar)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es nd"><img src="../Images/baee6e64e83d5585fb8bcfd147120c80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*97dNhN8getKkTYJkvd0QJw.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">The baseline model performs better.</figcaption></figure><div class="jt ju jv jw fd ab cb"><figure class="kx kk ls kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ba9abfd87ce3ed14474eaddb60d453c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*WOntTFjOKiDGVreF4QOG9Q.png"/></div></figure><figure class="kx kk ls kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/60df6f7be47cc7293c9b8dbd1e9acfa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QP3pGDrd1Wwdy37jm9T1_A.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx lt di lu lg">But the <strong class="bd mm">blockvar </strong>model has a much much better residual plot. The <strong class="bd mm">baselinecovar </strong>model has that weird beginning which happens if you squeeze your data to an artificial point via a baseline predictor.</figcaption></figure></div><p id="f436" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，我相信我不得不选择基线模型，因为它更容易被接受，但我不能说当时的选择让我感到满意。让我们看看这些预测是否有意义。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="cda9" class="kc kd hh jy b fi ke kf l kg kh">## Cow specific predictions<br/>newdat&lt;-expand.grid(Pen=unique(Growth_all$Pen),<br/>                      Block=unique(Growth_all$Block),<br/>                      Week=as.numeric(1:35),<br/>                      Baseline=unique(Growth_all$Baseline),<br/>                    Treat=unique(Growth_all$Treat))<br/>dim(newdat)<br/>Pred&lt;-predict(mix2.7_nlme_pen, newdata = newdat, level = 0:1 )<br/>newdat$pred.fix&lt;-Pred$predict.fixed<br/>newdat$pred.pen&lt;-Pred$predict.Pen<br/>newdat$idtreat&lt;-paste(newdat$Pen,newdat$Treat)</span><span id="cea8" class="kc kd hh jy b fi ki kf l kg kh">## Plot<br/>myx&lt;-scale_x_continuous(breaks=seq(1,35,by=1))<br/>myy&lt;-scale_y_continuous(breaks= seq(0, 400, by = 25))<br/>ggplot(newdat, aes(x=Week, colour=Treat))+<br/>  myx+<br/>  myy+<br/>  labs(title = "Growth(BW) over 35 Weeks", y="BW", x="Time(Week)")+<br/>  theme_bw()+<br/>  stat_summary(aes(y=pred.pen, group=idtreat),fun.y=median, geom="line", lwd=0.4, alpha=0.4)+ <br/>  stat_summary(aes(y=pred.fix, group=Treat),fun.y=median, geom="line", lwd=1)+<br/>  stat_summary(aes(y=pred.fix, group=Treat),fun.y=median, geom="point", lwd=2)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mv"><img src="../Images/52c8a06f135c46b34c731ace33abf35f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sd9XutzmU7AePgH1zfjV9w.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">They do, but without a solid error component the end of the model is going to be bad.</figcaption></figure><p id="4461" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我已经说过，我对线性混合模型同时使用了<strong class="iy hi"> lme </strong>和<strong class="iy hi"> lme4 </strong>包。<strong class="iy hi"> lme </strong>包比较老，但是在通过方差-协方差矩阵模拟误差项的形式上有更多的功能。至少，有预功能的可能性。</p><p id="c899" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以，让我们在<strong class="iy hi"> lme </strong>运行一个模型，有一个模拟误差，在<strong class="iy hi"> lme4 </strong>没有模拟误差。另一个不同之处是，<strong class="iy hi"> lme4 </strong>模型有一个嵌套的随机效应，看看我能否弥补在误差项中对互相关建模的不足。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="833e" class="kc kd hh jy b fi ke kf l kg kh">mix2.7_lme4_pen&lt;-lme4::lmer(BW~ns(Week,3)+Treat+Baseline+(0+Week|Pen), data=Growth_all, REML=FALSE)<br/>mix2.7_nlme_pen&lt;-lme(BW~ns(Week,3)+Treat+Baseline, <br/>                     data=Growth_group_pen,<br/>                     random=~0+Week,<br/>                     correlation=corAR1(0.95, form=~Week),<br/>                     method="ML", <br/>                     control=lmeControl(maxIter=10000, msMaxIter = 1000))<br/>VarCorr(mix2.7_nlme_pen)<br/>VarCorr(mix2.7_lme4_pen)</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es ne"><img src="../Images/a53f15604e07f93826c1e5287a05be83.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*Ck3M2fx9cbbBtmiX1siNGw.png"/></div></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="c7ff" class="kc kd hh jy b fi ke kf l kg kh">plot(mix2.7_nlme_pen)<br/>plot(mix2.7_lme4_pen)</span></pre><div class="jt ju jv jw fd ab cb"><figure class="kx kk nf kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1f91c7d3f70437cf686edfa623e2c4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*NV9S7D50CBgX_4NoVPYa9Q.png"/></div></figure><figure class="kx kk ng kz la lb lc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/04fa99321f8e9cca2356d65d321535b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*6DnhD_Esadve7Pm58Pk9KA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx nh di ni lg"><strong class="bd mm">lme </strong>shows slightly better residuals</figcaption></figure></div><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="9941" class="kc kd hh jy b fi ke kf l kg kh">par(mfrow=c(2,2))<br/>plot(acf(resid(mix2.7_nlme_pen)))<br/>plot(acf(resid(mix2.7_lme4_pen)))<br/>plot(pacf(resid(mix2.7_nlme_pen)))<br/>plot(pacf(resid(mix2.7_lme4_pen)))</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es nj"><img src="../Images/fffc5250e919d7c96f2f924a5088406e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WZ6pV_5jYqvPogLgYKVtUw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">lme and lme4 show similar results, although I like the results of the lme4 better.</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3f30" class="kc kd hh jy b fi ke kf l kg kh">AIC(mix2.7_lme4_pen)<br/>AIC(mix2.7_nlme_pen) </span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div class="er es nk"><img src="../Images/843a3121885f74795707dd31fde37a89.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*xiMOPMXA7UUf6P7se2-emQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">lme model is better, by far.</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="f34d" class="kc kd hh jy b fi ke kf l kg kh">predlme4&lt;-predict(mix2.7_nlme_pen, newdat=newdat)<br/>ggplot(Growth_all, aes(x=Week, y=BW, colour=Treat))+<br/>  theme_bw()+<br/>  geom_point(col="grey80")+<br/>  labs(title = "Growth(BW) over 35 Weeks", y="BW", x="Time(Week)")+<br/>  stat_summary(dat=newdat, aes(y=pred.pen, group=idtreat),fun=median, geom="line", lwd=0.4, alpha=0.4)+<br/>  stat_summary(dat=newdat, aes(y=pred.fix, group=Treat, colour="nlme"),fun=median, geom="line", lwd=1)+<br/>  stat_summary(dat=newdat, aes(y=fitlme4, group=Treat, colour="lme4"),fun=median, geom="line", lwd=1)+<br/>  scale_colour_manual(name="Method", values=c(nlme="blue", lme4="red"))</span></pre><figure class="jt ju jv jw fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es nl"><img src="../Images/9dcbd69d62b81c6300dd2e9abf839b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTo5eVKILUobqFL0iurtNQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">However, predictions on the fixed term look very much the same.</figcaption></figure><p id="d258" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以，这是一个反刍动物成长模型的帖子。希望你喜欢。如果你有问题，请告诉我！</p><div class="nm nn ez fb no np"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hi fi z dy nu ea eb nv ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">medium.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od kl np"/></div></div></a></div></div></div>    
</body>
</html>
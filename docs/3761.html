<html>
<head>
<title>Running Tensorflow Model on Edge with TensorRT for Fast Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorRT在Edge上运行Tensorflow模型进行快速推理</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/running-tensorflow-model-on-edge-with-tensorrt-for-fast-inference-4dcad300a523?source=collection_archive---------1-----------------------#2022-10-18">https://medium.com/mlearning-ai/running-tensorflow-model-on-edge-with-tensorrt-for-fast-inference-4dcad300a523?source=collection_archive---------1-----------------------#2022-10-18</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><div class=""/><div class=""><h2 id="f6e8" class="pw-subtitle-paragraph ii hk hl bd b ij ik il im in io ip iq ir is it iu iv iw ix iy iz dx translated">关于Linux环境下TensorRT的设置、量化和运行推理</h2></div><figure class="jb jc jd je fd jf er es paragraph-image"><div role="button" tabindex="0" class="jg jh di ji bf jj"><div class="er es ja"><img src="../Images/63aa6ef8fdd3884646302a633c8f56ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJSj5HQbXD3-bS31ojXmgw.jpeg"/></div></div><figcaption class="jm jn et er es jo jp bd b be z dx">Image by <a class="ae jq" href="https://unsplash.com/@chuttersnap" rel="noopener ugc nofollow" target="_blank">CHUTTERSNAP</a> on <a class="ae jq" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8197" class="pw-post-body-paragraph jr js hl jt b ju jv im jw jx jy ip jz ka kb kc kd ke kf kg kh ki kj kk kl km he bi kn translated">在实时人工智能模型部署过程中，模型预测(或推理)的速度至关重要。为了确保无缝的用户体验，苹果Siri的语音引擎不能永远破译一个…</p></div></div>    
</body>
</html>
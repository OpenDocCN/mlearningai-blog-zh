# 人在回路中或在回路中不是一个银弹。评估它们的有效性

> 原文：<https://medium.com/mlearning-ai/human-in-the-loop-or-on-the-loop-is-not-a-silver-bullet-evaluate-their-effectiveness-82f37835d765?source=collection_archive---------4----------------------->

## 人在回路或人在回路的有效性评估框架

![](img/7f8ceaeda0f1f4078c8441ad8dff0ea5.png)

<a href=’[https://www.freepik.com/vectors/process'](https://www.freepik.com/vectors/process')>Process vector created by freepik — [www.freepik.com](http://www.freepik.com)</a>

# **语境中的 HTL**

人在回路/回路上(本文称为“HTL”)是一种机制，通过这种机制，人类智能被整合到使用或利用机器学习的采用中，从而支持人类对机器活动/结果的判断。HTL 是关于两个关键因素(1)人机交互的设计和(2)决策的自主性。随着机器学习的日益采用，与人在回路中/在回路上相关的上述因素有助于(a)确保算法执行的动作的质量，(b)限制算法输出中的假阳性，以及(c)监督算法引起的风险。但是 HTL 模型对于高风险人工智能系统的有效性很难评估。

人在回路/在回路本质上是一种机制，包括在建模决策过程中对人的因素进行充分的模型监督和考虑。通常，在模型决策过程中，人类参与为数据提供适当的标签，提供对模型预测或分类的边缘情况的洞察，并测试或验证模型的正确性。

一个组合的人-自动化系统执行一系列四个连续的信息处理功能:获取信息，分析信息，根据信息决定采取什么行动，以及执行行动[【这里】](https://ieeexplore.ieee.org/document/844354)。随着自治系统的崛起，HTL 被认为是一个重要的风险缓解器(从道德和法律的角度来看)，甚至是一个更公平范式的方法[【这里】](https://www.researchgate.net/publication/320582722_Viewpoint_Human-in-the-loop_Artificial_Intelligence)和 [h](http://cardozolawreview.com/wp-content/uploads/2018/08/CROOTOF.36.5.pdf) ere】。2020 年和 2021 年(Arxiv 上)发表的大多数包含“人在回路中/在回路中”的研究论文都在研究 HTL，将其作为更高精度、更好预测和更好更有效模型的推动者。

# **HTL 的有效性**

HTL 在算法决策中的有效性，具体来说，高风险人工智能可能会受到 2 个关键问题的影响。(a)以前的研究表明，卷入 HTL 的人可能通过他们的决定[ [此处](https://scholar.harvard.edu/files/19-fat.pdf) ] & [ [此处](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3316266) ]加剧种族和社会群体之间的差距。(b)此外，并不是在所有的算法决策点，人在回路中或回路上的动作可能是有效的。这是因为我们作为人类可能具有的固有局限性，包括人类的监督可能是(a)橡皮图章式的自动决策，(b)放大自动化偏见，以及(c)模糊责任，将算法错误和偏见归咎于人类[ [此处](https://slate.com/technology/2021/06/human-oversight-artificial-intelligence-laws.html) ]。

以上阐明了 HTL 的有效性高度依赖于两个因素，即(1)HTL 在模型生命周期中的适当性和(2)机会、意愿、主观经验和参与 HTL 的人的能力。HTL 的适当性取决于其应用的具体用例及其潜在的业务环境。例如，参与 HTL 的人类的监督能力取决于数据的可用性、用可用信息得出结论的能力，以及在人工智能系统原始预测的背景下跟踪此类决定的后果的机制。类似地，人的主观经验和能力来解释和做出上下文感知决策或行动是至关重要的。这适用于履行其角色职责和临时职责的情况[ [此处为](https://arxiv.org/abs/1810.12644) ]。

从过去的研究中获得的经验展示了与 HTL 相关的以下见解:

*   将人放入循环中并不能保证人的作用是有意义的。这可能在人的角色责任和他们的因果责任之间造成差异，也可能使他们遭受不公正的法律措施和心理负担[ [此处](https://arxiv.org/abs/1810.12644) ]。
*   行为经济实验研究(任务:驾驶无人驾驶飞行器)表明，HTL 的人类效率低下是因为他们对算法结果的过度自信或不自信[ [此处](https://arxiv.org/pdf/2007.15869.pdf) ]。
*   为 HTL 考虑而产生的结果的呈现风格会影响人类的行动或决策。框架和信息也影响人类在涉及道德判断的决策上的行为[ [此处](https://arxiv.org/pdf/1911.03020.pdf) ]。
*   仅仅依靠 ML 专家和从业者的直觉来捕捉相关的细微差别可能是不充分和无效的[ [此处](https://arxiv.org/pdf/1911.03020.pdf) ]。
*   缺乏对人的权威，限制了检查事实的机会(特别是在不透明或模糊的过程场景中。例如，缺乏从传统来源之外的来源获得有关选定应用的更多信息的权限或访问权)或强调概率阈值的不相关性是 HTL [ [此处为](https://arxiv.org/abs/1810.12644) ]效果不佳的主要原因。
*   责任测量受到人工智能系统和人的能力评估水平(主观)的显著影响。责任测量的研究是基于静态效应，而不是基于时间效应。

综上所述，显然有必要考察 HTL 的有效性。虽然[ [此处](https://arxiv.org/abs/1810.12644) ]提出了一种责任衡量的数学方法，但它并没有完全提供一个框架来决定 HTL 的适当性或评估能力或经验。此外，责任测量旨在用于静态效应场景，而非时间效应，包括可用于做出决策的时间、对系统的相对依赖以及影响人机交互的行为效应(例如疲劳效应或学习效应)。此外，在 HTL 因果责任是受机会-意愿-经验-能力-能力(OWECC)的人参与循环的影响。从而表明有必要建立一个全面的框架来确定人类的 HTL 和 OWEC 的适当性。

# **HTL 成效评估框架**

从上述因素来看，HTL 有效性评估需要涵盖 HTL 的设计以及如何从 HTL 的角度呈现结果和见解。正如我们所见，代表权可以影响 HTL 的决策。

这里介绍的框架从这三个方面(设计、计算和表示)检查 HTL 有效性评估。这些维度被进一步划分为特定的过程领域，用于检查有效性。

## A.设计

HTL 的设计应考虑以下因素的影响:(a)数据和模型选择，(b)人员选择，(c)结果处理，以及(d)人员在履行这些职责时的局限性。

数据和模型的选择包括(a)数据的充分性，(b)数据的质量和代表性，(c)因果关系和推论的记录(包括衡量标准的阈值)和(d)算法的选择。这些选择和记录可能导致结果的错误或偏差，并可能影响 HTL 对此类结果的处理方式。有必要考虑到，对于各种各样的用例以及领域应用，感知到的影响程度可能是不同的。例如，因果推理或结构验证的影响程度对于信贷借贷决策阶段的欺诈预测和基于行为生物计量的账户黑客欺诈可能不同。这是由于在这两种情况下，事实真相可以被检验的程度。

为 HTL 角色选择人员是有效性评估的关键部分。在传统的高风险环境中，HTL 角色通常都有详细的选择标准和流程。这些选择标准和流程考虑的方面包括适合性、角色能力、应对压力的准备程度、做出支持更大人类事业的决策的能力以及健康和心理健康。这些旨在为处理此类敏感角色提供整体视角和最低可接受阈值。HTL 成效评估也需要考虑类似的方面，因为 HTL 成效对于人员选拔流程的成效来说是主观的。人员的选择应包括(a)能力评估，(b)领域知识，(c)对算法影响的理解(在特定领域环境中)，(d)压力准备以及(e)对角色中因果责任的认识。

与结果处理相关的过程是 HTL 下各项活动的核心。因此，对它们进行评估对于理解 HTL 的有效性至关重要。对结果的处理通常涉及(a)对结果执行的活动和/或行动，(b)在各种行动之前对结果进行的阈值、分类和过滤，(c)对执行可能有助于决策的活动的资源的访问，以及(d)确定对结果的 HTL 行动的决策因素。监督机会及其行动主要基于数据的可用性、从数据得出的见解以及跟踪此类行动的后果的机制。此外，还应考虑如何利用 HTL 的反馈来更新或强化模型。

人类在许多领域都存在局限性。在 HTL 所扮演角色的背景下审视这些限制是至关重要的。这些限制包括:( a)在决策过程中可以审查信息的程度,( b)对领域知识的认识或限制，以及(c)经验和信念影响决策过程的程度。

## **B .代表权**

如上所述，数据、结果和影响的表示也会对 HTL 产生影响。有必要考虑如何向 HTL 陈述结果，并检查这是否会对他们的决策产生影响。这也是为了检验这些过程是否会导致固有的确认偏差，从而影响 HTL 的有效性。结果表现及其对 HTL 的影响是主观的，可能因领域不同而不同。

影响是指 HTL 根据算法结果做出的决策对最终用户或客户产生的影响。影响表现是关于如何表现影响。陈述不足或虚假陈述会影响 HTL，还可能影响决策的有效性。

如果结果被不正确地评分、错误地标记或者结果在决策或此类决策的更新中有错误，HTL 可能会使算法降级[ [此处](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11746/1174616/Analyzing-a-human-in-the-loops-decisions-for-the-detection/10.1117/12.2586260.short?SSO=1) ]。在评估 HTL 的有效性时，了解这些不同的因素有助于制定使用 HTL 的有意义的方法。

## C.计算

在评估设计和代表因素是否很好地适应 HTL 环境时，有必要在个人和群体水平上对 HTL 性能进行计算评估和监测。它包括(a)基本事实验证和(b)行动的一致性。

基本事实验证是评估 HTL 做出的决定是否符合相关案件事实的一项措施。行动的一致性是指 HTL 个人或集体提议或采取的行动在统计上是否一致。使用计算方法和 HTL 绩效 KPI 考虑这些方面有助于评估 HTL 的有效性。这些可以在 HTL 进程的部署前(测试阶段)和部署后监测阶段进行。

有效性评估对领域、行业和上下文中的用例来说是主观的。

# **评估部署在 HTL 的人员**

在高风险环境中，了解 HTL 个人的能力至关重要。在这种情况下，需要从意愿-经验-能力-能力的角度评估个人的能力(不包括 OWECC 中的第一个方面“机会”)。根据流程中是否需要 HTL 来检查机会。

在评估个人意愿时，特别是在评估算法系统或结果的危害或影响的背景下，这一点很重要。不积极或不愿意参与的人会对人们产生不利影响。

处理高风险角色的经验和处理领域、行业和/或用例的具体经验可以成为评估个人的有用参数。此外，与行业、领域或用例相关的能力，以及处理高风险环境的能力(压力测试)。此外，考虑到结果的数量和频率，执行 HTL 的能力和可以实现的效率也是评估个人所必需的。这些评估应独立于上述 HTL 的成效评估。

# **结论**

HTL 是确保算法系统的结果得到有效监控和管理的重要工具。然而，与任何工具一样，它们的有效性也有局限性。意识到这些局限性对于实施以人为本的 HTL 至关重要。

虽然上面提到的 HTL 成效评估框架是一个很好的指导，但由于在评估各个方面的主观性，它有其局限性。

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
# 机器学习工程师应该知道的 20 大算法

> 原文：<https://medium.com/mlearning-ai/top-20-algorithms-machine-learning-engineer-should-know-4915ef7f4526?source=collection_archive---------0----------------------->

# 介绍

机器学习是当今计算机科学中最令人兴奋和最受欢迎的领域之一。这不仅仅是技术的问题，也是应用先进的算法来解决现实世界的问题。本文将介绍人工智能(AI)和机器学习，使用该领域中最常用的一些算法。

# 逻辑回归

逻辑回归是一种受监督的机器学习算法，用于分类和回归问题。它可用于预测某一事件的概率，如某一患者是否会在给定的时间段内死亡。

逻辑回归使用逻辑函数来模拟自变量和因变量之间的关系。这意味着您使用一组参数来确定每个自变量对因变量的影响程度。然后，根据这些值和其他输入数据(如该患者患有何种疾病)，您可以预测他/她在接受药物 x 治疗后不仅存活而且完全康复的可能性

逻辑回归算法是一种用于分类的判别分析。它可用于预测某一事件的概率，如某一患者是否会在给定的时间段内死亡。逻辑回归使用 logit 函数来模拟自变量和因变量之间的关系。这意味着您使用一组参数来确定每个自变量对因变量的影响程度。然后，根据这些值和其他输入数据(如该患者患有何种疾病)，您可以预测他/她在接受药物 x 治疗后不仅存活而且完全康复的可能性

# 决策树和随机森林

决策树和随机森林算法是决策树的下一步。这两种算法都使用一系列决策来预测事件的结果，例如根据用户的兴趣来预测他们是否会购买某样东西。

决策树最适合可以分割成小子集(也称为聚类)的大型数据集。当根据以前的经验预测结果涉及许多变量时，随机森林尤其擅长做出高准确度的预测。

下面的代码示例显示了如何将决策树和随机森林算法结合使用:

# 梯度推进机器

梯度推进机器(GBM)是最流行的机器学习算法之一。

它是一种有监督的机器学习算法，这意味着在使用它进行预测或分类问题之前，你必须在一些标记的数据上训练它。

GBM 背后的想法是，当问题中涉及许多变量时，使用梯度推进作为一种提高模型性能的方法。

对于有许多变量并且很难在数据中找到任何有用的结构的问题，GBM 是一个很好的选择。它还非常擅长处理高度相关的变量，这对于更简单的模型来说可能是个问题。

# k 均值

K-Means 是一种用于聚类数据的无监督学习算法。这是一种迭代算法，这意味着它从一组初始化的聚类开始，然后通过移动到新的中心来迭代地扩展这些聚类，直到不能再移动为止。

K-Means 可用于不同的情况，但它的主要用途之一是降维或降维算法(DR)。在这种情况下，DR 算法根据每个组的成员与整个数据集之间的某种相似性度量，将数据集分成多个组。然后使用 K-means 来确定哪些组最适合您的原始数据集；这将使你更容易找到这些群体中的模式

# 奇异值分解

奇异值分解(SVD)是矩阵的特征值分解。它可以用来计算矩阵的主成分，也可以计算矩阵的奇异值分解(SVD)。

理解 PCA 是处理数据的重要部分。它被用于无数的应用中，从金融和统计到机器学习。在本文中，我们将讨论什么是 PCA，它是如何工作的，以及它如何用于降维。

# 主成分分析

主成分分析(PCA)是一种寻找数据中最大方差方向的降维技术。它用于减少数据集中的要素数量，并通过查找投影方向来查找数据中的基础结构。

在本文中，我们将讨论 PCA 是如何工作的，以及作为一名算法工程师为什么应该学习它！

另一方面，全连接层由许多神经元组成，这些神经元从卷积层获取输出，并将其与权重相结合。这些权重用于确定哪些特征对分类任务最重要。

# 卷积神经网络(CNN)

卷积神经网络是一种人工神经网络，可用于图像识别、语音识别等。它们由卷积层和全连接层组成。

卷积层由许多小过滤器组成，这些过滤器在输入层的数据被传递到另一层之前对其进行处理。每个过滤器的大小取决于你想从你的机器学习模型中学习多少(例如，你是在看文本还是图像)。

然后，通过称为“池化”的加权求和操作，将每个滤波器的输出与前几层的其他输出组合在一起这有助于减少训练过程中的噪音，以便我们可以在稍后尝试将图像分类为“猫”、“狗”等类别时看到更好的结果！

# 递归神经网络(RNN)

递归神经网络(RNNs)是一种能够记住先前事件的神经网络。rnn 用于自然语言处理、语音识别和机器翻译。它们也是一种深度学习模型:LSTM 网络是一种 RNN，也可以记住以前的事件！

LSTM 的应用:自然语言处理、语音识别和机器翻译

这是一种更高级的算法，可用于计算矩阵的奇异值分解(SVD)。该算法通过执行 QR 分解的几次迭代，随后是结果矩阵的特征值分解来进行。LSTMs 是最流行的 rnn 类型之一。它们被用于许多应用程序，从谷歌翻译到 Siri 和 Alexa。LSTM 网络被用于机器翻译等任务，因为它们可以学习记忆之前发生的事情(并预测接下来会发生什么)。c

# 长短期记忆网络(LSTM)

LSTMs 是一种递归神经网络(RNN ),可以从过去学习并预测未来。它们对于语音识别、机器翻译和文本分类等序列学习任务非常有用。

在这篇文章中，我们将讨论如何在基于 Python 3.6+的机器学习中使用长短期记忆网络(LSTM)。

在本教程中，我们将向您展示如何使用 Keras 在 Python 中训练和评估长短期记忆网络(LSTM)。LSTM 网络是一种可以从过去学习并预测未来的递归神经网络(RNN)。它们对于语音识别、机器翻译和文本分类等序列学习任务非常有用。在这篇文章中，我们将讨论如何在基于 Python 3.6+的机器学习中使用长短期记忆网络(LSTM)。

# 马尔可夫链蒙特卡罗方法

马尔可夫链蒙特卡罗方法是一类用于近似随机系统中事件概率的算法。该名称来自于这样一个事实，即这些方法通过模拟难以分析建模的复杂系统的行为来工作。

马尔可夫链蒙特卡罗(MCMC)是一种基于样本数据和关于这些参数的先验知识计算后验分布的方法。它已广泛用于贝叶斯统计、机器学习和计算金融(如利率建模)。

在这篇文章中，我们将用 PyTorch 构建一个简单的 HMM，然后用 Hard EM 训练它。特别地，MCMC 已经被用于估计利率模型的后验分布。关于参数的先验信息通常存储在一个表中，称为“参数化”。然后，该算法使用随机数从该表中进行采样，以创建代表所研究的真实世界系统的状态链(例如，利率)。每个状态可以是可观察的或不可观察的(即潜在的)。m

# 隐马尔可夫模型

隐马尔可夫模型(HMMs)是一类马尔可夫模型，其附加的假设是潜在的马尔可夫链是隐藏的。

EM 有两种变体:软 EM 和硬 EM。它们之间的差异基于您如何估计您的参数，与软 em 或高斯混合模型相比，硬 EM 在预测准确性方面更有效，软 EM 或高斯混合模型可以使用梯度下降算法(如 SGD 或 Adam optimizer)轻松训练。

使用混合模型很好，但是如果你的数据有多个可以独立分离和处理的成分，那么最好使用 HMM。HMM 是一个观察序列的生成模型，其中所有可能观察的概率分布给定了一个隐藏状态序列。

# 期望最大化算法

期望最大化(EM)是一种寻找一组参数的最大似然估计的概率方法。EM 既用于分类问题，也用于回归问题，它可以被看作是最小二乘回归的推广。换句话说，期望最大化(EM)模型使用迭代方法来为每个参数找到最可能的值，以便精确地拟合数据点。

值得注意的是，EM 不仅仅局限于线性模型；它还成功地应用于非线性问题，如神经网络和非参数方法，如核函数和决策树。

# 随机梯度下降和交替最小二乘算法

随机梯度下降(SGD)和交替最小二乘法(ALS)是简单但有效的算法，用于最小化损失函数、最大化似然函数和在迭代过程中找到局部最小值。

这两种算法密切相关，因为它们都使用梯度下降来解决这些问题。在 SGD 中，我们最小化损失函数，而在 ALS 中，我们最大化似然函数。在这两种情况下，我们使用梯度下降来做到这一点；然而，这两种方法之间也存在一些技术差异。

# 朴素贝叶斯分类算法

朴素贝叶斯分类器是一种简单有效的分类算法。它基于贝叶斯定理，贝叶斯定理是概率论中的一个定理。该算法依靠归纳推理而不是演绎推理来进行预测。

朴素贝叶斯分类器算法在从诸如文本数据或图像之类的新实例中学习之前，使用关于类别的先验信息(例如，项目属于组 A 还是组 B)。

该算法用于分类，分类是预测实例的标签或类别的任务。有两种类型的分类问题:1)二元分类和 2)多元分类。在二元分类问题中，我们需要从两个类中预测一个标签(例如，预测某人是否会购买你的产品)。

在多分类问题中，我们需要从多个类别中预测多个标签。比如预测某人是否是客户(二元)或者预测某人是否会购买你的产品，还要预测他是否有可能推荐给朋友(多元分类)。

朴素贝叶斯分类算法是最流行和最简单的机器学习算法之一。它被用于各种应用，如垃圾邮件过滤、文档分类和文本挖掘等。

# q 学习强化学习算法

Q-learning 是一种强化学习算法。这是一种非策略学习方法，这意味着不是从一个模型开始，然后试图优化它，而是从一个初始策略(描述模型应该做什么的规则)开始，然后以此为起点，随着时间的推移进行改进。

q 学习也称为时间差异学习，因为它使用观察之间的时间差异来更新其动作值的估计。这可以被认为是在像《魔兽世界》或《口袋妖怪 Go》这样的游戏中使用经验点，玩家在花时间训练他们的角色后，通过做像打怪物或完成任务这样的事情变得更强。例如，如果你在 SNES 上玩最终幻想 VI，你会从击败敌人中获得经验值，这将允许他们变得更强，如果他们在完成最终老板之前被提升足够的次数，最终老板在死亡城堡王座室下面的巢穴深处守护着一些宝箱，当他不积极防御试图接管他的王国的入侵者时，他通常会把自己藏在那里！

# k 近邻算法(KNN)和协同过滤算法

k-最近邻(KNN)是一种用于分类和回归的算法。它使用 k-最近邻来分类新的数据点，然后形成监督学习的基础。KNN 也称为基于频繁模式匹配或线性判别分析的分类方法。

这种算法背后的前提是，在我们的世界中可能有许多不同类型的对象，我们需要找出哪一个最适合我们的训练集，然后再决定其类成员。这包括根据两个物体之间的相对距离以及它们各自的特征(如颜色、形状等)来找出它们有多相似。，然后使用一些数学公式(如它们之间的欧几里得距离)计算它们的相似性。一旦从每个类(稍后将使用)内的各种样本/多个样本中收集了该信息，就可以使用这些值以及诸如阈值之类的一些其他参数来创建 LDA 模型，以决定是否应该将一个实例分配到其对应的类标签中

# 外卖:

机器学习是人工智能的一个子领域，它开发了使计算机能够从数据中学习的算法。它可以用来建立预测模型，然后可以用来预测未来的事件。

机器学习算法已经用于许多领域，包括金融(例如，股票市场)、医疗保健和执法(例如，面部识别)、机器人和自动驾驶汽车(例如，自动驾驶汽车)。

# 结论

机器学习不再只是数据分析师和开发者的工具。这也是任何寻求建立基于人工智能的产品或服务的人的一项基本技能。开始机器学习的最佳方式是了解算法如何工作的基础知识，这样当你在路上遇到一个新算法时，你就知道它做什么和如何工作。

有了这个每个 ML 工程师都应该知道的 20 种算法的列表，我们希望你可以开始建立自己的机器学习生涯！

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
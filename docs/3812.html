<html>
<head>
<title>Using Neural Networks and NLP Word Embedding to Predict Amazon User Review Ratings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用神经网络和NLP单词嵌入来预测亚马逊用户评论评级</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/using-neural-networks-and-nlp-word-embedding-to-predict-amazon-user-review-sentiment-28156f69e1e1?source=collection_archive---------1-----------------------#2022-10-24">https://medium.com/mlearning-ai/using-neural-networks-and-nlp-word-embedding-to-predict-amazon-user-review-sentiment-28156f69e1e1?source=collection_archive---------1-----------------------#2022-10-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/cb648da7b3b2d4dc7a9f1d3bb1029114.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*YHPKTpGqvbilzmUQMvZ8LQ.jpeg"/></div></figure><h1 id="0c74" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">摘要</h1><h2 id="f4bf" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated">项目目的:</h2><p id="8171" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">该项目的目的是建立一个模型，根据用户评论中的文字预测用户对亚马逊数字音乐专辑的星级(1-5级)。我测试了几个神经网络算法，这些算法是用采样的用户评论评论及其对应的星级进行训练的。我利用几种自然语言处理(NLP)技术将文本标记化和矢量化为“可训练的”数据结构。通过建立一个从文本中解读用户意见的监督分类模型，我希望我的算法可以潜在地用于其他类型的情感分析问题，包括需要无监督学习的问题(即，没有星级分类标签进行训练)。当然，这是基于星级是用户情绪的真实反映的假设。</p><p id="edf3" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">如下表所示，我的模型将获取原始用户评论数据样本(reviewText列)，将对来自标记化关键词的文本进行矢量化(tokens列)，然后预测他们将留下的用户星级。然后，我会看到预测的星值(pred_stars)与数据集中的实际星值(diff_pred)相比如何。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/4d69f81a877475dde0baeb9b687fd48e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4zped0QxsdhSnNutA45nrg.png"/></div></div></figure><h2 id="7d43" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated">使用的数据和代码:</h2><p id="74c0" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">我使用的数据集是来自亚马逊的大约150万条用户评论的开源数据集。由于我的笔记本电脑有处理限制，并且无法访问云服务器，我选择只对整个数据集的10%随机样本进行训练/测试。我所有的代码都可以在我的Jupyter笔记本<a class="ae lj" href="https://github.com/omshapira/Amazon_star_rating_predictions/blob/master/Project_Amazon_Reviews.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="d025" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated">方法概述:</h2><p id="7cb2" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">为了建立这个模型，我最终测试和超参数调整了六种不同类型的算法和NLP矢量化组合。我探索的算法是支持向量机(SVM)、深度神经网络(DNN)和卷积神经网络(CNN)模型。为了对我的文本数据进行矢量化，我测试了三种方法:单词袋(BOW)，从头训练一个单词嵌入向量，以及使用预训练的单词嵌入向量全局向量进行单词表示(<a class="ae lj" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">手套</a>)算法。每个模型都遵循下图所示的相同工作流程。经过采样和文本预处理后，数据被分成测试数据和训练数据。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lk"><img src="../Images/396eacc426b79b95b14a656afe63ae37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G6mSlJDYCDMHer-6xUIOeQ.png"/></div></div></figure><h2 id="8715" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated">结果摘要:</h2><p id="2017" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">从下面的结果可以看出，具有弓形矢量化功能的DNN具有最高的准确率，为62%。虽然我对我所有模型的准确率只有60%感到失望，但我很高兴它们在一个星级内的预测准确率都达到了85%。但是从高训练精度可以看出，我的所有模型都显得过拟合。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/4cdb5d53d5d39e16cfb078ef13caf7ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aDfp235uQpwymKuP1E_Hdg.png"/></div></div></figure><p id="f0cc" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">重要的是要记住，多类模型(在这种情况下，每颗星5个)的解释性能不如二进制模型直接。例如，查看每个类别级别(即star)的<a class="ae lj" href="https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/" rel="noopener ugc nofollow" target="_blank">加权准确度</a>或性能可能是有意义的。我没有更深入地研究性能指标，但是计划在以后进行探索。也就是说，我怀疑是多种原因导致了我的模型过度拟合。概括地说，这些包括:</p><ol class=""><li id="b9cd" class="ll lm hh kc b kd kv kh kw jq ln jt lo jw lp ku lq lr ls lt bi translated"><em class="lu">不平衡的数据集:</em>我的原始数据样本极度扭曲，大约80%的评分为5星。虽然我使用了重采样技术来提高分布的均匀性，但它仍然不平衡。这种对性能的影响在多级模型上尤其严重。随着时间的推移，我计划探索其他过采样/欠采样技术。</li><li id="1d59" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated"><em class="lu">嵌入和训练参数</em>:可能是我的word嵌入训练有缺陷，或者超参数(如图层、滤镜等)不理想。)在我的NN/CNN算法里。我已经在Keras中测试了正则化函数，但这最终降低了我的训练数据的准确性，而没有提高我的验证数据的性能。虽然我使用GridSearch来调优我的模型超参数，但是它所花费的大量训练时间限制了我可以合理测试的参数的范围和数量。</li><li id="86cd" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated"><em class="lu">样本量不足:</em>我的采样数据集只有10，000条记录。如果我有更多的时间和云服务器，我会考虑使用更多时期的160万条记录的整个数据集…但我预计这将需要几天时间来运行。当我稍微增加样本量进行测试时，似乎没有太大的区别。在我的模型训练中，我也探索了使用更多的纪元，但是在最初的几个纪元之后，准确性似乎降低了。我最终为每个模型使用了10个时期。</li><li id="3304" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated"><em class="lu">没有足够的模型特征</em>:重要的是要记住，用户评论评论并不能完美地预测他们可能给出的星级。通过只根据用户评论训练我的模型，我没有考虑其他可能影响给定用户星级的预测因素。这包括一个成员如何评论其他在线产品、他们的人口统计数据(例如年龄、地点、教育程度等。)，或者与音乐专辑本身相关的其他因素。我的模型不是预测给出了什么星级，而是可以重新用于预测1-5级的用户情绪。我的模型在一颗恒星内预测的准确性证明了它可以有效地做到这一点。</li></ol><p id="de55" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">总的来说，对于在Keras和自然语言处理技术中试验不同的神经网络架构来说，这是一次很好的学习经历。下面，我提供了创建模型的每个步骤的更多细节。</p></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="81e9" class="il im hh bd in io mh iq ir is mi iu iv iw mj iy iz ja mk jc jd je ml jg jh ji bi translated">文本数据预处理:</h1><p id="5568" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">预处理和矢量化是这个项目非常耗时的部分。这是由于我对各种技术的研究和实验。文本预处理的最终目标是创建某种类型的向量，用数字表示每个单词。这个数字向量然后被输入到用于训练和测试目的的机器学习模型中。我使用的预处理的一般流程是1。2)对数据集进行采样。)标记化，3。)归一化，以及4。)对我所有的文本数据进行矢量化。</p><h2 id="afcc" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">对数据集进行采样:</strong></h2><p id="524c" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">早些时候，我意识到亚马逊评论数据集的两个关键问题。首先，它太大了(160万条记录)，无法在合理的时间内完成各种模型的训练。我最终只采样了10，000条记录，这仍然需要相当长的时间来训练某些模型。我接下来意识到，星级的分布是非常倾斜的。大约80%的记录有5星评级，我觉得这扭曲了我的准确性评分的意义(即预测所有评论都是5星的模型将有80%的准确性，这看起来很高)。为了在随机抽样我的10k记录时减轻这种情况，我对带有&lt; 5 stars. The distribution of ratings before and after sampling are shown below.</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mm"><img src="../Images/5b0d31489c551022f90cc80b075bd57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kWlUiwfkLcYbEGsGYMhCaA.png"/></div></div></figure><div class="lb lc ld le fd ab cb"><figure class="mn ii mo mp mq mr ms paragraph-image"><img src="../Images/1ae3f3e367599590a527f7f158a097cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*U9RYHqkpabyKDRk5CqFVnQ.png"/></figure><figure class="mn ii mt mp mq mr ms paragraph-image"><img src="../Images/4790342da13f382848725b214feea4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*V2TMJwKkM0NrkTkQRrRCvA.png"/><figcaption class="mu mv et er es mw mx bd b be z dx my di mz na">Left image shows initial distribution of star ratings, right image shows updated weightings.</figcaption></figure></div><h2 id="40d0" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">符号化</strong>的抽样记录赋予了更重的加权概率:</h2><p id="3d87" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">我的下一步是<a class="ae lj" href="https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html" rel="noopener ugc nofollow" target="_blank">标记化</a>数据，这样每个单词代表一个不同的标记特征。在这样做的时候，我还确保删除了“停用词”，这是一些常见的虚词，如“the”、“is”和“at”。以下是我在标记化前后的数据片段。预计像“n't”这样的标记将由缩写形成(例如，don 't)。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nb"><img src="../Images/b9f8e40c61eeaf96f1c71632d46c20e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-HjGbKt-IJdYHvO0nk4HYQ.png"/></div></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/a5774f7ac3f7cb85343c3204b7115933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FUsm09g4ZXZPNUJvKgTS6w.png"/></div></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/d06f098e8a6d0fb08bd57cd7bf8f7895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eLbzYpiqjVfnloQpiJsDMQ.png"/></div></div></figure><h2 id="e5a0" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">正常化</strong>:</h2><p id="90d0" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">在标记化之后，我进一步规范化了文本数据以减少冗余。这是通过删除任何非ASCII字符、删除标点符号、将所有内容都变成小写，并用文本表示替换数字(500 = 500)来实现的。我在这里利用了来自<a class="ae lj" href="https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html" rel="noopener ugc nofollow" target="_blank">的代码片段</a>。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nc"><img src="../Images/8b7b89cf87caaa1fefd8ab117be6254b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Re5F-UqihgabklNn9kV7aQ.png"/></div></div></figure><p id="f04d" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">我还应用了词汇化，这是一种词干化<a class="ae lj" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">技术</a>。这将单词，尤其是动词，正常化为它们的词根形式和现在时态。下面显示了规范化后的同一个审查记录的一个片段。注意“听”是如何变成“听”的，“想”是如何变成“想”的。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mm"><img src="../Images/2332afb8fec042823aa213e55d1f16ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4y8kliiM80XCcwXbq2eIw.png"/></div></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/3337b3593e5dd0ae8cd5fa3b82be55bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FsXhfPDaKfHXqFLmjoPuNw.png"/></div></div></figure><h2 id="61dd" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">矢量化</strong>:</h2><p id="4e6d" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">最后，也是最复杂的一步是将文本数据矢量化为数字矩阵，输入到我的算法中。有许多技术可以做到这一点。我探索的三种方法是单词袋(BOW)，从头训练一个单词嵌入向量，使用预先训练好的单词嵌入向量单词表示全局向量(GloVe)算法。</p><p id="00a4" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi"> BOW嵌入:</strong>使用这种方法<strong class="kc hi">，</strong>创建一个向量矩阵，表示每个单词的频率。每个向量对应一篇评论，每个向量的宽度是跨所有记录的整个语料库中所有不同单词的数量。在每个评论的向量中，填充了每个词的频率。一个<a class="ae lj" href="https://victorzhou.com/blog/bag-of-words/" rel="noopener ugc nofollow" target="_blank">示例</a>如下所示。虽然这是实现起来最简单的方法，但是它有几个缺点。随着记录和词汇数量的增加，向量变得非常宽，有许多非零值。此外，词频不考虑上下文或单词的顺序。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nd"><img src="../Images/48a5a325eacbc84f3e8a17118f569886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJglsARn7kWx6zZO9JqdFg.png"/></div></div></figure><p id="32ef" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">下面是我用SVM算法对1000条样本记录进行BOW测试的代码片段。它还显示了我的验证数据中250条记录的性能结果(75/25分割)。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ne"><img src="../Images/a8586ac496c7e08d176da8c0934fa044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPf_u2zzA5VyTk4LPpsYGA.png"/></div></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/e172d57171a2e803c6530294cc33c84a.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*6hscOXUh6E3nrfIYCrKL4w.png"/></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es ng"><img src="../Images/d80a0cbcbc3b99536413dc02f6b32e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*78yClGtMtmvOaluz5qXkmg.png"/></div></figure><p id="a095" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">手动训练的单词嵌入:</strong>我的第二种方法是创建单词嵌入，这将在我的模型中手动训练。有三种通用的令牌矢量化和单词嵌入方法:</p><ol class=""><li id="f951" class="ll lm hh kc b kd kv kh kw jq ln jt lo jw lp ku lq lr ls lt bi translated">由每个单词作为向量表示的单词</li><li id="3af1" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated">由每个字符作为向量表示的字符</li><li id="fb43" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated">表示为向量的单词/字符的n元语法。n元语法是文本中多个连续单词/字符的重叠组。例如，您可以选择N=3来查找类似“我喜欢糖果”的单词组合。这个<a class="ae lj" href="https://suyashkhare619.medium.com/how-to-deal-with-multi-word-phrases-or-n-grams-while-building-a-custom-embedding-eec547d1ab45" rel="noopener">方法</a>以相似的方式表示单词，如果它们以相似的方式使用的话。与鱼相比，蓝色更像红色的数字表示。</li></ol><p id="2d53" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">我选择了方法#1，因为我觉得对每个字符进行矢量化对于如此大的数据集来说是低效的，并且没有足够的时间来测试N-gram参数。在方法1中，我探索了一键编码和单词嵌入。独热编码输出一个0/1二进制指示符，指示一个单词是否存在于每个记录的不同单词的整个语料库中。但像BOW一样，一键编码的一个大缺点是它创建了非常广泛的输入向量，并且没有考虑单词排序(即上下文)。</p><p id="c89c" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">相反，我最终使用了一种单词嵌入技术，这种技术可以创建大小相等的压缩向量，其最大大小基于最长用户评论中的单词数。这个向量将包含与记录的用户评论中的给定单词相关联的不同索引数字。对于较短的用户评论，向量将用零“填充”。下图显示了如何将标记化的数据转换为训练序列，然后将其填充为大小相等的向量。在下面的示例<a class="ae lj" href="https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html" rel="noopener ugc nofollow" target="_blank">中，由于第一个文本序列只有三个单词，所以向量的其余部分用零填充</a></p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es nh"><img src="../Images/31e660977d8844b2db5b512721db6c7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*by-0WDL31MdetbYlGAHvEw.png"/></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ni"><img src="../Images/0d7010859e03b68b417e6d593f4e9cbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Py6aID0HMHcv_G9smar32A.png"/></div></div></figure><p id="cd8e" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">在Keras中，有一些有用的库可以对数据进行标记、填充和矢量化。下面是一个示例，它标记了一个示例审查记录，后面是一个代码片段，用于填充向量，使其大小相等。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nj"><img src="../Images/73b249b84f8a52ac17fdb383b0daecee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JnEOu3O6unPW-ggBxytWlw.png"/></div></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ne"><img src="../Images/6b1e2f0036892a026e896090a2b5b2d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5k9MwZvIOPwtCFbONGp5TA.png"/></div></div></figure><p id="d0b5" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">手套嵌入</strong>:我的第三种方法是使用预先训练好的手套嵌入。这个免费的<a class="ae lj" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">可下载的</a>嵌入已经初始化了单词的权重，这些权重很大程度上是通过在整个文本语料库中创建单词共现矩阵而获得的。Keras提供了将这些嵌入字典合并到神经网络模型的嵌入函数中的能力。虽然这种嵌入被用来作为模型的种子，但我选择在模型训练期间更新它们。如果我有更多的时间，我会探索其他预训练的嵌入库是<a class="ae lj" href="https://www.tensorflow.org/tutorials/text/word2vec" rel="noopener ugc nofollow" target="_blank"> Word2Vec </a>和<a class="ae lj" href="https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>。从下面的代码片段可以看出，如果我将最大嵌入维数设置为50，GloVe library占了我的数据的文本语料库中所有单词的大约93%。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es nk"><img src="../Images/f4439b400cc86d111ffa56173357ab3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*Ujm0kE6cqhopPTXRMYtgMg.png"/></div></figure></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="2f69" class="il im hh bd in io mh iq ir is mi iu iv iw mj iy iz ja mk jc jd je ml jg jh ji bi translated">建模:</h1><p id="28b2" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">由于数据量很大，特别是当文本被矢量化时，我倾向于使用神经网络进行探索。我对使用CNN特别感兴趣，这是文本分类问题中常用的<a class="ae lj" href="https://arxiv.org/abs/1412.1058" rel="noopener ugc nofollow" target="_blank">。我很好奇它与更传统/不太密集的ML算法(SVM)相比会有什么表现，这也是文本分类的一个流行的选择。</a></p><h2 id="aa90" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">支持向量机(SVM): </strong></h2><p id="f173" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">对于我的SVM模型，我使用默认参数来训练我的文本数据。它没有应用任何正则化惩罚，并使用径向基函数核。输入向量由BOW编码技术创建。由于SVM不是我项目的重点，我没有花太多时间来调整模型的参数值，而是将其视为一个基线模型。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nl"><img src="../Images/f73aa35854ad51fa8a8a725f4aa8d132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4T10ngBw4hh30EbG9uoltw.png"/></div></div></figure><p id="dec2" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">我的SVM基线模型的结果如下。2500条验证记录的准确率约为62%。此外，在训练数据集上的准确率仅为69.1%，这意味着该算法不是非常有效。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es nm"><img src="../Images/5f810e7a7625969fc5ea354871af7e9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*cRok3oRZY9Jbwvz2fp-LHQ.png"/></div></figure><h2 id="506b" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">深度神经网络(DNN) </strong>:</h2><p id="deeb" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated">我使用上文描述的BOW和训练词嵌入文本矢量化技术实现了一个DNN。我使用了Keras的顺序模型API，其中层是按顺序添加的。这个<a class="ae lj" href="https://realpython.com/python-keras-text-classification/#convolutional-neural-networks-cnn" rel="noopener ugc nofollow" target="_blank">教程</a>对于实现Keras和获得神经网络的基本理解都是一个特别有用的指南。我将尝试在下面总结这一点，我已经<em class="lu">斜体</em>了一个神经网络的关键元素，它有我试验过的多种变化。</p><p id="9c84" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">【非常】神经网络的高层描述:</strong>神经网络由从输入层前馈训练数据的节点组成→一个或几个<em class="lu">隐藏层</em>所有迭代训练都在那里发生→包含加权预测概率的输出层。输出图层的每个预测类都有一个结点(在本例中为5个)。下面是一个简单的图表。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es nn"><img src="../Images/96bd3c1887e589c8c3bac3530ca59767.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*7ZrwJcytqvhaj7g9_Q-2yg.png"/></div></figure><p id="c75e" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">在整个神经网络中，每一层的输入节点都乘以一个计算出的权重和偏差变量，以产生下一层的输出节点。模型的初始输入权重是随机分配的，并通过一种称为反向传播的方法进行训练。该方法使用<em class="lu">优化器</em>来减少计算的目标输出和期望的目标输出之间的误差。优化器的目标是减少<em class="lu">损失函数</em>，这就是我们量化误差的方式。在整个反向传播过程中，每个输入层的权重通过<em class="lu">激活函数</em>传递。</p><p id="1fb0" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">我的车型中的关键参数</strong>:</p><ol class=""><li id="17c8" class="ll lm hh kc b kd kv kh kw jq ln jt lo jw lp ku lq lr ls lt bi translated"><em class="lu">隐藏层</em>:我建立了一个“深度”神经网络，这意味着有几个隐藏层，以便进行额外的训练。在我手动训练嵌入的模型中，我必须在我的矢量化中添加一个嵌入层。这在我的BOW模型中是不需要的。为了帮助推广这个模型，我还测试了添加一个<a class="ae lj" href="https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">删除层</a>，它在整个反向传播过程中随机删除节点。但是，它对性能准确性的影响有限。</li><li id="9235" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated"><em class="lu">优化器</em>:我使用了一个<a class="ae lj" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"> Adam </a>优化器，因为它被广泛使用，而且<a class="ae lj" href="https://datascience.stackexchange.com/questions/10523/guidelines-for-selecting-an-optimizer-for-training-neural-networks" rel="noopener ugc nofollow" target="_blank">认为</a>在各种型号上都有很好的性能。</li><li id="1fe6" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated"><em class="lu">损失函数</em>:我使用了分类交叉熵损失函数，因为这是一个多类分类问题。</li><li id="4b76" class="ll lm hh kc b kd lv kh lw jq lx jt ly jw lz ku lq lr ls lt bi translated"><em class="lu">激活函数</em>:可以将不同的激活函数应用于神经网络中的不同层。对于我的初始层，我使用了10个具有Relu激活功能的神经元。我使用了softmax激活函数，它非常适合多类问题，因为它输出了每个类标签的概率。我还测试了添加正则函数到我的辍学层。</li></ol><p id="f37e" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">下面的代码片段展示了DNN是如何在喀拉斯建造的。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mm"><img src="../Images/9bdf7dde345e393b4fad75598d98699c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xteQcCbuEj4BEMD_X1suCg.png"/></div></div><figcaption class="mu mv et er es mw mx bd b be z dx">Defining model parameters</figcaption></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ne"><img src="../Images/0d509956076415fb5b9b0c93eca27d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BRFysVBtxXzsT0a2vbYUow.png"/></div></div><figcaption class="mu mv et er es mw mx bd b be z dx">Training the model</figcaption></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mm"><img src="../Images/896479d26ec3d5e459c657e8aa898a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Bu__15DzJHQoVhlfyNatQ.png"/></div></div><figcaption class="mu mv et er es mw mx bd b be z dx">Viewing performance results</figcaption></figure><p id="48d2" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">DNN结果:</strong></p><p id="7585" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">如下所示，我的两个DNN模型在2500条验证记录上的准确率都在60%左右。高训练精度(92–95%)意味着模型非常过拟合。然而，如上所述，我的带蝴蝶结的DNN在预测一星之内的星级评分方面表现最好(91.2%)。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es no"><img src="../Images/87ab9ea6a3d81955b6af460ac20b0fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*lEbELIrigySbxUR_iAQIQg.png"/></div></figure><p id="b88c" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">当将模型拟合到训练数据时，似乎验证数据的准确性实际上在大约5个时期后开始下降。下面，X轴表示时代，Y轴表示正确预测的星级比例。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es np"><img src="../Images/c29f05962043ad9c3ecdc5b0d9b546ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*1uRNlvIVlkad85Zlgno7BQ.png"/></div></figure><h2 id="1aaa" class="jj im hh bd in jk jl jm ir jn jo jp iv jq jr js iz jt ju jv jd jw jx jy jh jz bi translated"><strong class="ak">卷积神经网络</strong>:</h2><p id="f216" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jq kl km kn jt ko kp kq jw kr ks kt ku ha bi translated"><strong class="kc hi">架构和方法:</strong></p><p id="d3cd" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">CNN是一种DNN，其架构相似，但具有一些关键的附加层和参数，如下面的图<a class="ae lj" href="https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b" rel="noopener" target="_blank">所示</a>。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nq"><img src="../Images/b212b5904837d1584eb1510452db4245.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0tu1udjlyJrTwTW9MP-17w.png"/></div></div></figure><p id="536f" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">第1层——输入层:</strong>最左侧，输入层将单词嵌入低维向量中。这是由Keras中的嵌入函数完成的，类似于我的DNNs。</p><p id="f6db" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">在我的CNN模型中，使用了预先训练的GloVe单词嵌入，我通过在CNN架构的初始步骤中创建一个嵌入层来调用它。这是通过将权重设置为等于我导入的嵌入矩阵来完成的。输入长度是我在文本处理中创建的填充向量序列的最大长度(如上所述)。虽然这些嵌入为我的模型提供了种子，但我选择将嵌入设置为可训练的，并在模型训练期间不断更新权重。</p><p id="c5fa" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">层2 -卷积层:</strong>该第二层通过嵌入的字向量的第一输入层进行卷积。使用各种滤波器并用激活函数(如DNN)对每个卷积执行逐元素乘法。它对我的输入矩阵中的记号子集使用了许多不同大小的过滤器。下图左侧显示了一个示例，其中一个2x5过滤器一次遍历输入句子中的两个相邻单词(用嵌入矩阵表示)。然后，它会生成记录在要素地图输出图层(0.51)中的按元素分类的产品。这一顺序对它过滤的每一组单词重复进行。</p><p id="16f6" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">有不同的非线性激活函数<a class="ae lj" href="https://realpython.com/python-keras-text-classification/#convolutional-neural-networks-cnn" rel="noopener ugc nofollow" target="_blank">可以用</a>在这一层，比如Relu。在我的模型中，我使用了softmax激活函数，并使用了128个尺寸为5×5、步长为1的过滤器。这一层过滤了我的文本字符串输入中的各种标记子集。像我的DNN一样，我也在我的密集层中使用了Adam优化器和分类交叉熵损失函数。</p><p id="482d" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">第3层-汇集层:</strong>CNN中的汇集层从特征图输出中向下采样，以给出在输入中检测到的特征的<a class="ae lj" href="https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">概括和概括版本。因此，即使卷积层检测到特征输入的微小变化(例如单词的排序)，汇集的特征图也可以具有相同的结果。</a></p><p id="024a" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">与上图不同，我使用了全局最大池，它将整个特征映射向下采样为一个值。此外，我的模型的输出(最右边)有5个类(对于每个星星)而不是2个。</p><p id="3705" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">超参数调整:</strong>我使用Python的Gridsearch功能来测试我的CNN手套模型的最佳参数组合。前20名表演组合的结果输出如下。我测试的CNN参数是激活函数、辍学率、学习率和初始层神经元数量。我最终使用了默认的0.1的学习率，5个神经元，0.2的辍学率，和一个softmax激活函数。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es nr"><img src="../Images/91e23dee04e642a22120e5f4fd8a3ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U8dPdurD0vdYvHBM_D_XbQ.png"/></div></div></figure><p id="589d" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">下面是我如何用Python的Keras库编写CNN的代码片段。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/9daa769b89a8ff24aa8547279f154369.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVcCsIQ5PywIlFHV3_fJYA.png"/></div></div></figure><p id="44cc" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated"><strong class="kc hi">CNN结果:</strong></p><p id="acc5" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">尽管我的CNN模型进行了所有的调整(训练时间明显更长)，但它的表现比我的神经网络BOW模型略差。我的带手套嵌入的CNN在2500条验证记录中有57%的准确率。我的CNN有56.2%的准确率。像我的DNNs一样，它们在训练样本上都有很高的准确率(约93%)，这意味着明显的过度拟合。然而，我又一次感到高兴，他们在一颗恒星内有90%的预测准确率。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es ns"><img src="../Images/df90e63b4c4c77bfc9029b27fbc8403d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*-Xb47m2cw3cvylbn7PefcA.png"/></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es ns"><img src="../Images/df90e63b4c4c77bfc9029b27fbc8403d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*-Xb47m2cw3cvylbn7PefcA.png"/></div></figure><p id="7f31" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">同样，和我的DNNs一样，下面的学习曲线速率表明，我的验证数据的准确性在大约5个时期后开始下降。如果给我更多的时间，我会继续测试各种参数——特别是CNN卷积层的过滤参数。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es nt"><img src="../Images/c4506c0b549670713d90079427a3daa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*TIimuwXxAYCuA7wjox7tAg.png"/></div></figure><p id="5bd9" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jq kx km kn jt ky kp kq jw kz ks kt ku ha bi translated">随着我对NLP和神经网络建模技术的进一步了解，我希望能够再次访问这个项目，并有可能提高模型的性能。</p><div class="nu nv ez fb nw nx"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ny ab dw"><div class="nz ab oa cl cj ob"><h2 class="bd hi fi z dy oc ea eb od ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="oe l"><h3 class="bd b fi z dy oc ea eb od ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="of l"><p class="bd b fp z dy oc ea eb od ed ef dx translated">medium.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol ij nx"/></div></div></a></div></div></div>    
</body>
</html>
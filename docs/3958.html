<html>
<head>
<title>DreamFusion: 3D models from text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DreamFusion:来自文本的3D模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/dreamfusion-3d-models-from-text-561e8268a24c?source=collection_archive---------1-----------------------#2022-11-15">https://medium.com/mlearning-ai/dreamfusion-3d-models-from-text-561e8268a24c?source=collection_archive---------1-----------------------#2022-11-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9856" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个新的谷歌扩散模型，允许从文本中获得3D图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/95f98950ada8b7fc721eeeca48088081.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_EcbRV9T-l-3SRan5O0q5w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">image source: <a class="ae js" href="https://dreamfusion3d.github.io/" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="5508" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">获得3D图像并不容易。事实上，正如作者所写的那样，有很多2D图像，而3D图像要少得多。所以很难收集到好的数据集。现在，谷歌和加州大学伯克利分校研究训练的一种新模型可以从文本中生成3D图像。让我们一起去发现它。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="jt ju l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">the first author announcing the model</figcaption></figure><p id="e55b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，到目前为止，我们已经看到了能够从文本生成真实图像的模型(<a class="ae js" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">稳定扩散</a>，DALL-E，等等)。这表明扩散模型能够从文本描述中生成图像。那么为什么不从2D步骤开始，然后将图像转换成3D呢？</p><p id="fd8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型由两部分组成:<a class="ae js" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank"> NERF </a>和<a class="ae js" href="https://arxiv.org/abs/2205.11487" rel="noopener ugc nofollow" target="_blank"> Imagen </a>模型。简而言之，NERF是一种用于通过从一个或多个对象的图像生成神经辐射场来渲染3D场景的模型。NERF使用一组稀疏的输入来优化体积图像(而不是连续的)。从一组静态图像开始，这些图像覆盖了对象的各个角度，模型创建了一个3D表示。这种方法基本上不试图生成3d图像，而是从相机可能覆盖的所有可能角度创建图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jv"><img src="../Images/61aae470d013c1e536ff60ee87b947c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8KBBp-alr2GAZVmd.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image Source: <a class="ae js" href="https://arxiv.org/pdf/2003.08934.pdf" rel="noopener ugc nofollow" target="_blank"><em class="jw">NeRF Paper (Mildenhall1, Srinivasan1, Tancik, et. al)</em></a><em class="jw">. link to the project: </em><a class="ae js" href="https://www.matthewtancik.com/nerf" rel="noopener ugc nofollow" target="_blank"><em class="jw">here</em></a></figcaption></figure><p id="3cda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，想法是采用已经用文本标题和图像训练的模型，该模型因此学习如何从文本提示图像生成(<a class="ae js" href="https://theaisummer.com/diffusion-models/" rel="noopener ugc nofollow" target="_blank">扩散模型</a>)。扩散模型是Imagen一个类似于稳定扩散但由Google制作的模型(该模型不是开源的)。然后，该图像被转换成3D图像(NERF组件)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jx"><img src="../Images/9a354e6d48b7a37530a5ece00035d722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AzxLiWkxopeeyICAXfKi0w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">from the <a class="ae js" href="https://arxiv.org/pdf/2209.14988.pdf" rel="noopener ugc nofollow" target="_blank">original article</a>: Figure 3: “DreamFusion generates 3D objects from a natural language caption such as “a DSLR photo of a peacock on a surfboard.” The scene is represented by a Neural Radiance Field that is randomly initialized and trained from scratch for each caption. Our NeRF parameterizes volumetric density and albedo (color) with an MLP. We render the NeRF from a random camera, using normals computed from gradients of the density to shade the scene with a random lighting direction. Shading reveals geometric details that are ambiguous from a single viewpoint. To compute parameter updates, DreamFusion diffuses the rendering and reconstructs it with a (frozen) conditional Imagen model to predict the injected noise ˆφ(zt|y;t). This contains structure that should improve fidelity, but is high variance. Subtracting the injected noise produces a low variance update direction stopgrad[ˆφ − ] that is backpropagated through the rendering process to update the NeRF MLP parameters.”</figcaption></figure><p id="ee9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者提到的另一个关键因素是分数蒸馏取样(SDS)。一种开发的方法，允许将文本到图像模型(扩散模型)的输出转换到参数空间(3D模型)，如果该转换是可微分的。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jy"><img src="../Images/49c020a914310473875f4f04ba1b2131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*tAFIcF8hO_h3eU1w8CDhPQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">example of input and output. From the original article: <a class="ae js" href="https://arxiv.org/pdf/2209.14988.pdf" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="382e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如作者所述:</p><blockquote class="jz ka kb"><p id="8a80" class="ie if kc ig b ih ii ij ik il im in io kd iq ir is ke iu iv iw kf iy iz ja jb ha bi translated">给定标题，DreamFusion使用一种称为Imagen的文本到图像生成模型来优化3D场景。我们提出<strong class="ig hi">分数蒸馏采样(SDS) </strong>，这是一种通过优化损失函数从扩散模型中生成样本的方法。SDS允许我们在任意参数空间(如3D空间)中优化样本，只要我们可以有区别地映射回图像。我们使用类似于神经辐射场或NeRFs的3D场景参数化来定义这种可微分映射。SDS单独产生合理的场景外观，但是DreamFusion添加了额外的正则化和优化策略来改进几何图形。生成的经过训练的NeRFs是连贯的，具有高质量的法线、曲面几何体和深度，并且可以用朗伯着色模型重新照亮。——<a class="ae js" href="https://dreamfusion3d.github.io/" rel="noopener ugc nofollow" target="_blank">来源</a></p></blockquote><p id="2618" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法使我们能够避免包含文本标题和3D图像的大型数据集(这可能不像Imagen训练时使用的数百万张图像那样容易获得)。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kg ju l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">video explanation of the model from <a class="ae js" href="https://dreamfusion3d.github.io/" rel="noopener ugc nofollow" target="_blank">here</a>. embedded by the author on Vimeo.</figcaption></figure><p id="a6c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法显然不限于Imagen，而是可以用于任何其他扩散模型。事实上，这种方法有一个非官方的实现，使用稳定扩散(你可以在这里找到<a class="ae js" href="https://github.com/ashawkey/stable-dreamfusion" rel="noopener ugc nofollow" target="_blank"/>)。此外，还有一个非官方版本也是由相同的作者使用Google Colab ( <a class="ae js" href="https://colab.research.google.com/drive/1MXT3yfOFvO0ooKEfiUUvTKwUkrrlCHpF?usp=sharing" rel="noopener ugc nofollow" target="_blank">此处</a>)制作的，以便大家进行实验。</p><p id="06e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果非常有趣，因为它显示了扩散模型也可以用作3d图像应用的预训练基础。换句话说，由于该方法可以用于任何扩散模型，我们将很快看到更多的应用(已经有一个非官方的实现)。此外，这种训练方法是一种聪明的捷径，允许人们能够获得3d图像，而不必收集用于训练的3d图像数据集。图像的质量仍然可以提高。正如作者所说，这些图像可以轻松导出和编辑。</p><h1 id="414e" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">如果你觉得有趣:</h1><p id="012d" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">你可以寻找我的其他文章，你也可以<a class="ae js" href="https://salvatore-raieli.medium.com/subscribe" rel="noopener"> <strong class="ig hi">订阅</strong> </a>在我发表文章时得到通知，你也可以在<strong class="ig hi"/><a class="ae js" href="https://www.linkedin.com/in/salvatore-raieli/" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">LinkedIn</strong></a><strong class="ig hi">上连接或联系我。</strong>感谢您的支持！</p><p id="7693" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是我的GitHub知识库的链接，我计划在这里收集代码和许多与机器学习、人工智能等相关的资源。</p><div class="lk ll ez fb lm ln"><a href="https://github.com/SalvatoreRa/tutorial" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">GitHub - SalvatoreRa/tutorial:关于机器学习、人工智能、数据科学的教程…</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">关于机器学习、人工智能、数据科学的教程，包括数学解释和可重复使用的代码(python…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">github.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb jm ln"/></div></div></a></div><p id="2b5d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或者随意查看我在Medium上的其他文章:</p><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/mlearning-ai/generate-a-piano-cover-with-ai-f4178bc9cb30"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">用人工智能生成钢琴盖</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">一个新的模型从一首流行歌曲中生成了一个钢琴封面:它是如何工作的？你如何能尝试它？</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="mc l ly lz ma lw mb jm ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/illumination/how-ai-reimages-emotions-618c97cea132"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">人工智能如何重新成像情感</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">人工智能能在图像中转换甚至难以用语言解释的概念吗？</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="md l ly lz ma lw mb jm ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/illumination/ai-reimagines-mythical-creatures-49a57d5be909"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">人工智能重新想象神话生物</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">受中世纪动物寓言启发的现代动物寓言。</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="me l ly lz ma lw mb jm ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a href="https://pub.towardsai.net/google-unitune-text-driven-image-editing-4b176b1b16a1" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">Google UniTune:文本驱动的图像编辑</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">如何用文字修改你的图像</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">pub.towardsai.net</p></div></div><div class="lw l"><div class="mf l ly lz ma lw mb jm ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="mg l ly lz ma lw mb jm ln"/></div></div></a></div></div></div>    
</body>
</html>
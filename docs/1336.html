<html>
<head>
<title>Sensorial-based ML Applications in Modern Industrial Product-Lines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于感官的ML在现代工业生产线中的应用</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/sensorial-based-ml-applications-in-modern-industrial-product-lines-d4fed701b450?source=collection_archive---------4-----------------------#2021-11-24">https://medium.com/mlearning-ai/sensorial-based-ml-applications-in-modern-industrial-product-lines-d4fed701b450?source=collection_archive---------4-----------------------#2021-11-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a21ced67f371213648de9611a2bcbf61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90YazhbdUZTop4ZSU9wiJg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">When Machine-Learning (ML) meets modern sensorial-based product-lines</figcaption></figure><h1 id="4a03" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="abd1" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">现代工业生产线通常包括几十个传感器，这些传感器沿着产品的生成路径对每一个发展中的产品进行连续采样。从数据科学家的角度来看，这被解释为一座金矿，即一个巨大的数据集，它不断增长，并包含多个时间序列向量。在某些情况下，数据甚至可以用宁滨结果、质量测试标签等进行注释。</p><p id="a999" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">本文对现代工业生产线领域中常见的机器学习(ML)应用进行了技术概述。它没有过多地涉及编码细节，而是侧重于架构方面，并强调了几个定性讨论。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="f4e6" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">议程</h1><ol class=""><li id="6517" class="lg lh hh jt b ju jv jy jz kc li kg lj kk lk ko ll lm ln lo bi translated">问题定式化</li><li id="9de3" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">探索性数据分析</li><li id="97fe" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">特征工程</li><li id="dc19" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">聚类分析</li><li id="0c22" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">异常检测</li><li id="3d40" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">时间预测</li><li id="cf96" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">质量(QA)预测</li></ol></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="6de2" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">1.问题定式化</h1><p id="234f" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">每个工业批次沿着生产线路径经历不同的阶段(即状态)。每个阶段由多个传感器以给定的采样率监控。来自所有传感器的数据通常由指定的BI ETL管道收集和管理。BI，即商业智能，是指一套用于将原始数据转换为有意义的可用信息并获得对业务运营和机会的可操作洞察的流程和技术。BI ETL指的是从多个来源提取数据、将其转换为用于查询、报告和分析的适当格式或结构，并将其加载到数据仓库或其他类型的集中式数据存储库中的过程。</p><p id="33ab" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">BI ETL与AI或人工智能核心交互，该核心保存所有与数据科学相关的分析。BI提供输入数据，AI最终提交回相应的机器学习见解。AI和BI之间的通信通常通过SQL协议来应用。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/e50ebff9633f694ff07ed9020fb290f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VGA3_EyiV4lpc2uFghO-vQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">BI/AI interaction for modern sensorial-based product-lines — illustration</figcaption></figure><p id="dae4" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">常见基本术语:</p><ul class=""><li id="8a9b" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated"><strong class="jt hi">批次</strong>:沿着产品线发展的独特对象</li><li id="968d" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">样本</strong>:特定时间内所有传感器输出的集合。每批包括多个样本，即多个传感器结果。</li><li id="24d9" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">状态</strong>:批次生命周期中的一个独特阶段。产品线可以保持多种状态</li><li id="6190" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">传感器</strong>:监控生产过程中批次状态的物理设备。现代生产线通常维护多个传感器，每个传感器监控不同的指标，使用不同的标度</li><li id="13a3" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">虚拟传感器</strong>:物理传感器在不同状态下的拆分。例如，如果<em class="mc">传感器0 </em>在<em class="mc">状态0 </em>和<em class="mc">状态1 </em>上采样数据，那么对应的虚拟传感器是<em class="mc">传感器0 _状态0 </em>和<em class="mc">传感器0 _状态1 </em></li><li id="7b9d" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">全球时间</strong>:时间轴代表每个批次的整个生命周期</li><li id="6554" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">状态时间</strong>:时间轴代表每个批次的每个状态的生命周期</li></ul><p id="9552" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">接下来的部分将深入上图的人工智能应用方面。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="d71a" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">2.探索性数据分析(“迷你EDA”)</h1><p id="0f4c" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">在数据科学中，EDA术语通常是指对工程特性及其与因变量(以及它们自身)的相关性的初步分析。因此，“<strong class="jt hi">迷你EDA </strong>的主要目标是感受数据，获得关于其统计分布和各种变量(因变量和自变量)的一些初步见解。这种见解可以帮助数据科学家评估人工智能方法对于给定问题的可行性和潜力。应当注意，在提取任何特征之前，对原始感觉数据执行“迷你EDA”。</p><p id="b69b" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">下面列出了几个主要观察结果，并附有相应的图表</p><ul class=""><li id="d0b0" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated">每批样品(<em class="mc">左上角</em>)</li><li id="1964" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">每个传感器的样本(<em class="mc">中左</em>)</li><li id="9b27" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">每个状态的样本数(<em class="mc">左下角</em>)</li><li id="95c4" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">传感器与全球时间(<em class="mc">右上</em>)</li><li id="eb8c" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">传感器与状态时间(<em class="mc">中右</em>)</li><li id="8002" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">质量保证(QA) /每批实验室结果(<em class="mc">右下角</em>)</li></ul><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es md"><img src="../Images/de717665fcd5600d30e0633f6ee0b7c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DIJafaR6famevabiUboZqg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">mini-EDA phase — key observations</figcaption></figure><p id="7105" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">mini-EDA提供了对数据分布的快速了解，并解决了以下问题:</p><ul class=""><li id="5c06" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated">这些批次包含多少样本(从统计角度来看)？</li><li id="14aa" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">传感器包含多少样本(统计意义上)？</li><li id="57de" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">每个州包含多少个样本？</li><li id="aaaa" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">传感器如何随时间变化(对于任意批次)？</li><li id="6911" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">质量保证/实验室结果如何分布在各个批次中？</li></ul></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="921e" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">3.特征工程</h1><p id="b1b9" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">传感数据包括多个批次，每个批次充当一个多维时间序列(每个单个传感器代表一个一维时间序列)。<strong class="jt hi">特征工程</strong>阶段将问题从时域转移到特征域，同时通过统计度量利用时间信息。这允许在时间序列域之外的普通人工智能方法中的进一步处理。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/f1b418afdde35f5488ce93f221ea382f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSnVvbngc6563ebNKYQp1g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Features-Engineering (figure captured from tsfresh python package page</figcaption></figure><p id="d395" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">人工智能工具箱包含几个强大的方法，可以应用于当前的问题。这些方法可以分为两大类，即经典方法和神经网络方法。第一类是所谓的“浅层学习”方法，最后一类是所谓的“深度学习”方法。当谈到特征工程时，经典方法需要显式实现，而神经网络方法隐式地学习/工程特征，因此不需要显式实现。因此，本节指的是经典方法。一个非常流行的针对features-engineering的python包是<a class="ae mf" href="https://tsfresh.readthedocs.io" rel="noopener ugc nofollow" target="_blank"><strong class="jt hi"><em class="mc">ts fresh</em></strong>T5】。它自动计算大量的时间序列特征，即所谓的特征。此外，该软件包还包含评估这些特征对回归或分类任务的解释能力和重要性的方法。</a></p><p id="b99d" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated"><a class="ae mf" href="https://tsfresh.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> <em class="mc"> tsfresh </em> </a>包提供了4个级别的功能工程:</p><ul class=""><li id="a86d" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated"><strong class="jt hi">综合FCParameters </strong> —提取所有特征</li><li id="8e51" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">efficient fcparameters</strong>—跳过计算成本高的功能</li><li id="edb5" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">MinimalFCParameters</strong>——仅一小部分特征(快速设置)</li><li id="f526" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">TimeBasedFCParameters</strong>—仅需要DateTimeIndex的功能</li></ul><p id="d229" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">一旦特征被提取出来，探索它们与因变量的相关性是很有趣的，因此是QA / Lab结果。为此，常见的相关性指标是皮尔逊和斯皮尔曼系数，其范围在-1和+1之间，分别评估线性关系和单调关系。</p><p id="9197" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">下图显示了每个特征(x轴)的<strong class="jt hi">皮尔森</strong>(上)和<strong class="jt hi">斯皮尔曼</strong>(下)系数值，以及特定的QA/Lab结果。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mg"><img src="../Images/d5065e864934f189f4118f0b6cc60e7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eH9dcdJnVhmpgNBGhXgBcA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Pearson and Spearman correlation metrics</figcaption></figure><p id="ebac" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">皮尔逊和斯皮尔曼系数通常用热图方式的<strong class="jt hi">相关矩阵</strong>设置来处理。这不仅允许对特征和因变量之间的相关性进行更深入的分析，还允许对特征和它们自身之间的相关性进行更深入的分析。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/6b55e968346d109563f6cac7316ea45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5f-YMRSJyrbjPWs-XMniww.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Correlation Matrix analysis (figure captured from plotCorrelation python package page)</figcaption></figure><p id="c2c9" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">基于可用的特征，相关性分析建议监督学习方法是否可能成功预测因变量。显著的相关性(系数接近1的许多特征)可能会促使这种方法最终工作良好。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="c88c" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">4.聚类分析</h1><p id="020b" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">在这一点上，每一批都在反映原始感觉数据的关键统计度量的高维特征域中表示。聚类的目标是尝试将每一批标记到相应的桶中，其方式在数学上(例如，最小化给定的误差度量)和直观上(例如，每个桶将理想地能够检索一些人工解释)都有意义。</p><p id="20ae" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated"><strong class="jt hi">聚类分析</strong>是机器学习的一个分支，驻留在无监督学习框架中。无监督学习是一种机器学习，它在没有预先存在的标签和最少人工监督的情况下，在数据集中寻找以前未检测到的模式。一种常用的聚类分析算法是<strong class="jt hi"> K-Means </strong>算法。</p><p id="8eb2" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">K-Means算法通过尝试将样本分成n组相等的方差来对数据进行聚类，从而最小化称为<strong class="jt hi"> <em class="mc">惯性</em> </strong>或类内平方和的标准。该算法要求指定聚类数。它适用于大量样品，并已在许多不同领域的大范围应用中使用。k-means算法将一组N个样本X分成K个不相交的聚类C，每个聚类由聚类中样本的平均值μj来描述。这些平均值通常被称为星团“质心”。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/5691bcd48c2b8354d9ba28604f44d8cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*S0lLwhYx6WLV5NOoMVRSHw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">K-Means Inertia criterion, aka within-cluster sum-of-squares</figcaption></figure><p id="5a94" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">平均复杂度由O(k n T)给出，其中n是样本数，T是迭代次数。在实践中，k-means算法非常快(可用的最快的聚类算法之一)，但它会陷入局部最小值。这就是为什么重启几次会很有用。然而，对于许多实际应用，局部最小值是一个足够好的解决方案。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/b1185a3bf7c4ccfebd344781d40d6e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Mdrce26BJKpzR-qii4Yig.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Features Normalization, aka Standardization</figcaption></figure><p id="a099" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">在应用K-Means聚类算法之前，对特征进行规范化是必不可少的，也称为<strong class="jt hi">标准化</strong>(回想一下，每个特征可能存在于完全不同的范围内)。两个常见的规范化实现是<a class="ae mf" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.whiten.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">scipy . cluster . VQ . whiten</em></a>和<a class="ae mf" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">sk learn . preprocessing . standard scaler</em></a><em class="mc"/>(python库)。在这个阶段结束时，每个批次都在一个标准化的高维特征域中表示，并准备好进行聚类分析。</p><p id="3588" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">K-Means 的常见python <strong class="jt hi">实现是<a class="ae mf" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">sk learn . cluster . K Means</em></a>，它遵循劳埃德或埃尔坎的算法。</strong></p><p id="08e5" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">总体编码可能会如下所示:</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="9bbc" class="mo iu hh mk b fi mp mq l mr ms">from sklearn.cluster import KMeans<br/>from scipy.cluster.vq import whiten</span><span id="50f8" class="mo iu hh mk b fi mt mq l mr ms">features_df_whiten = features_df.copy()</span><span id="5959" class="mo iu hh mk b fi mt mq l mr ms">km = KMeans(n_clusters=clusters_num, <br/>            init=’random’, <br/>            n_init=10, <br/>            max_iter=300, <br/>            tol=1e-04, <br/>            random_state=0,<br/>            algorithm=”auto”)</span><span id="3d68" class="mo iu hh mk b fi mt mq l mr ms">y_km = km.fit_predict(features_df_whiten)</span><span id="cc61" class="mo iu hh mk b fi mt mq l mr ms">cluster_centers_df = pd.DataFrame(km.cluster_centers_)</span></pre><p id="9dd5" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">其中<em class="mc"> features_df </em>保存特征数据帧(N批x M个特征),而<em class="mc"> cluster_num </em>是定义K-Means的聚类数的参数。得到的数据帧被称为<em class="mc"> cluster_centers_df </em>，大小为C×M，其中C等于<em class="mc"> cluster_num </em>。换句话说，上面的代码片段以C个集群结束，其中每个集群由M个特征的向量表示。另外一个结果是<em class="mc"> y_km </em>向量，它将每个给定的批次映射到其对应的集群索引上，从0到C-1。</p><p id="8e70" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">为了可视化的目的，有必要将高维(M)特征域减少到更少的坐标(2或3)。实现这一目标的常见策略是<strong class="jt hi">主成分分析(PCA) </strong>算法。</p><p id="f008" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">PCA是一种无监督的学习技术，它提供了许多好处。例如，通过降低数据的维度，PCA能够实现更好的一般化机器学习模型，从而有助于处理“<a class="ae mf" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维度诅咒</a>”。此外，主成分分析可以帮助我们以非常低的模型精度成本提高性能，因为大多数算法的性能取决于数据的维度。PCA的其他好处包括减少数据中的噪声、特征选择(在一定程度上)以及产生独立的、不相关的数据特征的能力。</p><p id="46a8" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">这里，PCA被应用于可视化目的，并且允许检查K-Means聚类结果。PCA 常见的python <strong class="jt hi">实现是<a class="ae mf" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">sk learn . decomposition . PCA</em></a>。除了可视化，它实际上提供了一个额外的重要结果，这就是<strong class="jt hi">集群的贡献</strong>。例如，下图暗示14个聚类可能是K-Means <em class="mc"> cluster_num </em>参数的合适选择，因为14个聚类似乎覆盖了约90%的解释方差。</strong></p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mu"><img src="../Images/dfe29ce86ca3532435e285fbeeb80145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_r4-BlgY87GVOC1iRzArpw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Clusters Contribution, by PCA</figcaption></figure><p id="a767" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后，通过选择2(对于2D图)或3(对于3D图)最高有效坐标，可以在PCA域中可视化K均值聚类结果。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/55692ed9792f254df22eb5218805c988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s3tSu41OKq4zyM8ByugXGg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">K-Means Cluster-Analysis result in a 2D PCA domain</figcaption></figure><p id="6cf6" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">因此，每个<strong class="jt hi">点</strong>代表一个批次，每个<strong class="jt hi">星</strong>代表一个集群。</p><p id="1142" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">总之，我们从特征工程开始，将问题从原始感知领域(时间序列)转移到高维特征领域。这些特征进入标准化阶段，然后通过K-Means算法进行聚类。最后，在2D主成分分析域中可视化得到的聚类。</p><p id="f284" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后一点，时间序列分析的另一个常用策略叫做<strong class="jt hi">动态时间弯曲</strong> (DTW)，可以应用于<strong class="jt hi">层次聚类分析</strong> (HCA)。DTW/HCA常见的python实现是<a class="ae mf" href="https://dtaidistance.readthedocs.io/en/latest/modules/clustering.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">dtaidistance . clustering</em></a>。这里不再详细讨论这一策略，古玩读者可以在本文<a class="ae mf" href="https://towardsdatascience.com/time-series-hierarchical-clustering-using-dynamic-time-warping-in-python-c8c9edf2fda5" rel="noopener" target="_blank">中找到一个很好的起点。</a></p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mw"><img src="../Images/0cc4f25ed702107effa7965dcc50f13e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6gUhVTDDory2jn80Wh2ng.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Hierarchical-Clustering Analysis (HCA) using Dynamic Time Warping (DTW)</figcaption></figure></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="dc63" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">5.异常检测</h1><h1 id="0cbe" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">隔离森林</h1><p id="21ba" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated"><strong class="jt hi">“隔离森林</strong>是一种用于异常检测的无监督学习算法，其工作原理是隔离异常”(<a class="ae mf" href="https://en.wikipedia.org/wiki/Isolation_forest" rel="noopener ugc nofollow" target="_blank">维基百科</a>)。该算法的核心是通过在随机属性上创建决策树来“隔离”异常。随机分区为异常产生明显更短的路径，因为更少的(异常)实例导致更小的分区，并且因为可区分的属性值更可能在早期分区中被分离。因此，当随机树的森林集体地为一些特定点产生较短的路径长度时，那么它们很可能是异常的。下图展示了(在2D域中)隔离异常通常需要较少数量的分裂。</p><p id="389d" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">图12 —隔离林概念—异常需要更少的拆分</p><p id="52f9" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">隔离森林的常见python <strong class="jt hi">实现是<a class="ae mf" href="https://scikit-learn.org/0.20/modules/generated/sklearn.ensemble.IsolationForest.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">sk learn . ensemble . Isolation Forest</em></a>，只需要几行代码:</strong></p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="8615" class="mo iu hh mk b fi mp mq l mr ms">from sklearn.ensemble import IsolationForest</span><span id="89e1" class="mo iu hh mk b fi mt mq l mr ms">X = np.array(features_pca_df)</span><span id="9f7f" class="mo iu hh mk b fi mt mq l mr ms">model = IsolationForest(behaviour=’new’, # Decision_function<br/>                        contamination=0.01, # outliers_fraction<br/>                        random_state=42) # seed<br/>                        model.fit(X)<br/> <br/>y_pred = model.predict(X)</span></pre><p id="17bc" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">上述代码片段的输入称为<em class="mc"> X </em>，包含PCA域中的特征。从这个意义上说，它是上一个集群部分的直接延续。这意味着原始感知数据(时间序列)在进入隔离森林阶段之前要经过特征工程、标准化和PCA阶段。产生的输出是一个向量，称为<em class="mc"> y_pred </em>，它预测每个例子是否应该被认为是内侧(+1)或外侧(-1)。同样，PCA方法可以应用于2D(或3D)可视化。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mx"><img src="../Images/defcb1a7879dbe9c46617c6e031235bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMAzgSwwk5Q-ce4PpcgEIg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Anomaly-Detection with Isolation-Forest, visualized in a 2D PCA domain</figcaption></figure><p id="c04a" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">上图中的每个点代表一个不同的批次，颜色暗示异常决策。可以观察到，在右下方区域有一个孤立的孤立批次。接下来，探索异常推理通常很有趣，一种常见的技术是根据每个特征将异常值批次与平均值进行比较。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es my"><img src="../Images/c6385193e52c9c1984c7de22c4b13c77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uGnIPqbQmmFkO_EKDqsVcQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Anomaly-Detection with Isolation-Forest — Exploring anomalies reasoning</figcaption></figure><p id="d3fa" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">左图应用了RMSE指标，而右图应用了MAPE指标进行比较。红色水平线(右图)表示参数阈值。可以观察到，5个特征负责异常判定。</p><h1 id="4dd1" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">LSTM自动编码器</h1><p id="1bad" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">这是本文中第一次遇到深度学习，也是在问题公式化部分介绍的“虚拟传感器”术语的使用。</p><p id="b89c" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">自动编码器神经网络试图学习其输入的数据表示，通常是通过学习使用较少参数/内存的<strong class="jt hi">高效编码</strong>。在某种意义上，该模型使用尽可能少的参数来学习数据的最重要特征。</p><p id="8cfa" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">使用这种架构进行<strong class="jt hi">异常检测</strong>的基本原理是，模型根据“正常”数据进行训练，并确定产生的<strong class="jt hi">重建误差</strong>。然后，当模型遇到超出规范的数据并试图重建时，它将以重建误差的增加而结束，因为该模型从未被训练来准确地重建超出规范的项目。</p><p id="e232" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">使用LSTM单元的一个优点是能够在分析中包含<strong class="jt hi">多变量特征</strong>。这里是每个时间步的多个传感器读数。但是，在在线异常检测分析中，它可能是每个时间步长的要素。</p><p id="e013" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">自动编码器神经网络模型通常使用长短期记忆(LSTM)递归神经网络(RNN)细胞创建，这在Keras/TensorFlow框架内得到支持。Brent Larzalere的文章很好地涵盖了这个主题。</p><p id="320b" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">以下步骤适用于每个状态的<strong class="jt hi">:</strong></p><ol class=""><li id="39b7" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko ll lm ln lo bi translated"><strong class="jt hi">将所有批次连接成一个时间线(“虚拟传感器”)</strong></li><li id="d757" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated"><strong class="jt hi">交叉验证</strong> —训练/测试数据集分割，例如80:20</li><li id="68f0" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated"><strong class="jt hi">标准化</strong>，例如最小/最大</li><li id="6144" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated"><strong class="jt hi">重塑</strong>将标准化数据转换成适合输入LSTM网络的格式。LSTM单元期望一个形式为[数据样本，时间步长，特征]的三维张量。这里，输入到LSTM网络中的每个样本代表一个时间步长，并包含4个特征(在该时间步长上四个方位的传感器读数)</li><li id="2c6f" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">使用Keras库创建一个作为Python函数的自动编码器神经网络模型。<strong class="jt hi">编译</strong>使用Adam作为神经网络优化器，计算损失函数的平均绝对误差。</li><li id="3e87" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated"><strong class="jt hi">使</strong>模型符合训练数据并对其进行训练，例如100个时期。查看模型性能评估的培训损失通常很有趣。</li><li id="46a6" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko ll lm ln lo bi translated">探索<strong class="jt hi">损失分布</strong>，相应设置<strong class="jt hi">异常阈值</strong>。</li></ol><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mz"><img src="../Images/7f0b5d69379859141030e1599e0aed94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j0Lqb4DStUM6y8IYz1M7DQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Anomaly-Detection with LSTM AutoEncoder — Learning phase Anomaly prediction</figcaption></figure><p id="c908" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">上图指的是某个任意状态，称为“0108”。学习曲线图(左)表明，就偏差和方差而言，学习在年进展良好，因为训练和验证曲线最终都足够低且相对紧密。不过，应用较低的回声(~80)来提前结束学习并避免过度拟合似乎是个好主意。损失分布图(中间)意味着下降异常阈值可以设置为~0.3，因为较高的损失相对较少。最后，损失-时间图(右)提供了串联批次损失的有趣视图，分为训练和验证组。绿色水平线标记异常阈值，可以观察到异常已经被检测到并超过了阈值。</p><p id="f25b" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">对于相关状态，可以通过探索传感器-时间图来获得准确的异常推理。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es na"><img src="../Images/90ae106eb61b4f779b9fd1529f9389da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fFNzOFUpv5O_9dy9mxTS2g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Anomaly-Detection with LSTM AutoEncoder — Exploring anomalies reasoning</figcaption></figure><p id="528a" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">上图指的是示例状态(“0108”)，包括多个每个传感器的子图。每个子图将采样值与预测值进行比较，另外用红色标记突出显示异常时间戳。这一观点暗示了特定的异常原因。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="83d2" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">6.时间预测</h1><p id="8c2b" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">在题目的背景下，一个关键的观察结果是大多数时间序列数据可以由三个部分描述:</p><ul class=""><li id="54ff" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated"><strong class="jt hi">趋势</strong> →随时间变化且不重复的一般系统线性或(最常见的)非线性成分</li><li id="1b7a" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">季节性</strong> →一般系统的线性或(最常见的)非线性成分，随时间变化并重复</li><li id="8a40" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated"><strong class="jt hi">噪声</strong> →数据中非趋势/季节性的非系统成分</li></ul><p id="dfdd" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">将给定的时间序列分解成上述组成部分的过程被称为<strong class="jt hi">季节分解</strong>，通常以相加的方式应用。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nb"><img src="../Images/d83b1f95de6da7ddd8842fc395e3f608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nopnoL_nX5xXD7YgpiTJ6Q.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Seasonal Decomposition example</figcaption></figure><p id="e8e4" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated"><strong class="jt hi">时间预测</strong>是一个热门话题，有很多可能的应用，比如股票价格预测、天气预报、商业规划、资源分配等等。时间预测技术有很多种，在<a class="ae mf" href="https://towardsdatascience.com/an-overview-of-time-series-forecasting-models-a2fa7a358fcb" rel="noopener" target="_blank">大卫·伯巴的文章</a>中也有描述，因此重点放在ARIMA框架上。</p><p id="5cec" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated"><strong class="jt hi"/></p><p id="27a3" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">ARIMA模型有三个特征:d，p，q</p><ul class=""><li id="ec42" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated">d是差分的<strong class="jt hi">阶，即使时间序列平稳所需的差分次数。“d”参数可以从ACF图中提取，作为进入显著性圆锥的最小差分阶数</strong></li><li id="e7c4" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">p是AR项的<strong class="jt hi">阶，即用作预测值的Y的滞后数。在进入显著性圆锥之前，可以从PACF图中提取“p”参数，作为初始尖峰的数量。</strong></li><li id="30b4" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">q是MA项的<strong class="jt hi">阶，即应该进入模型的滞后预测误差的数量。在进入显著性圆锥之前，可以从ACF图中提取“q”参数，作为初始尖峰的数量</strong></li></ul><p id="6a9f" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">ARIMA模型是这样一种模型，其中时间序列被微分d次以使其平稳，然后组合AR和MA项。<br/>所以等式变成了:</p><p id="3d82" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi">𝑌𝑡=𝛼+𝛽1𝑌𝑡−1+𝛽2𝑌𝑡−2+…+𝛽𝑝𝑌𝑡−𝑝+𝜖𝑡+𝜙1𝜖𝑡−1+𝜙2𝜖𝑡−2+…+𝜙𝑞𝜖𝑡−𝑞</p><p id="3f8f" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">ARIMA的<strong class="jt hi"> SARIMAX </strong>扩展，它在单变量数据中显式地模拟季节性因素。除了ARIMA d、p、q参数之外，还有四个季节性因素:</p><ul class=""><li id="d39d" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated">p:季节性自回归序列。</li><li id="9075" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">d:季节性差异订单。</li><li id="a23a" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">问:季节性移动平均订单。</li><li id="a6ef" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">m:单个季节周期的时间步长数。</li></ul><p id="7187" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">当预测值不相关且相互独立时，线性回归模型效果最佳。因此，建立ARIMA模型的第一步是使时间序列<strong class="jt hi">平稳</strong>。平稳过程具有均值、方差和自相关结构不随时间变化的特性。检查平稳性的最流行方法之一是应用<a class="ae mf" href="https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test" rel="noopener ugc nofollow" target="_blank">增强的Dickey Fuller (ADF) </a>测试。ADF测试得到一个输入时间序列，并返回一个名为<em class="mc"> p值</em>的分数。如果<em class="mc"> p值</em>大于显著性水平0.05，则输入时间序列不是平稳的。</p><p id="f0c8" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">常见的python实现arima(和SARIMAX)是<a class="ae mf" href="https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html" rel="noopener ugc nofollow" target="_blank"><em class="mc">pmdarima . ARIMA . auto _ ARIMA</em></a>，自动发现ARIMA模型的最优阶。对每个传感器和每个状态重复该过程。所有的批处理都被连接起来，通过标准化，进入<em class="mc"> auto_arima </em>管道。结果是每个传感器和每个状态的时间预测模型，其可以应用于未来的传感器/状态行为。该模型可被视为额外的异常检测引擎，例如，如果实际样本明显偏离相应的预测，则称之为“异常”。</p><p id="a897" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">下图指的是一个称为“s22”的特定传感器，其中每一列对应一个不同的状态。顶行和底行分别提供时间轴上的缩小和放大视图。灰色圆锥代表预测确定性，其中窄圆锥意味着高确定性。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nc"><img src="../Images/9cfb9faaec45b087437633921091fde4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oEVI_muajDtBgbtS4JzFyQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Time Forecasting — Example of a specific sensor, per each state</figcaption></figure><p id="a304" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后一点，时间序列预测的另一个常用工具叫做<strong class="jt hi">脸书预言家</strong>。它是一个加法回归模型，有四个主要组成部分:</p><ul class=""><li id="b4e4" class="lg lh hh jt b ju kp jy kq kc ly kg lz kk ma ko mb lm ln lo bi translated">分段线性或逻辑增长曲线趋势。Prophet通过从数据中选择变化点来自动检测趋势的变化。</li><li id="f87c" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">使用傅立叶级数模拟的年度季节性成分。</li><li id="c4c2" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">使用虚拟变量的每周季节性成分。</li><li id="6a88" class="lg lh hh jt b ju lp jy lq kc lr kg ls kk lt ko mb lm ln lo bi translated">用户提供的重要节假日列表。</li></ul><p id="e2ee" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">不过，这里不会进一步详细讨论这一策略，古玩读者可能会在<a class="ae mf" href="https://facebook.github.io/prophet/" rel="noopener ugc nofollow" target="_blank">这个链接</a>找到一个很好的起点。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="55b0" class="it iu hh bd iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm lf jo jp jq bi translated">7.质量(QA)预测</h1><h1 id="b018" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">XGBoost</h1><p id="9a29" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">XGBoost代表“极端梯度推进”，其中术语“梯度推进”源自弗里德曼的论文<em class="mc">贪婪函数近似:梯度推进机器</em>。XGBoost用于监督学习问题，其中训练数据(具有多个特征)用于预测目标变量。</p><p id="b413" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">XGBoost实际上是一个<strong class="jt hi">决策树集成</strong>模型。树集成模型由一组分类和回归树(CART)组成。下图是一个简单的购物车示例，它对某人是否会喜欢一个假想的电脑游戏x进行分类。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nd"><img src="../Images/6f15cba68733acfef820157ff9a67f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IG6LbqIt_AUJBo-f8XcQ7A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">XGBoost CART example for whether someone will like a hypothetical computer game X</figcaption></figure><p id="1f7e" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">家庭成员被分类到不同的叶子中，并在相应的叶子上分配分数。CART与决策树有点不同，决策树的叶子只包含决策值。在CART中，一个真实的分数与每片叶子相关联，这给了我们比分类更丰富的解释。通常情况下，单棵树的强度不足以在实践中使用。实际使用的是系综模型，将多棵树的预测汇总在一起(见上图右侧子图)。</p><p id="0e52" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">回到我们关注的基于感觉的问题，来自系综森林的真实决策树将如下结束:</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ne"><img src="../Images/2b3229ea9d405d79172af7c2dbe2cc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UaDfRpcPEUKSg2QSCBccdQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">XGBoost — a realistic example for a sensorial decision tree</figcaption></figure><p id="fbae" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">常见的python实现XGBoost是<a class="ae mf" href="https://xgboost.readthedocs.io/en/latest/python/index.html" rel="noopener ugc nofollow" target="_blank"> XGBoost Python包</a>，它是一个开源库，提供了梯度增强决策树的高性能实现。底层的C++代码库与顶层的Python接口相结合，构成了一个极其强大而又易于实现的包。XGBoost带有多个超参数，结合<strong class="jt hi"> GridSearch </strong>来寻找最佳设置通常是一个好的实践。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="277a" class="mo iu hh mk b fi mp mq l mr ms">import xgboost as xgb<br/>from sklearn.model_selection import GridSearchCV</span><span id="dc39" class="mo iu hh mk b fi mt mq l mr ms">model = xgb.XGBRegressor()</span><span id="d434" class="mo iu hh mk b fi mt mq l mr ms">parameters = {'nthread':[4],<br/>              'objective':['reg:linear'],<br/>              'learning_rate': [.03, 0.05, .07],<br/>              'max_depth': [5, 6, 7],<br/>              'min_child_weight': [4],<br/>              'silent': [1],<br/>              'subsample': [0.7],<br/>              'colsample_bytree': [0.7],<br/>              'n_estimators': [500]}</span><span id="8aaa" class="mo iu hh mk b fi mt mq l mr ms">xgb_grid = GridSearchCV(model,<br/>                        parameters,<br/>                        cv = 3,<br/>                        n_jobs = 4, <br/>                        verbose = True)</span><span id="6869" class="mo iu hh mk b fi mt mq l mr ms">xgb_grid.fit(X, y)</span><span id="e12d" class="mo iu hh mk b fi mt mq l mr ms">model_score = xgb_grid.best_score_<br/>model_params = xgb_grid.best_params_</span></pre><p id="e1ab" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated"><em class="mc"> X </em>和<em class="mc"> y </em>表格中的每一行对应不同的批次(索引保存批次id)。<em class="mc"> X </em>中的每一列对应一个不同的特性，而<em class="mc"> y </em>中有一列保存QA/Lab结果。因为通常有多种QA/Lab类型，所以对于每种类型，该过程重复多次。</p><p id="befe" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">为了建立更健壮的模型，通常应用<strong class="jt hi"> K重交叉验证</strong>，其中原始训练数据集中的所有条目都用于训练和验证(每个条目仅用于验证一次)。另一个重要的结果是XGBoost训练的最佳步数。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nf"><img src="../Images/2ce8c89dc22145f064434ca93bd87b9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tawDk3EeKhGOcfmzSVN1Rg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">XGBoost applies K-Fold Cross Validation method</figcaption></figure><p id="f7dd" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">接下来，在训练集上训练最佳模型。然后将训练好的模型用于预测测试集QA/Lab结果。最后，将模型预测与真实的已知结果进行比较，以评估模型性能。在竞赛中，比较模型性能与每个QA/Lab结果的内在差异通常很有意思，以便评估误差范围。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/03f404fa91b7f2b81efd0cfdfbebba93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4v_ozQxTsaz04GBUy-MpSg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">XGBoost result example — Actual vs. Predicted, for a specific QA/Lab types</figcaption></figure><p id="376d" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">XGBoost模型的另一个重要输出是<strong class="jt hi">特性重要性</strong>。<strong class="jt hi"> </strong>可以检查模型内原始数据集中每个特征列的重要性。通过计算每个特征在模型中的所有推进回合(树)中被分割的次数来检索该结果。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ng"><img src="../Images/b98a8eac3f35bf254c2f79f0638bc508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kcegoVHUDda4xEn0pFiA6A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">XGBoost result example — Features Importance, for a specific QA/Lab types</figcaption></figure><h1 id="c41e" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">LSTM-RNN(多对多)</h1><p id="4e08" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">递归神经网络(<strong class="jt hi"> RNN </strong>)已经被证明可以有效地解决序列问题。特别地，长短期记忆网络(<strong class="jt hi">【LSTM】</strong>)是RNN的变体，目前被用于各种领域来解决序列问题。</p><p id="2f74" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated"><strong class="jt hi">多对一</strong>序列问题获取一系列数据作为输入，并且必须预测单个输出。<strong class="jt hi">多对多</strong>序列问题有一个数据序列作为输入，必须预测一个维度的输出。</p><p id="35ea" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">多对一LSTM网络常用于基于传感器的<strong class="jt hi">活动识别</strong>(如<a class="ae mf" href="https://www.mdpi.com/1424-8220/19/7/1716" rel="noopener ugc nofollow" target="_blank"> Chung，Seungeun等人，2019 </a>)、情感分析<strong class="jt hi"/>(如<a class="ae mf" href="https://ieeexplore.ieee.org/abstract/document/8692753" rel="noopener ugc nofollow" target="_blank"> Wen，Shiping等人，2019 </a>)等任务。在这里，我们愿意训练一个LSTM网络来预测QA/Lab结果评分(输出)，基于多变量传感器数据(输入)。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nh"><img src="../Images/124ec3db54b654f76cf17320af0cfaea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0hPMluws0r0ymkLpm7qubA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Common sequence problem types</figcaption></figure><p id="6c38" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">作为<strong class="jt hi">虚拟传感器</strong>公式的一部分，每个传感器(Sx)按状态(Sx_State)分开，并根据最长的系列用零填充。一个附加的表格保存了每个批次的所有质量保证/实验室结果。接下来，从这两个表的交集中提取出<em class="mc"> X </em>和<em class="mc"> y </em>数组(数据和标签)。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ni"><img src="../Images/b3933b46a962fc9eafd4ef6e74bc517c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d9LOTLdIvjCD_Ex6OtfVeQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Virtual Sensors formulation</figcaption></figure><p id="a300" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">执行交叉验证，例如80/20，用于将数据和标签分成训练集和测试集。然后，每个集合都经过标准化(也称为标准化)。最后，每一组都被整形以符合LSTM格式。数据集被整形为(<em class="mc">样本、时间步长、特征)</em>维度，而标签集被整形为<em class="mc">(样本、特征)</em>维度。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nj"><img src="../Images/998ffb1203f8ac63e7b4851eb8b399ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VpYY8M94pRyPxQU6LGVqaA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Virtual Sensors before (left) and after (right) normalization</figcaption></figure><p id="c7a5" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">在这个阶段，数据和相应的标签已经准备好被注入到LSTM中，所以是时候编译神经网络了。确切的架构需要一定程度的探索，尽管在实践中，即使是如下相对简单的网络也可能产生下降结果。据此，最长系列有17626个样本，有23种QA/Lab结果。</p><figure class="lu lv lw lx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nk"><img src="../Images/bb3660f471d98e447a1aac955aec53f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*naKGRMW1jMVwCrly1SpBZw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">RNN LSTM architecture example for QA/Lab results prediction</figcaption></figure><p id="5ce9" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">LSTM模型以小批量方式训练1000个时期，验证分割为5%:</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="1d16" class="mo iu hh mk b fi mp mq l mr ms">history = model.fit(X,<br/>                    y, <br/>                    epochs=1000, <br/>                    batch_size=512,<br/>                    validation_split=0.05,<br/>                    verbose=2).history</span></pre><p id="2976" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后，通过比较实际标签和预测标签，可以在测试集上评估模型性能。</p><div class="nl nm ez fb nn no"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="np ab dw"><div class="nq ab nr cl cj ns"><h2 class="bd hi fi z dy nt ea eb nu ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nv l"><h3 class="bd b fi z dy nt ea eb nu ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nw l"><p class="bd b fp z dy nt ea eb nu ed ef dx translated">medium.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc in no"/></div></div></a></div></div></div>    
</body>
</html>
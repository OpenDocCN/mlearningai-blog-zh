<html>
<head>
<title>Neural Networks: It’s all about the embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络:一切都是关于嵌入</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/intuition-to-neural-network-embeddings-986c6bcaa502?source=collection_archive---------1-----------------------#2022-01-24">https://medium.com/mlearning-ai/intuition-to-neural-network-embeddings-986c6bcaa502?source=collection_archive---------1-----------------------#2022-01-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="7fcc" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">通过理解特征嵌入简化混合和复杂模型</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/dbc3ccfaead3cb40a5a7b3494ae8dd44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MzRREg9dkmORKwc2slgOgw.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx"><em class="jm">Neurons. (source: </em><a class="ae jn" href="https://pixabay.com/en/neurons-brain-cells-brain-structure-582054/" rel="noopener ugc nofollow" target="_blank"><em class="jm">Pixabay</em></a><em class="jm">)</em></figcaption></figure></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><h1 id="9c31" class="jv jw hh bd jx jy jz ka kb kc kd ke kf in kg io kh iq ki ir kj it kk iu kl km bi translated">介绍</h1><p id="d487" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">神经网络是人工智能的一种。理解神经网络<em class="lj">嵌入</em>使得从强化代理构建复杂模型来击败视频游戏或创建深度假货成为可能。</p><p id="e1d7" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">很多时候，神经网络被描述为难以理解的黑盒。这是因为它们通过多个图层自动提取自己的特征。我在这里告诉你，对他们如何学习，以及如何理解复杂和混合模型，发展一种直觉是可能的。</p><h2 id="b370" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">我是谁？</h2><p id="d4f8" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">我是理科学士。计算机工程专业毕业，后来专攻机器学习和计算机视觉。目前从事计算机视觉研究。</p><p id="e190" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">而这篇文章反映了我在深度学习中用高级/混合模型的学习经验。</p><p id="0706" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">机器学习(尤其是计算机视觉)让我兴奋的是处理和解决现实世界场景的能力，如人脸识别、无人驾驶汽车等问题。相比之下，常规手工制作的功能(传统方法)只能在有限和狭窄的环境中工作，需要许多工程技巧，如仔细照明以及相机和物体的定位。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es md"><img src="../Images/dada505b22b4ca167f6174b3c69f9d9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/0*tFMfzDv3l6X9eySj.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Example of classical image processing for bottle defects — taken from Parisa Tech</figcaption></figure><h2 id="2f56" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">这篇文章是写给谁的？</h2><p id="35eb" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">我为任何在机器学习或深度学习方面具有<strong class="kp hi">基础背景</strong>的人写这篇文章，并且有兴趣扩展他们对ImageNet分类器之外的理解。</p><p id="32b0" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">迁移学习，可能是一个理所当然的话题(我不怪你)，在线课程快速浏览它们，每次都神奇地工作，并且它可以用几行代码实现也没有帮助。因为在深度学习中，由于大多数概念对初学者来说都是新的，所以一开始会有大量的填鸭式学习。</p><p id="8e21" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">我已经阅读了许多迁移学习文章，但我只是不断遇到相同的信息:</p><blockquote class="me mf mg"><p id="2818" class="kn ko lj kp b kq lk ii ks kt ll il kv mh lm ky kz mi ln lc ld mj lo lg lh li ha bi translated">使用预训练的模型(如Resnet或<a class="ae jn" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"> VGG16 </a>)从类似的数据集中提取特征，然后针对我们的特定用例重新训练最后几层(分类器)。</p></blockquote><p id="349a" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">我只是接受了这一点，并认为这是理所当然的，后来意识到我实际上并不理解我所读的内容，我没有足够地质疑它(我们在接受信息时都需要更具批判性)。<br/>我遗漏了一些细节，比如数据需要多接近？为什么会这样？为什么只去掉最后几层？</p><p id="4710" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">我的结论是，所有这些问题都可以通过理解一件事来回答:那些特征究竟是提取出来的？数字是什么意思，代表什么？</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mk"><img src="../Images/674c5db7a53bcc9b3a6f83895972fd03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*0miqsNIH0JOiP1u7"/></div></figure><p id="aa2c" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">理解了数字，剩下的就来了。这些值通常是一个<a class="ae jn" href="https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning" rel="noopener ugc nofollow" target="_blank">特征嵌入向量</a>。</p><p id="efaf" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">为了简单起见，大多数例子将集中在图像分类问题上，因为这对初学者来说是最熟悉的。</p><h2 id="0533" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">文章注释</h2><p id="aae9" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">为了保持这篇文章的简洁，我会尽可能地链接到其他文章，这样任何需要的额外阅读都可以单独完成。</p><p id="cf21" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">本文将重点关注:</p><ul class=""><li id="10dd" class="ml mm hh kp b kq lk kt ll kw mn la mo le mp li mq mr ms mt bi translated">对这些提取的特征/嵌入意味着什么的直觉</li><li id="b6ae" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated">一些示例应用</li></ul><p id="1a0e" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">并将<strong class="kp hi">而不是</strong>集中在:</p><ul class=""><li id="5e2f" class="ml mm hh kp b kq lk kt ll kw mn la mo le mp li mq mr ms mt bi translated">代码实现</li><li id="8b18" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated">重新解释迁移学习</li><li id="a9ba" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated">网络是如何被训练的</li></ul><p id="3001" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">在这篇文章的结尾，我希望复杂的模型看起来不那么神奇。</p><h1 id="c3a9" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">概述深度神经网络(DNNs)</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ne"><img src="../Images/c7dbdd5a0265f335d924e24010b3d354.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xgzBFrIqkeIZlWbX.gif"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Deep neural network forward pass — <a class="ae jn" href="https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6" rel="noopener" target="_blank">source</a></figcaption></figure><p id="8095" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">从根本上说，深度神经网络学习模式识别，我们将重点关注CNN分类器(卷积神经网络)的例子。它们可以自动提取图像中的特征。</p><p id="4762" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">中间层可以被解释为原始数据的经过处理的表示。</p><h2 id="115e" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">1.降维</h2><p id="e917" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">给定原始的非结构化数据(例如来自图像的像素)，网络很难直接做出决定(对狗或猫进行分类)。</p><p id="7679" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">提取一个中间层作为图像的表示形式可以显著减少原始数据的大小，使其更有用，也更容易让更深的层最终决定输出</p><p id="c731" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">CNN会降低维度，只提取重要的特征，然后做出决定。使用卷积图层提取重要要素后，数据会被传递到一个或多个完全连接的图层，这些完全连接的图层会接收高级别要素，从而更容易为最终输出做出决策。</p><p id="06cb" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">与224×224 = 50176尺寸的原始输入图像相比，这些尺寸通常看起来像高级特征的尺寸512。</p><blockquote class="me mf mg"><p id="88ef" class="kn ko lj kp b kq lk ii ks kt ll il kv mh lm ky kz mi ln lc ld mj lo lg lh li ha bi translated">这是浅层学习(常规机器学习)和深度学习之间的关键区别。我们可以对结构化数据/高级功能(如包含结构化数据的CSV文件)使用浅层学习，对原始非结构化数据(如音频、视频、图像、文本等)使用深度学习。</p></blockquote><p id="6dd2" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">一旦数据成为高级特征，您可以使用浅层学习方法处理它，如逻辑回归或支持向量机更好地处理图像的小表示</p><p id="cb5b" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">您可以将网络末端的全连接层(fc_3、fc_4、…)视为逻辑回归层。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/2c2e1e3ceda7e9176492d5c3b107b86f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CgMCL353Sb4gA_Ay.jpeg"/></div></div></figure><h2 id="a7dd" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">2.投射到更简单的空间</h2><p id="959a" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">简单意味着问题更容易处理，简单可以是:<em class="lj">线性可分</em>，<em class="lj">与输出线性相关</em>，或者简单包含<em class="lj">可以直接用于决策的高级特征</em></p><p id="6324" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">线性可分只是意味着更容易/可能画线。单个神经元可以画一条线，这就是为什么我们在一个DNN中需要许多神经元。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nf"><img src="../Images/8a7a65be6e2f1f2656a22f54bfa70b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t79D7wrnJRFvjHV3"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">A: Linearly separable (can draw line), B: not linearly separable (can’t draw line)</figcaption></figure><p id="12a0" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">如果起始特征(DNN的输入)看起来像<strong class="kp hi"> B </strong>，那么单个神经元不能将其分开，但如果需要，许多神经元可以画出接近圆形的东西。</p><blockquote class="me mf mg"><p id="db29" class="kn ko lj kp b kq lk ii ks kt ll il kv mh lm ky kz mi ln lc ld mj lo lg lh li ha bi translated">仅供参考:事实证明，将网络做得更深更容易<a class="ae jn" href="https://arxiv.org/abs/1705.05502" rel="noopener ugc nofollow" target="_blank"/>，而不是拥有一个有许多神经元的浅网络(因为那可能导致过度拟合)。</p></blockquote><p id="da57" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">所发生的是，对于深度网络，输入空间(<strong class="kp hi"> B </strong>)实际上得到<em class="lj">投影/变换</em>到另一个更容易处理(线性可分)的域(<strong class="kp hi"> A </strong>)。所以神经网络只是让事情变得越来越简单，直到做出最终决定。如前所述，在最后一层，你甚至可以使用简单的机器学习方法，如逻辑回归或SVM。</p><h1 id="a962" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">嵌入</h1><p id="a068" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">嵌入/潜在向量/特征向量是表示关于我们的领域/任务的一些信息的向量，这些向量是网络的输出或网络中的中间值。</p><h2 id="12c4" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">嵌入中的信息</h2><p id="0850" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">嵌入包含的内容实际上归结于训练过程和损失函数。训练网络可以有许多目标，可以是使用<em class="lj"> softmax </em>函数区分类别，使用对比学习度量、BERT式训练将类别分开，或者只是让GAN鉴别器告诉我们图像是真是假。这些方法中的每一种(即使它们都具有相同的嵌入形状，但在这些嵌入中它们的值的意义完全不同。</p><p id="f944" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">考虑类数据也很重要。例如，一个面部识别网络被用来提取<em class="lj">有区别的</em>面部特征，这意味着它不应该关注面部毛发或眼镜，因为我们希望它识别同一个人，无论他们是否剃了胡子。</p><h2 id="4f13" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated">例子</h2><p id="5776" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">本节将举例说明</p><p id="ee73" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">如果你对编码器-解码器范例更熟悉，那么就把嵌入想象成编码</p><p id="f63c" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">编码器-解码器将有效地将数据压缩到z潜在向量(您仍然可以称之为嵌入)。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ng"><img src="../Images/d38cc1969b2140c9a1d61aca4a604c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Qb0eLWhW6-D6XPOc.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Encoder-decoder</figcaption></figure><p id="aaf8" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">如果你有任何自然语言处理的经验，那么你可能听说过单词嵌入。</p><div class="ix iy iz ja fd ab cb"><figure class="nh jb ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/f3b2faf0d1e89873909dacdf7c970605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/0*bxI8_kA6gOUfuRAA.png"/></div></figure><figure class="nh jb nn nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/28b7497e2662a49f5bee6fe4daad92d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/0*pP89w-L9K67CKnlb.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx no di np nq">Word embedding space</figcaption></figure></div><p id="1544" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">嵌入是一种比一键向量更有意义的表示类的方式。一键嵌入是嵌入的子集。单词嵌入的想法是让单词的嵌入向量在意义上相似，非常接近，而远离其他单词。C <em class="lj"> lose </em>和<em class="lj"> far，</em>表示距离度量，这可以是任何距离度量，例如L2距离(欧几里德距离)或余弦距离。使用余弦距离的一个特性是它不依赖于嵌入向量的大小，而是依赖于方向。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nr"><img src="../Images/c3f2ce0b6831b631c5a21902242fd056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cVYk3HbOwSWvLLjX.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">An example of movie embedding in two-dimensional space — taken from <a class="ae jn" href="https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="6c2c" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">自动编码器的思想是用一个特定领域的编码器将输入压缩成最重要的特征。证明这一点的证据是，解码器可以以某种方式重建输入，这意味着——正如<em class="lj">信息论中所述——</em>固定大小的嵌入向量(或潜在向量)必须能够容纳重建压缩输入所需的信息。</p><p id="92ec" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">关键点:嵌入向量中的数字并不总是<a class="ae jn" href="https://arxiv.org/abs/1802.05312" rel="noopener ugc nofollow" target="_blank">解开</a>；每一个都与上面的电影嵌入直接对应(尺寸<em class="lj">大片</em>和<em class="lj">成人</em>)。<br/>它不一定是人类可读的，但它应该包含信息，只要嵌入后的神经网络层<strong class="kp hi">能够理解它，那么它就应该工作。<br/>有意义是什么意思？嗯，这取决于用例。如果任务是人脸识别，那么相似人脸的嵌入应该具有较短的距离，视觉上不同的人脸在嵌入空间中应该具有较大的距离。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/34c9ef525120e9a9b3acb8944cdc0fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zloa5TTWd3YYW0jZ.jpg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Face recognition objective using triplet loss</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="ab fe cl nt"><img src="../Images/bba9c57bcb008ed33ad048b44f1ebfed.png" data-original-src="https://miro.medium.com/v2/format:webp/0*T5X0551oS70qy8Jy.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Extracting face embeddings</figcaption></figure><h1 id="e966" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">使用嵌入</h1><p id="cb11" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">乐趣开始的地方</p><p id="73d4" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">我将查看一些稍微复杂一点的模型的例子，并展示拥有不同类型的嵌入的力量。</p><h2 id="19fa" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated"><strong class="ak">多扬声器</strong> <a class="ae jn" href="https://github.com/CorentinJ/Real-Time-Voice-Cloning" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> TextToSpeech工具箱</strong> </a></h2><p id="1eec" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">它扩展了常规的TextToSpeech，但以扬声器嵌入为条件，允许您选择声音。这是通过一个SpeakerEncoder网络来实现的，该网络经过训练，可以提取许多声音的风格嵌入，迫使它提取分离扬声器的特征，如音色和音高，并忽略内容。而另一个编码器只负责内容。拥有两个编码器的强大功能意味着内容和说话声音不再纠缠不清，允许你为同一个句子交换说话声音。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nu"><img src="../Images/3d491602e188ba2e4f08bb823214f61c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/0*28OyulX_X-FxSFn2"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">TextToSpeech toolbox architecture. <a class="ae jn" href="https://arxiv.org/pdf/1806.04558.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1806.04558.pdf</a></figcaption></figure><h2 id="cb38" class="lp jw hh bd jx lq lr ls kb lt lu lv kf kw lw lx kh la ly lz kj le ma mb kl mc bi translated"><strong class="ak">图像翻译(</strong><a class="ae jn" href="https://nvlabs.github.io/FUNIT/" rel="noopener ugc nofollow" target="_blank"><strong class="ak">FUNIT</strong></a><strong class="ak">paper)</strong></h2><p id="3950" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">这种架构旨在从一幅图像中提取姿态，并将其应用到另一幅图像中。它通过使用2个编码器和1个解码器工作，每个编码器输出嵌入，然后一个解码器(蓝色)从这两个嵌入中重建图像回到像素。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nv"><img src="../Images/81951d70e999c35d195b2fecd6798687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DLEiM1fBOq6VM8H0xY-znQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">FUNIT architecture</figcaption></figure><p id="556c" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">一个<em class="lj">内容编码器</em>(粉色)负责动物的姿势，它接收左边的图像，并输出包含动物姿势的嵌入。<br/><em class="lj">类编码器</em>(绿色)负责动物的品种/风格，它拍摄一个或多个图像，并输出品种的平均嵌入，如果它们看起来足够相似，你甚至可以合并不同的动物。最后，<em class="lj">解码器</em>将这两种嵌入内容转换回图像。<br/>你甚至可以在这里尝试互动演示<a class="ae jn" href="http://nvidia-research-mingyuliu.com/ganimal" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nw"><img src="../Images/b490e38fc46fc8339c1dcd86d67b45b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ErXwxQcVZmTXmXrgtxkKCA.gif"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">FUNIT example output</figcaption></figure><p id="a9c7" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">如果你对GANs感兴趣(比如StyleGAN:生成真实人脸和深度假像的酷酷的人工智能),我强烈建议你阅读这篇文章:A- <a class="ae jn" href="https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737" rel="noopener" target="_blank">看GANs的新方式</a></p><h1 id="5e7d" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">将所有东西整合在一起</h1><p id="cabd" class="pw-post-body-paragraph kn ko hh kp b kq kr ii ks kt ku il kv kw kx ky kz la lb lc ld le lf lg lh li ha bi translated">现在为了测试你的理解，考虑这个问题:如果我有许多图像，我想把相似的图像聚集在一起，会怎么样？假设这些图像是512x512=262144像素，逐像素比较既没有效果，也没有效率。</p><p id="3ba7" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">看看你是否能想出一个方法，花一分钟思考，然后继续阅读。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nx"><img src="../Images/b74c8dde9ee9fdea06620e6ad82d8538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LWaMEWM7ziywC3Z1"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@elijahdhiett?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Elijah Hiett</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="45eb" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">想好了吗？以下是我的看法:</p><p id="9bfb" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">一种可能的解决方案是使用预先训练的模型来提取特征，这些特征将具有固定长度的特征向量。因此，对于每幅图像，我们将其通过特征提取器网络，并输出固定长度的特征向量(例如1024个值)。例如，我们将图像从512x512=262144个值减少到1024个值。现在我们有了这1024个特征，我们可以使用简单的浅层学习(SVM，线性回归等..)或某种类型的聚类(k均值、均值漂移等)。<br/>毕竟原来的深度学习模型在特征提取器之后只有一个全连接层，基本上是一个逻辑回归分类器。</p><p id="dc1f" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">这样做会产生类似下图的图像:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ny"><img src="../Images/92ad7898fc1ea6ce752925f4e47f9f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VXIJs3uOmi7liF7x.jpg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Images mapped for similarity using t-SNE, based on Google ML</figcaption></figure><h1 id="f2a9" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">摘要</h1><ul class=""><li id="952b" class="ml mm hh kp b kq kr kt ku kw nz la oa le ob li mq mr ms mt bi translated">最后几层只是逻辑回归，你也可以使用支持向量机</li><li id="164b" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated">嵌入的意义取决于训练过程和损失函数</li><li id="cf5f" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated">你可以用创造性的方式使用这些嵌入，而不仅仅是分类，这在GANs中特别有用</li></ul><h1 id="c183" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">资源</h1><ul class=""><li id="7665" class="ml mm hh kp b kq kr kt ku kw nz la oa le ob li mq mr ms mt bi translated"><a class="ae jn" href="https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="kp hi">“为机器学习提取和提供特征嵌入</strong> </a> <strong class="kp hi">”:这本谷歌指南包含了本文的大部分观点</strong></li><li id="865a" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated"><strong class="kp hi">嵌入:</strong> <a class="ae jn" href="https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526" rel="noopener" target="_blank"> <strong class="kp hi">神经网络嵌入解释</strong></a><strong class="kp hi"/></li><li id="becb" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated"><a class="ae jn" href="https://www.datacamp.com/community/tutorials/transfer-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="kp hi">《迁移学习:初学者指南</strong></a><strong class="kp hi"/></li><li id="e3c2" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated">表达自然功能的深层网络的力量:越深越容易</li><li id="c9ce" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated"><a class="ae jn" href="https://github.com/instillai/deep-learning-roadmap" rel="noopener ugc nofollow" target="_blank">https://github.com/instillai/deep-learning-roadmap</a></li></ul><h1 id="91a4" class="jv jw hh bd jx jy mz ka kb kc na ke kf in nb io kh iq nc ir kj it nd iu kl km bi translated">代码资源</h1><ul class=""><li id="a5ce" class="ml mm hh kp b kq kr kt ku kw nz la oa le ob li mq mr ms mt bi translated"><a class="ae jn" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank"> Colab笔记本“迁移学习与微调”</a></li><li id="cc21" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated"><a class="ae jn" href="https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/" rel="noopener ugc nofollow" target="_blank"> <strong class="kp hi">用计算机视觉模型迁移Keras中的学习—机器学习掌握</strong> </a></li><li id="1a1e" class="ml mm hh kp b kq mu kt mv kw mw la mx le my li mq mr ms mt bi translated"><strong class="kp hi">进行练习:</strong><a class="ae jn" href="https://github.com/udacity/deep-learning-v2-pytorch/blob/master/transfer-learning/Transfer_Learning_Solution.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="kp hi">uda city/deep-learning-v2-py torch</strong></a></li></ul><p id="ef9f" class="pw-post-body-paragraph kn ko hh kp b kq lk ii ks kt ll il kv kw lm ky kz la ln lc ld le lo lg lh li ha bi translated">这是我的第一篇文章，我希望你受益，并随时留下反馈和建设性的批评。祝你愉快。</p><div class="oc od ez fb oe of"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="og ab dw"><div class="oh ab oi cl cj oj"><h2 class="bd hi fi z dy ok ea eb ol ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="om l"><h3 class="bd b fi z dy ok ea eb ol ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="on l"><p class="bd b fp z dy ok ea eb ol ed ef dx translated">medium.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot jg of"/></div></div></a></div></div></div>    
</body>
</html>
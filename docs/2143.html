<html>
<head>
<title>400 Birds Species Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">400鸟类物种分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/400-birds-species-classification-f4de768aac4?source=collection_archive---------0-----------------------#2022-03-15">https://medium.com/mlearning-ai/400-birds-species-classification-f4de768aac4?source=collection_archive---------0-----------------------#2022-03-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7fe5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一种用于鸟类分类的深度学习方法🐦</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/8b1f1b5578cc11414b69a6fa3e2ba98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zAs_DpqCJVo4sgZk"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@oneor0?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Dmitry Chernyshov</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1d0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">目录</strong></p><ol class=""><li id="6980" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb jy jz ka kb bi translated">介绍</li><li id="23c2" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">商业问题</li><li id="0d36" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">机器学习问题</li><li id="6333" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">加载数据</li><li id="192f" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">电子设计自动化(Electronic Design Automation)</li><li id="ff8f" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">数据管道创建和图像增强</li><li id="dce4" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">深度学习模型</li><li id="1dc6" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">使用Flask API部署</li><li id="923e" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">未来的工作</li><li id="2a5d" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">我的外卖</li><li id="6a88" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">参考</li><li id="8c05" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">我的个人资料</li></ol></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><h2 id="aa94" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated"><strong class="ak"> 1。简介</strong></h2><p id="c09b" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">这实际上是一个名为<a class="ae js" href="https://www.kaggle.com/gpiosenka/100-bird-species" rel="noopener ugc nofollow" target="_blank"> 400种鸟类分类</a>的Kaggle数据集，该数据集的所有者是Gerry。本案例研究的目的是对数据集中提供的多种鸟类进行分类。</p><h2 id="34a0" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">2.<strong class="ak">商业问题</strong></h2><p id="04f0" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">2.1.<strong class="ig hi">问题陈述</strong></p><p id="84dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这类问题对于像森林部门这样的机构，或者对于整天都在研究各种动植物的人来说是很重要的。根据<a class="ae js" href="https://ourworldindata.org/birds#how-many-bird-species-are-there" rel="noopener ugc nofollow" target="_blank">这个资源</a>在<strong class="ig hi">我们的世界在</strong>的数据，显然，到目前为止已经发现了超过11000种不同的鸟类。</p><p id="cdf4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在对人类来说，很难看到和分析一只鸟属于哪个物种，特别是当遇到非常稀有的物种时。这就是机器/计算机来救援的地方。</p><p id="a14c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个数据集总共包含400种不同的鸟类。任务是使用一种算法来训练一台关于所有这些不同物种的机器，以便在需要时尽可能减少对人类干预的需要。</p><p id="a3b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.2.<strong class="ig hi">业务约束</strong></p><ul class=""><li id="ee01" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb lo jz ka kb bi translated">没有严格的等待时间限制:没有人会急于鉴定一个物种。但是，是的，不应该是这样的，培训总共需要几周/几个月。花几天时间当然不错，但如果训练需要几个小时，那最好不过了。但是，通过一个训练过的模型进行预测应该足够快，最好是在毫秒或秒的范围内。</li><li id="0932" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">有可解释性是件好事:我们可以用机器认为某只鸟属于物种“A”的概率来理解机器的想法。</li><li id="9ea5" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">模型简单:物种分类一类的东西主要用于基于研究的活动。我们的模型将用于为研究而制造的适当系统中。因此，即使模型有点重，也不会有问题。</li><li id="d853" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">最小化多类错误:虽然这不是一个问题，如果模型预测不正确，会有一些危及生命的机会，但尽可能低的多类错误仍然是好的。</li></ul><h2 id="cc86" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">3.<strong class="ak">机器学习问题</strong></h2><p id="f377" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">3.1.<strong class="ig hi">数据</strong></p><ul class=""><li id="b6a8" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb lo jz ka kb bi translated">该数据集总共包含58388张鸟类图像(jpg格式)。</li><li id="4afe" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">这些被细分为3个单独的目录→一个用于58388个训练图像，一个用于2000个测试图像，一个用于2000个验证图像。测试和验证目录中每个物种有5张图片)。</li><li id="6260" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">所有图像的形状都是224x224x3 →即所有图像都是RGB格式(即具有红色、绿色和蓝色通道)。</li><li id="0c1e" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">每组(训练、验证、测试)有400个不同物种的400个目录。</li><li id="0543" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">每个物种(此处为目录)至少有120张该类型的图片。</li><li id="eec3" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">每幅图像都是这样的，鸟占据了整个图像的至少50%。</li><li id="bf9e" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">每个图像文件从1或001开始按顺序编号。</li></ul><p id="4295" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.2.<strong class="ig hi">将现实世界问题映射到ML问题</strong></p><ul class=""><li id="4625" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb lo jz ka kb bi translated">问题类型→多类分类任务</li><li id="8748" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">我们需要分类什么→从提供的400种不同种类的鸟中选出不同种类的鸟。</li><li id="308e" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">我们的目标/类别标签→400个不同的目录名表示400个不同的物种(我们的目标变量)</li></ul><p id="125d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.3.<strong class="ig hi">绩效指标</strong></p><ul class=""><li id="cd22" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb lo jz ka kb bi translated">我对这个数据集的初步调查显示，这个数据集是不平衡的。所有的物种(类)至少有120个图像，有些有更多的图像(如140，160)，有些有240个图像。</li><li id="d660" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">分类交叉熵➡我们的业务约束要求我们的模型给出某种程度的预测概率。因此，我们可以利用这个来计算分类交叉熵损失。由于这是一个多类分类，该模型需要使用“分类交叉熵”损失进行优化，该损失是该多类分类任务的多类对数损失等价物。众所周知，对数损失本身就是一个非常好的指标。</li><li id="3693" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">因此，<strong class="ig hi">分类交叉熵是我们将在这里使用的度量</strong>。</li></ul><h2 id="18d9" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">4.<strong class="ak">加载数据</strong></h2><p id="e189" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">我只是使用Kaggle的API将这个数据集的数据放入我的系统。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="7c39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这会将所有3个数据集下载到您的系统中。将有3个文件夹，分别用于培训、测试和验证。您可以选择忽略随此API一起下载的其他文件/文件夹。</p><h2 id="e773" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">5.<strong class="ak"> EDA </strong></h2><p id="b54c" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">让我们讨论一下已经完成的探索性数据分析。我使用了下面的函数来掌握这个数据集的基本细节。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="cafc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下图说明了每个目录中的图片数量(即每个物种的图片数量)。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="dd94" class="ko kp hh ls b fi lw lx l ly lz"># TRAIN<br/>train_species_names,train_species_image_count,<br/>train_images_heights,train_images_widths = get_counts(dataset_path=”/content/train/”,dataset_type=”train”)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ma"><img src="../Images/0b31d13e2ca7a685e3bfa2f81f0884a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2crWAS_hM2-OuSeYyepoVQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image by Author</figcaption></figure><p id="37dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有物种至少有120张图片，这是一个不平衡的数据集(有些物种有120-160张图片，有些甚至更多)。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="8b9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的图证实了所有图像都是224x224大小。</p><p id="ddcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看验证数据集的类似情况:-</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mb"><img src="../Images/a0afdd5bb52f1151fc2ee5b336e0211b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y7awgb-Q1iyFTTbhItYw2Q.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image by Author</figcaption></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="de5a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这表明验证数据集在每个物种目录中有5个图像，并且每个图像都具有相同的大小:224x224。所有这些观察结果在测试数据集的情况下也是一样的。</p><p id="8061" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我对所有3个数据集中的物种名称进行了健全性检查。我发现了一个有趣的观察。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="dfdc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在所有3个数据集上，所有物种的名称并不相同。让我们更深入地挖掘。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="e097" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，物种名称“黑黄嘴”在训练数据集中获得了额外的空间，这就是为什么我们在检查所有物种名称是否相同时得到了False。解决办法？</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="e110" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您正在处理此数据集，请确保选中此项。只需通过删除多余的空间来重命名文件夹。</p><p id="28f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，所有的物种名称是真实的:—</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="fb02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看这个数据集中随机选择的25只鸟。为此，我使用了下面的代码片段</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="0acc" class="ko kp hh ls b fi lw lx l ly lz"># PRINT SOME RANDOMLY SELECTED 25 IMAGES FROM THE TRAIN FOLDER<br/>parent_dir = “/content/train/”<br/>all_subdirs = os.listdir(parent_dir)<br/>plt.subplots(figsize=(20,17))</span><span id="4430" class="ko kp hh ls b fi mc lx l ly lz">for col in range(1,26):<br/>  plt.subplot(5,5,col)<br/>  chosen_species_dir = all_subdirs[random.randint(0,401)]<br/>  chosen_dir = parent_dir + chosen_species_dir<br/>  all_images_in_chosen_dir = os.listdir(chosen_dir)<br/>  chosen_img = chosen_dir + “/” +<br/>all_images_in_chosen_dir[random.randint(0,len(all_images_in_chosen_dir)-1)]<br/>  image = imread(chosen_img)<br/>  plt.title(chosen_species_dir)<br/>  plt.imshow(image)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es md"><img src="../Images/8e597b5d593cb08482b7540d79f8f303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6i1ObiMTzdoMD6x4caJ4Yg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image by Author</figcaption></figure><p id="7fb0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如你可能已经注意到的，所有的图像都是RGB的&amp;占据了整个224x224图像的至少50%。</p><h2 id="7548" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">6.<strong class="ak">数据管道创建&amp;图像增强</strong></h2><p id="4465" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">为了避免过度拟合，可以使用许多技术，如使用一个漏失、批量归一化或其他L1/L2正则化技术。但是在图像的情况下，避免/控制过度拟合的最佳方式是图像放大。这只是一种在旅途中创建人工训练数据点的方法，以帮助模型很好地推广到新的/测试数据点。可以使用Tensorflow的<a class="ae js" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>类来实现这一点。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es me"><img src="../Images/511b57891db0b873af01cfb8c5a6d3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*dGomGTObl72IX2FIiQXGyQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Original Image</figcaption></figure><p id="d120" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们来看看某种图像增强看起来会是什么样子</p><p id="8ebc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一、<strong class="ig hi">宽度偏移</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mf"><img src="../Images/ac910e0774f46fcd0e0f34bc42036b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JOs1VWwX9Utj4UkM_Hi8rA.png"/></div></div></figure><p id="7cb1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">二。<strong class="ig hi">高度变化</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mg"><img src="../Images/a0dbfc563253edf7631ccd2799aeb813.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E84MgTJrJJoSv6DxKXpb2Q.png"/></div></div></figure><p id="83a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">三。<strong class="ig hi">随机旋转</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mh"><img src="../Images/96f262d9ff61dc369af3260c07258eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jAynDE7DZBqc3eCHH6lANQ.png"/></div></div></figure><p id="7b45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">四。<strong class="ig hi">随机亮度(变暗/变亮)</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mh"><img src="../Images/9a35ddd5f4a325e984ee5dde10ee9e44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*boxYdmTS56O-u3y3Dq_gPg.png"/></div></div></figure><p id="ffbb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">动词 （verb的缩写）<strong class="ig hi">水平翻转</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mi"><img src="../Images/7bddbf0add037904886e9aaff8fd377b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oDyRuGugF3775QBFMiEq0A.png"/></div></div></figure><p id="5096" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不及物动词<strong class="ig hi">垂直翻转</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mj"><img src="../Images/3f9b861defb117fd267d5bf51e95db98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pGrZCEyPOqwmKCIxcpUMiQ.png"/></div></div></figure><p id="e815" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">七。<strong class="ig hi">剪切</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mk"><img src="../Images/b9779fb5d8145a9d6edb00eb44b4e62b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TnN8vtZ64W_9NoP4wbG57Q.png"/></div></div></figure><p id="071e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">八。<strong class="ig hi">随机缩放</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ml"><img src="../Images/f28171f1b97e0563a47e657d569c30ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62lkm_z_cWUBjMEcMoZw9w.png"/></div></div></figure><p id="d9a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">考虑到我们这里的问题，几乎所有这些增强技术都是有用的。</p><p id="97d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mm">注意:仅在训练数据集上执行增强。从不在验证/测试数据集中。“通过训练数据集学习”并在应用于测试数据时很好地概括自己是你的模型的责任。</em></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="4ba9" class="ko kp hh ls b fi lw lx l ly lz"># A SIMPLE IMAGE DATA GENERATOR WITHOUT ANY AUGMENTATION; JUST SCALING PIXELS WITHIN 0–1 </span><span id="e0ce" class="ko kp hh ls b fi mc lx l ly lz">datagen1 = ImageDataGenerator(rescale=1/255)</span><span id="29cd" class="ko kp hh ls b fi mc lx l ly lz">#A MORE COMPLEX IMAGE DATA GENERATOR WITH DIFFERENT KINDS OF AUGMENTATION ALONG WITH PIXEL SCALING LIKE ABOVE.<br/>NOTE --&gt; THIS WILL BE ONLY USED FOR TRAINING DATASET</span><span id="a744" class="ko kp hh ls b fi mc lx l ly lz">datagen2 = ImageDataGenerator(rescale=1/255,width_shift_range=[0.1,0.15,0.2,0.25],height_shift_range=[0.1,0.15,0.2,0.25],<br/>rotation_range=60,brightness_range=[0.5,1.9],horizontal_flip=True,shear_range=45,zoom_range=[0.6,1.2])</span></pre><p id="5a7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我使用了<a class="ae js" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory" rel="noopener ugc nofollow" target="_blank"> flow_from_directory </a>方法来为模型创建数据管道。你可以通过我的这个案例研究的Github repo参考详细的代码片段。(链接在本文末尾)</p><h2 id="8d96" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">7.深度学习模型</h2><p id="1afa" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">我从一些非常基本的卷积架构开始。第一个架构只有2个卷积+最大池模块，后面是扁平化和密集层。我想用可分离卷积进行实验(它有一个特殊的属性，计算需求低，但结果相似)。你可以在奇-汪锋的博客中了解更多关于可分卷积的知识。这种架构导致在完全看不见的测试图像上损失了<strong class="ig hi"> <em class="mm"> 3.26 </em> </strong>。</p><p id="6bfb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一个模型也很简单，只有2个2xConv+Maxpool模块。在这里，我在第二个conv块中试验了<a class="ae js" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D" rel="noopener ugc nofollow" target="_blank"> GlobalMaxPooling </a>。在这种模式下损失下降到<strong class="ig hi"> <em class="mm"> 2.07 </em> </strong>。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mn"><img src="../Images/9fcc9738ba064bf7cb062fb9a203f82b.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*j3rCsSE-PgWnxQxlyW4Siw.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Left (1st model) ; Right (2nd model) (Image by Author)</figcaption></figure><p id="319d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mm">注意:第一个模型在没有任何增强的情况下被训练，每个图像的大小被减小到96×96，而第二个模型在图像大小被减小到32×32的情况下被训练。看到了吗？这就是增强的魔力！它有助于您的模型在训练时学习如此多的额外/不同的功能，即使您缩小图像大小。</em></p><p id="df54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">继续下一个模型。我将图像尺寸保持为128x128，使用了dropout &amp;没有进行任何放大。该架构比前两个稍微复杂一点(但并不复杂)。我使用了3块(2xConv + Pooling ),最后一块是GlobalMaxPooling，后面是通常的密集层。测试损耗为<strong class="ig hi"> <em class="mm"> 1.16 </em> </strong>，与前两者相比，该损耗明显较低。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/aba3a7cdb4036ad565fd5cfa351054e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*Abm9VOul5whSFegDcCLVlw.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Train Loss(orange) &amp; Validation Loss (blue) (Image by Author)</figcaption></figure><p id="f531" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">看看损失是如何改变的。没有过度拟合。</p><p id="1767" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在进入深度学习的传说——<a class="ae js" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>。我用了卷积神经网络领域的多个图例，从VGG16，ResNet，InceptionNet到EfficientNet，VGG19。一些我根据数据集进行了微调，一些用于特征提取&amp;一些我从头开始训练。让我们一个一个地看看我是如何利用迁移学习的。</p><p id="057b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL方法-1:用我自己的分类器进行特征提取的VGG16最后:- </strong></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="282e" class="ko kp hh ls b fi lw lx l ly lz">input_layer = Input(shape=(img_width,img_height,3), name=”main_input_layer”)<br/># pre-trained model → VGG16<br/>model = VGG16(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height, 3))<br/>model.trainable = False</span><span id="f4df" class="ko kp hh ls b fi mc lx l ly lz"># our new classifier starts here<br/>glob = GlobalAveragePooling2D()(model.layers[-1].output)<br/>drp = Dropout(rate=0.4)(glob)<br/>dense = Dense(units=1024,activation=”relu”,kernel_initializer=”he_uniform”)(drp)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="b186" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model4 = Model(inputs=model.inputs,outputs=output_layer)</span></pre><p id="26fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我用Imagenet权重初始化了每个模型，并在最后添加了自己的分类器(并且不包括原始VGG16模型的顶部)。</p><p id="ec5e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一个方法是相似的，只是在某种意义上略有不同，我使用了增强&amp;没有退出。在这两种方法中，我都使用了<a class="ae js" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D" rel="noopener ugc nofollow" target="_blank"> GlobalAvgPooling </a>。</p><p id="6f83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL方法-2: ResNet50从零开始微调</strong></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="ebfa" class="ko kp hh ls b fi lw lx l ly lz"># pre-trained model → ResNet50<br/>model = ResNet50(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height,3),pooling=”avg”)</span><span id="2d66" class="ko kp hh ls b fi mc lx l ly lz"># our new classifier starts here<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_uniform”)(model.layers[-1].output)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="09ea" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model6 = Model(inputs=model.inputs,outputs=output_layer)<br/>opt = Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)</span></pre><p id="2c93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mm">注意，如果你想从头开始训练一个预训练的模型，并使用一些权重进行初始化，保持学习率非常低。例如:每当我从头开始训练预训练模型时，我就把学习率降低到0.0001。这样做是为了那些“良好的预训练重量”不会在训练时被破坏。</em></p><p id="7b0f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你想知道这个模型表现如何吗？</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mp"><img src="../Images/1fa1e87722a5227ec7ef2ce1e69c1921.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*SQEcVim0-nVjqQ0oDbJhog.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">A pigmy kingfsher predicted with 100% surity (Image by Author)</figcaption></figure><p id="dbf1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL方法-3: EfficientNetB0，从头开始微调</strong></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="177c" class="ko kp hh ls b fi lw lx l ly lz"># pre-trained model → EfficientNetB0<br/>model = EfficientNetB0(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height,3),pooling=”avg”)</span><span id="59f2" class="ko kp hh ls b fi mc lx l ly lz"># our new classifier starts here<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_uniform”)(model.layers[-1].output)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="bbe3" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model7 = Model(inputs=model.inputs,outputs=output_layer)<br/>opt = Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)</span></pre><p id="e470" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL方法-4:从头开始微调的InceptionV3】</strong></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="e3cb" class="ko kp hh ls b fi lw lx l ly lz"># pre-trained model → InceptionV3<br/>model = InceptionV3(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height,3),pooling=”avg”)</span><span id="e7a7" class="ko kp hh ls b fi mc lx l ly lz"># our new classifier starts here<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_uniform”)(model.layers[-1].output)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="d937" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model8 = Model(inputs=model.inputs,outputs=output_layer)</span></pre><p id="3d8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL方法-5:用于特征提取的VGG19】</strong></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="0045" class="ko kp hh ls b fi lw lx l ly lz"># pre-trained model → VGG19<br/>model = VGG19(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height,3))<br/>model.trainable = False</span><span id="39d7" class="ko kp hh ls b fi mc lx l ly lz"># our new classifier starts here<br/>flat = Flatten()(model.layers[-1].output)<br/>dense = Dense(units=1024,activation=”relu”,kernel_initializer=”he_uniform”)(flat)<br/>dense = Dense(units=1024,activation=”relu”,kernel_initializer=”he_uniform”)(dense)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="5685" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model9 = Model(inputs=model.inputs,outputs=output_layer)<br/>opt = Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)</span></pre><p id="4452" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我在分类器前使用了展平图层。</p><p id="2324" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL Approach-6: VGG16冻结前11层&amp;微调其余</strong></p><p id="93ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你也可以选择微调一些图层，冻结其余的图层。在这种方法中，我冻结了原始VGG16网络的前11层。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="b813" class="ko kp hh ls b fi lw lx l ly lz"># pre-trained model → VGG16<br/>model = VGG16(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height,3),pooling=”avg”)<br/>for layer in model.layers[:11]:<br/>  layer.trainable = False</span></pre><p id="757f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以训练，即微调其余的层，包括最后添加的最后一个分类器。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="4d13" class="ko kp hh ls b fi lw lx l ly lz"># our new classifier starts here<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_uniform”)(model.layers[-1].output)<br/>drp = Dropout(0.25)(dense)<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_uniform”)(drp)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="af3a" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model10 = Model(inputs=model.inputs,outputs=output_layer)<br/>opt = Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)</span></pre><p id="670b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TL Approach-7: VGG19冻结前17层&amp;微调其余</strong></p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="bb0c" class="ko kp hh ls b fi lw lx l ly lz"># pre-trained model → VGG19<br/>model = VGG19(include_top=False,weights=”imagenet”,input_shape=(img_width,img_height,3))<br/>for layer in model.layers[:17]:<br/>  layer.trainable = False</span><span id="0a03" class="ko kp hh ls b fi mc lx l ly lz"># our new classifier starts here<br/>glob = GlobalAveragePooling2D()(model.layers[-2].output)<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_normal”)(glob)<br/>dense = Dense(units=128,activation=”relu”,kernel_initializer=”he_normal”)(dense)<br/>output_layer = Dense(units=400,activation=”softmax”,name=”main_output_layer”)(dense)</span><span id="e823" class="ko kp hh ls b fi mc lx l ly lz"># final definition of our model<br/>model11 = Model(inputs=model.inputs,outputs=output_layer)<br/>opt = Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)</span></pre><p id="1e25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我用的是Adam optimizer，学习率=0.0001，保持图片尺寸不变:224x224，最后用了增广，无脱落和GlobalAvgPool。下面是一段代码，显示了我使用的增强功能</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="568e" class="ko kp hh ls b fi lw lx l ly lz">ImageDataGenerator(rescale=1/255, width_shift_range=[0.1,0.15,0.2,0.25], height_shift_range=[0.1,0.15,0.2,0.25],<br/>rotation_range=60, brightness_range=0.5,1.9], horizontal_flip=True, shear_range=45, zoom_range=0.6,1.2], preprocessing_function=prep_func)</span></pre><p id="fecd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里prep_func对应的是我使用的预训练模型，即VGG19的预处理函数。你可以在这里找到关于这个<a class="ae js" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/preprocess_input" rel="noopener ugc nofollow" target="_blank">的更多细节。这种方法被证明是最好的。导致<strong class="ig hi"> <em class="mm">最低测试损耗0.1426 </em> </strong>。</a></p><p id="c20f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是我使用的所有模型的总结</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="a9db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型被保存下来，并继续进行部署。</p><h2 id="86b8" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">8.使用Flask API部署</h2><p id="0c1f" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">我使用Flask API &amp; basic HTML、CSS &amp; jQuery创建了一个web应用程序，并将其部署在本地。您也可以将其部署在AWS或任何其他基于cloude的平台上。这是我的网络应用的一个短片</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mq lq l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">400 Birds web-app</figcaption></figure><h2 id="3f3c" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">9.未来的工作</h2><p id="42d1" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">如果您希望进一步研究这个案例，您可以尝试自己的一些更复杂的架构(如VGG、ResnEt和Inception块的一些组合)，或者如果您有足够的计算资源，甚至可以使用VGG19从头开始训练一切。</p><h2 id="ca07" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">10.我的外卖</h2><p id="1d23" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">我想提一下我在解决这个问题时观察到的一些非常有趣的事情</p><ul class=""><li id="3fdc" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb lo jz ka kb bi translated">虽然可分离卷积由于训练较少数量的参数而需要较少的计算资源，但是结果不如卷积给出的那样好(这是明显的，因为它们需要训练更多数量的参数)。</li><li id="fe00" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">GlobalAvgPooling和GlobalMaxPooling是展平卷积输出并最终馈入全连接层的密集层的两种最佳方式。展平图层不必要地增加了参数的数量。</li><li id="1dd0" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">如果计算资源相对较少，那么与从头开始训练复杂模型相比，最好对预训练模型的最后几层进行微调。例如:我的情况是VGG19。亏损0.14就足够好了。如果整个VGG19从零开始训练，它甚至可能减少到10^-2周围的某个地方。</li><li id="6392" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb lo jz ka kb bi translated">图像增强是高泛化的关键。始终执行增强。</li></ul><p id="44f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢您的阅读！😄如果你喜欢这个博客，请点击拍手图标！👏 😃</p><p id="169c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还有，一定要访问这个项目的GitHub Repo。</p><p id="c311" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">链接:<a class="ae js" href="https://github.com/toushalipal6991/400-Birds-Species-Classification" rel="noopener ugc nofollow" target="_blank">https://github . com/toushalipal 6991/400-鸟类-物种-分类</a></p><h2 id="9423" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">11.参考</h2><p id="342c" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">首先，非常感谢<a class="ae js" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">应用人工智能课程</a>带给我的所有收获。</p><p id="8c50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" href="https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">如何在KERAS中配置图像数据增强</a></p><p id="1548" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">研究论文:-</p><p id="f0e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" href="https://arxiv.org/pdf/1409.1556.pdf" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的超深度卷积网络</a></p><p id="6c09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" rel="noopener ugc nofollow" target="_blank">用回旋加深</a></p><p id="9a0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></p><h2 id="3017" class="ko kp hh bd kq kr ks kt ku kv kw kx ky ip kz la lb it lc ld le ix lf lg lh li bi translated">12.我的个人资料</h2><div class="mr ms ez fb mt mu"><a href="https://www.linkedin.com/in/toushali-pal-099799146/" rel="noopener  ugc nofollow" target="_blank"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">TOUSHALI PAL - Kolkata，西孟加拉邦，印度|职业简介| LinkedIn</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">查看TOUSHALI PAL在LinkedIn上的职业资料。LinkedIn是世界上最大的商业网络，帮助…</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">www.linkedin.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni jm mu"/></div></div></a></div><div class="mr ms ez fb mt mu"><a href="https://github.com/toushalipal6991" rel="noopener  ugc nofollow" target="_blank"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">toushalipal6991 -概述</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">github.com</p></div></div><div class="nd l"><div class="nj l nf ng nh nd ni jm mu"/></div></div></a></div><div class="mr ms ez fb mt mu"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">medium.com</p></div></div><div class="nd l"><div class="nk l nf ng nh nd ni jm mu"/></div></div></a></div></div></div>    
</body>
</html>
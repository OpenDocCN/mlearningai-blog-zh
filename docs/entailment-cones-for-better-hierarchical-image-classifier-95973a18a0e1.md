# 用于更好的分层图像分类的蕴涵锥

> 原文：<https://medium.com/mlearning-ai/entailment-cones-for-better-hierarchical-image-classifier-95973a18a0e1?source=collection_archive---------3----------------------->

由 Caroline Freyer 和 Marios Marinos 撰写

在这篇博客中，解释了 Dhall 等人[2020]提出的利用嵌入在类标签中的语义层次信息的方法。Dhall 等人发表了一篇文章，根据经验显示了这种外部语义信息的可用性，并提出了几个利用这种知识的模型。他们在分层 ETHEC 数据集上验证了这些模型。我们希望这篇博客能为读者提供一个更详细、更直白的解释，来解释这篇论文中提到的概念。这个解释是基于我们自己的研究以及我们使用 Dhall 等人提供的知识库来重现论文结果的努力。

再现性是指重现论文结果的能力，从而验证和建立所提议方法的可信度。许多人认为，一篇论文要在科学上合理和完整，它应该是独立可复制的[Raff，2019]，即不需要作者的额外帮助。此外，复制纸质结果的能力是一项困难但必须练习的基本技能。为了跟上快节奏的环境，有必要借鉴他人的工作成果，而要有效地做到这一点，复制是主要步骤。在这篇博客中，我们希望进一步理解 Dhall 等人[2020]提出的主题，同时也分享我们复制这篇论文的经验。

在机器学习领域，分类是监督学习的一个实例。形式上，超视觉学习问题是训练数据包括输入向量及其相应目标向量的例子的应用[Bishop，2006]。给定这种标记的训练数据，监督模型必须学习将输入映射到目标向量的函数。在分类中，目标向量是类别的有限离散集合的元素，通常称为类。通常，通过独立地预测类别概率(即，属于每个类别的输入向量的概率)来执行分类，并且预测对应于最大类别概率的类别。这假定了互斥的和非结构化的标签。然而，Dhall 等人[2020]认为，许多常见数据集中的标签有一个潜在的组织，允许提取分层信息。引入这样的层次结构可以改进分类，因为它使用外部指导而不是传统的对象-标签对来进行训练。图像和语言的偏序关系(层次)，如图 1 所示，作者称之为视觉语义层次。此外，它通过利用共享特征改善了训练数据稀缺的类的一般化，并弥合了人类和机器视觉理解概念的方式之间的差距。因此，性能和可解释性都得到了提高。此外，仅考虑基于图像的特征来区分不同对象可能是不够的，尤其是在类内方差高于类间方差的情况下。这将应该在同一类中的图像分类到不同的类中[Dhall et al .，2020]。因此，使用标签-标签交互以及对象-标签交互可以提高学习质量。

![](img/40fd07280056f229ccdc78bc776b84bf.png)

Figure 1: Sample images from the ETHEC dataset with their 4 levels [Dhall et al., 2020].

Dhall 等人提出了多种方法用于在现有技术的 CNNclassifiers 中注入层次语义。这些方法可以分为两类:一种是在损失函数中利用层次结构，另一种是在公共空间中嵌入图像和标签。后者基于可以嵌入欧几里得和双曲空间的蕴涵锥。所有这些方法都在 ETHEC 数据集上得到验证，ETH Zurich 的昆虫学(昆虫)分级数据集。该数据集包括 47978 幅图像，具有 4 个不同级别和 723 个标签。样本图像如图 1 所示。为了帮助读者形象化层次化数据集的含义，图 2 展示了一个由三幅图像及其层次化属性组成的小型玩具数据集。图中的箭头表示不同类别的层次关系。

![](img/b4677e051f97b1ff252d59b619a08623.png)

FIgure 2: A slice of the visual-semantic hierarchy [Vendrov et al., 2015].

**顺序嵌入**

顺序嵌入保持对象之间的顺序，而不是它们的距离。这一点很重要，因为由于高差异，物理上的接近可能不总是代表相同的对象。更具体地说，序嵌入是单调函数，它提供了一种将一个偏序集包含到另一个偏序集中的方法。偏序集(poset)是一组具有相关二元关系的值，例如≤。在有序集合中，每对元素都需要通过二元关系进行比较，然而，对于偏序集合，这一要求是宽松的，因为它允许元素对不进行另一个。偏序集的一个例子是( *N+* ，),其中 *N+* 表示自然数的集合，不包括零。在这个集合中，3 和 5 不具有可比性，因为 3÷5 和 5÷3 不是包含在 *N+* 中的值。另一方面，6 和 3 是因为 6÷3 = 2∈N+。为了区分有序对和无序对，Dhall 等人[2020]分别定义了集合 *P* 和 *N* 。

为了完整起见，我们给出了 Schmidt [2010]的顺序嵌入的以下定义:

![](img/8d11df852789382ca9eeef82e7b72b4f.png)

这种排序加强了传递性和反对称关系，而不必依赖于点之间的物理接近度。我们将这些概念定义如下[Schmidt，2010]:

![](img/960fd320c81ff0e9797ebfaa0d4c367c.png)

图 3 显示了一个排序嵌入的例子。在此示例中，函数 f(x) =(94x+ 3)/100 将开区间(0，1)和闭区间[0，1]分别映射到子集(0.03，0.97)和[0.03，0.97]。因此，fis 既是保序的又是反映序的。

![](img/b4875590b59c329357ed54a6a968f64e.png)

Mutual order embedding of the open interval (0,1) and the closed [0,1] usingf(x) =(94x+ 3)/100 in both directions. Figure by Jochen Burghardt.

使用这种排序来嵌入分层语义为嵌入空间提供了结构，这是利用分类中的分层信息所必需的。目标是确定嵌入空间中的任意对是否有序。Dhall 等人[2020]使用了以下关系式:

![](img/8a24253e656af5257e21cbd8b4b9d98f.png)

请注意表达式中的反方向。这是指订单的顶部元素是更一般的概念。换句话说，如果 y 的所有单个坐标都大于或等于 x 的坐标，则该关系将 y 定义为 x 的子概念。在实践中，给定的顺序嵌入的形式定义过于严格。因此，使用了近似的顺序嵌入。首先，定义一个惩罚项来衡量一对点违反顺序的程度。我们将这种罚函数，即后来的能量，定义如下:

![](img/e13d3242ad20cd07e297a7e8bc10533a.png)

换句话说，这就是如果 *y* 成功 *x* 的话 *x* 和 *y* 的绝对差值。如果 *y* 存在或等于 *x* ，则 *E(x，y) = 0* 。然后，为了学习顺序嵌入 f，我们最小化最大余量损失，这鼓励正对(在集合 *P* 中)在嵌入中具有零惩罚，而负对(在集合 *N* 中)在嵌入中具有大于余量α的惩罚。形式上，最大利润损失被定义为

![](img/0773d8d8f59b21e2825bddb31c826ed0.png)

**双曲几何**

双曲几何是一种非欧几里得几何，它拒绝第五公设:

![](img/6911ab9abdcc32b7c5ba07b02302ef04.png)

在双曲几何中，至少有两条平行于给定直线的直线通过给定点。然而，不像欧几里得几何那样，直线在任何地方都是等距的，直线在一个方向上会聚，而在另一个方向上发散。而且，三角形内角之和小于双曲几何中的两个直角。图 4 直观地总结了这些概念。

![](img/90df9d3d68e022f6a546797ab6591655.png)

Figure 4: Summary of the difference between hyperbolic and Euclidean geometry [A’Campo and Papadopoulos , 2012]

这种几何学的一个模型是庞加莱球。在 N 维中，它是由流形定义的

![](img/72c78f48659d8f29b34f05ff53d328c7.png)

在哪里

![](img/c5cc5fcc576c8c9a26da0b3a8173bdd3.png)

这是半径为 1 的球，定义在双曲空间中。在这种情况下， *‖x‖_D* 是欧几里得空间中标准范数的双曲等价形式，定义为

![](img/36f5cfe16e3e9ce96c6c54863cdffc5c.png)![](img/799199d22da2de595773a1ec1a1ba499.png)

请参见图 6，了解庞加莱球及其切空间的直观表示。这些是定义嵌入分类器中使用的双曲锥的必要构造。使用这种几何图形背后的动机是，与欧几里德几何中的多项式相比，球的体积随着半径呈指数增长，因此我们可以在低维空间中嵌入指数增长的层次。此外，它更好地模拟了树状结构，这是用于定义标签层次结构的数据结构。

**双曲锥**

传统的顺序嵌入使用 orthants 作为距离函数。因此，如果 *v* 是 *u* 的子概念，则它位于 *u* 处的正交元素内。然而，这导致每个概念在嵌入的空间中占据很大的体积，并且遭受严重的正交交叉。因此，使用了圆锥。图 5 直观地展示了这种差异。

![](img/e4865302ed2638f53f00cfdb8d226d05.png)

Figure 5: Example comparing the use of orthants and cones in the embedded space.

双曲锥是映射到双曲几何上的欧几里得锥(如图 5 所示)。这种锥是序嵌入的推广，比通常所知的欧几里得锥更灵活。为了定义这些圆锥，我们在庞加莱球中的点 *x* 处引入指数映射，定义为

![](img/a2fccb2e3ffe752ea31ebb1f88659bcf.png)

然后，我们可以在目标空间中定义一个圆锥体，并使用此地图对其进行投影。加内亚等人[2018]对此的说明见图 6。

![](img/975a853a9a2196b7ceeb19afa28e357e.png)

Figure 6: Visualisation of hyperbolic cones in 3D space from [Ganea et al. , 2018].

对于庞加莱球中的 *x* ，圆锥的孔径为

![](img/544e3bedf417df073ee45e9c82b9ee84.png)

其中 *K* 是要调整的超参数。注意，圆锥体的最大孔径是π/2。给定这些构造，我们可以定义圆锥的轴和矢量 *y* 之间的最小角度。这将用于估算 *x* 和 *y* 之间的能量。我们将这个角度定义为

![](img/043010c12d997cfca9cf2f7920629c27.png)

那么 *x* 和 *y* 之间的能量可以定义为

![](img/d83af486951acc1d088ee22398642f03.png)

该角度代表将圆锥轴从 *x* 旋转到 *y* 进入圆锥所需的最小角度。因此，我们希望最小角度小于孔径的大小，以便最小化两点之间的能量。

**双曲空间中的优化**

对于双曲空间中的参数，使用黎曼随机梯度下降(RSGD)。这使用了更新

![](img/b2f9fe6724a413fbc2e95d9d483821a0.png)

其中，梯度是参数 *u 的黎曼梯度，η* 是学习速率，而 ***L*** 是我们试图最小化的无序度。黎曼随机梯度下降定义为欧几里德梯度的重新缩放，如下所示:

![](img/67b42aabe63735e5e09f57863947f9af.png)

其中λ_u= 2/(1−‖u‖^2).然而，Dhall 等人【2020】指出，双曲空间中 Adam 优化器的近似版本比精确的 RSGD 效果更好。尽管如此，RSGD 仍然用于部分优化。这将在随后的章节中进一步解释。

**基于嵌入的模型**

基于一些定义的相似性度量，这些模型返回给定查询的嵌入空间中最接近的概念[Dhall 等人，2020]。在通常的设置中，标签和对象被嵌入到相同的空间中。然后计算该对象与所有标签之间的相似度，并返回最优的跨模态关系。常见的映射包括神经网络，常见的相似性度量是点积。将这一概念扩展到使用双曲锥的双曲几何中，可以在利用标注等级时提供更大的灵活性。这与将分级信息注入损失函数形成对比，损失函数具有很强的限制性，并且必须针对特定的下游任务进行调整。

在上一节中，Dhall 等人[2020]针对分类任务定义了通用结构。Dhall 等人[2020]考虑的方法可以分为两类:基于 CNN 的分类器，其中将层次信息注入到最小化的损失函数中，以及嵌入分类器，其中标签和图像嵌入到相同的空间中。在这篇博客中，我们关注两个基于 CNN 的分类器，每级分类器(PLC)和边缘分类器(MC ),因为它们是我们复制的。此外，我们描述了使用双曲锥的联合嵌入分类器。

**基于 CNN 的模型**

在本节中，我们将讨论将标签层次结构合并到损失函数中的分类器。我们首先描述了等级不可知的基线分类器(HAB ),它被用作比较等级信息效果的基线。稍后我们描述 PLC 和 MC 分类器。Dhall 等人[2020]认为，这些模型不如嵌入分类器灵活，因为层次结构通常是固定的，并且是为一个特定的下游任务定制的。然而，我们随后看到，MC 的结果优于嵌入分类器的结果，因此值得进一步考虑。

**层次不可知基线分类器(HAB):** 对于层次不可知基线(HAB)分类器，使用残差网络进行图像分类【何等，2016】。此分类器不在数据集中包含任何标签层次结构。它对 N_t 个标签执行分类，其中 N_t 表示所有 L 个级别的标签总数(图 8)。对于这种分类，多标签软利润损失被最小化。这种损失被定义为[Dhall 等人，2020]:

![](img/f8569e6f368809af9d32500df4c53de7.png)

此外，x ∈ R^{N_t}是来自模型最后一层的逻辑， *y∈{0,1}^{* N_t}是对应于 *x* 的最大元素的输入的一个热编码标签。

![](img/7e076ef3d62005f2d47f1ace813bcbf0.png)

Figure 8: Model schematic for the hierarchy-agnostic classifier. The model is a multi-label classifier and does not utilize any information about the presence of an explicit hierarchy in the labels [Dhallet al., 2020]

**逐级分类器(PLC):** 逐级分类器非常类似于 HAB 分类器，但是它不是使用单个 N_t 路分类器，而是用 L 个 N_i 路分类器来代替。在 PLC 中，L 层中的每一层都有一个分类器，用于处理 I 层上的 N_i 标签(图 9)。它使用的损失函数是每个独立分类器的多标签软边际损失的总和。其定义如下:

![](img/77a9b210746290245d0639863acacc50.png)

Dhall 等人【2020】注意到，尽管 L 层的概念已被纳入 PLC，但它仍然不知道跨层节点之间的关系。因此，需要一个能够“记住”不同层次之间关系的分类器，这就是 MC 的用武之地。

![](img/6c9a2f3d1ac66750e53431f973ed35dd.png)

Figure 9: Model schematic for the per-level classifier (=L Ni-way classifiers). The model use information about the label hierarchy by explicitly predicting a single label per level for a given image[Dhall et al., 2020].

**边缘化分类器(MC):**MC 分类器使用单个分类器，该分类器输出分级结构中最后一级的概率分布。对于剩余的 L1 层，Dhall 等人[2020]通过对子节点的概率求和来计算该层标签的概率分布(图 10)。对于该分类器，最小化的损失为

![](img/e2eb03d8b7d02a3791aa692038e231d4.png)![](img/a1f5674297924eba775ea2a01ed4f542.png)![](img/c4aedcdc198192d9c0a640a7256da6a4.png)

Figure 10: Model schematic for the Marginalization method. Instead of predicting a label per level, the model outputs a probability distribution over the leaves of the hierarchy. The probability for non-leaf nodes is determined by marginalizing over the direct descendants. The Marginalization method models how different nodes are connected among each other in addition to the fact that there are L levels in the label hierarchy [Dhall et al., 2020].

为了简明扼要地总结上述信息，我们给出了表 1。

![](img/c7d029ad0364c97e34094b66e2e94cf4.png)

Table 1: Summary

**顺序嵌入模型**

对于这个模型，标签和图像被嵌入到同一个 N 维双曲空间中。标签是在这个空间中定义的，而图像是由 R^2048 空间中的特征来表示的。这些特征是从上述性能最好的基于 CCN 的模型中提取的。为了将它们映射到 D^N 空间，使用了学习线性变换 W∈R^{2048×N}。然后，使用等式 1 中定义的 0 处的指数映射，将该变换的结果映射到。接下来，必须在此空间中表示标签层次结构。标签层次被视为由包含蕴涵关系(u，v)的数据集 X 定义的有向非循环图。这些关系表示从概念 *u* 到概念 *v* 的有向边，并传达出 *v* 是 *u* 的子概念。然后训练模型将这些语义嵌入到空间中。在训练中，X 中不存在的边缘(称为负边缘)被添加到训练数据中，以允许更鲁棒的嵌入。为了提高收敛并帮助更好地将层次嵌入空间，Dhall 等人[2020]限制负边生成，以仅形成层次中不同级别之间的边。Adam 优化器用于这种嵌入。现在一切都嵌入到空间中，我们可以计算每个图像和每个标签之间的能量 *E* 并选择最小能量对应的标签。

**训练环境:**由于神经网络的训练过程可能是一个密集而繁重的过程，我们决定使用谷歌云平台来训练分类器，因为它提供了图形处理单元(GPU)。使用 GPU 对一个模型进行 100 个时期的训练可能需要大约 30 到 35 个小时。

![](img/75a28dbac76174f0c93f8c793ccf7d02.png)

Figure 7: Jointly embedding labels and images using EC in R^2\. The images are accumulated around the periphery, away from the origin [Dhall et al.,2020].

**超参数:**在我们的再现中，我们试图再现表 2 Dhall 等人【2020】的结果。更具体地说，我们试图重现上述 PLC 和 MC 模型的结果。所用的超参数如表 2 所示。对于 MC 模型，使用完全相同的参数，但是学习率是 0.0001 而不是 0.01。

![](img/57e3ca608f9f435eb021fa98093263fd.png)

在表 3 和表 4 中，我们将我们的复制结果与 Dhall 等人[2020]的表 2 中的结果进行了比较。我们看到我们的繁殖模型与他们的相比表现不佳。这可能是由于神经网络优化中的随机性。尽管如此，我们看到不同层的总体趋势是相同的。这种趋势更多地说明了结果的一致性，而不是它们的价值。因此，尽管表现不佳，我们对复制感到满意。我们相信，再次训练模型(也许我们不同的初始化)可能会产生更好的结果，但是，由于时间限制，我们不可能检查这一点。

![](img/344010bb346d35716a57a7a4195dfde4.png)

当开始钻研代码时，我们很难理解他们的代码。代码文件又大又乱。幸运的是，在大多数情况下，我们只需要配置代码，而不需要实现新的特性或更改现有的特性。除此之外，在更改了数据路径并对代码进行了微小的修改之后，代码运行起来并不太困难。

**我们在复制方面的工作:**最初的目标是复制三种模型的结果:PLC、MC 和 HC。不幸的是，我们未能实现这一目标。在尝试运行 HC 模型时，我们遗漏了三个。GitHub 存储库中运行模型所必需的 npy 文件。因此，我们联系作者索要这些文件。不幸的是，他们没有这些文件了，但给了我们一个如何生成它们的粗略程序。然而，由于时间限制，我们无法实施这一程序。然而，我们为您提供一些伪代码，告诉您如果我们有足够的时间，我们认为应该如何实现它。

![](img/2669700c3db38f2e1e0e781f9b0da732.png)

数据集以及模型将在第 9 行(model.forward(dataset))获得的输入将是 ETHEC 数据集的图像(224 x 224 RGB)。pty 是表现最好的 CNN 模型的权重，在我们的例子中是 MC 模型。使用此步骤是为了不需要重新训练 MC 模型。上述伪代码的输出有三个。npy 文件(train，test，val)应该是带有图像名称的字典(如 ETHZ_ENT01_2017 _03_30_008939。JPG)作为键，fc-7 特性作为值。我们假设它们只是 NumPy 数组，但这仍然需要检查和研究。

总之，本文试图将微分几何引入图像分类和神经网络领域。我们遇到的一些麻烦是本文 GitHub 库中代码的组织，这相当混乱和难以理解，作者自己在我们的通信中也提到了这一点。我们希望重现双曲锥(HC)分类器的结果，但由于缺少文件和时间限制，我们无法做到这一点。然而，根据作者 Dhall 等人[2020]的说法，其中最好的模型是边缘化分类器(MC)，所以这种大规模复杂的扩展甚至是必要的吗？

乍看之下，我们和 Dhall 等人[2020]似乎浪费了大量时间对双曲锥和双曲几何进行广泛的研究和解释，因为 MC 分类器的结果优于 HC 分类器。然而，这是第一份涉及这种方法的文件。理论上讲，与欧几里德几何中的多项式相比，双曲几何中的球的体积随半径呈指数增长。因此，我们可以在低维空间中嵌入指数增长的层次结构。此外，它更好地对类似于树的结构进行建模，这是用于定义标签层次结构的数据结构。因此，尽管结果平庸，该概念是有效的，并可用于许多应用中，以潜在地改进分类。因此，这一思想应该得到进一步的开发和应用在不同的应用。例如，当考虑对象之间的相关性而不是试图对它们进行分类时，它的性能可能优于最先进的技术。Dhallet 等人[2020]的主要不足在于，在分类器中嵌入层次语义可以提高分类器的性能。使用双曲几何来进一步帮助这种性能提升是一件仍然应该积极探索的事情。

**参考值**

名词（noun 的缩写）A'Campo 和 A. Papadopoulos。关于双曲几何的注记。斯特拉斯堡几何硕士班，18:1–182，2012 年。doi: 10.4171/105。

克里斯托弗·毕晓普。模式识别和机器学习。斯普林格，2006 年。

安吉特·达尔、阿纳斯塔西娅·马卡罗娃、屋大维·加内亚、达里奥·帕夫洛、迈克尔·格里夫和安-德瑞斯·克劳斯。基于蕴涵锥嵌入的分层图像分类。CoRR，abs/2004.03459，2020。网址:http://ar XIV . org/ABS/2004 . 03459。

O.加内亚，Becigneul G .，和 T. Hofmann。学习层次问题的双曲蕴涵锥。2018.

K.何、张 x、任 s、孙 j。用于图像识别的深度剩余学习。2016 年 IEEE 计算机视觉和模式识别会议(CVPR)，第 770-778 页，2016 年。doi:10.1109/CVPR.2016.90。

爱德华·拉夫。迈向量化可独立再现的机器学习研究的一步，2019 年。

冈瑟施密特。关系数学。美国剑桥大学出版社，2010.ISBN0521762685。

伊万·温德罗夫、瑞安·基罗斯、萨尼娅·菲德勒和拉奎尔·乌塔松。订单嵌入的形象和语言。arXiv 预印 arXiv:1511.06361，2015。
<html>
<head>
<title>Generating Realistic Human Faces</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成逼真的人脸</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/generating-realistic-human-faces-3e5fa40c76b3?source=collection_archive---------11-----------------------#2022-02-02">https://medium.com/mlearning-ai/generating-realistic-human-faces-3e5fa40c76b3?source=collection_archive---------11-----------------------#2022-02-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2bc2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">机器学习可能是当今最通用的领域之一，但同时也可能是最不稳定的领域之一。任何领域的新发现都可以动摇基础，并导致该领域的新研究。例如计算机视觉的ConvNet的引入。构建ConvNet是为了从图像中提取特征，但现在它也被用于处理顺序数据，这项任务以前非常适合LSTM和RNN。目前，机器学习最有前途的领域包括无监督学习，更具体地说，包括生成模型，如GANs(生成对抗网络)和变压器神经网络。今天，我将解决使用生成对抗性神经网络生成人脸的问题。</p><h1 id="c2a9" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">甘斯的一点背景:</h1><p id="8357" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">生成对抗性神经网络是Ian Goodfellow在2014年提出的一种理论，此后在机器学习领域获得了许多应用。它可以用于从图像数据集生成图像，这是它的主要目的，但是生成模型也可以用于强化学习(更多信息:<a class="ae kf" href="https://simons.berkeley.edu/talks/tbd-241" rel="noopener ugc nofollow" target="_blank">https://simons.berkeley.edu/talks/tbd-241</a>)。生成模型通过使两个模型相互对立来工作。这使得该模型非常适合无监督学习，但也使得该模型在没有大量数据的情况下极其不稳定并且难以收敛。该模型通过一个生成器和一个鉴别器来工作。鉴别器的工作是区分生成器生成的图像和数据集。生成器的工作是从作为输入提供给生成器的潜在空间生成图像。它试图生成与数据集足够相似的图像来欺骗鉴别器。</p><figure class="kg kh ki kj fd kk"><div class="bz dy l di"><div class="kl km l"/></div></figure><p id="6e63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢约瑟夫·罗卡的精彩解释。</p><h1 id="9d29" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">生成模型背后的数学:</h1><p id="5e68" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们之前在高层次上探索了一般对抗性网络的基础，现在让我们通过分析伊恩·古德费勒在他的论文《生成对抗性网络》(【https://arxiv.org/pdf/1406.2661.pdf】<a class="ae kf" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank"/>)中提出的数学来深入研究生成模型的数学和基础。在他的论文中，他提出了这个数学方程式:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kn"><img src="../Images/fceafd71d17b47ea1d925d65d2cabc1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGD4I7fwNC5LVIGGnFSsrw.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx">Math equation for GANs from Ian Goodfellow’s paper</figcaption></figure><p id="a43e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">函数D(x)指的是鉴频器接收真实图像并输出一个值，该值随后被对数函数缩放以返回0和1之间的值。在log(1-D(G(z))中也发生同样的情况，该函数接收发生器模型的输出并返回从1减去的缩放后的值，该值返回从0到1的标度下端的值。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ky"><img src="../Images/1a7eca4cfefa6f84c00ea8e85fe6668a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iv9PfCEZl6itXsfoM75GfA.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx">Math equation for Discriminator gradient from Ian Goodfellow’s paper</figcaption></figure><p id="a39e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输入由鉴别器产生的真实图像的x值和伪图像的G(z)值，该值再次由对数函数缩放。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kz"><img src="../Images/ce12351fba68d6ef40f0aee0dc6ed7ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_3dDCQldLLidiGxIFzy1Q.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx">Math Equation for generator gradient</figcaption></figure><p id="f9af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">发生器被输入一个随机噪声矢量(z ),其输出随后被传递到鉴别器函数，该函数使用对数函数来缩放该值。</p><p id="3ba1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型分批训练，首先训练鉴别器n步，之后训练停止，生成模型开始训练，试图从高斯噪声生成图像，试图用它认为与数据库中的图像相同的图像欺骗鉴别器。</p><h1 id="a67d" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">GAN的实施:</h1><p id="4e4b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">GAN的实现非常简单，但是如果使用Tensorflow这样的高级api，它的长度仍然很长。</p><pre class="kg kh ki kj fd la lb lc ld aw le bi"><span id="437d" class="lf jd hh lb b fi lg lh l li lj">discriminator = keras.Sequential(</span><span id="cef9" class="lf jd hh lb b fi lk lh l li lj">[</span><span id="14ba" class="lf jd hh lb b fi lk lh l li lj">keras.Input(shape=(128, 128, 3)),</span><span id="59c3" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='same'),</span><span id="7bc5" class="lf jd hh lb b fi lk lh l li lj">keras.layers.LeakyReLU(alpha=0.2),</span><span id="d502" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Conv2D(filters=128, kernel_size=4, strides=2, padding='same'),</span><span id="c2ab" class="lf jd hh lb b fi lk lh l li lj">keras.layers.LeakyReLU(alpha=0.2),</span><span id="2c0f" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Conv2D(filters=128, kernel_size=4, strides=2, padding='same'),</span><span id="2e08" class="lf jd hh lb b fi lk lh l li lj">keras.layers.LeakyReLU(alpha=0.2),</span><span id="0809" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Flatten(),</span><span id="ce50" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Dropout(0.2),</span><span id="98fe" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Dense(units=1, activation='sigmoid')</span><span id="17ec" class="lf jd hh lb b fi lk lh l li lj">],</span><span id="33aa" class="lf jd hh lb b fi lk lh l li lj">name='discriminator'</span><span id="3c7e" class="lf jd hh lb b fi lk lh l li lj">)</span><span id="e461" class="lf jd hh lb b fi lk lh l li lj">discriminator.summary()</span></pre><p id="238f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鉴别器遵循与深度卷积神经网络相似的模型，这允许它在鉴别生成的图像和来自数据集的图像时具有更好的准确性。</p><pre class="kg kh ki kj fd la lb lc ld aw le bi"><span id="edaf" class="lf jd hh lb b fi lg lh l li lj">latent_dim = 128</span><span id="e8c6" class="lf jd hh lb b fi lk lh l li lj">generator = keras.Sequential([</span><span id="1b79" class="lf jd hh lb b fi lk lh l li lj">keras.Input(shape=latent_dim),</span><span id="3a01" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Dense(16*16*128),</span><span id="65b5" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Reshape((16, 16, 128)),</span><span id="f7f7" class="lf jd hh lb b fi lk lh l li lj">layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding="same"),</span><span id="bb05" class="lf jd hh lb b fi lk lh l li lj">layers.LeakyReLU(alpha=0.2),</span><span id="6f7a" class="lf jd hh lb b fi lk lh l li lj">layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding="same"),</span><span id="91c9" class="lf jd hh lb b fi lk lh l li lj">layers.LeakyReLU(alpha=0.2),</span><span id="e96a" class="lf jd hh lb b fi lk lh l li lj">layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding="same"),</span><span id="d2cd" class="lf jd hh lb b fi lk lh l li lj">layers.LeakyReLU(alpha=0.2),</span><span id="2a3a" class="lf jd hh lb b fi lk lh l li lj">keras.layers.Conv2D(3, kernel_size=4, padding='same', activation='sigmoid')</span><span id="209a" class="lf jd hh lb b fi lk lh l li lj">],</span><span id="ec52" class="lf jd hh lb b fi lk lh l li lj">name='generator'</span><span id="5b80" class="lf jd hh lb b fi lk lh l li lj">)</span><span id="a970" class="lf jd hh lb b fi lk lh l li lj">generator.summary()</span></pre><p id="669c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">生成器遵循与全连接神经网络相似的模型，具有conv2d转置层，返回大小为输入张量两倍的张量。</p><pre class="kg kh ki kj fd la lb lc ld aw le bi"><span id="8645" class="lf jd hh lb b fi lg lh l li lj">class GAN(keras.Model):</span><span id="9ea0" class="lf jd hh lb b fi lk lh l li lj">def __init__(self, discriminator, generator, latent_dim):</span><span id="c926" class="lf jd hh lb b fi lk lh l li lj">super(GAN, self).__init__()</span><span id="1b80" class="lf jd hh lb b fi lk lh l li lj">self.discriminator = discriminator</span><span id="2246" class="lf jd hh lb b fi lk lh l li lj">self.generator = generator</span><span id="b9b5" class="lf jd hh lb b fi lk lh l li lj">self.latent_dim = latent_dim</span><span id="9f93" class="lf jd hh lb b fi lk lh l li lj">def compile(self, d_optimizer, g_optimizer, loss_fn):</span><span id="d2ba" class="lf jd hh lb b fi lk lh l li lj">super(GAN, self).compile()</span><span id="7db3" class="lf jd hh lb b fi lk lh l li lj">self.d_optimizer = d_optimizer</span><span id="a63d" class="lf jd hh lb b fi lk lh l li lj">self.g_optimizer = g_optimizer</span><span id="73f7" class="lf jd hh lb b fi lk lh l li lj">self.loss_fn = loss_fn</span><span id="2881" class="lf jd hh lb b fi lk lh l li lj">self.d_loss_metric = keras.metrics.Mean(name="d_loss")</span><span id="6c57" class="lf jd hh lb b fi lk lh l li lj">self.g_loss_metric = keras.metrics.Mean(name="g_loss")</span><span id="17df" class="lf jd hh lb b fi lk lh l li lj">@property</span><span id="722a" class="lf jd hh lb b fi lk lh l li lj">def metrics(self):</span><span id="3f11" class="lf jd hh lb b fi lk lh l li lj">return [self.d_loss_metric, self.g_loss_metric]</span><span id="5123" class="lf jd hh lb b fi lk lh l li lj">def train_step(self, real_images):</span><span id="a87a" class="lf jd hh lb b fi lk lh l li lj"># Sample random points in the latent space</span><span id="9b6f" class="lf jd hh lb b fi lk lh l li lj">batch_size = tf.shape(real_images)[0]</span><span id="29e2" class="lf jd hh lb b fi lk lh l li lj">random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))</span><span id="5d23" class="lf jd hh lb b fi lk lh l li lj"># Decode them to fake images</span><span id="4312" class="lf jd hh lb b fi lk lh l li lj">generated_images = self.generator(random_latent_vectors)</span><span id="4471" class="lf jd hh lb b fi lk lh l li lj"># Combine them with real images</span><span id="6b84" class="lf jd hh lb b fi lk lh l li lj">combined_images = tf.concat([generated_images, real_images], axis=0)</span><span id="5d9e" class="lf jd hh lb b fi lk lh l li lj"># Assemble labels discriminating real from fake images</span><span id="c6d4" class="lf jd hh lb b fi lk lh l li lj">labels = tf.concat(</span><span id="273e" class="lf jd hh lb b fi lk lh l li lj">[tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0</span><span id="c760" class="lf jd hh lb b fi lk lh l li lj">)</span><span id="55cd" class="lf jd hh lb b fi lk lh l li lj"># Add random noise to the labels - important trick!</span><span id="b809" class="lf jd hh lb b fi lk lh l li lj">labels += 0.05 * tf.random.uniform(tf.shape(labels))</span><span id="38ee" class="lf jd hh lb b fi lk lh l li lj"># Train the discriminator</span><span id="8d20" class="lf jd hh lb b fi lk lh l li lj">with tf.GradientTape() as tape:</span><span id="35c1" class="lf jd hh lb b fi lk lh l li lj">predictions = self.discriminator(combined_images)</span><span id="e7f3" class="lf jd hh lb b fi lk lh l li lj">d_loss = self.loss_fn(labels, predictions)</span><span id="18ee" class="lf jd hh lb b fi lk lh l li lj">grads = tape.gradient(d_loss, self.discriminator.trainable_weights)</span><span id="529a" class="lf jd hh lb b fi lk lh l li lj">self.d_optimizer.apply_gradients(</span><span id="fd30" class="lf jd hh lb b fi lk lh l li lj">zip(grads, self.discriminator.trainable_weights)</span><span id="2710" class="lf jd hh lb b fi lk lh l li lj">)</span><span id="9fbb" class="lf jd hh lb b fi lk lh l li lj"># Sample random points in the latent space</span><span id="fd24" class="lf jd hh lb b fi lk lh l li lj">random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))</span><span id="c6ee" class="lf jd hh lb b fi lk lh l li lj"># Assemble labels that say "all real images"</span><span id="333f" class="lf jd hh lb b fi lk lh l li lj">misleading_labels = tf.zeros((batch_size, 1))</span><span id="d0fa" class="lf jd hh lb b fi lk lh l li lj"># Train the generator (note that we should *not* update the weights</span><span id="a88e" class="lf jd hh lb b fi lk lh l li lj"># of the discriminator)!</span><span id="ba63" class="lf jd hh lb b fi lk lh l li lj">with tf.GradientTape() as tape:</span><span id="b12a" class="lf jd hh lb b fi lk lh l li lj">predictions = self.discriminator(self.generator(random_latent_vectors))</span><span id="bfac" class="lf jd hh lb b fi lk lh l li lj">g_loss = self.loss_fn(misleading_labels, predictions)</span><span id="272a" class="lf jd hh lb b fi lk lh l li lj">grads = tape.gradient(g_loss, self.generator.trainable_weights)</span><span id="903a" class="lf jd hh lb b fi lk lh l li lj">self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))</span><span id="3d3f" class="lf jd hh lb b fi lk lh l li lj"># Update metrics</span><span id="9744" class="lf jd hh lb b fi lk lh l li lj">self.d_loss_metric.update_state(d_loss)</span><span id="51de" class="lf jd hh lb b fi lk lh l li lj">self.g_loss_metric.update_state(g_loss)</span><span id="208a" class="lf jd hh lb b fi lk lh l li lj">return {</span><span id="1184" class="lf jd hh lb b fi lk lh l li lj">"d_loss": self.d_loss_metric.result(),</span><span id="bf58" class="lf jd hh lb b fi lk lh l li lj">"g_loss": self.g_loss_metric.result(),</span><span id="932f" class="lf jd hh lb b fi lk lh l li lj">}</span></pre><p id="6f62" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">代码改编自keras DCGAN模型</p><p id="224c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以创建一个名为GAN的类，它包含了训练生成模型所需的所有方法。在编译函数中，我们简单地实例化参数。真正复杂的行为是在train_step函数中。该功能包括两个阶段。</p><ul class=""><li id="ab16" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated">在第一阶段，我们向生成器输入高斯噪声来生成假图像，然后我们通过连接相同数量的真实图像来完成这一批。伪图像的目标设置为0，真实图像的目标设置为1(这些标签用于计算损失函数)。然后，我们在这一批上训练鉴别器。</li><li id="dff3" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">在第二阶段，我们给GAN注入一些高斯噪声。然后，生成器开始生成假图像，同时鉴别器尝试猜测图像是真的还是假的。我们还创造了“误导标签”,让鉴别者相信假图像是真的</li></ul><p id="fe70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">运行这段代码会产生非常接近的图像，由于生成器没有完全收敛，所以会有一些小瑕疵。</p><p id="4802" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">查看mnist上tensorflow的教程，自己实现GAN:<a class="ae kf" href="https://www.tensorflow.org/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/generative/dcgan</a></p><div class="lz ma ez fb mb mc"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="md ab dw"><div class="me ab mf cl cj mg"><h2 class="bd hi fi z dy mh ea eb mi ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mj l"><h3 class="bd b fi z dy mh ea eb mi ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mk l"><p class="bd b fp z dy mh ea eb mi ed ef dx translated">medium.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ks mc"/></div></div></a></div><p id="3504" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae kf" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb">成为ML作家</a></p></div></div>    
</body>
</html>
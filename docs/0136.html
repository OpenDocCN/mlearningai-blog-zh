<html>
<head>
<title>An explanation of K-means and two of its offshoots</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对K-means及其两个分支的解释</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/an-explanation-of-k-means-and-two-of-its-offshoots-69487110c7c4?source=collection_archive---------0-----------------------#2021-02-18">https://medium.com/mlearning-ai/an-explanation-of-k-means-and-two-of-its-offshoots-69487110c7c4?source=collection_archive---------0-----------------------#2021-02-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6b3e" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">k-means、层次k-means及其小批量兄弟的介绍</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/d36719636b87fbe1a873b1dd4c86afd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dgeYsB2Yl6_4GdGR"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@billy_huy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Billy Huynh</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="30d6" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="kj">K</em>-均值聚类是机器学习中广泛使用的一种技术，作为矢量量化的一种形式，用于将点的矢量空间划分为<em class="kj"> k </em>个聚类。这是一种非常有用的无监督方法，可以将多个点聚类成一个质心集合，稍后可以用于许多具有深度学习的下游任务。然而，有时普通的<em class="kj"> k </em> -means计算量太大，或者在大型数据集上运行需要几天时间。这就是使用<em class="kj"> k </em>的方法——分层次地使用或在小批中使用数据——大大提高了效率，同时仍然保持相当的性能。</p><h1 id="c7d6" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">k均值</h1><p id="6b5e" class="pw-post-body-paragraph jn jo hh jp b jq lc ii js jt ld il jv jw le jy jz ka lf kc kd ke lg kg kh ki ha bi translated">传统的<em class="kj">k</em>-意味着算法从向量空间中的数据开始，我们称之为<em class="kj"> X，</em>其中<em class="kj"> X </em>由<em class="kj"> r </em>点<em class="kj"> (x₁，x₂，…，xᵣ).</em>我们希望将<em class="kj"> k </em>形心与<em class="kj"> X </em>相匹配，这样对于每个形心的聚类，方差最小化。通俗地说，这意味着每个质心的点集形成了一个很好的聚类，与其他质心的聚类不同。</p><p id="ec00" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">那么在实践中如何做到这一点呢？有很多方法可以做到这一点，但是k-means使用了一种叫做劳埃德算法的东西。首先，质心被初始化为向量空间中的随机点。<em class="kj"> X </em>中的每个点都被分配了一个质心，该质心是通过找到离每个点最近的质心来计算的。之后，每个质心的位置被更新为与其相关联的或其聚类的所有点的平均值。然而，在此步骤之后，考虑到质心位置已被更新，<em class="kj"> X </em>中的一些点将被分配给不同的质心。因此，我们重复前面的步骤，更新每个质心的位置，以反映其聚类中点的变化平均值。我们这样做，直到质心的位置不再改变，或者换句话说，当它已经收敛。这使得质心倾向于数据中存在的固有聚类的平均值。下面是一张说明整个过程的gif图:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lh"><img src="../Images/68e8b2771b55a98cab1478fdb9446e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/1*Nx6IyGfRAV1ly6uDGnVCxQ.gif"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Source: <a class="ae jm" href="https://en.wikipedia.org/wiki/K-means_clustering#/media/File:K-means_convergence.gif" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/K-means_clustering#/media/File:K-means_convergence.gif</a></figcaption></figure><p id="c20b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如您所见，这种简单的方法意味着聚类方法对于小数据集非常有效。然而，有许多方法可以使这更快更有效。</p><h1 id="c8ce" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">分级<em class="li">k</em>-意思是</h1><p id="24d6" class="pw-post-body-paragraph jn jo hh jp b jq lc ii js jt ld il jv jw le jy jz ka lf kc kd ke lg kg kh ki ha bi translated">分层<em class="kj">k</em>-意思是聚类(又名<em class="kj">hk</em>-意思是聚类)，不要与分层聚类(这是完全不同的东西)混淆，它是普通<em class="kj"> k </em>意思的更有效的兄弟。这是一种递归方法，包括对相对较小的数据使用<em class="kj"> k </em> -means，然后对使用相同<em class="kj"> k </em>的每个质心簇使用<em class="kj"> k </em> -means，用于<em class="kj"> h </em>层次。最后一个层次的质心被连接成整个数据集的质心。当具有大的<em class="kj"> k </em>并且更新<em class="kj"> k </em>形心的计算代价很高时，这种方法是有益的。该方法的直观表示如下所示:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lj"><img src="../Images/d8ef3f708c5093a5777c74d32ce150d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vXfHETCdbbMTLmIDtkLj3w.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Source: <a class="ae jm" href="https://www.andrew.cmu.edu/user/hgifford/projects/k_means.pdf" rel="noopener ugc nofollow" target="_blank">https://www.andrew.cmu.edu/user/hgifford/projects/k_means.pdf</a></figcaption></figure><h1 id="1aff" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">迷你批次k均值</h1><p id="1918" class="pw-post-body-paragraph jn jo hh jp b jq lc ii js jt ld il jv jw le jy jz ka lf kc kd ke lg kg kh ki ha bi translated">顾名思义，minibatch<em class="kj">k</em>——的意思是和mini batch<em class="kj">hk</em>——的意思是使用mini batch使这种算法适用于极其庞大的数据集。类似于神经网络如何批量消耗数据，k的这个分支<em class="kj"> k </em> -means在每一批之后迭代并更新质心。这使得在大型数据集上进行k均值计算变得简单，并获得与常规k均值计算相对相似的结果。有关minibatch hk-means的编码示例，请查看这个python包:</p><div class="lk ll ez fb lm ln"><a href="https://github.com/ammesatyajit/hierarchical-minibatch-kmeans" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">ammesatyajit/分级-小型批次-kmeans</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">分层kmeans的一种实现，使用小型批处理来提高大型数据集的效率。pip3…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">github.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb jg ln"/></div></div></a></div><h1 id="8dbf" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">结论</h1><p id="a1d4" class="pw-post-body-paragraph jn jo hh jp b jq lc ii js jt ld il jv jw le jy jz ka lf kc kd ke lg kg kh ki ha bi translated">均值是一种有用的技术，可以用作聚类方法、矢量量化等等。它还有多个分支，可以提高现实世界中大型数据集的性能和效率。其中两个变体是分层的<em class="kj"> k </em> -means和迷你批处理<em class="kj"> k </em> -means，但是还有无数其他方法可以进一步提高这种性能，比如智能地初始化质心。有了这么多的用途和这么多的改进，<em class="kj"> k </em> -means仍然是机器学习中最突出的聚类算法之一也就不足为奇了。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Multiple Linear Regression Fundamentals and Modeling in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的多元线性回归基础和建模</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/multiple-linear-regression-fundamentals-and-modeling-in-python-60db7095deff?source=collection_archive---------0-----------------------#2021-03-29">https://medium.com/mlearning-ai/multiple-linear-regression-fundamentals-and-modeling-in-python-60db7095deff?source=collection_archive---------0-----------------------#2021-03-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ac9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博文中，首先，我将尝试解释多元线性回归的基础知识。然后，我将通过Python使用数据集构建模型。最后，我将通过计算均方差来评估模型。让我们一步一步开始吧。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/805fb00a9eec4bfc7ada342e9222d914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*HLN6FxlXrzDtYN0KAlom4A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Resource: <a class="ae jo" rel="noopener" href="/analytics-vidhya/new-aspects-to-consider-while-moving-from-simple-linear-regression-to-multiple-linear-regression-dad06b3449ff">https://medium.com/analytics-vidhya/new-aspects-to-consider-while-moving-from-simple-linear-regression-to-multiple-linear-regression-dad06b3449ff</a></figcaption></figure><h1 id="7c42" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是多元线性回归？</h1><p id="d1cf" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">多元线性回归的主要目的是找到表达因变量和自变量之间关系的线性函数。多元线性回归模型有一个因变量和多个自变量。在另一个来源中，它被定义如下:</p><blockquote class="ks kt ku"><p id="2f1e" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated"><strong class="ig hi">多元线性回归</strong>用于估计<strong class="ig hi">两个或多个自变量</strong>与<strong class="ig hi">一个因变量</strong>之间的关系。当您想知道以下内容时，可以使用多元线性回归:</p><p id="db5a" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated">-两个或更多自变量和一个因变量之间的关系有多强(例如，降雨量、温度和施肥量如何影响作物生长)。</p><p id="7783" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated">-自变量的某个值处的因变量的值(例如，在特定降雨量、温度和施肥水平下的作物预期产量)。</p></blockquote></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><p id="56ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么它和简单的线性回归有什么不同呢？我可以解释如下的区别。当我们对现实生活中的问题进行预测分析时，我们可能无法用单个自变量进行很好的预测。使用几个独立变量进行估计会更容易，也更准确。</p><p id="bfb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，假设您想要估计一辆汽车的销售价格。因变量是销售价格。想象一下，如果你有一些关于汽车的信息，你就能猜出它的售价。这些是；</p><ul class=""><li id="71b7" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">公里信息，</li><li id="49f7" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">发动机功率，</li><li id="6bcd" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">生产年份，</li><li id="515c" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">损坏率</li></ul><p id="a01f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种情况下，您有4个参数。有了这4个独立变量，你可以更准确地预测汽车的销售价格。</p><p id="7508" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以实际上我们仍然在寻找一个线性关系，比如简单的线性回归。但是我们会用更多的论据来证明。</p><p id="9f78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多元线性回归在世界各地都很常见。它有一些假设。</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h2 id="4513" class="lu jq hh bd jr lv lw lx jv ly lz ma jz ip mb mc kd it md me kh ix mf mg kl mh bi translated">多元线性回归的假设</h2><p id="0d25" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">多元线性回归与简单线性回归有相似的假设。这些是；</p><ul class=""><li id="5fa2" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">误差呈正态分布。</li><li id="9c09" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">这些误差是相互独立的，它们之间没有共同的相关性。</li><li id="741f" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">每次观测的误差项方差是常数。</li><li id="b8a0" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">变量和误差项之间没有关系。</li><li id="4c58" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">自变量之间没有问题<code class="du mi mj mk ml b">Multiple Linear Relationship</code>。</li></ul><p id="6d2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们试着理解多元线性回归的数学。</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="1409" class="jp jq hh bd jr js mm ju jv jw mn jy jz ka mo kc kd ke mp kg kh ki mq kk kl km bi translated">多元线性回归模型</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mr"><img src="../Images/7f8fbddd759bbd97887132d2c3613a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*ToA8ZzKgljNDnFsIIOlukw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Multiple Linear Regression Formula</figcaption></figure><ul class=""><li id="94df" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">y →因变量的预测值。</li><li id="1342" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">β0 →是要在数据集中找到的参数。它是指简单线性回归线与Y轴相交的点。</li><li id="e410" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">β1x 1→第一个自变量的回归系数(B1)。(X1)(也称为增加独立变量的值对预测的<strong class="ig hi"> y </strong>值的影响)</li><li id="9d7b" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">βnXn →最后一个自变量的回归系数。</li><li id="13d9" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">ϵ →指误差项。</li></ul></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="260e" class="jp jq hh bd jr js mm ju jv jw mn jy jz ka mo kc kd ke mp kg kh ki mq kk kl km bi translated">用Python建模</h1><p id="d347" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">现在让我们在一个样本数据集上建立一个<code class="du mi mj mk ml b">Multiple Linear Regression</code>模型。然后让我们计算模型的平方根，这将给出模型误差。</p><p id="2794" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我导入<code class="du mi mj mk ml b">pandas</code>库。然后，我将广告数据集保存在数据帧中。此数据集中的第一列是错误的索引列。这就是为什么我没有在数据框架中包括这个列。我正在用<code class="du mi mj mk ml b">df.head()</code>回顾前5个观察结果</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="164f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我把自变量X放入数据帧。我用Drop函数做到了这一点。我把销售以外的东西保存在一个数据框架中。我将因变量Sales保存为不同数据框架中的y。作为这些操作的结果，我们把因变量和自变量彼此分开。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="eca6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我正在查看y和X数据框架的前5个观察值。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><h2 id="ea38" class="lu jq hh bd jr lv lw lx jv ly lz ma jz ip mb mc kd it md me kh ix mf mg kl mh bi translated"><strong class="ak">用Statsmodel建立模型</strong></h2><p id="2822" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">分离因变量和自变量后；首先，我们将使用Statsmodel建立多元线性回归模型。这是一个有点原始的方法。我导入Statsmodel库来安装模型。然后我用OLS方法创建lm模型对象。当我们用Statsmodel建立一个模型时，我们获得了一个可以了解更多的模型。</p><ul class=""><li id="02de" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">OLS →普通最小二乘法</li></ul><p id="4bbd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除了OLS，还有两种不同的方法，WLS和GLS。</p><ul class=""><li id="0f7b" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">WLS →加权最小二乘法</li><li id="c00c" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">GLS →广义最小二乘法</li></ul><p id="57e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多关于<code class="du mi mj mk ml b">Statsmodel</code>的信息，可以访问网站。</p><p id="3cc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jo" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">https://www.statsmodels.org/stable/index.html</a></p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="c4c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们说<code class="du mi mj mk ml b">model.summary()</code>时，我们可以访问我们已经构建的模型的所有概要信息。对我们来说很重要的价值观是:</p><ul class=""><li id="0b08" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">r平方→随着变量数量的增加，膨胀。</li><li id="f8db" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">Adj. R-squared →防止因变量数量增加而膨胀。</li><li id="836a" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">方法→多元线性回归模型中的方法。</li><li id="6137" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">coef →最后的自变量是系数。</li><li id="a07e" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">P&gt;|t| →它给出了系数是否有意义的信息。如果小于0.05，则模型显著。</li></ul><p id="7978" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，其他数据也提供了重要信息。但是我不会在这篇博文中谈论多元线性回归，所以我不会讲太多细节。如果你愿意，你可以自己研究一下。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><h2 id="dd4d" class="lu jq hh bd jr lv lw lx jv ly lz ma jz ip mb mc kd it md me kh ix mf mg kl mh bi translated">使用Scikit Learn构建模型</h2><p id="b22d" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">现在我们来看对我们来说更重要的部分。我们将使用Scikit学习库安装多元线性回归模型。</p><p id="5846" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我从Scikit学习库中导入LinearRegression。然后我用LinearRegression创建lm模型对象。然后我们用物体lm来拟合模型。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="fee6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用intercept_来看模型的常系数。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="8344" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用coef_来查看模型自变量的系数。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="9063" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将这些系数解释如下。例如，我们发现电视的值为0.04576465。假设其他变量不变，电视支出每增加一个单位，将导致因变量(即销售额)平均增加0.04576465个单位。</p><p id="8f68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们继续用我们建立的模型进行预测。</p><h2 id="d491" class="lu jq hh bd jr lv lw lx jv ly lz ma jz ip mb mc kd it md me kh ix mf mg kl mh bi translated">模型预测法</h2><p id="c96e" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">首先，我在一个数组中给出新的数据，以便模型能够做出预测。然后我转置这个数组。因为我们输入的数据属于每一列的一个独立变量。它不应包含在一个单独的列中。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="66e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们所要做的预测就是将新数据作为参数提供给predict函数。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="78d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">利用我们建立的多元线性回归模型，我们估计当我们在电视上做30个单位的广告，在广播上做10个单位的广告，在报纸上做45个单位的广告时，销售额是6.15个单位。</p><p id="a84f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用<code class="du mi mj mk ml b">model.score()</code>来衡量模型的成功。我们对因变量和自变量的计算如下。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="a540" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于模型来说，一切似乎都很好。但是目前我们不知道这个模型有多大的误差。现在让我们计算数据集中的实际销售额和我们估计的销售额之间的平均误差平方。为此，我们将使用<code class="du mi mj mk ml b">mean_squared_error</code>函数。</p><p id="56f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du mi mj mk ml b">mean_squared_error</code>函数获取真实的y值作为第一个参数，获取估计的y值作为第二个参数。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="02e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们计算均方误差的平方根如下。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><blockquote class="ks kt ku"><p id="019f" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated"><strong class="ig hi"> MSE: </strong>简单来说，均方差告诉你一条回归曲线与一组点有多接近。MSE衡量机器学习模型(预测器)的性能，它总是为正，可以说MSE值接近零的预测器性能更好。</p><p id="815b" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated"><strong class="ig hi"> RMSE: </strong>这是一种二次度量，经常用于查找机器学习模型的预测值和实际值之间的距离，并测量误差的大小。RMSE估计误差的标准差(残差)。也就是说，残差是回归线距离数据点有多远的度量；RMSE是衡量这些残留物扩散程度的标准。换句话说，它会告诉您最符合数据的线周围的数据密度。RMSE值的范围可以从0到∞。负向分数，即具有较低值的预测值，表现更好。零RMSE值意味着模型没有错误。RMSE的优势是惩罚更大的错误，所以它可能更适合某些情况。RMSE防止在许多数学计算中不必要的使用绝对值。</p></blockquote><h2 id="6b9b" class="lu jq hh bd jr lv lw lx jv ly lz ma jz ip mb mc kd it md me kh ix mf mg kl mh bi translated">模型调整</h2><p id="bdbd" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">我们进行调整过程，以最大化机器学习模型，防止过度学习和高方差。</p><p id="18cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kv">什么是模型调优？</em> </strong></p><blockquote class="ks kt ku"><p id="56e9" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated">调整通常是一个反复试验的过程，通过该过程，您可以更改一些超参数(例如，基于树的算法中的树的数量或线性算法中的alpha值)，再次对数据运行该算法，然后比较其在验证集上的性能，以确定哪组超参数会产生最准确的模型。</p></blockquote><p id="308c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用于模型调整；首先，我们将数据集分为训练集和测试集。我们用<code class="du mi mj mk ml b">train_test_split</code>来做这件事。使用<code class="du mi mj mk ml b">train_test_split</code>函数中的test_size，我们可以确定我们拥有的数据集中有多少百分比将成为测试集。<code class="du mi mj mk ml b">random_state</code>关于数据集的不同划分。如果我们不输入值，每次运行模型时，我们都会使用不同的数据进行计算。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="c561" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，如我们所知，我们使用lm模型对象在训练数据集上建立模型。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="ce03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我们分别计算训练和测试数据的均方误差。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><h2 id="2c67" class="lu jq hh bd jr lv lw lx jv ly lz ma jz ip mb mc kd it md me kh ix mf mg kl mh bi translated">k倍交叉验证</h2><blockquote class="ks kt ku"><p id="ffbf" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated">交叉验证是一种重采样过程，用于在有限的数据样本上评估机器学习模型。</p><p id="f3a2" class="ie if kv ig b ih ii ij ik il im in io kw iq ir is kx iu iv iw ky iy iz ja jb ha bi translated">该过程有一个称为k的参数，它指的是给定数据样本要被分成的组的数量。因此，该程序通常被称为k倍交叉验证。当选择了k的特定值时，它可以用来代替模型引用中的k，例如k=10成为<strong class="ig hi"> 10重交叉验证。</strong></p></blockquote><p id="12d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我通过对我安装的模型进行10重交叉验证来计算MSE和RMSE值。在这种情况下，我们计算10种不同的误差。因为我们说cv = 10，所以训练集被分成10个不同的部分。首先，用9个选定的零件建立模型，然后用剩余的1个零件估算模型。这个过程每次针对不同的零件计算10次。因此，我们通过取这10个误差的平均值得到一个测试误差。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="18cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">数据集:</strong>【https://www.kaggle.com/ashydv/advertising-dataset T2】</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="ea0c" class="jp jq hh bd jr js mm ju jv jw mn jy jz ka mo kc kd ke mp kg kh ki mq kk kl km bi translated">最后</h1><p id="0f2c" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">首先，我们在这篇博文中研究了什么是多元线性回归。然后我们讲了多元线性回归的假设。数学上，我们检查了这个算法的模型。然后，我们通过在Python中建立多元线性回归模型来计算误差值。最后，我们调整了模型，并使用k-fold交叉验证计算了验证的误差值。</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="2506" class="jp jq hh bd jr js mm ju jv jw mn jy jz ka mo kc kd ke mp kg kh ki mq kk kl km bi translated">资源</h1><ol class=""><li id="340c" class="lg lh hh ig b ih kn il ko ip mu it mv ix mw jb mx lm ln lo bi translated"><a class="ae jo" href="https://www.scribbr.com/statistics/multiple-linear-regression/" rel="noopener ugc nofollow" target="_blank">https://www . scribbr . com/statistics/多元线性回归/ </a></li><li id="9514" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb mx lm ln lo bi translated"><a class="ae jo" href="https://bookdown.org/llt1/202s21_notes/multiple-linear-regression-fundamentals.html" rel="noopener ugc nofollow" target="_blank">https://book down . org/ll t1/202 s21 _ notes/multiple-linear-regression-fundamentals . html</a></li><li id="196d" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb mx lm ln lo bi translated"><a class="ae jo" href="https://veribilimcisi.com/2017/07/14/mse-rmse-mae-mape-metrikleri-nedir/" rel="noopener ugc nofollow" target="_blank">https://veribilimcisi . com/2017/07/14/MSE-RMSE-Mae-mape-metrikleri-nedir/</a></li><li id="0946" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb mx lm ln lo bi translated"><a class="ae jo" href="https://www.datarobot.com/wiki/tuning/" rel="noopener ugc nofollow" target="_blank">https://www.datarobot.com/wiki/tuning/</a></li><li id="0272" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb mx lm ln lo bi translated"><a class="ae jo" href="https://machinelearningmastery.com/k-fold-cross-validation/" rel="noopener ugc nofollow" target="_blank">https://machinelearningmastery.com/k-fold-cross-validation/</a></li></ol></div></div>    
</body>
</html>
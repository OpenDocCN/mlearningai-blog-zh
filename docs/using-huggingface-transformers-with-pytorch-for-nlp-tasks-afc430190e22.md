# ä½¿ç”¨æ‹¥æŠ±è„¸ğŸ¤—PyTorch å˜å½¢é‡‘åˆšğŸ”¥å¯¹äº NLP ä»»åŠ¡

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/using-huggingface-transformers-with-pytorch-for-nlp-tasks-afc430190e22?source=collection_archive---------0----------------------->

![](img/9b9b79b7e36f8c961b522061e8905616.png)

Photo by [Claudio Testa](https://unsplash.com/@claudiotesta?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

æˆ‘ä»¬æ— æ³•æƒ³è±¡æ²¡æœ‰å˜å½¢é‡‘åˆšçš„ NLPï¼Œæœ€åˆï¼Œå®ƒä»¬æ˜¯ç”¨äºç¿»è¯‘ä»»åŠ¡çš„ã€‚ä½†æ˜¯ï¼Œç”±äºå®ƒä»¬çš„åŠç›‘ç£å­¦ä¹ å’Œæ³¨æ„åŠ›å±‚ï¼Œå®ƒä»¬åœ¨åˆ†ç±»ã€æ‘˜è¦å’Œæ–‡æœ¬ç”Ÿæˆç­‰å…¶ä»–ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ã€‚å˜å½¢é‡‘åˆšèƒ½å¤Ÿä»å¥å­ä¸­è·å–ä¸Šä¸‹æ–‡å«ä¹‰ï¼Œå¹¶ç»™æˆ‘ä»¬é¢„æµ‹ã€‚

è®­ç»ƒè¿™ç§é«˜æ€§èƒ½å˜å‹å™¨æ˜¯æ˜‚è´µçš„ï¼Œå¹¶ä¸”éœ€è¦é«˜è®¡ç®—èƒ½åŠ›ã€‚è¿™æ˜¯åƒ HuggingFaceï¼ŒGoogleï¼ŒFaceboook research è¿™æ ·çš„ç»„ç»‡ç«™å‡ºæ¥è®­ç»ƒè¿™äº›æ¨¡å‹çš„åœ°æ–¹ã€‚ä»–ä»¬æŠŠå®ƒä»¬å…è´¹æä¾›ç»™å…¬ä¼—ä½¿ç”¨ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚

## ä»€ä¹ˆæ˜¯åŠç›‘ç£å­¦ä¹ ï¼Ÿ

å˜å‹å™¨æ¥å—å„ç§æ•°æ®çš„è®­ç»ƒã€‚ç ”ç©¶äººå‘˜ä½¿ç”¨äº†ä»–ä»¬èƒ½æƒ³åˆ°çš„æ‰€æœ‰æ•°æ®æºæ¥è®­ç»ƒè¿™äº›æ¨¡å‹ã€‚è¿™äº›å˜å‹å™¨çš„åˆå§‹æ¶æ„æ²¡æœ‰ç›‘ç£å­¦ä¹ çš„æ ‡ç­¾ã€‚ç¼–ç å™¨å’Œè§£ç å™¨é‡‡ç”¨åŠç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ¨¡å‹è‡ªåŠ¨ç¡®å®šæ ‡ç­¾ã€‚

## å…³æ³¨å±‚æ˜¯ä»€ä¹ˆï¼Ÿ

å¯¹äº NLP ä»»åŠ¡ï¼Œå°†æ–‡æœ¬å¥å­è½¬æ¢æˆæ•°å­—è¡¨ç¤ºæ˜¯å¿…è¦çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è®°å·èµ‹äºˆå™¨ï¼Œå®ƒå°†è¯æ±‡åŠå…¶å‰åçš„å¥å­è€ƒè™‘åœ¨å†…ï¼Œä¸ºå•è¯åˆ›å»ºæ•°å­—è®°å·ã€‚

## ç”¨äºä»å˜å‹å™¨è¿›è¡Œæ¨æ–­çš„å…¬å…±ç®¡é“

![](img/ed90f7eac38b448188cc07b260f39573.png)

Huggingface åº“æä¾›äº†å˜å½¢é‡‘åˆšç±»ï¼Œåœ¨è¿™ä¸ªç±»ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä»é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ä¸­è¿›è¡Œç®€å•çš„æ¨ç†ï¼Œå¹¶ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹ã€‚

## æˆ‘ä»¬å¦‚ä½•å®‰è£…å˜å‹å™¨

```
!pip -q install transformers 
```

## è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å®ƒä»¬

è¿™ä¸€æ¬¡ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨æ¨¡å‹ 3 è¡Œä»£ç  transformers åº“æä¾›çš„ç®¡é“æ¨¡å—ï¼Œå…¶ä¸­æœ‰é¢„å®šä¹‰çš„æ–¹æ³•ï¼Œæ‚¨å¯ä»¥åœ¨çŸ­çŸ­ 3 è¡Œä»£ç ä¸­è·å¾—è¾“å‡º

```
from transformers import pipeline 
cls = pipeline("sentiment-analysis")
cls("I like the way it is and I love it")
```

![](img/f136a2f462f3cebeb69dc3b4f326b261.png)

here we are getting sentiment analysis out of the box.

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬è¿˜èƒ½åˆ©ç”¨è¿™æ¡ç®¡é“åšäº›ä»€ä¹ˆ

```
cls_b = pipeline("zero-shot-classification")
cls_b(["This is related to computers" , "I love apples"] , ["apples", "computers"])
```

![](img/5c25473b38c81b0cee9b930f65a69ed7.png)

è®©æˆ‘ä»¬ä½¿ç”¨æ‘˜è¦ç®¡é“æ¥è·å¾—æ®µè½çš„æ‘˜è¦:

```
sum = pipeline("summarization")sum("""What's the semi supervised learning? The transformers are trained on wide variety of data. Researchers have used all the data sources they can think of to train these models. Initial architecture of these transformers didn't have labels for supervised learnings. The encoder and decoders were trained with semi-supervised learning method. In this method model determines labels automatically.What's the attention layer? For NLP tasks converting textual sentences to their numerical representation is necessary. For this we are using tokenizers which takes vocabulary into account along with the sentences before and after it for creating numerical tokens for words.""")[0]["summary_text"]
```

![](img/5b4b3b22bc53557697de5d59e72bad48.png)

æœ‰å„ç§å¯ç”¨çš„é¢„å®šä¹‰ç®¡é“ï¼Œæ‚¨å¯ä»¥å€ŸåŠ©ä»¥ä¸‹å†…å®¹è¿›è¡Œæ¨æ–­:

*   `feature-extraction`(è·å–æ–‡æœ¬çš„çŸ¢é‡è¡¨ç¤º)
*   `fill-mask`
*   `ner`(å‘½åå®ä½“è¯†åˆ«)
*   `question-answering`
*   `sentiment-analysis`
*   `summarization`
*   `text-generation`
*   `translation`
*   `zero-shot-classification`

## ä½¿ç”¨è¿™äº›é¢„å…ˆæ„å»ºçš„æ¨¡å‹æ¥å®Œæˆæˆ‘ä»¬çš„ä»»åŠ¡

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›æ¨¡å‹ä½œä¸ºåŸºç¡€æ¨¡å‹æ¥ä¸ºæˆ‘ä»¬çš„ä»»åŠ¡æ„å»ºæ¨¡å‹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨ PyTorch ä¸­å®ç°å®ƒğŸ”¥

![](img/d9500854c2e2c2c71e2abb60ee5a2f96.png)

ç¬”è®°æœ¬é“¾æ¥:

[](https://colab.research.google.com/drive/1AFUqAc1uwF3xFYQUv_B2H8jOjGuhoXTh?usp=sharing) [## è°·æ­Œè”åˆå®éªŒå®¤

é“¾æ¥åˆ° colab.research.google.com](https://colab.research.google.com/drive/1AFUqAc1uwF3xFYQUv_B2H8jOjGuhoXTh?usp=sharing) 

> æ„Ÿè°¢é˜…è¯»æˆ‘çš„åšå®¢:)å…³æ³¨æ›´å¤šï¼Œ
> ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ğŸ˜ƒ

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai æäº¤å»ºè®®

### å¦‚ä½•æˆä¸º Mlearning.ai ä¸Šçš„ä½œå®¶

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
<html>
<head>
<title>Hive Tutorial 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">蜂巢教程1</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/hive-tutorial-1-1c4192389c02?source=collection_archive---------2-----------------------#2021-07-14">https://medium.com/mlearning-ai/hive-tutorial-1-1c4192389c02?source=collection_archive---------2-----------------------#2021-07-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="99a4" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated"><strong class="ak"> 1。为什么我们需要一个蜂巢？</strong></h2></div><p id="219b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在深入研究蜂巢之前，我们应该知道我们为什么需要它。所以，这一切都始于90年代初，当时脸书刚刚起步，用户数量慢慢增加。随着时间的推移，他们拥有了10亿用户，他们必须处理的数据也随之增加，每天大约有1000的数据、10万次查询和500张上传的照片。因此，这是一个巨大的数据量，我们需要处理它。<br/>所以，每个人首先想到使用的是“RDBMS ”,但是RDBMS不能处理如此大量的数据，也没有足够的能力处理这些数据。因此，我们可以使用的第二个工具是“Hadoop ”,它能够处理大量的数据，但在Hadoop上处理所有查询并不容易，因为我们需要了解MAP-REDUCE，而且在HADOOP中，处理查询需要花费大量时间。但是所有的软件开发人员都知道“SQL ”,所以脸书所做的是将HADOOP <br/>和SQL结合起来。他们提出了一个解决方案，利用HADOOP的数据处理能力和SQL接口，这是HIVE的起源。<br/>因此，Hive的创建是为了让拥有强大SQL技能的分析师能够对脸书存储在HDFS的大量数据进行查询。<br/>它是在脸书开发的，这样有SQL经验的人就能够在不实际学习MapReduce或新编程语言的情况下查询数据集。</p><h2 id="8a88" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak"> 2。什么是HIVE？</strong></h2><p id="89cd" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">Apache Hive是一个分布式容错数据仓库系统，支持大规模分析。数据仓库提供了一个中央信息存储库，可以轻松地对其进行分析，从而做出基于数据的明智决策。Hive建立在Apache Hadoop之上，这是一个开源框架，用于高效存储<br/>和处理大型数据集。因此，Hive与Hadoop紧密集成，旨在快速处理数Pb的数据。</p><h2 id="9015" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak"> 3。什么是数据仓库？</strong></h2><p id="b2b1" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">数据仓库是一种数据管理系统，旨在实现和支持分析。数据仓库仅用于执行查询和分析，通常包含大量历史数据。<br/>数据仓库集中并整合了来自多个来源的大量数据。其分析能力使组织能够从数据中获得有价值的业务见解，从而改进决策。</p><h2 id="b69c" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak"> 4。Hive和Hadoop的区别？</strong></h2><p id="745b" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">Hive是一个处理大数据的框架Hive是一个基于SQL的工具，构建于Hadoop之上，用于处理数据。Hadoop适用于所有类型的数据，无论是结构化、非结构化还是半结构化数据。Hive只能处理/查询结构化数据。Hadoop只能理解Map Reduce。它编译语言有两个主要任务:映射器和缩减器。我们可以使用Python或Java来定义任务。Hive支持用于交互和数据建模的类似SQL的查询语言，即HiveQL。</p><p id="a80f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Hadoop具有较低的抽象级别，而Hive是较高的抽象级别。<br/>因此，Hadoop效率较高，Hive效率较低，因为Map-Reduce是Hadoop不可或缺的一部分，Hive的查询首先转换为Map Reduce，然后由Hadoop处理以查询数据。<br/>Hadoop中需要定义更多行代码。在Hive中执行一个查询需要更少的代码行，这就是Hadoop需要更多开发时间而Hive需要更少开发时间的原因。</p><h1 id="9152" class="ks jt hh bd ju kt ku kv jy kw kx ky kc in kz io kf iq la ir ki it lb iu kl lc bi translated"><strong class="ak"> 5。蜂巢的主要特征</strong></h1><ol class=""><li id="1892" class="ld le hh iy b iz kn jc ko jf lf jj lg jn lh jr li lj lk ll bi translated">Hive提供了类似SQL的声明性语言，称为HiveQL，用于表达查询。</li><li id="7a34" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">各种用于处理日期、字符串等的内置函数。</li><li id="6409" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">数据的简单ETL(提取、转换和加载)。</li><li id="5be6" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">Hive engine将这些查询编译成要在Hadoop上执行的Map-Reduce作业。</li><li id="cb16" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">在Hive中，首先创建表和数据库，然后将数据加载到这些表中。</li><li id="ed15" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">Hive是一个数据仓库，专门用于管理和查询存储在表中的结构化数据。</li><li id="7d03" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">在处理结构化数据时，Map减少了像UDF这样的可用性特性，但Hive framework做到了。</li><li id="0076" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">Hive支持分区和桶概念，以便在客户端执行查询时轻松检索数据。</li><li id="7f75" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">Hive的一个新的重要组件，即用于存储模式信息的元存储。</li><li id="caab" class="ld le hh iy b iz lm jc ln jf lo jj lp jn lq jr li lj lk ll bi translated">Hive支持四种文件格式:文本文件、序列文件、ORC和RCFILE(记录列文件)。</li></ol><h2 id="99c6" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">6.蜂巢建筑</h2><p id="d0da" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">一个蜂巢由3部分组成:<br/> <em class="lr"> 1。Hive客户端<br/> 2。蜂巢服务<br/> 3。Hive存储与计算</em> <br/> <strong class="iy hi"> Hive客户端:</strong> <br/> Hive允许用各种语言编写应用，包括Java、Python、C++。它支持不同类型的客户端，例如:-<br/><strong class="iy hi"><em class="lr">节俭服务器-</em></strong><br/>它是一个跨语言服务提供商平台，请求所有那些支持节俭的<br/>编程语言。脸书的大多数服务都写得很节俭。<br/><strong class="iy hi"><em class="lr">JDBC驱动-</em></strong><br/>用于在hive和Java应用之间建立连接。JDBC驱动程序存在于类<em class="lr">org . Apache . Hadoop . hive . JDBC . Hive Driver .</em><br/><strong class="iy hi"><em class="lr">ODBC驱动程序-</em></strong><br/>它允许支持ODBC协议的应用程序连接到Hive。</p><p id="16de" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="lr"> Hive服务:</em> </strong> <br/> <strong class="iy hi"> <em class="lr">以下是Hive提供的服务:-</em></strong><br/><strong class="iy hi"><em class="lr">Hive CLI</em></strong>—Hive CLI(命令行界面)是一个shell，我们可以在其中执行Hive查询和命令。<br/><strong class="iy hi"><em class="lr">【Hive Web用户界面</em></strong>—Hive Web用户界面只是Hive CLI的一个替代方案。它为执行Hive查询和命令提供了一个基于web的GUI。<br/><strong class="iy hi"><em class="lr">Hive元存储</em> </strong> —它是一个中央存储库，存储仓库中各种表和分区的所有结构信息。<br/><strong class="iy hi"><em class="lr">Hive服务器</em> </strong> —它被称为Apache节俭服务器。它接受来自不同客户端的请求，并将其提供给配置单元驱动程序。</p><p id="a343" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="lr"> Hive驱动程序— </em> </strong>它接收来自不同来源的查询，如web UI、CLI、Thrift和JDBC/ODBC驱动程序。它将查询传递给编译器。<br/><strong class="iy hi"><em class="lr">Hive编译器</em> </strong> —编译器的目的是解析查询，并对不同的查询块和表达式执行语义分析。它将HiveQL语句转换为MapReduce作业。<br/><strong class="iy hi"><em class="lr">Hive执行引擎— </em> </strong>优化器生成map-reduce任务和HDFS任务的DAG形式的逻辑计划。最后，执行引擎按照任务的依赖性顺序执行传入的任务。<br/> <strong class="iy hi"> <em class="lr"> Hive存储和计算— </em> </strong>元存储、文件系统和作业客户端等Hive服务依次与Hive存储通信并执行以下操作。在Hive中创建的表的元数据信息存储在Hive“元存储数据库”中。所有Hive实现都需要一个元存储服务，它在其中存储元数据。它是使用关系数据库中的表实现的。表中加载的查询结果和数据将存储在HDFS的Hadoop集群中。</p><h2 id="a965" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">7<em class="ls">。配置单元</em>中的作业执行</strong></h2><p id="249e" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">Hive中的数据流表现为以下模式:<br/> 1。配置单元的接口，如命令行或Web用户界面，将查询传递给<br/>驱动程序执行。<br/> 2。驱动程序正在与编译器交互以获取计划。(此处计划是指查询<br/>执行)流程及其相关元数据信息采集<br/> 3。编译器为要执行的作业创建计划。编译器正在与Meta <br/>存储进行通信，以获取元数据请求<br/> 4。元存储将元数据信息发送回编译器<br/> 5。编译器使用建议的计划与驱动程序通信，以执行查询<br/> 6。驱动程序向执行引擎发送执行计划</p><p id="feab" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">7.执行引擎(EE)作为Hive和Hadoop之间的桥梁来处理查询。对于DFS操作。EE应该首先联系名称节点，然后再联系数据节点来获取存储在表中的值。EE将从数据节点获取所需的记录。表<br/>的实际数据只存在于数据节点中。而从名称节点，它只获取查询的元数据信息。<br/>它从与上述查询相关的数据节点收集实际数据<br/>执行引擎(EE)与配置单元中的元存储进行双向通信，以执行DDL(数据定义语言)操作。这里完成DDL操作，如创建、删除和修改表和数据库。元存储将只存储有关数据库名、表名和列名的信息。它将获取与提到的查询相关的数据。执行引擎(EE)依次与Hadoop守护进程(如名称节点、数据节点和作业跟踪器)通信，以在Hadoop文件系统上执行查询</p><p id="a3e9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">8.从驱动程序<br/> 9获取结果。将结果发送到执行引擎。一旦将结果从数据节点提取到EE，它将通过执行引擎将结果发送回与Hadoop文件系统及其守护程序保持联系的驱动程序和UI或CLI <br/> Hive。</p><h2 id="8528" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak"> 8。蜂巢的不同模式</strong></h2><p id="1c79" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">根据Hadoop中数据节点的大小，Hive可以在两种模式下运行。<br/><strong class="iy hi"><em class="lr">1。本地模式<br/>2。Map-reduce模式</em> </strong> <br/> <strong class="iy hi"> <em class="lr">何时使用本地模式:</em> </strong> <br/>【如果Hadoop安装在伪模式下，并且有一个数据节点，我们在此模式下使用Hive。如果数据大小较小，仅限于单个本地机器，我们可以使用此模式处理本地机器中的较小数据集<br/> <strong class="iy hi"> <em class="lr">何时使用Map reduce模式:</em> </strong> <br/>如果Hadoop有多个数据节点，并且数据分布在不同的节点上，我们在此模式下使用Hive。它将在大量数据集上执行，查询将以并行方式执行，通过该模型可以实现对大型数据集的更好性能处理。</p></div></div>    
</body>
</html>
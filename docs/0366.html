<html>
<head>
<title>How to prepare a speech recognition dataset using YouTube videos?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用YouTube视频准备语音识别数据集？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-prepare-a-speech-recognition-dataset-using-youtube-videos-8aeefc663e43?source=collection_archive---------1-----------------------#2021-03-30">https://medium.com/mlearning-ai/how-to-prepare-a-speech-recognition-dataset-using-youtube-videos-8aeefc663e43?source=collection_archive---------1-----------------------#2021-03-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/47815756fe4a34f0676f998a8602a7d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*anfb7ErR4qNDKJpG"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@nordwood?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">NordWood Themes</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="38af" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当使用一种不常见的语言时，训练自己的语音识别模型可能会变得特别忙碌，这正是我最近在一个需要乌尔都语语音识别器的项目中遇到的情况。</p><p id="6ad8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">经过一些研究，我发现很少有开源的乌尔都语数据集，而且质量非常低。即使我使用了它们，开源数据集也很少能满足您特定项目的需求。这就是为什么在构建人工智能系统时，针对特定领域使用自己的数据集总是一个好主意。</p><p id="6da5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但是你能在哪里找到大量你喜欢的语言的口语数据呢？就在那时，我的一个同事向我推荐了YouTube。你可以在那里找到各种视频；新闻、课程、脱口秀、博客，应有尽有。但将这些视频转换成训练数据是真正的任务，因为大多数YouTube视频都有背景音乐或大量噪音。</p><h1 id="24de" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">我们在做什么？</h1><p id="1baf" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在这篇文章中，我将带您了解准备YouTube视频的过程，这些视频将用于训练您的ASR。为此，我使用了Python 3和一些工具和库。我在整个过程中使用了<a class="ae it" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>,因为它使设置变得非常快速和容易。正如你已经猜到的，我将为乌尔都语准备一个数据集，但是你也可以使用本教程为任何语言准备一个数据集。你所需要的只是一个YouTube链接列表！</p><h1 id="b6e6" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">我们如何做到这一点？</h1><p id="2fed" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">首先，我们需要安装我所说的工具和库。我将在接下来的小节中讨论对这些库的需求。让我们使用pip安装它们:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="1b18" class="le jt hh la b fi lf lg l lh li">!pip install spleeter<br/>!pip install youtube_dl<br/>!pip install pydub</span></pre><p id="6e5d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您需要为整个程序执行以下导入操作:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="c424" class="le jt hh la b fi lf lg l lh li">import spleeter<br/>from __future__ import unicode_literals<br/>import youtube_dl<br/>from pydub import AudioSegment<br/>from pydub.silence import split_on_silence</span></pre><p id="efb8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">安装并导入依赖项后，我们需要对列表中的每个视频执行以下步骤:</p><ol class=""><li id="f18c" class="lj lk hh iw b ix iy jb jc jf ll jj lm jn ln jr lo lp lq lr bi translated">提取并下载音频</li><li id="1f6e" class="lj lk hh iw b ix ls jb lt jf lu jj lv jn lw jr lo lp lq lr bi translated">将语音从音频中分离出来</li><li id="650e" class="lj lk hh iw b ix ls jb lt jf lu jj lv jn lw jr lo lp lq lr bi translated">调整采样率、样本宽度和通道</li><li id="3a6a" class="lj lk hh iw b ix ls jb lt jf lu jj lv jn lw jr lo lp lq lr bi translated">分成更小的块</li><li id="431b" class="lj lk hh iw b ix ls jb lt jf lu jj lv jn lw jr lo lp lq lr bi translated">转录音频</li></ol><p id="8f5e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以让我们开始吧。</p><h2 id="dd61" class="le jt hh bd ju lx ly lz jy ma mb mc kc jf md me kg jj mf mg kk jn mh mi ko mj bi translated">提取并下载音频</h2><p id="246c" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">我们将使用<a class="ae it" href="https://github.com/ytdl-org/youtube-dl" rel="noopener ugc nofollow" target="_blank"> youtube-dl </a>从给定的youtube链接下载音频。它是一个从YouTube和其他视频平台下载视频的命令行程序。下面是一个简单的代码，它将音频下载为“audio.wav”。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="a867" class="le jt hh la b fi lf lg l lh li">ydl_opts = {<br/>    "format": "bestaudio/best", <br/>    "audio-format": "wav",<br/>    "outtmpl": "audio.wav",        <br/>}<br/>try:<br/>    with youtube_dl.YoutubeDL(ydl_opts) as ydl:<br/>        ydl.download([link])<br/>except Exception as e:<br/>    print("Video cannot be downloaded. Exception:/n{}".format(e))</span></pre><p id="5403" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对象<code class="du mk ml mm la b">ydl_opts</code>用于根据自己的需求定制下载。在这里，我们告诉youtube_dl下载WAV格式的最佳可用质量音频，并将其保存为“audio.wav”。</p><p id="d717" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于某些视频在您所在的地区不可下载，或者下载音频可能会因任何其他原因而失败，因此我们添加了try-except块。您可以将第8行中的“link”替换为您希望在数据中使用的任何YouTube视频链接。</p><h2 id="4e8e" class="le jt hh bd ju lx ly lz jy ma mb mc kc jf md me kg jj mf mg kk jn mh mi ko mj bi translated">将语音从音频中分离出来</h2><p id="c3cd" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">这是整个过程中最重要的一步，因为它将决定音频数据的质量，从而决定我们使用它训练的ASR的质量。有很多工具可以用来分离音频中的人声，但我发现的最好的开源工具是Deezer的<a class="ae it" href="https://research.deezer.com/projects/spleeter.html" rel="noopener ugc nofollow" target="_blank">Spleeter</a>。</p><p id="62fe" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Spleeter是一个用Python编写的源分离库，它提供了不同的预训练模型来分离歌曲中的音轨。您也可以使用库来训练您自己的模型。我们将使用Spleeter的2项模型来将声音从音频中的所有其他声音中分离出来。这将允许我们从视频中只提取语音数据来满足我们的数据需求。</p><p id="ca1f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为此使用了一个单行命令:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="4081" class="le jt hh la b fi lf lg l lh li">!spleeter separate -p spleeter:2stems -o output "/content/audio.wav"</span></pre><p id="cafa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这将在“/output/audio”文件夹中为您提供两个名为“vocals.wav”和“con伴奏. wav”的WAV文件。很明显，我们将使用vocals.wav。</p><h2 id="2aa0" class="le jt hh bd ju lx ly lz jy ma mb mc kc jf md me kg jj mf mg kk jn mh mi ko mj bi translated">调整采样率、样本宽度和通道</h2><p id="d91b" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">语音识别数据集中的音频具有以下特征是一个标准:</p><p id="784b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">采样率= 16000 kHz <br/>样本宽度=每个样本16位<br/>通道=单声道(1)</p><p id="d158" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将使用<a class="ae it" href="https://github.com/jiaaro/pydub" rel="noopener ugc nofollow" target="_blank"> Pydub </a>库来调整这些参数，并用修改后的文件替换原来的音频文件。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="ff8d" class="le jt hh la b fi lf lg l lh li">sound = AudioSegment.from_file("/content/output/audio/vocals.wav")<br/>sound = sound.set_frame_rate(16000)<br/>sound = sound.set_channels(1)<br/>sound = sound.set_sample_width(2)<br/>sound.export("/content/output/audio/vocals.wav", format ="wav")</span></pre><h2 id="a253" class="le jt hh bd ju lx ly lz jy ma mb mc kc jf md me kg jj mf mg kk jn mh mi ko mj bi translated">分成更小的块</h2><p id="2fe7" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">与大多数开源数据集一样，在语音识别数据集中拥有长度为15到30秒的音频是一个很好的实践。我们可以将音频分成相等的块，但我发现对于YouTube视频来说，更好的方法是在静音上分割。这样，我们就不会在音频的开头或结尾出现不完整的单词。</p><p id="35d5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将再次使用Pydub来分割无声的音频。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="d7ad" class="le jt hh la b fi lf lg l lh li">sound_file = AudioSegment.from_wav("/content/output/audio/vocals.wav")<br/>audio_chunks = split_on_silence(sound_file, min_silence_len=500, silence_thresh=-50)<br/>for chunk_num, chunk in enumerate(audio_chunks):<br/>    out_file = "{chunk_num}.wav".format(i)<br/>    chunk.export(out_file, format="wav")</span></pre><p id="70e2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上面的代码读取“vocals.wav ”,并使用函数<code class="du mk ml mm la b">pydub.silence.split_on_silence</code>来分割静音上的音频。for循环导出所有的块，并将它们命名为<code class="du mk ml mm la b">0.wav</code>、<code class="du mk ml mm la b">1.wav</code>、<code class="du mk ml mm la b">2.wav</code>等等。</p><p id="92ff" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以通过调整函数的参数来控制分裂。<code class="du mk ml mm la b">min_silence_len</code>定义无声补丁需要多长时间(以毫秒为单位)才能被考虑拆分，而<code class="du mk ml mm la b">silence_thresh</code>定义无声补丁的最大响度限制(以dBFS为单位),超过该限制将不会被考虑拆分。我发现半秒(500毫秒)的最小静音长度对大多数音频来说都很好，但是你应该根据你的具体音频来调整静音阈值，以获得最佳效果。</p><h2 id="2317" class="le jt hh bd ju lx ly lz jy ma mb mc kc jf md me kg jj mf mg kk jn mh mi ko mj bi translated">转录音频</h2><p id="de57" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">既然我们已经准备好了音频，是时候生成相应的文本来完成我们的数据集了。为了生成高质量的数据，您必须手动完成这项工作。难过，我知道！😢</p><p id="9b2c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">尽管如此，我还是有一些建议可以让这个过程变得简单一些:</p><ol class=""><li id="73fc" class="lj lk hh iw b ix iy jb jc jf ll jj lm jn ln jr lo lp lq lr bi translated">如果你自己做转录，使用语音到文本的应用程序是一个好主意，如果有的话。例如，<a class="ae it" href="https://support.google.com/docs/answer/4492226?hl=en#zippy=%2Clanguages-that-work-with-voice-typing" rel="noopener ugc nofollow" target="_blank">谷歌语音打字</a>支持多种语言，可以很容易地在谷歌文档上使用。您可以对着麦克风说出句子，然后将文本粘贴到您需要的地方。它仍然需要一些完善的编辑，但这种技术可以大大减少手动输入文本所需的时间。</li><li id="e4bd" class="lj lk hh iw b ix ls jb lt jf lu jj lv jn lw jr lo lp lq lr bi translated">但是，如果您没有预算限制，您可以通过使用语音到文本API并将文本直接保存为您喜欢的格式，使这个过程自动化，不那么忙乱。同样，<a class="ae it" href="https://cloud.google.com/speech-to-text" rel="noopener ugc nofollow" target="_blank"> Google Speech </a>拥有大量受支持的语言、丰富的文档和现收现付的定价计划，可以帮助您完成这项任务。在你使用API生成了TXT文件或任何你需要的文本格式后，你可以听音频并自己纠正错误。</li></ol><p id="10b4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正如您所看到的，这些技术可以显著减少工作量，但您仍然需要进行编辑来产生高质量的数据集，然后可以使用该数据集来训练高质量的语音识别系统。</p><h1 id="21f7" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">链接列表的自动化</h1><p id="9f51" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">必须对您在开始时准备的列表中的所有YouTube视频执行步骤1至4。你可以在这里找到带有完整代码的<a class="ae it" href="https://github.com/TehreemFarooqi/Preparing-a-speech-recognition-dataset-using-YouTube-videos" rel="noopener ugc nofollow" target="_blank"> Colab笔记本，它可以自动完成上面讨论的过程。</a></p><p id="2ff1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">它将一个TXT文件作为<strong class="iw hi">输入</strong>，该文件中的链接由一个新行分隔开(意味着每个链接在一个单独的行上)。</p><p id="9d1c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">笔记本<strong class="iw hi">为<code class="du mk ml mm la b">link number 1, link number 2, link number 3…</code>输出名为<code class="du mk ml mm la b">1, 2, 3…</code>的</strong>文件夹，在这些文件夹中，组块被命名为<code class="du mk ml mm la b">{link_number}_{chunk_number}</code>。所以文件夹<code class="du mk ml mm la b">1</code>会有文件<code class="du mk ml mm la b">1_0.wav</code>、<code class="du mk ml mm la b">1_1.wav</code>、<code class="du mk ml mm la b">1_2.wav</code>等等。</p><p id="8125" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我建议你<a class="ae it" href="https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA" rel="noopener ugc nofollow" target="_blank">安装Google Drive </a>并将输出直接保存在你的驱动器中，这样可以节省从Colab下载文件的时间。如果Colab由于某种原因断开连接，它也将帮助您保存您的进度。</p></div><div class="ab cl mn mo go mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ha hb hc hd he"><p id="3480" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是一个关于如何利用YouTube视频为任何ASR或相关系统准备语音识别数据集的详细教程。如果这对你有所帮助，请为我鼓掌！</p><p id="e410" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于任何与数据科学或机器学习相关的问题或疑问，请随时通过我的电子邮件联系我:【teefarooqi@gmail.com】T2或<a class="ae it" href="https://www.linkedin.com/in/tehreemfarooqi/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>。</p></div></div>    
</body>
</html>
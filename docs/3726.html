<html>
<head>
<title>Build An Automated Labeling system</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立一个自动化的标签系统</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/build-an-automated-labeling-system-f960419e458b?source=collection_archive---------5-----------------------#2022-10-13">https://medium.com/mlearning-ai/build-an-automated-labeling-system-f960419e458b?source=collection_archive---------5-----------------------#2022-10-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="9c04" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">这篇文章介绍了我如何建立一个标签系统的过程，从理论到部署。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/93ae86eb57e398962a489d790c64e1e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3jDNcRcyJaNYmHN82CSsg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">image from undraw.co</figcaption></figure><h1 id="34c0" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">让我们理解为什么我们需要标签</h1><p id="7513" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">人工智能的最新发展，包括计算机视觉、自然语言处理、预测分析、自主系统和广泛的应用，都是由机器学习驱动的。我们需要数据，所以这些算法可以从中学习，从而可以很好地推广。大多数过渡算法需要标签数据才能工作。当谈到深度学习时，与传统的机器学习算法相比，需要的数据量是巨大的，特别是在深度学习神经网络中，以建立一个达到适当精度水平的模型。因此，不言而喻，为了得到准确的机器学习模型，机器学习数据必须是干净、准确、完整和标记良好的。尽管总是出现垃圾进垃圾出的情况，但对于机器学习数据来说尤其如此。大约80%的AI/ML项目时间花在收集、组织和标记计算上。</p><blockquote class="la lb lc"><p id="e576" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">我们可以获得大量未标记的数据，但是手动标记是昂贵的</p></blockquote><p id="290c" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我希望现在你已经很好地理解了标记数据对于我们机器学习项目的重要性。</p><h1 id="85d0" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">我们最终会拥有什么！</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lm"><img src="../Images/4471569d4848e322daa580ec4f7a20ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*upOH0fH2DIwuK_mf.gif"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Source <a class="ae ln" href="https://ashishlotake-active-labelling-system-project-app-14t6bq.streamlitapp.com/" rel="noopener ugc nofollow" target="_blank">https://ashishlotake-active-labelling-system-project-app-14t6bq.streamlitapp.com/</a></figcaption></figure><p id="ba7c" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><a class="ae ln" href="https://ashishlotake-active-labelling-system-project-app-14t6bq.streamlitapp.com/" rel="noopener ugc nofollow" target="_blank"> Web App </a>、<a class="ae ln" href="https://hub.docker.com/r/ashishlotake/active-labelling-system" rel="noopener ugc nofollow" target="_blank"> Docker Image </a>和所有IPYNB <a class="ae ln" href="https://www.ashishlotake.com/blog/active-labelling-system#all-jupyter-notebooks" rel="noopener ugc nofollow" target="_blank"> Colab链接</a></p><h1 id="801a" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">我们前进需要什么</h1><p id="a4c0" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">具有讽刺意味的是，我们需要带标签的数据，原因很简单，模型在标记任何东西之前应该知道标签是什么，然后它还应该知道哪个标签对应于哪个图像。</p><blockquote class="la lb lc"><p id="d87a" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">这就像增加我们需要的钱一样</p></blockquote><ul class=""><li id="d298" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz lt lu lv lw bi translated">我们将使用深度学习，所以GPU是必须的，使用谷歌Colab。</li></ul><p id="6a33" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">如果你有这两样东西，你就可以建立你的标签系统</p><h1 id="9dc2" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">手头的数据集</h1><p id="c414" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">我将使用Caltech101数据集，但您也可以使用任何其他数据集。让我们简单回顾一下Caltech101数据集。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lx"><img src="../Images/a26202a39d8847a2d4665a2fb19669c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNRRtJpijqSP3_VQX9hEEg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="df09" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">它由9146幅图像组成，不均匀地分布在101个不同的物体类别和一个背景类别之间。根据官方网站，每个类别大约有40到800幅图像，此外，大多数类别在数据集中有大约50幅图像。当试图在深度神经网络训练中实现高精度时，每个类别的这种变化的图像可能是一个真正的问题。每个图像的大小大约为300 x 200像素。图像的格式是RGB，这意味着我们有3个颜色通道。</p><p id="1247" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">现在我们来看看班级分布</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ly"><img src="../Images/4408ba468dacae03d8208231bf072871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDPxaZCjeV25cMLYBCfoug.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lz ma l"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">from giphy.com</figcaption></figure><p id="1750" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们可以看到，飞机和摩托车类别的图像数量最多，约为800张，而对于大多数标签，图像数量最少的可能只有40张。对于这样一个不平衡的数据集，如果我们决定从头开始训练，将很难从网络中获得良好的性能。</p><h1 id="971a" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">让我们了解一下高层部署</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mb"><img src="../Images/c1bd480731e5c10adc82a7e9ef4a15b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GoayCwRiuITxsM7-Sv-PZQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="3505" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我觉得上面的布局不言自明。不过，我还是要用几行字来解释一下</p><ul class=""><li id="92df" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz lt lu lv lw bi translated">使用分层抽样将数据集分为三个部分</li><li id="f749" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">训练CNN，然后评估看不见的数据</li><li id="dd7a" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">选择最佳型号</li><li id="28b9" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">创建一个stremlit web应用程序</li><li id="2bb5" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">将stremlit包在容器中</li><li id="6ddd" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">在云上部署容器</li><li id="dcd3" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">Wola！你的模型现在是全球性的，</li><li id="8a9f" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">如果用户想要训练模型，则获取新数据和一部分旧数据，将它们组合起来并重新训练。</li><li id="f2bf" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">然后，用户可以下载带标签的数据。</li></ul><h1 id="fdb1" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">让我们开始真正的工作吧</h1><p id="ec94" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">我们会弄脏自己的手，通过创建一个基线模型并从头训练它，我知道我告诉如果我们从头训练模型获得良好的性能将是困难的，但这不会伤害我们，我将从头实现Alexnet，就像架构一样，所以如果我们没有达到满意的结果，我们仍然可以说'我从starch实现了Alexnet！</p><p id="fcbe" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">顺便说一下，在2012年的ImageNet ILSVRC挑战赛中，正是在这场比赛中，AlexNet展示了深度卷积神经网络可以用于解决图像分类，这是一个新时代的开始。</p><blockquote class="la lb lc"><p id="f8e2" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">当你看到大多数先进的深度学习模型时，它们都是通过实验研究得出的，其中大多数甚至没有像传统的机器学习算法那样有适当的数学或统计解释</p></blockquote><h2 id="4f27" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">AlexNet</h2><p id="775a" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">在从头开始创建Alexnet之前，让我们对卷积神经网络(CNN)有一个高度的概述，这样你就知道在什么之上发生了什么。</p><p id="3e83" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">卷积神经网络是借助于堆叠在彼此之上的不同层来形成的，以执行图像分类任务。CNN的架构包含不同的层。整个网络本身分为两部分:<strong class="kg hi">卷积基</strong>和<strong class="kg hi">分类器</strong>。在卷积库中提取特征，在分类器中进行分类。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mv"><img src="../Images/9b979cfc988368fa2d9b9654f70a9f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDVZWk5paDz0v8kL5ZhysQ.png"/></div></div></figure><h2 id="8341" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">卷积基中的层:-</h2><ul class=""><li id="83d9" class="lo lp hh kg b kh ki kk kl kn mw kr mx kv my kz lt lu lv lw bi translated">输入图层-该输入图层接受原始图像，并将其转发到其他图层以提取要素。</li><li id="105c" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">卷积层-在这一层中，许多过滤器被应用于图像，用于从图像中寻找特征。</li><li id="f64b" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">池层-该层捕获大图像并缩小它们，并缩小参数以保存重要信息。它保留了每个窗口的最大值。</li></ul><h2 id="d767" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">分类器中的层:-</h2><ul class=""><li id="0c0f" class="lo lp hh kg b kh ki kk kl kn mw kr mx kv my kz lt lu lv lw bi translated">完全连接层-该层采用高级过滤图像，并将其转换为带有的标签。</li><li id="f650" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">输出图层-该图层为每个类提供小数概率。这些十进制概率介于0和1之间。</li></ul><p id="06ed" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">这是你能建立的最简单的CNN。</p><p id="b47e" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">现在你知道了CNN的基本知识，让我们来看看AlexNet的结构</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mz"><img src="../Images/1f1f072e9a75a602ac4eac8a377a57a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FnkbxNJrJTTfAgFNL8isXQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image from <br/>Advanced Deep Learning with Python by Ivan Vasilev</figcaption></figure><p id="c048" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">这是一个很大的进步，所以让我们简要地回顾一下每一个独特的层</p><p id="9ecd" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">卷积层</em> :-数学术语“卷积”是指两组元素的点积相乘。卷积层的过滤器/内核和一系列图像数据受到深度学习中卷积运算的影响。因此，卷积层只是一个包含发生在滤波器和由卷积神经网络处理的图像之间的卷积运算的层。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es na"><img src="../Images/cc3f87ecb1279d807a80d56f96d2dcba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-ns9EIDKTpeyeHIcruE4A.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image from Nvidia.com</figcaption></figure><p id="2916" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld"> ReLU激活功能</em>:修改神经元价值输出的特定激活过程。ReLU对来自神经元的值施加的变换由公式y=max(0，x)表示。来自神经元的任何负值都被ReLU激活函数箝位到0，而正值保持不变。在神经网络中，这种数学转换的结果被用作下一层的输入和当前层的输出。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nb"><img src="../Images/7f8a0cf7473aa8fcd22bc7177ec6fd76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*wd1kiULGfjLzexwj3de1xQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Hossam H. Sultan from researchgate</figcaption></figure><p id="d35d" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">最大汇集</em> :-使用最大汇集，输出是包含在子采样层内的单元感受域内的像素的最高像素值。下面的max-pooling操作通过用一个2x2窗口滑过输入数据来产生内核感受域内像素的平均值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nc"><img src="../Images/db3e9c1369fce72878d2b83e71fc3a44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*feJOXYgHeWcM_O3n.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image from wikimedia</figcaption></figure><p id="427d" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">批量标准化</em> :-通过增加一层对来自前一层的输入进行操作，批量标准化是一种减少神经网络内不稳定梯度影响的技术。在缩放和移位操作转换输入值之前，这些操作首先对输入值进行标准化和规范化。</p><p id="0c85" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">丢失</em> :-丢失技术随机减少神经网络中互连神经元的数量。在每个训练步骤中，每个神经元都有机会从连接神经元的整理贡献中被丢弃。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nd"><img src="../Images/87f4815fe4543b65e17b69f6c6d8184f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/0*2u9rvsjtl5yWGr32.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Imad Dabbura</figcaption></figure><p id="ade8" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">展平图层</em> :-获取一个输入图形，并将输入图像数据展平成一维数组。</p><p id="02a1" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">展平图层</em> :-获取一个输入图形，并将输入图像数据展平成一维数组。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ne"><img src="../Images/c9881ee5a09759599a70fa8fdb5cae35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yX6sTIgp4t1A6k6p.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image from SuperDataScience</figcaption></figure><p id="e891" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">密集层</em> :-密集层中嵌入了任意数量的单元/神经元。每个神经元都是一个感知器。</p><p id="66f3" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld"> Softmax激活函数</em>:一种特定类型的激活函数，用于确定包含在输入向量中的一组数字的概率分布。softmax激活函数的结果是一个向量，该向量的一组值表示类或事件将发生的可能性。向量的值总计为1。</p><h1 id="1daf" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">让我们从头开始编写AlexNet</h1><p id="fd10" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">请记住这个架构:-</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mv"><img src="../Images/58a1265ef2075c2e68814c5d134121fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*saeb9-ZDjHR8YGxb.png"/></div></div></figure><p id="60cb" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">下载数据并从zip文件中提取</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><p id="4409" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">分层将数据分为训练、val和测试文件夹</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><p id="ff4a" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">加载数据</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><p id="e310" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">从头开始建模</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><p id="9e66" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">培训模式</p><pre class="ix iy iz ja fd ng nh ni nj aw nk bi"><span id="94b0" class="mh jn hh nh b fi nl nm l nn no">history = alexnet_scratch.fit(<br/>  train_dataset,<br/>  epochs=30,<br/>  validation_data=validation_dataset,<br/>  )</span></pre><h1 id="ac83" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">从零开始训练的表现</h1><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><pre class="ix iy iz ja fd ng nh ni nj aw nk bi"><span id="bdf0" class="mh jn hh nh b fi nl nm l nn no">plot_performance(history)</span></pre><h1 id="9f78" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">从零开始训练的表现</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/e4a94f86162df05b8d721247d2dae710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u5pMk2M8PIZ3gV5e.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="2c1d" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">很明显，这个模型过于符合我们的训练数据。</p><h1 id="965f" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">超参数调谐</h1><p id="1bf5" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">深度学习非常依赖于超参数优化。其原因是神经网络极难配置，并且需要设置大量参数。此外，单个模型的训练可能非常慢。我们将尝试为CNN优化一些重要的超参数</p><ol class=""><li id="eff5" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz nq lu lv lw bi translated">优化算法:-优化器是改变神经网络的权重和学习速率以最小化损失的技术。</li><li id="d4fc" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">学习率:-学习率控制在每批结束时更新多少重量。</li><li id="30b6" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">动量:-动量控制学习率的先前更新对当前权重更新的影响程度</li></ol><p id="ba3c" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我试用了三个优化器RMSProp，Adam，和SGD在不同的学习速率下(0.001，0.005，0.01，0.05，0.1)，使用SGD在0.01和0.05的学习速率下得到最好的结果。</p><h2 id="f891" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">优化器和学习率</h2><p id="fab9" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">在不同学习速率下使用SGD作为优化器的结果。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/b4aa0653f1b75cad35f22cad64b116b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Y1D4I9oONNyFV-zh.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nr"><img src="../Images/63d9bfac657f9b92ad1f0b8df7b87cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EXHA_TVyjcnBNi0K.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="9450" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">学习率为0.01和0.05时的结果看起来很有希望，让我们探索更多。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/d8af8e219862d7cbeb4a139df93a860b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6K6QTBzLYgy2Fsu1m8kXIw.png"/></div></div></figure><p id="8101" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">通过查看图和表，与0.01相比，0.05的学习率看起来非常好，但是我们需要理解，我们需要我们的模型在新的/看不见的数据上表现良好，即使我们在训练数据上没有完美的99–100%的分数。现在，如果我们关注测试数据的损失，0.01的学习率看起来不错。</p><blockquote class="la lb lc"><p id="2e92" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">这些结果在每次运行期间会有所不同，因为我们使用的是SGD，它在本质上是随机的。</p></blockquote><p id="be60" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们可以说，在学习率为0.05和0.01时，两个结果非常相似，这里的差异是由于SGD的随机性质。</p><h2 id="6add" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">动力</h2><p id="237f" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">现在我们将在各种动量(0，0.3，0.6，0.8，0.9)下试用这个配置(优化器=sgd，学习率=0.01)。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/21ab53aa67f3cf93d13a162b7cc2cea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iCuTO89zkvv296Yc.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nt"><img src="../Images/f70bb26554bb562f8c8871310687808f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WB8zOCvJ0phHM8LN.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="ec33" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">让我们把注意力集中在三大动力上</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/d9bc238f390306628c3ed77f081dd089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QsYpNSZSDbMPOTH3ocWtsg.png"/></div></div></figure><p id="1799" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">动量=0.3似乎是更好的选择，因为与动量= 0时相比，它已经在少得多的时期内取得了良好的结果，并且动量= 0.3的模型与其他学习速率相比似乎具有良好的泛化能力。</p><h2 id="57f7" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">到目前为止取得了什么成就</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/e8bcd263ebda6b13a6cdfaf94a5cbdb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TCwY2xq4cNoFGW9e2xwXBA.png"/></div></div></figure><p id="f5f9" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们可以看到，我们能够将模型的验证和测试精度提高2%，仅仅是通过调整一些超参数，或者可能是由于SGD的随机性质。</p><p id="ef11" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们在上面看到的各种图表表明，用如此少的样本从头开始训练一个网络，除了能够很好地概括看不见的数据之外，不会产生一个从训练集中很好地学习的好模型。</p><blockquote class="la lb lc"><p id="4549" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">总之，在小数据集的情况下，从头开始训练网络是一项困难且耗时的任务。</p></blockquote><h1 id="0aef" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">数据扩充</h1><p id="1bbc" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">影像数据扩充是一种通过生成数据集影像的变更版本来人为增加训练数据集大小的方法。这是通过将特定于领域的技术应用于来自训练数据的示例来实现的，这些示例创建新的不同的训练示例。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><p id="6160" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">将使用以下增强功能:</p><ul class=""><li id="1e39" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz lt lu lv lw bi translated">水平翻转增强</li><li id="46c4" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">随机旋转增强</li><li id="771e" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">随机变焦增强</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nu"><img src="../Images/ea01164c156697dda0274010a8f8c6a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/0*dRHee2XauvnUEG1F.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="677a" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">应用数据数据扩充后的结果:-</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/7dae53e90b8c41402e38f21ddc100824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bh_UvNqKHVNxYCXN.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/2f2ea8e90a7d0bc195d85e8d7bb8f0cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-4CCYn_G3VF16-7y.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="1d50" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">看起来应用数据扩充似乎并没有改善我们的模型架构和数据集的模型泛化。</p><p id="1ffc" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">从这里我们可以去很多地方:</p><ol class=""><li id="58a7" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz nq lu lv lw bi translated">过采样和欠采样</li><li id="81a7" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">添加新数据</li><li id="d6ee" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">迁移学习</li></ol><blockquote class="la lb lc"><p id="0b69" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">剧透-&gt;只有转移学习有效</p></blockquote><p id="0ed8" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">如果你还想了解我是如何进行过采样和欠采样的，以及如何添加新的数据点，请查看<a class="ae ln" href="https://www.ashishlotake.com/blog/active-labelling-system#all-jupyter-notebooks" rel="noopener ugc nofollow" target="_blank"> Jupyter notebook </a> notebook，<a class="ae ln" href="https://www.kaggle.com/datasets/ashishlotake/extendedcaltech101" rel="noopener ugc nofollow" target="_blank">扩展数据集托管在Kaggle </a>上。</p><h1 id="5815" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">迁移学习</h1><p id="3f18" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">在小图像数据集上进行深度学习时，一种常见且高效的方法是使用预训练模型。</p><p id="45a1" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">神经网络通常需要大量数据才能有效运行，在这种情况下用于分类。为了解决从零开始训练中的低精度问题，可以使用迁移学习，该迁移学习使用来自大数据集上的预训练模型的权重，如果该原始数据集足够大并且足够通用，则由预训练模型学习的特征的空间层级可以有效地充当视觉世界的通用模型，因此，其特征可以证明对许多不同的计算机视觉问题有用， 尽管这些新问题可能涉及与原始任务完全不同的类，但它被用作在我们的小数据集(即加州理工学院-101)上训练的起点。</p><p id="6958" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">使用预训练模型有两种方式:特征提取和微调。我们将使用特征提取。用于图像分类的内容包括两个部分:一系列卷积和池层，最后是密集连接的分类器，第一部分称为模型的卷积基。</p><p id="4254" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">特征提取包括采用先前训练的网络的卷积基，通过它运行新数据，并在输出之上训练新的分类器，因为卷积基学习的表示可能更通用，因此更可重用。而由分类器学习的表示将必然特定于模型在其上被训练的类别集。</p><p id="fe5f" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated"><em class="ld">这是如何使用ResNet50进行迁移学习的示例，只需根据您选择的模型和conv库改变预处理函数。</em></p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ma l"/></div></figure><p id="d4f2" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">在将图像馈送到网络之前，我们需要以针对预训练模型对图像进行预处理的相同方式对它们进行预处理。</p><p id="45c9" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们将测试3种型号:</p><ul class=""><li id="6d6b" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz lt lu lv lw bi translated">MobileNet</li><li id="1475" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">ResNet50</li><li id="21df" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">InceptionV3</li></ul><p id="d2bc" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">对于我的场景，MobileNet的性能似乎比基线模型差。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/bf439e39d94198473282a140aff8888e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*13cLLenvdHwIpZw5.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="ade1" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">Resnet50和Inception都已经实现了大于90%训练和赋值准确度。让我们关注损失。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nt"><img src="../Images/e28e1f44416fbd5bb56ca01cc680456e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Di3wZR_SJ8NGEmCa.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/47dc84419219fd52fd9c71dde681d355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2CaG9iZH2HmgEWKttQvm6Q.png"/></div></div></figure><p id="1e74" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">t看起来Resnet在有和没有数据增强的情况下都表现良好，模型的大小大约为100 MB</p><h1 id="80c2" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">最终确定模型</h1><p id="7de8" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">在进行了从超参数调整到添加新数据的各种实验后，我们决定使用keras的ResNet50，因为结果非常好，在测试和验证集上都比我们的基线模型提高了约20%。</p><p id="0022" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">如前所述，我们需要根据我们选择的预训练模型预处理图像，让我们看看来自resnet50卷积库的预处理图像:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nv"><img src="../Images/1d0dbae7bf2bab22d47528d25d39fba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0zBiESkpL7-CRsRr.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><h1 id="3ca8" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">再训练</h1><p id="825e" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">为了重新训练模型，我们将加载模型，并在离开的地方继续模型训练，而不进行编译，因此分类器学习的所有权重将从先前的模型复制，并且模型将从离开的地方开始学习。</p><p id="560b" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们将从原始数据集中复制一些数据点，然后将新图像复制到原始数据集中，我们将通过结合新旧图像来开始重新训练。</p><h1 id="3035" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">模型可解释性</h1><p id="60ac" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">在开发计算机视觉应用程序时，最基本的问题之一是可解释性:当你看到的只是一个扳手时，为什么你的分类器会认为一个特定的图像包含一把吉他？</p><p id="7988" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">深度学习模型经常被称为“黑盒”，因为它们学习难以提取和以人类可读格式呈现的表示。虽然对于一些深度学习模型来说是这样，但是对于convnets来说就不是这样了。convnets所学的表述是高度可解释的。</p><p id="641c" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们将着重于在图像中可视化类激活的热图。这有助于理解给定图像的哪些部分导致convnet做出最终分类决定。这有助于“调试”convnet的决策过程，尤其是在分类错误的情况下。</p><p id="8928" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">类激活图(CAM)可视化是一个广泛的方法家族，包括在输入图像上创建类激活的热图。类别激活热图是与特定输出类别相关联的分数的2D网格，针对任何输入图像中的每个位置进行计算，指示每个位置对于所考虑的类别的重要性。</p><p id="36ee" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">Grad-CAM包括获取卷积层的输出特征图，给出输入图像，并通过与通道相关的类的梯度对该特征图中的每个通道进行加权。直观地说，理解这种技巧的一种方法是想象您正在用“每个通道对类的重要性”来加权“输入图像激活不同通道的强烈程度”的空间映射，从而得到“输入图像激活类的强烈程度”的空间映射</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nw"><img src="../Images/e5bee061f4844f298d7b9aac672d822d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/0*elshUrEDMgV-d2xa.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="a223" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">通过查看上面的图像，我们可以说，在模型检测到附近有一个人和车轮后，模型以99.64%的置信度判定这是一辆轮椅</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nx"><img src="../Images/2b66c4609f4715b830233c60b3f3845e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KLLYjT4Qj1grV0BS.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><h1 id="aead" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">建筑应用</h1><p id="e48b" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">该模型将用于现实世界的场景，从用户那里获取连续的原始输入，然后给他们带标签的数据作为输出。</p><p id="fb6f" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">在这一步中，使用<a class="ae ln" href="https://www.ashishlotake.com/blog/streamlit.io" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>开发了一个web应用程序。它为用户提供了一个上传多张图片的前端。<a class="ae ln" href="https://www.ashishlotake.com/blog/streamlit.io" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>是一个开源python框架，用于构建机器学习和数据科学的web应用。它只需在几分钟内将简单的Python脚本转换成实用的、交互式的、可共享的web应用程序。</p><p id="4b72" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">使用<a class="ae ln" href="https://www.ashishlotake.com/blog/streamlit.io" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>构建应用程序的详细步骤将在后面的文章中介绍。</p><p id="9d61" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">该文件的代码可以在<a class="ae ln" href="https://github.com/ashishlotake/active-labelling-system-project/blob/main/app.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="95e3" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">归档</h1><p id="a1a9" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">Dockerizing是使用Docker容器打包、部署和运行应用程序的过程。Docker是一个开源工具，它将您的应用程序作为一个包含所有必要功能的包来提供。Docker允许您将应用程序运行所需的一切(如库)打包，并作为一个单独的包——一个容器来运输。容器由指定其确切内容的图像组成。</p><p id="6f54" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">创建docker而不是直接部署的原因:-</p><ul class=""><li id="2896" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz lt lu lv lw bi translated">易于使用:- Docker简化了我们部署应用程序的方式。您不将软件作为源代码分发，而是发送磁盘一部分的二进制映像。</li><li id="19e0" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">快速:- Docker容器只是运行在内核上的沙盒环境。您可以在几秒钟内创建并运行容器</li><li id="f247" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">能够创建一个可复制的环境:-将所有东西包装到容器中意味着您构建的应用程序可以在其他设备上无摩擦地运行。</li></ul><h2 id="2325" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">创建Dockerfile文件</h2><p id="8ef1" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">在您创建Streamlit应用程序的根目录中创建Dockerfile文件:</p><pre class="ix iy iz ja fd ng nh ni nj aw nk bi"><span id="ef84" class="mh jn hh nh b fi nl nm l nn no">FROM python:3.8-slim<br/>EXPOSE 8501<br/>WORKDIR /app<br/>COPY . .<br/>RUN pip3 install -r requirements.txt<br/>ENTRYPOINT ["streamlit", "run", "app.py", "--server.port=8501","--server.address=0.0.0.0"]</span></pre><ol class=""><li id="d68a" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz nq lu lv lw bi translated">从docker hub中提取python3.8 slim图像。</li><li id="368d" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">公开端口8501以从浏览器访问streamlit。</li><li id="a5b7" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">创建一个新目录。</li><li id="98b4" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">将根目录中的所有内容复制到app文件夹中。</li><li id="951e" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">安装项目依赖项。</li><li id="deb3" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">配置将作为可执行文件运行的容器。</li></ol><h2 id="f9d7" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">建筑形象</h2><p id="fbe6" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">从保存Dockerfile的项目根目录运行此命令:-</p><pre class="ix iy iz ja fd ng nh ni nj aw nk bi"><span id="1f1d" class="mh jn hh nh b fi nl nm l nn no">docker build -t streamlit:v1 .</span></pre><p id="362c" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">建立形象需要一些时间</p><p id="1659" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">构建映像后，运行以下命令检查映像。</p><pre class="ix iy iz ja fd ng nh ni nj aw nk bi"><span id="08bd" class="mh jn hh nh b fi nl nm l nn no">docker images</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ny"><img src="../Images/4a3d79ad741093d45ba0776d92fb215c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VLilBXxQjmoyX8rL.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="1736" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">这就是你创建的docker图像！</p><h2 id="077d" class="mh jn hh bd jo mi mj mk js ml mm mn jw kn mo mp jy kr mq mr ka kv ms mt kc mu bi translated">运行图像</h2><pre class="ix iy iz ja fd ng nh ni nj aw nk bi"><span id="b2a5" class="mh jn hh nh b fi nl nm l nn no">docker run -p 8501:8501 streamlit:v1</span></pre><p id="b782" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">现在，我们可以通过访问localhost:8501来访问web应用程序。</p><p id="5b2e" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">您的streamlit应用程序已被dockerized，现在它可以部署在任何地方，现在它可以在任何地方启动。</p><h1 id="4ce5" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">部署</h1><p id="9712" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">部署是项目的最后一个阶段，在这个阶段，我们将整个机器学习管道部署到一个实时场景中的生产系统中。在这个最后阶段，我们必须部署这个机器学习管道，以使最终用户能够获得研究成果。该模型将用于现实世界的场景，从用户那里获取连续的原始输入，然后给他们带标签的数据作为输出。</p><p id="bb96" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我已将我的应用程序部署在:-</p><ul class=""><li id="bee1" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz lt lu lv lw bi translated">简化应用程序</li><li id="3dfb" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz lt lu lv lw bi translated">在AWS EC2上</li></ul><p id="4106" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">我们将在此介绍streamlit部署，因为它是最快且免费的</p><ol class=""><li id="6c0c" class="lo lp hh kg b kh le kk lf kn lq kr lr kv ls kz nq lu lv lw bi translated">在GitHub上创建一个资源库。</li><li id="62ff" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">将所有代码从本地推送到GitHub存储库。</li><li id="2911" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">现在转到<a class="ae ln" href="https://www.ashishlotake.com/blog/streamlit.io" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>并创建一个帐户。</li><li id="5f75" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated">点击新应用程序</li></ol><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nz"><img src="../Images/75154414dd1a11da48c62e605816feee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TfmJofuprXeax0PR.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="c751" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">5.选择存储应用程序的存储库和所有streamlit代码所在的主文件路径，然后按Deploy！。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es oa"><img src="../Images/23ee894db67ff10c8227a0abfc425e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RcESoruhUjec6b--.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Image by Author</figcaption></figure><p id="013c" class="pw-post-body-paragraph ke kf hh kg b kh le ii kj kk lf il km kn lh kp kq kr lj kt ku kv ll kx ky kz ha bi translated">Wola，您的应用程序已部署。转到streamlit给出的链接。</p><h1 id="a4ab" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">最终想法</h1><p id="6ed3" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">我们已经成功地创建了一个主动标记系统，使用迁移学习可以在看不见的数据上实现90%以上的准确性。允许用户输入原始数据，标记模型是否表现不佳，然后通过将图像放入正确的目录，为用户提供正确分类的图像。</p><h1 id="3799" class="jm jn hh bd jo jp jq jr js jt ju jv jw in jx io jy iq jz ir ka it kb iu kc kd bi translated">所有Jupyter笔记本Colab链接:</h1><p id="cf1f" class="pw-post-body-paragraph ke kf hh kg b kh ki ii kj kk kl il km kn ko kp kq kr ks kt ku kv kw kx ky kz ha bi translated">IPYNB <a class="ae ln" href="https://www.ashishlotake.com/blog/active-labelling-system#all-jupyter-notebooks" rel="noopener ugc nofollow" target="_blank"> Colab链接</a></p><blockquote class="la lb lc"><p id="cd1c" class="ke kf ld kg b kh le ii kj kk lf il km lg lh kp kq li lj kt ku lk ll kx ky kz ha bi translated">本帖原帖<a class="ae ln" href="https://www.ashishlotake.com/blog/" rel="noopener ugc nofollow" target="_blank">此处</a></p></blockquote></div><div class="ab cl ob oc go od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ha hb hc hd he"><h1 id="8948" class="jm jn hh bd jo jp oi jr js jt oj jv jw in ok io jy iq ol ir ka it om iu kc kd bi translated">参考</h1><ol class=""><li id="6230" class="lo lp hh kg b kh ki kk kl kn mw kr mx kv my kz nq lu lv lw bi translated"><a class="ae ln" href="https://www.manning.com/books/deep-learning-with-python" rel="noopener ugc nofollow" target="_blank">https://www.manning.com/books/deep-learning-with-python</a></li><li id="0721" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated"><a class="ae ln" href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/grid-search-hyperparameters-deep-learning-models-python-keras/</a></li><li id="1e5e" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated"><a class="ae ln" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank">https://keras.io/api/applications/</a></li><li id="2c5e" class="lo lp hh kg b kh mc kk md kn me kr mf kv mg kz nq lu lv lw bi translated"><a class="ae ln" href="https://data.caltech.edu/records/mzrjq-6wc02" rel="noopener ugc nofollow" target="_blank">https://data.caltech.edu/records/mzrjq-6wc02</a></li></ol><div class="on oo ez fb op oq"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="or ab dw"><div class="os ab ot cl cj ou"><h2 class="bd hi fi z dy ov ea eb ow ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ox l"><h3 class="bd b fi z dy ov ea eb ow ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="oy l"><p class="bd b fp z dy ov ea eb ow ed ef dx translated">medium.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe jg oq"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Semantic Segmentation with PyTorch: U-NET from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch语义分割:从零开始的U-NET</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/semantic-segmentation-with-pytorch-u-net-from-scratch-502d6565910a?source=collection_archive---------0-----------------------#2022-07-24">https://medium.com/mlearning-ai/semantic-segmentation-with-pytorch-u-net-from-scratch-502d6565910a?source=collection_archive---------0-----------------------#2022-07-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/c0381c44ab6b749cd6c73a53083f93c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fbLvUsof93illP5qeLusLg.jpeg"/></div></div></figure><p id="3ac6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先，让我们了解一下这篇文章是否适合您:</p><ul class=""><li id="09ac" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">如果你是一个数据科学家/ML工程师或者是一个接近语义分割的书呆子，你应该读读它。</li><li id="0258" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">如果你试图理解多类语义分割，你不应该读它。我的U-NET是在<a class="ae kb" href="https://davischallenge.org/index.html" rel="noopener ugc nofollow" target="_blank"> Davis 2017数据集</a>上训练的，目标遮罩不是特定于类的(它们的颜色是随机的)。</li></ul><p id="34b7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你已经到了这一步，那么这篇文章是给你的。现在让我们把重点放在实现上。</p><p id="7837" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">整个模型由以下部分组成。py文件:</p><ol class=""><li id="d914" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm kc jt ju jv bi translated">model.py</li><li id="f11a" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">dataset.py</li><li id="a101" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">train.py</li><li id="a69b" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">配置. py</li></ol></div><div class="ab cl kd ke go kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="ha hb hc hd he"><h2 id="f641" class="kk kl hh bd km kn ko kp kq kr ks kt ku ja kv kw kx je ky kz la ji lb lc ld le bi translated">模型。巴拉圭</h2><p id="c75c" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">这是UNET架构，突出显示的部分是我用来构建模型的子类:CNNBlock、CNN block、编码器和解码器。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lk"><img src="../Images/cb5073ea172c78c24c096ca9bd9db92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVGi3pOKQq78tI90ZltRgg.png"/></div></div></figure><ul class=""><li id="4b3e" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi"> CNNBlock </strong>只是依次应用卷积层、批量归一化和RELU激活函数。</li></ul><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><ul class=""><li id="90ec" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi"> CNNBlocks </strong>连续执行<em class="lr"> x次</em>一个CNNBlock(在我们的例子中是2个)。这里的<em class="lr"> n_conv </em>参数表示完成的卷积数:如果像我们的例子中那样设置为2，那么它将执行两次卷积。</li></ul><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><ul class=""><li id="65ee" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi">编码器</strong>执行<em class="lr">下坡</em>次CNNBlocks，存储route_connection，然后应用MaxPool2d层。如果你回到UNET建筑的图像，你可以通过计算两个蓝色箭头后面跟着一个红色箭头的次数来形象化它:4次。由于最后一个CNNBlocks不需要MaxPool2d，我们将其添加到for循环之外。</li></ul><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="72d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">解码器</strong> →执行<em class="lr">上坡</em>次数的转置卷积，将输出与相应的route_connection连接，并将连接的张量输入到CNNBlocks。最后，在图片的右上角，输出层返回一个形状张量[batch_size，n_classes=1，height，width]。注意:编码器的<em class="lr">下坡</em>参数必须等于解码器的<em class="lr">上坡</em>参数。</p><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="55e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，我们把所有的部分放在一起，创建我们的<strong class="ir hi"> UNET </strong>类:</p><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="f6c3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这里，我想考虑一下我的实现的优点和缺点:</p><ol class=""><li id="a717" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm kc jt ju jv bi translated">这是多余的:正如Aladdin Persson在<a class="ae kb" href="https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/image_segmentation/semantic_segmentation_unet/model.py" rel="noopener ugc nofollow" target="_blank">他的实现</a>中所示，这个模型可以用大约70行代码构建(我的是大约150行)。主要原因是我为编码器和解码器创建了两个不同的类，而不是直接在UNET类中实现它们。另一方面，我的版本的优点是灵活性:你可以通过修改<em class="lr"> first_out_channels </em>和<em class="lr">download</em>参数来试验调整原始UNET。</li><li id="6e28" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">允许解码器中的第二个输入变量<em class="lr"> forward(self，x，route_connection) </em>这不是很优雅。这可以通过在一个独特的UNET类中编写编码器和解码器来解决。</li></ol></div><div class="ab cl kd ke go kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="ha hb hc hd he"><h2 id="81ec" class="kk kl hh bd km kn ko kp kq kr ks kt ku ja kv kw kx je ky kz la ji lb lc ld le bi translated">数据集。巴拉圭</h2><p id="7535" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">因为这个类大约有80行，所以我没有粘贴到文章中，但是你可以在这里找到它。</p><p id="d06e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是DAVIS_2017数据集的树形结构:</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/47c11dd7e18cebe95daafe927f6903ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*116RITmOknuJsXdyBOTOOw.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx">To help the visualisation I replaced all the classes with “class” in the subfolders of 480p</figcaption></figure><p id="effb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我使我的数据加载器适应了这个<a class="ae kb" href="https://github.com/kmaninis/OSVOS-PyTorch/blob/master/dataloaders/davis_2016.py" rel="noopener ugc nofollow" target="_blank"> one </a>，并对其进行了修改，使其更简洁、更易于阅读。</p><p id="6e3f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它是如何工作的？</p><p id="0f32" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">除了初始化参数之外，<strong class="ir hi"> __init__() </strong>的作用是创建两个列表，img_list和labels，它们包含了以相同顺序排列的每个图像的所有路径(<em class="lr"> img_list[i] </em>引用<em class="lr"> labels[i] </em>)。</p><p id="888c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了实现这一点，我们采用了这一策略(以下示例针对<em class="lr"> img_list </em>完成，但针对<em class="lr">标签</em>也是如此):</p><ol class=""><li id="0721" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm kc jt ju jv bi translated">我们用root_folder (DAVIS_2017文件夹)的路径初始化这个类。</li><li id="d991" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">我们打开并加载train.txt，其中包含所有类的列表(“熊”、“跑酷”等)</li><li id="163b" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">通过os.path.join()我们到达每个class_folder，然后用os.listdir()列出所有包含的图像。</li><li id="a0b2" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kc jt ju jv bi translated">我们应用这个函数:"<em class="lr">list(map(lambda x:OS . path . join(' path _ to-&gt;'，" class_folder "，x)，images)) </em>，它为一个给定的class_folder创建一个到每个图像的路径列表。可以这样读:<em class="lr"> map(function，iterable) </em>将给定的<em class="lr">函数</em>应用到一个<em class="lr"> iterable </em>的每个元素上。这里我们的函数是<em class="lr">λ</em>，它为<em class="lr">图像</em>列表<em class="lr">中的每个<em class="lr"> img_name </em>创建一个到<em class="lr"> img_name </em>的路径。</em></li></ol><p id="fb3e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后<strong class="ir hi"> __getitem__(self，idx) </strong>方法将基于它们在<em class="lr"> img_list </em>和<em class="lr">标签</em>中的idx来检索图像和遮罩。</p><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="ef67" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> __getitem__(self，idx) </strong>的步骤如下:</p><ul class=""><li id="326c" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">我们用PIL库加载图像，并将它们转换成np.arrays</li><li id="ffa7" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">我们应用数据扩充。</li><li id="1074" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">白蛋白库不会对面具进行标准化，因此我们自己进行标准化。</li><li id="0203" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">在UNET的原始论文中，他们使用了<em class="lr">“有效卷积”</em> (kernel_size=3，stride=1，padding=0)而不是<em class="lr">“相同卷积”</em> (kernel_size=3，stride=1，padding=1)。由于我们已经加载了形状为[batch_size，channels，height=388，width=388]的图像和遮罩，为了使我们的模型输出形状相同的张量，我们必须输入形状为[batch_size，channels，height=572，width=572]的张量。为了增加输入张量的高度和宽度，我们使用了92((572–388)/2)的<a class="ae kb" href="https://res.cloudinary.com/practicaldev/image/fetch/s--ENjk_7PR--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/16zxbk5x7jegfof422bk.png" rel="noopener ugc nofollow" target="_blank">反射填充(或镜像</a>)。</li></ul></div><div class="ab cl kd ke go kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="ha hb hc hd he"><h2 id="0979" class="kk kl hh bd km kn ko kp kq kr ks kt ku ja kv kw kx je ky kz la ji lb lc ld le bi translated">火车。巴拉圭</h2><p id="fd60" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated"><a class="ae kb" href="https://github.com/AlessandroMondin/computer_vision/blob/main/U-NET/train.py" rel="noopener ugc nofollow" target="_blank">该文件</a>使用了许多在<a class="ae kb" href="https://github.com/AlessandroMondin/computer_vision/blob/main/U-NET/utils.py" rel="noopener ugc nofollow" target="_blank"> utils.py </a>中定义的函数，而超参数和其他变量位于<a class="ae kb" href="https://github.com/AlessandroMondin/computer_vision/blob/main/U-NET/config.py" rel="noopener ugc nofollow" target="_blank"> config.py </a>中。</p><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div><figcaption class="lt lu et er es lv lw bd b be z dx"><strong class="ak"><em class="lx">If you’re new to torch.cuda.amp.GradScaler check it </em></strong><a class="ae kb" href="https://pytorch.org/docs/stable/amp.html" rel="noopener ugc nofollow" target="_blank"><strong class="ak"><em class="lx">here</em></strong></a><strong class="ak"><em class="lx"> and then a look at the train_loop() in the utils.file linked above.</em></strong></figcaption></figure><p id="0aa1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些是在train中执行的步骤。py:</p><ul class=""><li id="cdbe" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">定义损失函数、模型和优化器。</li><li id="a300" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">如果定义了检查点，则加载模型和优化器的工件。</li><li id="7d0c" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">导入数据集的数据加载器。</li><li id="0c2d" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">然后，对于EPOCHS时间，它在整个数据集上训练模型，在控制台中登录评估度量(<a class="ae kb" href="https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2" rel="noopener" target="_blank"> dice-score </a> &amp;先前定义的loss_fn)，保存模型，最后保存图像，比较地面_真相掩码和预测_掩码(模型的输出)</li></ul></div><div class="ab cl kd ke go kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="ha hb hc hd he"><h2 id="0d10" class="kk kl hh bd km kn ko kp kq kr ks kt ku ja kv kw kx je ky kz la ji lb lc ld le bi translated">结果</h2><p id="cada" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">我用SageMaker中的ml.p2.xlarge对模型进行了训练，当它在验证集的<strong class="ir hi">0.48<strong class="ir hi">回忆</strong>和骰子点数</strong>的<strong class="ir hi"> 0.52上达到时，在第14个历元获得了最佳结果。一开始，我对这些结果非常失望，但后来我注意到，在DAVIS_2017比赛中取得最佳成绩的模型在ImageNet或COCO数据集上进行了预训练。这个事实应该提醒我们迁移学习的力量和重要性。</strong></p><p id="40b4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以下是14个时期验证集的一些最佳和最差预测:</p><div class="ll lm ln lo fd ab cb"><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/6ae36dc6795aeea124d948c89e9c61ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*l0OUYXbCWuVMnkl6fcP2xg.png"/></div></figure><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/6959679e3e42a7083c5dcb9dfca1b8cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*09Py7VLs8uLr6ZWDMkJs7w.png"/></div></figure></div><div class="ab cb"><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/0da09ea8e5f35e7790281c02d1c3a15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*U8-i3-uVhufOMDOfVarbow.png"/></div></figure><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/796aa75cc1189b19839c51ba1f3c70d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*rDp7hN0zfAchEYpU8KtcVw.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx me di mf mg">Some of the best predictions</figcaption></figure></div><div class="ab cb"><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/cbc829896779bc45c000e1ffa8d858d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*E3GBRwm8RdziC29lJ3F5jw.png"/></div></figure><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/4fd3a8a18746c8cf90de6b9e122093c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5GHaCYmDeIb62z604CbGfA.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx me di mf mg">Some of the worst predictions</figcaption></figure></div><p id="bccb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">很难在糟糕的预测中找出共同的模式:也就是说，你可以认为在两张图片中，棕色占主导地位，前景和背景的颜色相似。改进这种对象的检测的最佳方式可能是，一如既往地，在更大的数据集上利用预训练。</p><h2 id="9fa8" class="kk kl hh bd km kn ko kp kq kr ks kt ku ja kv kw kx je ky kz la ji lb lc ld le bi translated">结论</h2><p id="8fe9" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">在开始一个项目之前，你应该检查你的数据集是否符合你的目的。在我的案例中，DAVIS datasat是为了支持视频对象检测的研究而创建的，因此每一类的观察都是(几乎相同的)视频的连续帧。</p><div class="ll lm ln lo fd ab cb"><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/6b6536f91425a49acc220ba1aa8606d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*7r21ZTpUXm-PFXWT3F3W7Q.jpeg"/></div></figure><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/f9aed14d38c080970250a9fb0fc83d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*CXvU0vrRUgatyzAEwGCQqQ.jpeg"/></div></figure></div><div class="ab cb"><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/9c61cfd8a3618549303645ff1645c9fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*Twb8B0NCze0UVZr8bsGIWw.jpeg"/></div></figure><figure class="ly ii lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/a413c0d0ab3eb88841cf1ca1d2131660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*zsk_cnmPJskIOO_zAcOHIA.jpeg"/></div><figcaption class="lt lu et er es lv lw bd b be z dx me di mf mg">These are the images 00034.jpg, 00035.jpg, 00036.jpg, 00037.jpg of the car-turn class</figcaption></figure></div><p id="29e1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">鉴于我最初的目的是训练一个图像语义分割算法，我宁愿选择另一个数据集，因为戴维斯没有提供足够的概括。</p><p id="611a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当在远离DAVIS的环境中测试模型时，这些限制会明显出现:</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/2a3d5c73fb5777f4cf153437cdb01834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fgLNLdPnIeGisXQCOkshHQ.jpeg"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx">Myself while crossing the Ponte Tibetano of Bellinzona (CH)</figcaption></figure><p id="5c13" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这应该提醒我们，为了训练神经网络来有效地检测我们的目标对象，我们必须为它提供大量适合我们目的的高质量数据。</p><p id="2e3d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我希望这篇教程对你有帮助，感谢你阅读它！</p><div class="mi mj ez fb mk ml"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz in ml"/></div></div></a></div></div></div>    
</body>
</html>
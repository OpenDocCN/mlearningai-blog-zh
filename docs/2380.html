<html>
<head>
<title>NLP: A Comprehensive Guide to Text Cleaning and PreProcessing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP:文本清洗和预处理综合指南</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/nlp-a-comprehensive-guide-to-text-cleaning-and-preprocessing-63f364febfc5?source=collection_archive---------2-----------------------#2022-04-24">https://medium.com/mlearning-ai/nlp-a-comprehensive-guide-to-text-cleaning-and-preprocessing-63f364febfc5?source=collection_archive---------2-----------------------#2022-04-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8ea6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">以正确的方式处理原始文本</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/79ae2707ee16a6a61b85a5b1d1a834e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CDvBSK03vytPWsKa"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@rey_7?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Rey Seven</a> on <a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="993d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自然语言处理，简称NLP，是人工智能中处理语言学和人类语言的一个领域。NLP处理计算机和人类语言之间的交互。它使计算机能够理解人类语言，并对其进行编程，以执行分类、摘要、命名实体识别等任务。</p><p id="e647" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是在计算机程序能够分析人类语言之前，需要进行大量的清理和预处理步骤。文本数据的预处理和清理对模型的性能有着巨大的影响。因此，文本清理和处理在NLP项目的生命周期中占有非常重要的地位。</p><p id="38da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将介绍一些文本清理和处理技术，并将使用Python编程语言实现它们。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="573f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">移除HTML标签</strong></p><p id="d07d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">原始文本可能包含HTML标记，尤其是在使用web或屏幕抓取等技术提取文本的情况下。HTML标签是噪音，对理解和分析文本没有多大价值。因此，它们应该被删除。我们将使用<em class="jc">beautiful soup</em>库来移除HTML标签。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="f020" class="kg kh hh kc b fi ki kj l kk kl">from bs4 import BeautifulSoup</span><span id="1dbc" class="kg kh hh kc b fi km kj l kk kl">def remove_html_tags(text):<br/>    return BeautifulSoup(text, 'html.parser').get_text()</span><span id="627b" class="kg kh hh kc b fi km kj l kk kl">remove_html_tags( ‘<!-- -->&lt;p&gt;A part of the text &lt;span&gt;and here another part&lt;/span&gt;&lt;/p&gt;<!-- -->’)</span><span id="564c" class="kg kh hh kc b fi km kj l kk kl">#output<br/>&gt;&gt; A part of the text and here another part</span></pre><p id="aa74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">案例标准化</strong></p><p id="d475" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是NLP中最常见的预处理步骤之一，将文本转换成相同的大小写，通常是小写。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="e3ba" class="kg kh hh kc b fi ki kj l kk kl">def to_lowercase(text):<br/>    return text.lower()</span><span id="4799" class="kg kh hh kc b fi km kj l kk kl">print("Learning NLP is Fun....")<br/>&gt;&gt; learning nlp is fun</span></pre><p id="b594" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是这一步会导致一些NLP任务中的信息丢失。例如，在情感分析任务中，用大写字母书写的单词可以表示强烈的情感，如愤怒、兴奋等。在这种情况下，我们可能希望以不同的方式执行这一步，甚至可能避免这一步。</p><p id="3831" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">标准化重音字符</strong></p><p id="80ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有时，人们会使用重音符号，如{\\ T10 }é,}等。表示发音时对特定字母的强调。在某些情况下，重音符号还可以澄清单词的语义，如果没有重音符号，可能会有所不同。虽然您可能很少遇到带重音符号的字符，但是将这些字符转换成标准ASCII字符是一个很好的做法。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="0cd3" class="kg kh hh kc b fi ki kj l kk kl">import unicodedata</span><span id="3867" class="kg kh hh kc b fi km kj l kk kl">def standardize_accented_chars(text):<br/> return unicodedata.normalize(‘NFKD’, text).encode(‘ascii’, ‘ignore’).decode(‘utf-8’, ‘ignore’)</span><span id="1489" class="kg kh hh kc b fi km kj l kk kl">print(standardize_accented_chars('Sómě words such as résumé, café, prótest, divorcé, coördinate, exposé, latté.'))</span><span id="1769" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; Some words such as resume, cafe, pretest, divorce, coordinate, expose, latte.</span></pre><p id="7cb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">处理网址</strong></p><p id="3f1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">很多时候，人们使用URL，尤其是在社交媒体上，来为上下文提供额外的信息。这些URL不会在样本之间进行归纳，因此是噪声。我们可以使用<em class="jc">正则表达式删除URL。</em></p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="5a5c" class="kg kh hh kc b fi ki kj l kk kl">impor re <br/>def remove_url(text):<br/> return re.sub(r’https?:\S*’, ‘’, text)</span><span id="2239" class="kg kh hh kc b fi km kj l kk kl">print(remove_url('using <a class="ae jt" href="https://www.google.com/" rel="noopener ugc nofollow" target="_blank">https://www.google.com/</a> as an example'))</span><span id="4039" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; using as an example</span></pre><p id="adb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>在一些任务中，URL可以给数据添加额外的信息。例如，在旨在检测社交媒体评论是否是广告的文本分类任务中，评论中URL的存在可以提供有用的信息。在这种情况下，我们可以用一个定制的令牌来替换URL，如<strong class="ig hi"><em class="jc">&lt;URL&gt;</em></strong>，或者在特征向量中添加一个额外的二进制特征来对应URL的存在。</p><p id="a871" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">扩张收缩</strong></p><p id="1948" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">缩写是单词或音节的缩写。它们是通过从单词中去掉一个或多个字母而产生的。有时，多个单词组合在一起构成一个缩略词。例如，<em class="jc">将我的意志承包成我的意志，不要成不要。</em>考虑到<em class="jc">我将</em>和<em class="jc">我将</em>不同可能会导致模型性能不佳。因此，将每个收缩转换成它的扩展形式是一个很好的实践。我们可以使用<em class="jc">缩写库</em>将缩写转换成它们的扩展形式。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="5e14" class="kg kh hh kc b fi ki kj l kk kl">import contractions</span><span id="37af" class="kg kh hh kc b fi km kj l kk kl">def expand_contractions(text):<br/>    expanded_words = [] <br/>    for word in text.split():<br/>       expanded_words.append(contractions.fix(word)) <br/>    return ‘ '.join(expanded_words)</span><span id="a70f" class="kg kh hh kc b fi km kj l kk kl">print(expand_contractions("Don't is same as do not"))</span><span id="04e4" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; Do not is same as do not</span></pre><p id="3e56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">删除提及和标签</strong></p><p id="2322" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这一步在处理社交媒体文本数据时生效，例如，<em class="jc"> Tweets。</em>提及和标签不能在样本间推广，在大多数NLP任务中是噪声。因此，最好移除这些。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="0fa6" class="kg kh hh kc b fi ki kj l kk kl">import re</span><span id="2537" class="kg kh hh kc b fi km kj l kk kl">def remove_mentions_and_tags(text):<br/>    text = re.sub(r’@\S*’, ‘’, text)<br/>    return re.sub(r’#\S*’, ‘’, text)</span><span id="b604" class="kg kh hh kc b fi km kj l kk kl">#testing the function on a single sample for explaination<br/>print(remove_mentions_and_tags('Some random @abc and#def'))</span><span id="38d8" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; Some random and </span></pre><p id="9e80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上述输出可能对人类有很大意义，但有助于提高模型的性能。</p><p id="81ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>在这一步中，我们将删除“@”和“#”后面的文本。此外，这一步应该在从文本中删除特殊字符之前执行(这是我们接下来要研究的步骤)</p><p id="39e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">删除特殊字符</strong></p><p id="cf19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特殊字符是非字母数字字符。像%、$、&amp;等字符是特殊的。在大多数NLP任务中，这些字符对文本理解没有任何价值，并且会在算法中引入噪声。我们可以使用正则表达式来删除特殊字符。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="633b" class="kg kh hh kc b fi ki kj l kk kl">import re<br/>def remove_special_characters(text):<br/>    # define the pattern to keep<br/>    pat = r'[^a-zA-z0-9.,!?/:;\"\'\s]' <br/>    return re.sub(pat, '', text)<br/> <br/>print(remove_special_characters(“007 Not sure@ if this % was #fun! 558923 What do# you think** of it.? $500USD!”))</span><span id="448c" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; '007 Not sure if this  was fun! 558923 What do you think of it.? 500USD!'</span></pre><p id="0da8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">删除数字</strong></p><p id="aca8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文本中的数字不会给数据增加额外的信息，也不会给算法带来干扰。因此，从文本中删除数字是一个很好的做法。同样，我们可以使用regex来完成这项任务。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="e9a8" class="kg kh hh kc b fi ki kj l kk kl"># imports<br/>import re <br/>def remove_numbers(text):<br/>    pattern = r'[^a-zA-z.,!?/:;\"\'\s]' <br/>    return re.sub(pattern, '', text)<br/> <br/>print(remove_numbers(“You owe me 1000 Dollars”))</span><span id="38d0" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; You owe me Dollars</span></pre><p id="3036" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">去掉双关语</strong></p><p id="c2f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">再说一次，双关不会给NLP中的数据增加额外的信息，因此，我们把它们去掉了。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="1b6a" class="kg kh hh kc b fi ki kj l kk kl">import string</span><span id="60f5" class="kg kh hh kc b fi km kj l kk kl">def remove_punctuation(text):<br/>    return ''.join([c for c in text if c not in string.punctuation])<br/>    </span><span id="2878" class="kg kh hh kc b fi km kj l kk kl">remove_punctuation('On 24th April, 2005, "Me at the zoo" became the first video ever uploaded to YouTube.')</span><span id="fec1" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; On 24th April 2005 Me at zoo became the first video ever uploaded to Youtube</span></pre><p id="b889" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">引理</strong></p><p id="6b6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">词汇化从单词的屈折形式中产生单词的词根形式。比如对于词根'<em class="jc">打</em>'，'<em class="jc">打</em> ' <em class="jc"> </em>会是它的屈折形式。请注意，<em class="jc">播放和播放</em>的意思几乎相同，如果我们的模型认为<em class="jc">播放</em>与<em class="jc">播放</em>相同会更好。为了实现这样的转换，我们使用了词汇化。词汇化利用词汇和词形分析来生成单词的词根形式。我们将使用spaCy库来执行词汇化。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="7842" class="kg kh hh kc b fi ki kj l kk kl">import spacy<br/>def lemmatize(text, nlp):<br/>   doc = nlp(text)<br/>   lemmatized_text = []<br/>   for token in doc:<br/>     lemmatized_text.append(token.lemma_)<br/>   return “ “.join(lemmatized_text)</span><span id="db93" class="kg kh hh kc b fi km kj l kk kl">print(lemmatize('Reading NLP blog is fun.' ,nlp ))</span><span id="51c0" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; Read NLP blog is fun.</span></pre><p id="cea4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在词汇化之前，词干化被用来将词形变化的单词还原成它们的词根形式。但是词干分析并不考虑语言的词汇，而是使用一些基于规则的方法来消除单词的屈折变化。在许多情况下，词干生成的单词不是语言词汇的一部分。因此，词汇化几乎总是比词干化更受青睐。尽管如此，我还是提供了执行词干分析的代码。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="0222" class="kg kh hh kc b fi ki kj l kk kl">import nltk<br/>def get_stem(text):<br/>    stemmer = nltk.porter.PorterStemmer()<br/>    return ' '.join([stemmer.stem(word) for word in text.split()])</span><span id="92cc" class="kg kh hh kc b fi km kj l kk kl">print(get_stem("Sharing and caring is a good habit"))</span><span id="39e7" class="kg kh hh kc b fi km kj l kk kl">&gt;&gt; Shar and car is a good habit</span></pre><p id="1f1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意到<em class="jc">关心</em>变成了<em class="jc">车</em>和<em class="jc">共享</em>变成了<em class="jc">沙尔山。</em></p><p id="fce4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">删除停用词</strong></p><p id="efbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">像<em class="jc">我，我，我，等等，</em>这样的停用词不会添加任何有助于建模的信息。保持它们会增加噪声并增加特征向量的维数，严重影响计算成本和模型精度。因此，建议删除它们。我们将使用spacy库删除停用词。Spacy在停用词集中有326个词。在某些情况下，我们可能希望添加一些自定义的停用词，例如，这些词是我们任务的停用词，但可能不在空间的停用词集中。此外，在一些NLP任务中，我们可能希望从spacy的停用词集中删除一些词。例如，在情感任务中，我们希望在文本中保留否定词，如<em class="jc">‘not，nenot，not，etc’</em>，因此，我们会将它们从spacy的停用词集中删除。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="2d2e" class="kg kh hh kc b fi ki kj l kk kl">def remove_stopwords(text,nlp):       <br/>    filtered_sentence =[] <br/>    doc=nlp(text)<br/>    for token in doc:<br/>        <br/>        if token.is_stop == False: <br/>          filtered_sentence.append(token.text)   </span><span id="86ef" class="kg kh hh kc b fi km kj l kk kl">    return “ “.join(filtered_sentence)</span><span id="242d" class="kg kh hh kc b fi km kj l kk kl">nlp = spacy.load("en_core_web_sm", disable=["parser", "ner"])</span><span id="14b2" class="kg kh hh kc b fi km kj l kk kl">print(remove_stopwords('I love going to school',nlp))<br/>&gt;&gt; love going school</span></pre></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="bd2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论</strong></p><p id="fe32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们已经讨论了一些常见和有用的文本清理和处理技术。您可能已经注意到，我已经分别实现了这些函数，有些函数可以组合起来增强代码的性能。为了更好地解释各个步骤，我将所有步骤分开保存。在项目中实现这些步骤时，可以将一些步骤组合起来。此外，在某些NLP任务中可能不需要其中的一些。我试图解释在什么情况下可以忽略哪些步骤。但是，包含这些步骤的决定在很大程度上取决于问题陈述。此外，可能还有其他一些库用最少的代码执行相同的步骤，但是我试图用代码解释这些步骤，让人们可以思考幕后发生了什么。理解了这些步骤，移植到那些库就不是一件棘手的事情了。谢谢！！！下一篇文章再见。</p><p id="31e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献</strong></p><ol class=""><li id="611a" class="kn ko hh ig b ih ii il im ip kp it kq ix kr jb ks kt ku kv bi translated"><a class="ae jt" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">https://spacy.io/</a></li><li id="dc01" class="kn ko hh ig b ih kw il kx ip ky it kz ix la jb ks kt ku kv bi translated"><a class="ae jt" href="https://www.w3schools.com/python/python_regex.asp" rel="noopener ugc nofollow" target="_blank">https://www.w3schools.com/python/python_regex.asp</a></li><li id="e103" class="kn ko hh ig b ih kw il kx ip ky it kz ix la jb ks kt ku kv bi translated"><a class="ae jt" href="https://pypi.org/project/contractions/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/contractions/</a></li></ol><div class="lb lc ez fb ld le"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd hi fi z dy lj ea eb lk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">medium.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls jn le"/></div></div></a></div></div></div>    
</body>
</html>
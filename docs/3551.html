<html>
<head>
<title>Object Detection service with YOLO and FastAPI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YOLO和FastAPI的对象检测服务</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-detection-service-with-yolo-and-fastapi-af1318ee73ed?source=collection_archive---------2-----------------------#2022-09-19">https://medium.com/mlearning-ai/object-detection-service-with-yolo-and-fastapi-af1318ee73ed?source=collection_archive---------2-----------------------#2022-09-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="c885" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">部署经过定制培训的机器学习模型，检测图像中的对象</h2></div><p id="986a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我之前的机器学习文章<a class="ae js" rel="noopener" href="/mlearning-ai/image-classification-with-transfer-learning-on-tensorflow-68b6bc87ef4b"> 1 </a>、<a class="ae js" rel="noopener" href="/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-2d718c85b58f"> 2 </a>、<a class="ae js" rel="noopener" href="/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-lightning-6665ddb5b748"> 3 </a>中，我涵盖了计算机视觉中的一项重要任务，图像分类。图像分类是计算机视觉的一个应用。在本文中，我想探索“对象检测”任务，并使用FastAPI部署机器学习模型，以便它可以由restful API接口使用。</p><p id="7911" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面的文章很好地概述了对象检测。</p><div class="jt ju ez fb jv jw"><a href="https://viso.ai/deep-learning/object-detection/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">2022年的物体探测:权威指南</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">这篇文章将提供一个对象检测的介绍，并提供一个最先进的计算机…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">viso.ai</p></div></div><div class="kf l"><div class="kg l kh ki kj kf kk kl jw"/></div></div></a></div><p id="fb4c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLO是<a class="ae js" href="https://www.geeksforgeeks.org/difference-between-yolo-and-ssd/" rel="noopener ugc nofollow" target="_blank">一种</a>类型的深度神经网络，常用于“物体检测”任务，速度非常快。YOLO的最新版本是<a class="ae js" rel="noopener" href="/@armaan.sandhu.2002/training-yolov7-to-detect-vehicle-braking-e8e7e9db1b3b"> v7 </a>。我们将在本文中使用YOLO。</p><h1 id="fc2f" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated">COCO数据集格式</h1><p id="8521" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">在“对象检测”领域，COCO(代表上下文中的公共对象)数据集是一种用于对象检测研究的数据集格式。在高层次上，它使用JSON来做图像标注，它需要指定图像位置和其他基本信息，最重要的是，它用相应的对象类别来标注每个图像中的包围盒(例如，图像中的哪个位置是苹果，哪个位置是香蕉，等等)。).以下是部分COCO JSON的样例，注意注释[]。image_id指的是实际图像[]。id，注释[]。category_id引用类别[]。id，这样您就知道哪个注释引用了哪个图像中的哪个边界框/位置以及边界框的类别。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lj"><img src="../Images/423487567bd42f1eefebcdd4d48fb70a.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*GcPHhBVbK4639-3S6_oAsg.png"/></div></figure><p id="9051" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">更多信息，请参考以下关于COCO格式的文章。</p><div class="jt ju ez fb jv jw"><a href="https://haobin-tan.netlify.app/ai/computer-vision/object-detection/coco-dataset-format" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">可可JSON格式的对象检测|郝斌谭</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">COCO数据集的格式是JSON，它是“信息”、“许可证”、“图像”、“注释”、“类别”的集合…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">郝斌-谭</p></div></div><div class="kf l"><div class="lq l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/coco-dataset-what-is-it-and-how-can-we-use-it-e34a5b0c6ecd"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">Coco数据集，是什么？我们如何使用它？</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">COCO格式是什么？</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="lr l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://towardsdatascience.com/coco-data-format-for-object-detection-a4c5eaf518c5" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">对象检测的COCO数据格式</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">在本文中，我们将了解两种流行的数据格式:COCO数据格式和Pascal VOC数据格式。这些数据…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">towardsdatascience.com</p></div></div><div class="kf l"><div class="ls l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://towardsdatascience.com/getting-started-with-coco-dataset-82def99fa0b8" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">COCO数据集入门</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">理解计算机视觉常用数据集的格式</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">towardsdatascience.com</p></div></div><div class="kf l"><div class="lt l kh ki kj kf kk kl jw"/></div></div></a></div><p id="256c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用<a class="ae js" href="https://gist.github.com/mkocabas/a6177fc00315403d31572e17700d7fd9" rel="noopener ugc nofollow" target="_blank">链接</a>中的代码下载样本COCO数据集</p><p id="a7ce" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你可以使用<a class="ae js" href="https://github.com/cocodataset/cocoapi/tree/master/PythonAPI" rel="noopener ugc nofollow" target="_blank"> pycocotools </a>来解析Python中的COCO数据集。下面是一些解析注释并显示为图片的示例，如<a class="ae js" rel="noopener" href="/mlearning-ai/coco-dataset-what-is-it-and-how-can-we-use-it-e34a5b0c6ecd">这篇文章</a>。</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="9e65" class="lz kn hh lv b fi ma mb l mc md"># instance with bounding boxes and category text<br/>import pandas as pd <br/>import os<br/>from pycocotools.coco import COCO<br/>import skimage.io as io<br/>import matplotlib.pyplot as plt<br/>from pathlib import Path</span><span id="dc68" class="lz kn hh lv b fi me mb l mc md">dataDir=Path('coco/images/val2017')<br/>annFile = Path('coco/annotations/instances_val2017.json')<br/>coco = COCO(annFile)<br/>imgIds = coco.getImgIds()<br/>imgs = coco.loadImgs(imgIds[-3:])</span><span id="28dd" class="lz kn hh lv b fi me mb l mc md">_,axs = plt.subplots(len(imgs),2,figsize=(10,5 * len(imgs)))<br/>for img, ax in zip(imgs, axs):<br/> I = io.imread(dataDir/img['file_name'])<br/> annIds = coco.getAnnIds(imgIds=[img['id']])<br/> anns = coco.loadAnns(annIds)<br/> ax[0].imshow(I)<br/> ax[1].imshow(I)<br/> plt.sca(ax[1])<br/> coco.showAnns(anns, draw_bbox=True)<br/> for i, ann in enumerate(anns):<br/> cat = coco.loadCats(anns[i]['category_id'])<br/> cat_name = cat[0]['name']<br/> ax[1].text(anns[i]['bbox'][0], anns[i]['bbox'][1], cat_name, style='italic', <br/> bbox={'facecolor': 'white', 'alpha': 0.7, 'pad': 5})</span><span id="97a3" class="lz kn hh lv b fi me mb l mc md"># person key points<br/>dataDir=Path('coco/images/val2017')<br/>annFile = Path('coco/annotations/person_keypoints_val2017.json')<br/>coco = COCO(annFile)<br/>imgIds = coco.getImgIds()<br/>imgs = coco.loadImgs(imgIds[-1:])<br/>_,axs = plt.subplots(len(imgs),2,figsize=(10,5 * len(imgs)))<br/>for img, ax in zip(imgs, axs):<br/> I = io.imread(dataDir/img['file_name'])<br/> annIds = coco.getAnnIds(imgIds=[img['id']])<br/> anns = coco.loadAnns(annIds)<br/> ax[0].imshow(I)<br/> ax[1].imshow(I)<br/> plt.sca(ax[1])<br/> coco.showAnns(anns, draw_bbox=False)</span></pre><h1 id="582e" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated">基于Google Colab的Yolov5和fastapi模型推理</h1><p id="9878" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">当您在Google Colab上运行fastapi API时，您希望将端点公开，以便您可以从Internet访问。之前你可以使用<a class="ae js" href="http://ngrok.com" rel="noopener ugc nofollow" target="_blank"> ngrok </a>如本文<a class="ae js" href="https://medium.datadriveninvestor.com/flask-on-colab-825d2099d9d8" rel="noopener ugc nofollow" target="_blank">文章</a>所述，以及<a class="ae js" href="https://colab.research.google.com/github/gstaff/flask-ngrok/blob/master/examples/flask_ngrok_example.ipynb" rel="noopener ugc nofollow" target="_blank">本colab笔记本</a>。然而，似乎不是ngrok要求你在使用它之前先注册帐户。也试过<a class="ae js" href="https://colab.research.google.com/drive/1QZywh4xiiR8BX14dThVVRaJ3c7hgJcyU#scrollTo=NyJSh3xaZUCB" rel="noopener ugc nofollow" target="_blank">这个colab笔记本</a>，但是python minimal_server.py就是挂。终于找到了<a class="ae js" href="https://blog.infuseai.io/run-a-full-tty-terminal-in-google-colab-without-colab-pro-2759b9f8a74a" rel="noopener ugc nofollow" target="_blank"> colab-xterm </a>，解决了问题，并且可以并行运行多个xterm(例如服务器和客户端)，启用第三方cookies后。</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="20d7" class="lz kn hh lv b fi ma mb l mc md">!pip install colab-xterm<br/>%load_ext colabxterm</span></pre><p id="080c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">那就跑</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="b94c" class="lz kn hh lv b fi ma mb l mc md">%xterm</span></pre><p id="6215" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我在下面跟踪了repo</p><div class="jt ju ez fb jv jw"><a href="https://github.com/WelkinU/yolov5-fastapi-demo" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">GitHub-WelkinU/yolov 5-fastapi-demo:yolov 5的FastAPI包装器</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">这是一个演示FastAPI应用程序，允许用户上传图像，使用预先训练的YOLOv5模型进行推理…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="kf l"><div class="mf l kh ki kj kf kk kl jw"/></div></div></a></div><p id="6628" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">快速回顾一下<a class="ae js" href="https://github.com/WelkinU/yolov5-fastapi-demo/blob/main/minimal_client_server_example/server_minimal.py" rel="noopener ugc nofollow" target="_blank"> FastAPI服务器代码</a>，它是一个基于Python的快速(高性能)web框架，用于构建API。</p><p id="ce61" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">典型的当你每次点击托管机器学习模型的FastAPI端点时，会发生以下情况:</p><ol class=""><li id="2d25" class="mg mh hh iy b iz ja jc jd jf mi jj mj jn mk jr ml mm mn mo bi translated">根据您的路由设置，您的请求将由FastAPI路由到由route注释的函数中</li><li id="f507" class="mg mh hh iy b iz mp jc mq jf mr jj ms jn mt jr ml mm mn mo bi translated">然后您的代码使用该模型(该模型通常是全局加载的，以避免每次请求时都加载它)</li><li id="8c9c" class="mg mh hh iy b iz mp jc mq jf mr jj ms jn mt jr ml mm mn mo bi translated">使用模型预测功能或向前传递模型以获得预测结果</li><li id="d1b1" class="mg mh hh iy b iz mp jc mq jf mr jj ms jn mt jr ml mm mn mo bi translated">将结果转换成JSON</li></ol><p id="662a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">主uvicorn服务器代码，告诉服务器监听localhost:8000并运行app实例，这是FastAPI实例。</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="6af0" class="lz kn hh lv b fi ma mb l mc md">from fastapi import FastAPI<br/>app = FastAPI()</span><span id="74cf" class="lz kn hh lv b fi me mb l mc md"># Python main entrypoint</span><span id="3435" class="lz kn hh lv b fi me mb l mc md">if __name__ == '__main__':<br/>    import uvicorn</span><span id="7bde" class="lz kn hh lv b fi me mb l mc md">    # <a class="ae js" href="https://www.uvicorn.org/settings/" rel="noopener ugc nofollow" target="_blank">APP/app_str</a> - The ASGI application to run, in the format <!-- -->"&lt;module&gt;:&lt;attribute&gt;"</span><span id="1fe8" class="lz kn hh lv b fi me mb l mc md">    app_str = 'server_minimal:app'<br/>    uvicorn.run(app_str, host='localhost', port=8000, reload=True, workers=1)</span></pre><p id="40f1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">主对象检测API端点。FastAPI用decorator告诉“/”，HTTP post组合要路由到process_home_form函数，函数可以取传入的filestream和模型名并得到预测结果，然后转换成默认要求的JSON格式，并发回。</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="ee1a" class="lz kn hh lv b fi ma mb l mc md"><a class="ae js" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.post("/")<br/>async def process_home_form(file: UploadFile = File(...), <br/>              model_name: str = Form(...)):<br/>  <br/>    '''<br/>    Requires an image file upload, model name (ex. yolov5s).<br/>    Returns: json response with list of list of dicts.<br/>      Each dict contains class, class_name, confidence, normalized_bbox<br/>    Note: Because this is an async method, the YOLO inference is a blocking<br/>    operation.<br/>    '''</span><span id="a514" class="lz kn hh lv b fi me mb l mc md">model = torch.hub.load('ultralytics/yolov5', model_name, pretrained=True, force_reload = False)</span><span id="c774" class="lz kn hh lv b fi me mb l mc md">#This is how you decode + process image with PIL<br/>    results = model(Image.open(BytesIO(await file.read())))</span><span id="a951" class="lz kn hh lv b fi me mb l mc md">    json_results = results_to_json(results,model)<br/>    return json_results</span></pre><p id="380e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果您查看<a class="ae js" href="https://github.com/WelkinU/yolov5-fastapi-demo/blob/main/minimal_client_server_example/client_minimal.py" rel="noopener ugc nofollow" target="_blank">客户端代码</a>，您会看到它正在向http://localhost:8000发送，传递模型名称和图像文件流。</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="ed24" class="lz kn hh lv b fi ma mb l mc md">import requests as r<br/>import json<br/>from pprint import pprint</span><span id="306b" class="lz kn hh lv b fi me mb l mc md">def send_request(image = '../images/zidane.jpg', model_name = 'yolov5s'):<br/>    res = r.post("<a class="ae js" href="http://localhost:8000" rel="noopener ugc nofollow" target="_blank">http://localhost:8000</a>", <br/>                    data={'model_name': model_name}, <br/>                    files = {'file': open(image , "rb")} #pass the files here<br/>                    )</span><span id="865d" class="lz kn hh lv b fi me mb l mc md">pprint(json.loads(res.text))</span><span id="3a93" class="lz kn hh lv b fi me mb l mc md">if __name__ == '__main__':<br/>    send_request()</span></pre><p id="3373" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLOv5对象检测restful API服务器。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mu"><img src="../Images/ae99c696bec89a324b1ec2cf5120799f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vcIp6sUL8n56D6uaivnd8w.png"/></div></div></figure><p id="4fb1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对象检测api客户端</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mz"><img src="../Images/67011d71520973d1de8605f685c39844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CGamQ90NwMZuGQBV3rck6g.png"/></div></div></figure><p id="865f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在现实世界中，你将构建一个具有必要依赖关系的容器镜像(例如Python运行时，fastapi(例如FastAPI，uvicorn)和YOLO(例如pytorch)需要的Python包，机器学习模型)。下面是一个示例Dockerfile文件</p><div class="jt ju ez fb jv jw"><a href="https://github.com/DanielChuDC/yolov5-fastapi/blob/main/Dockerfile" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">yolov 5-fastapi/docker file at main Daniel chudc/yolov 5-fastapi</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">此文件包含双向Unicode文本，其解释或编译可能与下面显示的不同…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="kf l"><div class="na l kh ki kj kf kk kl jw"/></div></div></a></div><h1 id="620f" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated">YOLO转移学习/定制培训</h1><p id="9ca3" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">您还希望根据自己的数据训练自己的模型，并从预先训练好的YOLO模型开始。<a class="ae js" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLO5回购</a>提供教程。要使用它，您需要以下列格式提供数据。</p><div class="jt ju ez fb jv jw"><a href="https://kikaben.com/yolov5-transfer-learning-dogs-cats/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">YOLOv5在简单的步骤中转移学习，而不会失去你的头脑- KiKaBeN</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">YOLOv5迁移学习很好地集成到Ultralytics的实现中。我们将对…进行迁移学习</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">kikaben.com</p></div></div><div class="kf l"><div class="nb l kh ki kj kf kk kl jw"/></div></div></a></div><ul class=""><li id="54e9" class="mg mh hh iy b iz ja jc jd jf mi jj mj jn mk jr nc mm mn mo bi translated">图像和标签文件夹</li></ul><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es nd"><img src="../Images/cb55fd8904e364e8cd1fea4c09b33db7.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/0*3Bmo-nebablX-XiR"/></div></figure><ul class=""><li id="f2e1" class="mg mh hh iy b iz ja jc jd jf mi jj mj jn mk jr nc mm mn mo bi translated">对于相应的图像，它需要有。标签文件夹中具有相同名称的txt，例如data/images/train/00000000009 . jpg需要包含注释的data/labels/train/00000000009 . txt</li><li id="eb0c" class="mg mh hh iy b iz mp jc mq jf mr jj ms jn mt jr nc mm mn mo bi translated">标签文件格式:每行有五个数字，第一个是类别id，其他表示边界框，每个文件可以有多行用于多个注释</li></ul><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="a2d4" class="lz kn hh lv b fi ma mb l mc md">0 0.35750000000000004 0.53875 0.463334 0.39499999999999996</span></pre><ul class=""><li id="f8d9" class="mg mh hh iy b iz ja jc jd jf mi jj mj jn mk jr nc mm mn mo bi translated">为数据和标签提供信息的训练配置文件，例如，在下面，您有数据集的路径、训练数据集的相对路径、验证和测试数据集，以及名称中的类列表</li></ul><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="2986" class="lz kn hh lv b fi ma mb l mc md">path: ../datasets/coco128  # dataset root dir<br/>train: images/train2017  # train images (relative to 'path') 128 images<br/>val:  # val images (relative to 'path') 128 images<br/>test:  # test images (optional)</span><span id="d2f1" class="lz kn hh lv b fi me mb l mc md"># Classes<br/>names:<br/>  0: person<br/>  1: bicycle<br/>  2: car<br/>  3: motorcycle<br/>  4: airplane</span></pre><p id="7733" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLOv5还将主干(提取图像特征)与头层分开。通常，在迁移学习过程中，您希望保持这些层的权重不变。有一个“冻结”参数来保持主干层冻结。训练自定义数据集的基本命令是</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="60b9" class="lz kn hh lv b fi ma mb l mc md">python train.py --img &lt;image size&gt; --batch &lt;batch size&gt; --epochs &lt;epoch&gt; --data &lt;training config file/coco128.yaml&gt; --weights &lt;pretrained model&gt; --freeze &lt;number of layers to freeze&gt;</span></pre><p id="ea91" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用定制的模型</p><pre class="lk ll lm ln fd lu lv lw lx aw ly bi"><span id="9fda" class="lz kn hh lv b fi ma mb l mc md">python detect.py --weights runs/train/exp2/weights/best.pt --img 640 --conf 0.25 --source data/images</span></pre><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es ne"><img src="../Images/038d7d30d1a57f175317b5bbe8b83bb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*qN_FoAd5NQ3-vjskkGMeyQ.jpeg"/></div></figure><p id="fa7a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">而对于一个快速启动的项目，FastAPI是可以部署机器学习模型的。在大规模生产工作负载中，需要一个成熟的模型服务框架。这将在另一篇文章中。</p><h1 id="d535" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated">附录</h1><h2 id="2b38" class="lz kn hh bd ko nf ng nh ks ni nj nk kw jf nl nm ky jj nn no la jn np nq lc nr bi translated">用于COCO格式的工具</h2><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/codable/convert-any-dataset-to-coco-object-detection-format-with-sahi-95349e1fe2b7"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">使用SAHI将任何数据集转换为COCO对象检测格式</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">读完这篇文章后，你将能够轻松地将任何数据集转换成COCO对象检测格式🚀</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="ns l kh ki kj kf kk kl jw"/></div></div></a></div><p id="8d20" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">sahi Python包可以生成COCO格式(其实是一个轻量级的视觉库，用于物体检测)</p><div class="jt ju ez fb jv jw"><a href="https://towardsdatascience.com/how-to-work-with-object-detection-datasets-in-coco-format-9bf4fb5848a4" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">如何使用COCO格式的对象检测数据集</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">一个全面的指南，以定义，加载，探索和评估对象检测数据集在COCO格式使用…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">towardsdatascience.com</p></div></div><div class="kf l"><div class="nt l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://medium.datadriveninvestor.com/how-to-create-custom-coco-data-set-for-object-detection-96ec91958f36" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">如何创建用于对象检测的自定义COCO数据集</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">之前，我们已经用Pascal VOC数据格式的自定义注释数据集训练了一个mmdetection模型。你没有…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.datadriveninvestor.com</p></div></div><div class="kf l"><div class="nu l kh ki kj kf kk kl jw"/></div></div></a></div><h2 id="be35" class="lz kn hh bd ko nf ng nh ks ni nj nk kw jf nl nm ky jj nn no la jn np nq lc nr bi translated">YOLO</h2><div class="jt ju ez fb jv jw"><a href="https://blog.roboflow.com/guide-to-yolo-models/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">你对YOLO模型家族的全面指导</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">YOLO(你只看一次)是一个计算机视觉模型家族，自从约瑟夫…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">blog.roboflow.com</p></div></div><div class="kf l"><div class="nv l kh ki kj kf kk kl jw"/></div></div></a></div><p id="ebca" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLO的历史:旧版本的YOLO基于Darknet，但是从v5开始，大多数实现都基于PyTorch。</p><div class="jt ju ez fb jv jw"><a href="https://github.com/meituan/yolov6" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">GitHub - meituan/YOLOv6: YOLOv6:一个单级对象检测框架，专用于工业…</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">论文的实现- YOLOv6:一个工业应用的单阶段目标检测框架YOLOv6是一个…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="kf l"><div class="nw l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">YOLOv6:下一代物体探测—回顾与比较</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">下一代目标探测的回顾与比较</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">towardsdatascience.com</p></div></div><div class="kf l"><div class="nx l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://machinelearningknowledge.ai/yolov6-explained-with-tutorial-and-example/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">YOLOv6用教程和例子讲解——MLK——机器学习知识</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">在本文中，我们将介绍新的对象检测模型YOLOv6，它已经在计算机中引起了轰动…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">machinelearningknowledge.ai</p></div></div><div class="kf l"><div class="ny l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://viso.ai/deep-learning/yolov7-guide/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">YOLOv7:最强大的对象检测算法(2022指南)- viso.ai</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">YOLOv7算法正在计算机视觉和机器学习社区掀起轩然大波。最新的YOLO…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">viso.ai</p></div></div><div class="kf l"><div class="nz l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/augmented-startups/top-yolo-variants-of-2021-19dddc23043c"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">2021年YOLO的顶级变体</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">目标检测的目的是用包围盒标记图像中包含目标的区域，并对它们进行分类。这个…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="oa l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/text/object_detection/yolo_v4.html" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">YOLOv4 -迁移学习工具包3.0文档</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">YOLOv4是迁移学习工具包中包含的一个对象检测模型。YOLOv4支持以下功能…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">docs.nvidia.com</p></div></div><div class="kf l"><div class="ob l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/augmented-startups/train-yolov8-on-custom-data-6d28cd348262"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">用自定义数据训练YOLOv8？</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">YOLOv8🔥在平均精度(MAP)方面创下新高，得分为53.7。</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="oc l kh ki kj kf kk kl jw"/></div></div></a></div><h2 id="651f" class="lz kn hh bd ko nf ng nh ks ni nj nk kw jf nl nm ky jj nn no la jn np nq lc nr bi translated">使用FastAPI部署机器学习模型</h2><div class="jt ju ez fb jv jw"><a href="https://towardsdatascience.com/how-you-can-quickly-deploy-your-ml-models-with-fastapi-9428085a87bf" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">如何使用FastAPI快速部署ML模型</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">如何使用这个API构建工具快速部署您的ML模型？</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">towardsdatascience.com</p></div></div><div class="kf l"><div class="od l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/@mingc.me/deploying-pytorch-model-to-production-with-fastapi-in-cuda-supported-docker-c161cca68bb8"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">在支持CUDA的Docker中使用FastAPI将PyTorch模型部署到生产环境中</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">介绍</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="oe l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://betterprogramming.pub/fastapi-best-practices-1f0deeba4fce" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">FastAPI最佳实践</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">我们在初创公司生产1.5年后开发的最佳实践和惯例的自以为是的列表。</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">better编程. pub</p></div></div><div class="kf l"><div class="of l kh ki kj kf kk kl jw"/></div></div></a></div><h2 id="4fe6" class="lz kn hh bd ko nf ng nh ks ni nj nk kw jf nl nm ky jj nn no la jn np nq lc nr bi translated">使用Python以外的语言进行对象检测</h2><div class="jt ju ez fb jv jw"><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-onnx" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">教程:使用ONNX深度学习模型检测对象。网</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">了解如何使用model预先训练的ONNX模型来检测图像中的对象。训练对象检测模型…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">docs.microsoft.com</p></div></div><div class="kf l"><div class="og l kh ki kj kf kk kl jw"/></div></div></a></div><h2 id="d6ad" class="lz kn hh bd ko nf ng nh ks ni nj nk kw jf nl nm ky jj nn no la jn np nq lc nr bi translated">YOLO迁移学习</h2><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/@Smartcow_ai/nvidia-transfer-learning-toolkit-a-comprehensive-guide-75148d1ac1b"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">Nvidia迁移学习工具包—全面指南</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">在当今世界，大多数高度优化的深度神经网络架构已经可供使用，什么…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="oh l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">迁移学习工具包-迁移学习工具包3.0文档</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">创建实验规范文件-分类规范文件</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">docs.nvidia.com</p></div></div><div class="kf l"><div class="oi l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://mingzhi2.medium.com/yolov4-transfer-learning-for-scanned-document-structure-recognition-dc3fc8bfe426" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">用于扫描文档结构识别的YOLOv4迁移学习</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">当你第一次听到“YOLO”时，你可能会直觉地想到“你只能活一次”。但它也是…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">mingzhi2.medium.com</p></div></div><div class="kf l"><div class="oj l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/train-a-custom-yolov4-object-detector-using-google-colab-61a659d4868"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">训练一个自定义的YOLOv4对象检测器(使用Google Colab)</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">(初学者教程)</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="ok l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/train-a-custom-yolov4-tiny-object-detector-using-google-colab-b58be08c9593"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">训练一个定制的yolov 4-微小物体探测器(使用Google Colab)</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">训练用于掩模检测的定制YOLO检测器</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="ol l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://github.com/edgeimpulse/yolov5" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">GitHub-Edge Impulse/yolo V5:yolo V5边缘脉冲迁移学习模型</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">这个库是一个如何将你自己的模型引入Edge Impulse的例子。这个库使用YOLOv5(一个…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="kf l"><div class="om l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://github.com/Danielskauge/yolo_transfer_learning" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">GitHub-Danielskauge/yolo _ transfer _ Learning:学习如何在yolo上用…</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="kf l"><div class="on l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://blog.ovhcloud.com/object-detection-train-yolov5-on-a-custom-dataset/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">对象检测:在自定义数据集上训练yolov 5-ovh cloud博客</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">在数据集上训练YOLO对象检测算法的指南。它基于YOLOv5开源库，由…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">blog.ovhcloud.com</p></div></div><div class="kf l"><div class="oo l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://forums.pytorchlightning.ai/t/object-detection/405" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">目标检测</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">有没有使用PtTorch Lightening实现物体检测的教程/示例，是用Faster_rcnn还是…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">forums.pytorchlightning.ai</p></div></div><div class="kf l"><div class="op l kh ki kj kf kk kl jw"/></div></div></a></div><p id="dae6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">PyTorch闪电YOLO可能还不成熟。只找到一些相关的帖子。</p><div class="jt ju ez fb jv jw"><a href="https://github.com/Lightning-AI/lightning-bolts/issues/22" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">添加yolo v3/4第22期闪电-AI/闪电-螺栓</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="kf l"><div class="oq l kh ki kj kf kk kl jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="or l kh ki kj kf kk kl jw"/></div></div></a></div></div></div>    
</body>
</html>
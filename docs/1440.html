<html>
<head>
<title>Building a Robust Model with Partial Least Squares Regression (PLS)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用偏最小二乘回归(PLS)建立稳健模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/building-a-robust-model-with-partial-least-squares-regression-pls-39fc5c47c843?source=collection_archive---------1-----------------------#2021-12-18">https://medium.com/mlearning-ai/building-a-robust-model-with-partial-least-squares-regression-pls-39fc5c47c843?source=collection_archive---------1-----------------------#2021-12-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/14d2023ec81af19eafa6ac28895f4123.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkD-zd6c_dEgQT-6nUDJlg.png"/></div></div></figure><p id="d84f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi jn translated">稳健是每个数据科学家在为分类或回归任务建立机器学习模型时想到的东西，我们所说的稳健是指他们的模型是否能够生成新的预测，这些预测可以推广到模型以前没有训练过的其他样本。换句话说，为了使线性回归有效，必须检查一些假设，并进行一些分析。在接下来的内容中，我们将处理R中的一个简单数据集，以了解如何检查这些假设的有效性，如何处理违反假设的情况，以及偏最小二乘回归如何帮助建立一个稳健的模型。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="c02f" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">目录</h1><ul class=""><li id="b8ba" class="lb lc hh ir b is ld iw le ja lf je lg ji lh jm li lj lk ll bi translated"><a class="ae lm" href="#0ac8" rel="noopener ugc nofollow">数据集</a></li><li id="de90" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#8f88" rel="noopener ugc nofollow">关联</a></li><li id="4166" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#52d2" rel="noopener ugc nofollow">线性度</a></li><li id="8c1e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#5545" rel="noopener ugc nofollow">残差的同方差</a></li><li id="b063" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#f21a" rel="noopener ugc nofollow">残差的独立性</a></li><li id="e437" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#b090" rel="noopener ugc nofollow">残差的正态性</a></li><li id="69e5" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#760c" rel="noopener ugc nofollow">有影响的值(杠杆和异常值)</a></li><li id="0c4e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#3368" rel="noopener ugc nofollow">回归变量的多重共线性</a></li><li id="0f47" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="#e0b5" rel="noopener ugc nofollow">拟合偏最小二乘回归</a></li></ul></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="0ac8" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">资料组</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/6948fb8b09e437c3a9c5f759c39ae57c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YxRbeUvwxlwuTlUE"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@elvir?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Elvir K</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f587" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将使用混凝土强度数据集；你可以从<a class="ae lm" href="https://www.kaggle.com/prathamtripathi/regression-with-neural-networking" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">这里</strong> </a>下载。</p><p id="4971" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所有数据集回归量都是连续的:</p><ul class=""><li id="32d3" class="lb lc hh ir b is it iw ix ja mb je mc ji md jm li lj lk ll bi translated">水泥</li><li id="0f8e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">高炉矿渣</li><li id="111f" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">飞灰</li><li id="c66a" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">水</li><li id="6260" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">超塑化剂</li><li id="fa10" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">粗骨料</li><li id="0f6e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">细集料</li><li id="ff6a" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">年龄</li></ul><p id="a6fb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">目标变量也是连续的:</p><ul class=""><li id="c312" class="lb lc hh ir b is it iw ix ja mb je mc ji md jm li lj lk ll bi translated">水泥的强度</li></ul><p id="9043" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们在R中加载数据集:</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="8f88" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">相互关系</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mg"><img src="../Images/365d79db7a4da6ecaf25ea4b6801d694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kHdPSXKLesvTZXCv"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@rudakov_g?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Georgy Rudakov</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="83d2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在确定变量之间的关系时，相关矩阵非常方便，它有助于发现回归变量之间的潜在共线性，并向我们显示响应变量如何与其他变量相关。现在让我们看看如何制作数据的相关矩阵，并使用R:</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/fa053fe266fbfb38ffc1cc5d83aae769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Y8qH8bCiOAVxgJ90IyTyw.png"/></div></div></figure><p id="1af3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以看到，超塑化剂和水是高度相关的，这表明调查回归之间的潜在共线性。目标可变强度与水泥、矿渣、减水剂、龄期呈正相关，与粉煤灰、水、粗骨料、细骨料呈负相关。</p><p id="1cc3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，我们将对我们的数据拟合一个普通的最小二乘模型，以获得关于它的更多信息:</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/03457882629dc3cd561dbf1f1a357b2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XviJaz_fiGqujXV5HKeZ1A.png"/></div></div></figure><ul class=""><li id="3bff" class="lb lc hh ir b is it iw ix ja mb je mc ji md jm li lj lk ll bi translated">f统计=204.3，p值&lt; 0.05，因此我们可以拒绝所有参数的零假设。</li><li id="3409" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">r平方=0.6155，因此该模型解释了61%的响应变量在其均值附近的变化。</li><li id="b2d0" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">截距、粗骨料和细骨料不显著，p值&gt; 0.05</li><li id="6459" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">粉煤灰、粗骨料和细骨料的系数为正，但这些变量与目标变量强度负相关。</li></ul></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="52d2" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">线性</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mi"><img src="../Images/aa4d48f519024ad1f8ca742bacda5067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-g3WHXIp6ldy-5kI"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@sunriseking?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sunrise King</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9cce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们必须检查的基本假设是数据的线性。因此，让我们检查残差与拟合图:</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/15b3f9815ddb8a9c638eda970c217930.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2eU-rzk8s6yfc9O--vyvGw.png"/></div></div></figure><p id="0f4f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">残差图显示，没有拟合的模式表明我们的数据是线性的。</p><h2 id="d713" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">如何处理非线性的情况？</h2><p id="9e46" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">在非线性的情况下，我们使用回归量的非线性变换，如X和log(X)…</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="5545" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">残差的同方差</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es na"><img src="../Images/384490fba83047c694a03dd853529956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qLWEJsKsCPyl_GQu"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@pritesh557?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Pritesh Sudra</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2d39" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">残差的同方差假设意味着残差的方差对于所有的观测值都是相同的。让我们用比例-位置图来检验这一假设的有效性，并用Goldfeld-Quandt检验来检验这一假设的有效性。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/cdf87152360d8e0c6d3f30cdb455d39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TH8xoKRcGLljzGT3KDxivA.png"/></div></div></figure><p id="a479" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">红线大约是水平的，这表示同质性。</p><h2 id="f7b6" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">戈德菲尔德-夸特试验:</h2><p id="dec6" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">Goldfeld-Quandt检验是一种统计检验，用于检查残差的方差是否均匀。</p><p id="31b5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Null (H0):存在同质性。</p><p id="f26f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">备选方案(H1):不存在同质性。</p><p id="7ae4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">要了解更多关于Goldfeld-Quandt测试的信息，请点击此<a class="ae lm" href="https://www.r-bloggers.com/2021/11/homoscedasticity-in-regression-analysis/" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">链接</strong> </a>。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/05c00843a015b1f966c4932d161ade7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7TzefcPcFO9l3MrcgUiAg.png"/></div></div></figure><p id="f434" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">p值大于0.05，因此我们可以接受零假设，即残差的同方差。</p><h2 id="d212" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">如何处理异方差的情况？</h2><p id="ea95" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">如果违反残差的同方差假设(存在异方差)。我们可以对响应变量(Y)或因变量(Xi)进行变换，通过使用图基的权力阶梯来选择适当的变换，以拉平方差。要了解更多关于异方差以及如何处理异方差的信息，请点击<a class="ae lm" href="https://statisticsbyjim.com/regression/heteroscedasticity-regression/" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">链接</strong> </a>。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="f21a" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">残差的独立性</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nb"><img src="../Images/897ee14d56adeb85c0a2eb67a6ce1adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ROX75xga2lboBCqp"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@sauravmahto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Saurav Mahto</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a094" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">残差的独立性假设表明残差之间没有自相关。为了检验这个假设是否成立，我们可以使用杜宾-沃森检验。</p><h2 id="df30" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">德宾-沃森试验:</h2><p id="a94b" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">简而言之，Durbin-Watson检验具有残差的自相关为0的零假设。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/f9f6e0b3a6ba557e3dddbadd393f66ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TktVSQ5hgnP0YU7QIqZ12w.png"/></div></div></figure><p id="4e6d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">p值&lt; 0.05，所以拒绝零假设，所以我们可以说我们有残差的自相关。</p><h2 id="4895" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">如何处理残差的自相关？</h2><p id="11a9" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">在自相关的情况下，我们通过第一差分(Y[i]-Y[i-1])变换目标变量Y。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="b090" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">残差的正态性</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nc"><img src="../Images/b8f74de5fc26aff7b3d02115dfb2622b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7HZZq52L80rVW6QT"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@joesvalentine?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Joes Valentine</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="dbf0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们用一个普通的Q-Q图来检验这个假设是否成立:</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/12b65b556d5bdcd507a6cb126dca80e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xC2Z3Cmma9QRDcmNv5IC0Q.png"/></div></div></figure><p id="9bd2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">残差点遵循直虚线，因此我们可以假设残差是正态分布的。</p><h2 id="308c" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">如何处理残差非正态性？</h2><p id="17b8" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">我们可以通过对响应变量y进行Box-Cox变换来解决残差的非正态性。</p><p id="70f0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">要了解更多信息，请查看此<a class="ae lm" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02104/full" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">链接</strong> </a>。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="760c" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">有影响力的价值(杠杆和异常值)</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nd"><img src="../Images/ee0743918772f6fe9106dc58967e22c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d_KphkqLezDGfa81"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@will_myers?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Will Myers</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="09fe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们的观测值具有较大的残差(异常值)或残差接近于零(杠杆)时，我们称之为有影响的值，因为它们对回归分析的结果有很大的影响，因此，我们必须检测它们，以便考虑和处理它们。</p><h2 id="13e2" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">库克的距离</h2><p id="9f5f" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">对于第I个观察值，我们在没有该观察值的情况下重新调整回归模型，然后我们计算该回归模型的系数与已经对所有观察值进行拟合的模型的系数之间的距离，以便查看当删除第I个观察值时所有拟合值改变了多少。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/4d0d53136006c6cbe521d9a18b3c8209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sho6VoLulILt65f-9atK9A.png"/></div></div></figure><p id="e7a4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">用红色突出显示的观察值是潜在的异常值。</p><h2 id="577f" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">DFBETAS</h2><p id="936e" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">DFBETA测量有和没有影响点的每个变量的每个参数估计的差异。</p><p id="8428" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">COOKD和dfbeta的联合使用:如果变量很多，我们先看有全局影响的观测值(高COOKD)，那么对于这个观测值，是哪些变量造成了这个影响(dfbeta)。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/ee99e97e2cba48da6e75e8b8ae0c4855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iypbus0SmyACeTC-3Lx08A.png"/></div></div></figure><p id="90f2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这段代码绘制了所有解释变量的DFBETAS，但是我们将只考虑四个变量(尝试自己检查其他变量的绘图)。我们可以看到，对于每个变量，都有一些观察值被突出显示为潜在的异常值，因为它们超过了DFBETAS阈值，在本例中为0.06。</p><h2 id="f88e" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">DFFITS</h2><p id="6237" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">简而言之，DFFITS是从完整数据获得的第I个拟合值和通过删除第I个观察值获得的第I个拟合值之间的比例差。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/9c3ddfb8130c32e9d5f79d6ad099d38f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tt_QUdf5VLiBIJE7MVZcjQ.png"/></div></div></figure><p id="9580" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以看到，有些观察值的DFT fit超过了阈值(在我们的例子中为0.19)，因此它们代表了需要调查的潜在异常值。</p><h2 id="0361" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">用一行代码进行强大的诊断</h2><p id="4d08" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">如果您想用一行代码运行快速诊断，以便检测有影响的值并进行其他分析，该怎么办？</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="c52e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这段代码输出了10个图，但是我们只检查其中的一个(自己运行代码并分析其余的图)。</p><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/6931e15169a01090a9783b81bd605b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*unyxjH6Rw70JA-BPEmSoqQ.png"/></div></div></figure><p id="956c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">从上面的图中，我们可以看到一些观察结果被突出显示为潜在的杠杆和潜在的异常值，因此，我们需要调查这些点。</p><h2 id="12e6" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">如何处理有影响的值(异常值和杠杆)？</h2><p id="a8dd" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">调查数据是否被错误记录(如果可能，回到数据源)。</p><ul class=""><li id="e7b0" class="lb lc hh ir b is it iw ix ja mb je mc ji md jm li lj lk ll bi translated">如果异常值不是由于转录错误造成的，那么在重新调整模型之前可能需要将其删除。</li><li id="7903" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">一般来说，应该在移除单个离群点之后重新拟合模型，因为移除一个离群点会改变拟合的模型，从而使其他点看起来与模型不太(或更多)一致。</li><li id="ef7e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">将这些异常值视为缺失值，并运行模型来预测它们(K-最近邻…)</li></ul><p id="4301" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">要了解更多信息，请访问此<a class="ae lm" href="https://www.maths.usyd.edu.au/u/UG/SM/STAT3022/r/current/Lecture/lecture08_2020JC.html#1" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">链接</strong> </a>。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="3368" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">回归变量的多重共线性</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ne"><img src="../Images/d3881c52f0302a8ded9e3117a7ab5a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uFEuORdyIrueoZs7"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@redaquamedia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Denny Müller</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="81ce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">多重共线性涉及两个以上的变量是彼此接近完美的线性组合。在多重共线性存在的情况下，回归估计是不稳定的，并且具有较高的标准误差。</p><h2 id="2794" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">差异通货膨胀系数(VIF)</h2><p id="c89c" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">简而言之，方差膨胀因子(VIF)测量模型中预测变量之间存在相关性时估计回归系数的方差膨胀的程度。如果值VIF超过5，则存在多重共线性。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/a0f32540d6978862d5c07f82ebfb4113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*1Vy_7QfhYPuWSutWPbQdww.png"/></div></figure><p id="7f56" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">水泥(和其余变量)、高炉矿渣(和其余变量)、粉煤灰(和其余变量)、水(和其余变量)、粗骨料(和其余变量)和细骨料(和其余变量)之间存在多重共线性。</p><h2 id="3957" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">条件指数和方差比例</h2><p id="2f76" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">通过找到2个或更多具有对应于大条件指数的大比例方差(. 50或更大)的变量来发现共线性。经验法则是将30或更大范围内的那些条件指数标注为大。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ng"><img src="../Images/5077a6170ec3476739ec536e6cd7f562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6ZK6EAlccPxPtWAck5pmA.png"/></div></div></figure><p id="5299" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">水泥和高炉渣是共线的，因为它们的变化比例大于0.50，条件指数超过30。</p><h2 id="608d" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">如何处理多重共线性？</h2><ul class=""><li id="8131" class="lb lc hh ir b is ld iw le ja lf je lg ji lh jm li lj lk ll bi translated">删除某些回归变量，它们是共线性的主要“原因”</li><li id="2e3e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">通过收集其他观察值来增加样本量</li><li id="6b50" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">选择回归变量</li><li id="ee25" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">使用岭回归</li><li id="dfbe" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">研究回归变量产生的主要成分</li><li id="96a0" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">使用“套索”类型的方法</li><li id="660e" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated">使用偏最小二乘回归(PLS)回归，我们将在下一节中介绍</li></ul></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="e0b5" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">拟合偏最小二乘回归</h1><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nh"><img src="../Images/917c860d4fc26650cedeeca556275b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zumMNnesvdjCSifz"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Photo by <a class="ae lm" href="https://unsplash.com/@claybanks?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Clay Banks</a> on <a class="ae lm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b072" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">偏最小二乘(PLS)回归是一种非线性模型，将待解释的变量与一组解释变量(定量或定性)相关联。PLS回归是多元线性回归和主成分分析之间的折衷。换句话说，PLS最大化了解释变量的方差，并且最大化了这些变量和响应变量之间的相关性。当存在大量具有<strong class="ir hi">多重共线性</strong>或缺失值的变量时，这很有用。要了解更多关于PLS回归的信息，请查看此<a class="ae lm" href="https://en.wikipedia.org/wiki/Partial_least_squares_regression#:~:text=Partial%20least%20squares%20regression%20(PLS,the%20predicted%20variables%20and%20the" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">链接</strong> </a>。</p><p id="bd3d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们将数据分为训练集和测试集。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="4c5f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们拟合我们的PLS回归模型。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ni"><img src="../Images/3676d339755d033e8dac2d0b6554e3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KS6jq2V2fNyw8l5ckB7ZRA.png"/></div></div></figure><p id="df7c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以看到，在我们的PLS模型中有8个组成部分，其中解释的方差百分比在最后3个组成部分中最大化。但是要小心！大量组件可能导致<a class="ae lm" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">过拟合</strong> </a>！</p><h2 id="5ea2" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">我们如何选择正确的元件数量？</h2><p id="b870" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">我们选择给出最小预测均方根误差或最小预测均方误差的分量数。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/e6177a5a9ac997501919f85e0e718d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPeDGcFAGz5qGqXAWNHKrw.png"/></div></div></figure><p id="0210" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在我们的例子中，我们可以得出这样的结论:给出最小MSEP的分量数是8。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h2 id="f643" class="mj ke hh bd kf mk ml mm kj mn mo mp kn ja mq mr kr je ms mt kv ji mu mv kz mw bi translated">参考</h2><ul class=""><li id="03cf" class="lb lc hh ir b is ld iw le ja lf je lg ji lh jm li lj lk ll bi translated"><a class="ae lm" href="https://cran.r-project.org/web/packages/olsrr/vignettes/residual_diagnostics.html" rel="noopener ugc nofollow" target="_blank">https://cran . r-project . org/web/packages/ol SRR/vignettes/residual _ diagnostics . html</a></li><li id="7fd7" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://cran.r-project.org/web/packages/olsrr/vignettes/regression_diagnostics.html" rel="noopener ugc nofollow" target="_blank">https://cran . r-project . org/web/packages/ol SRR/vignettes/regression _ diagnostics . html</a></li><li id="8959" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://cran.r-project.org/web/packages/olsrr/vignettes/influence_measures.html" rel="noopener ugc nofollow" target="_blank">https://cran . r-project . org/web/packages/ol SRR/vignettes/influence _ measures . html</a></li><li id="5c69" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://cran.r-project.org/web/packages/lmtest/lmtest.pdf" rel="noopener ugc nofollow" target="_blank">https://cran.r-project.org/web/packages/lmtest/lmtest.pdf</a></li><li id="3329" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/#influential-values" rel="noopener ugc nofollow" target="_blank">http://www . sth da . com/English/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/# influenced-values</a></li><li id="70e6" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://www.r-bloggers.com/2021/11/homoscedasticity-in-regression-analysis/" rel="noopener ugc nofollow" target="_blank">https://www . r-bloggers . com/2021/11/homoscedassity-in-regression-analysis/</a></li><li id="c9b8" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://www.maths.usyd.edu.au/u/UG/SM/STAT3022/r/current/Lecture/lecture08_2020JC.html#1" rel="noopener ugc nofollow" target="_blank">https://www . maths . usyd . edu . au/u/UG/SM/stat 3022/r/current/Lecture/Lecture 08 _ 2020 JC . html # 1</a></li><li id="fc61" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://statisticsbyjim.com/regression/heteroscedasticity-regression/" rel="noopener ugc nofollow" target="_blank">https://statistics byjim . com/regression/heteroscensity-regression/</a></li><li id="a677" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02104/full" rel="noopener ugc nofollow" target="_blank">https://www . frontier sin . org/articles/10.3389/fpsyg . 2018.02104/full</a></li><li id="e23d" class="lb lc hh ir b is ln iw lo ja lp je lq ji lr jm li lj lk ll bi translated"><a class="ae lm" href="https://en.wikipedia.org/wiki/Influential_observation" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Influential_observation</a></li></ul><div class="nj nk ez fb nl nm"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nn ab dw"><div class="no ab np cl cj nq"><h2 class="bd hi fi z dy nr ea eb ns ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nt l"><h3 class="bd b fi z dy nr ea eb ns ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nu l"><p class="bd b fp z dy nr ea eb ns ed ef dx translated">medium.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa in nm"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Progressive Image Reconstruction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">渐进图像重建</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/progressive-image-reconstruction-gan-d1f56dad573e?source=collection_archive---------7-----------------------#2022-11-23">https://medium.com/mlearning-ai/progressive-image-reconstruction-gan-d1f56dad573e?source=collection_archive---------7-----------------------#2022-11-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/04ec7de1277414628978e34ebda41153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4CzMd1ciJ4tsl0nzzJ3Rg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Image reconstruction on different kinds of edges and colour domains <a class="ae it" href="https://github.com/youyuge34/PI-REC/blob/master/files/s_banner4.jpg" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><h1 id="9c0f" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">什么是图像重建？</h1><p id="b681" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">图像重建是<strong class="ju hi">计算机视觉</strong>中的一种风格转移任务，目的是从给定的信息中重建图像缺失的部分。😄</p><p id="010e" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">近年来，在引入深度神经网络之后，重建图像的质量有了显著的提高。下面展示的是在风格转移领域表现显著的<strong class="ju hi">深度学习(DL) </strong>模型:</p><p id="3896" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><a class="ae it" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi"> Pix2Pix </strong> </a> <strong class="ju hi"> : </strong>第一个统一的图像到图像(I2I)翻译框架</p><p id="5b04" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><a class="ae it" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi">cycle gan</strong></a><strong class="ju hi">:</strong>引入了循环一致性丢失，并提供了<strong class="ju hi">两个不同域之间的双向映射</strong></p><p id="dc38" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><a class="ae it" href="https://arxiv.org/abs/1711.09020" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi">StarGAN</strong></a><strong class="ju hi">:</strong>通过应用条件标签，StarGAN可以将样式转移到<strong class="ju hi">多域</strong></p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kv"><img src="../Images/177ff73bd03f282e3d2fa9a002afc9c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Unht3O5K259oKp7TQf1Zfg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">image generated by star GAN <a class="ae it" href="https://github.com/yunjey/stargan/blob/master/jpg/main.jpg" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><h1 id="4d0d" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">渐进图像重建网络</h1><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es la"><img src="../Images/fb98b704e7c7d8c9716f9cc4aa2681e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZnOyX3DinGzOJMGRnA3Yw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://github.com/youyuge34/PI-REC/blob/master/files/banner3.png" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="d835" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">渐进图像重建网络(PI-REC)最早由尤等人(2019)在论文“<a class="ae it" href="https://arxiv.org/abs/1903.10146" rel="noopener ugc nofollow" target="_blank"> <em class="lb"> PI-REC:带边缘和色域的渐进图像重建网络</em> </a>”中提出。</p><p id="b5e8" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">PI-REC是一种<strong class="ju hi">风格的传输网络</strong>，就像以前的模型(例如cycleGAN)一样，旨在解决<strong class="ju hi">草图到图像</strong> (S2I)或<strong class="ju hi">图像到图像</strong> (I2I)的转换。然而，PI-REC与其他模型的最大区别在于，PI-REC重建的图像基于<strong class="ju hi">稀疏边缘</strong>输入，而不是<strong class="ju hi">密集边缘</strong>输入。</p><h2 id="2ebb" class="lc iv hh bd iw ld le lf ja lg lh li je kd lj lk ji kh ll lm jm kl ln lo jq lp bi translated">为什么稀疏边缘输入很重要？</h2><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lq"><img src="../Images/76b123c310b71ab23219f4c99e3e6f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GGNi4ev9cccGn_zo2OUoiQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">image generate by cycleGAN <a class="ae it" href="https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781788629416/7/ch07lvl2sec23/principles-of-cyclegan" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><p id="44d4" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">上图是使用cycleGAN进行的<strong class="ju hi">边缘到照片的转换</strong>。我们可以看到，要在左侧生成一幅向日葵图像，我们需要像右侧一样绘制边缘数据。然而，<strong class="ju hi">对于大多数人来说，用如此详细的信息画出一条边是非常困难的</strong>，尤其是对于像我这样只会画棍子的人来说。😢 😢</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/d81dd3cca028ea0e434dd6c73f5d1513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EgJ-gID-qPymrKC5s3gxsA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Image generated by a sparse edge (<a class="ae it" href="https://github.com/youyuge34/PI-REC" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="ce9e" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">PI-REC提出了一种新的方法，允许我们通过输入上图所示的<strong class="ju hi">稀疏边缘</strong>和<strong class="ju hi">色域</strong>来生成高质量的图像。</p><h1 id="2f12" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">体系结构</h1><p id="0a51" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">PI-REC是一个基于GAN的模型，有两个组件:一个<strong class="ju hi">发生器</strong>和一个<strong class="ju hi">鉴别器</strong>。</p><p id="7461" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">对于什么是甘，欢迎阅读我之前的帖子:<a class="ae it" rel="noopener" href="/@s125349666/anime-image-generation-by-style-gan-b566db5a4f2e"> <strong class="ju hi">动漫形象按风格生成甘</strong> </a> <strong class="ju hi">😄</strong></p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/6a1d4794a47601bc0873e1e6519cdea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t1CBmQAnvraCK-dfO5HfAQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">architecture of cycle gan (<a class="ae it" href="https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d" rel="noopener" target="_blank">source</a>)</figcaption></figure><p id="6628" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">PI-REC的发生器类似于<strong class="ju hi"> cycle gan </strong>和<strong class="ju hi"> U-net </strong>，由编码器、变压器和解码器模块组成。</p><p id="bddf" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">唯一不同的是作者在<strong class="ju hi">解码器</strong>中用(<strong class="ju hi">上采样+卷积</strong>)代替了<strong class="ju hi">反卷积层</strong>，解决了上采样时出现的<strong class="ju hi"> <em class="lb">棋盘格伪影</em> </strong>问题。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lt"><img src="../Images/e72fba1367a87f7b0b9efe4d40f2aa15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pHhsaAtuogKJ_n6XJ8-I3w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">discriminator of patch gan (<a class="ae it" href="https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d" rel="noopener" target="_blank">source</a>)</figcaption></figure><p id="789f" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi"> PI-REC鉴频器使用了贴片GAN结构</strong>，它输出一个N*N矩阵，而不是一个标量。</p><h1 id="5daf" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">培养</h1><p id="ea2c" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">因为<strong class="ju hi">稀疏边缘</strong>或<strong class="ju hi">色域</strong>与真实图像相比具有巨大的数据差距。对于模型来说，仅仅从边缘和色彩域学习是非常困难的。😢</p><p id="e8f0" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">因此，作者提出了一个三阶段的训练过程来解决这个问题:<strong class="ju hi"> <em class="lb">模仿阶段、生成阶段和细化阶段</em> </strong>，训练时只有一个生成器和一个鉴别器。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/948919cac35c087093d4877f82f36be7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MZq3xLWWBHKLUIsn6D4r5Q.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">the architecture of PI-REC (<a class="ae it" href="https://github.com/youyuge34/PI-REC" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><blockquote class="lv"><p id="928f" class="lw lx hh bd ly lz ma mb mc md me kp dx translated">很多有志青年艺术家一开始就被建议通过临摹大师来学习。</p><p id="d7ec" class="lw lx hh bd ly lz mf mg mh mi mj kp dx translated">在初步绘画期间，草图和背景绘画提供基本元素和结构信息。</p><p id="df44" class="lw lx hh bd ly lz mf mg mh mi mj kp dx translated">在微调阶段，作品逐渐细化细节，色彩层越来越浓，增加了光影效果。</p><p id="c95b" class="lw lx hh bd ly lz mf mg mh mi mj kp dx translated">尤等(2019)</p></blockquote></div><div class="ab cl mk ml go mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ha hb hc hd he"><p id="8b61" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">类似于这样的绘画过程，细节重建方法如下所示:</p><h2 id="c637" class="lc iv hh bd iw ld le lf ja lg lh li je kd lj lk ji kh ll lm jm kl ln lo jq lp bi translated"><strong class="ak"> <em class="mr">模仿阶段:</em> </strong></h2><p id="2aad" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在模仿阶段，模型的输入是<strong class="ju hi">边缘</strong>和<strong class="ju hi">被遮罩的地面真实图像</strong>，而输出是没有遮罩的<strong class="ju hi">地面真实图像</strong> (GT图像)。</p><p id="d299" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">通过随机覆盖地面真实图像，<strong class="ju hi">将迫使生成器学习被覆盖部分的细节</strong>。同时，网络考虑了边的输入。</p><ul class=""><li id="3cd5" class="ms mt hh ju b jv kq jz kr kd mu kh mv kl mw kp mx my mz na bi translated"><em class="lb">模仿阶段也可以被视为图像修复任务。</em></li></ul><h2 id="1794" class="lc iv hh bd iw ld le lf ja lg lh li je kd lj lk ji kh ll lm jm kl ln lo jq lp bi translated"><strong class="ak"> <em class="mr">生成阶段</em> </strong></h2><p id="b802" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在<strong class="ju hi">仿制阶段</strong>网络<strong class="ju hi">收敛</strong>后，我们将在<strong class="ju hi">同型号</strong>上继续训练下一阶段。生成阶段是训练的主要阶段，输入(<strong class="ju hi">边缘+色域</strong>)和输出<strong class="ju hi"> GT图像</strong>。</p><h2 id="982b" class="lc iv hh bd iw ld le lf ja lg lh li je kd lj lk ji kh ll lm jm kl ln lo jq lp bi translated"><strong class="ak"> <em class="mr">细化阶段</em> </strong></h2><p id="b272" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">最后，在训练<strong class="ju hi">收敛</strong>后，我们将采集生成阶段的<strong class="ju hi">输出图像(上图中的<strong class="ju hi">G1–2</strong>)作为该阶段的输入，同时输出也是GT图像。</strong></p></div><div class="ab cl mk ml go mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ha hb hc hd he"><blockquote class="nb nc nd"><p id="e7bc" class="js jt lb ju b jv kq jx jy jz kr kb kc ne ks kf kg nf kt kj kk ng ku kn ko kp ha bi translated">综上所述，我们可以看到，在培训的不同阶段，我们只是<strong class="ju hi">改变模型</strong>的输入。我们首先从<strong class="ju hi">简单任务</strong>(图像修补)开始，然后到<strong class="ju hi">主任务</strong>(图像重建)，最后我们添加一个<strong class="ju hi">细化阶段</strong>来生成更多高频细节。</p><p id="a882" class="js jt lb ju b jv kq jx jy jz kr kb kc ne ks kf kg nf kt kj kk ng ku kn ko kp ha bi translated">有了这个<strong class="ju hi">渐进策略</strong>，我们可以期待训练会变得更稳定，表现会变得更好👐</p></blockquote><h1 id="6e7e" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结论</h1><p id="9e89" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在这篇文章中，我们探索了一种新的渐进模型PI-REC，用于图像重建任务。通过应用<strong class="ju hi">三阶段</strong>训练，PI-REC成功地保证了图像的内容或风格可以容易地由输入数据控制(<strong class="ju hi">备用边缘</strong>和平坦色域)。</p><p id="0577" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">我简单介绍了PI-REC的模型结构和训练过程。不过我没有提到的是<strong class="ju hi">损失函数</strong>和<strong class="ju hi">输入数据的增强</strong>这也是PI-REC的重要部分。</p><p id="244d" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">如需了解更多信息，强烈建议阅读以下报纸:</p><ul class=""><li id="d980" class="ms mt hh ju b jv kq jz kr kd mu kh mv kl mw kp mx my mz na bi translated"><a class="ae it" href="https://arxiv.org/abs/1903.10146" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi"> <em class="lb"> PI-REC:带边缘和色域的渐进图像重建网络</em></strong></a><strong class="ju hi"><em class="lb"/></strong>🥀⏳</li><li id="7307" class="ms mt hh ju b jv nh jz ni kd nj kh nk kl nl kp mx my mz na bi translated"><a class="ae it" href="https://arxiv.org/abs/1901.00212" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi"> <em class="lb"> EdgeConnect:生成式图像修复与对抗性边缘学习</em></strong></a><strong class="ju hi"><em class="lb"/></strong>🐶 🐶</li></ul><div class="nm nn ez fb no np"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hi fi z dy nu ea eb nv ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">medium.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od in np"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Processors: CPU, GPU, FPGA, Accelerator</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理器:CPU、GPU、FPGA、加速器</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/processors-cpu-gpu-fpga-accelerator-8bfc3a73333c?source=collection_archive---------1-----------------------#2022-04-05">https://medium.com/mlearning-ai/processors-cpu-gpu-fpga-accelerator-8bfc3a73333c?source=collection_archive---------1-----------------------#2022-04-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2c9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注1 </strong>:这个帖子是一个介绍性的视频，对于没有上过任何计算机架构和硬件方面的课程，想学习的纯软件/算法/数据科学的人来说可以很有用。此外，它可以为计算机工程和科学学士学生提供信息。</p><p id="090d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注2</strong>:Xilinx公司作为全球最大的FPGA厂商之一，从<strong class="ig hi">2022年2月</strong> <strong class="ig hi"> 14日</strong>就属于AMD<a class="ae jc" href="https://www.amd.com/en/corporate/xilinx-acquisition" rel="noopener ugc nofollow" target="_blank">查看此处</a>。之所以提到它，是因为在视频中，Xilinx是作为一家独立公司提到的。</p><h1 id="39dd" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">介绍</h1><p id="5f69" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">计算机科学人士已经多次听说GPU是当前深度学习热潮的主要推动者。下面的视频回顾了标题中提到的处理器，并进一步介绍了CPU的工作原理。此外，它还区分了它们。</p><figure class="kg kh ki kj fd kk"><div class="bz dy l di"><div class="kl km l"/></div><figcaption class="kn ko et er es kp kq bd b be z dx">CPU, GPU, FPGA, Accelerator</figcaption></figure><h1 id="ee1f" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">中央处理器</h1><p id="a03e" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">CPU代表<strong class="ig hi">C</strong>entral<strong class="ig hi">P</strong>processing<strong class="ig hi">U</strong>nit。“<strong class="ig hi">中央</strong>”源于这些处理器是负责整个系统的主要设备。这意味着操作系统在它们上面运行。此外，它们还处理整个系统的数据流。当这个处理器将它的一些工作卸载给它们时，其他处理器如GPU或其他专用处理器来帮助这个处理器。</p><p id="864c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">CPU被设计成能快速执行顺序程序。与其他处理器相比，CPU可以非常快地执行顺序程序，因为它提供了高工作频率。此外，该优点的另一个原因是所采用的复杂硬件结构，例如无序执行、高速缓存层次结构、流水线和分支预测单元。</p><p id="b1b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现代CPU从存储在内存中的程序中取出几条指令，并隐式地并行执行它们。实际上，CPU利用了程序员对此一无所知的<strong class="ig hi"> I </strong>指令<strong class="ig hi">L</strong>level<strong class="ig hi">P</strong>并行性(<strong class="ig hi"> ILP </strong>)。然而，如今，如果程序员打算以并行的方式思考和开发他们的程序，CPU拥有更多的内核，并且一次可以执行多个线程。此外，与GPU等相比，CPU提供了细粒度和高效的分时技术。由于这种能力，它可以轻松地在线程之间切换，并让所有线程都满意它的执行速度。</p><h1 id="fc94" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> GPU </strong></h1><p id="9184" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">GPU代表<strong class="ig hi"> G </strong>图形<strong class="ig hi"> P </strong>处理<strong class="ig hi"> U </strong> nit。它们作为图形应用程序的协处理器出现。但是，随着2006年<strong class="ig hi"> Nvidia </strong>推出<strong class="ig hi"> CUDA </strong>和<strong class="ig hi">特斯拉架构</strong>，这些设备进入了通用计算领域。与CPU相比，这些设备包含许多更简单的内核，这使它们能够一次启动大量线程。这就是他们擅长执行并行程序的原因。它们是并行处理器，与CPU相比工作在较低的时钟频率。CPU中可用的细粒度共享和许多其他机制在这些并行处理器中是找不到的。下图显示了CPU和GPU示意图，展示了它们的架构差异。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es kr"><img src="../Images/98c1a65e701b43805ea73fe4fc432cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4juwQi8MVj-EK58W.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">CPU, GPU Schematic [<a class="ae jc" href="https://cvw.cac.cornell.edu/GPUarch/gpu_characteristics" rel="noopener ugc nofollow" target="_blank">https://cvw.cac.cornell.edu/GPUarch/gpu_characteristics</a>]</figcaption></figure><h1 id="0772" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">现场可编程门阵列 （Field Programmable Gata Array的缩写）</h1><p id="aeb5" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">FPGA代表<strong class="ig hi">F</strong>field-<strong class="ig hi">P</strong>可编程<strong class="ig hi"> G </strong> ate <strong class="ig hi"> A </strong> rray。与CPU和GPU相比，这些设备在内部电路的连接方面提供了灵活性。在FPGA中，设计者用Verilog或VHDL等硬件描述语言描述目标电路。设计者指定输入、输出以及输入将通过它变成输出的电路。最好把CPU和GPU看作是指令的执行者，它们的电路是在制造过程中固定和构建的。然而，FPGAs有一个逻辑单元网格，设计人员可以连接并构建他们想要的东西。下图显示了FPGA的架构。FPGA提供的灵活性的含义是，在FPGA内部构建一个电路后，程序员可以擦除它并构建另一个电路。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ky"><img src="../Images/2d2824768a54ea933992d5219af7a968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/0*UdwaRYprS5Gn4fc7.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx">FPGA Architecture [<a class="ae jc" href="https://allaboutfpga.com/fpga-architecture/" rel="noopener ugc nofollow" target="_blank">https://allaboutfpga.com/fpga-architecture/</a>]</figcaption></figure><h1 id="e5bc" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">加速器</h1><p id="b952" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">这些设备是实现硬件电路(如如何构建CPU和GPU电路)的专用设备，用于解决特定问题，例如深度学习推理。这些器件如何获得输入并通过电路传递这些输入由它们的设计者决定。<strong class="ig hi"> Google TPUs </strong>和<strong class="ig hi"> Cerebras WSEs </strong>是深度学习加速器的例子，旨在快速高效地运行深度学习工作负载。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es kz"><img src="../Images/e6561e99513a66a5c79b5d8102328fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QJkmgyoBKWhUKgE8.jpg"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">[<a class="ae jc" href="https://www.trendsmap.com/twitter/tweet/1394735176412921858" rel="noopener ugc nofollow" target="_blank">https://www.trendsmap.com/twitter/tweet/1394735176412921858</a>]</figcaption></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es la"><img src="../Images/e2bb525376a8b43405bcff48fe6cb0b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HGTSu9ptw92a5Lwk.jpg"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">[<a class="ae jc" href="https://cerebras.net/chip/" rel="noopener ugc nofollow" target="_blank">https://cerebras.net/chip/</a>]</figcaption></figure><h1 id="9d07" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">比较</h1><p id="2db9" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">为了从灵活性、易用性、性能和能效角度比较前面讨论的处理器，下图是一个代表性的演示。</p><p id="0307" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">灵活性意味着用户可以在处理器上运行的不同程序的数量，而不会面临任何严峻的挑战。</p><p id="89f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">易用性意味着开发一个程序所需要的努力。</p><p id="8223" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">CPU提供了最高的灵活性和易用性，因为用户可以选择像Python这样的高级语言来开发他们需要的东西。虽然他们做了更多的工作来完成计算，以尽可能实现最高的灵活性，但从性能和能效的角度来看，他们是最差的。另一方面，ASIC或加速器器件为应用构建物理电路，可提供最高的性能和功效。但是，它们是特定于应用程序的，使用它们需要知道它们到底是什么。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es lb"><img src="../Images/93f6fca2103313ac5b18ccdaf8a9bf2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g3fMETnfV4mq6v1w.jpg"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">[<a class="ae jc" href="https://www.napatech.com/road-to-fpga-reconfigurable-computing/" rel="noopener ugc nofollow" target="_blank">https://www.napatech.com/road-to-fpga-reconfigurable-computing/</a>]</figcaption></figure><div class="lc ld ez fb le lf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hi fi z dy lk ea eb ll ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lm l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ln l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">medium.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt kw lf"/></div></div></a></div></div></div>    
</body>
</html>
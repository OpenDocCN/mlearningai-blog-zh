<html>
<head>
<title>Object-Level Representation Learning for Few-Shot Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于少镜头图像分类的对象级表示学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-level-representation-learning-for-few-shot-image-classification-8ed397a2085c?source=collection_archive---------8-----------------------#2019-07-08">https://medium.com/mlearning-ai/object-level-representation-learning-for-few-shot-image-classification-8ed397a2085c?source=collection_archive---------8-----------------------#2019-07-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="ab83" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">简介</strong></h1><p id="4f76" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">人类在现实生活中表现出很强的快速理解概念的能力。基于先验知识和演绎推理，我们可以很容易地感知和识别物体的变化。因此，我们正在尝试转移这种想法，并在机器学习系统上实现它们。然而，传统的机器学习系统通常需要大量的数据和庞大的标注类来训练。因此，设计了少量学习的想法——使用少量可能类别的示例来训练模型以完成分类任务。</p><h1 id="28d2" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">方法论</strong></h1><p id="3318" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">提出了一种基于对象层次关系学习图像相似度的新方法。它被称为OLFSL，是目标级少量学习的缩写。来自两个图像的对象被比较以学习对象级别关系，从而推断对象的相似性。这个模型包括三个主要部分:<strong class="je hi">表示学习</strong> 𝔉ϕ(x】、<strong class="je hi">对象关系学习</strong> ℜθ(a,b)和<strong class="je hi">相似性学习</strong> 𝔖ϕ(r).</p><p id="4521" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">表示学习</strong>从每个输入图像中提取物体的特征。这些特征随后将被输入到<strong class="je hi">对象关系学习模块</strong>中，并生成图像级<strong class="je hi">相似性得分</strong>。最近邻搜索随后应用于目标数据集以进行少量拍摄分类。</p><p id="f328" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">它利用从已知类别中学习到的对象级关系来推断未知类别中样本的相似性。在Omniglot和MiniImagenet两个数据集上对该方法进行了评估。</p><p id="6512" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi"> Omniglot数据集</strong></p><p id="7588" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">它使用Omniglot数据集，该数据集由来自50个不同字母的1623个手绘字符组成(每个字符由不同的人绘制)。每个图像都是105×105尺寸的灰度图像。</p><p id="5fa0" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">为了澄清字符和字母表之间的区别，以英语为例，从A-Z被认为是字母表，而字母A、B … Z中的每一个都被认为是字符。因此，一个英语字母表有26个字符。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/be58619126c701defc8865381bfad47d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9DcP91TSWZJgh6mOBFQgug.jpeg"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Image source: <a class="ae kv" href="https://sorenbouma.github.io/blog/oneshot/" rel="noopener ugc nofollow" target="_blank">https://sorenbouma.github.io/blog/oneshot/</a></figcaption></figure><p id="6c34" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">Omniglot数据集可以从<a class="ae kv" href="https://github.com/brendenlake/omniglot" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><p id="0183" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">迷你图像网络数据集</strong></p><p id="85d2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这个数据集是由Ravi &amp; Larochelle提出的[1]。它由100个类组成，每个类有600个84x84彩色图像样本。点击<a class="ae kv" href="https://drive.google.com/file/d/1rV3aj_hgfNTfCakffpPm7Vhpr1in87CR/view" rel="noopener ugc nofollow" target="_blank">此处</a>可下载MiniImageNet数据集。</p><h1 id="8693" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">模型架构</strong></h1><p id="1da0" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在少镜头学习过程中，模型被输入一组带标签的图像<em class="kw"> 𝔖 = {(x1，y1)，(x2，y2)，…，(xn，yn)} </em>，其中<strong class="je hi"> <em class="kw"> x </em> </strong>表示图像的特征，<strong class="je hi"> <em class="kw"> y </em> </strong>表示类别标签。很常见的是看到术语<strong class="je hi"> <em class="kw"> N路K拍学习</em> </strong>，其中N表示每类的图像实例数，K表示类标签数。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kx"><img src="../Images/f93ee31542a0304c439ee3a9aa592578.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xU7fM7kmPsOrkUghiyq5Cw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Image source : <a class="ae kv" href="https://arxiv.org/pdf/1805.10777" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1805.10777</a></figcaption></figure><p id="e733" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">从上图可以看出，xα表示原始图像的特征，yα表示原始图像的标签。将它们送入卷积神经网络，从高维空间中提取有用的特征。随后，对象级关系学习通过成对连接对象来比较这两个输入的矢量表示。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ky"><img src="../Images/87ca776a520c0747b1f2dbcb6d7c38f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*4gBPOxwBIkOLg2YvixcVBw.png"/></div></figure><p id="189c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">然后，将每个连接的向量提供给完全连接的神经网络，以学习对象级关系。所有对象关系向量被聚集以形成图像级关系。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kz"><img src="../Images/10ee8f35e6364cae90c1fe2f6d3dd3fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*WbX9OIx6bHPHBUriFWc-Xg.png"/></div></figure><p id="3931" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">然后将图像层次关系特征向量输入全连接神经网络计算相似性得分。它用于计算向量α和向量β之间的相似性，并最终归一化为[0，1]，其中0表示它们都属于不同的类，1表示相同的类。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es la"><img src="../Images/f2724a53bf16e1a8f9f299bdba9d7afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*sLJKqUvlOVX5P7uCltwbCQ.png"/></div></figure><p id="eb6f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">对象级少数镜头学习的算法如下所示。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lb"><img src="../Images/fb08addcc2d3f67f5254e8224f0d6f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HACbCQsoBv0tUNgI2YyL0g.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Algorithm 1: Pseudocode for OLFSL</figcaption></figure><h1 id="b424" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">实验和结果</strong></h1><p id="c9ea" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在Omniglot数据集上的实验设置是用5路1射、5路5射、20路1射和20路5射来完成的。结果是600个测试集的平均值，并以95%的置信区间报告。可以看出，对于4个任务中的3个，该方法优于现有方法。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lc"><img src="../Images/1632ca80deb1c874fee0356a8e0f9b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7lVS5me-9OdsuHggohdwA.png"/></div></div></figure><p id="8f9e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">MiniImageNet上的实验设置也是类似的。可以看出，该模型也实现了比现有方法更好的改进。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es ld"><img src="../Images/fa0584573125983196223d65af70b7e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-dNKKgfQOZ9c7dGJg1rerg.png"/></div></div></figure><h1 id="448c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">参考文献</strong></h1><p id="5827" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">a.<a class="ae kv" href="https://arxiv.org/pdf/1805.10777" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1805.10777</a></p><p id="e351" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">b.<a class="ae kv" href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="noopener ugc nofollow" target="_blank">https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf</a></p><p id="62eb" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">[1]拉维、萨钦和拉罗歇尔，雨果。作为少量学习模型的最优化。在<em class="kw">2017年国际学习代表大会(ICLR) </em></p><p id="acc3" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">[2]MiniImageNet:<a class="ae kv" href="https://drive.google.com/uc?id=0B3Irx3uQNoBMQ1FlNXJsZUdYWEE&amp;export=download" rel="noopener ugc nofollow" target="_blank">https://drive.google.com/uc?id=0B3Irx3uQNoBMQ1FlNXJsZUdYWEE&amp;导出=下载</a></p></div></div>    
</body>
</html>
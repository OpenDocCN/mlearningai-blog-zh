<html>
<head>
<title>Gradient Boosting for Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于分类的梯度推进</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/gradient-boosting-for-classification-f9a93381e37c?source=collection_archive---------3-----------------------#2022-08-01">https://medium.com/mlearning-ai/gradient-boosting-for-classification-f9a93381e37c?source=collection_archive---------3-----------------------#2022-08-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="544d" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">Python中梯度增强的解释和实现</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/7a73bd1845d3015dfaee2f4f1b9259cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rA8i3sz79n1dwQVhP4lCQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@mocaandrew?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Andrew Moca</a> on <a class="ae jm" href="https://unsplash.com/s/photos/together?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d9f0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这篇博文是第二篇关于渐变提升的博文。第一章是关于回归问题；</p><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/mlearning-ai/gradient-boosting-for-regression-from-scratch-bba968c16c57"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">从零开始回归的梯度推进</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">Python中梯度增强的解释和实现</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kv l"><div class="kw l kx ky kz kv la jg km"/></div></div></a></div><p id="e00b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们将使用下面显示的虚拟数据集；</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lb"><img src="../Images/3e1d4fdf66863f3db13558abcc9d4ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*LmpdwKE8xQ766Jd1M-KCTg.png"/></div></figure><p id="53a1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在同一个回归中，我们有一个由n个观测值和目标要素组成的数据集，以及一个损失函数。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lc"><img src="../Images/a7ae2833c21f534a35aca749c378ace6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Xk09YQi6lX7TYVMgepTaw.png"/></div></figure><p id="3dbe" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于损失函数，我们需要像在逻辑回归中一样计算对数(可能性)。</p><div class="kj kk ez fb kl km"><a href="https://python.plainenglish.io/logistic-regression-from-scratch-7b707662c8b9" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">从零开始的逻辑回归</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">解释和实施</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">python .平原英语. io</p></div></div><div class="kv l"><div class="ld l kx ky kz kv la jg km"/></div></div></a></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es le"><img src="../Images/73c34d52a2085c464886dd3d07548959.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*7Mo_jvV6Ex_vkFglm99hbg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">log(likelihood of an observed data given the prediction)</figcaption></figure><p id="d364" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lf"> p </em>为预测概率，<em class="lf"> yi </em>为每次观测的目标值。在逻辑回归中，我们的目标是最大化对数(可能性)值。因为这个值越高，我们的预测就越好。如果我们要使用对数(可能性)作为损失函数，较小的值应该更合适。为此，我们将整个函数乘以-1。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lg"><img src="../Images/6c9dad63c8d9c8948b87a10851521cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*rmmXc8n3MbuqrXwBammxKg.png"/></div></figure><p id="78c9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">所以，让我们简化上面的等式:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lh"><img src="../Images/cc3f8c46e0633757941b5fee1a769b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5DAe_H-S7EXdDIyXVTvQPQ.png"/></div></div></figure><p id="2753" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们得到了一个基于赔率的简化损失函数；损失函数的导数是:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es li"><img src="../Images/0aff4ec5fdf50bbe2f966667300488c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QJGmNWXbUFQ8LzCgdT9cyg.png"/></div></div></figure><p id="dc4b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们可以在推导中同时使用odds和p。</p><p id="f8ff" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">第一步:</strong>用一片叶子初始化模型。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lj"><img src="../Images/e9c51c2be4a2bff53e53638741a7022b.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*cdBRv8SfkfD65JSdeeSW7g.png"/></div></figure><p id="cac1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">所以，我们将使用损失函数来寻找最佳的初始预测值；</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lk"><img src="../Images/382451e750d1bfb6cddc259b5c0acae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*_S0L5iVgugEZuAyCp8z5bw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Loss</figcaption></figure><p id="c91e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对损失函数求导；p= 0.67，第一个初始值= 0.69</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ll"><img src="../Images/f0c5f39765ed9fa548a26553c0f7a5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*DIvOgCQBnwdznpQtVIJENw.png"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lm"><img src="../Images/883480ca4dbca001ffe8a6dde374bd34.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*4fBKx-pZlQAP00Ehwrf30g.png"/></div></figure><p id="d5d7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">第二步:</strong>对于m=1到M:开始循环</p><p id="6b45" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">答:</strong>计算伪残差，损失函数的导数</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ln"><img src="../Images/243ef4dbfa6e6b7e70c02bb2fd38080a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*P3JIBxpdpaPgreIKpy2Jbw.png"/></div></figure><p id="9494" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">r =(易— 0.67)</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lo"><img src="../Images/1f81800ce3c6f0a9664314e4d04cb475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*FW2rQ_bZ0mijJ69UvufnNw.png"/></div></figure><p id="bef0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi"> B: </strong>将回归树拟合到每个特征，以预测残差并创建末端区域Rjm，标记叶子。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lp"><img src="../Images/fe02f02999e1f02d3837baf0cf5f20a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*4wHojgqsSRZJAIA812rHxw.png"/></div></figure><p id="7a44" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi"> C: </strong>计算新树的输出值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lc"><img src="../Images/005e99d0015303320cb84bc8a105f7ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VY7LiLwhGc-aS7CPMcQ5bw.png"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lq"><img src="../Images/1f34f5c7dc5e4531badfc18fe09b7579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lGuHy9XZgvu3GiL8ZuQ8w.png"/></div></div></figure><p id="d874" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">很难计算上述函数对γ的导数。相反，我们将使用二阶泰勒多项式与<a class="ae jm" href="https://en.wikipedia.org/wiki/Taylor_series#:~:text=Taylor%20polynomials%20are%20approximations%20of,the%20use%20of%20such%20approximations." rel="noopener ugc nofollow" target="_blank">的近似。</a></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lr"><img src="../Images/609f9d28ae4ca218a529ad24e9257006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3aScM1EBSObQKNpWbsdYPg.png"/></div></div></figure><p id="ae1b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在应用了一些微积分之后；</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ls"><img src="../Images/5b312e9208f3ce3b97300f461800c19f.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*0gPLvhmbNpT-TWJAnm4K5w.png"/></div></figure><p id="885d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们为每个叶子和残差解这个方程；</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lt"><img src="../Images/b882461382fefc32c65762458e3e6f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*ModoFPqwj8xRcw4nQ_EDjw.png"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lu"><img src="../Images/821f4263a0c36e35e2284f6a64d269f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*vysRZbGQMRGjjxtStdhEow.png"/></div></figure><p id="d543" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi"> D: </strong>对每个样本进行新的预测；(学习率=0.8)</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lv"><img src="../Images/5f15d5e3739a3e59ee168a18b2d814a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*J_DQZNZgTRa38nNMubUosA.png"/></div></div></figure><p id="98c7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">第一个样本:0.69 + 0.8 * 1.5 = 1.89是新的对数(赔率)</p><p id="26f3" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">第二个样本:0.69 + 0.8 * -0.77 = 0.07</p><p id="300f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">第三个样本:0.69 + 0.8 * -0.77 = 0.07</p><p id="329d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在我们完成了for循环的第一轮。我们将通过将m设置为2来重新开始。</p><p id="8acb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">第三步:</strong>输出Fm(x)</p><h2 id="a00f" class="lw lx hh bd ly lz ma mb mc md me mf mg jw mh mi mj ka mk ml mm ke mn mo mp mq bi translated">Python Sklearn代码</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mr ms l"/></div></figure><pre class="ix iy iz ja fd mt mu mv mw aw mx bi"><span id="9028" class="lw lx hh mu b fi my mz l na nb">Accuracy score (training): 0.873<br/>Accuracy score (validation): 0.780<br/>Confusion Matrix:<br/>[[145  16]<br/> [ 43  64]]<br/>Classification Report<br/>              precision    recall  f1-score   support<br/><br/>           0       0.77      0.90      0.83       161<br/>           1       0.80      0.60      0.68       107<br/><br/>    accuracy                           0.78       268<br/>   macro avg       0.79      0.75      0.76       268<br/>weighted avg       0.78      0.78      0.77       268</span></pre><p id="b09b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">感谢阅读。如果您有任何问题或意见，请随时写信给我！</p><h2 id="588f" class="lw lx hh bd ly lz ma mb mc md me mf mg jw mh mi mj ka mk ml mm ke mn mo mp mq bi translated">阅读更多内容…</h2><div class="kj kk ez fb kl km"><a href="https://python.plainenglish.io/decision-tree-parameters-explanations-tuning-a2b0749976e5" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">决策树参数解释</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">Sklearn的决策树参数解释</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">python .平原英语. io</p></div></div><div class="kv l"><div class="nc l kx ky kz kv la jg km"/></div></div></a></div><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/mlearning-ai/gradient-boosting-for-regression-from-scratch-bba968c16c57"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">从零开始回归的梯度推进</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">Python中梯度增强的解释和实现</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kv l"><div class="kw l kx ky kz kv la jg km"/></div></div></a></div><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/mlearning-ai/adaboost-from-scratch-f8979d961948"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">从头开始</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">AdaBoost算法的解释和实现</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kv l"><div class="nd l kx ky kz kv la jg km"/></div></div></a></div><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/@okanyenigun/scala-7-spark-introduction-e6bb908a8d1b"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">Scala #7: Spark:简介</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">Apache Spark简介</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kv l"><div class="ne l kx ky kz kv la jg km"/></div></div></a></div><h2 id="e027" class="lw lx hh bd ly lz ma mb mc md me mf mg jw mh mi mj ka mk ml mm ke mn mo mp mq bi translated">参考</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nf ms l"/></div></figure><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kv l"><div class="ng l kx ky kz kv la jg km"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Easily Scrape to Create a Twitter Dataset in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python轻松创建Twitter数据集</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/easily-scrape-to-create-a-twitter-dataset-in-python-f1949e4fb1c9?source=collection_archive---------3-----------------------#2022-10-09">https://medium.com/mlearning-ai/easily-scrape-to-create-a-twitter-dataset-in-python-f1949e4fb1c9?source=collection_archive---------3-----------------------#2022-10-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6420" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人们喜欢为数据分析或数据建模做的一个常见分析是从Twitter等社交媒体来源获取用户数据。Python中的snscrape包允许用户轻松地做到这一点。我们将通过一个例子来说明如何做到这一点。如果您想查看源代码，请使用下面的GitLab或GitHub库:</p><p id="811b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">GitLab:<a class="ae jc" href="https://gitlab.com/rshowrav/python-snscrape-tutorial" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/rshowrav/python-snscrape-tutorial</a></p><p id="4e30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">GitHub:【https://github.com/rshowrav/python-snscrape-tutorial T2】</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/469290b19f431b04453c898d233dc17d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6kgka7GXkbaVP_Rh.jpg"/></div></div></figure><h2 id="e5ea" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">snscrape是什么？</h2><p id="e2da" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">snscrape软件包允许我们浏览社交媒体服务。它允许抓取hastags、用户配置文件和搜索。这个包允许的社交媒体服务是Twitter、脸书、Instagram、Mastodon、Reddit、Telegram、VKontakte和Weibo。要更新这个包，可以在下面的GitHub库中找到它的源代码。</p><div class="kp kq ez fb kr ks"><a href="https://github.com/JustAnotherArchivist/snscrape" rel="noopener  ugc nofollow" target="_blank"><div class="kt ab dw"><div class="ku ab kv cl cj kw"><h2 class="bd hi fi z dy kx ea eb ky ed ef hg bi translated">GitHub-just another archivist/snscrape:Python中的社交网络服务scraper</h2><div class="kz l"><h3 class="bd b fi z dy kx ea eb ky ed ef dx translated">snscrape是社交网络服务(SNS)的刮刀。它抓取像用户资料、标签或搜索…</h3></div><div class="la l"><p class="bd b fp z dy kx ea eb ky ed ef dx translated">github.com</p></div></div><div class="lb l"><div class="lc l ld le lf lb lg jn ks"/></div></div></a></div><h2 id="6130" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">抓取Twitter数据</h2><p id="8ae8" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">现在让我们看看这个包如何轻松地收集Twitter数据。这个例子将通过Jupyter笔记本来完成。</p><p id="c2b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果还没有下载，第一步将是下载这个包。下面的代码将很容易做到这一点:</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="47b5" class="jp jq hh li b fi lm ln l lo lp">!pip install snscrape</span></pre><p id="1047" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是导入感兴趣的包。请注意，我们在这里引入熊猫是因为我们的理想目标是将我们的数据放在一个数据框架中。使用以下代码:</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="f79d" class="jp jq hh li b fi lm ln l lo lp">import snscrape.modules.twitter as sntwitter<br/>import pandas as pd</span></pre><p id="7859" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最初的抓取以JSON格式返回，注意我们需要一些东西来附加数据。下面的步骤将创建一个空列表来存储我们的数据。使用以下代码:</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="2958" class="jp jq hh li b fi lm ln l lo lp">twt_list = []</span></pre><p id="2cd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，必须创建一个循环来提取我们感兴趣的数据，这是使用下面的代码完成的。让我们浏览一下这部分代码。for循环定义了I和tweet，其中I是我们希望返回的tweet的数量。使用enumerate函数是因为JSON数据有键和项，而在我们的实例中，我们只想得到这些项。枚举函数内部是我们的snscrape，它收集2022年9月1日至2022年10月9日关于NFL的推文。if循环告诉我们不要超过3000条tweets，最后一步是将日期、id、内容和用户添加到我们的列表中。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="f289" class="jp jq hh li b fi lm ln l lo lp"># Using TwitterSearchScraper to scrape data and append tweets to list<br/>for i,tweet in enumerate(sntwitter.TwitterSearchScraper('NFL since:2022-09-01 until:2022-10-09').get_items()):<br/>    if i&gt;3000:#number of tweets you want to scrape<br/>        break<br/>    twt_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username])</span></pre><p id="9a31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然已经创建了数据，那么数据框架将是存储这些数据的最佳位置。使用下面的代码来实现这一点:</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="cbc0" class="jp jq hh li b fi lm ln l lo lp">user_tweets_df = pd.DataFrame(usr_twt_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])</span></pre><p id="92e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是我们的数据帧输出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/18c955801b7405a6172eacee339d9f5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-VQAWWABfAlmQAIQIdFEqA.png"/></div></div></figure><p id="1ecb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">创建数据集就是这么简单。现在让我们再看一个例子，但是这次是关于用户的。对于这个例子，我们将使用NBA。下面的代码将被使用:</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="b6b3" class="jp jq hh li b fi lm ln l lo lp"># Creating an empty list to append tweet data to<br/>usr_twt_list = []</span><span id="0054" class="jp jq hh li b fi lr ln l lo lp"># Using TwitterSearchScraper to scrape data and append tweets to list<br/>for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:NBA').get_items()): #declare a username <br/>    if i&gt;3000: #number of tweets you want to scrape<br/>        break<br/>    usr_twt_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned<br/>    <br/># Creating a dataframe from the tweets list above <br/>user_tweets_df = pd.DataFrame(usr_twt_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])</span></pre><p id="1f1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面代码中最大的变化是enumerate函数现在有一个“from:”供用户搜索。下面是输出，而不是用户名。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ls"><img src="../Images/91372fd5f773faee1f7d4a4e3ec5aa03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cOqtCEOrUtm_s8XHH9wuoQ.png"/></div></div></figure><h2 id="9115" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">结论</h2><p id="fc86" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">Python中的snscrape包简化了我们获取社交媒体数据的方式。社交媒体数据是一项有趣的分析，通常用于研究目的。我希望这个包和示例对您有所帮助。</p><p id="1c1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，我仍然是一个新的媒体作者。我感谢你能提供的任何建议和支持。反馈越多，我就越能改进要讨论的主题和各种方法，以确保我的文章真正提供有意义的见解。</p><div class="kp kq ez fb kr ks"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kt ab dw"><div class="ku ab kv cl cj kw"><h2 class="bd hi fi z dy kx ea eb ky ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kz l"><h3 class="bd b fi z dy kx ea eb ky ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="la l"><p class="bd b fp z dy kx ea eb ky ed ef dx translated">medium.com</p></div></div><div class="lb l"><div class="lu l ld le lf lb lg jn ks"/></div></div></a></div></div></div>    
</body>
</html>
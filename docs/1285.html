<html>
<head>
<title>Let’s Build A Simple Object Classification Task In PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们在PyTorch中构建一个简单的对象分类任务</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/lets-build-a-simple-object-classification-task-in-pytorch-dea3e6584dd5?source=collection_archive---------3-----------------------#2021-11-12">https://medium.com/mlearning-ai/lets-build-a-simple-object-classification-task-in-pytorch-dea3e6584dd5?source=collection_archive---------3-----------------------#2021-11-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c122" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在阅读这个故事之前，我希望你已经阅读了我之前的文章，这些文章将提供关于<a class="ae jc" rel="noopener" href="/@sandeepkirwai/understand-deep-learning-with-a-simple-exercise-pytorch-4be98cd1ca48"> <strong class="ig hi"> <em class="jd">的基本知识，通过简单的练习理解深度学习——py torch</em></strong></a><strong class="ig hi"><em class="jd"/></strong><em class="jd">和</em> <a class="ae jc" href="https://becominghuman.ai/do-you-want-to-know-how-perceptron-algorithm-works-internally-e45b757bd19d" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jd"> DL感知器工作</em> </strong> </a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/c490468774e7d2fcbe1cf885dade9d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nthMmLa9NpUkZ_8mCuw-pg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Image from Udacity Deep Learning Nano Degree Curriculum</figcaption></figure><p id="a115" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们将尝试对手写数字(MNIST数据集)进行分类。在实现对象分类模型之前，我们将首先尝试理解神经网络的几个核心概念，这将有助于我们在实现模型时理解。</p><h2 id="0108" class="ju jv hh bd jw jx jy jz ka kb kc kd ke ip kf kg kh it ki kj kk ix kl km kn ko bi translated">前馈网络</h2><p id="e722" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">如果我们试图从单词本身来理解，意思是网络谁在转发方向上工作，这包括网络输入、权重和偏差，它们将被馈送到步骤/激活功能以获得期望的输出/预测。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/ffa35de8cf97e2e207f9dd7e696df8a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HwyNMTfOsviQERqnd3HXsg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">FeedForwar pass</figcaption></figure><p id="a160" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，我们通过向网络显示真实数据的例子(这里是手写数字的图像)来训练网络，然后调整网络参数，使其近似于阶跃/激活函数。<br/>要找到这些参数，我们需要知道网络对实际输出的预测有多差。为此，我们计算一个<strong class="ig hi">损失函数</strong>(也称为成本)，一个预测误差的度量。例如，均方损失常用于回归和二元分类问题。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/9c172306d6fe2d42a67c675bb2a3732e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwJ2WTgdKg840Z3VePaWlA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Loss calculation</figcaption></figure><p id="ee3e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中n是训练样本的数量，yi是真实标签，<br/>是预测标签。</p><h2 id="3adc" class="ju jv hh bd jw jx jy jz ka kb kc kd ke ip kf kg kh it ki kj kk ix kl km kn ko bi translated">梯度下降</h2><p id="a68c" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">通过最小化关于网络参数的这种损耗，我们可以找到损耗最小并且网络能够以高精度预测正确标签的配置。我们用一个叫做<strong class="ig hi">梯度下降</strong>的过程找到这个最小值。梯度是损失函数的斜率，指向变化最快的方向。为了在最少的时间内达到最小值，我们要沿着梯度(向下)走。你可以把这想象成沿着最陡的斜坡下山。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kv"><img src="../Images/b36f6f48c25a216bc5a19d5ed05f6766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*Z7u580Cr1BvdzJYu_z740g.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">Image from Udacity Deep Learning Nano Degree Curriculum</figcaption></figure><h2 id="d118" class="ju jv hh bd jw jx jy jz ka kb kc kd ke ip kf kg kh it ki kj kk ix kl km kn ko bi translated">反向传播</h2><p id="6655" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">如果我们是建立单层，梯度下降很容易实现。然而，对于更深层次的多层神经网络来说，就像我们已经建立的那样，这就更复杂了。</p><p id="5caf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多层网络的训练是通过<strong class="ig hi">反向传播</strong>完成的，这实际上是微积分中链式法则的一个应用。在前馈通道完成后，后馈开始起作用，预测不符合预期，我们将尝试调整损失。如果我们把一个两层网络转换成一个图形表示，这是最容易理解的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kw"><img src="../Images/c2776ecea057fe7e54446df7bfee0303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_PhOCrD3sPgPKRIaTv4-Gg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Image from Udacity Deep Learning Nano Degree Curriculum</figcaption></figure><p id="46d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在网络的正向传递中，我们的数据和操作在这里是自下而上的。我们将输入𝑥通过线性变换L1，权重为W1，偏差为b1。假设，输出然后经过sigmoid操作S和另一个线性变换L2。最后，我们计算ℓ.的损失我们用这个损失来衡量网络的预测有多糟糕。目标是调整权重和偏差，使损失最小化。</p><p id="ab02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了用梯度下降来训练权重，我们通过网络反向传播损失的梯度。每个操作在输入和输出之间都有一些梯度。当我们向后发送梯度时，我们将引入的梯度与操作的梯度相乘。从数学上来说，这实际上就是用链式法则计算损耗相对于重量的梯度。</p><p id="0a38" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以最终的重量损失与初始重量的比值是这样的</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kx"><img src="../Images/cbdfc65ac612c41e59339030757b9e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*oFKtgT6ug5vF3tS_OfDfjQ.png"/></div></figure><p id="6cc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们尝试计算新更新的权重，使用具有一些学习率的梯度:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kx"><img src="../Images/6fbce38434aa664a35ae9f751f427b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*mDRm7V7fp4IBHysKFol4Cw.png"/></div></figure><p id="cfa9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">学习率α被设置为使得权重更新步长足够小，使得迭代方法稳定在最小值。</p><p id="bda9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在阅读了更多关于神经网络训练的内容后，现在我们准备开始实现我们的对象分类神经网络模型。</p><p id="cbf8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">是时候进行实际的代码实现了</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="5779" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了开始实现，我们首先需要导入torch库，并开始编写NN，我们将需要更多的支持库</p><ul class=""><li id="89ec" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">神经网络将提供神经网络结构的基本构件</li><li id="f2c3" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><code class="du lo lp lq lr b"><a class="ae jc" href="https://pytorch.org/vision/stable/index.html#module-torchvision" rel="noopener ugc nofollow" target="_blank">torchvision</a></code>包由流行的数据集、模型架构和计算机视觉的通用图像转换组成。</li><li id="005f" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">Transform也是torchvision提供的工具之一，它将用于操纵数据，并使其适合于训练。像Pytorch这样的例子只适用于张量，在这里我们可以传递给Tensor，它会将现有的输入数据类型转换为张量，规范化有助于CNN更好地执行。</li><li id="9709" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">标准化有助于获得一定范围内的数据，并减少偏斜，从而有助于更快更好地学习。此外，为了加入多个任务，我们可以使用Compose方法作为管道。</li><li id="3634" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">下一步是从torchvision加载MNIST数据集并应用定义的变换。</li><li id="d7f1" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><code class="du lo lp lq lr b">Dataset</code>存储样本及其相应的标签，<code class="du lo lp lq lr b">DataLoader</code>在<code class="du lo lp lq lr b">Dataset</code>周围包裹一个可重复标签，以便于获取样本。</li></ul><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="7bb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从神经网络模块，我们正在使用顺序的方法，就像一个管道的架构层。<br/>我在这里添加了3个隐藏层，在每层的末尾添加了激活功能。</p><p id="ab97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jd">现在</em> <strong class="ig hi"> <em class="jd">大问题，</em> </strong> <em class="jd">如何识别有多少层及其维度以及我们需要使用哪个激活函数。坦率地说，这只是一个简单的实验基础，意味着你试图从任意维度的2层开始(通常维度是28或64的乘积)，然后尝试训练模型，然后通过评估模型结果来逐渐增加或减少层数。</em></p><blockquote class="ls lt lu"><p id="3209" class="ie if jd ig b ih ii ij ik il im in io lv iq ir is lw iu iv iw lx iy iz ja jb ha bi translated"><strong class="ig hi">根据我在互联网上学习和阅读后的经验，我发现在中间隐藏层ReLU激活函数效果最好，大多数研究人员在他们发表的论文中也提到了相同的激活。<br/>现在从哪个维度开始，通常我在第一个隐藏层中选择更大的维度，比如上面我提到的784作为开始，128作为结束(两者都是28的倍数),然后我们可以分别添加更多的层。</strong></p></blockquote><p id="36e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在顺序模块中</p><ul class=""><li id="d0d2" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">nn。线性意味着简单的密集/神经网络层，其对输入数据应用线性变换:y = xA^T + b</li><li id="f3b8" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">nn。ReLU means按元素应用校正的线性单位函数:<br/> ReLU(x) = (x)^+ = max(0，x)范围从0到x</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ly"><img src="../Images/d2ea8f889106e4d4541807b21390f8ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*XCIiq90ja_BDjXlUFGURMg.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae jc" href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><ul class=""><li id="b52b" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">nn。LogSoftmax:通常对于网络最底层的任何分类问题，Softmax激活函数是给出所有类别概率的最佳组合。但是对于分类问题，LogSoftmax比普通的Softmax要好。<a class="ae jc" href="https://datascience.stackexchange.com/questions/40714/what-is-the-advantage-of-using-log-softmax-instead-of-softmax" rel="noopener ugc nofollow" target="_blank">来源</a></li><li id="fb5e" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">nn。LLLoss:对于log-softmax输出，最适合计算损失的是负对数似然损失，<code class="du lo lp lq lr b">nn.NLLLoss</code> ( <a class="ae jc" href="https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss" rel="noopener ugc nofollow" target="_blank">文档</a>)。</li><li id="4016" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">优化器:我们需要开始训练的最后一部分，是一个优化器，我们将使用它来更新梯度的权重。我们从PyTorch的<code class="du lo lp lq lr b"><a class="ae jc" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank">optim</a></code> <a class="ae jc" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank">包</a>中获得这些。例如:可以使用<code class="du lo lp lq lr b">optim.SGD</code>的随机梯度下降。</li></ul><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="92f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们提到了随机时期5意味着5次迭代将训练一个模型来学习输入模式。</p><ul class=""><li id="045d" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">从我们在上面定义的训练加载器，我们迭代图像和各自的标签</li><li id="7a0d" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">下一步是展平输入平均值，将输入转换为矢量(1维)</li><li id="b8cd" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">在开始训练之前，我们将确保优化器应该被赋值为零，所以我们增加了<code class="du lo lp lq lr b">optimizer.zero_grad()</code></li><li id="97f5" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">现在，让我们通过将图像传递到模型中来开始训练，并获得输出。</li><li id="64b4" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">根据预测产量和实际产量计算损失<code class="du lo lp lq lr b">criterion(output, labels)</code></li><li id="afde" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">计算完损失后，接下来就是启用反向传播<code class="du lo lp lq lr b">loss.bacwards()</code></li><li id="d45f" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">相应更新重量和偏差<code class="du lo lp lq lr b">optimizer.step()</code></li><li id="0514" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">门店最终损失<code class="du lo lp lq lr b">running_loss += loss.items()</code></li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lz"><img src="../Images/412c735add53c2db3378c6a73e099a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*5G9ed1Us-nhE_Z331I61rA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">training loss calculation over each epoch</figcaption></figure><p id="d4aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上面的结果中，我们可以清楚地看到，反向传播实际上是有效的，并且随着每个时代的到来，减少了训练损失。也许随着更多的纪元，损失会更接近于零(局部最小值)</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="c67e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，在对模型进行训练之后，是时候预测我们的模型是否在对数字进行分类了。</p><ul class=""><li id="1928" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">这里首先要提到的是，我们不需要反向传播<code class="du lo lp lq lr b">torch.no_grad() </code>，因为这里我们只需要根据训练好的模型进行预测</li><li id="b9a5" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">将单个图像传递给模型以获得对数概率</li><li id="1b5f" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">应用对数概率的指数得到类的实际概率</li><li id="429c" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">查看结果概率</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ma"><img src="../Images/5de72c662179bff673ca57b533356471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jVnPRHsgN5FwOKdAptOHFQ.png"/></div></div></figure><p id="2caa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">看起来很棒。我们的网络找到了模式，并以最大概率预测了正确的类<br/>这里我们尝试了仅具有几个层的简单神经网络，但是当我们将处理复杂的数据集时，那时我们将需要处理更完整的体系结构，或者我可以说已经在大数据集上训练过的transformer模型具有非常大的体系结构。<br/>主要难点在于包含GPU的大型复杂体系结构的训练时间，可能需要一天以上的时间来训练它们，因此建议将已经训练好的模型用于复杂任务。</p><p id="01b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望您已经对对象分类问题以及在Pytorch中实现它们所涉及的步骤有了相当多的了解。</p><p id="8e51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">git Repo—<a class="ae jc" href="https://github.com/sndpkirwai/deep-learning-pytorch/blob/main/intro-to-pytorch/nn-object-classification-pytorch.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/sndpkirwai/deep-learning-py torch/blob/main/intro-to-py torch/nn-object-class ification-py torch . ipynb</a></p><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms jo me"/></div></div></a></div></div></div>    
</body>
</html>
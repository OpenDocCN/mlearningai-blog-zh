<html>
<head>
<title>Simple Linear Regression Fundamentals and Modeling in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的简单线性回归基础和建模</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/simple-linear-regression-fundamentals-and-modeling-in-python-ff9d60aac48?source=collection_archive---------3-----------------------#2021-03-25">https://medium.com/mlearning-ai/simple-linear-regression-fundamentals-and-modeling-in-python-ff9d60aac48?source=collection_archive---------3-----------------------#2021-03-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="979e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博文中，我将首先尝试解释简单线性回归的基础知识。然后，我们将通过Python使用数据集构建模型。最后，我们将通过计算均方差来评估模型。让我们一步一步开始吧。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/6061121f99036a718b7fbafe9733bfc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*87aMm1RRoaxS4Sy8Q-XMDg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Resource: <a class="ae js" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Linear_regression</a></figcaption></figure><h1 id="12e9" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">什么是简单线性回归？</strong></h1><p id="9c15" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">简单线性回归是一种统计方法，可以帮助我们描述和分析两个变量(一个因变量和一个自变量)之间的关系。在另一个来源中，它被定义如下:</p><blockquote class="kw kx ky"><p id="2ddd" class="ie if kz ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated"><strong class="ig hi">简单线性回归</strong>用于估计两个定量变量之间的关系。当您想知道以下内容时，可以使用简单的线性回归:</p><p id="8a82" class="ie if kz ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">-两个变量之间的关系有多强。</p><p id="3920" class="ie if kz ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">-自变量的某一值处因变量的值。</p></blockquote><p id="4f5c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从定义中可以看出，如果我们想进行简单的线性回归计算，我们必须有一个因变量和一个自变量。</p><p id="03ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，篮球运动员的工资是因变量。同一篮球运动员的投篮成功率是自变量。球员的工资可能会根据赛季期间的投篮成功率而有所增减。我们可以这样描述从属和独立的概念。</p><p id="cb16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单线性回归的主要目的是找到表达因变量和自变量之间关系的线性函数。所以通过找到这个线性函数，我们对变量之间的关系进行建模。建模意味着用数学方法表达各种概念之间的关系。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/92ea6b310154f83c4541fd9b4f6ed705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tgz7swefVSSBYg1D7QSkJw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Resource: <a class="ae js" href="https://towardsdatascience.com/how-are-logistic-regression-ordinary-least-squares-regression-related-1deab32d79f5?gi=a006f2d79fb4" rel="noopener" target="_blank">https://towardsdatascience.com/how-are-logistic-regression-ordinary-least-squares-regression-related-1deab32d79f5?gi=a006f2d79fb4</a></figcaption></figure><blockquote class="kw kx ky"><p id="0b8e" class="ie if kz ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">一个表示为<em class="hh"> x </em>的变量被视为<strong class="ig hi">预测变量</strong>、<strong class="ig hi">解释变量</strong>或<strong class="ig hi">独立变量</strong>。</p><p id="57e3" class="ie if kz ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">另一个变量表示为<em class="hh"> y </em>，被视为<strong class="ig hi">响应</strong>、<strong class="ig hi">结果</strong>或<strong class="ig hi">依赖</strong>变量。</p></blockquote></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><p id="be67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单线性回归对数据做出一些假设。这些是:</p><ul class=""><li id="e805" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated"><strong class="ig hi">方差齐性(homscedastacy):</strong>我们预测的误差大小在自变量的值之间没有显著变化。</li><li id="d089" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated"><strong class="ig hi">观察值的独立性:</strong>数据集中的观察值是使用统计上有效的抽样方法收集的，观察值之间没有隐藏的关系。</li><li id="8d55" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated"><strong class="ig hi">正态性:</strong>数据服从正态分布。</li></ul><p id="505b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归做了一个额外的假设:</p><ul class=""><li id="0929" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated"><strong class="ig hi">自变量和因变量之间的关系是线性的:</strong>通过数据点的最佳拟合线是直线(而不是曲线或某种分组因子)。</li></ul></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><p id="3747" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们试着理解简单线性回归的数学。</p><h1 id="74d5" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">简单线性回归模型</strong></h1><p id="626b" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们知道Y是因变量，X是自变量。因此，简单线性回归模型的数学表达式如下。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ly"><img src="../Images/7393af533434808686e40044d2493071.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*NvfdwBVFeCSu66Bdv5X93A.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Simple Linear Regression Formula</figcaption></figure><ul class=""><li id="51ff" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">y →指预测值。</li><li id="69a6" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">Xi →指自变量。</li><li id="952b" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">β0 →是要在数据集中找到的参数。是指简单线性回归线与Y轴相交的点。</li><li id="77aa" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">β1 →是要在数据集中找到的参数。表示简单线性回归线的斜率。</li><li id="7188" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">ϵ →指误差项。</li></ul><p id="c8c8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">β0和β1的系数必须是最佳值，这样我们创建的模型才能给出最合适的结果。我们建立的这个模型的方程，表达了坐标平面中属于这个模型的直线。β0和β1在公式中表示如下。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lz"><img src="../Images/2f0cf7c4e529dbe307b4f5caa9924cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*tg1iXb984SITCbe-LbZIzQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Formulas of β0 and β1</figcaption></figure><p id="7332" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">公式β1是通过一些简单的导数运算计算出来的。如果想了解公式是如何计算的，可以回顾下面的文章。</p><p id="7fe9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" href="http://users.stat.ufl.edu/~winner/qmb3250/notespart2.pdf" rel="noopener ugc nofollow" target="_blank">http://users.stat.ufl.edu/~winner/qmb3250/notespart2.pdf</a></p><p id="8243" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们的目标是最小化误差项。现在让我们用Python对一个数据创建一个简单的线性回归模型。</p><h1 id="ee23" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">用Python建模</h1><p id="0797" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">现在让我们在一个样本数据集上建立一个<code class="du ma mb mc md b">Simple Linear Regression</code>模型。然后让我们计算模型的平方根，这将给出模型误差。</p><p id="c438" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，让我们导入必要的库。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="d4d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们将样本数据集从本地存储区读入一个<code class="du ma mb mc md b">DataFrame</code>。数据集的第一列中有不正确的索引数据。我们用<code class="du ma mb mc md b">iloc</code>函数从<code class="du ma mb mc md b">DataFrame</code>中排除了这一点。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="efb9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们检查数据框中的数据。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="e9bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为我们用简单的线性回归建模，我们需要一个独立变量。为此，我们选择“电视”变量。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="6f1d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们选择销售额作为因变量。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="4224" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将slreg对象定义为能够建立简单的线性回归模型。然后我们通过拟合slreg对象来建立模型。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="e2b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们建立了模型。参数β0和β1在简单线性回归中很重要。我们求出β0的系数如下。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="2f05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们发现β1参数如下。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="8a71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们需要计算模型的误差。因此，我们将有一个有意义的结果。使用Predict，我们预测实际存在于模型中的X值。我们将其保存为y_pred。稍后，如果您愿意，还可以看到前5个预测观测值。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="3096" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果，我们来计算一下均方差。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="7db3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们拥有的数据集非常简单，适合理解这个主题。因此，我们的误差值也很低。</p><p id="1d23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">数据集</strong></p><p id="395d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">https://www.kaggle.com/ashydv/advertising-dataset<a class="ae js" href="https://www.kaggle.com/ashydv/advertising-dataset" rel="noopener ugc nofollow" target="_blank"/></p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="44a8" class="jt ju hh bd jv jw mg jy jz ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq bi translated">最后</h1><p id="1f53" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">首先，我们在这篇博文中研究了什么是简单线性回归。然后我们讲了简单线性回归的假设。数学上，我们检查了这个算法的模型。最后，我们通过在Python中建立简单的线性回归模型来计算误差值。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="84ed" class="jt ju hh bd jv jw mg jy jz ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq bi translated">资源</h1><ol class=""><li id="5059" class="lk ll hh ig b ih kr il ks ip ml it mm ix mn jb mo lq lr ls bi translated"><a class="ae js" href="https://www.scribbr.com/statistics/simple-linear-regression/#:~:text=What%20is%20simple%20linear%20regression,Both%20variables%20should%20be%20quantitative" rel="noopener ugc nofollow" target="_blank">https://www . scribbr . com/statistics/simple-linear-regression/#:~:text = What % 20 is % 20 simple % 20 linear % 20 regression，既% 20 variables % 20 should % 20 be % 20 quantitative</a>。</li><li id="71b0" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb mo lq lr ls bi translated"><a class="ae js" href="https://online.stat.psu.edu/stat462/node/91/" rel="noopener ugc nofollow" target="_blank">https://online.stat.psu.edu/stat462/node/91/</a></li><li id="4d46" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb mo lq lr ls bi translated"><a class="ae js" href="https://bookdown.org/ugurdar/dogrusalregresyon/basit-do%C4%9Frusal-regresyon.html" rel="noopener ugc nofollow" target="_blank">https://book down . org/ugurdar/dograsusregression/basit-do % C4 % 9 rusal-regression . html</a></li></ol></div></div>    
</body>
</html>
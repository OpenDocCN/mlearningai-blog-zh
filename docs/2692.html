<html>
<head>
<title>Linear Regression with Gradient Descent from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始梯度下降的线性回归</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/linear-regression-with-gradient-descent-from-scratch-ef3cb1dc0c6f?source=collection_archive---------7-----------------------#2022-05-30">https://medium.com/mlearning-ai/linear-regression-with-gradient-descent-from-scratch-ef3cb1dc0c6f?source=collection_archive---------7-----------------------#2022-05-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0aa6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当有人想了解机器学习时，线性回归是最常用的算法之一。Python提供了一个方便的库来实现线性回归，比如Scikit-learn。然而，如果我们试图从零开始实现线性回归，以便深入了解它是如何工作的，这将是很好的。</p><p id="e17f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个故事中，我们将从Python中的梯度下降优化开始稍微深入一点线性回归。</p><p id="89de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">线性回归</strong></p><p id="a334" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一种监督学习方法，可以对连续变量进行建模，并基于这些变量进行预测。换句话说，我们可以绘制一个散点图，其中X为自变量，Y为因变量，最佳拟合线称为回归线。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/5b5323f7720725a49a87c2804c9d6544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/0*XMg0O4_NT4XTwotB.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Image 1. Linear Regression (Source: <a class="ae jo" href="https://vitalflux.com/linear-regression-hypothesis-testing-examples/" rel="noopener ugc nofollow" target="_blank">vitalflux</a>)</figcaption></figure><p id="8c9a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在数学形式中，它可以表示为:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/26776931a114eec30c633f8c28948324.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/0*Up-upiHkC1I35xCl.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Linear regression equation</figcaption></figure><p id="024d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中X是自变量，Y是因变量。我们可以看到方程是一条直线的方程。是的，我们的目标是找到数据的最佳拟合线。但是我们如何知道一条线是否最适合数据呢？</p><p id="ecef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了做到这一点，我们将使用<strong class="ig hi">成本函数</strong>来找出实际数据和线之间的误差。正如我们在图1中看到的，这条线在数据方面存在误差。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/c849024ecd7bc03568b36b0e0e8342ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/0*gxV14VKS0BCniPtK.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Cost function</figcaption></figure><p id="fad7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">成本函数方程将计算我们的线在数据方面产生了多少误差。我们的目标是找到最小的误差，或者换句话说，我们的目标是找到最小的成本函数。为了做到这一点，我们可以玩它的系数值。在这个例子中，我们将使用<strong class="ig hi">梯度下降</strong>来改变系数值，使得成本函数最小化。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jr"><img src="../Images/8e24c9ca3e608a559f5eabe565955922.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/0*U1Oi0L1duhD7zztW.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Gradient descent function</figcaption></figure><blockquote class="js"><p id="b5bf" class="jt ju hh bd jv jw jx jy jz ka kb jb dx translated">“知识的目的是行动，而不是知识。”——亚里士多德</p></blockquote><p id="8414" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated"><strong class="ig hi">实现</strong></p><p id="f3f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个特定的实现中，我们将使用来自Kaggle的数据，即<a class="ae jo" href="https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho?datasetId=33080&amp;sortBy=voteCount&amp;select=car+data.csv" rel="noopener ugc nofollow" target="_blank">车辆数据集</a>。这是使用过的车辆数据集，包含5个离散变量和4个连续变量。我们的目标是根据年份、当前价格、行驶公里数、燃料类型、卖方类型、变速器和车主变量来预测二手车的价格。在我们将数据输入线性回归方程之前，我们需要对它们进行预处理，以便模型能够以适当的方式消化它们。这些预处理步骤包括<strong class="ig hi">离群点剔除</strong>、离散变量的<strong class="ig hi">一键编码</strong>和连续变量的<strong class="ig hi">标准化</strong>。</p><p id="77b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们完成预处理步骤并将数据分成训练和测试数据之后，下一步是将数据输入线性回归。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kh ki l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Linear Regression with Gradient Descent</figcaption></figure><p id="170a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的函数只是我们之前讨论过的等式的代码版本。该函数取一些参数，这些参数是作为自变量的<strong class="ig hi"> X </strong>，作为因变量的<strong class="ig hi"> Y </strong>，以及用于梯度下降的<strong class="ig hi">学习率</strong>和<strong class="ig hi">迭代</strong>。换句话说，学习率表明我们想要相对于成本函数更新梯度下降多少。学习率越大，每次迭代的步长就越大(图2)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es kj"><img src="../Images/7bc703afcacaa3a4ac77341ee65e6616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YrpB22EZd7752bk9.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Image 2. Gradient Descent (Source: <a class="ae jo" href="https://www.ibm.com/cloud/learn/gradient-descent" rel="noopener ugc nofollow" target="_blank">IBM</a>)</figcaption></figure><p id="299c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个实验中，我们将使用学习率= 0.1，迭代次数= 100。模型训练是通过使用下面的代码完成的。我们还可以使用代码的最后两行绘制模型的损耗曲线。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kh ki l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Model training and plot loss curve</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ko"><img src="../Images/42a40f942d7fd250a6c19d1dcfd82bca.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*MDmGWBkm1lFtRxuYC5syYA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Loss curve</figcaption></figure><p id="39b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从损失曲线中，我们可以看到，由于我们的成本最小化，我们的模型学习得很好。我们可以推断我们的学习速度和迭代非常适合我们的问题和数据。</p><p id="a6dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们训练我们的模型之后，下一步是用测试数据评估它们。我们将使用<strong class="ig hi">平均绝对误差</strong>和<strong class="ig hi"> R </strong>。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kp"><img src="../Images/1e6d2befb6e625ce3e988d97eaa1495f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*cRYK5hQE9NZhdO1CdZkhvA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Mean Absoulte Error (MAE)</figcaption></figure><p id="8247" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> MAE </strong>是一种简单的评估方法，计算模型给出的关于数据的绝对误差。该结果将给出预测值与实际值偏差的绝对值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es kj"><img src="../Images/f92de1aa5f86d389d60ba62501ee29ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pb4A9l9IS-iHcvDO.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">R² (R-squared)</figcaption></figure><p id="9f5b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> R </strong>量化模型捕获的因变量的变化量。r通过计算所有错误预测的平方和除以目标变量平均值的平方和来获得这些值。如果我们的R值接近1，我们的模型就能做出准确的预测。对于这两个评估，我们将从scikit-learn导入函数。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="dea2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们分别在<strong class="ig hi"> 1.2315 </strong>和<strong class="ig hi"> 0.8747 </strong>得到了我们测试数据的<strong class="ig hi"> MAE </strong> ad <strong class="ig hi"> R </strong>的结果。通过使用学习率= 0.1和迭代次数= 100，这产生了良好的结果。然而，我们可以通过调整它们来玩得更多。</p><p id="256b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望这个故事能帮助你更多的理解线性回归和梯度下降。继续学习，感谢阅读！</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><p id="c568" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有的代码都可以在我的GitHub上找到。</p><div class="kx ky ez fb kz la"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hi fi z dy lf ea eb lg ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">medium.com</p></div></div><div class="lj l"><div class="lk l ll lm ln lj lo ji la"/></div></div></a></div></div></div>    
</body>
</html>
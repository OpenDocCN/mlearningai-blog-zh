<html>
<head>
<title>Neural Networks on Graphs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图上的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/neural-networks-on-graphs-e06fc7f2b934?source=collection_archive---------5-----------------------#2022-02-11">https://medium.com/mlearning-ai/neural-networks-on-graphs-e06fc7f2b934?source=collection_archive---------5-----------------------#2022-02-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="8af4" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">介绍了三种常见的图形神经网络模型——GNN、GCN、GAT</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/0229733e9cf1d72be79c77908c4c9d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkZTrgpIwYF-qCI0W8N2Ug.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@dead____artist?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Z</a> on <a class="ae jm" href="https://unsplash.com/s/photos/map?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ff5e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">神经网络可用于处理由图形自然表示的数据。这发生在许多科学和工程领域，如计算机视觉，分子化学等。</p><h1 id="8400" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">图形神经网络</h1><p id="c705" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">我们回顾的第一个变体是由一个递归架构激发的，并被命名为图形神经网络(GNN)。我们用一个例子来说明GNN是如何工作的。如图1所示，绘制了一个具有4个<strong class="jp hi">节点</strong>和4条<strong class="jp hi">边</strong>的无向图，并为每个节点和边给出了<strong class="jp hi">标签</strong>(例如<code class="du lg lh li lj b">l1</code>是节点1的标签，<code class="du lg lh li lj b">l(1,2)</code>是边1–2的标签)。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lk"><img src="../Images/cd3b3f364b38a95de8758c65118d0546.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*rUDTxtxQIsCBb6x69lKYQg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 1: Example undirected graph with labels denoted by l. (Quoted from the original paper.)</figcaption></figure><p id="bd24" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了表示这个图，作者首先为每个<strong class="jp hi">节点</strong>定义了一个<strong class="jp hi">状态</strong>T2，来表示每个节点所描述的概念。然后，为了从其邻居和相关标签中推断出<code class="du lg lh li lj b">x</code>的值，作者定义了一个<strong class="jp hi">函数</strong> <code class="du lg lh li lj b">f_w</code>，它将<em class="ll">节点</em>的标签、包含节点的<em class="ll">边的标签、其<em class="ll">邻居</em>的内部状态<code class="du lg lh li lj b">x</code>以及包含其邻居</em>的<em class="ll">边的标签作为估计<code class="du lg lh li lj b">x</code>的输入。这里可以使用神经网络。每个节点还有一个相应的输出值<code class="du lg lh li lj b">o</code>，该值由一个<strong class="jp hi">函数</strong> <code class="du lg lh li lj b">g_w</code>近似，该函数将节点<em class="ll">的内部状态<code class="du lg lh li lj b">x</code>和标签</em>作为输入。这同样可以使用神经网络来估计。</em></p><p id="eecb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然而，内部状态<code class="du lg lh li lj b">x</code>并未给出，因此为了实现良好的估计并在所有节点之间达成共识，作者从<strong class="jp hi">扩散</strong>的现象中得出直觉，并执行多个时间步长<code class="du lg lh li lj b">T</code>的扩散迭代。根据<a class="ae jm" href="https://en.wikipedia.org/wiki/Banach_fixed-point_theorem" rel="noopener ugc nofollow" target="_blank"> Banach不动点定理</a>，动力系统以指数速度快速收敛到一致。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lm"><img src="../Images/6e6d01815a92a7241dae7e509caf69ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cdFtc3Hri6SbggOrRahaCA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 2: How GNN represents the given graph, while maintaining the graph structure. (Quoted from the original paper.)</figcaption></figure><p id="f98e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了可视化，作者沿着时间轴展平了模型的迭代结构，结果如图3所示。(注意扩散是指这里的重复前馈。)这类似于经典的神经网络，因此可以通过反向传播来学习。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ln"><img src="../Images/03dbbeb5e6e427ed77462d05377dbdd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOnUCuTM-E4d0ihqK7XXUw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 3: GNN architecture when flattened along the time axis. (Quoted from the original paper.)</figcaption></figure><p id="837a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[1]然后继续证明反向传播的使用，并调查这种方法中不同操作的计算复杂性，如果感兴趣，这两者都值得进一步研究。</p><h1 id="002c" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">图形卷积网络</h1><p id="8bdf" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">我们回顾的第二个也可能是更普遍的变体，称为图卷积网络(GCN)，基于图的<strong class="jp hi">谱卷积</strong>。与GNN的递归架构不同，该架构为每层每个节点重用相同的函数<code class="du lg lh li lj b">f_w</code>，并依赖扩散机制来实现平衡，GCN为每层<code class="du lg lh li lj b">l</code>应用了具有不同权重矩阵<code class="du lg lh li lj b">W_l</code>的卷积。</p><p id="08a4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">数学公式由等式1概括，其中<code class="du lg lh li lj b">H_l</code>是层<code class="du lg lh li lj b">l</code>的<strong class="jp hi">激活</strong>，<code class="du lg lh li lj b">A</code>是图的<a class="ae jm" href="https://en.wikipedia.org/wiki/Adjacency_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">邻接矩阵</strong> </a>，<code class="du lg lh li lj b">DAD</code>构造用于谱卷积中使用的<a class="ae jm" href="https://en.wikipedia.org/wiki/Laplacian_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">图拉普拉斯</strong> </a>计算，<code class="du lg lh li lj b">W_l</code>是如前所述的<strong class="jp hi">权重</strong>矩阵，σ表示<strong class="jp hi">激活</strong>函数(例如tanh</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lo"><img src="../Images/818f8a6f65b5212b65841cfa1f705d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*SP2zi3biqvv--tkHhPOGjw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Equation 1: Formulation of the graph convolutional network.</figcaption></figure><p id="a114" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">图4展示了GCN的可视化描述。在这个例子中，在输入层，有4个节点，每个节点取维数为C的输入向量，它们一起形成初始激活<code class="du lg lh li lj b">H_0</code>。在通过几个隐藏层之后，激活被转换成输出层节点<code class="du lg lh li lj b">Z_i</code>上的值，每个维度<code class="du lg lh li lj b">F</code>。然后将这些标签与部分标签<code class="du lg lh li lj b">Y_i</code>进行比较，以生成模型训练的损失。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lp"><img src="../Images/04439dcf0d0f2baefed74ea8fdcc57ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eywXLpO_jwxdI8hL3Vlcsw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 4: Graphical explanation of the graph convolutional network model. (Quoted from the original paper.)</figcaption></figure><p id="4040" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[2]还包含了对等式1背后动机的精彩解释，以及针对不同基准的实验，值得一读。</p><h1 id="7444" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">图形注意网络</h1><p id="c9dc" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">尽管它们具有优越的实际性能，但是上面提到的像GCN这样的谱方法依赖于拉普拉斯特征基，而拉普拉斯特征基依赖于<strong class="jp hi">图结构</strong>。因此，在特定结构<strong class="jp hi">上训练的模型不能</strong>直接应用于具有不同结构的图。相反，非谱方法，如图形注意网络(GAT)，没有这样的限制。更具体地说，GAT采用一种<strong class="jp hi">自我关注</strong>机制，通过关注其邻居来计算图中每个节点的隐藏表示。</p><p id="1f46" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">等式2示出了GAT中单头图注意力层的公式，其中α是节点<code class="du lg lh li lj b">i</code>和节点<code class="du lg lh li lj b">j</code>之间的归一化<strong class="jp hi">注意力系数</strong>，<code class="du lg lh li lj b">W</code>是该层的<strong class="jp hi">权重矩阵</strong>，<code class="du lg lh li lj b">h</code>是该层的输入，而虚线<code class="du lg lh li lj b">h</code>是输出。注意，图的结构信息可以通过<strong class="jp hi">屏蔽掉α中的非邻居注意力权重</strong>来注入(这是作者在他们的实验中所做的)。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lq"><img src="../Images/e96f654d6ec8c63b3a65a8627c7f62dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*QBMZbcibKYlU3cRCG7qbDA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Equation 2: Formulation of a single-head graph attentional layer used in a graph attention network.</figcaption></figure><p id="a7c0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">图5中示出了注意力权重计算的示例，包括总体<a class="ae jm" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> softmax </a>、LeakyReLU 激活和串联的线性变换激活向量的线性变换。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lr"><img src="../Images/c145423f307209ce11f45d2b41ee1e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*347Z0jZZZau6W2NLnj8M7Q.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 5: Example implementation of the attention mechanism. (Quoted from the original paper.)</figcaption></figure><p id="d5fd" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">作者还将等式2中的公式扩展到多头注意力，这有助于学习过程的稳定。这在图6中用图形描述。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ls"><img src="../Images/bdb01666bdb05faae679b769e685117d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*jAm100nr8dZpigsVje8UGw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 6: An illustration of multi-head attention (with K = 3 heads) by node 1 on its neighborhood. Different arrow styles and colors denote independent attention computations. The aggregated features from each head are concatenated or averaged to obtain the output vector. (Quoted from the original paper.)</figcaption></figure><p id="970a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然后，可以通过堆叠这些图形注意层并用反向传播进行训练来构建整体模型。</p><h1 id="a7ec" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">结论</h1><p id="96f1" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">我们回顾了3个感兴趣的图形神经网络结构，希望能让你了解如何分析图形结构的数据。其他方法也存在，如GraphSAGE⁴，我们也鼓励我们的读者看一看原始论文中对动机和证据的详细解释。如果您对实现上面提到的模型感兴趣，论文中通常会提供原始代码，下面是一个使用TDS的PyTorch的示例。</p><div class="lt lu ez fb lv lw"><a href="https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8" rel="noopener follow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">PyTorch和PyTorch Geometric图形神经网络实践</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">在我的上一篇文章中，我介绍了图形神经网络(GNN)的概念和它的一些最新进展。自从…</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">towardsdatascience.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk jg lw"/></div></div></a></div><p id="7ae0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">感谢您的阅读，并请在下方留下评论:)</p></div><div class="ab cl ml mm go mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ha hb hc hd he"><p id="cf51" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[1]斯卡塞利，弗兰科，等.“图形神经网络模型”IEEE神经网络汇刊20.1(2008):61–80。</p><p id="8f30" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[2]基普夫、托马斯·n和马克斯·韦林。"图卷积网络的半监督分类."<em class="ll"> arXiv预印本arXiv:1609.02907 </em> (2016)。</p><p id="44eb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[3] Velickovic，Petar等人，“图形注意网络”<em class="ll">统计</em> 1050 (2017): 20。</p><p id="aaff" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[4]汉密尔顿、威尔、之桃·英和朱尔·莱斯科维奇。"大型图上的归纳表示学习."<em class="ll">神经信息处理系统进展</em> 30 (2017)。</p><div class="lt lu ez fb lv lw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">medium.com</p></div></div><div class="mf l"><div class="ms l mh mi mj mf mk jg lw"/></div></div></a></div><p id="4b72" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">🔵<a class="ae jm" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"> <strong class="jp hi">成为作家</strong> </a></p></div></div>    
</body>
</html>
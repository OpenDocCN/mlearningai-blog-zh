<html>
<head>
<title>SimSiam: your go-to representation learning model for invariant features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SimSiam:不变特征的首选表示学习模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/simsiam-your-go-to-representation-learning-model-for-invariance-features-74b907106d6?source=collection_archive---------2-----------------------#2021-10-01">https://medium.com/mlearning-ai/simsiam-your-go-to-representation-learning-model-for-invariance-features-74b907106d6?source=collection_archive---------2-----------------------#2021-10-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a145" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">外卖:</strong></p><ul class=""><li id="85f9" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">暹罗模型是一种自我监督的表示学习模型。</li><li id="4eeb" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><a class="ae jq" href="https://arxiv.org/pdf/2011.10566.pdf" rel="noopener ugc nofollow" target="_blank">简单的连体网络</a>(公平地说)可以学习有意义的表示，而不需要使用:负样本对、大批量或动量编码器。</li><li id="eb1a" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">根据经验，停止梯度操作有助于防止崩溃。</li></ul><p id="6451" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">表征学习是对事物进行编码。我们希望利用丰富的未标记数据来进行预训练，然后执行下游任务。暹罗网络对输入数据(通常是图像)进行编码，方法是在给定原始数据的不同扩充的情况下，强制模型识别相同的对象。</p><h2 id="77eb" class="jr js hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated">感应偏差</h2><p id="ee80" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">对于那些不熟悉机器学习中的偏差的人来说，它是模型无法完全捕捉观察到的数据的模式。这里有一个著名的偏差-方差权衡，我们无法同时实现低偏差和低方差。</p><p id="7805" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">归纳偏差是我们基于领域知识引入的，以更好地将我们的模型推广到看不见的数据。</p><h2 id="a49a" class="jr js hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated">不变性</h2><p id="d334" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">这种不变性与偏差-方差权衡无关。在分类任务中，当一个模型可以将一个对象识别为一个对象时，我们说它具有不变的结构，即使当外观以某种方式变化时。我们以猫vs狗的分类器为例。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kr"><img src="../Images/a32ec491e0fd39cc5f12e97afee3b920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gEQyY_795l2JgPyYQd_zuQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">A cat rotated is still a cat. <a class="ae jq" href="https://www.animalshq.com/are-siamese-cats-friendly/" rel="noopener ugc nofollow" target="_blank">Link</a></figcaption></figure><p id="2050" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们希望任何分类模型都能识别物体，尽管猫在照片中可能有各种姿势。</p><p id="7e4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">普通的CNN模特是如此的“愚蠢”,如果他们只看到了左边的猫，他们就认不出右边的猫。我们通过对原始图片进行数据扩充来解决这个问题，即充分旋转或翻转原始图片(尽管非常昂贵)来教会我们的模型标签“猫”的意思。</p><h2 id="5a11" class="jr js hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated">暹罗网络</h2><p id="ddf8" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">连体网络是比较实体的通用模型。它们的应用包括签名和人脸验证、跟踪、一次性学习等。最重要的是，暹罗网络可以自然地为建模不变性引入归纳偏差。(惊喜！)</p><p id="52ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我看过脸书人工智能研究所(FAIR)的研究人员最近完成的一篇论文，他们在论文中提供了一个更简单的版本，称为SimSiam，并反驳了相关工作中一些不必要的模块。这里我只介绍暹罗建筑。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lh"><img src="../Images/2658a2fb81f44773eb61229d7f27e830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88yuPy4k6H8A8xiJi4FsGQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">SimSiam architecture. <a class="ae jq" href="https://arxiv.org/pdf/2011.10566.pdf" rel="noopener ugc nofollow" target="_blank">Link</a></figcaption></figure><p id="3ec7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给定一幅图像，我们创建两个增强视图，并用相同的编码器网络(主干加投影MLP)处理这两个版本。预测器是另一个MLP，并且在另一侧应用停止梯度操作。最后我们将相似性最大化。</p><p id="9d52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里的主干模型是ResNet-50。预测器中的MLP维数低于编码器中的MLP维数。因此，它同时充当“匹配器”和瓶颈。</p><p id="477f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们最小化负余弦相似性以优化参数:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es li"><img src="../Images/5e3c9d8ee508dca8b234b4b78e546ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*5mi30bUJyQYMxyKO01j5-A.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">l is the output of the left encoder, while r is the output of the right encoder.</figcaption></figure><p id="09b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了提高精度，作者引入了对称损失。但总的来说，整个模型就是这样。暹罗网络有许多变体，其比较如下所示。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lj"><img src="../Images/2bd80c8eccc02751cc70bbc52defb1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ENyz8VIZkse_dcv0Tjb7WQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Comparisons on ImageNet linear classification. All are based on ResNet-50 pre-trained with two 224×224 views. Evaluation is on a single crop. <a class="ae jq" href="https://arxiv.org/pdf/2011.10566.pdf" rel="noopener ugc nofollow" target="_blank">Link</a></figcaption></figure><p id="1527" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它只需要每批256个，并在100个时期达到最佳结果。本文阐述了该SimSiam架构下可能的优化过程，并提供了概念验证。请随意查看这里的。</p><h2 id="6cdb" class="jr js hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated">杂念</h2><p id="f578" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我的想法仅仅是未经证实的理解和猜测。在<a class="ae jq" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> SimCLR </a>架构中，相似性和不相似性的度量更加直观，也称为对比学习。但是这有点落入旧的陷阱，你必须定义事物来告诉模型什么是不同的，什么不是。(而且是被辛暹打败的)</p><p id="e54c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">SimSiam能够以简单的MLP可以定位(通过映射)增强对象的方式来约束潜在空间编码。在论文中，预编码器增强是随机的(官方<a class="ae jq" href="https://github.com/facebookresearch/simsiam" rel="noopener ugc nofollow" target="_blank">报告</a>待读)。在我看来，等方差的约束是消除相异度量的关键。</p><h2 id="1710" class="jr js hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated">参考资料:</h2><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/2011.10566" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">探索简单的连体表示学习</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">暹罗网络已经成为各种无监督视觉表示模型的常见结构…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb lb ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/2002.05709" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">视觉表征对比学习的简单框架</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">本文介绍了SimCLR:一个简单的视觉表征对比学习框架。我们最近简化了…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div><div class="lw l"><div class="mc l ly lz ma lw mb lb ln"/></div></div></a></div></div></div>    
</body>
</html>
# 检索增强型变形金刚:DeepMind 论文摘要

> 原文：<https://medium.com/mlearning-ai/retrieval-enhanced-transformers-deepmind-paper-summary-efc2653e64b4?source=collection_archive---------4----------------------->

上个月(2021 年 12 月 8 日) [DeepMind 发表了一篇论文](https://arxiv.org/abs/2112.04426)，其中他们展示了一个聪明的技巧，让 transformer 模型在语言建模任务中表现更好，而不必使用最近模型使用的那么多参数。这是非常有趣的，因为这个领域的许多进展都来自于把模型做得更大和投入更多的计算能力。这很好，但这意味着没有[数百万美元用于培训模型的团体](https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/)更难与拥有资源的大型行业研究实验室竞争…
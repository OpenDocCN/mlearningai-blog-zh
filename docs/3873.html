<html>
<head>
<title>Lasso Regression and Hyperparameter tuning using sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用sklearn进行Lasso回归和超参数调整</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/lasso-regression-and-hyperparameter-tuning-using-sklearn-885c78a37a70?source=collection_archive---------1-----------------------#2022-11-02">https://medium.com/mlearning-ai/lasso-regression-and-hyperparameter-tuning-using-sklearn-885c78a37a70?source=collection_archive---------1-----------------------#2022-11-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="7fb7" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="de36" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">深度学习模型要求高端GPU在合理的时间内接受大数据训练，包括财务和计算。这些GPU非常昂贵，但没有它们，将深度网络训练到高性能是不可能的。快速CPU、固态硬盘存储和快速大容量RAM都是有效使用此类高端GPU所必需的。经典的ML算法，如线性或Lasso回归，可以用一个像样的CPU来训练，而不需要尖端的硬件。因为它们的计算成本更低，所以允许我们更快地迭代，在更短的时间内尝试更多的技术。</p><p id="449c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">为了探索关于回归模型的更多信息，我们使用Lasso回归和超参数调整建立了一个体脂预测模型。我们在使用sklearn完成数据清理、特征工程、数据可视化和模型评估等任务的同时，也在做所有这些工作。</p><h1 id="8be2" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">什么是套索回归？</h1><p id="4405" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">最小绝对收缩和选择操作符缩写为“套索”套索回归是一种正则化。它比回归方法更适合于更精确的预测。该模型利用收缩，收缩是数据值向称为平均值的中心点收缩的过程。L1正则化用于套索回归。当有许多特征时使用它，因为它自动执行特征选择。Lasso回归的主要目的是通过对这些系数应用惩罚来找到最小化误差平方和的系数。</p><h2 id="124d" class="kf if hh bd ig kg kh ki ik kj kk kl io jn km kn is jr ko kp iw jv kq kr ja ks bi translated">套索回归模型</h2><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es kt"><img src="../Images/11f3ad00ffc9ac181ad084760abda27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DGroMFbzoZ2zCMqH"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.1</figcaption></figure><ul class=""><li id="cbb5" class="lj lk hh je b jf ka jj kb jn ll jr lm jv ln jz lo lp lq lr bi translated">λ表示收缩量。</li><li id="669f" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">λ = 0表示考虑了所有特征，这相当于线性回归，其中仅考虑残差平方和来构建预测模型</li><li id="95ec" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">λ = ∞表示不考虑任何特征，即当λ接近无穷大时，它会消除越来越多的特征</li><li id="b833" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">偏差随着λ的增加而增加</li><li id="23e1" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">方差随着λ的减小而增加</li></ul><h2 id="74e9" class="kf if hh bd ig kg kh ki ik kj kk kl io jn km kn is jr ko kp iw jv kq kr ja ks bi translated">描述数据集</h2><p id="349a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">图1.2 </strong>简要概述了所提供的数据集。存在的特征总数是18。存在的实例数量为252，平均体脂百分比为19.1%。在研究了数据集之后，我们可以看到未命名的:0列只是用于索引，对于估计身体脂肪来说不是一个好的特性，因此它被放弃了。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lx"><img src="../Images/5f2bee974aa46dd602607f77a21fe2e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i0olcxGr-MNM2HvT"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.2</figcaption></figure><h1 id="ddce" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">数据预处理</h1><p id="070b" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">规范化是一个广义的术语，指的是变量的缩放。缩放将一组变量转换成具有相同数量级的另一组变量。因为它通常是线性变换，所以不影响特征的相关性或预测能力。</p><p id="1933" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">为什么标准化我们的数据是必要的？这是因为特性的数量级会影响某些模型的性能。例如，如果一个要素的数量级等于1000，而另一个要素的数量级等于10，则一些模型可能“认为”一个特征比另一个特征更重要。数量级没有告诉我们任何关于预测能力的信息，因此它是有偏差的。我们可以通过改变变量使它们具有相同的数量级来消除这种偏差。</p><p id="f795" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">标准化和规范化是这些转换中的两种，它们将每个变量转换为0-1区间(将每个变量转换为0均值和单位方差变量)。理论上，标准化优于规范化，因为它不会导致变量的概率分布在异常值出现时缩小。但是对于给我们的数据集，我们使用MinMaxScaler得到了比StandardScaler更好的RMSE分数，这表明了更好的拟合。两个结果的比较如图1.3所示。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ly"><img src="../Images/e95e8d098bde0be5059c85d7cc123e13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GXnBh9bdbKY7E8Ei"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.3</figcaption></figure><p id="5f34" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，对于数据预处理，我们使用了MinMaxScaler，它单独缩放和转换每个特征，以便它落在训练集的给定范围内，例如在0和1之间。该变换由下式给出:</p><pre class="ku kv kw kx fd lz ma mb mc aw md bi"><span id="ccca" class="kf if hh ma b fi me mf l mg mh">X_std = (X — X.min(axis=0)) / (X.max(axis=0) — X.min(axis=0)) X_scaled = X_std * (max — min) + min</span></pre><p id="f34a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">下面的代码块描述了如何使用MinMaxScaler来规范化我们的数据。</p><pre class="ku kv kw kx fd lz ma mb mc aw md bi"><span id="b980" class="kf if hh ma b fi me mf l mg mh">from sklearn.preprocessing import MinMaxScaler<br/>def scale_numerical(data):<br/> scaler = MinMaxScaler()<br/> data[data.columns] = scaler.fit_transform(data[data.columns])</span></pre><h1 id="e495" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">构建模型</h1><p id="24dc" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们同时使用了线性回归和Lasso回归模型来有效地衡量这两种模型之间的差异。对于Lasso回归，我们使用了100个alpha参数，并将其输入GridSearchCV进行超参数调整。</p><pre class="ku kv kw kx fd lz ma mb mc aw md bi"><span id="1419" class="kf if hh ma b fi me mf l mg mh">from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error</span><span id="e3f3" class="kf if hh ma b fi mi mf l mg mh">def construct_model():<br/> # the list of classifiers to use<br/> regression_models = [<br/> LinearRegression(),<br/> Lasso(),<br/> ]</span><span id="1c2f" class="kf if hh ma b fi mi mf l mg mh">linear_model_parameters = {}</span><span id="2a03" class="kf if hh ma b fi mi mf l mg mh">lasso_parameters = {<br/> ‘alpha’: np.arange(0.00, 1.0, 0.01)<br/> }</span><span id="2f78" class="kf if hh ma b fi mi mf l mg mh">parameters = [<br/> linear_model_parameters,<br/> lasso_parameters<br/> ]</span><span id="ac51" class="kf if hh ma b fi mi mf l mg mh">data[‘estimators’] = []</span><span id="c75a" class="kf if hh ma b fi mi mf l mg mh"># iterate through each classifier and use GridSearchCV<br/> for I, regressor in enumerate(regression_models):<br/>   clf = GridSearchCV(regressor, # model<br/>     param_grid = parameters[i], # hyperparameters<br/>     scoring=’neg_mean_absolute_error’, # metric for scoring<br/>     cv=10,<br/>     n_jobs=-1, error_score=’raise’, verbose=3)<br/>   clf.fit(X_train, y_train)<br/>   # add the clf to the estimators list<br/>   data[‘estimators’].append((regressor.__class__.__name__, clf))</span></pre><h2 id="5d12" class="kf if hh bd ig kg kh ki ik kj kk kl io jn km kn is jr ko kp iw jv kq kr ja ks bi translated">交叉验证和GridSearchCV</h2><p id="1f6e" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">交叉验证是一种用于估计机器学习模型性能(或准确性)的统计方法。它用于防止预测模型中的过度拟合，尤其是在可用数据量有限的情况下。交叉验证包括将数据分成固定数量的折叠(或分区)，对每个折叠进行分析，然后平均总误差估计值。</p><p id="56f1" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">GridSearchCV使用交叉验证方法为字典中传递的每个值组合评估模型。使用该函数的结果是，我们可以计算每个超参数组合的精度/损失，并选择具有最佳性能的组合。对于我们的模型，alpha参数的最佳值被选择为0.01，这使我们的平均测试分数为-0.560748，随后的排名为1。超参数的参数得分在<strong class="je hi">图1.4 </strong>中描述。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lx"><img src="../Images/93cddfcb47dc5669ba2af428b58c26e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ne07p_DCydZY5IIo"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.4</figcaption></figure><h1 id="1a59" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">模型评估</h1><p id="7943" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">图1.5 </strong>显示了我们的模型的表现以及它对实际体脂百分比和预测体脂百分比之间关系的逼近程度。我们用R2、梅和RMSE进行评估。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mj"><img src="../Images/84bd6da77fc76fbbb91f31e3725a4071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OppgJqaG1bsrKJli"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.5</figcaption></figure><h2 id="5bd6" class="kf if hh bd ig kg kh ki ik kj kk kl io jn km kn is jr ko kp iw jv kq kr ja ks bi translated">平均绝对误差</h2><p id="46d4" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">这只是目标值和预测值之间的绝对差值的平均值。当异常值突出时，不建议使用。从我们的指标中可以看出，Lasso回归器的MAE误差为0.38。</p><h2 id="51e6" class="kf if hh bd ig kg kh ki ik kj kk kl io jn km kn is jr ko kp iw jv kq kr ja ks bi translated">r平方或决定系数</h2><p id="a1ad" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">此指标表示可由模型的自变量解释的因变量方差的比例。它评估我们的模型与因变量关系的强度。我们的Lasso回归方程给出了0.99的分数，这意味着模型代表了因变量的方差。</p><h2 id="f7c6" class="kf if hh bd ig kg kh ki ik kj kk kl io jn km kn is jr ko kp iw jv kq kr ja ks bi translated">均方根误差(RMSE)</h2><p id="50d3" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">残差平方的平均值的根就是RMSE。我们知道残差表明这些点离回归线有多远。因此，RMSE量化了这些残差的分散性。我们的Lasso回归方程给出了0.50的分数，表明该模型可以相对准确地预测数据。</p><h1 id="96a0" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">特征重要性</h1><p id="d9f6" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">下面的代码块显示了我们如何计算和绘制Lasso回归模型所使用的最重要的特征。</p><pre class="ku kv kw kx fd lz ma mb mc aw md bi"><span id="a6e0" class="kf if hh ma b fi me mf l mg mh">import matplotlib.pyplot as plt<br/>from textwrap import wrap</span><span id="b4b7" class="kf if hh ma b fi mi mf l mg mh">def rf_feat_importance(model, df):<br/> importance = model.coef_<br/> keys = list(df.keys())<br/> # summarize feature importance<br/> for i,v in enumerate(importance):<br/> print(‘Feature: %s, Score: %.5f’ % (keys[i],v))<br/> labels =[x[:10] for x in keys]<br/> fig = plt.figure()<br/> ax = fig.add_axes([0,0,1,1])<br/> ax.bar([x for x in range(len(importance))], height=importance, color=’b’)<br/> ax.set_xticklabels([labels[i — 1] for i in range(len(importance) +1)], rotation=45)</span><span id="f168" class="kf if hh ma b fi mi mf l mg mh">plt.show()<br/> return importance</span></pre><p id="e8b5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">图1.6显示了我们的模型在去除低重要性特征之前和之后的曲线图。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mk"><img src="../Images/fae595529f9f53d1a2d1c25f7424492d.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/0*4c6X-oYMUTEVZifd"/></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es ml"><img src="../Images/6c9a5d40a82d090d2ab31675ac7774fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/0*I-Z1jKeEf7d-f5Ju"/></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.6</figcaption></figure><p id="034f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">通过排除低价值的因素，我们似乎可以只使用一部分列，仍然可以获得好的结果。所以我们已经移除了所有重要性为0的特征(<strong class="je hi">图1.7 </strong>)。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mm"><img src="../Images/38a90415f1f8c1d2886cefea162fda20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OsWiV1iQdqEwGllI"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Figure 1.7</figcaption></figure><p id="d515" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这给我们留下了5列:</p><ul class=""><li id="a9e5" class="lj lk hh je b jf ka jj kb jn ll jr lm jv ln jz lo lp lq lr bi translated">密度克/厘米</li><li id="de8e" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">年龄</li><li id="d0a1" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">重量(磅)</li><li id="7878" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">无脂肪重量(1-身体脂肪的分数)*重量，使用布罗泽克公式(磅)</li><li id="c914" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">胸围(厘米)</li><li id="a2e5" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">腹围(厘米)</li></ul><p id="0d35" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们可以很有可能得出结论，上述测量值是计算体脂百分比的最基本的方法。</p><h1 id="6941" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结论</h1><p id="d405" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">Lasso回归在我们回归模型的开发中被广泛使用。通过使用GridSearchCV进行超参数调优，我们获得了0.99的R平方分数。在我们的模型中，用MinMaxScaler标准化对减少偏倚和增加方差有显著影响。我们还使用模型系数来确定计算体脂百分比所需的最重要的特征。</p><h1 id="7105" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><ul class=""><li id="6fba" class="lj lk hh je b jf jg jj jk jn mn jr mo jv mp jz lo lp lq lr bi translated">代码库:<a class="ae mq" href="https://github.com/nandangrover/lasso-regression" rel="noopener ugc nofollow" target="_blank">nandangrover/lasso-regression</a></li><li id="0f49" class="lj lk hh je b jf ls jj lt jn lu jr lv jv lw jz lo lp lq lr bi translated">【https://www.statisticshowto.com/lasso-regression/ T4】</li></ul><div class="mr ms ez fb mt mu"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">medium.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni ld mu"/></div></div></a></div></div></div>    
</body>
</html>
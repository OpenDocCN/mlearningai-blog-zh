<html>
<head>
<title>Credit Card Fraud Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">信用卡欺诈检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/credit-card-fraud-detection-d7bf2818ec0c?source=collection_archive---------4-----------------------#2021-03-01">https://medium.com/mlearning-ai/credit-card-fraud-detection-d7bf2818ec0c?source=collection_archive---------4-----------------------#2021-03-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="703c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章是关于我在Kaggle不平衡数据集上的实践——信用卡欺诈检测。</p><h2 id="008b" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">导入包</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="2f55" class="jc jd hh kc b fi kg kh l ki kj">import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt</span><span id="5d98" class="jc jd hh kc b fi kk kh l ki kj">from sklearn.preprocessing import RobustScaler</span><span id="80e5" class="jc jd hh kc b fi kk kh l ki kj">from sklearn.model_selection import StratifiedKFold<br/>from sklearn.model_selection import GridSearchCV</span><span id="f463" class="jc jd hh kc b fi kk kh l ki kj">from sklearn.linear_model import LogisticRegression</span><span id="9ed2" class="jc jd hh kc b fi kk kh l ki kj">from imblearn.under_sampling import NearMiss<br/>from imblearn.under_sampling import RandomUnderSampler</span><span id="9b3b" class="jc jd hh kc b fi kk kh l ki kj">from imblearn.over_sampling import SMOTE</span><span id="7943" class="jc jd hh kc b fi kk kh l ki kj">from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score</span></pre><h1 id="faea" class="kl jd hh bd je km kn ko ji kp kq kr jm ks kt ku jp kv kw kx js ky kz la jv lb bi translated">简单EDA</h1><h2 id="79da" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">输入数据</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="a026" class="jc jd hh kc b fi kg kh l ki kj">all_data = pd.read_csv(‘creditcard.csv’)<br/>all_data.shape</span></pre><p id="584e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="6960" class="jc jd hh kc b fi kg kh l ki kj">(284807, 31)</span></pre><h2 id="a40c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">检查柱子</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="9a14" class="jc jd hh kc b fi kg kh l ki kj">all_data.columns</span></pre><p id="d7e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="0dc6" class="jc jd hh kc b fi kg kh l ki kj">Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10','V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20','V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount','Class'], dtype='object')</span></pre><p id="ca0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总共有31个特征。</p><ul class=""><li id="2b13" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">时间:该事务与数据集中第一个事务之间经过的秒数</li><li id="5b2e" class="ld le hh ig b ih lm il ln ip lo it lp ix lq jb li lj lk ll bi translated">V1～v 28:主成分分析降维的结果</li><li id="d933" class="ld le hh ig b ih lm il ln ip lo it lp ix lq jb li lj lk ll bi translated">金额:交易金额</li><li id="bb3d" class="ld le hh ig b ih lm il ln ip lo it lp ix lq jb li lj lk ll bi translated">类别:交易的标签。1表示欺诈交易，否则为0</li></ul><p id="4936" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">并且该数据集中没有缺失数据。</p><h2 id="4b8c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">检查每个标签的数据编号</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="e095" class="jc jd hh kc b fi kg kh l ki kj">sns.countplot(x=’Class’, data=all_data)</span></pre><p id="17f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><figure class="jx jy jz ka fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lr"><img src="../Images/c4ddef578a944c5929f4a8d8fc00335e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1FhZIVgGyikztEvXj0_7Dg.png"/></div></div></figure><p id="0d2c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">非欺诈交易284315笔，欺诈交易492笔。显然，这个数据集真的很不平衡。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="36fc" class="jc jd hh kc b fi kg kh l ki kj">non_fraud_num, fraud_num = all_data[‘Class’].value_counts()</span><span id="4c41" class="jc jd hh kc b fi kk kh l ki kj">print(‘Non-fraud ratio: {} %’.format(round(non_fraud_num/all_data.shape[0]*100, 2)))<br/>print(‘Fraud ratio: {} %’.format(round(fraud_num/all_data.shape[0]*100, 2)))</span></pre><p id="0163" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="3364" class="jc jd hh kc b fi kg kh l ki kj">Non-fraud ratio: 99.83 %<br/>Fraud ratio: 0.17 %</span></pre><h1 id="9808" class="kl jd hh bd je km kn ko ji kp kq kr jm ks kt ku jp kv kw kx js ky kz la jv lb bi translated">拆分数据集(培训和测试)</h1><p id="5128" class="pw-post-body-paragraph ie if hh ig b ih lz ij ik il ma in io ip mb ir is it mc iv iw ix md iz ja jb ha bi translated">我将数据分成训练集和测试集，它们的标签分布与原始数据集相同。训练集的规模是测试集的三倍。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="7698" class="jc jd hh kc b fi kg kh l ki kj">X, y = all_data.iloc[:, 0:-1], all_data.iloc[:, -1]</span><span id="1566" class="jc jd hh kc b fi kk kh l ki kj">orig_x_train, orig_y_train, orig_x_test, orig_y_test = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()<br/>orig_train_idx, orig_test_idx = [], []</span><span id="4aa7" class="jc jd hh kc b fi kk kh l ki kj">skf = StratifiedKFold(n_splits=4)<br/>for train_idx, test_idx in skf.split(X, y): <br/>   orig_x_train, orig_y_train = X.iloc[train_idx], y.iloc[train_idx]<br/>   orig_x_test, orig_y_test = X.iloc[test_idx], y.iloc[test_idx]<br/>   orig_train_idx, orig_test_idx = train_idx, test_idx<br/>   break<br/>    <br/>train_non_fraud_num, train_fraud_num = orig_y_train.value_counts()<br/>test_non_fraud_num, test_fraud_num = orig_y_test.value_counts()</span><span id="de98" class="jc jd hh kc b fi kk kh l ki kj">print('Training set non-fraud ratio: {:.2f} %'.format(train_non_fraud_num/len(train_idx)*100))<br/>print('Training set fraud ratio: {:.2f} %'.format(train_fraud_num/len(train_idx)*100))<br/>print('Testing set non-fraud ratio: {:.2f} %'.format(test_non_fraud_num/len(test_idx)*100))<br/>print('Testing set fraud ratio: {:.2f} %'.format(test_fraud_num/len(test_idx)*100))</span></pre><p id="745a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="4025" class="jc jd hh kc b fi kg kh l ki kj">Training set non-fraud ratio: 99.83 %<br/>Training set fraud ratio: 0.17 %<br/>Testing set non-fraud ratio: 99.83 %<br/>Testing set fraud ratio: 0.17 %</span></pre><h1 id="2294" class="kl jd hh bd je km kn ko ji kp kq kr jm ks kt ku jp kv kw kx js ky kz la jv lb bi translated">特征缩放</h1><p id="8f3b" class="pw-post-body-paragraph ie if hh ig b ih lz ij ik il ma in io ip mb ir is it mc iv iw ix md iz ja jb ha bi translated">这里我缩放了<code class="du me mf mg kc b">Time</code>和<code class="du me mf mg kc b">Account</code>的特征。我首先在训练集上安装了定标器，并用它来转换测试集，以防止<strong class="ig hi">数据泄露</strong>。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="5f2c" class="jc jd hh kc b fi kg kh l ki kj">orig_x_train_deep = orig_x_train.copy(deep=True)<br/>orig_x_test_deep = orig_x_test.copy(deep=True)</span><span id="dde3" class="jc jd hh kc b fi kk kh l ki kj">time_transformer = RobustScaler()<br/>orig_x_train_deep =         orig_x_train_deep.assign(Scaled_time=time_transformer.fit_transform(orig_x_train_deep[‘Time’].values.reshape(-1,1)))<br/>orig_x_test_deep = orig_x_test_deep.assign(Scaled_time=time_transformer.transform(orig_x_test_deep[‘Time’].values.reshape(-1,1)))</span><span id="bf8a" class="jc jd hh kc b fi kk kh l ki kj">amount_transformer = RobustScaler()<br/>orig_x_train_deep = orig_x_train_deep.assign(Scaled_amount=amount_transformer.fit_transform(orig_x_train_deep[‘Amount’].values.reshape(-1,1)))<br/>orig_x_test_deep = orig_x_test_deep.assign(Scaled_amount=amount_transformer.transform(orig_x_test_deep[‘Amount’].values.reshape(-1,1)))</span><span id="ef4a" class="jc jd hh kc b fi kk kh l ki kj">orig_x_train_deep.drop(['Time', 'Amount'], axis=1, inplace=True)<br/>orig_x_test_deep.drop(['Time', 'Amount'], axis=1, inplace=True)</span></pre><h1 id="2b4d" class="kl jd hh bd je km kn ko ji kp kq kr jm ks kt ku jp kv kw kx js ky kz la jv lb bi translated">逻辑回归</h1><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="7d56" class="jc jd hh kc b fi kg kh l ki kj"># Logistic Regression <br/>orig_log_reg = LogisticRegression(max_iter=1000)<br/>orig_log_reg.fit(orig_x_train_deep.values, orig_y_train.values.ravel())</span><span id="9324" class="jc jd hh kc b fi kk kh l ki kj"># Prediction<br/>orig_y_pred = orig_log_reg.predict(orig_x_test_deep)<br/>print('Classification report: \n\n', classification_report(orig_y_test, orig_y_pred))</span><span id="014b" class="jc jd hh kc b fi kk kh l ki kj"># Calculate AUROC<br/>print('AUROC: ', roc_auc_score(orig_y_test, orig_y_pred))</span></pre><p id="0e1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="1622" class="jc jd hh kc b fi kg kh l ki kj">Classification report: <br/><br/>               precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00     71079<br/>           1       0.74      0.85      0.79       123<br/><br/>    accuracy                           1.00     71202<br/>   macro avg       0.87      0.93      0.90     71202<br/>weighted avg       1.00      1.00      1.00     71202<br/><br/>AUROC:  0.9265689945128041</span></pre><p id="97b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我选择欺诈类的<strong class="ig hi">召回</strong>和<strong class="ig hi"> AUROC </strong>作为好模型的指标。</p><ul class=""><li id="9770" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">回忆:检测类的能力。(TP/(TP+FN))</li><li id="2d8f" class="ld le hh ig b ih lm il ln ip lo it lp ix lq jb li lj lk ll bi translated">AUROC:ROC曲线下的面积，表示模型区分类别的程度。理想值是1。</li></ul><blockquote class="mh mi mj"><p id="ea0a" class="ie if lc ig b ih ii ij ik il im in io mk iq ir is ml iu iv iw mm iy iz ja jb ha bi translated">在这种情况下，使用准确性作为好模型的指标并不是一个好的选择，因为存在大量的非欺诈案例和少量的欺诈案例。比方说，如果一个模型预测数据集中的所有案例都是非欺诈性的，它将获得很高的准确性分数，但实际上它什么也没学到。</p></blockquote><p id="da78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">logistic回归模型有0.85的召回率和0.92的AUROC，不错。但是我们可以做得更好。</p><h1 id="8438" class="kl jd hh bd je km kn ko ji kp kq kr jm ks kt ku jp kv kw kx js ky kz la jv lb bi translated">带类别权重的逻辑回归</h1><p id="ab17" class="pw-post-body-paragraph ie if hh ig b ih lz ij ik il ma in io ip mb ir is it mc iv iw ix md iz ja jb ha bi translated">默认的逻辑回归对每个类使用相同的惩罚权重。然而，对于不平衡数据集，欺诈类的错误分类比非欺诈类的错误分类代价更大。</p><p id="c53c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，让我们调整两个职业的惩罚。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="f0ca" class="jc jd hh kc b fi kg kh l ki kj"># Logistic Regression <br/>w = {0:1, 1:99}<br/>weighted_log_reg = LogisticRegression(max_iter=1000, class_weight=w)<br/>weighted_log_reg.fit(orig_x_train_deep.values, orig_y_train.values.ravel())</span><span id="4566" class="jc jd hh kc b fi kk kh l ki kj"># Prediction<br/>weighted_y_pred = weighted_log_reg.predict(orig_x_test_deep)<br/>print('Classification report: \n\n', classification_report(orig_y_test, weighted_y_pred))</span><span id="7330" class="jc jd hh kc b fi kk kh l ki kj"># Calculate AUROC<br/>print('AUROC: ', roc_auc_score(orig_y_test, weighted_y_pred))</span></pre><p id="9f95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="3599" class="jc jd hh kc b fi kg kh l ki kj">Classification report: <br/><br/>               precision    recall  f1-score   support<br/><br/>           0       1.00      0.99      0.99     71079<br/>           1       0.10      0.88      0.18       123<br/><br/>    accuracy                           0.99     71202<br/>   macro avg       0.55      0.93      0.58     71202<br/>weighted avg       1.00      0.99      0.99     71202<br/><br/>AUROC:  0.9320251358931095</span></pre><p id="43c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们得到了更好的召回率和AUROC，分别是0.88和0.932。</p><p id="bdf7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不够，上面的重量是我的猜测。让我们试试其他重量组合。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="d3f7" class="jc jd hh kc b fi kg kh l ki kj">w = [{0:25, 1:9975}, {0:2.5, 1:997.5}, {0:0.25, 1:99.75}, {0:0.025, 1:9.975}, {0:0.0025, 1:0.9975}, {0:0.00025, 1:0.09975},<br/> {0:20, 1:9980}, {0:2.0, 1:999.0}, {0:0.2, 1:99.8}, {0:0.02, 1:9.98}, {0:0.002, 1:0.998}, {0:0.0002, 1:0.0998},<br/> {0:17, 1:9983}, {0:1.7, 1:998.3}, {0:0.17, 1:99.83}, {0:0.017, 1:9.983}, {0:0.0017, 1:0.9983}, {0:0.00017, 1:0.09983},<br/> {0:10, 1:9990}, {0:1, 1:999}, {0:0.1, 1:99.9}, {0:0.01, 1:9.99}, {0:0.001, 1:0.999}, {0:0.0001, 1:0.0999},<br/> {0:100, 1:9900}, {0:10, 1:990}, {0:1, 1:99}, {0:0.1, 1:9.9}, {0:0.01, 1:0.99}]</span><span id="68e1" class="jc jd hh kc b fi kk kh l ki kj">log_reg_params = {‘class_weight’: w}</span><span id="7994" class="jc jd hh kc b fi kk kh l ki kj"># Logistic Regression with grid search <br/>grid_weighted_log_reg = GridSearchCV(LogisticRegression(max_iter=1000), log_reg_params, scoring=’roc_auc’)<br/>grid_weighted_log_reg.fit(orig_x_train_deep.values, orig_y_train.values.ravel())</span><span id="4e7b" class="jc jd hh kc b fi kk kh l ki kj"># Best hyperparameters<br/>best_hyperparams = grid_weighted_log_reg.best_params_<br/>print(‘Best hyperparameters: ‘, best_hyperparams)<br/>best_weighted_log_reg = grid_weighted_log_reg.best_estimator_</span><span id="bc73" class="jc jd hh kc b fi kk kh l ki kj"># Prediction<br/>best_weighted_y_pred = best_weighted_log_reg.predict(orig_x_test_deep)<br/>print(‘Classification report: \n\n’, classification_report(orig_y_test, best_weighted_y_pred))</span><span id="ceef" class="jc jd hh kc b fi kk kh l ki kj"># Calculate AUROC<br/>print(‘AUROC: ‘, roc_auc_score(orig_y_test, best_weighted_y_pred))</span></pre><p id="2728" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="dbbf" class="jc jd hh kc b fi kg kh l ki kj">Best hyperparameters:  {'class_weight': {0: 0.00025, 1: 0.09975}}<br/>Classification report: <br/><br/>               precision    recall  f1-score   support<br/><br/>           0       1.00      0.98      0.99     71079<br/>           1       0.07      0.97      0.13       123<br/><br/>    accuracy                           0.98     71202<br/>   macro avg       0.54      0.97      0.56     71202<br/>weighted avg       1.00      0.98      0.99     71202<br/><br/>AUROC:  0.9727590976580851</span></pre><p id="b798" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在召回和AUROC看起来很棒。我们来参考一下混淆矩阵的可视化。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="f105" class="jc jd hh kc b fi kg kh l ki kj">cfs_mat = confusion_matrix(orig_y_test, best_weighted_y_pred)<br/>fig, ax = plt.subplots(figsize=(12,9)) <br/>sns.heatmap(pd.DataFrame(cfs_mat), cmap=”Blues”, annot=True, fmt=’d’, ax=ax, annot_kws={“fontsize”:16})<br/>ax.set_xlabel(‘Predicted label’, fontsize = 16)<br/>ax.set_ylabel(‘True label’, fontsize = 16)</span></pre><p id="e19b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><figure class="jx jy jz ka fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mn"><img src="../Images/8d08f8a4bb89c63f7acaecf5b822f190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8HrOxaoCnV4VBQDrEt72IA.png"/></div></div></figure><p id="cb93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的模型识别出125个欺诈案例中的119个！太棒了。</p><p id="bdb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里我也尝试了一些常用的数据抽样方法，如逻辑回归中的<code class="du me mf mg kc b">RandomUnderSampler</code>、<code class="du me mf mg kc b">NearMiss</code>、<code class="du me mf mg kc b">SMOTE</code>。</p><h2 id="27a5" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">随机欠采样器</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="490a" class="jc jd hh kc b fi kg kh l ki kj">rus = RandomUnderSampler(random_state=42)<br/>rus_X, rus_y = rus.fit_sample(orig_x_train, orig_y_train)</span><span id="9ef4" class="jc jd hh kc b fi kk kh l ki kj">rus_y.value_counts()</span></pre><p id="bf3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="1a6d" class="jc jd hh kc b fi kg kh l ki kj">0    369<br/>1    369<br/>Name: Class, dtype: int64</span></pre><p id="551f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了使数据集更加平衡，<code class="du me mf mg kc b">RandomUnderSampler</code>随机选择非欺诈案例，其数量与欺诈案例相同。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="ee6d" class="jc jd hh kc b fi kg kh l ki kj"># Feature scaling<br/>time_transformer = RobustScaler()<br/>rus_X = rus_X.assign(Scaled_time=time_transformer.fit_transform(rus_X[‘Time’].values.reshape(-1,1)))<br/>rus_X_test = orig_x_test.assign(Scaled_time=time_transformer.transform(orig_x_test[‘Time’].values.reshape(-1,1)))</span><span id="ac16" class="jc jd hh kc b fi kk kh l ki kj">amount_transformer = RobustScaler()<br/>rus_X = rus_X.assign(Scaled_amount=amount_transformer.fit_transform(rus_X[‘Amount’].values.reshape(-1,1)))<br/>rus_X_test = rus_X_test.assign(Scaled_amount=amount_transformer.transform(rus_X_test[‘Amount’].values.reshape(-1,1)))</span><span id="9dc3" class="jc jd hh kc b fi kk kh l ki kj">rus_X.drop([‘Time’, ‘Amount’], axis=1, inplace=True)<br/>rus_X_test.drop([‘Time’, ‘Amount’], axis=1, inplace=True)</span><span id="fe11" class="jc jd hh kc b fi kk kh l ki kj"># Logistic Regression<br/>rus_log_reg = LogisticRegression(max_iter=1000)<br/>rus_log_reg.fit(rus_X.values, rus_y.values)</span><span id="24bd" class="jc jd hh kc b fi kk kh l ki kj"># Prediction<br/>rus_y_pred = rus_log_reg.predict(rus_X_test)<br/>print(‘Classification report: \n\n’, classification_report(orig_y_test, rus_y_pred))</span><span id="dd7a" class="jc jd hh kc b fi kk kh l ki kj"># Calculate AUROC<br/>print(‘AUROC: ‘,roc_auc_score(orig_y_test, rus_y_pred))</span></pre><p id="036e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="5916" class="jc jd hh kc b fi kg kh l ki kj">Classification report: <br/><br/>               precision    recall  f1-score   support<br/><br/>           0       1.00      0.92      0.96     71079<br/>           1       0.02      0.90      0.04       123<br/><br/>    accuracy                           0.92     71202<br/>   macro avg       0.51      0.91      0.50     71202<br/>weighted avg       1.00      0.92      0.96     71202<br/><br/>AUROC:  0.9107363877842551</span></pre><h2 id="6492" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><code class="du me mf mg kc b">NearMiss (undersampling)</code></h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="c5d3" class="jc jd hh kc b fi kg kh l ki kj">nm_X, nm_y = NearMiss().fit_sample(orig_x_train, orig_y_train)</span><span id="b89b" class="jc jd hh kc b fi kk kh l ki kj">nm_y.value_counts()</span></pre><p id="ac98" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="9659" class="jc jd hh kc b fi kg kh l ki kj">0    369<br/>1    369<br/>Name: Class, dtype: int64</span></pre><p id="7aea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这两个类的大小与<code class="du me mf mg kc b">RandomUnderSampler</code>相同，但是NearMiss使用不同的策略来选择非欺诈案例。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="1c3e" class="jc jd hh kc b fi kg kh l ki kj"># Feature scaling<br/>time_transformer = RobustScaler()<br/>nm_X = nm_X.assign(Scaled_time=time_transformer.fit_transform(nm_X[‘Time’].values.reshape(-1,1)))<br/>nm_x_test = orig_x_test.assign(Scaled_time=time_transformer.transform(orig_x_test[‘Time’].values.reshape(-1,1)))</span><span id="8e44" class="jc jd hh kc b fi kk kh l ki kj">amount_transformer = RobustScaler()<br/>nm_X = nm_X.assign(Scaled_amount=amount_transformer.fit_transform(nm_X[‘Amount’].values.reshape(-1,1)))<br/>nm_x_test = nm_x_test.assign(Scaled_amount=amount_transformer.transform(nm_x_test[‘Amount’].values.reshape(-1,1)))</span><span id="0508" class="jc jd hh kc b fi kk kh l ki kj">nm_X.drop([‘Time’, ‘Amount’], axis=1, inplace=True)<br/>nm_x_test.drop([‘Time’, ‘Amount’], axis=1, inplace=True)</span><span id="1a76" class="jc jd hh kc b fi kk kh l ki kj"># Logistic Regression<br/>nm_log_reg = LogisticRegression(max_iter=1000)<br/>nm_log_reg.fit(nm_X.values, nm_y.values)</span><span id="8a3c" class="jc jd hh kc b fi kk kh l ki kj"># Prediction<br/>nm_y_pred = nm_log_reg.predict(nm_x_test)<br/>print(‘Classification report: \n\n’, classification_report(orig_y_test, nm_y_pred))</span><span id="7e48" class="jc jd hh kc b fi kk kh l ki kj"># Calculate AUROC<br/>print(‘AUROC: ‘,roc_auc_score(orig_y_test, nm_y_pred))</span></pre><p id="1087" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="4551" class="jc jd hh kc b fi kg kh l ki kj">Classification report: <br/><br/>               precision    recall  f1-score   support<br/><br/>           0       1.00      0.49      0.66     71079<br/>           1       0.00      0.94      0.01       123<br/><br/>    accuracy                           0.49     71202<br/>   macro avg       0.50      0.72      0.33     71202<br/>weighted avg       1.00      0.49      0.66     71202<br/><br/>AUROC:  0.7177637112124298</span></pre><h2 id="6e5c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">SMOTE(过采样)</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="c486" class="jc jd hh kc b fi kg kh l ki kj">smt_X, smt_y = SMOTE().fit_sample(orig_x_train, orig_y_train)</span><span id="8437" class="jc jd hh kc b fi kk kh l ki kj">smt_y.value_counts()</span></pre><p id="fdc6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="f019" class="jc jd hh kc b fi kg kh l ki kj">0    213236<br/>1    213236<br/>Name: Class, dtype: int64</span></pre><p id="520f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">SMOTE不是从非欺诈案例中选择数据，而是自己创建新的欺诈案例。现在两个类的数据数量仍然相同。但是总数据数量变成超过400，000。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="86e1" class="jc jd hh kc b fi kg kh l ki kj"># Feature scaling<br/>time_transformer = RobustScaler()<br/>smt_X = smt_X.assign(Scaled_time=time_transformer.fit_transform(smt_X[‘Time’].values.reshape(-1,1)))<br/>smt_x_test = orig_x_test.assign(Scaled_time=time_transformer.transform(orig_x_test[‘Time’].values.reshape(-1,1)))</span><span id="9115" class="jc jd hh kc b fi kk kh l ki kj">amount_transformer = RobustScaler()<br/>smt_X = smt_X.assign(Scaled_amount=amount_transformer.fit_transform(smt_X[‘Amount’].values.reshape(-1,1)))<br/>smt_x_test = smt_x_test.assign(Scaled_amount=amount_transformer.transform(smt_x_test[‘Amount’].values.reshape(-1,1)))</span><span id="30a2" class="jc jd hh kc b fi kk kh l ki kj">smt_X.drop([‘Time’, ‘Amount’], axis=1, inplace=True)<br/>smt_x_test.drop([‘Time’, ‘Amount’], axis=1, inplace=True)</span><span id="9e2a" class="jc jd hh kc b fi kk kh l ki kj"># Logistic Regression<br/>smt_log_reg = LogisticRegression(max_iter=1000)<br/>smt_log_reg.fit(smt_X.values, smt_y.values)</span><span id="74a8" class="jc jd hh kc b fi kk kh l ki kj"># Prediction<br/>smt_y_pred = smt_log_reg.predict(smt_x_test)<br/>print(‘Classification report: \n\n’, classification_report(orig_y_test, smt_y_pred))</span><span id="8a36" class="jc jd hh kc b fi kk kh l ki kj"># Calculate AUROC<br/>print(‘AUROC: ‘, roc_auc_score(orig_y_test, smt_y_pred))</span></pre><p id="d851" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="abc8" class="jc jd hh kc b fi kg kh l ki kj">Classification report: <br/><br/>               precision    recall  f1-score   support<br/><br/>           0       1.00      0.97      0.98     71079<br/>           1       0.05      0.98      0.09       123<br/><br/>    accuracy                           0.97     71202<br/>   macro avg       0.52      0.97      0.54     71202<br/>weighted avg       1.00      0.97      0.98     71202<br/><br/>AUROC:  0.9749380541541034</span></pre><p id="f1d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">混淆矩阵可视化:</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="e8f4" class="jc jd hh kc b fi kg kh l ki kj">cfs_mat = confusion_matrix(orig_y_test, smt_y_pred)<br/>fig, ax = plt.subplots(figsize=(8,6)) <br/>sns.heatmap(pd.DataFrame(cfs_mat), cmap=”Blues”, annot=True, fmt=’d’, ax=ax, annot_kws={“fontsize”:16})<br/>ax.set_xlabel(‘Predicted label’, fontsize = 16)<br/>ax.set_ylabel(‘True label’, fontsize = 16)</span></pre><p id="de57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lc">输出</em></p><figure class="jx jy jz ka fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mo"><img src="../Images/ba5d578004d21d5fd775311250481dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XQqmqPhHkYvGiWkJAJGNg.png"/></div></div></figure><p id="b9e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在三种抽样方法中，SMOTE的结果最好，略好于带权重调整的logistic回归。</p><h2 id="9eaf" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">结论</h2><p id="0d05" class="pw-post-body-paragraph ie if hh ig b ih lz ij ik il ma in io ip mb ir is it mc iv iw ix md iz ja jb ha bi translated">在本文中，我使用了两种方法来处理不平衡数据集。一个是权重调整，另一个是数据欠采样/过采样。这两种方法都适用于这种情况。</p><p id="8316" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">欢迎任何反馈/讨论！</p></div></div>    
</body>
</html>
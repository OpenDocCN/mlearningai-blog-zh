<html>
<head>
<title>Understanding the Diffusion Model and the theory behind it</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解扩散模型及其背后的理论</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/understanding-the-diffusion-model-and-the-theory-tensorflow-cafcd5752b98?source=collection_archive---------0-----------------------#2022-12-21">https://medium.com/mlearning-ai/understanding-the-diffusion-model-and-the-theory-tensorflow-cafcd5752b98?source=collection_archive---------0-----------------------#2022-12-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/e0591a1af2b8b0ca63af1efd220122d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*k-dWltEZ_YF_VS6iTvevEQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Image generated from novel AI (<a class="ae ip" href="https://twitter.com/umecha1128/status/1582572128880115712?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1582572128880115712%7Ctwgr%5E6cd14f8776cdf327b562f45858b0a6a88951f363%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fgame.ettoday.net%2Farticle%2F2362451.htm" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="f9ad" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">AI图像生成是一项在艺术和深度学习(DL)领域备受热议的技术。你一定听说过人工智能艺术生成器，如<a class="ae ip" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> Dall-E 2 </strong> </a>或<a class="ae ip" href="https://novelai.net/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> NovelAI </strong> </a>，这是一种从给定的文本序列中生成逼真图像的DL模型。</p><p id="a62e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">为了更深入地探索这项技术，我们需要在生成模型中引入一个新的类，称为'<strong class="is hi">扩散'</strong>，首先由Sohl-Dickstein等人(2015年)提出，旨在使用<strong class="is hi">反向去噪过程</strong>从噪声中生成图像。</p><p id="d831" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">迄今为止，已有几种生成模型，包括<a class="ae ip" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"><strong class="is hi"/></a><a class="ae ip" href="https://arxiv.org/abs/1312.6114" rel="noopener ugc nofollow" target="_blank"><strong class="is hi">【VAE】</strong></a><strong class="is hi">基于流程的模型</strong>。它们中的大多数都可以生成高质量的图像，如当前最先进的图像生成模型<a class="ae ip" href="https://github.com/autonomousvision/stylegan_xl" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> StyleGAN-XL </strong> </a>。然而，每一种都有其自身的局限性。</p><blockquote class="jo jp jq"><p id="4860" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn ha bi translated">众所周知，GAN模型具有潜在的不稳定训练，并且由于其对抗性的训练性质，在一代中多样性较低。VAE依赖于替代损失。流动模型必须使用专门的架构来构建可逆转换(Lilian Weng，2021)</p></blockquote><p id="3eb9" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">扩散模型在将噪声转换成图像时提供了一个缓慢的迭代过程。这使得扩散模型比GAN模型更具有可扩展性。此外，由于扩散模型的目标是预测输入噪声，这是<strong class="is hi">监督学习，</strong>我们可以预期扩散模型的训练将比GAN ( <strong class="is hi">非监督学习</strong>)更加<strong class="is hi">稳定</strong>。</p><blockquote class="jo jp jq"><p id="3f88" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn ha bi translated">本文的实现将基于<a class="ae ip" href="https://arxiv.org/abs/2006.11239" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi">去噪扩散概率模型</strong> </a> <strong class="is hi"> </strong>(何等，2021)【】<a class="ae ip" href="https://arxiv.org/abs/2010.02502" rel="noopener ugc nofollow" target="_blank"><strong class="is hi">去噪扩散隐式模型</strong> </a> <strong class="is hi"> </strong>(宋等，2021)、</p><p id="24f4" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn ha bi translated">数学公式来自<a class="ae ip" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" rel="noopener ugc nofollow" target="_blank"><strong class="is hi"/></a></p></blockquote><h1 id="fd6c" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">什么是扩散模型？</h1><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kt"><img src="../Images/70288e59a79921e9e981f94af08ac963.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jddoOVRLrc5hjYY9bVcZwg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">the diffusion process of the particle in water (<a class="ae ip" href="https://en.wikipedia.org/wiki/Diffusion" rel="noopener ugc nofollow" target="_blank"><strong class="bd jx">source</strong></a>)</figcaption></figure><p id="737b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">单词<strong class="is hi">扩散</strong>被定义为任何物质从较高浓度区域到较低浓度区域的<strong class="is hi">运动</strong>。</p><p id="0e6d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">受这个概念的启发，扩散模型定义了<strong class="is hi">马尔可夫链</strong>来缓慢地给图像添加随机噪声。<strong class="is hi">马尔可夫链</strong>可以看作是<strong class="is hi">扩散，</strong>和<strong class="is hi">加噪声</strong>的过程就是<strong class="is hi">运动。</strong> <em class="jr">因此，我们的目标是找到添加到图像中的噪声(运动)并反转这个过程。</em></p><p id="c11a" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">扩散模型主要由两个过程组成<strong class="is hi">正向去噪</strong>和<strong class="is hi">反向去噪；</strong>这可以被认为是不断地<strong class="is hi">将噪声</strong>添加到图像中，而不是<strong class="is hi">反转</strong>这个过程。😈 😈</p><h1 id="47ed" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">正向噪声</strong></h1><p id="a79a" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">在DDPM的论文中，作者将正向过程定义为:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lh"><img src="../Images/d10139ed3fe67dfdc694b3c693ee7593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hd0RGkKbdS0OqKMlMaz4Hg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Eq. 1: Definition of the <strong class="bd jx">Markov chain</strong> in Forward noising</figcaption></figure><p id="cd67" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">以上是一个<strong class="is hi">马尔可夫链</strong>其中每一个时间步<strong class="is hi"> t </strong>只依赖于前一步<strong class="is hi"> t-1 </strong>。我们使用方差表<strong class="is hi"> <em class="jr"> β </em> </strong>来控制均值和方差，<em class="jr">其中β</em>₀<em class="jr">t64】β</em>₁&lt;…&lt;t44】βt .</p><p id="9e52" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们将从x0(从真实数据分布q(x)中采样)开始，然后重新计算x0的均值和方差以生成x1。最后，到最后的状态xT，这是一个<strong class="is hi">高斯噪声。</strong>该过程可以被视为迭代地推出图像，直到它离开真实数据分布并变成噪声。</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es li"><img src="../Images/f103d8d4d588f22d61dadddc96c4286d.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*VL0JOztzvPg5b_tJwpZOhg.png"/></div><figcaption class="il im et er es in io bd b be z dx">The figure describes the forward process (<a class="ae ip" href="https://www.youtube.com/watch?v=fbLgFrlTnGU" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="195f" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">在开始编码之前，让我先介绍一下扩散模型中的两个重要性质。</p><h2 id="74d4" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated"><strong class="ak">属性1:重新参数化技巧</strong></h2><p id="cb6d" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">在扩散模型中，我们会有很多值需要从一个分布中抽样，例如z ~ N(z；μ, σ2).然而，我们不能通过网络执行<strong class="is hi">反向传播</strong>，因为我们不能对随机变量进行<strong class="is hi">求导</strong>。</p><p id="075f" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">因此，<strong class="is hi">重新参数化技巧</strong>提供了另一种形式的采样过程。而不是从N(Z；μ，σ2)我们可以将其重写为:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/1ae99ef97b4d827a0cc7ce06968251b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*MtinwnymMDfbOVDXqKA4Gg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 2: <strong class="bd jx">reparameterization of Normal distribution</strong></figcaption></figure><p id="0102" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在我们<strong class="is hi">把随机性转移到从高斯分布中采样的随机变量<em class="jr"> ∈ </em> </strong> <em class="jr"> </em>。这使得该过程可微分，因为我们可以在训练期间获得值<em class="jr"> ∈ </em>。💛</p><h2 id="7ee0" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated"><strong class="ak">性质2:任意时间步长的Xt可以用X0和<em class="ly">β</em>T3】来表示</strong></h2><p id="8bca" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">为了获得噪声图像<strong class="is hi"> Xt，</strong>，我们需要遍历马尔可夫链，直到到达<strong class="is hi">时间步长t </strong>。<strong class="is hi"> </strong>显然这个过程非常<strong class="is hi">低效</strong>，尤其是在<strong class="is hi"> DL训练</strong>中，会有一堆输入同时进行。</p><p id="cbf4" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">由于<strong class="is hi">重新参数化技巧</strong>，我们现在可以通过输入<strong class="is hi">初始图像X0 </strong>和相应的时间步长<strong class="is hi"> t，</strong>得到<strong class="is hi">噪声图像Xt </strong>，公式如下:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/2bc53072157b8f4ff05da5d4b2b255d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*CgNnDIt9-4QtWZlOLY7RpQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 3: Distribution of q after applying <strong class="bd jx">reparameterization trick</strong></figcaption></figure><p id="064c" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jr">(详细的推导过程，我放在本节末尾)</em></p></div><div class="ab cl lz ma go mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ha hb hc hd he"><p id="c46e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最后，让我们基于<strong class="is hi">属性2来编码前向探测过程😄</strong></p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="b7ab" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">上面显示了两种不同版本的扩散时间表，<strong class="is hi">离散</strong>和<strong class="is hi">连续。</strong>这个实现将集中在前一个上。</p><p id="ef0e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">关于<strong class="is hi">连续</strong>扩散时间表的更多信息，我推荐阅读DDIM模型的<a class="ae ip" href="https://keras.io/examples/generative/ddim/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> Keras范例</strong> </a>。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mi"><img src="../Images/d9f72b4b13bb7bdc12d4f2455d8e7cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0lDNgz73WdtUxV2590MBjg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Image created by the author</figcaption></figure><h2 id="ee25" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated"><strong class="ak">性质2 </strong>的数学证明</h2><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lh"><img src="../Images/d10139ed3fe67dfdc694b3c693ee7593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hd0RGkKbdS0OqKMlMaz4Hg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Eq. 4: the noising process</figcaption></figure><p id="cc9f" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们的最终目标是获得xT。通过遍历多个高斯条件概率<strong class="is hi">q(XT | XT 1)</strong>。</p><p id="5d53" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">首先，我们重新定义<strong class="is hi">阿尔法和贝塔</strong>如下:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/6e55bdf9a7411f87f91583c8cf622a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*iPbUTr8YRmE8qzz3kSADhA.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 5: refine <strong class="bd jx">alpha and beta</strong></figcaption></figure><p id="2493" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">使用<strong class="is hi">重新参数化技巧，我们可以将</strong>q(XT | XT 1)重写为:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es mj"><img src="../Images/c27d27bb89ae3483ad501ba8d8fbb4c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*3lLDxxiviNuC6Ufe_P-PMw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 6: Gaussian conditional probability <strong class="bd jx">q(xt|xt−1)</strong></figcaption></figure><p id="5e2b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">其中z1 ~ N(0，I)</p><p id="85e6" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">展开<strong class="is hi"> xt </strong>我们可以得到:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mk"><img src="../Images/b2a5ffeb332ddc9a82d96c6f67107b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RRi1ysCF0wj8XZbcQsliHA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Eq. 6: calculation of Xt</figcaption></figure><p id="e51c" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">既然两个高斯的合并也是一个高斯也就是</strong></p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/92937f2576e78c84ab10a776ae50f344.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*FW8-qofzciRj-7hZjdb1hw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 7: merge of two Gaussians is also a Gaussians</figcaption></figure><p id="a38b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">合并后的标准差为</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/f42f7bce1c20fc85eeb4ccade75d659b.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*1Ew9Jg8QK1KJyIvlsup8HA.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 8: merged standard deviation</figcaption></figure><p id="a3a9" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最后，利用该结果可以得到任意时间步长的含噪图像。</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/2bc53072157b8f4ff05da5d4b2b255d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*CgNnDIt9-4QtWZlOLY7RpQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 9: Distribution of q after applying <strong class="bd jx">reparameterization trick</strong></figcaption></figure><p id="35b8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi">🥀 🥀 🥀 🥀 🥀🥀 🥀 🥀 🥀 🥀🥀 🥀 🥀 🥀 🥀🥀 🥀 🥀 🥀 🥀🥀 🥀 🥀🥀🥀🥀🥀🥀</p><h1 id="cabc" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">反向去噪</strong></h1><p id="d272" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">如果说正向过程是添加噪声的过程，那么反向过程就是去除噪声。</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/2c7bec9d6d048c09dcb1c43a1781c7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*YpNsRtVZaiTkA6TYz-HOOg.png"/></div><figcaption class="il im et er es in io bd b be z dx">The figure describes the backward process (<a class="ae ip" href="https://www.youtube.com/watch?v=fbLgFrlTnGU" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="8df0" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">如果我们可以找到逆分布q(xT 1 | xT ),就可以从高斯噪声xT ~ N(0，I)中重建真实图像。由于q(XT | XT 1)是高斯函数，如果<em class="jr"> βt </em>足够小，q(XT 1 | XT)也将是高斯函数。</p><p id="6944" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">然而，我们不能简单地估计<strong class="is hi"> <em class="jr"> q </em> </strong>，因为它需要估计整个数据分布；这样，我们就学习一个模型<strong class="is hi"> <em class="jr"> P </em> </strong>来近似这个条件概率。<strong class="is hi">p(XT 1 | XT)</strong>的分布写为:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/e156c2e78c27998308904a51926af7b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*3H0teVZ5Ic2E2z_XFmKbow.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 10: reverse distribution p(xt−1|xt)</figcaption></figure><p id="1df0" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们的目标是获得初始状态X0</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/8272f037cb793045d35b245f7df47bbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*kkB5BKHxRA5s1IrIrWLBvQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 11: the process to obtain initial state X0</figcaption></figure><h2 id="2c28" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated">DDPM</h2><p id="1426" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">在ddpm论文中，作者将采样过程定义为:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/ebce79b367f210c8aa9d53beec63685e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*LtTcYYq-dPmezWqZdQcZKg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Sampling process in DDPM (<a class="ae ip" href="https://arxiv.org/abs/2006.11239" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="9d11" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">反向分布<strong class="is hi">p(XT 1 | XT)</strong>可以写成:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/519836c2072dbe4ce58da8d5162f02d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*-Ge7GW2chuxOnYDDY8HPzw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 12: reverse distribution <strong class="bd jx">p(xt−1|xt) </strong>in DDPM</figcaption></figure><p id="c0bd" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们使用<strong class="is hi"> U-net </strong>模型用输入(xt，t)预测<strong class="is hi"><em class="jr"/></strong><em class="jr"/>，此外DDPM使用<strong class="is hi">未训练sigma _<em class="jr">θ</em><em class="jr"/>并相信<strong class="is hi"> sigma_ <em class="jr"> θ </em> </strong>(上图中的sigma_t)近似为<strong class="is hi"> <em class="jr"> βt </em> </strong></strong></p><p id="3fb7" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">让我们对此进行编码！！！~~~ 😙</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="9765" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">以上是DDPM的去噪过程。然而，我更喜欢DDIM去噪过程，它基于:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es ml"><img src="../Images/44a5ac651498ea5618a5f85c9d3c9410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_QluDZ_ExahiFYQPDBWuNw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Eq. 13: Sampling process in DDIM</figcaption></figure><p id="8dc2" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">通过将σ设置为0，我们可以消除采样过程中的随机性，从而减少推断时间。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h2 id="372c" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated">逆向过程背后的数学</h2><p id="87c0" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">好了，该来点数学了~~😢 😢</p><p id="63c2" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">让我们再次回顾一下取样过程。我们的目标是得到反向条件概率q(xt1 | XT)。为了使它易于处理，我们首先像这样把一个X0放入其中:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/b2cb920e219eedb6f38b00bfd79f8133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*H5mn90CFxV_2k-1dHGjuBg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 14: adding x0 into q(xt−1|xt)</figcaption></figure><p id="dab2" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">应用贝叶斯法则后，我们得到:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/fea0b4123c85c07d26b7481a6d9737e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*HIjdEWVIgeAgsO2dNnqiRg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 15: applying Bayes’ rule to q(xt−1|xt, x0)</figcaption></figure><p id="d32d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在，所有的<strong class="is hi"> q </strong>都变成了<strong class="is hi">前进</strong>，这意味着我们可以根据前面提到的<strong class="is hi">属性2 </strong>得到<strong class="is hi"> q </strong>的<strong class="is hi">均值</strong>和<strong class="is hi">方差</strong>。</p><p id="7f25" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">扩展q的<strong class="is hi">标准高斯密度函数</strong>，我们可以得到:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mn"><img src="../Images/69de52733bd77dfd6f1582898385cf7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXsRAOozDqnD9cPL7gL_fQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Eq. 16: Expanding the <strong class="bd jx">standard Gaussian density function </strong>of q</figcaption></figure><p id="1b3e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">继续扩大我们可以得到:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mo"><img src="../Images/25fb2fc3111389f30f7181d59691a86d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IBv63JUafZcnRC9H9-rk4w.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Eq. 17: obtain the <strong class="bd jx">mu</strong> and <strong class="bd jx">beta</strong></figcaption></figure><p id="014e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最后，我们只剩下X0需要删除。多亏了<strong class="is hi">重新参数化技巧</strong> ( <strong class="is hi">属性1 </strong>)，我们可以将其重写为:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/bd1decc3d2e6b26b848bff33cdfcd3fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*MMJ-jyPMGhN4iIyD2GQDEQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Eq. 18: replace <strong class="bd jx">x0</strong> in <strong class="bd jx">mu</strong> using the <strong class="bd jx">reparameterization trick</strong></figcaption></figure><p id="8282" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">如上图，我们需要去噪的东西是<strong class="is hi"><em class="jr"/></strong>其中<strong class="is hi"> <em class="jr"> </em> </strong>是<strong class="is hi"> <em class="jr"> </em> </strong>等于<strong class="is hi">输入噪声</strong>在正向过程中，神经网络可以预测出来。嗯~~😁 😁</p><h1 id="7dee" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">模型架构和培训</h1><p id="3026" class="pw-post-body-paragraph iq ir hh is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn ha bi translated">在扩散模型中，我们通过输入<strong class="is hi"> <em class="jr"> </em>图像数据X0 </strong>和<strong class="is hi">时间步长t </strong>，使用<strong class="is hi"> U网结构</strong>来预测噪声<strong class="is hi"><em class="jr">【є_t</em></strong>。</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mp"><img src="../Images/5df92c7cf53c35479dd2c8f63ea53561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JYIrFOiulsGPj_npSsiXhQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">image is taken from the official paper of u-net (<a class="ae ip" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="7306" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">U-Net是一种流行的卷积神经网络(CNN)架构，最初是为生物医学<strong class="is hi">图像分割</strong>开发的。它基于<strong class="is hi">卷积层</strong>对输入图像进行下采样和上采样，并在具有相同分辨率的层之间添加<strong class="is hi">跳过连接</strong>。</p><blockquote class="jo jp jq"><p id="2245" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn ha bi translated">这里是<a class="ae ip" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> u-net </strong> </a>官方论文的链接</p></blockquote><p id="3fe9" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">让我们写我们的扩散模型！！~~~ 👐</p><p id="d2cb" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi"> <em class="jr">欢迎访问我的</em></strong><a class="ae ip" href="https://github.com/Yukino1010/Diffusion_Model" rel="noopener ugc nofollow" target="_blank"><strong class="is hi"><em class="jr">GitHub</em></strong></a><strong class="is hi"><em class="jr">。我已经把代码放上去了~~😸</em>T13】</strong></p><h2 id="ea83" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated">u形网块</h2><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h2 id="c5b1" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated">u网模型</h2><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="d511" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">为了简单起见，我省略了注意力层，它可以提供更好的全局一致性。另外，我用<strong class="is hi">批量定额</strong>代替<strong class="is hi">分组定额</strong>来减少计算量。</p><h2 id="2fc2" class="lj jw hh bd jx lk ll lm kb ln lo lp kf jb lq lr kj jf ls lt kn jj lu lv kr lw bi translated">培养</h2><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="aa02" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们选择均方误差作为模型优化的损失函数，以计算<strong class="is hi">噪声</strong>(来自正向过程)<strong class="is hi"> </strong>和<strong class="is hi">预测噪声</strong>(来自模型)之间的损失。</p><p id="12c1" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">但是为什么</strong>可以用MSE这样简单的函数来优化两个分布，<strong class="is hi"> p </strong>和<strong class="is hi"> q </strong>？</p><p id="708c" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">为了回答这个问题，我强烈推荐观看阿里·塞夫的视频和T42的视频。🥀 🥀 </p><h1 id="3c93" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结果</h1><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/3cc253f02c5b530070286e4880daa651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/1*KChOkJXWMIIrEo6Aof1nDw.gif"/></div></figure><figure class="ku kv kw kx fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/c3018269b28136be37baa63ccd7f41f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/1*sCQAIKjuiz9UYx4It2s42A.gif"/></div></figure><h1 id="2575" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">参考</strong></h1><ol class=""><li id="ceb8" class="mr ms hh is b it lc ix ld jb mt jf mu jj mv jn mw mx my mz bi translated"><a class="ae ip" href="https://arxiv.org/abs/2006.11239" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jr">去噪扩散概率模型</em> </strong> </a></li><li id="7ed2" class="mr ms hh is b it na ix nb jb nc jf nd jj ne jn mw mx my mz bi translated"><a class="ae ip" href="https://arxiv.org/abs/2010.02502" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jr">去噪扩散隐式模型</em> </strong> </a></li><li id="ef00" class="mr ms hh is b it na ix nb jb nc jf nd jj ne jn mw mx my mz bi translated"><a class="ae ip" href="https://keras.io/examples/generative/ddim/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jr"> Keras示例—去噪扩散隐式模型</em> </strong> </a></li><li id="7e2a" class="mr ms hh is b it na ix nb jb nc jf nd jj ne jn mw mx my mz bi translated"><a class="ae ip" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jr"> Lil' Log —什么是扩散模型？</em> </strong> </a></li><li id="c407" class="mr ms hh is b it na ix nb jb nc jf nd jj ne jn mw mx my mz bi translated"><a class="ae ip" rel="noopener" href="/@vedantjumle/image-generation-with-diffusion-models-using-keras-and-tensorflow-9f60aae72ac"><strong class="is hi"><em class="jr">Vedant Jumle——使用Keras和TensorFlow的扩散模型生成图像</em> </strong> </a></li></ol><div class="nf ng ez fb nh ni"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw ij ni"/></div></div></a></div></div></div>    
</body>
</html>
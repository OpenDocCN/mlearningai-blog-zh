<html>
<head>
<title>Create simple Bag-of-Words models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建简单的单词袋模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/create-simple-bag-of-words-models-78b19578246?source=collection_archive---------5-----------------------#2021-05-28">https://medium.com/mlearning-ai/create-simple-bag-of-words-models-78b19578246?source=collection_archive---------5-----------------------#2021-05-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="950b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本系列的前一篇博客中，我们了解了什么是单词袋模型，以及我们如何手动创建一个简单的模型。</p><p id="85ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你没有读过这篇博客，请在这里阅读:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/8074ef9cef446974407011307b8bb776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2-HD39fHQ03MQpek"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jc" href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Brett Jordan</a> on <a class="ae jc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c5ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博客中，我们将学习如何使用Scikit-Learn和Keras创建简单的弓模型。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="417e" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">使用Scikit-Learn创建弓</h1><p id="2216" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">有不同类型的评分方法可用于将文本数据转换为数字向量。你可以在这里阅读这些技术<a class="ae jc" rel="noopener" href="/@priyansh-kedia/methods-for-scoring-words-in-nlp-8a1f0b55605a">。</a></p><p id="1a3d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Scikit-Learn提供了将文本数据转换成数值向量的不同方法。其中两种方法是:</p><ul class=""><li id="fadf" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated"><strong class="ig hi">计数矢量器</strong></li><li id="dc3b" class="ld le hh ig b ih lm il ln ip lo it lp ix lq jb li lj lk ll bi translated"><strong class="ig hi">tfidf矢量器</strong></li></ul></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h2 id="daa7" class="lr kb hh bd kc ls lt lu kg lv lw lx kk ip ly lz ko it ma mb ks ix mc md kw me bi translated">计数矢量器</h2><blockquote class="mf mg mh"><p id="1fe4" class="ie if mi ig b ih ii ij ik il im in io mj iq ir is mk iu iv iw ml iy iz ja jb ha bi translated">将文本文档集合转换为令牌计数矩阵</p></blockquote><pre class="je jf jg jh fd mm mn mo mp aw mq bi"><span id="04f0" class="lr kb hh mn b fi mr ms l mt mu">from sklearn.feature_extraction.text import CountVectorizer</span><span id="37e1" class="lr kb hh mn b fi mv ms l mt mu"># input text data<br/>text = ["When your only tool is a hammer, all problems start looking like nails."]</span><span id="e4c7" class="lr kb hh mn b fi mv ms l mt mu"># create the instance of vectorizer<br/>vectorizer = CountVectorizer()</span><span id="b64e" class="lr kb hh mn b fi mv ms l mt mu"># fit is used to learn the vocabulary<br/>vectorizer.fit(text)</span><span id="3f52" class="lr kb hh mn b fi mv ms l mt mu"># print the generated vocabulary<br/>print(vectorizer.vocabulary_)</span><span id="df16" class="lr kb hh mn b fi mv ms l mt mu"># vectorize the input text<br/>vector = vectorizer.transform(text)</span><span id="1fcb" class="lr kb hh mn b fi mv ms l mt mu">print(vector.shape)<br/>print(vector.toarray())</span></pre><p id="f180" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上面的代码片段中，我们简单地向矢量器<code class="du mw mx my mn b">fit</code>方法提供了一个样本文本数据，它从输入文本中学习词汇。</p><p id="f0cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们使用<code class="du mw mx my mn b">transform</code>方法将文本转换成数字向量。</p><h2 id="abc8" class="lr kb hh bd kc ls lt lu kg lv lw lx kk ip ly lz ko it ma mb ks ix mc md kw me bi translated">tfidf矢量器</h2><blockquote class="mf mg mh"><p id="eb2b" class="ie if mi ig b ih ii ij ik il im in io mj iq ir is mk iu iv iw ml iy iz ja jb ha bi translated">将原始文档集合转换为TF-IDF特征矩阵。</p></blockquote><pre class="je jf jg jh fd mm mn mo mp aw mq bi"><span id="061c" class="lr kb hh mn b fi mr ms l mt mu">from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="9853" class="lr kb hh mn b fi mv ms l mt mu"># input text data<br/>text = ["When your only tool is a hammer, all problems start looking like nails.",<br/>  "When your",<br/>  "problems start looking"]</span><span id="fadd" class="lr kb hh mn b fi mv ms l mt mu"># create the instance of vectorizer<br/>vectorizer = TfidfVectorizer()</span><span id="d350" class="lr kb hh mn b fi mv ms l mt mu"># fit is used to learn the vocabulary<br/>vectorizer.fit(text)</span><span id="cc03" class="lr kb hh mn b fi mv ms l mt mu"># print the generated vocabulary and idf values<br/>print(vectorizer.vocabulary_)<br/>print(vectorizer.idf_)</span><span id="4a45" class="lr kb hh mn b fi mv ms l mt mu"># vectorize an input text<br/>vector = vectorizer.transform([text[0]])</span><span id="eca1" class="lr kb hh mn b fi mv ms l mt mu">print(vector.shape)<br/>print(vector.toarray())</span></pre><p id="4742" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上面的代码片段中，我们简单地向矢量器<code class="du mw mx my mn b">fit</code>方法提供了一个样本文本数据，它从输入文本中学习词汇。</p><p id="5882" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们使用<code class="du mw mx my mn b">transform</code>方法将文本转换成数字向量。</p><h1 id="9f5b" class="ka kb hh bd kc kd mz kf kg kh na kj kk kl nb kn ko kp nc kr ks kt nd kv kw kx bi translated">使用Keras创建弓</h1><p id="2826" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">我们可以使用<strong class="ig hi"> keras预处理</strong>模块的<strong class="ig hi">标记器</strong>类。</p><blockquote class="mf mg mh"><p id="e7fd" class="ie if mi ig b ih ii ij ik il im in io mj iq ir is mk iu iv iw ml iy iz ja jb ha bi translated">这个类允许对文本语料库进行矢量化，方法是将每个文本转换为整数序列(每个整数是字典中一个标记的索引)或向量，其中每个标记的系数可以是二进制的，基于字数，基于tf-idf…</p></blockquote><p id="b718" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Tokenizer类使用起来非常方便，因为它提供了对不同类型的现成评分方法的支持。</p><pre class="je jf jg jh fd mm mn mo mp aw mq bi"><span id="6d6d" class="lr kb hh mn b fi mr ms l mt mu">from keras.preprocessing.text import Tokenizer</span><span id="cd56" class="lr kb hh mn b fi mv ms l mt mu"># define 4 documents<br/>docs = ["No man is an island", "Entire of itself,", "Every man is a piece of the continent,", "A part of the main."]</span><span id="fc68" class="lr kb hh mn b fi mv ms l mt mu"># create the tokenizer<br/>t = Tokenizer()</span><span id="b39e" class="lr kb hh mn b fi mv ms l mt mu"># fit the tokenizer on the documents<br/>t.fit_on_texts(docs)</span><span id="72dc" class="lr kb hh mn b fi mv ms l mt mu"># summarize what was learned<br/>print(t.word_counts)<br/>print(t.document_count)<br/>print(t.word_index)<br/>print(t.word_docs)</span><span id="04ac" class="lr kb hh mn b fi mv ms l mt mu"># integer encode documents<br/>encoded_docs = t.texts_to_matrix(docs, mode='count')<br/>print(encoded_docs)</span></pre><p id="964d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上面的代码片段中，我们首先在所有文档上安装标记器来学习词汇。这是使用<code class="du mw mx my mn b">fit_on_texts</code>完成的。然后我们用<code class="du mw mx my mn b">texts_to_matrix</code>把文字转换成相应的矢量。</p><p id="9cec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">需要注意的重要一点是该函数的第二个参数<code class="du mw mx my mn b">mode</code>。</p><p id="9904" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以使用<code class="du mw mx my mn b">mode</code>来指定我们希望在对文本进行矢量化时使用的评分方法的类型。<strong class="ig hi">该值可以是“二进制”、“计数”、“tfidf”、“频率”中的一个。</strong></p><pre class="je jf jg jh fd mm mn mo mp aw mq bi"><span id="dd2e" class="lr kb hh mn b fi mr ms l mt mu">#       if mode == 'count':</span><span id="8899" class="lr kb hh mn b fi mv ms l mt mu">#             x[i][j] = c</span><span id="74ad" class="lr kb hh mn b fi mv ms l mt mu">#       elif mode == 'freq':</span><span id="848d" class="lr kb hh mn b fi mv ms l mt mu">#             x[i][j] = c / len(seq)</span><span id="162c" class="lr kb hh mn b fi mv ms l mt mu">#       elif mode == 'binary':</span><span id="17fa" class="lr kb hh mn b fi mv ms l mt mu">#             x[i][j] = 1</span><span id="2d9c" class="lr kb hh mn b fi mv ms l mt mu">#       elif mode == 'tfidf':</span><span id="7fc1" class="lr kb hh mn b fi mv ms l mt mu">#             tf = 1 + np.log(c)</span><span id="1ba8" class="lr kb hh mn b fi mv ms l mt mu">#       idf = np.log(1 + self.document_count /</span><span id="172a" class="lr kb hh mn b fi mv ms l mt mu">#             (1 + self.index_docs.get(j, 0)))</span><span id="f3d2" class="lr kb hh mn b fi mv ms l mt mu">#             x[i][j] = tf * idf</span></pre><p id="4b74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上述公式可在<code class="du mw mx my mn b">texts_to_matrix</code>方法的文档说明中找到。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><p id="c40c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博文中，我们了解了使用Scikit-Learn和keras创建单词袋模型的不同方法。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><p id="11ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献</strong></p><div class="ne nf ez fb ng nh"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hi fi z dy nm ea eb nn ed ef hg bi translated">sk learn . feature _ extraction . text . count vectorizer-sci kit-learn 0 . 24 . 2文档</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">class sk learn . feature _ extraction . text . count vectorizer(*，input='content '，encoding='utf-8 '，decode_error='strict'…</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">scikit-learn.org</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv jn nh"/></div></div></a></div><div class="ne nf ez fb ng nh"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hi fi z dy nm ea eb nn ed ef hg bi translated">sk learn . feature _ extraction . text . tfidf vectorizer-sci kit-learn 0 . 24 . 2文档</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">class sk learn . feature _ extraction . text . tfidf vectorizer(*，input='content '，encoding='utf-8 '，decode_error='strict'…</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">scikit-learn.org</p></div></div><div class="nq l"><div class="nw l ns nt nu nq nv jn nh"/></div></div></a></div><div class="ne nf ez fb ng nh"><a href="https://keras.io/api/preprocessing/text/#tokenizer-class" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hi fi z dy nm ea eb nn ed ef hg bi translated">Keras文档:文本数据预处理</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">从目录中的文本文件生成tf.data.Dataset。如果您的目录结构是:然后调用…</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">keras.io</p></div></div><div class="nq l"><div class="nx l ns nt nu nq nv jn nh"/></div></div></a></div></div></div>    
</body>
</html>
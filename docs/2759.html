<html>
<head>
<title>Mixed models of chick weight</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">雏鸡体重的混合模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/mixed-models-of-chicks-weight-a41413c99b51?source=collection_archive---------5-----------------------#2022-06-07">https://medium.com/mlearning-ai/mixed-models-of-chicks-weight-a41413c99b51?source=collection_archive---------5-----------------------#2022-06-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="bdf5" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">贝叶斯方法</h2></div><p id="29c8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">那些读过我的帖子的人知道，或者很容易发现，我经常使用混合模型。事实上，考虑到混合模型的<a class="ae js" href="https://pub.towardsai.net/blups-and-shrinkage-in-mixed-models-sas-3fbc6662fa6b" rel="noopener ugc nofollow" target="_blank">正则化能力</a>，我几乎看不出为什么还有人会决定使用正则线性回归。</p><p id="e00d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，我将对ChickWeight数据集使用贝叶斯分析，这是r中的一个标准数据集。这个数据集的好处是它是纵向数据，这使得它是嵌套的。因此，对于混合模型，处理这种数据集应该没有问题。</p><p id="014c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">《贝叶斯方法》的副标题当然是用词不当。没有贝叶斯方法，只有数据、信息、知识和更新的循环，当涉及到整合新旧时，可以说没有比<a class="ae js" rel="noopener" href="/mlearning-ai/why-science-is-beautifully-human-and-very-frail-4f6225d32bb0">贝叶斯定理</a>更好的数学框架了。</p><p id="af31" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，我在这里要做的，以及这个例子旁边的许多其他例子，是向你们展示我如何使用<a class="ae js" rel="noopener" href="/mlearning-ai/pr-non-vax-icu-pr-icu-non-vax-f7af477896ad">贝叶斯定理</a>分析数据集。与连接到R的所有东西一样，有许多可用的包让您连接到STAN sampler，您将看到我使用不同的包来分析、检查和扩展我所做的分析。</p><p id="6ea5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这整个努力中最重要的一部分我将不得不忽略，这就是我如何选择我的前科。我拒绝使用弱的、无信息的、一致的先验，因为它们在数学上等同于知道绝对不可能的知识。</p><p id="0c39" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以，我用了我不能真正备份的信息先验，因为确定你的信息先验需要一个完整的科学周期。这并不容易，但一旦你有了它，贝叶斯分析远远胜过任何一种频率，当代看数据。这就是为什么它只是贝叶斯定理的一部分。一个重要的部分，但仍然只是一部分！</p><p id="0d9b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们开始吧。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/a394c039410e7d9d18b091f78562b089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kLF4I7z7ZnWdQsVbdQvFuA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">A quick look at the chickweight dataset shows you it is longitudinal data which is nested.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kj"><img src="../Images/762d01ffe563bb4265c1bafa6f92c3a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4jV8-I8YBqwdGzu0mjydQ.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Fancy output of simple linear regression models. Too fancy, and not informative at all.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/4a1df164be0ce995470edd382e9d2271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*87lPzbDcALN816nT3oh-kw.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Boxplot of the data. We have four treatments, 12 measurement points and an increasing variance.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/6db4bea2b1e15a4160f0df39fb88c26a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iUL6A9JG5XLEyg4bVII1Pg.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">The smoothed Diet means. Their meaning fades as time goes on due to the increasing variance.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/9fbc3067e1a4610561480ba2bb23ecfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1wm1BuYU898M6Vt1lfiV5Q.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Showing the raw data on top of the means.</figcaption></figure><div class="ju jv jw jx fd ab cb"><figure class="kl jy km kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/b52ecb336d332e10ce79471295a0b466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*8SkOECi5JMjNkAncmbYQaw.png"/></div></figure><figure class="kl jy kr kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/d921d72c7d0d299d94f85d87325212b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*UrodNLmnNtkRQbxlXbGGkg.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx ks di kt ku">A first regression model, from which I plotted the grand mean (intercept only) and its diagnostics.</figcaption></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/1f5956ba96843f435918feddd27809cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jgbLFk3HsMZHScSmQPS5PQ.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/aff8e19809a138f26c5e8658b448e011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dceao21ug7Scqiq99l1vSw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">A second model, which is a mixed model, from which I plotted the predicted values coming from a random intercept (not a random slope). The calibration plot shows the model is not that bad, but does deviate seriously as values increase. This is normal considering the increased variance.</figcaption></figure></div><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/b7c3e372b2a38232463abef5bce07097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPJvo-5TJ8BuPycRqljC_A.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Trying to see if a linear regression (blue line) does better than a polynomial (red line).</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ky"><img src="../Images/b480bc67dc4ba6b34ea3c03c538e5716.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*eIwIsYrE3kdqKT6TFECEjg.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">The quadratic model performs best compared to an intercept only or a linear regression (yes, the polynomial is also linear in its parameters but you probably know what I mean).</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kz"><img src="../Images/dd657b1c6aef85db7b147994318a2e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*7MSSQkMG1q4L72Spj-tcWw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">The linear random intercept random slopes model in a nice output.</figcaption></figure><div class="ju jv jw jx fd ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/de6104b3a86b9312c84dfb3ca786a364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*xd_7FWXEOLH0INfiGWdxvA.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/c262a4c69b9990db65664ab1296a89d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*wD0Zc3hiryZ82fXrFgB58w.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">The predictions and calibration coming from a linear random intercept random slopes model. The model is severely overfitted, which you can see in the left plot. Because the random components (intercept, slope) are extremely correlated, the model will determine predictions from start to end, and from end to start. Hence, why it has such a problem predicting from the start. Fixing the values at the start would be of help, but for now, we have done enough frequentist modelling.</figcaption></figure></div><div class="ab cb"><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/6c2c5285a8fa0aef3c58df1d77edf626.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*PLrxEwIQtnyH8xsnbNK3kA.png"/></div></figure><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/61baa1db25e066deab0ab68f008e38ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*vcwmh7YxWpLdERMxAM4rbg.png"/></div></figure><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/7117f849619cb3717ccdd7753e2ca03a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*kB3JNhfXQZxh7qiXCTKehw.png"/></div></figure></div><div class="ab cb"><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/78949579fb17b700875bbc230ecce884.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*TL7RACKaqzRGOcSh0F696g.png"/></div></figure><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/10d3b2e6bdb6dc2157d7ab6cfed6d9e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*zWtlr_uEopCPien0KlvbjA.png"/></div></figure><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/3a3c15509cc16cffb0f1b8a76692ea4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qZLU-AQQ15G2z3OXYt4DrQ.png"/></div></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/2a5c7665c8b74320d71aefd3ddec5cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Iqcgz6HFnWNauayfPC_J_Q.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/58b33dcc818ea0687ab37ebde11f64bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3tpxRAleN-E500fj0ViWbA.png"/></div></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/5cbd05511dec722de406312bc5762e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uVu4dLRl2nLPzgDgspchDA.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/bcd8a597f82a8500b2c2e7dd2962b04b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*W-FTfCrYchd8Ph9RMT5t7Q.png"/></div></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/0c857325eb7c1889f6deee0b3fa70b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*zqGuN-t-9Zy7C4iRJ2a9cQ.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/268a1fd90a6ffd73cdc77060ef160dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FiQ9MZjssgUX6xT1KH_M5w.png"/></div></figure></div><div class="ab cb"><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/b7264ff5fd88b14c554d31b8d81fc101.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*jY2wtDXb8iUwJHzPMi_SCg.png"/></div></figure><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/1219adcf2f5baeb1199538c04f257561.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*e7QUnEUP2j4LMVEqAqUWwg.png"/></div></figure><figure class="kl jy la kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/ceb7662d14f598b91f9e76c537b0a0ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*JnkISllYTSqNcGeArhRYsw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx lb di lc ku">A lot of plots coming from several packages by which you can assess a mixed model. It may seem like overkill, but a mixed model has several assumptions that must be adhere to, and the model itself can easily overfit and become unstable due to the correlation matrix of the random components. Another thing we did not put IN the models is the autocorrelation component of the residual term which is necessary to deal, in a robust manner, with the standard errors</figcaption></figure></div></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><p id="cd21" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们移动到贝叶斯建模部分。我将首先展示<em class="lk"> lmer </em>模型和<em class="lk"> stan_lmer </em>模型，它们具有完全相同的语法，但肯定不会给出相同的结果。例如，贝叶斯模型根本不关心<a class="ae js" rel="noopener" href="/mlearning-ai/inference-estimates-p-values-and-confidence-limits-a-frequentist-approach-acdd45d94bd5"> p值</a>，你也不应该关心。永远不会。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/0bff4e9b930c17fdf46342fae00ec32e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1EEE8l65imkvT7r3ss_nA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">The <strong class="bd ll">lmer model</strong> results, showing a random intercept random slopes model. The correlation of -0.99 between the random components should have you worried. A text-book example of overfitting the model.</figcaption></figure><div class="ju jv jw jx fd ab cb"><figure class="kl jy lm kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/6d4b3188c8af993323c05edf51ff1e67.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*O7XPtVITTx5D31A9mddt5A.png"/></div></figure><figure class="kl jy ln kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/69227262320955adad7a51c57f1e3001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*pNheW1w6trfdisofkQ21ww.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx lo di lp ku">And the results of the <strong class="bd ll">Bayesian model</strong>, which shows all the posterior estimates. Do note that NO prior distributions were specified, so the results should amount to almost exact replicates compared to the <strong class="bd ll">lmer model</strong>. We see it does not, but does show sufficient overlap. Nevertheless, a Bayesian model with no prior is a model bases solely on the likelihood, which is similar to the maximum or restricted maximum likelihood estimates we see in frequentist models.</figcaption></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/73c9392cedd356d792b8ce7a565ef16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ls-DZhAHAY7ZpOVkV1gvzQ.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/a3f5fd9d4ded3654acd2d9bb4e920a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iVmuuw2UxFc-nIcvVQc8nw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">Just as we can assess the random components of the <strong class="bd ll">lmer model</strong>, we can also compare them of the <strong class="bd ll">Bayesian model</strong>. Looks good to me, with sufficient rank order to warrant the inclusion of both random components (intercept and slope).</figcaption></figure></div><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lq"><img src="../Images/5a21d9ef8f0e828616aa136d1ea27417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n4S_lhDRGoiIPE-28PdTCQ.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">The predictions coming from the <strong class="bd ll">Bayesian model</strong>. If you compare these posterior draws to the predictions from the <strong class="bd ll">lmer model</strong>, you can see it suffers the same problems. Way to high correlation of both random components leading to some bad predictions at the start. Correlation is not causation and leads to issues both ways.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lr"><img src="../Images/c2daeecae1d862b22b2884ae775ddb3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rPI-hIfZD-DEqxbfWcnzRw.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">There is another package, called <strong class="bd ll">brms</strong>, which can do the same as <strong class="bd ll">stan_glmer</strong> but is even more intuitive. You can see its results in the plot above.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/02c51b56beff0ecef409240a73824ed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tPwdWyOorAoVplbduBBzpA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">And the posterior distributions coming from the model, which had no specific priors included. Hence, nothing really different from a standard mixed model constructed in <strong class="bd ll">lme4</strong>.</figcaption></figure><div class="ju jv jw jx fd ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/60bd688c36724f94dbc179f5b63017b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sAwJbEsCiIOi3Gef2v2wAA.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/5fd770e7d150cefd35760cfe9c14c941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XhQx5UgKeF3Oupm9EcibNw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">Posterior draws from which to assess the chains. You want to see no patterns in the chains, it needs to be messy, noisy and overlapping.</figcaption></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/d0ac106c8b7bbf6ba0e5bb924791d1df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*2AW8IExiy1rZVlIqW5kutA.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/5cc6d6544c2b92f19f03986c45093d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*0AODlzAO4_FVLHCMz_mHew.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">Differences between observed responses and posterior draws.</figcaption></figure></div><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/06f8f38597241b23e796d2488e068e38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h4J7nmqehX1QkdGu1kgimQ.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Assessment of the (mean, sd) of the observed response, and that of the sampling space. What you want to see is that the sampling space does not show any boundaries, not for a response on the normal distribution. However, what you DO NOT HAVE TO SEE, is that the observed value is within the sampling space of the posterior draws. The reason why the point of the observed (mean, sd) is almost in the middle of the sampling space is because we DID NOT indicate any priors. What you see is just sampling, nothing more, nothing less. Looks nice but hardly carries any worthwhile information.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/443d4cd2fec36a4eb2b50bfc01a85a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPrOZ1vKMQWM0fKPJScqMw.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Leave-One-Out resampling looking for Probability Integral Transformations. What you want to see is that the values lie on the diagonal line, indicating that the model by itself is able to pick the underlying distribution, which is normal. <em class="ls">In probability theory, the probability integral transform relates to the result that data values that are modeled as being random variables from any given continuous distribution can be converted to random variables having a standard uniform distribution. This holds exactly provided that the distribution being used is the true distribution of the random variables; if the distribution is one fitted to the data, the result will hold approximately in large samples</em></figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/67913e9512fc461f1c94398d2eff7ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5GZqjAn0CFbua-Vwh3Tj_w.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">The observed median response, per diet, and the sampling space coming from the posterior draws.</figcaption></figure><p id="6533" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们进入有趣的部分。确定先验。老实说，没有信息先验，贝叶斯分析提供的消息很少，并且陈述没有信息先验的贝叶斯分析不是获取知识的方式。事实上，我会说，使用非信息性先验比任何信息性先验更难辩护。因为，如果你使用了一个非信息性的先验，你为什么要首先进行这项研究呢？填补空白，当然，但它不是凭空出现的。此外，你如何估计运行一个像样的<a class="ae js" rel="noopener" href="/mlearning-ai/general-introduction-to-design-of-experiments-in-animal-science-using-sas-for-codes-fe1c5272b37a">实验</a>所需的<a class="ae js" href="https://towardsdatascience.com/how-many-samples-do-you-need-simulation-in-r-a60891a6e549" rel="noopener" target="_blank">样本量</a>？</p><p id="94ee" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，让我们看看<strong class="iy hi"> brms </strong>包在数据中找到了什么样的先验，我们将陈述哪些先验。请注意，我没有进行任何事先分析，也没有对什么是好的前科做任何研究，因为我没有设计这项研究。但我确实确保了事先提供信息，把它们保持得很紧，但不要太过分。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lt"><img src="../Images/98d0ba0ae4832b0a3f1dd7c0e97f580b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*2pzkBATcXf26n9Q5Aj8b_A.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lu"><img src="../Images/d5510c1db7334ece173489eacdfbb518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ej_JEMQTGb7HxvZMGRYnsA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">For any kind of variance estimate, <strong class="bd ll">gamma distributions</strong> work wonders, as they have a natural boundary of one which is also the natural boundary of a variance component.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lv"><img src="../Images/71f1fa77ea9277ecb85d4d4b35a6b204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*duMawGEIRN62uvVC6dWphg.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">The posterior distributions are now a true combination of the prior, likelihood and the entire dataset.</figcaption></figure><div class="ju jv jw jx fd ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/a57ef5c5623d23a7209037db4f9c7dc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3hanl7mv5SIZOWi_rRNdvg.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/900aab3612c294014c012e811ec7e1c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*avtLY4jg_RPSWKkXe3k5Lg.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">Chains look good.</figcaption></figure></div><div class="ab cb"><figure class="kl jy lw kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/bb6c167f349a3904eb2d7681ac77fb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*ZyqT51LqTszgxydML95FUw.png"/></div></figure><figure class="kl jy lx kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/27d16b582d9c8ce674c9f9225b14ffa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*ynttxcHoTUAv8oTYoMw8mQ.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx ly di lz ku">Posterior predicts look good. Still issues on the intercept though.</figcaption></figure></div><div class="ab cb"><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/4fd2e5cc9a481280176b8580bf92a995.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*hY7Q1h89K0F7bcNhkrDDIw.png"/></div></figure><figure class="kl jy kv kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/916fb0f77908847e01d1d02960591055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*nzJYcnd0kIcf2JWhfacW6w.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx kw di kx ku">Sampling went well.</figcaption></figure></div><div class="ab cb"><figure class="kl jy ma kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/87fa8ac134de58e70bf0972f1442ebc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*X6vxiz8UgMt0AqfmYDjOtw.png"/></div></figure><figure class="kl jy mb kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/a29cb0c053c60bd1dd78681a59c45845.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*Y9VDua-4rSjoen1YWUalTg.png"/></div></figure><figure class="kl jy mc kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/960267231cedf84e1e9d14724e272e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*Y97U0dwcOc8psztqf4K21Q.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx md di me ku">Predictions look good as well. They DO NOT have to be though. This should never be forgotten. All the previous plots are really to assess the sampling, not if you are able to fully connect to the latest dataset. That is not how science works.</figcaption></figure></div><div class="ab cb"><figure class="kl jy mf kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/7892dc361ba11889e1e6f6114fd7f30b.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*qEK0cJjsGyhZC3got988Vw.png"/></div></figure><figure class="kl jy mg kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/62311c79eef3496b9dcd71aa19a91748.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*x85pXgjp0Ctv2pS7g9UqCA.png"/></div></figure><figure class="kl jy mg kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/227760161f6eaf964d2268faf7533cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*7Nq17MZF6bYhH8dLNJGewA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx mh di mi ku">And more fancy plots.</figcaption></figure></div><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mj"><img src="../Images/8fde439263f1e3826c534b2b2dfc35b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCSewa1BQFM_J2UUa3N1gA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Even more fancy plots.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mk"><img src="../Images/5d45810bf3bfb8a0322ceff10fefa61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZEf5AsdqFwXXayvzyFkwbg.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Posterior distributions of the diets. As you can see, just looking at the diets without taking into account <strong class="bd ll">time </strong>or the <strong class="bd ll">chicks </strong>makes no sense at all.</figcaption></figure><p id="99b0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，到了有趣的部分。比较饮食，边缘的，或有条件的。就像我之前说的，忘掉p值吧。它们完全没有意义。查看差异的分布并非没有意义，因为这些估计值有助于更深入的分析和在新模型中的进一步整合。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mk"><img src="../Images/56de6b7d630cf30ccddd3bc00f662a0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*raqFXF58qCJ-s8p5d0Iz6w.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Any differences that includes a zero in its distribution is not meaningless, but cannot rule out the possibility of no effect. The 5% threshold we often accept in frequentist analysis does not play a role here, although of course, it could. But I will not.</figcaption></figure><p id="41a8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们运行一个最终模型，看看<strong class="iy hi">时间</strong>和<strong class="iy hi">饮食</strong>之间的相互作用。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ml"><img src="../Images/92d974fc528ff1b5420cf158dcc1de00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*6rDlJ53V4fRaeQsZINNaIQ.png"/></div></div></figure><div class="ju jv jw jx fd ab cb"><figure class="kl jy mm kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/5dc7a259af34a199e2ca2003240dc349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*hqJa15AEr0b-m5eKxSzDqA.png"/></div></figure><figure class="kl jy mn kn ko kp kq paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><img src="../Images/6254e48c575164c2e09e220d2421116f.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*sWs1MWcdOSU4iHbQpInJ_Q.png"/></div></figure></div><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mo"><img src="../Images/3c29465d893ca11a4e22f1b71cc9d122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kw9joPM4PTAWZZ0er2zfyw.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Predictions seem to coincide with the data better in the middle of time, not the beginning or the end.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mp"><img src="../Images/2f4f3a61eb330fa472c072ab750a444d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9WlBceTMHgdDvxm2Jn1AeA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Comparison between diets at time = 10.7 which is the mean time point. Of course, one could enter any time point they would like.</figcaption></figure><p id="124f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我希望这个小例子给出了一个关于如何使用混合模型对纵向数据建模的新观点。代码在下面，更多的帖子将跟随这个。</p><p id="10e2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">尽情享受吧！</p><figure class="ju jv jw jx fd jy"><div class="bz dy l di"><div class="mq mr l"/></div></figure><div class="ms mt ez fb mu mv"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mw ab dw"><div class="mx ab my cl cj mz"><h2 class="bd hi fi z dy na ea eb nb ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nc l"><h3 class="bd b fi z dy na ea eb nb ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nd l"><p class="bd b fp z dy na ea eb nb ed ef dx translated">medium.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj kd mv"/></div></div></a></div></div></div>    
</body>
</html>
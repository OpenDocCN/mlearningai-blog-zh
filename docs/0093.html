<html>
<head>
<title>Turn Your Computer into an Artist with AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能把你的电脑变成艺术家</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/turn-your-computer-into-an-artist-with-ai-8a58014bb5d4?source=collection_archive---------1-----------------------#2021-01-29">https://medium.com/mlearning-ai/turn-your-computer-into-an-artist-with-ai-8a58014bb5d4?source=collection_archive---------1-----------------------#2021-01-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/33e52663c6b467ce0bae1ed891a3bc03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zDCpR6jUlbUJ93QE.jpg"/></div></div></figure><p id="3a05" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">想象一下，如果文森特·梵高是一台电脑。</p><p id="38cf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">想象一下，如果梵高的电脑可以学习创作梵高名画的数字版本，而不是绘制画布和混合颜色来创造星空。</p><p id="7d78" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一台可以创造艺术的电脑，就像这台假设的梵高电脑，看起来相当令人印象深刻。很难想象计算机拥有创作像《星夜》这样的画作所必需的创造力和灵活性。</p><p id="2fc4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然而，事实是，任何计算机都可以像梵高一样学习创造艺术。</p><p id="dca6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">不幸的是，你的电脑不能像梵高那样在画布上绘画。但它可以创造数字艺术，为了教它如何创造这样的艺术，我们求助于生成性对抗网络(GANs)。</p><h2 id="2d93" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">GANs简介</strong></h2><p id="edd2" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">我不会深入研究GANs的技术细节，但是如果你对它们的内部工作方式感兴趣，<a class="ae kn" rel="noopener" href="/@ayannair2021/a-deep-dive-into-gans-c8b8eb6a4dac">这里有一篇我写的深入描述GANs复杂性的文章。</a></p><p id="3d8b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">给定一些原始数据，<strong class="ir hi">阿甘的最终目标是学习如何生成看起来像是直接来自原始数据的新数据样本</strong>。用技术术语来说，GAN学习从潜在空间映射到所需的数据分布(这只是人工智能专家前一句话中的复杂方式)。</p><p id="5455" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里有一个例子——假设给一只甘一个装满香蕉图像的数据集。GAN希望通过检查提供给它的香蕉数据集来学习创建自己的香蕉图像。</p><p id="ad1d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">GANs通过利用两个组件——生成器和鉴别器，实现了生成与原始数据集相匹配的数据的目标。<strong class="ir hi">生成器负责创建新数据，而鉴别器则试图区分真实数据和虚假数据。</strong>GAN的预期最终结果是发生器能够欺骗鉴别器，使其相信其产生的数据是真实的。</p><p id="3ec5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">创建GAN时，生成器和鉴别器将是两个独立的<a class="ae kn" href="https://www.forbes.com/sites/bernardmarr/2018/09/24/what-are-artificial-neural-networks-a-simple-explanation-for-absolutely-anyone/?sh=793d9fe81245" rel="noopener ugc nofollow" target="_blank">神经网络</a>。生成器将一个随机向量(换句话说，一行随机数)作为输入，并在通过网络发送该向量时将该向量转换为新的数据样本。鉴别器接收数据样本并转换该数据样本以返回对应于数据样本真实性的概率。</p><p id="54a5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">深度卷积GANs (DCGANs) </strong></p><p id="72fe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了训练我们的甘成为一名艺术家，它必须在处理和生成图像方面变得熟练。这使得我们的艺术家甘成为卷积神经网络(CNN)应用的理想领域。</p><p id="4b67" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CNN是一种神经网络，以擅长分析图像数据而闻名(<a class="ae kn" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">在此了解更多关于CNN的信息</a>)。由于其处理图像的能力，细胞神经网络可以应用于GANs以帮助他们有效地产生图像样本。<strong class="ir hi">CNN和GANs的这种组合被称为深度卷积生成对抗网络，或DCGAN。</strong></p><p id="d54c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">DCGAN架构的关键区别在于，鉴别器和发生器不是由普通神经网络组成，而是由多层CNN组成。然而，鉴别器和发生器的功能保持不变。</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ko"><img src="../Images/defce8cde1be26a0f9f36579bb3e2537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_SYADvVHP2MDkOlH.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx">Diagram for the structure of the DCGAN’s generator. The diagram depicts how an input is transformed as it goes through the network, with each rectangle object representing the input shape after passing through a convolutional layer.</figcaption></figure><p id="1701" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">DCGAN为普通GAN增加了惊人的功能；<strong class="ir hi">生成逼真、高质量图像的能力使DCGAN成为艺术生成等应用的关键GAN架构。</strong></p><h2 id="c009" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">py torch简介</strong></h2><p id="3afa" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">由于复杂的底层算法和数学，从头开始编写创建DCGANs和其他类似架构的程序相当困难。像PyTorch这样的工具，一个为开发人工智能模型而开发的库，为我们处理了困难的数学问题，并使创建和训练像DCGANs这样的模型变得容易得多。</p><p id="cfbc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">PyTorch具有相当广泛的功能，但这里是用于创建DCGAN的主要PyTorch概念。</p><ul class=""><li id="bfc3" class="kx ky hh ir b is it iw ix ja kz je la ji lb jm lc ld le lf bi translated">PyTorch Tensors: 本质上是PyTorch存储数据集合的方式。如果你熟悉矩阵和向量，张量就是矩阵的PyTorch版本。</li><li id="ec50" class="kx ky hh ir b is lg iw lh ja li je lj ji lk jm lc ld le lf bi translated"><strong class="ir hi">数据集和数据加载器:</strong> PyTorch的工具可以轻松定义和修改GAN训练的数据。</li><li id="cb99" class="kx ky hh ir b is lg iw lh ja li je lj ji lk jm lc ld le lf bi translated"><strong class="ir hi"> Conv/Conv转置层:</strong>构成我们的发生器和鉴别器的CNN中的主要层。</li><li id="cb80" class="kx ky hh ir b is lg iw lh ja li je lj ji lk jm lc ld le lf bi translated"><strong class="ir hi">优化器:</strong>这些优化器允许模型从数据集中学习。</li><li id="637b" class="kx ky hh ir b is lg iw lh ja li je lj ji lk jm lc ld le lf bi translated"><strong class="ir hi"> Transforms: </strong>允许PyTorch改变数据集中的图像，使我们能够执行调整大小、裁剪或翻转图像等操作。</li><li id="6266" class="kx ky hh ir b is lg iw lh ja li je lj ji lk jm lc ld le lf bi translated"><strong class="ir hi">归一化:</strong> PyTorch将图像视为一个范围从0到255的像素值矩阵。众所周知，人工智能不擅长处理大范围的数据，因此使用归一化来压缩这些数字的范围，使它更容易从图像中学习。</li><li id="d8df" class="kx ky hh ir b is lg iw lh ja li je lj ji lk jm lc ld le lf bi translated"><strong class="ir hi">损失函数:</strong>本质上是模型如何从错误中学习。</li></ul><p id="f9f1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你在下面的代码中看到这些词，不要害怕！这些解释给出了这些术语含义的要点。</p><h2 id="4799" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">数据转换</strong></h2><p id="48d0" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated"><em class="ll">快速说明——这段代码摘自</em> <a class="ae kn" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank"> <em class="ll"> PyTorch的DCGAN预排</em></a><em class="ll">；我只是做了一些调整，并将其应用于一个新的数据集。如果你对GANs感兴趣，我强烈推荐你看看这个教程！</em></p><p id="e29c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们已经了解了所使用的技术，我们可以开始把我们的电脑变成一个艺术家了！</p><p id="33d7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">第一步是<strong class="ir hi">识别DCGAN将从</strong>学习的数据集。对于艺术创作，数据集应该主要由某种艺术风格的绘画组成；GAN将学会以选择的风格合成新的图像。作为起点，我摆弄了一下这个中国古代艺术数据集，它包含了大约5800幅中国画的图片。</p><p id="794d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在识别数据集之后，我们需要<strong class="ir hi">定义一些变换来增加图像并产生更好的训练结果</strong>。以下是我应用的图像转换:</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/0cb02d37588969bbe3daab46f84219c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/0*56jMzp2FEUVx3k5X"/></div><figcaption class="kt ku et er es kv kw bd b be z dx">Set of transforms that I utilized for augmenting the dataset images.</figcaption></figure><p id="49a3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">前两个转换调整原始数据集图像的大小并对其进行裁剪，以创建64x64的图像，从而可以将图像传递到鉴别器中进行训练。下一个变换随机水平翻转图像。然后将图像转换成PyTorch张量并归一化。</p><h2 id="6c92" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">定义发生器和鉴别器</strong></h2><p id="31f7" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">应用转换后，我们可以继续创建我们的生成器和鉴别器了！</p><p id="aca0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">快速回顾一下——生成器将随机向量作为输入，输出新合成的图像，而鉴别器将图像作为输入，输出表示它认为图像有多“真实”的概率。知道了它们的输入和输出，发生器和鉴别器可以定义为PyTorch中的CNN。</p><p id="cccd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在事情变得有点像T21的技术了。</p><p id="52c2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">把图像想象成一个三维物体。它的高度和宽度由像素值定义，深度为三。彩色图像需要红色、绿色和蓝色的组合来创建它们的颜色，并且每个深度单位表示图像的每个像素中红色、绿色和蓝色的量。</p><p id="e8da" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">生成器尝试从一维的向量映射到三维的彩色图像。这个过程被称为<strong class="ir hi">上采样</strong>，因为当输入通过发生器时，维度会增加。</p><p id="3221" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然而，正常的CNN层用于<strong class="ir hi">下采样</strong>；它通常将其输入压缩成更小的维度。因此，发生器需要一种称为卷积转置层的CNN层，它对其输入进行上采样。</p><p id="c68f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些层在生成器中被大量使用，在生成器中，随机向量通过由卷积转置、批量归一化(帮助神经网络更快训练的归一化步骤)和ReLU层(这实质上允许神经网络学习更复杂的信息)的堆栈组成的CNN发送。最终输出是三维的、新合成的彩色图像。</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/32cf45818eeffa620b1dcb95d8e7eefd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6FNeU-syTHZJefoY"/></div><figcaption class="kt ku et er es kv kw bd b be z dx">Code for creating the generator in PyTorch.</figcaption></figure><p id="05ee" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">与发生器不同，鉴别器对其输入进行下采样，将三维图像转换为概率。它通过卷积、批量归一化和泄漏ReLU(非常类似于ReLU的功能)层的堆栈来实现这一点，这些层将图像逐步压缩为单个概率。</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lo"><img src="../Images/f7ab46fd854a8f1a98617d84bb9bd3d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_fJXTSwxsMeMvqDb"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx">Code for creating the discriminator in PyTorch.</figcaption></figure><p id="470d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">generator和discriminator类都有一个forward方法，该方法允许输入进入函数并被函数修改。输入被传递到网络并被转换的过程的正式术语叫做<strong class="ir hi">前向传播。</strong></p><h2 id="501c" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">定义损失函数和优化器</strong></h2><p id="af40" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">生成器和鉴别器在定义后不会立即工作；相反，他们学习如何通过处理数据分别生成图像和识别假图像。而这两个网络要学习，就需要<strong class="ir hi">损失函数和优化器。</strong></p><p id="c440" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于DCGAN，使用一种称为二进制交叉熵(BCE)损失的特定类型的损失。这种损失函数特别适合处理需要分类的输出(比如鉴别器预测图像是真是假)。</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lp"><img src="../Images/2073e986a9b225cb9aed3e42d12935ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3VJ38euUc4p8Ai7UOxSgeA.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx">Binary Cross-Entropy Loss Function. Image source <a class="ae kn" href="https://i.stack.imgur.com/HlYNr.png" rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure><p id="b5df" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">用于生成器和鉴别器的优化器是Adam，它是训练大多数神经网络的首选优化器。</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/54e1b329b5d8eb07eb3101c36bdfc54b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/0*wYuFMlSbqMBEeTO-"/></div><figcaption class="kt ku et er es kv kw bd b be z dx">Code for defining the loss function and optimizers in PyTorch.</figcaption></figure><p id="d6ff" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们已经创造了一切，我们需要训练甘创造一些艺术！</p><h2 id="ca82" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">结果</strong></h2><p id="4df1" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">在训练DCGAN大约650个时期后，输出看起来有些真实。DCGAN似乎捕捉到了训练图像的风格。它甚至能够复制训练集中出现的树木和山脉等结构！</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/b7ec9d9495f8e4baf4f8de109161d38d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n1frSxnlIBH3E1eh"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx">Outputs of the 64x64 DCGAN. The left-hand images are images directly from the dataset, and right-hand images are synthesized by the GAN. Notice how the GAN was able to replicate waterfalls, flowers, and mountains!</figcaption></figure><p id="d0fa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我对输出非常满意，并认为GAN达到了相当好的性能水平。然而，我唯一的问题是图像太小了。</p><p id="45cc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">之前创建的DCGAN仅限于创建64x64像素的图像。然而，通过对生成器和鉴别器的代码进行一些轻微的调整，我让它们能够生成128x128像素的图像。</p><figure class="kp kq kr ks fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/872d839f4f3c9a85ebb01830f490c586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*erQ6WBA50h7Ab24O"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx">Outputs of the 128x128 DCGAN. Left side contains training images and right hand side contains generated images.</figcaption></figure><p id="ee77" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">输出质量的下降相当明显。<strong class="ir hi">当增加输出大小时，模型有更多的参数需要训练，因此需要更多的训练时间来生成清晰的输出。</strong>如果我增加了训练历元的数量，图像质量无疑会更清晰。</p><h2 id="c63e" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">可能的改进</strong></h2><p id="5e35" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">虽然该模型能够生成一些高质量的图像，但DCGAN生成的大多数图像看起来与数据集中的图像非常不同。要提高图像质量，以下是一些可行的方法:</p><p id="2dd7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">利用不同的GAN架构。</strong>DCGAN虽然令人印象深刻，但并不是最好的GAN架构。像NVIDIA StyleGAN或Wasserstein GAN这样的替代产品已经获得了更高的图像质量。</p><p id="1e65" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">训练模型的时间更长。</strong>让模型扫描数据集进行更多次迭代可能会使它能够获得新的艺术特征，然后可以用来生成更好的图像。</p><p id="5934" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">寻找更大的数据集。</strong>用于训练该模型的数据集仅包含约6000幅图像，而<a class="ae kn" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank">本PyTorch教程</a>中用于测试DCGAN的数据集包含约200，000幅图像。更多的数据为模型提供了更多的信息来分析，使它能够对它试图复制的图像有更深的理解。</p><p id="e1d7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">无论如何，训练一台计算机来创造艺术不是一件容易的事，毫无疑问，DCGAN在复制数据集中的图像方面做得非常出色！</p><p id="768e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">通过使用DCGAN和可用的艺术数据集，任何计算机都可以获得任何艺术家的能力。而这仅仅是甘的开始；这项技术正在进行许多改进，很快计算机生成的艺术可能会与人类制作的艺术相媲美。因此，人工智能的力量并不局限于技术领域——GANs通过允许它通过技术改变艺术来扩展人工智能的能力。</p><h2 id="36ed" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated"><strong class="ak">TL；博士</strong></h2><p id="07c6" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">GANs能够使用两个神经网络(称为生成器和鉴别器)生成图像；鉴别器试图区分真实图像和生成图像，而生成器试图欺骗鉴别器，使其相信其图像是真实的。DCGANs使用两个卷积神经网络(CNN)来构成生成器和鉴别器。因为CNN擅长图像处理，所以DCGANs擅长生成图像。在这个项目中，我使用DCGAN的图像生成功能来生成中国古代艺术和新的梵高画作。</p><p id="81c6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ll">如果你想亲自尝试一下art DCGAN，可以看看我的</em><a class="ae kn" href="https://github.com/ayan-aji-nair/art-generation-gan" rel="noopener ugc nofollow" target="_blank"><em class="ll">Github Repo</em></a><em class="ll">！</em></p><p id="fe05" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ll">点击</em> <a class="ae kn" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> <em class="ll">此处</em> </a> <em class="ll">查看DCGAN论文原文链接。</em></p><p id="fee1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ll">谢谢你看完！别忘了留个</em>👏<em class="ll">也是！</em></p><p id="1e1d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">简单介绍一下我——我今年17岁，非常喜欢颠覆性技术，主要是人工智能。如果你喜欢这篇文章或者想谈谈有趣的深度学习/机器学习项目、研究论文或想法，请通过我的<a class="ae kn" href="https://www.linkedin.com/in/ayan-nair-31388a1b7/" rel="noopener ugc nofollow" target="_blank"><em class="ll">LinkedIn</em></a><em class="ll">，</em><a class="ae kn" href="https://www.instagram.com/nair.030/" rel="noopener ugc nofollow" target="_blank"><em class="ll">insta gram</em></a><em class="ll">或电子邮件(ayan.aji.nair@gmail.com)给我留言！你也可以通过我的每月简讯获得我的酷项目的更新和我写的新文章——在这里订阅</em><a class="ae kn" href="https://www.subscribepage.com/a8y3j1" rel="noopener ugc nofollow" target="_blank"><em class="ll"/></a><em class="ll">！</em></p></div></div>    
</body>
</html>
<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/classification-using-logistic-regression-6f2927b82c63?source=collection_archive---------4-----------------------#2022-05-20">https://medium.com/mlearning-ai/classification-using-logistic-regression-6f2927b82c63?source=collection_archive---------4-----------------------#2022-05-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="a3b5" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">机器学习中的分类问题(逻辑回归)</h2><p id="0af1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io hr ip iq ir hv is it iu hz iv iw ix iy ha bi translated">分类问题是机器学习中一类重要的问题。这些问题对企业有重要的启示，下一次营销活动是否会导致顾客的转化。获得的下一个客户会导致收支平衡吗？</p><p id="5560" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">有两种分类问题:</p><ul class=""><li id="d8f4" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated"><strong class="ig jn">二元分类</strong>:这是一类答案在结果上是二元的问题，<em class="jo">要！！还是不要了！！</em>。这类问题的输出是“是”或“否”以及“0”或“1”的形式(编码为二进制变量)。这类问题的一些例子可以是:</li><li id="33cc" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">特定的笔记本电脑/台式机是否会要求维修</li><li id="17e4" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">预测客户是否会拖欠贷款</li><li id="72b0" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">一名新员工的表现是否会达到最佳</li><li id="4e15" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">新的数字营销活动会产生更高的转化率吗</li></ul><p id="d368" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn">多类分类</strong>:</p><p id="b926" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这是一种输出是一组离散元素的问题。<em class="jo">注意这里的Discreet这个词</em>。这些变量中的输出再次被编码为分类变量(比如0–9，如果我们有9个类别)。一些例子可以是:</p><ul class=""><li id="0f8d" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">在1-5分的范围内，新员工的可能得分是多少</li><li id="9bbc" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">MNIST数据集分类对图像进行分类</li></ul><p id="4f97" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn"> <em class="jo">注</em> </strong> : <em class="jo">美国高中生和美国人口普查局员工手写的7万个数字小图像的MNIST数据集。这种算法已经被用作任何机器学习算法的游乐场。我将尝试在其他笔记本中介绍该数据集。在这本笔记本中，我们将使用一个相对简单的数据集。</em></p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="299e" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn">逻辑回归</strong>:解决一个分类问题有很多方法，其中一种方法就是使用逻辑回归。还有其他方法的例子——分类树(我们将在另一篇文章中介绍)。神经网络也被用来主动解决分类问题。然而，我们在本文中的重点将是逻辑回归。</p><p id="994e" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">之所以称之为逻辑是因为建模是通过一个函数完成的:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es kb"><img src="../Images/5461e6670e9b80413199ab67df3d56b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*Q2g4tIK2dyPGcYYpgS5AiQ.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX Editor add-on for Chrome</figcaption></figure><p id="e187" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">该函数也称为<em class="jo"> SIGMOID函数</em> <br/> Z是我们的常规线性回归方程，因此:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es kn"><img src="../Images/fd093d44317042f4debe4203d4cf550a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*Ur5f1Mqx42b-9o7gh0IVcg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="2d2a" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">现在，我们已经将一个多变量问题公式化，该问题可以转换为生成值的Sigmoid函数。现在我们还知道另一件事，Sigmoid函数可以将最大值1作为z ➛ ∞ <br/>同样，Sigmoid函数将最小值0作为z ➛ -∞</p><p id="51e4" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">通过上面的讨论，我们已经转换了一个函数变化范围[-∞，∞] ➛ [0，1]</p><p id="cd4f" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn">阈值概率</strong>:这里还有一个问题，我们有一个函数，它仍然取0到1之间的连续值。然而，在二进制分类的情况下，我们需要值0或1。因此，我们使用某个阈值概率，例如0.5。因此，如果我们的逻辑函数取值大于0.5，我们将该值视为1，如果小于或等于0.5，我们将该值视为0。</p><p id="2f6e" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这本身就是一个壮举——我们已经将取值在-∞和∞之间的连续函数转换为取精确值为0或1的函数，因此生成了一个二元分类器。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="5ef6" class="hf hg hh kp b fi kt ku l kv kw">##Plotting of Sigmoid function<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>A = np.arange(-20,20,0.5)<br/>B = 1/(1 + np.exp(-A))<br/>plt.plot(A, B)<br/>plt.show()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/1daab5aa3afa3dc806085034f2448673.png" data-original-src="https://miro.medium.com/v2/format:webp/1*NN9_t7kIhFRA3b2GvwN19g.png"/></div></figure><p id="0278" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">上面是在-20和+20之间绘制一个sigmoid函数的代码。您可以将两边的值更改为任何值，该函数永远不会低于0，也不会高于1。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="b832" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn">造型过程</strong></p><p id="8f43" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">现在让我们开始建模过程，因为我们知道任何建模活动都由以下步骤组成:</p><ul class=""><li id="b3a7" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">读出数据</li><li id="d975" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">处理数据</li><li id="4bd1" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">运行模型</li><li id="1f53" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">选择最重要的自变量</li><li id="7800" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">通过评估模型的性能来微调模型</li></ul><p id="00d3" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">在逻辑回归中，我们选择<strong class="ig jn">阈值</strong>，如果它们是手动选择的，我们需要通过选择合适的阈值来微调模型。</p><p id="933e" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">读取数据集。该数据集在<a class="ae ky" href="https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/." rel="noopener ugc nofollow" target="_blank">这里</a>公开发布。</p><p id="afca" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">但是，为了运行模型，我们将对数据集进行一些更改。<br/> <em class="jo">使用数据的步骤</em>:</p><ol class=""><li id="460d" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy kz jk jl jm bi translated">从上面的链接下载数据</li><li id="2e6b" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">打开excel表格中的数据和数据选项卡-&gt;文本到列-&gt;使用分隔符拆分-&gt;选择空间-&gt;在所需位置将数据保存为CSV文件</li><li id="9876" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">使用<code class="du la lb lc kp b">pd.read_csv()</code>加载python中的数据</li><li id="55b3" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">按照<code class="du la lb lc kp b">base_data_2.columns = [...]</code>中给出的方式创建列名</li><li id="8c2b" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">原始数据集具有1，2具有bad_loan和non_bad_loan状态，我们将它们转换为0和1。这只是为了方便使用。</li><li id="65af" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">我们使用选择的列来运行一个截断的模型</li></ol><p id="4bc5" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><em class="jo">运行截断模型的原因:因为一些附加变量可能存在共线性，所以我已经删除了这些变量，如foreign_worker和job正在提供类似的信息。因此，为了使文章的长度可行，我已经消除了感知共线性。您可以尝试在完整数据集上运行模型，并比较您的结果</em></p><p id="b909" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">为了运行我们的模型，我们将从数据集中选择一些列:<br/> <em class="jo"> checkin_acc，duration，credit_history，amount，savings_acc，present_emp_since，inst_rate，personal_status，inst_plans，num_credits，job，status </em></p><p id="29f1" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">作为练习，您可以尝试在整个数据集上运行模型。现在我们将使用截断的数据。<br/>我还在下面的git-hub repo <a class="ae ky" href="https://github.com/muditsharma1234/Machine-Learning-Basics/blob/main/2022_05%20Classification%20Problems/Datasets/German%20Credit%20Data.csv" rel="noopener ugc nofollow" target="_blank">这里</a>保存了截断的数据集(包含选定的列)。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="b796" class="hf hg hh kp b fi kt ku l kv kw">import pandas as pd<br/>import numpy as np<br/>base_data_2 = pd.read_csv("Datasets/german.data.csv",header = None)<br/>#print(base_data_2.head())<br/>#base_data_2 = pd.read_csv("~/Downloads/german.data.csv",header = None)<br/>base_data_2.columns = ['checkin_acc','duration','credit_history','purpose','amount',<br/>                      'savings_acc','present_emp_since','inst_rate',<br/>                      'personal_status','other_debters','residing_since','property','age','inst_plans','housing',<br/>                      'num_credits','job','dependent_count','telephone','foreign_worker','status']<br/>base_data_2['status'] = np.where(base_data_2['status']==1,0,1)<br/>base_data_2.head()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/9b8a35c30174ebee3b4f68504feb9f0c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ol60jYr_p27rf3AEcuf0KA.png"/></div></figure><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="0cc5" class="hf hg hh kp b fi kt ku l kv kw">import pandas as pd<br/>base_data = pd.read_csv("Datasets/German Credit Data.csv") <br/><br/>#If you want to arrive at the truncated data-set in this notebook from the original dataset you can run following steps <br/>#On the base_data_2 extracted above<br/>#selected_columns = ['checkin_acc', 'duration', 'credit_history', 'amount', 'savings_acc',<br/>#       'present_emp_since', 'inst_rate', 'personal_status', 'residing_since',<br/>#       'age', 'inst_plans', 'num_credits', 'job', 'status']<br/>#base_data1 = base_data_2[selected_columns]<br/><br/>base_data.head()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/e9c534d78bdcc289415bd7ee952664e9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*wngWP0WCP6GFL_ESiSQ4UQ.png"/></div></figure><p id="ca64" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">现在我们已经下载/提取了截断的数据集，让我们试着理解这些列的含义。<br/>你可以在这里找到原始数据集<a class="ae ky" href="https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/" rel="noopener ugc nofollow" target="_blank">的描述。<br/>在名为<code class="du la lb lc kp b">german.doc</code>的文件中。当我们试图优化我们的模型时，最后会有一个表格。</a></p><p id="9cf8" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">让我们首先尝试描述数据，以了解数据中有什么，因为数据中有许多代码，如<code class="du la lb lc kp b">checckin_acc</code>列中的A11、A12。</p><p id="a55c" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn"> <em class="jo">数据集的描述</em> </strong></p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/f8e44e3557cfa5dd15483ca9ec303c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zABTntH5n8DLrriWbWqlww.png"/></div></div><figcaption class="kj kk et er es kl km bd b be z dx">Description of Dataset</figcaption></figure><p id="52ea" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">让我们看看数据框架，以了解数据中的列及其完整性。正如您在下面看到的，数据集中有1000行，没有一列包含null元素(每个is中的非Null计数= 1000)</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="07b4" class="hf hg hh kp b fi kt ku l kv kw">print(base_data.info())<br/>print("\n \n Shape of the data set is given by -",base_data.shape)</span><span id="efba" class="hf hg hh kp b fi li ku l kv kw">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 1000 entries, 0 to 999<br/>Data columns (total 14 columns):<br/> #   Column             Non-Null Count  Dtype <br/>---  ------             --------------  ----- <br/> 0   checkin_acc        1000 non-null   object<br/> 1   duration           1000 non-null   int64 <br/> 2   credit_history     1000 non-null   object<br/> 3   amount             1000 non-null   int64 <br/> 4   savings_acc        1000 non-null   object<br/> 5   present_emp_since  1000 non-null   object<br/> 6   inst_rate          1000 non-null   int64 <br/> 7   personal_status    1000 non-null   object<br/> 8   residing_since     1000 non-null   int64 <br/> 9   age                1000 non-null   int64 <br/> 10  inst_plans         1000 non-null   object<br/> 11  num_credits        1000 non-null   int64 <br/> 12  job                1000 non-null   object<br/> 13  status             1000 non-null   int64 <br/>dtypes: int64(7), object(7)<br/>memory usage: 109.5+ KB<br/>None<br/><br/> <br/> <strong class="kp jn">Shape of the data set is given by - (1000, 14)</strong></span></pre><p id="05b3" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">如我们所见，数据集中有7个分类变量和7个数值变量。数据集中总共有1000个数据点。<br/>我们的输出变量是状态，其值</p><ul class=""><li id="d77c" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated"><strong class="ig jn"> 1:不良信用(可能违约)</strong></li><li id="a727" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn"> 0:信用良好(无违约责任)</strong></li></ul><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="fbec" class="hf hg hh kp b fi kt ku l kv kw">base_data.status.value_counts()</span><span id="338d" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong></span><span id="165a" class="hf hg hh kp b fi li ku l kv kw">0    700<br/>1    300<br/>Name: status, dtype: int64</span></pre><p id="52d7" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">坏信用和好信用之间的数据比例为70:30。如果这更偏向于任何一个方向，我们可能会陷入<code class="du la lb lc kp b">oversampling/ under-sampling</code>的问题。有一些技术可以解决这个问题，我将在另一篇文章中介绍它们。<br/>目前，我们的数据表现良好，给出了70-30的比例。</p><p id="289b" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们提取X特征，这是我们的独立变量。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="53d7" class="hf hg hh kp b fi kt ku l kv kw">X_features = list(base_data.columns)<br/>X_features.remove('status')<br/>X_features</span><span id="99a5" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong><br/>['checkin_acc',<br/> 'duration',<br/> 'credit_history',<br/> 'amount',<br/> 'savings_acc',<br/> 'present_emp_since',<br/> 'inst_rate',<br/> 'personal_status',<br/> 'residing_since',<br/> 'age',<br/> 'inst_plans',<br/> 'num_credits',<br/> 'job']</span></pre><p id="a3ae" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们使用上面的命令集提取因变量和自变量。我们得到了以下结果:</p><ul class=""><li id="2359" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">自变量:用于预测因变量的13个变量</li><li id="a54e" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">因变量:只有一个因变量，有两个级别(0和1)，因此这成为一个二元预测问题的情况</li></ul><p id="01a3" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">让我们开始我们的数据处理过程，它将有以下步骤:</p><ul class=""><li id="4137" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">分类变量编码:</li></ul><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="0cab" class="hf hg hh kp b fi kt ku l kv kw">encoded_base_data = pd.get_dummies(base_data[X_features],<br/>                                  drop_first = True)<br/><br/>list(encoded_base_data.columns)</span><span id="f09a" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong></span><span id="5a9b" class="hf hg hh kp b fi li ku l kv kw">['duration',<br/> 'amount',<br/> 'inst_rate',<br/> 'residing_since',<br/> 'age',<br/> 'num_credits',<br/> 'checkin_acc_A12',<br/> 'checkin_acc_A13',<br/> 'checkin_acc_A14',<br/> 'credit_history_A31',<br/> 'credit_history_A32',<br/> 'credit_history_A33',<br/> 'credit_history_A34',<br/> 'savings_acc_A62',<br/> 'savings_acc_A63',<br/> 'savings_acc_A64',<br/> 'savings_acc_A65',<br/> 'present_emp_since_A72',<br/> 'present_emp_since_A73',<br/> 'present_emp_since_A74',<br/> 'present_emp_since_A75',<br/> 'personal_status_A92',<br/> 'personal_status_A93',<br/> 'personal_status_A94',<br/> 'inst_plans_A142',<br/> 'inst_plans_A143',<br/> 'job_A172',<br/> 'job_A173',<br/> 'job_A174']</span></pre><p id="2fda" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">正如我们所知，pandas的<code class="du la lb lc kp b">get_dummies</code>方法只会对<code class="du la lb lc kp b">object</code>类型的数据进行编码，而<code class="du la lb lc kp b">drop_first</code>会从K级分类数据中创建K-1个类别。例如，从上面的数据描述表可以明显看出，我们的<code class="du la lb lc kp b">checkin_acc</code>有4个级别。然而，在这种情况下,<code class="du la lb lc kp b">get_dummies</code>方法会降低第一级。</p><p id="595c" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">请记住，我们也可以添加第一级。然而，根据我们在线性回归中的讨论，我们知道多重共线性需要另外处理</p><ul class=""><li id="85ed" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">条件数值变得太高</li><li id="ea3a" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">VIF参数也变得高于4，我们的模型可能无法适当地拟合数据</li></ul><p id="87b4" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">如果我们包括分类变量的所有级别，那么通过使用K-1个级别，我们可以预测第K个级别的值，这将导致多重共线性。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="4331" class="hf hg hh kp b fi kt ku l kv kw">encoded_base_data[['checkin_acc_A13','checkin_acc_A14','checkin_acc_A12']].head()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/45a2aed4d6ab054f300e8fceea0afa0f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*fk_6bWLwBk9eSfsFwuvwnQ.png"/></div></figure><p id="736f" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">让我们现在开始构建我们的模型</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="c35f" class="hf hg hh kp b fi kt ku l kv kw">import statsmodels.api as sm<br/>from sklearn.model_selection import train_test_split<br/>Y = base_data['status']<br/>X = sm.add_constant(encoded_base_data)<br/><br/>##Splitting the data into train and test datasets<br/><br/>train_X, test_X, train_y, test_y = train_test_split(X,Y,test_size = 0.30,<br/>                                                   random_state = 1)</span><span id="1a6f" class="hf hg hh kp b fi li ku l kv kw">logistic_model = sm.Logit(train_y,train_X)<br/>logistic_model_fit = logistic_model.fit()<br/>logistic_model_fit.summary2()</span><span id="c4a8" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong></span><span id="1fbc" class="hf hg hh kp b fi li ku l kv kw">Optimization terminated successfully.<br/>         Current function value: 0.467094<br/>         Iterations 7</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lj"><img src="../Images/6f640ca693186e647220442c57175689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pAKm4anJx_BVFBOvRTJDVw.png"/></div></div></figure><p id="29c2" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><code class="du la lb lc kp b">Logit</code>迭代次数的默认值为35，超过该值模型将失败。我们可以手动设置这些参数，这个过程称为<strong class="ig jn">超参数优化</strong>。</p><p id="f959" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们将在另一篇文章中讨论超参数优化。</p><p id="0740" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">以下是定义逻辑回归模型质量的参数:</p><ul class=""><li id="c17e" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated"><strong class="ig jn">与参数相关的P值</strong>(与系数遵循t分布的线性回归不同，其遵循卡方分布):该测试被称为<em class="jo"> WALD测试</em></li><li id="fb69" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn">伪R-Square </strong>:与R-Square和调整R-Square在线性回归中的作用相同。<em class="jo">但这并不是用来说20%的参数是由模型解释的(那会是一个很糟糕的模型)。我们使用混淆矩阵来确定模型的准确性。</em></li><li id="3c53" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn">似然比</strong>确定整体模型的显著性，类似于线性回归模型中的F统计(这里是P值)</li><li id="af9e" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn">对数似然</strong>检查不使用任何参数的模型更好(H0)还是有参数的模型更好(H1)。</li></ul><p id="1199" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn">过滤最重要的变量</strong> <br/>我们的P值存储在<code class="du la lb lc kp b">logistic_model_fit</code>中的<code class="du la lb lc kp b">pvalues</code>变量中，这是一个<code class="du la lb lc kp b">pandas.series</code>类型的变量，这个变量的索引是我们P值的名称，可以很容易地过滤。请记住，我们正在寻找价值为0.05美元的产品。<br/>转换成列表使得从原始数据集中提取数据更加容易。<br/>我们将在<code class="du la lb lc kp b">significant_variables</code>中保存我们的重要变量</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="58da" class="hf hg hh kp b fi kt ku l kv kw">significant_variables = list(logistic_model_fit.pvalues[logistic_model_fit.pvalues &lt;= 0.05].index)<br/>print(significant_variables)<br/>print(len(logistic_model_fit.pvalues))</span><span id="28e7" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong></span><span id="ba56" class="hf hg hh kp b fi li ku l kv kw">['duration', 'amount', 'inst_rate', 'age', 'num_credits', 'checkin_acc_A12', 'checkin_acc_A14', 'credit_history_A33', 'credit_history_A34', 'savings_acc_A64', 'savings_acc_A65']<br/>30</span><span id="0d47" class="hf hg hh kp b fi li ku l kv kw">type(logistic_model_fit.pvalues)</span><span id="c9f9" class="hf hg hh kp b fi li ku l kv kw">pandas.core.series.Series</span></pre><p id="6c46" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><code class="du la lb lc kp b">logistic_model_fit.pvalues</code>返回一个以index为变量的熊猫序列。我们可以使用过滤P值≤ 0.05来选择适当的变量</p><p id="197d" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">在30个变量中，我们有11个变量是重要的。(还记得我们最初的13个奇数变量列表由于这些变量的编码而被夸大了)。<br/>现在让我们用选定的变量运行agan模型。我们将运行模型，直到所有的P值≤ 0.05</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="e1fb" class="hf hg hh kp b fi kt ku l kv kw">logistic_model2 = sm.Logit(train_y,sm.add_constant(train_X[significant_variables]))<br/>logistic_model_fit2 = logistic_model2.fit()<br/>logistic_model_fit2.summary2()</span><span id="810d" class="hf hg hh kp b fi li ku l kv kw">Optimization terminated successfully.<br/>         Current function value: 0.488668<br/>         Iterations 7</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lk"><img src="../Images/273624f9a1e2d5329f44aae68369e337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9yoKhwNMPv6MRKSNmcdfPg.png"/></div></div></figure><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="c8e7" class="hf hg hh kp b fi kt ku l kv kw">significant_variables2 = list(logistic_model_fit2.pvalues[logistic_model_fit2.pvalues &lt;= 0.05].index)</span><span id="95e9" class="hf hg hh kp b fi li ku l kv kw">logistic_model3 = sm.Logit(train_y,sm.add_constant(train_X[significant_variables2]))<br/>logistic_model_fit3 = logistic_model3.fit()<br/>logistic_model_fit3.summary2()</span><span id="86e4" class="hf hg hh kp b fi li ku l kv kw">Optimization terminated successfully.<br/>         Current function value: 0.490472<br/>         Iterations 7</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ll"><img src="../Images/414ed7bf00f740d750cdf655f4884dec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5pGLoJr73TFhlp2IcFXp5w.png"/></div></div></figure><p id="f76a" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">现在我们根据我们创建的<code class="du la lb lc kp b">model3</code>来预测变量的值。现在所有的p值都小于0.05。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="244c" class="hf hg hh kp b fi kt ku l kv kw">predicted_dataframe = pd.DataFrame({'Actual': test_y,<br/>                                  'Predicted Probability': logistic_model_fit3.predict(<br/>                                      sm.add_constant(test_X[significant_variables2]))})</span><span id="75e2" class="hf hg hh kp b fi li ku l kv kw">predicted_dataframe.head()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/16accb6fee3278663ab61e693e9c9a6e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*YI3iHWiTq_5N7E-I7WGeng.png"/></div></figure><p id="de43" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们已经在<code class="du la lb lc kp b">Predicted Probability</code>列中生成了在0和1之间变化的<code class="du la lb lc kp b">sigmoid</code>函数，现在我们需要设置一个截止点，这样我们就可以将它们分为是和否事件。如果该值大于0.5，我们使用0.5作为临界值。我们假设该值为1，表示信用不良，0表示信用良好</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="83b0" class="hf hg hh kp b fi kt ku l kv kw">predicted_dataframe['Predicted'] = predicted_dataframe['Predicted Probability'].map(lambda x: 1 if x &gt; 0.5 else 0)<br/>predicted_dataframe.head(10)</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/3952a37bd411a0174050c479a0026371.png" data-original-src="https://miro.medium.com/v2/format:webp/1*TANCrxtfVdvJA9sBdLTIjg.png"/></div></figure><p id="d4ab" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">正如我们可以看到的，一些值是正确预测的，一些是错误预测的。让我们把这些值制成表格。</p><h2 id="021b" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">评估模型性能</h2><p id="f2d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io hr ip iq ir hv is it iu hz iv iw ix iy ha bi translated">现在我们已经创建了模型，让我们来评估模型的性能。基本上是模型相对于0和1的实际输出的表现。用于评估结果的一些方法有:</p><ul class=""><li id="0f4e" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">混淆矩阵</li><li id="8a17" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">受试者工作特征曲线</li><li id="2cc6" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">尤尔登度量</li><li id="d3ab" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">价值函数</li></ul><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="5fbe" class="hf hg hh kp b fi kt ku l kv kw">predicted_dataframe[['Actual','Predicted']].value_counts(normalize = False).sort_index()</span><span id="63a1" class="hf hg hh kp b fi li ku l kv kw">Actual  Predicted<br/>0       0            185<br/>        1             29<br/>1       0             55<br/>        1             31<br/>dtype: int64</span></pre><p id="baed" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们可以看到，当实际值为0时，我们有185个预测值为0，有55个案例我们预测不正确，但得分很高<br/>。类似地，我们有31个案例预测正确，29个案例预测不正确。</p><p id="3eba" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">正确预测良好信用的概率由下式给出:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es lm"><img src="../Images/9aa833255743dbff38972d4539f5d533.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*t0876zEDBJvxKQvHg_j1CA.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="bcc7" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">正确预测不良的概率由下式给出:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es ln"><img src="../Images/a6860d74602e1baf976f19d6b621bde1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*X34fIUuT3-Zq6ukuYRdv_g.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="127d" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">虽然我们在预测高分方面做得很好，但预测低分的概率几乎是零(36%的概率——这还不够好)。银行对预测不良信贷比对预测良好信贷更感兴趣(从风险管理的角度来看)</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="e842" class="hf hg hh kp b fi kt ku l kv kw">pd.crosstab(predicted_dataframe.Actual,predicted_dataframe.Predicted,normalize = False,margins = True)</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/71731d1fe9070b10ee85c3c8e960feb2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9dVf9_yVoCBuOq8GFf3GmQ.png"/></div></figure><p id="493f" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这种表示法称为<strong class="ig jn"> <em class="jo">混淆矩阵</em> </strong>。<br/>混淆矩阵有以下元素:(假设我们试图预测不良信用)</p><ul class=""><li id="f8e7" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated"><strong class="ig jn">真阳性</strong>:已被预测为不良信用的不良信用。上表中的(1，1)元素</li><li id="6496" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn">真否定</strong>:被预测为良好信用的良好信用。上表中的(0，0)元素</li><li id="8f35" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn">误报</strong>:被预测为不良信用的良好信用。上表中的(0，1)元素</li><li id="60eb" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn">假阴性</strong>:已经被预测为良好信用的不良信用。上表中的(1，0)元素</li></ul><p id="61d4" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><em class="jo">注意:这里我们的正面是不良信用</em></p><p id="87a0" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">使用混淆矩阵，我们可以计算模型准确性的一些指标:</p><ul class=""><li id="65e6" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">敏感度/召回率:P(预测类别+ve |实际类别+ve)在我们的情况下P(不良信用预测|不良信用实际)</li><li id="8a88" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">特异性:P(预测等级-ve |实际等级-ve)在我们的情况下P(良好信用预测|良好信用实际)</li></ul><p id="dd70" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这可以用真/假阳性/阴性来表示，如下所示:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es lo"><img src="../Images/a3e34096bf7a54edd06c71acba8e78ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dUzZV-w6xDhvShdJbCwjog.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="9eef" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">使用贝叶斯定理可以很容易地得到这些结果。</p><p id="629d" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">现在，如果你试图理解上述结果，我们基本上是如何正确地分类模型的不良和良好的信用。应该还有一个衡量模型分离数据的正确程度的指标。<br/>给定预测值为正，实际值为正的概率。<br/>这个度量被称为精度，由下式给出:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es lp"><img src="../Images/b329fff686dc0d0f96beb4a657b931d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*X8oTZ2FwlF3XzBNXE3SVmg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="6a06" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">为了评估我们的模型，我们计算</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es lq"><img src="../Images/fa0fd2642948f462541a0ef4b30fcc41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*lJ_DeXkjq7OdleXmbd_nyw.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="5245" class="hf hg hh kp b fi kt ku l kv kw">from sklearn import metrics<br/>print(metrics.classification_report(predicted_dataframe.Actual,predicted_dataframe.Predicted))</span><span id="f54a" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong></span><span id="1ba2" class="hf hg hh kp b fi li ku l kv kw">precision    recall  f1-score   support<br/><br/>           0       0.77      0.86      0.81       214<br/>           1       0.52      0.36      0.42        86<br/><br/>    accuracy                           0.72       300<br/>   macro avg       0.64      0.61      0.62       300<br/>weighted avg       0.70      0.72      0.70       300</span></pre><p id="a45d" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">上表给出了精度和召回率的两个值，因为它不知道我们的正值是0还是1。而且，它没有给出具体性。<br/>然而，以上指标已经足够。</p><p id="d2d0" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">此外，请注意，该模型非常擅长预测<code class="du la lb lc kp b">Good Credit</code>,参见相对于0的值。然而，预测<code class="du la lb lc kp b">Bad Credit</code>相当糟糕。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="af92" class="hf hg hh kp b fi kt ku l kv kw">import seaborn as sn<br/>plt.figure(figsize = (8,6))<br/>sn.distplot(predicted_dataframe[predicted_dataframe.Actual == 1]['Predicted Probability'],<br/>            kde = True,color = 'b',label = 'Bad Credit')<br/><br/>sn.distplot(predicted_dataframe['Predicted Probability'],<br/>            kde = True,color = 'g',label = 'Good Credit')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/fa97020880bdb488fdce0b6d0bfd5d47.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xdONpmsKlNko13eXj8xLug.png"/></div></figure><p id="e33a" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这里交叉区域是我们的问题，我们应该尽量减少交叉，这样我们的假阳性和假阴性开始减少。这可以通过调整我们已经定义为0.5的<code class="du la lb lc kp b">cut-off</code>概率来实现。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="5e91" class="hf hg hh kp b fi kt ku l kv kw">FPR, TPR, thresholds = metrics.roc_curve(predicted_dataframe.Actual,predicted_dataframe['Predicted Probability'])<br/>auc_score = metrics.roc_auc_score(predicted_dataframe.Actual,predicted_dataframe['Predicted Probability'])<br/>plt.plot(FPR,TPR,label = 'ROC Curve Area (area = %0.2f)'%auc_score)<br/>plt.plot([0,1],[0,1],'k--')<br/>plt.xlim([0.0,1.0])<br/>plt.ylim([0.0,1.05])<br/>plt.xlabel('False Positive Rate or [1-True Negative Rate]')<br/>plt.ylabel('True Positive Rate')<br/>plt.legend(loc = 'lower right')<br/>plt.show()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/293aa74744026b04b626a2a4007b6871.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bq6VAXu-ZaB1gHYrFpOPAw.png"/></div></figure><p id="c6ce" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">以下是对上述术语的解释:</p><ul class=""><li id="0474" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated"><strong class="ig jn"> FPR </strong> —误报率(实际为1时得到0的概率)</li><li id="cc49" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn"> TPR </strong> —真阳性率(当实际为1时得到1的概率)</li><li id="3b08" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated"><strong class="ig jn"> AUC分数</strong>—ROC曲线下的面积(ROC曲线是各种概率值下FPR对TPR的作图)。AUC通常应大于0.7。然而，如果数据集不平衡(阳性率&lt; 10%)，较高的ROC可能会产生误导，所以要小心使用ROC作为唯一的评估指标。</li></ul><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="ed8a" class="hf hg hh kp b fi kt ku l kv kw">precision, recalls,thresholds1 = metrics.precision_recall_curve(predicted_dataframe.Actual,<br/>                                                              predicted_dataframe['Predicted Probability'])</span><span id="40eb" class="hf hg hh kp b fi li ku l kv kw">def plot_precision_recall_vs_threshold(precisions,recalls,thresholds):<br/>    plt.plot(thresholds,precisions[:-1],"b--",label = "Precision")<br/>    plt.plot(thresholds,recalls[:-1],"g-",label = "Recall")<br/>    plt.xlabel("Threshold")<br/>    plt.legend(loc = "center left")<br/>    plt.ylim([0,1])</span><span id="9bce" class="hf hg hh kp b fi li ku l kv kw">plot_precision_recall_vs_threshold(precision,recalls,thresholds1)<br/>plt.show()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/4faaac56acb601b0fcae95225f366580.png" data-original-src="https://miro.medium.com/v2/format:webp/1*cOGv4J2FmZiDHmHL2WnWEw.png"/></div></figure><p id="e59b" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">正如我们在上面看到的，阈值的选择是精确度和召回率之间的权衡，因为我们增加阈值的值，而精确度增加召回率的值降低。</p><p id="f592" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">虽然该图可用于推导过程背后的直觉，但也有数值方法来寻找阈值的最佳值。</p><p id="2b0f" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">找到正确的临界值:<br/>正确的临界值可用于确定什么是正确的临界值(目前我们选择0.5)。用于这种分类的一些方法是:</p><ul class=""><li id="9df1" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy jj jk jl jm bi translated">尤登指数</li><li id="8da4" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy jj jk jl jm bi translated">基于成本的方法</li></ul><p id="4742" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn"/></p><p id="7d69" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn">灵敏度+特异性— 1 </strong>最大化。</p><p id="ac19" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们知道灵敏度公式由下式给出:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es lo"><img src="../Images/a3e34096bf7a54edd06c71acba8e78ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dUzZV-w6xDhvShdJbCwjog.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="b0ad" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我们还知道，FPR的TPR =灵敏度<br/>由下式给出:</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es lr"><img src="../Images/c8cddc024eb5df611aefb17514764f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*VRLvVePzdJW2rEiHMj1Yog.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Created using LaTeX editor add-on for Chrome</figcaption></figure><p id="7049" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">使用上面的等式，我们得到灵敏度+特异性-1 = TPR-FPR。<br/>绘制AUC曲线时，我们已经计算了FPR、TPR。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="5acd" class="hf hg hh kp b fi kt ku l kv kw">youlden_df = pd.DataFrame({"TPR":TPR,"FPR":FPR,"THRESHOLDS":thresholds})<br/><br/>youlden_df['YOULDEN'] = youlden_df['TPR'] - youlden_df['FPR']<br/>youlden_df.head()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/415eb8f88c5bcd30e12d0484ead53b3f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*A93Il5n9iiBRdEdKHB3rOA.png"/></div></figure><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="6dd1" class="hf hg hh kp b fi kt ku l kv kw">youlden_df.sort_values('YOULDEN',ascending = False).head()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/71bb0f3787873983db43e30be49c5da7.png" data-original-src="https://miro.medium.com/v2/format:webp/1*T8AqEeFcvHBa12UQYZfcDg.png"/></div></figure><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="b3a5" class="hf hg hh kp b fi kt ku l kv kw">predicted_dataframe['Predicted New'] = predicted_dataframe['Predicted Probability'].map(lambda x: 1 if x &gt; 0.377961<br/>                                                                                       else 0)</span><span id="b392" class="hf hg hh kp b fi li ku l kv kw">print(metrics.classification_report(predicted_dataframe.Actual,predicted_dataframe['Predicted New']))</span><span id="5ee7" class="hf hg hh kp b fi li ku l kv kw">precision    recall  f1-score   support<br/><br/>           0       0.83      0.76      0.79       214<br/>           1       0.50      0.60      0.55        86<br/><br/>    accuracy                           0.72       300<br/>   macro avg       0.67      0.68      0.67       300<br/>weighted avg       0.73      0.72      0.72       300</span><span id="7679" class="hf hg hh kp b fi li ku l kv kw">pd.crosstab(predicted_dataframe.Actual,<br/>            predicted_dataframe['Predicted New'],<br/>            normalize = False,margins = True)</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/8c385a35a96cd0eb66a4f6ae0530335d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*OFkEbhpNTeT-az8kwtMteA.png"/></div></figure><p id="31ac" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">最后，我们使用最终的方法使用成本函数来确定最佳的方法。在该方法中，我们提取多个混淆矩阵，并对误报和漏报实现一个代价函数，以确定最佳阈值。</p><p id="ad9d" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这里，我们首先创建一个函数get_cost，它主要采用以下参数:</p><ol class=""><li id="d06e" class="je jf hh ig b ih iz il ja hr jg hv jh hz ji iy kz jk jl jm bi translated">实际值(信用分数的实际值)</li><li id="53a6" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">预测值(credit_score的预测值)</li><li id="cd87" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">cost_FP(与误报相关的成本)</li><li id="8fbf" class="je jf hh ig b ih jp il jq hr jr hv js hz jt iy kz jk jl jm bi translated">cost_FN(与假阴性相关的成本)</li></ol><p id="9c9b" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">现在你可以参考<code class="du la lb lc kp b">german.doc</code>的最后一部分，这实际上给出了假阳性和假阴性的成本函数。</p><p id="e658" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">这些成本还表明，银行非常厌恶风险，它准备放弃信用良好的客户，但希望对不良贷款的预测具有非常高的准确性。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="2948" class="hf hg hh kp b fi kt ku l kv kw">def get_cost(actual,predicted,cost_FP, cost_FN):<br/>    C_Matrix = metrics.confusion_matrix(actual,predicted)<br/>    return C_Matrix[0,1]*cost_FP + C_Matrix[1,0]*cost_FN</span><span id="70ae" class="hf hg hh kp b fi li ku l kv kw">cost_dataframe = pd.DataFrame(columns = ['Probability','Cost'])<br/>index = 1<br/>for probability in range(10,50):<br/>    cost = get_cost(predicted_dataframe.Actual,<br/>                   predicted_dataframe['Predicted Probability'].map(lambda x: 1 if x &gt; (probability/100) else 0),<br/>                   1,5)<br/>    cost_dataframe.loc[index] = [(probability/100),cost]<br/>    index+=1</span><span id="f287" class="hf hg hh kp b fi li ku l kv kw">min_prob= cost_dataframe.sort_values('Cost',ascending = True).head().reset_index()['Probability'][0]<br/>print(min_prob)</span><span id="99e1" class="hf hg hh kp b fi li ku l kv kw">0.11</span><span id="364f" class="hf hg hh kp b fi li ku l kv kw">predicted_dataframe['Predicted_Cost'] = predicted_dataframe['Predicted Probability'].map(lambda x: 1 <br/>                                                                                         if x &gt; min_prob else 0)</span><span id="d0e3" class="hf hg hh kp b fi li ku l kv kw">print(metrics.classification_report(predicted_dataframe.Actual,predicted_dataframe['Predicted_Cost']))</span><span id="5675" class="hf hg hh kp b fi li ku l kv kw"><strong class="kp jn">OUTPUT</strong></span><span id="855b" class="hf hg hh kp b fi li ku l kv kw">precision    recall  f1-score   support<br/><br/>           0       0.91      0.32      0.47       214<br/>           1       0.35      0.92      0.51        86<br/><br/>    accuracy                           0.49       300<br/>   macro avg       0.63      0.62      0.49       300<br/>weighted avg       0.75      0.49      0.48       300</span><span id="0717" class="hf hg hh kp b fi li ku l kv kw">pd.crosstab(predicted_dataframe.Actual,<br/>            predicted_dataframe['Predicted_Cost'],<br/>            normalize = False,margins = True)</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/1c5a5ca9062de060d518db13f5128895.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ejTnWGbf6YBtvPMcp_AZnQ.png"/></div></figure><p id="9636" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">看到我们对负面(良好信用)的正确预测已经显著下降。然而，我们误算的不良信贷价值只有8%,这可能是银行的重点领域。</p><pre class="kc kd ke kf fd ko kp kq kr aw ks bi"><span id="6e03" class="hf hg hh kp b fi kt ku l kv kw">train_X.describe()</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="ab fe cl kx"><img src="../Images/d02d33ba5d818b653caad1d05824ccb3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*SRg4QbPB_34gxFMCP_hd_w.png"/></div></figure><h2 id="c74b" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">提高模型精度的其他方法</h2><p id="42ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io hr ip iq ir hv is it iu hz iv iw ix iy ha bi translated"><strong class="ig jn"> 1。特征缩放或标准化</strong>:如果我们的数值变量在非常不同的尺度上，那么在更高尺度上的变量可能最终支配模型预测。在我们的例子中，数量变量具有3K的平均值，而其他数值变量如持续时间、inst_rate等。有个位数的意思。很有可能数量将开始支配模型，我们可以标准化数量变量。这可以通过<code class="du la lb lc kp b">Normalization</code>或<code class="du la lb lc kp b">Standardization</code>完成</p><p id="49d1" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn"> 2。超参数调整</strong>:除了数据之外，用于运行模型的任何东西都称为模型的超参数(不严格)。我们可以部署<code class="du la lb lc kp b">Gridsearch</code>来优化我们的超参数，<code class="du la lb lc kp b">Gridsearch</code>尝试不同的超参数，给我们最好的模型。</p><p id="1e47" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn"> 3。尝试其他模型</strong>:虽然逻辑回归是分类问题的技术之一，但是还有很多其他的选择。比如基于树的分类、支持向量机等。您可以尝试其他型号，并找出最适合您需求的型号。<em class="jo">还记得使用成本函数时，我们得到了一个整体准确性得分较低的模型，但它更准确地预测了不良贷款，而且企业可能希望您牺牲他们希望关注的领域的准确性。</em></p><p id="d3dd" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated"><strong class="ig jn"> 5。分离数据以创建独立的模型并组合(集成)</strong>:集成本质上意味着将数据划分为子集，在这些子集上，您的模型可能表现得更好，并将结果聚合为平均值或一些其他技术。(<em class="jo">注:这是对合奏技巧的一个非常高层次的定义</em>)。</p><p id="8065" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">对于逻辑回归，还有更高级的调整，我们将在其他文章中介绍。<br/>现在我们可以结束这一讨论，并将返回到具有高级参数模式的逻辑回归。</p><p id="051b" class="pw-post-body-paragraph ie if hh ig b ih iz ij ik il ja in io hr jb iq ir hv jc it iu hz jd iw ix iy ha bi translated">我刚刚开始在这个平台上写作。希望你喜欢这些文章，请提供你的反馈，这样我可以提高我的写作水平。喜欢和兴趣相似甚至完全不同的人交往。</p><div class="ls lt ez fb lu lv"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lw ab dw"><div class="lx ab ly cl cj lz"><h2 class="bd jn fi z dy ma ea eb mb ed ef mc bi translated">Mlearning.ai提交建议</h2><div class="md l"><h3 class="bd b fi z dy ma ea eb mb ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="me l"><p class="bd b fp z dy ma ea eb mb ed ef dx translated">medium.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk kh lv"/></div></div></a></div></div></div>    
</body>
</html>
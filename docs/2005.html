<html>
<head>
<title>K Nearest Neighbours (KNN) explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k近邻(KNN)解释说</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/k-nearest-neighbours-knn-all-you-need-to-know-b9b93e22380e?source=collection_archive---------3-----------------------#2022-02-21">https://medium.com/mlearning-ai/k-nearest-neighbours-knn-all-you-need-to-know-b9b93e22380e?source=collection_archive---------3-----------------------#2022-02-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/f6d86e284c26ed1998da92deeff7f711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iKm6BDljNsDsB-VJDcgv8g.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://www.pexels.com/@stasknop?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Stas Knop</a> from <a class="ae it" href="https://www.pexels.com/photo/white-mug-on-red-background-2916450/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><h2 id="2cae" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">简介</strong></h2><p id="6d20" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">当我们听到机器学习这个词时，我们脑海中会出现复杂的计算、假设参数和偏导数。但是，这个不一样。一个简单，轻松，懒散的。没有复杂的计算，没有偏导数，没有超平面。</p><h2 id="cdb4" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">k最近邻是什么:</strong></h2><p id="79a9" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">k最近邻或简称为KNN是一种机器学习算法，主要用于分类任务，尽管它也可以执行回归任务。它根据最接近它的数据点所属的组来估计数据点成为一个数据组或另一个数据组的成员的可能性。</p><h2 id="d3e0" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">KNN如何工作:</strong></h2><p id="59f4" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">像我之前说的，KNN是一个懒惰的学习和非参数算法。它被称为懒惰学习算法或懒惰学习器，因为它在训练时不执行任何任务。它只是存储数据。就是这样。没有计算，没有概率估计，没有偏导数或没有训练模型的建立。它什么也不做。它仅在您测试模型或执行查询时构建模型。比如，你通过给一个未知的数据点来问模型它属于哪个类。</p><h2 id="2c27" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">让我们来了解一下KNN的工作方式:</strong></h2><p id="755a" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">KNN使用特征相似性来预测新数据点的值。它是怎么做到的？让我们通过一个流行的伪代码来理解。(我是通过修改其他文章的内容来粘贴这篇文章的)</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es kn"><img src="../Images/6c5f7f40b64819fc110cba731bd1468c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*1JOgYkcHa2IdLnfqKWzDXQ.png"/></div></figure><p id="925b" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi">第一步:</strong></p><p id="68ab" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">数据。加载您的数据集。不过很明显。</p><p id="b526" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi">第二步:</strong></p><p id="8ab9" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">执行数据预处理。处理缺失值，必要时进行降维。</p><p id="a7c4" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi">第三步:</strong></p><p id="6315" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">选择k的值。</p><p id="f5f2" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">“KNN”中的“K”代表投票时你要考虑多少个邻近点。我们将在稍后的文章中讨论这个问题。它是一个整数。不要太小也不要太大。</p><p id="210c" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi">第四步:</strong></p><p id="3fc4" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">预言；预测；预告</p><p id="405c" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx"> 4.1 </em> </strong>计算您的查询示例与每个训练行之间的距离，例如训练中使用的现有数据点。您可以使用任何方法来测量距离:欧几里得距离、曼哈顿距离、闵可夫斯基距离或海明距离。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es ky"><img src="../Images/9837e7e3eaa8e2e3bb2646ffb52c25d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*TCxmkeZ881h94s3YWJ9naQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Euclidean distance</figcaption></figure><p id="f921" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">人们使用最多的是欧几里德距离，它很简单。</p><p id="2c3e" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx"> 4.2 </em> </strong>按升序排列距离。</p><p id="2d91" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx"> 4.3 </em> </strong>从排序后的数组中选择前k行或条目。</p><p id="4c8f" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx"> 4.4 </em> </strong>获取这k个条目的标签，找到其中最频繁的类(投票)，这将是我们的查询示例的预测类，为查询示例分配该类。</p><p id="a424" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx"> 4.5 * </em> </strong>对于回归计算那些k个最近的数据点的平均值。这将是我们查询示例的标签。</p><h2 id="5383" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">投票:</strong></h2><p id="b026" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">这是一个简单的程序，可以找到附近最常去的班级。就像现实世界的选举一样。在计算一个地区的票数时，负责的官员计算有限数量的投票响应。并分类哪个候选人得了多少票。并按降序排列。像这样</p><p id="880f" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">约翰:14369</p><p id="8379" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">施里坎特:9650</p><p id="0662" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">劳拉:8771</p><p id="4379" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">所以约翰赢了。在KNN也是同样的程序。从这K个最近的数据点中，我们找到出现次数最多的类别。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es kz"><img src="../Images/8dd4be4bd58bb0b1e9e97dc2d6687d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*8v8ZM_b6Ne1m2PPZtuEo4g.png"/></div></figure><p id="809c" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">在该图中，我们可以看到，在5个最接近的数据点中，3个是红色类，2个是蓝色类。因此，我们将为我们的查询选择红色类。</p><h2 id="975c" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">如何选择k的最优值:</strong></h2><p id="bde7" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">选择“K”没有具体的方法。你必须手动选择它。因此，我们必须使用不同的“K”值进行实验，多次训练模型，测量模型性能，并选择性能最佳的“K”继续前进。</p><p id="8b10" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">当我们处理二元分类时，最好为“K”选择一个奇数值。否则，可能发生两个类邻居数量相同的情况。以同样的方式,“K”的值不能是当前类别数的倍数。另一种选择“K”的方法是sqrt(n ),其中n是训练中存在的样本数。</p><p id="acc8" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">k '不应该像1或2那样非常低。这将导致过度拟合。在这种情况下，它将是嘈杂的，并受到离群值的影响。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es la"><img src="../Images/4e1633af1f24857b99d530fdbb66159e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*Mme_AyIbySPxCRzSDXzTsA.png"/></div></figure><p id="f063" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">在我们查询周围的四个数据点中，三个是红色的，一个是蓝色的，但是蓝色的是最接近的。如果k = 1，它将选择蓝色类作为最近邻，并归类为蓝色，但我们知道事实并非如此。</p><p id="1faa" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">在大多数情况下，k值越大，决策边界越平滑。但是不能太大。否则，数据点数量较少的组将总是被其他组否决。此外，较大的K在计算上将是昂贵的。</p><h2 id="c338" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">降维:</strong></h2><p id="d187" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">当我们有大量数据时，这意味着当我们有太多的特征要处理时，有可能会过度拟合，导致模型不准确。我们的模型将更难测量距离。另一个问题是许多数据点可能是等距。</p><p id="2806" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">所以过程降维是方法。在这种情况下，在数据准备步骤中考虑<strong class="ju hi">主成分分析(PCA) </strong>和<strong class="ju hi">特征选择</strong>。</p><p id="e547" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">我们还没有写任何关于这些话题的文章，但很快就会了。</p><h2 id="77a8" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">KNN的优缺点:</strong></h2><p id="8141" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated"><strong class="ju hi">优点:</strong></p><p id="db7d" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">1.这很容易实现</p><p id="cc2b" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">2.没有必要建立一个模型，调整几个参数，或作出额外的假设。</p><p id="ba98" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">3.既可以做回归，也可以做分类。</p><p id="c96d" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">4.它可以很好地处理多类分类</p><p id="9285" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi">缺点:</strong></p><p id="c732" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">1.需要高存储容量</p><p id="9352" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">2.需要确定一个合适的“K”</p><p id="4131" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">3.对不相关的特征敏感</p><p id="e768" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">4.当n(例子的数量)增加，特征或独立变量的数量增加时，速度明显变慢</p><p id="4755" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">5.由于测量训练样本中所有数据点之间的距离，计算成本很高。</p><h2 id="b3c9" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">KNN的应用:</strong></h2><p id="f92e" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">KNN被用于各种领域。</p><p id="bff6" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx">政治:</em> </strong></p><p id="0681" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">通过计算一些因素和使用KNN，我们可以知道一个选民会把他的票投给哪个政党。</p><p id="09e1" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx">银行业:</em> </strong></p><p id="de23" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">KNN可以在银行系统中用于预测个人是否适合贷款审批。</p><p id="e087" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><strong class="ju hi"> <em class="kx">推荐系统:</em> </strong></p><p id="c7f7" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">这是KNN分类法的一个伟大应用。我们将很快写一篇关于推荐系统的文章。</p><h2 id="e430" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">注:</strong></h2><p id="786d" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">1.在建模阶段之前，我们需要很好地清理数据。此外，该实现假设所有列都包含数字数据，并且数据的最后一列有标签，我们可以对其执行一些功能。</p><p id="de0f" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">2.选择“K”值时，领域知识很重要。</p><p id="4ae2" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">3.对于模型评估，在执行分类时使用混淆矩阵检查模型准确性。</p><p id="ba3e" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">4.其他统计方法如似然比检验也用于验证。</p><p id="e402" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">这篇文章就是这么说的。请评论您的反馈。如果有一些错误，请指出。</p><p id="045b" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated">帮我接通</p><p id="1b95" class="pw-post-body-paragraph js jt hh ju b jv ks jx jy jz kt kb kc jf ku ke kf jj kv kh ki jn kw kk kl km ha bi translated"><a class="ae it" href="https://github.com/shubhendu-ghosh-DS" rel="noopener ugc nofollow" target="_blank"> Github </a>，<a class="ae it" href="https://www.linkedin.com/in/shubhendu-ghosh-423092205/" rel="noopener ugc nofollow" target="_blank"> linkedIn </a>，<a class="ae it" href="https://twitter.com/shubhendubro" rel="noopener ugc nofollow" target="_blank"> Twitter </a></p><div class="lb lc ez fb ld le"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd hi fi z dy lj ea eb lk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">medium.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls in le"/></div></div></a></div></div></div>    
</body>
</html>
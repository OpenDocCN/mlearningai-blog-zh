<html>
<head>
<title>Learning Process of Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络的学习过程</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/learning-process-of-neural-networks-654c0c1f80f8?source=collection_archive---------11-----------------------#2022-01-31">https://medium.com/mlearning-ai/learning-process-of-neural-networks-654c0c1f80f8?source=collection_archive---------11-----------------------#2022-01-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/ebda3094e2c8255e11b426d7f763fe21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dUQbRa2KXz1BoNsL"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@kierinsight?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kier In Sight</a></figcaption></figure><p id="7744" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">目录</strong></p><ol class=""><li id="7c00" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">正向传播</li><li id="3d30" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">反向传播</li><li id="89c5" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">结构</li><li id="2b13" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">层</li></ol><h2 id="c22a" class="kg kh hh bd ki kj kk kl km kn ko kp kq jf kr ks kt jj ku kv kw jn kx ky kz la bi translated">预测阶段</h2><p id="06b5" class="pw-post-body-paragraph iu iv hh iw b ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">神经网络有不同的阶段。在这个例子中，我演示了如何使用一个简单的神经网络<em class="lg">来解决异或<em class="lg">(一个逻辑运算，当且仅当它的参数不同时才成立)</em>。</em>我用两种不同的方法:<em class="lg">训练</em> &amp; <em class="lg">运行</em>。在<em class="lg">训练</em>中，我使用前向传播和反向传播。我们将减少这些术语的复杂性来理解这种方法。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="426f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">假设我们有一个球，我们要把它扔向球门。在正向传播中，应该首先预测这些指标:</p><ol class=""><li id="b543" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">球需要飞多远？</li><li id="e4e6" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">背后要投入多少精力？</li><li id="9b30" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">球的路径</li></ol><p id="e1d2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">诸如此类。</p><h2 id="5411" class="kg kh hh bd ki kj kk kl km kn ko kp kq jf kr ks kt jj ku kv kw jn kx ky kz la bi translated">测量阶段</h2><p id="d76a" class="pw-post-body-paragraph iu iv hh iw b ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">从这些步骤中得出答案的过程称为正向传播<em class="lg">(预测)</em>。现在我们可以理解我们离实际目标有多远了。此外，估计预测目标和实际目标之间的差异被称为反向传播<em class="lg">(测量)</em>，反向传播的第二阶段是学习。最终，我们再次扔球，球扔得太远了，我们测量差异并再次做出<em class="lg">预测</em>。这个序列描述了神经网络的学习过程。</p><h2 id="89c1" class="kg kh hh bd ki kj kk kl km kn ko kp kq jf kr ks kt jj ku kv kw jn kx ky kz la bi translated">运行我们的网络</h2><p id="8894" class="pw-post-body-paragraph iu iv hh iw b ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">在运行我们的网络时，我们不再需要衡量我们离目标有多远。因为我们已经知道了区别，所以不需要反向传播。在整个训练过程中，神经网络都在测量这种差异，这种差异被称为误差。我们可以通过在<em class="lg"> log </em>函数中传递<em class="lg"> error </em>参数并指定<em class="lg"> logPeriod </em>来查看错误。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="6b80" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">虽然可能会有很多错误，但Net最终会加速其学习能力，直到错误率开始下降到非常低的数字，直到训练完成。一旦训练完成，就没有必要继续训练，我们可以向前传播。</p><h1 id="6456" class="ln kh hh bd ki lo lp lq km lr ls lt kq lu lv lw kt lx ly lz kw ma mb mc kz md bi translated">结构</h1><p id="1ea4" class="pw-post-body-paragraph iu iv hh iw b ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">神经网络的编程结构由接收输入作为参数并产生输出的函数组成。</p><p id="bba1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经网络从随机数开始，影响输出的一切最初都是一串随机值，因为从数学上讲，这是一种从知识开始的有效方法。事实上，随着时间的推移，我们可以重塑随机数据，以存储神经网络内部正在发生的事情。听起来可能很奇怪，每个神经元实际上都是Math.random()。神经网络的下一个重要结构行为是激活函数。</p><h2 id="dfc9" class="kg kh hh bd ki kj kk kl km kn ko kp kq jf kr ks kt jj ku kv kw jn kx ky kz la bi translated">激活功能</h2><p id="73e8" class="pw-post-body-paragraph iu iv hh iw b ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di"> A </span>激活函数专门用于神经网络，将输入信号转换成输出信号，该输出信号又作为输入被馈送到堆栈中的下一层。在神经网络中，我们估计输入及其互连权重的乘积之和，最后对其应用激活函数，以获得相应层的输出，并将其作为下一层的输入。激活函数在反向传播中使用它们的导数来测量。</p><h1 id="abf5" class="ln kh hh bd ki lo lp lq km lr ls lt kq lu lv lw kt lx ly lz kw ma mb mc kz md bi translated">层</h1><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/dddc9bd9e384cc1f60a0c7aab916b3db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z3zHoX1nhK6Rsmd4yNPdsg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Nodes represent neurons, stacks represent layers</figcaption></figure><p id="2429" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">层是一个通用术语，适用于在神经网络中特定深度一起工作的“节点”的集合。</p><p id="cdd0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">输入层</strong>包含原始数据(将每个变量视为一个“节点”)。</p><p id="7cb7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在神经网络中，<strong class="iw hi">隐藏层</strong>是<em class="lg">黑魔法</em>发生的地方。每一层都试图通过最小化误差/成本函数来了解数据的不同方面。理解这些图层最直观的方法就是在<a class="ae it" href="https://en.wikipedia.org/wiki/Pattern_recognition" rel="noopener ugc nofollow" target="_blank"> <em class="lg">的背景下进行图像识别</em> </a>比如人脸。例如，第一层可以学习边缘检测，第二层可以检测眼睛，第三层可以检测鼻子，等等。虽然这个例子不一定代表程序结构，但其思想是将问题分解成不同抽象层次可以拼凑起来的特征，就像我们自己的大脑工作一样(因此得名“神经网络”)。</p><p id="981c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">输出层</strong>是最简单的，通常由分类问题的单个输出组成。尽管它是单个“节点”,但它仍被视为神经网络中的<em class="lg">层</em>,因为它可以拥有多个节点。</p><div class="mo mp ez fb mq mr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hi fi z dy mw ea eb mx ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">medium.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf in mr"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Summary of the article “A few useful things to know about machine learning” by Pedro Domingos</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pedro Domingos的文章“关于机器学习需要知道的一些有用的事情”的摘要</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/summary-of-the-article-a-few-useful-things-to-know-about-machine-learning-by-pedro-domingos-ecf1ef3e6ae9?source=collection_archive---------3-----------------------#2021-03-06">https://medium.com/mlearning-ai/summary-of-the-article-a-few-useful-things-to-know-about-machine-learning-by-pedro-domingos-ecf1ef3e6ae9?source=collection_archive---------3-----------------------#2021-03-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/d595945e86949cd0b6768f6b23b5451a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QnECQHMq2YrTS21i"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Photo by <a class="ae hu" href="https://unsplash.com/@pietrozj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Pietro Jeng</a> on <a class="ae hu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="8943" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这篇文章旨在<strong class="iw hy">总结</strong>Pedro Domingo文章最重要的方面:<strong class="iw hy">“关于机器学习需要知道的一些有用的事情”。</strong></p><p id="c6fa" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">主文章的目标是<em class="js">“交流科学文章中通常没有的关于机器学习的民间知识”</em>。Pedro在ML方面有丰富的经验，所以我认为这些基于他的经验的建议非常有意义！你可以在这里找到这篇文章——https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf。</p><p id="bbf5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此外，如果你喜欢我的同胞所做的工作(我也是葡萄牙人:)，我推荐他关于机器学习的书—<em class="js">The Master Algorithm:The Quest for The Ultimate Learning Machine将如何重塑我们的世界</em>。这本书解释了不同类型的机器学习算法，是一个很好的机器学习的起点。</p><p id="e7ca" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我把这篇文章分成9个主要的提示:</p><ol class=""><li id="cd9e" class="jt ju hx iw b ix iy jb jc jf jv jj jw jn jx jr jy jz ka kb bi translated"><a class="ae hu" href="http://9e73" rel="noopener ugc nofollow" target="_blank">学习=表示+评估+优化</a></li><li id="7bfe" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://adf1" rel="noopener ugc nofollow" target="_blank">重要的是归纳——超越训练数据的归纳</a></li><li id="96c6" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://ed3b" rel="noopener ugc nofollow" target="_blank"> Oveffiting有很多面</a></li><li id="d0ba" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://2027" rel="noopener ugc nofollow" target="_blank">直觉在高维中失败——维度的诅咒</a></li><li id="1cf3" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://35a3" rel="noopener ugc nofollow" target="_blank">理论上的保证并不像它们看起来的那样</a></li><li id="55ae" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://391d" rel="noopener ugc nofollow" target="_blank">特色工程是关键</a></li><li id="2cbf" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://27da" rel="noopener ugc nofollow" target="_blank">更多的数据胜过更聪明的算法</a></li><li id="20b1" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated"><a class="ae hu" href="http://55d2" rel="noopener ugc nofollow" target="_blank">学习多种模式，而不仅仅是一种</a></li><li id="5d8d" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">简单并不意味着准确</li></ol><h1 id="9e73" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">1.学习=表示+评估+优化</h1><p id="8272" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">通常很难选择最佳的ML算法。我们只专注于选择算法，而将其他重要任务抛在脑后。然而，学习由这三个重要方面组成<em class="js">表现、评估和优化</em>。因此，<strong class="iw hy">为了成功，我们需要</strong>仔细选择我们将如何<em class="js">表示</em>数据，我们将如何<em class="js">评估</em>结果，以及我们将如何<em class="js">找到</em>最佳算法/参数。</p><p id="e3ae" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正如Pedro所写的，<em class="js">“机器学习项目中的一些选择甚至可能比学习者的选择更重要”。</em></p><h1 id="adf1" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">2.重要的是概括</h1><p id="ee6b" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">主要目标是让<strong class="iw hy">能够超越训练数据</strong>进行归纳。这意味着学习者必须对新的和看不见的数据表现良好。</p><p id="0408" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用同一组数据来训练和测试模型带来了成功的<strong class="iw hy">假象</strong>。在这种情况下，Pedro建议<em class="js">“从一开始就把一些数据放在一边，只用来测试你选择的分类器”</em>。他还谈到如果我们没有很多数据，我们如何使用交叉验证。</p><h1 id="ed3b" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">3.过度拟合有很多面</h1><p id="ede9" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">每个人都知道过度拟合——用训练数据得到很好的结果，但用新的和看不见的数据得到很差的结果。从这个意义上来说，佩德罗说过度拟合可能会以<em class="js">“许多形式不会立即显现出来”。</em></p><p id="1005" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了更好地理解过度拟合，Pedro建议<strong class="iw hy">将泛化误差分为偏差和方差。</strong>正如Pedro解释的那样，<em class="js">“偏差是学习者持续学习相同错误内容的倾向，而方差是学习随机内容而不考虑真实信号的倾向”</em>。</p><p id="6b1a" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">根据我们选择的模型的表现，我们可以选择基于偏差和方差的算法。例如，线性学习者有很高的偏差，决策树没有很高的偏差，但是有很高的方差。</p><p id="ec0b" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">佩德罗还建议使用<em class="js">交叉验证和正则化</em>来对抗过度拟合。他在本节<strong class="iw hy">结尾警告</strong><em class="js">“陷入适配不足的相反错误很容易避免适配过度”。</em></p><h1 id="2027" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">4.直觉在高维空间失效</h1><p id="096f" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">Pedro以<em class="js">“过度拟合后，ML最大的问题是维数灾难”开始这一段。</em>基本上，当我们使用越来越多的特征时，最大似然算法在更高维度中开始变得非常糟糕。</p><p id="43bd" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">随着维度的增长，学习数据<strong class="iw hy">变得越来越困难</strong>，因为示例数量和特征数量之间的比率变得非常低。因此，作为一个建议，明智地选择特性并只使用最相关的特性是很重要的。不要给你的学生制造噪音。</p><h1 id="35a3" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">5.理论上的保证并不像它们看起来那样</h1><p id="b83b" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">这一条很简单——仅仅因为某个算法在理论上取得了好的结果，并不意味着它在实践中也会工作得很好。正如佩德罗所说:“仅仅因为一个学习者有一个理论上的理由并在实践中工作，并不意味着前者是后者的原因。”</p><h1 id="391d" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">6.特征工程是关键</h1><p id="67a8" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">在这一部分，Pedro思考了特征工程的重要性。他解释说，机器学习项目成功的最重要因素是所使用的特征。</p><p id="bf56" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对此的解释很简单:<em class="js">“如果你有许多独立的特征，并且每个特征都与类相关联，那么学习就很容易。另一方面，如果类是一个非常复杂的功能，你可能无法学习它。”</em></p><p id="8e19" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">他还表示，ML流程<strong class="iw hy">不是</strong>“一次性流程”。这是一个反复的过程，工程师们用新的和不同的特征来测试新的假设，以达到最好的结果。</p><h1 id="27da" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">7.更多的数据胜过更聪明的算法</h1><p id="57a9" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">当你的模型不够精确时，你有两个主要的选择:<em class="js">“设计一个更好的学习算法，或者收集更多的数据(更多的例子，可能还有更多的原始特征】</em>。佩德罗推荐<strong class="iw hy">第二条路径</strong>。首先，因为获取更多数据通常比构建新算法更快。第二，因为算法从数据中学习，我们拥有的数据越多，算法必须尝试学习的例子就越多。</p><h1 id="55d2" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">8.学习许多模型，而不仅仅是一个</h1><p id="c149" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">在这一部分，Pedro谈论了模型组合的<strong class="iw hy">好处</strong>。他首先说，在<em class="js">之前，“人们会测试许多模型，然后选择最佳模型”</em>。但是，一个更好的方法是结合许多不同的模型。这是一个很好的方法，因为我们基本上是将多种算法的优势结合成一种。因此，一种算法的优点解决了另一种算法的缺点。</p><h1 id="4354" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">9.简单并不意味着准确</h1><p id="8146" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">这个很简单:<em class="js">“给定两个具有相同训练误差的分类器，两个分类器中较简单的可能具有最低的测试误差”。根据经验，我们应该总是选择更简单的算法。正如Pedro所解释的，复杂的学习者有更大的假设空间，因此<em class="js">“一个拥有更大假设空间的学习者尝试更少的假设，比一个在更小空间尝试更多假设的学习者更不容易过度适应。”</em></em></p><p id="57db" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请随意评论您从经验中学到的其他有用技巧:)</p></div></div>    
</body>
</html>
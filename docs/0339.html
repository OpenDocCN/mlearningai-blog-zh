<html>
<head>
<title>Stereo Vision: Adding Object Detection to our Depth map!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">立体视觉:将物体检测添加到我们的深度图中！</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/stereo-vision-adding-object-detection-to-our-depth-map-2bce3b45181d?source=collection_archive---------2-----------------------#2021-03-25">https://medium.com/mlearning-ai/stereo-vision-adding-object-detection-to-our-depth-map-2bce3b45181d?source=collection_archive---------2-----------------------#2021-03-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/2f988eef70d5fcf80da8b9ae8380e4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*qP6jHMmMlEE3TFtU.gif"/></div><figcaption class="il im et er es in io bd b be z dx">Source: Gifer</figcaption></figure><p id="cd21" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">到目前为止，我们的相机能够创建一个深度图，并在单击鼠标时确定像素的距离。</p><p id="db05" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但那只是半个终结者。我们需要我们的‘终结者’能够说:“有一个人站在那里。人在<em class="jn"> x </em>米外。进攻！”</p><p id="0ad0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您还没有通读本系列的<a class="ae jo" href="https://aryanvij02.medium.com/stereo-vision-how-do-terminators-see-the-world-5a70f3a1f4d1" rel="noopener">第1部分</a>和<a class="ae jo" href="https://aryanvij02.medium.com/stereo-vision-making-a-depth-map-from-scratch-6cd25c82897a" rel="noopener">第2部分</a>，请通读一下，以便更好地理解这一部分！</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="be48" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">这将如何工作</h1><ol class=""><li id="5374" class="ku kv hh ir b is kw iw kx ja ky je kz ji la jm lb lc ld le bi translated">使用TensorRT运行SSD-Mobilenet-v2对象检测模型。</li><li id="a4dd" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">结合物体检测和我们的深度图。</li><li id="31a1" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">确定对象检测边界框的质心。</li><li id="c96d" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">将质心的(x，y)坐标映射到深度图，从深度图的2D矩阵获得深度值。</li><li id="8a8d" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">显示距离。</li></ol></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="85b8" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">加载对象检测模型</h1><p id="2aaf" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">为了在这个系列中进行物体检测，我们将使用Nvidia的<a class="ae jo" href="https://github.com/dusty-nv/jetson-inference" rel="noopener ugc nofollow" target="_blank"> jetson推理库</a>，这是他们的Hello AI World教程系列的一部分。</p><blockquote class="ln lo lp"><p id="e771" class="ip iq jn ir b is it iu iv iw ix iy iz lq jb jc jd lr jf jg jh ls jj jk jl jm ha bi translated">Hello AI World教程是在Jetson产品上开始AI和深度学习项目的好方法。去<a class="ae jo" href="https://www.youtube.com/watch?v=QXIwdsyK7Rw&amp;list=PL5B692fm6--uQRRDTPsJDp4o0xbzkoyf8&amp;index=9" rel="noopener ugc nofollow" target="_blank">检查一下</a>！</p></blockquote><p id="d2d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将从源代码构建Nvidia的jetson-inference项目。这可能需要一些时间，并且会让您完成某些安装，所以请耐心等待！</p><p id="cb57" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">访问<a class="ae jo" href="https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md" rel="noopener ugc nofollow" target="_blank">本网站</a>并按照步骤或在您的终端中键入以下命令。</p><pre class="lt lu lv lw fd lx ly lz ma aw mb bi"><span id="9360" class="mc jx hh ly b fi md me l mf mg">$ sudo apt-get update<br/>$ sudo apt-get install git cmake libpython3-dev python3-numpy<br/>$ git clone --recursive https://github.com/dusty-nv/jetson-inference<br/>$ cd jetson-inference<br/>$ mkdir build<br/>$ cd build<br/>$ cmake ../<br/>$ make -j$(nproc)<br/>$ sudo make install<br/>$ sudo ldconfig</span></pre><p id="45c2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所有这些命令都取自Nvidia的教程。如果您遇到任何错误，确保检查他们的<a class="ae jo" href="https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md" rel="noopener ugc nofollow" target="_blank">位置</a>，以防安装过程发生某些变化。</p><h2 id="5f47" class="mc jx hh bd jy mh mi mj kc mk ml mm kg ja mn mo kk je mp mq ko ji mr ms ks mt bi translated">在安装过程中…</h2><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mu"><img src="../Images/ff695d8cf89be47f9f9cc8006a5018b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GqnJEZmm1UK-GguFXmH9Ew.png"/></div></div></figure><p id="855c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你会看到这个屏幕来下载一些深度学习模型。除了<strong class="ir hi"> SSD-Mobilenet-v2 </strong>之外，您可以选择取消选择所有选项，因为这是我们将用于本项目的选项。</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="bd5b" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">测试安装</h1><p id="8908" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">在我们进入下一步之前，让我们检查一下我们的安装是否成功。打开您的终端并键入:</p><pre class="lt lu lv lw fd lx ly lz ma aw mb bi"><span id="3665" class="mc jx hh ly b fi md me l mf mg">$ python3<br/>&gt;&gt;&gt; import jetson.utils<br/>&gt;&gt;&gt; import jetson.inference</span></pre><p id="b738" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您能够成功导入两个模块，这意味着我们可以开始了！如果您遇到任何关于<strong class="ir hi"> <em class="jn">杰特森</em> </strong>模块丢失的错误，请再次检查<a class="ae jo" href="https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md" rel="noopener ugc nofollow" target="_blank">杰特森-推断安装现场</a>并确保遵循所有步骤。</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="c5f6" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">测试对象检测模型</h1><p id="08ef" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">好吧！现在我们已经安装了所有的东西，让我们运行对象检测模型。</p><p id="f139" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">导航至<code class="du mz na nb ly b">/home/jetson-inference/python/examples/</code></p><p id="6c1b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后运行<code class="du mz na nb ly b">python3 my-detection.py</code></p><p id="5983" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">第一次运行该模型大约需要<strong class="ir hi">5-8分钟</strong>。</p><p id="d848" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果图像倒置，请使用:</p><pre class="lt lu lv lw fd lx ly lz ma aw mb bi"><span id="80b8" class="mc jx hh ly b fi md me l mf mg">python3 my-detection.py --flip-method=rotate-180 csi://0</span></pre><p id="9109" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如需了解更多详情，请查看该视频:</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="nc nd l"/></div></figure></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="05d8" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">那个人站在多远的地方？</h1><p id="6e81" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">我们已经运行了目标检测模型。我们也有深度图。现在是时候把两者结合起来了！</p><p id="bb9a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您之前已经克隆了我的<a class="ae jo" href="https://github.com/aryanvij02/StereoVision" rel="noopener ugc nofollow" target="_blank"> StereoVision repo </a>，您会在<strong class="ir hi"> <em class="jn"> main_scripts </em> </strong>文件夹中找到一个<strong class="ir hi"> 6_depthwithdistance.py </strong>文件。这就是你所需要的！</p><p id="ee70" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">导航到<code class="du mz na nb ly b">/home/StereoVision/main_scripts/</code>目录并运行:</p><p id="ebe5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><code class="du mz na nb ly b">python3 6_depthwithdistance.py</code>。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="nc nd l"/></div><figcaption class="il im et er es in io bd b be z dx">End result!</figcaption></figure><p id="6bf5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是你应该看到的。我修改了Python脚本，使模型只检测人，以避免周围其他物体的干扰。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="ne nd l"/></div></figure><p id="f0c4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您希望检测其他物体，请修改<strong class="ir hi"> 6_depthwithdistance.py </strong>中的<em class="jn">物体检测</em>功能。</p><p id="e140" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您可以从<a class="ae jo" href="https://github.com/dusty-nv/jetson-inference/blob/master/data/networks/ssd_coco_labels.txt" rel="noopener ugc nofollow" target="_blank">这里</a>了解COCO数据集中对象的不同<strong class="ir hi"> <em class="jn"> item_class </em> </strong>。只要记住<strong class="ir hi"> <em class="jn"> item_class </em> </strong>是索引，因此从0开始，因此<em class="jn">未标记=0，person=1，bicycle=2，等等</em>。</p><p id="055e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了更好地理解detectNet包，请查看这个页面。从这里你可以了解到<a class="ae jo" href="https://github.com/dusty-nv/jetson-inference/blob/master/examples/detectnet/detectnet.cpp#LC140:~:text=detectNet%3A%3ADetection*%20detections" rel="noopener ugc nofollow" target="_blank"><em class="jn">jetson . inference . detect net . detection</em></a>返回的是什么。</p><h1 id="a0f0" class="jw jx hh bd jy jz nf kb kc kd ng kf kg kh nh kj kk kl ni kn ko kp nj kr ks kt bi translated">想要删除jetson-inference文件夹吗？</h1><p id="3b72" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">我们不得不按照jetson-inference的指导将<strong class="ir hi"> jetson </strong>模块安装到我们的机器上。但是，我们不希望整个文件夹不必要地占用我们的Jetson Nano的存储空间。</p><p id="fa14" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">目前，我们无法删除jetson-inference文件夹，因为其中安装了对象检测模型。因此，让我们将模型移动到我们的立体视觉目录！</p><h2 id="d9aa" class="mc jx hh bd jy mh mi mj kc mk ml mm kg ja mn mo kk je mp mq ko ji mr ms ks mt bi translated">下载模型</h2><p id="62fe" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">您可以导航到<code class="du mz na nb ly b">/home/jetson-inference/data/networks/</code>并将SSD-Mobilenet-v2文件夹复制到<code class="du mz na nb ly b">StereoVision</code>目录。</p><p id="efe5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">或者…</p><p id="40de" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">前往<a class="ae jo" href="https://github.com/aryanvij02/StereoVision/releases/tag/ssd" rel="noopener ugc nofollow" target="_blank">发布页面</a>，下载两个文件到<code class="du mz na nb ly b">/home/StereoVision/SSD-Mobilenet-v2/</code>。</p><figure class="lt lu lv lw fd ii er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nk"><img src="../Images/1fa46383db6917729a61cf7fc960ba70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YvnQg0dOXUdA5R4sa7Rc7g.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Files to download</figcaption></figure><p id="c3d2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">修改6_depthwithdistance.py </strong></p><p id="b285" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们需要改变加载ssd-mobilenet-v2  的路径。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="ne nd l"/></div></figure><p id="acce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如上所示，注释正在加载ssd-mobilenet-v2模型的当前行，并取消注释以下3行。</p><p id="7ab8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一定要把<code class="du mz na nb ly b">--model=/home/aryan/StereoVision/SSD-Mobilenet-v2/ssd_mobilenet_v2_coco.uff</code>换成自己的路径。</p><p id="d0b4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们终于可以删除jetson-inference文件夹了。</p><blockquote class="ln lo lp"><p id="d9f3" class="ip iq jn ir b is it iu iv iw ix iy iz lq jb jc jd lr jf jg jh ls jj jk jl jm ha bi translated">我们也可以用这个方法加载不同的深度学习模型。只要确保相应地改变不同的参数。</p></blockquote><p id="2b50" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">试着再次运行<strong class="ir hi"> 6_depthwithdistance.py </strong>，应该可以！</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="4653" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">恭喜你！</h1><p id="0c57" class="pw-post-body-paragraph ip iq hh ir b is kw iu iv iw kx iy iz ja lk jc jd je ll jg jh ji lm jk jl jm ha bi translated">我们已经完成了本教程，并学到了这么多！尝试立体视觉和物体检测(深度学习)是一个很好的开始方式！</p><p id="f9e7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留下评论，如果你扩展这个项目或有任何反馈！感谢阅读！</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="fa7f" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">重要来源</h1><ol class=""><li id="0637" class="ku kv hh ir b is kw iw kx ja ky je kz ji la jm lb lc ld le bi translated">我的<a class="ae jo" href="https://github.com/aryanvij02/StereoVision" rel="noopener ugc nofollow" target="_blank">立体视觉储存库</a></li><li id="4e88" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><a class="ae jo" href="https://github.com/dusty-nv/jetson-inference" rel="noopener ugc nofollow" target="_blank">杰特森-推理知识库</a></li><li id="a737" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><a class="ae jo" href="https://www.youtube.com/watch?v=QXIwdsyK7Rw&amp;list=PL5B692fm6--uQRRDTPsJDp4o0xbzkoyf8&amp;index=9" rel="noopener ugc nofollow" target="_blank">你好AI世界YouTube教程</a></li><li id="ca63" class="ku kv hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><a class="ae jo" href="https://rawgit.com/dusty-nv/jetson-inference/python/docs/html/python/jetson.inference.html#:~:text=Detection%20%3D%20%3Ctype" rel="noopener ugc nofollow" target="_blank">已定义的检测网络属性</a></li></ol></div></div>    
</body>
</html>
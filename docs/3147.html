<html>
<head>
<title>Object Detection using YOLO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YOLO的目标检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-detection-using-yolo-3f7399b652a8?source=collection_archive---------3-----------------------#2022-07-26">https://medium.com/mlearning-ai/object-detection-using-yolo-3f7399b652a8?source=collection_archive---------3-----------------------#2022-07-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ec03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我分享了一个一步一步的方法来建立一个简单的对象检测器使用YOLO和网络摄像头从您的笔记本电脑来识别一个特定的对象。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/8b0963d9215761b38b4e411a9a8b3801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NgTKBkAgsl-h7cru.jpg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://dagshub.com/blog/yolov6/" rel="noopener ugc nofollow" target="_blank">dagshub</a></figcaption></figure><blockquote class="jt ju jv"><p id="623a" class="ie if jw ig b ih ii ij ik il im in io jx iq ir is jy iu iv iw jz iy iz ja jb ha bi translated">注意:拥有YOLO模型的基础知识将有助于更好地理解本文。还有，代码是用Python写的。</p></blockquote><p id="6c93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">什么是YOLO？</strong></p><blockquote class="jt ju jv"><p id="2f68" class="ie if jw ig b ih ii ij ik il im in io jx iq ir is jy iu iv iw jz iy iz ja jb ha bi translated">YOLO，是“你只看一次”的首字母缩写(灵感来自名言“你只活一次”)</p></blockquote><p id="6c88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">YOLO是一种对象检测算法，它使用卷积神经网络(CNN)来实时检测对象。顾名思义，它是一个单级对象检测模型，只需要通过神经网络进行一次前向传播来检测对象。为了更多地了解YOLO及其历史，我发现来自pyimagesearch的这篇<a class="ae js" href="https://pyimagesearch.com/2022/04/04/introduction-to-the-yolo-family/" rel="noopener ugc nofollow" target="_blank">文章</a>非常有帮助，但是你也可以参考许多其他有用的在线资源。</p><p id="08f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">初始要求</strong></p><p id="31e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个项目，我们将<strong class="ig hi">而不是</strong>从头开始训练模型，而是使用YOLOv4的预训练配置和权重。为此，需要首先下载以下文件:</p><ul class=""><li id="bfb2" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb kf kg kh ki bi translated"><a class="ae js" href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg" rel="noopener ugc nofollow" target="_blank">配置文件</a>:模型架构存储在该文件中。</li><li id="6610" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb kf kg kh ki bi translated"><a class="ae js" href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights" rel="noopener ugc nofollow" target="_blank">权重文件</a>:预先训练好的模型权重。这些是使用MS COCO数据集上的DarkNet代码库训练的。</li><li id="ad31" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb kf kg kh ki bi translated"><a class="ae js" href="https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names" rel="noopener ugc nofollow" target="_blank">类文件</a>:包含COCO数据集中80个对象类别的名称。</li></ul><p id="5c05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们通过使用OpenCV DNN函数<code class="du ko kp kq kr b">cv2.dnn.readNetFromDarknet</code>加载YOLO模型来完成初始设置。然后，我们读取类文件<code class="du ko kp kq kr b">coco.names</code>,它包含80个不同对象类的列表，YOLO模型在这些对象类上进行训练，并将它们存储在一个python列表中。接下来，我们定义需要检测的对象。在这种特殊情况下，我们希望从摄像头馈送中检测手机。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ks kt l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Initial configuration and set-up</figcaption></figure><p id="ceb9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">物体检测功能</strong></p><p id="62e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是“奇迹”发生的地方。接下来，我们定义一个对象检测函数。此功能从您的相机获取图像帧，然后检测目标对象。摄像机提要的代码片段将在后面解释。但是现在，让我们假设这个函数接收单个图像作为输入。</p><p id="c7c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们得到输入图像的高度和宽度。然后，我们需要使用<code class="du ko kp kq kr b">cv2.dnn.blobFromImage</code>函数将图像转换成一个斑点(这是一个4D NumPy数组对象——图像、通道、宽度、高度)。这是为模型输入准备所需格式的输入图像所必需的。要了解blob是什么以及<code class="du ko kp kq kr b">cv2.dnn.blobFromImage</code>函数如何工作的更多信息，请参考这个<a class="ae js" href="https://pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/" rel="noopener ugc nofollow" target="_blank">博客</a>。该函数的输入参数取决于正在使用的模型。对于<a class="ae js" href="https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html#create-a-blob" rel="noopener ugc nofollow" target="_blank"> YOLO </a>，使用以下参数:</p><pre class="jd je jf jg fd ku kr kv kw aw kx bi"><span id="e1a7" class="ky kz hh kr b fi la lb l lc ld">the <strong class="kr hi">image</strong> to transform<br/>the <strong class="kr hi">scale factor</strong> (1/255 to scale the pixel values to [0..1])<br/>the <strong class="kr hi">size</strong>, here a 416x416 square image<br/>the <strong class="kr hi">mean</strong> value (default=0)<br/>the option <strong class="kr hi">swapBR</strong>=True (since OpenCV uses BGR)</span></pre><p id="9052" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后将斑点对象设置为网络的输入，并且在从YOLO模型确定输出层之后，通过YOLO网络执行正向传递。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ks kt l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Object detection function</figcaption></figure><p id="b241" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还需要在检测到物体后将结果可视化。但是首先，让我们初始化几个列表来存储所需的信息，以便:</p><ul class=""><li id="973a" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb kf kg kh ki bi translated"><code class="du ko kp kq kr b">boxes</code>:对象周围的边框。</li><li id="457b" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb kf kg kh ki bi translated"><code class="du ko kp kq kr b">confidences</code>:YOLO模型赋予对象的置信度得分。我们设置最小概率分数<code class="du ko kp kq kr b">0.5</code>来过滤掉弱检测。较低的置信度值表明对象可能不是网络认为的那样。</li><li id="53a3" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb kf kg kh ki bi translated"><code class="du ko kp kq kr b">class_ids</code>:被检测对象类别的标签。</li></ul><p id="3de1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们遍历每个<code class="du ko kp kq kr b">layeroutput</code>，然后遍历<code class="du ko kp kq kr b">output</code>中的每个<code class="du ko kp kq kr b">detection</code>。然后从<code class="du ko kp kq kr b">detection</code>列表的第5个元素中提取所有对象类别的<a class="ae js" href="https://pyimagesearch.com/2022/04/11/understanding-a-real-time-object-detection-network-you-only-look-once-yolov1/#h3E2E" rel="noopener ugc nofollow" target="_blank">置信度得分，并选择具有最大置信度得分的对象的类别id。如果检测到的类别id等于所需对象(即本例中的手机)的类别id，并且置信度得分大于阈值(以滤除弱检测)，则我们尝试通过绘制边界框并添加该对象的标签来可视化所需的检测到的对象。</a></p><p id="ba1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">YOLO模型返回边界框的中心(x，y)坐标，后跟框的宽度和高度。但是在我们实际使用它们之前，我们需要首先相对于图像的大小来缩放这些值。缩放后，我们使用边界框的中心坐标、宽度和高度来导出边界框的左上角坐标。然后更新<code class="du ko kp kq kr b">boxes</code>、<code class="du ko kp kq kr b">confidences</code>和<code class="du ko kp kq kr b">class_ids</code>列表。</p><p id="39f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">默认情况下，YOLO不应用<a class="ae js" href="https://pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/" rel="noopener ugc nofollow" target="_blank">非最大值抑制</a>，因此我们需要使用<code class="du ko kp kq kr b">cv2.dnn.NMSBoxes</code>函数显式应用它。该函数简单地抑制明显重叠的边界框，只保留有把握的边界框，而排除任何多余的边界框。输入参数是盒子、置信度、置信度阈值(即<code class="du ko kp kq kr b">0.5</code>)和NMS阈值。</p><p id="4673" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设已经检测到预期的对象(即本例中的手机)，我们循环通过由非最大值抑制确定的<code class="du ko kp kq kr b">indexes</code>,以使用随机类别颜色在图像上绘制边界框和文本。然后，最后，我们显示我们的结果图像。</p><p id="0d66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">从摄像机中捕捉视频并识别目标物体</strong></p><p id="1f29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于这个项目的目标是从摄像机的饲料中识别一个特定的对象，我们首先需要用摄像机(网络摄像头)捕捉直播流。为此，我们需要从OpenCV库中创建一个<code class="du ko kp kq kr b">VideoCapture</code>类的对象。作为输入，<code class="du ko kp kq kr b">VideoCapture</code>类接收我们想要使用的设备的索引。如果我们有一个连接到计算机的摄像机，我们可以传递一个值0。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ks kt l"/></div></figure><p id="6053" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这之后，在while循环中，我们可以开始一帧一帧地从摄像机中读取视频。我们在<code class="du ko kp kq kr b">VideoCapture</code>对象上使用<code class="du ko kp kq kr b"><a class="ae js" href="https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-read" rel="noopener ugc nofollow" target="_blank">read</a></code>方法来读取每一帧。这个方法没有参数，返回一个元组。第一个返回的值是一个布尔值，指示一个帧是否被正确读取(True或False ),第二个值是来自摄像机的帧。接下来，我们将每一帧传递给我们的对象检测函数<code class="du ko kp kq kr b">imgRead</code>。如果预期的对象(例如，本例中的手机)出现在相机馈送中，那么一个带有对象标签的边界框将围绕在它的周围(如下图所示)。<code class="du ko kp kq kr b">cv2.imshow()</code>方法在窗口中显示视频或图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es le"><img src="../Images/a0477543b20cb122b3c60a5f66b42b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*AswJLz-WFAYxWfsC1KNvvA.png"/></div></figure><p id="55ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，如果我们想关闭摄像头，我们可以简单地按下键盘上的<code class="du ko kp kq kr b">q</code>键。</p><p id="6702" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参考资料:</p><ol class=""><li id="b79f" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb lf kg kh ki bi translated"><a class="ae js" href="https://pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/" rel="noopener ugc nofollow" target="_blank">https://pyimagesearch . com/2018/11/12/yolo-object-detection-with-opencv/</a></li><li id="3e3a" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb lf kg kh ki bi translated"><a class="ae js" href="https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html" rel="noopener ugc nofollow" target="_blank">https://opencv-tutorial . readthedocs . io/en/latest/yolo/yolo . html</a></li></ol><div class="lg lh ez fb li lj"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lk ab dw"><div class="ll ab lm cl cj ln"><h2 class="bd hi fi z dy lo ea eb lp ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lq l"><h3 class="bd b fi z dy lo ea eb lp ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lr l"><p class="bd b fp z dy lo ea eb lp ed ef dx translated">medium.com</p></div></div><div class="ls l"><div class="lt l lu lv lw ls lx jm lj"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>How to Tokenize Words and Sentences using NLTK and NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用NLTK和NLP对单词和句子进行分词</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-tokenize-words-and-sentences-using-nltk-and-nlp-f5b428a4e822?source=collection_archive---------6-----------------------#2021-08-04">https://medium.com/mlearning-ai/how-to-tokenize-words-and-sentences-using-nltk-and-nlp-f5b428a4e822?source=collection_archive---------6-----------------------#2021-08-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/c14512adcd14f511680d3eddd253e6df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TYSJ7T8SV9sLuTrSsZfmQQ.jpeg"/></div></div></figure><p id="c058" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">NLTK模块是一个大型工具包，旨在帮助您处理自然语言处理(NLP)的许多方面。NLTK可以帮助你从段落断句到拆分单词，识别这些单词的词性，强调重要的主题，甚至帮助你的计算机理解文本。在本文中，我们将关注情感分析领域，通常被称为意见挖掘。</p><p id="7042" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您将需要NLTK模块以及Python来开始。</p><p id="4dfe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你还没有Python，去Python.org下载最新版本的Windows。您应该能够在Mac或Linux系统上执行以下代码:</p><pre class="jn jo jp jq fd jr js jt ju aw jv bi"><span id="92f5" class="jw jx hh js b fi jy jz l ka kb">sudo apt-get install python3</span></pre><p id="bb81" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">之后你就需要NLTK 3了。Pip3将是安装NLTK模块最方便的方式。</p><p id="7231" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所有用户都可以通过打开cmd.exe、bash或您使用的任何一个shell并键入:</p><pre class="jn jo jp jq fd jr js jt ju aw jv bi"><span id="3866" class="jw jx hh js b fi jy jz l ka kb">pip3 install nltk</span></pre><p id="c459" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">之后，我们必须安装一些NLTK组件。使用您喜欢的方法和类型打开python:</p><pre class="jn jo jp jq fd jr js jt ju aw jv bi"><span id="b2a7" class="jw jx hh js b fi jy jz l ka kb">import nltk<br/>nltk.download()</span></pre><p id="826c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">除非您是无头运行，否则会出现一个GUI。</p><p id="1356" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">选取“全部”以下载所有软件包，然后点按“下载”作为结果，您将获得所有的分词器、分块器、各种算法和语料库。如果空间不足，您可以选择手动下载所有内容。nltk模块将占用大约7MB，而完整的NLTK数据目录(包括您的组块器、解析器和语料库)将占用大约1.8GB。</p><p id="60fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您正在运行headless，您可以通过运行Python并执行上述代码和以下步骤来安装所有内容:</p><p id="f6eb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><code class="du kc kd ke js b">d</code>(供下载)</p><p id="6706" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><code class="du kc kd ke js b">all</code>(用于下载一切)</p><p id="e6dc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它会为你下载所有的东西，而你不需要做任何事情。</p><p id="cf36" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当你第一次加入自然语言处理(NLP)领域时，这些是你会听到的最常见的单词，尽管还有更多我们将在后面介绍。之后，让我们看一个NLTK模块如何被用来标记任何东西的例子。</p><pre class="jn jo jp jq fd jr js jt ju aw jv bi"><span id="6606" class="jw jx hh js b fi jy jz l ka kb">from nltk.tokenize import sent_tokenize, word_tokenize<br/><br/>EXAMPLE_TEXT = "The dog was called Wellington. It belonged to Mrs. Shears who was our friend. She lived on the opposite side of the road, two houses to the left."<br/><br/>print(sent_tokenize(EXAMPLE_TEXT))</span></pre><p id="5fa1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">乍一看，用单词或短语之类的东西来标记似乎是一项简单的任务。它可以出现在很多句子中。简单的. split(' . '))，或者除以句点后跟一个空格，很可能是第一步。然后，您可以使用正则表达式按句点、空格和大写字母分隔文本。问题是像舍尔斯夫人这样的人会给你带来麻烦。按单词拆分可能也很困难，尤其是在处理像we和are to we 're这样的连接时。通过这个看似简单，但实际上非常复杂的过程，NLTK将会为您节省大量时间。</p><p id="7c17" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上面的代码将生成一个短语列表，您可以使用for循环遍历它:</p><p id="1e87" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[“这只狗叫威灵顿。”“它属于我们的朋友舍尔斯太太。”，‘她住在路的对面，左边两栋房子。’]</p><p id="c3b3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们开发了记号或短语。相反，这次让我们按单词来标记:</p><pre class="jn jo jp jq fd jr js jt ju aw jv bi"><span id="8f10" class="jw jx hh js b fi jy jz l ka kb">print(word_tokenize(EXAMPLE_TEXT))</span></pre><p id="2206" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们的输出是:['The '，' dog '，' was '，' called '，' Wellington '，'.'、'它'、'属于'、'属于'、'夫人'、'舍尔斯'、'谁'、'曾经是'、'我们的'、'朋友'、'等等、'她'、'住过'、'对'、'对'、'对面'、'的'、'道'、'的'、'二'、'房子'、'对'、'的'、'左'、'的.']</p><p id="2382" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里有几件事需要记住。首先，请注意，标点符号被视为一个独特的符号。此外，注意单词“不应该”是如何分为“应该”和“不应该”的最后，观察“粉蓝色”是如何被处理成它想要成为的“一个单词”的。真的很酷！</p><p id="79cd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们面前有了这些标记化的单词，我们必须考虑我们的下一步。我们开始思考如何从这些词中提取意义。许多词可能显然被赋予了货币价值，但有一小部分本质上是无用的。这是一种我们也可能会遇到的“停用词”。无论如何，这就是NLP和NLTK的基本原理；它既有趣又复杂。</p></div></div>    
</body>
</html>
# 为什么过参数化的深网不会过拟合？

> 原文：<https://medium.com/mlearning-ai/intuitive-explanations-of-why-over-parameterised-deep-nets-dont-overfit-8a323b223ba6?source=collection_archive---------1----------------------->

## 训练过参数化深度神经网络的惊人特性

**过参数化**:模型参数数量大于训练样本数量的状态。

**概括:**一个经过训练的模型在看不见的测试数据上表现如何？

传统的统计理论认为，在过度参数化的状态下，过度拟合是非常可能的。我们讨论偏差-方差权衡以及如何增加模型的复杂性超过一定…
<html>
<head>
<title>Controlling Smart Bulb Using GreenGrass Core And ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GreenGrass内核和ML控制智能灯泡</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/controlling-smart-bulb-using-greengrass-core-and-ml-c284fc922ed5?source=collection_archive---------3-----------------------#2021-03-12">https://medium.com/mlearning-ai/controlling-smart-bulb-using-greengrass-core-and-ml-c284fc922ed5?source=collection_archive---------3-----------------------#2021-03-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="5108" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用AWS Greengrass核心进行机器学习的指南</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="cef0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>阅读这篇文章需要对Python、机器学习以及类似AWS IoT、AWS Greengrass、AWS Sagemaker和AWS Lambda函数的AWS服务有基本的了解。</p><p id="abd0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我一直在学习AWS，特别是AWS IoT，并创建了一些小项目，但我不相信它们。我想利用AWS资源的力量创造一些令人兴奋和有用的东西。然后我有了一个项目想法:如果我可以用手写命令控制我的智能灯泡会怎么样？<br/>我创建了这个项目的草图，这是它的样子:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jj"><img src="../Images/8dff78400c2da4f937783717c3382441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lz0sXdvv-Ma_BbAqkFgqQ.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Project workflow</figcaption></figure><h2 id="2e6c" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">项目工作流程</h2><p id="9ee6" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我会在纸上写一个命令。一个物联网的东西会拍下那张纸的照片，并在MQTT主题<em class="kz">手写模型/框架</em>上发布这个图像。部署在Greengrass core上并订阅了该主题的lambda函数将接收该图像并执行ML推理来预测命令。然后这个命令通过MQTT主题<em class="kz">模型/预测发送。另一个lambda函数也部署在Greengrass core上并订阅了这个主题，它将接收这个命令，然后控制智能灯泡。这里使用的ML模型由AWS Sagemaker Neo编译，并保存在S3桶中，该桶由AWS物联网核心拉至Greengrass核心进行部署。这整个项目发布在<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上。</em></p><p id="c816" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，如你所见，这个项目涉及了很多东西。我使用自顶向下的方法，从创建ML模型开始。下面是这篇文章的提纲:</p><p id="05ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#65bb">创建ML模型</a></p><p id="de64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#a5eb">创建手写数据集以训练模型</a></p><p id="a377" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#99df">上传S3模型</a></p><p id="9c6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#82f0">使用Sagemaker Neo编译模型</a></p><p id="d3cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#cd66">创建Lambda函数</a></p><p id="9373" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#681a">创造物联网</a></p><p id="67c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">7.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#9faf">创建绿草集团</a></p><p id="9f2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">8.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#ac0a">安装Neo DLR </a></p><p id="ad7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">8.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#3950">将羔羊肉加入绿草群</a></p><p id="6783" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">9.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#ffc8">添加ML模型</a></p><p id="ca46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">10.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#9e02">添加物联网东西</a></p><p id="3144" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">11.<a class="ae la" rel="noopener" href="/p/c284fc922ed5#19a1">添加订阅</a></p><h2 id="65bb" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">1.创建ML模型</h2><p id="b8bb" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">创建一个可以阅读手写字符的ML模型是一件非常困难的工作。我试图创建自己的模型，但是我的模型没有达到预期的精度。然后我决定用迁移学习的概念。我使用了由pyimagesearch 的<a class="ae la" href="https://www.pyimagesearch.com/2020/08/24/ocr-handwriting-recognition-with-opencv-keras-and-tensorflow/" rel="noopener ugc nofollow" target="_blank"> Adrian创建的模型(多亏了他),这个模型有95%的准确率。我砍掉了</a><a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/handwriting.h5" rel="noopener ugc nofollow" target="_blank">模型</a>的最后一层，添加了我自己的层，并根据我自己的笔迹训练了那个模型，得到了96%的准确率。这是我执行迁移学习的<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/train_ocr_model.py" rel="noopener ugc nofollow" target="_blank">代码</a>。如果你想看的话，我还添加了他的模型的代码。我将我训练过的模型保存为<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/myhandwriting.h5" rel="noopener ugc nofollow" target="_blank">my handship . H5</a>。如果你注意到了，我正在加载数据集<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/myhandwriting.csv" rel="noopener ugc nofollow" target="_blank">my written . CSV</a>来训练我的模型。因此，下一步是创建这个数据集。</p><h2 id="a5eb" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">2.创建手写数据集以训练模型</h2><p id="6a18" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">首先，我在一张纸上多次书写一个字母表(例如，A)。我给那张纸拍了张照片，然后对这张照片进行处理，从照片中提取出字符，并将它们保存到<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/myhandwriting.csv" rel="noopener ugc nofollow" target="_blank">my handship . CSV</a>文件中。下面是从图像中提取字符并保存到<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/myhandwriting.csv" rel="noopener ugc nofollow" target="_blank">my handshawd . CSV</a>文件中的<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/extract_handwriting.py" rel="noopener ugc nofollow" target="_blank">代码</a>。这段代码对图像使用了与pyimagesearch 的<a class="ae la" href="https://www.pyimagesearch.com/2020/08/24/ocr-handwriting-recognition-with-opencv-keras-and-tensorflow/" rel="noopener ugc nofollow" target="_blank"> Adrian相同的预处理，尽管在将字符保存为csv的方式上有所不同。<br/>我没有创建所有英文字母的数据集，因为在控制灯泡的命令中只使用了很少一部分。所以，我只在那些特定的字母上训练我的模型。在每一行的第一个数字代表分配给字母表的标签。比如我把0赋给了a。</a></p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="03d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到目前为止，我们已经完成了AWS之外的工作。现在是切换到AWS的时候了。目的是使用Sagemaker Neo编译训练好的模型<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/extracting-my-handwriting-and-train-model/myhandwriting.h5" rel="noopener ugc nofollow" target="_blank">my handshage . H5</a>并部署在Greengrass Core上。</p><h2 id="99df" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">3.在S3上传模型</h2><p id="ef3b" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我创建的模型是一个Keras模型，以h5格式保存。此模型无法上传到Greengrass，因为Greengrass不支持Keras库。支持的库和框架可以在这里看到<a class="ae la" href="https://docs.aws.amazon.com/greengrass/v1/developerguide/what-is-gg.html#ml-runtimes-libs" rel="noopener ugc nofollow" target="_blank">。这个问题的解决方案是</a><a class="ae la" href="https://docs.aws.amazon.com/sagemaker/latest/dg/neo.html" rel="noopener ugc nofollow" target="_blank"> Sagemaker Neo </a>。基本上，它是一个AWS服务，转换和优化Gluon、Keras、MXNet、PyTorch、TensorFlow、TensorFlow-Lite和ONNX模型，以便在特定硬件上运行。我使用Sagemaker Neo转换了我的Keras模型，并对其进行了优化，以便在我基于x86的Greengrass内核上运行。</p><p id="bcf6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了使用Sagemaker Neo，有三点需要注意:<br/> 1。经过训练的Keras模型将被上传到S3桶中。Sagemaker Neo将从桶中取出模型，并将编译后的模型(经过转换和优化)保存回同一个S3桶中。这个编译好的模型以后会被AWS Greengrass使用。</p><p id="00e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.训练好的模型应压缩为. tar.gz格式，然后上传到S3，以便Neo进行编译。这里有一个<a class="ae la" href="https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-frameworks.html" rel="noopener ugc nofollow" target="_blank">表</a>，根据不同的框架，到底应该压缩什么。在Keras的情况下，只有. h5模型应该压缩为. tar.gz。</p><p id="166b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.存储桶名称应该包含<code class="du lb lc ld le b">greengrass</code>。这个要求来自<a class="ae la" href="https://docs.aws.amazon.com/greengrass/v1/developerguide/ml-inference.html" rel="noopener ugc nofollow" target="_blank">绿草</a>。名称中包含<code class="du lb lc ld le b">greengrass</code>的S3存储桶由于其awsgrengrassresourceaccrolepolicy而被Greengrass自动读取。</p><p id="c901" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以我将我的. h5模型压缩为. tar.gz，并上传到一个名为<code class="du lb lc ld le b">greengrass</code>的S3桶中。</p><h2 id="82f0" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">4.使用Sagemaker Neo编译模型</h2><p id="9049" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">创建编译任务的过程如<a class="ae la" href="https://docs.aws.amazon.com/sagemaker/latest/dg/neo-job-compilation-console.html" rel="noopener ugc nofollow" target="_blank">所示，此处为</a>。我给出了以下与我的案例相关的输入:</p><ol class=""><li id="7049" class="lf lg hh ig b ih ii il im ip lh it li ix lj jb lk ll lm ln bi translated">数据输入配置:{"input_1":[1，1，32，32]}</li></ol><p id="826a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个数据输入配置是特定于Keras的。针对不同框架的不同数据配置在这里是<a class="ae la" href="https://docs.aws.amazon.com/sagemaker/latest/dg/neo-job-compilation.html" rel="noopener ugc nofollow" target="_blank"/>。这里，第一个1意味着一次要预测的图像数量是1。第二个1表示图像中的通道数为1。32和32是图像的高度和宽度。该数据对应于模型第一层的输入。我可以通过检查<em class="kz"> model.summary() </em>输出来查看这些数据。在我的模型中，它是[无，32，32，1]。这里需要注意的是，在数据输入配置中，输入格式是NCHW，而在<em class="kz"> model.summary() </em>输出中，输入格式是NWHC。</p><p id="a72f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.目标平台OS : Linux <br/>我在Greengrass core上用的是Linux(正好是Ubuntu 18.04)。</p><p id="626f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.目标平台OS:x86 _ 64<br/>Ubuntu 18.04安装在intel芯片上。</p><p id="d454" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.机器学习框架:KERAS</p><p id="627b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不使用加密。我使用上述输入成功地编译了我的模型，并将编译后的模型保存到同一个S3桶中。编译大约需要1分钟。编译后的模型也被压缩为. tar.gz格式。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="9f15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到目前为止，我在AWS之外创建并训练了一个模型，然后我使用Sagemaker Neo编译了这个模型，使它可以在Greengrass上部署。现在是时候创建lambda函数了。</p><h2 id="cd66" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">5.创建Lambda函数</h2><p id="fc96" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我在这个项目中使用了2个lambda函数。<br/>第一个lambda函数用于对部署在Greengrass上的模型进行推理。下面是这个lambda函数的代码。这个lambda函数对图像使用与创建数据集相同的处理。因为这个lambda函数的输入也是一个带有由字母组成的命令的图像。这里需要注意的是，到模型的路径，即<em class="kz">/neo-compiled-my written-model</em>。这是在Greengrass core上保存模型的路径。每当通过MQTT主题<em class="kz">手写模型/帧从物联网发布图像时，该lambda函数就会被触发。</em>然后它<em class="kz"> </em>预测图像上的命令，并通过MQTT主题<em class="kz">模型/预测发布命令。</em></p><p id="71c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第二个lambda函数用于使用<a class="ae la" href="https://yeelight.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Python的Yeelight库</a>控制我的Yeelight智能灯泡。每当在MQTT topic <em class="kz"> model/predictions上发布命令时，就会触发这个函数。</em>根据命令改变灯泡的状态，并通过MQTT话题<em class="kz">灯泡/确认</em>向物联网返回确认。这是这个lambda函数的代码。</p><p id="9ca0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">两个lambda函数都上传到AWS lambda和greengrasssdk文件夹中，这基本上使这些lambda函数能够在Greengrass上运行。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="fad9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到目前为止已经做了很多工作，但是这个项目还远远没有结束。现在我到达了主要部分，即AWS IoT。</p><h2 id="681a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">6.创造物联网</h2><p id="427b" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我用我的Windows电脑有一个物联网的东西，因为它已经有一个摄像头，这是拍照所必需的。在AWS中创建物联网显示为<a class="ae la" href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-moisture-create-thing.html" rel="noopener ugc nofollow" target="_blank">这里是</a>。这是我的原则:</p><pre class="jk jl jm jn fd lo le lp lq aw lr bi"><span id="5a30" class="jz ka hh le b fi ls lt l lu lv">{<br/>  "Version": "2012-10-17",<br/>  "Statement": [<br/>    {<br/>      "Effect": "Allow",<br/>      "Action": [<br/>        "iot:Connect",<br/>        "iot:Publish",<br/>        "iot:Subscribe",<br/>        "iot:Receive",<br/>        "greengrass:*"<br/>      ],<br/>      "Resource": [<br/>        "*"<br/>      ]<br/>    }<br/>  ]<br/>}</span></pre><p id="8c09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将pc连接到AWS物联网核心和Greengrass核心的最佳方式是使用用于Python的AWS物联网设备SDK。我用了这个SDK的<a class="ae la" href="https://github.com/aws/aws-iot-device-sdk-python" rel="noopener ugc nofollow" target="_blank">版本1 </a>，因为我要用Greengrass版本1.x。</p><p id="5580" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">安装这个SDK后，我可以使用SDK的greengrass连接功能将我的Windows pc连接到Greengrass core，并将网络摄像头拍摄的图像发送给它。同样的代码在这里是<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/sendCameraFrames.py" rel="noopener ugc nofollow" target="_blank"/>。在这段代码中，从网络摄像头拍摄的图像在通过MQTT发布之前被压缩。背后的原因是AWS MQTT有效负载大小的128KB限制。</p><h2 id="9faf" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">7.创建绿草小组</h2><p id="c345" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我用的是安装在intel芯片上的Ubuntu 18.04作为我的绿草核心设备。此处显示了Greengrass支持的所有平台和操作系统<a class="ae la" href="https://docs.aws.amazon.com/greengrass/v1/developerguide/what-is-gg.html#gg-platforms" rel="noopener ugc nofollow" target="_blank">。我用这个</a><a class="ae la" href="https://docs.aws.amazon.com/greengrass/v1/developerguide/gg-gs.html" rel="noopener ugc nofollow" target="_blank"> AWS教程</a>创建了AWS Greenrass组，并部署在Greengrass Core上。最后，我有一个工作的Greengrass核心设备向AWS物联网核心发布“Hello World”。</p><h2 id="ac0a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">8.安装Neo DLR</h2><p id="8f19" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">需要Sagemaker Neo运行时才能在Greengrass core上运行模型。关于Neo深度学习运行时以及如何安装它的更多信息，在这里给出<a class="ae la" href="https://docs.aws.amazon.com/greengrass/v1/developerguide/ml-dlc-console.html" rel="noopener ugc nofollow" target="_blank">。我使用这里</a><a class="ae la" href="https://neo-ai-dlr.readthedocs.io/en/latest/install.html#building-on-linux" rel="noopener ugc nofollow" target="_blank">的指令</a>在我的绿草核心设备上安装Neo DLR。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="156a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到目前为止，我们已经创建了这个项目所需的所有组件。现在是将它们相互连接并完成项目的时候了。</p><h2 id="3950" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">9.将lambdas添加到Greengrass组</h2><p id="e476" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我用下面的配置添加了我的两个lambda函数，将其他选项保留为默认值:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es lw"><img src="../Images/d397216efc40af7e83470fe0e7c41241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f4M_za-vTJPPca5z-i56vw.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Lambda Configuration</figcaption></figure><h2 id="ffc8" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">10.添加ML模型</h2><p id="531c" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我在绿草集团的<em class="kz">资源</em>下添加了ML模型，配置如下。这里，本地路径与<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/lambda%20functions/MLInferencing.py" rel="noopener ugc nofollow" target="_blank">ml推理</a> lambda函数中给出的路径相同:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es lx"><img src="../Images/fa09703351db0a7b960939dd44f12316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yysVlLsiUd-ntJe-DGFJIQ.png"/></div></div></figure><h2 id="9e02" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">11.添加物联网东西</h2><p id="d1f1" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我在Greengrass Group的<em class="kz">设备</em>下添加了我在第6部分创建的物联网。</p><h2 id="19a1" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">12.添加订阅</h2><p id="1930" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我在Greengrass group的<em class="kz">下面添加了</em>的订阅:</p><ol class=""><li id="67cc" class="lf lg hh ig b ih ii il im ip lh it li ix lj jb lk ll lm ln bi translated">物联网事物-&gt; mlinterception . py |主题:手写模型/框架</li><li id="460b" class="lf lg hh ig b ih ly il lz ip ma it mb ix mc jb lk ll lm ln bi translated">ml interference . py--&gt; control yee light . py |主题:模型/预测</li><li id="cb12" class="lf lg hh ig b ih ly il lz ip ma it mb ix mc jb lk ll lm ln bi translated">ControlYeelight.py -&gt;物联网|主题:灯泡/确认</li></ol><p id="cd9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">没有这些订阅，无法触发lambda函数。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="663e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们结束了。我在Greengrass Core上部署了这个更新后的组，并在我的物联网上运行了<a class="ae la" href="https://github.com/anubhav1/ControlSmartBulbUsingGreenGrassCoreAndML/blob/master/sendCameraFrames.py" rel="noopener ugc nofollow" target="_blank">sendmaceraframes . py</a>。</p><p id="fc9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我已经跳过了这篇文章中的许多小细节，因为我在上面做了假设。欢迎大家在评论里留下问题，我会尽力解答。</p></div></div>    
</body>
</html>
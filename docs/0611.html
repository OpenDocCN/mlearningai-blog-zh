<html>
<head>
<title>How To Improve Your Model’s Performance Using Cross-Validation Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用交叉验证技术提高模型的性能</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-improve-your-models-performance-using-cross-validation-techniques-d202dfe3edd4?source=collection_archive---------0-----------------------#2021-05-26">https://medium.com/mlearning-ai/how-to-improve-your-models-performance-using-cross-validation-techniques-d202dfe3edd4?source=collection_archive---------0-----------------------#2021-05-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/bc4d218eaf4b5b318bc2ba14ba99fa7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3VA_ek1UyDnL9kKaQ6vdPw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Source: <a class="ae it" href="https://unsplash.com/photos/zoCDWPuiRuA" rel="noopener ugc nofollow" target="_blank">Daria Nepriakhina On Unspalsh</a></figcaption></figure><p id="4050" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">机器学习模型通常无法很好地概括未经训练的数据。因此，总是需要验证你的机器学习模型的稳定性。这意味着我们需要确保模型的效率始终保持不变。换句话说，我们需要验证我们的模型在看不见的数据上表现得有多好。基于模型对未知数据的表现，我们可以说模型是过拟合、欠拟合还是良好泛化。</p><h2 id="6b9e" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">为什么模型会失去稳定性？</h2><p id="fad9" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">让我们用下图来理解:</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ks"><img src="../Images/7a91026641af1aafdf0d5f3550e2dcc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4dV-cNA9Ay4hc8lsLvZMJQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Source: AnalystPrep</figcaption></figure><ol class=""><li id="1206" class="kx ky hh iw b ix iy jb jc jf kz jj la jn lb jr lc ld le lf bi translated">第一个图，我们试图建立一个线性关系，这个关系不太符合数据。它与训练数据有很高的误差，这意味着我们的模型无法获得数据中的潜在模式，这意味着它也会在看不见的数据上表现不佳。这种情况被称为<strong class="iw hi">欠拟合</strong>，当一个模型在训练和测试数据集(验证数据或看不见的数据)上都表现不佳。</li><li id="e2db" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">在第二个图中，我们发现了恰到好处的关系，即具有低训练误差和良好概括的模型。</li><li id="2c0b" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">第三幅图，我们发现了一个零训练误差的关系。这意味着模型过于敏感，捕捉到了每一个微小的偏差，包括可能只存在于训练数据中的不必要的噪音。模型在训练数据上表现良好并推广到它，但在新的、看不见的数据上未能保持同样的效率，这种情况被称为<strong class="iw hi">过拟合</strong>。</li></ol><p id="c9e0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型开发中的一个常见做法是，在训练阶段，我们区分我们的模型是在提高其性能还是简单地过度拟合数据。为此，我们使用各种交叉验证技术。</p><h2 id="89bc" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">什么是交叉验证？</h2><p id="19fb" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">交叉验证的定义是:</p><blockquote class="lm ln lo"><p id="1d49" class="iu iv lg iw b ix iy iz ja jb jc jd je lp jg jh ji lq jk jl jm lr jo jp jq jr ha bi translated">交叉验证是一种评估模型性能的技术，通过在数据子集上训练几个模型，并在以前看不到的数据子集上测试它们。</p></blockquote><p id="798d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们也可以说，它是一种检查统计模型如何推广到独立数据集的技术。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/b833c3431e3dbd15a2af69ee073be3a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*hjrKBi6xQxPMf6_7mJV6Pg.gif"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Source: <a class="ae it" rel="noopener" href="/x8-the-ai-community/use-of-cross-validation-in-machine-learning-f3b80ad813e6">Rishi Sidhu</a></figcaption></figure><p id="b0a6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">它为给定的预测建模问题比较和选择模型，评估模型的性能。随后通过在新数据集上验证来判断他们的表现，也称为<strong class="iw hi">测试/验证数据集</strong></p><h2 id="87d3" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">为什么传统的坚守方式不成立？</h2><p id="1a54" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">拒绝是经典的“最简单的交叉验证”。在这种方法中，我们将数据随机分为两部分:训练集和测试/验证集，即保留集。然后，我们在训练数据集上训练模型，并在测试/验证数据集上评估模型。使用保留方法时，一个常见的划分是将80%的数据用于训练，其余20%的数据用于测试。</p><blockquote class="lm ln lo"><p id="b75d" class="iu iv lg iw b ix iy iz ja jb jc jd je lp jg jh ji lq jk jl jm lr jo jp jq jr ha bi translated">你不应该触摸测试设备</p></blockquote><p id="b6ed" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">随机拆分数据的问题是，大量原本可用于训练模型的数据丢失给了测试数据，导致我们的模型无法从有限的训练数据中有效学习。由于测试数据集中的数据可能完全不同，这导致了高方差导致的欠拟合。</p><p id="156b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">另一个问题是当我们有高度不平衡的数据集时。如果训练或测试数据集不能代表实际的完整数据，则测试集的结果可能会有偏差。</p><h2 id="27cf" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">交叉验证的常用技术:</h2><p id="9ab5" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">现在我们将看到一些常见的交叉验证技术。</p><h2 id="eb74" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak"> 1。验证集方法:</strong></h2><p id="b2e2" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">这种方法非常类似于坚持的方法。我们保留50%的数据集用于验证，剩下的50%用于训练模型。</p><p id="5093" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这种方法的主要缺点是，因为我们只在50%的可用数据上训练我们的模型，这导致拟合不足。</p><figure class="kt ku kv kw fd ii"><div class="bz dy l di"><div class="lt lu l"/></div></figure><h2 id="d48f" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">2.省略P交叉验证(LPOCV):</h2><p id="36c7" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">这种交叉验证方法将数据<code class="du lv lw lx ly b">P</code>点排除在训练数据之外，即如果原始样本中有<code class="du lv lw lx ly b">N</code>个数据点，则<code class="du lv lw lx ly b">N-P</code>样本用于训练模型，<code class="du lv lw lx ly b">P</code>点用作测试/验证集。</p><p id="792d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lg">这种方法计算量很大，因为它为</em> <code class="du lv lw lx ly b"><em class="lg">P</em></code> <em class="lg">的所有可能组合训练和验证模型，并且对于适度大的p，它在计算上可能变得不可行。</em></p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/53e34e9fac51bf95455c54bdece6ad88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*uap3Mg4ZdM6NDP6OnNaWoQ.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Source: neptune.ai</figcaption></figure><p id="8c0d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lg">计算成本较低的LPOCV情况是</em> <code class="du lv lw lx ly b"><em class="lg">P=1</em></code> <strong class="iw hi"> </strong>不会遭受密集计算的情况，因为可能组合的数量等于原始样本中数据点的数量或简单地等于<code class="du lv lw lx ly b">N</code>。这种方法被称为<strong class="iw hi">留一交叉验证(LOOCV)。</strong></p><p id="b983" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这种方法有一个缺点，如果我们训练的数据点被证明是一个异常值，我们的模型会受到数据点的很大影响，这就容易产生很大的差异。</p><h2 id="2c27" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">3.k倍交叉验证:</h2><p id="df22" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">到目前为止，显然永远没有足够的数据来训练模型<em class="lg">。</em> <strong class="iw hi"> <em class="lg">通过减少训练数据</em> </strong>、<strong class="iw hi"> <em class="lg">我们冒着丢失数据集中重要模式/趋势的风险，这反过来又增加了由偏差引起的误差。</em> </strong></p><p id="dc88" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，我们需要的是一种既能为模型训练提供充足数据，又能为验证留下充足数据的方法。K-Fold交叉验证正是这样做的。</p><p id="7fc7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">与所有其他技术相比，它提供了一个dias较低的模型。它易于实现，性能良好。涉及的步骤如下:</p><ol class=""><li id="d649" class="kx ky hh iw b ix iy jb jc jf kz jj la jn lb jr lc ld le lf bi translated">将整个数据集随机分成<code class="du lv lw lx ly b">k</code>个子集。</li><li id="28ba" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">对于每个k倍，在数据集的<code class="du lv lw lx ly b">k-1</code>子集上训练模型。然后在<code class="du lv lw lx ly b">kth</code>子集(测试集)上测试模型。</li><li id="d3af" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">记录每个预测的误差。</li><li id="0586" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">重复此操作，直到所有的<code class="du lv lw lx ly b">k</code>子集都被用作测试集，即我们迭代<code class="du lv lw lx ly b">k</code>子集，并记录每次迭代的误差。</li><li id="2fb3" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">对所有<code class="du lv lw lx ly b">k</code>试验的误差估计进行平均，以获得模型的总有效性/性能指标。</li></ol><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ma"><img src="../Images/eb9d37919bf905a70020688f29a0c380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8frCfJ7W8UwkasHo_BWSMA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Source: <a class="ae it" href="http://ethen8181.github.io/machine-learning/model_selection/model_selection.html" rel="noopener ugc nofollow" target="_blank">ethen8181</a></figcaption></figure><p id="b382" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，一个最常见的问题是，“如何选择<code class="du lv lw lx ly b">k</code>的正确值？”</p><p id="cef0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">永远记住，<code class="du lv lw lx ly b">k</code>的值越低，越有根据。因此不受欢迎。然而，<code class="du lv lw lx ly b">k</code>的值越高，偏差越小，但方差可能越大。较小的<code class="du lv lw lx ly b">k</code>值导致我们采用验证集方法，而较大的<code class="du lv lw lx ly b">k</code>值导致LOOCV方法。</p><blockquote class="lm ln lo"><p id="847f" class="iu iv lg iw b ix iy iz ja jb jc jd je lp jg jh ji lq jk jl jm lr jo jp jq jr ha bi translated">LOOCV无非是<code class="du lv lw lx ly b">n-fold</code>交叉验证，其中<code class="du lv lw lx ly b">k=n</code>，n是原始数据集中的样本总数。</p></blockquote><h2 id="48fa" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">4.简化的K倍交叉验证:</h2><p id="09df" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">分层K-Fold交叉验证是K-Fold交叉验证的扩展，其中数据集在分裂成<code class="du lv lw lx ly b">k</code>折叠数据之前被混洗，使得观察值的比率在所有折叠中保持相同。</p><p id="d9c4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在处理偏差和方差时，这通常是更好的方法。随机选择的折叠可能不足以代表次要类别，尤其是在不平衡数据集的情况下。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mb"><img src="../Images/aa7776c90fa4f176ad3cbf6f2d7b86ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F5iXU382lPrrV0XGyNBxyA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Source:<a class="ae it" href="https://dataaspirant.com/8-stratified-k-fold-cross-validation/" rel="noopener ugc nofollow" target="_blank"> Data Aspirant</a></figcaption></figure><h2 id="6829" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">关键要点:</h2><ol class=""><li id="4420" class="kx ky hh iw b ix kn jb ko jf mc jj md jn me jr lc ld le lf bi translated">k倍交叉验证是最常用的验证形式。</li><li id="f627" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">在大多数项目中，验证成为最关键的一步，因为它为现实世界准备了模型。</li><li id="ae0d" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">交叉验证是一种程序，用于减轻过度拟合，并根据新数据评估模型的技能。</li><li id="9ee3" class="kx ky hh iw b ix lh jb li jf lj jj lk jn ll jr lc ld le lf bi translated">总是建议在开始交叉验证模型之前进行详尽的<strong class="iw hi">探索性数据分析</strong>。</li></ol><p id="4bb7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我希望这篇文章能让你对不同的交叉验证技术有一个基本的了解。这是您开始使用令人惊叹的<strong class="iw hi"> Scikit-Learn </strong>库<strong class="iw hi"> </strong>进行交叉验证所需的所有基础知识，只需几行python代码就能让您上手并运行。祝你好运！</p><p id="1a57" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我将在我的下一篇文章中看到你。再见！</p><h2 id="e731" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">参考资料:</h2><p id="5780" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">[1]<a class="ae it" href="https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/</a></p><p id="c191" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[2]<a class="ae it" href="https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f" rel="noopener" target="_blank">https://towards data science . com/cross-validation-in-machine-learning-72924 a 69872 f</a></p><p id="5320" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[3]<a class="ae it" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/cross _ validation . html #交叉验证</a></p></div><div class="ab cl mf mg go mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ha hb hc hd he"><p id="6df0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢您的阅读，期待您的反馈！</p></div><div class="ab cl mf mg go mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ha hb hc hd he"><p id="847b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我每天写机器学习教程和文章，讲述我进入人工智能世界的旅程。在<a class="ae it" href="https://twitter.com/SindhuSeelam_" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae it" href="https://www.linkedin.com/in/sindhuseelam/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae it" href="https://sindhuseelam.medium.com/" rel="noopener"> Medium </a>上关注我。</p></div></div>    
</body>
</html>
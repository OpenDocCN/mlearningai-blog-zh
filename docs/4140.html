<html>
<head>
<title>Generative Adversarial Network (GAN) — SimpleGAN, DCGAN, WGAN, ProGAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络(GAN) —简单对抗网络、DCGAN、WGAN、程序对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/generative-adversarial-network-gan-simplegan-dcgan-wgan-progan-c92389a3c454?source=collection_archive---------3-----------------------#2022-12-14">https://medium.com/mlearning-ai/generative-adversarial-network-gan-simplegan-dcgan-wgan-progan-c92389a3c454?source=collection_archive---------3-----------------------#2022-12-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="e551" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">高级深度学习— Dnyanesh Walwadkar</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/6962993790b016f02b795e4a8de38907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q6Gmiqt0c4paaRjYbOBCfQ.png"/></div></div></figure><p id="ea17" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">内容:</p><ol class=""><li id="644e" class="ke kf hh jk b jl jm jo jp jr kg jv kh jz ki kd kj kk kl km bi translated">简单GAN</li><li id="34fe" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">衡量GAN中生成的样本质量的指标</li><li id="19ac" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">甘</li><li id="b450" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">亲甘</li><li id="8208" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">WGAN</li><li id="63f3" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">实施</li><li id="bbfa" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">甘综述</li><li id="b5c0" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">良好的研究工作从GAN开始</li></ol><p id="12ca" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">生成式对抗网络(GAN)是一种深度学习模型，旨在生成与训练数据集相似的新数据样本。该模型由两部分组成:学习生成新样本的生成模型，以及学习对给定样本是真是假进行分类的判别模型。</p><h1 id="959f" class="ks kt hh bd ku kv kw kx ky kz la lb lc in ld io le iq lf ir lg it lh iu li lj bi translated">简单根</h1><p id="5dbc" class="pw-post-body-paragraph ji jj hh jk b jl lk ii jn jo ll il jq jr lm jt ju jv ln jx jy jz lo kb kc kd ha bi translated">生成模型通常是一种神经网络，它接受随机噪声向量作为输入，并输出生成的样本。该模型被训练以通过试图欺骗判别模型来产生与训练数据相似的样本。</p><p id="1f43" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">另一方面，鉴别模型是一个分类器，它接收样本并输出它是真的还是假的。该模型被训练以正确地分类来自训练数据的真实样本以及由生成模型生成的虚假样本。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lp"><img src="../Images/819576f7cb87bf974420efb36894ee70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jrPKIia_YdHNNNVi.png"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx">src : <a class="ae lu" href="https://commons.wikimedia.org/wiki/File:A-Standard-GAN-and-b-conditional-GAN-architecturpn.png" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:A-Standard-GAN-and-b-conditional-GAN-architecturpn.png</a></figcaption></figure><p id="753f" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">训练GAN的目标是在两个模型之间找到平衡，其中生成模型产生高质量的样本，而判别模型不能区分真实和虚假的样本。这是通过使用对抗性损失函数来实现的，该函数测量生成的样本和真实样本之间的差异。</p><p id="5d38" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">训练GAN的过程可以数学地描述如下。设G是生成模型，D是鉴别模型，x是来自训练数据的真实样本，z是随机噪声向量。创成式模型的损失函数定义为:</p><p id="065d" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_G = E[log(1 — D(G(z)))]</p><p id="629a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">该损失函数促使生成模型产生被判别模型分类为真实的样本。判别模型的损失函数定义为:</p><p id="713b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">l _ D = E[log(D(x))]+E[log(1—D(G(z))]]</p><p id="2eee" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这个损失函数促使判别模型正确地将真实样本分类为真实样本，将虚假样本分类为虚假样本。GAN的总损耗定义为生成型和判别型模型的损耗之和:</p><p id="e87e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_GAN = L_G + L_D</p><p id="4a20" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">换句话说，GAN的总损失等于生成模型的损失加上判别模型的损失，生成模型促使模型产生被判别模型分类为真实的样本，判别模型促使模型正确地将真实样本分类为真实样本并将虚假样本分类为虚假样本。</p><div class="lv lw ez fb lx ly"><a href="https://github.com/dnyanshwalwadkar/Adv-Deep-Learning/blob/main/1.%20SimpleGAN/fc_gan.py" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">高级深度学习/fc _ gan . py at main dnyanshwalwadkar/高级深度学习</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">通过在GitHub上创建帐户，为dnyanshwalwadkar/Adv-深度学习开发做出贡献。</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">github.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm jg ly"/></div></div></a></div><h2 id="f5fc" class="mn kt hh bd ku mo mp mq ky mr ms mt lc jr mu mv le jv mw mx lg jz my mz li na bi translated">除了初始得分和弗雷歇初始距离之外，还有几个其他指标可用于测量GAN中生成的样本的质量。这些指标包括:</h2><ol class=""><li id="ce92" class="ke kf hh jk b jl lk jo ll jr nb jv nc jz nd kd kj kk kl km bi translated">Frechet距离:这个度量通过计算最适合样本的多元高斯分布之间的距离来测量两组样本x和y之间的相似性。弗雷歇距离定义为:</li></ol><p id="66a6" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">D_F(x，y)= | | m _ x—m _ y | |+tr(c _ x+c _ y—2(c_x^(1/2)c _ y c_x^(1/2))^(1/2))</p><p id="7d40" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">其中，m_x和m_y是分布的平均值，C_x和C_y是协方差矩阵，Tr是跟踪算子。</p><p id="35f3" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">2.Frechet初始距离(FID)是一种度量，用于测量预训练分类器的特征空间中真实样本和生成样本的分布之间的距离。FID的计算如下:</p><p id="bb1d" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">FID = | | mu _ r—mu _ g | |+Tr(Cov _ r+Cov _ g—2 * sqrt(Cov _ r * Cov _ g))</p><p id="275e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">其中mu_r和Cov_r是真实样本特征的均值和协方差，mu_g和Cov_g是生成样本特征的均值和协方差。</p><p id="75be" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">3.精确召回起始距离(PRID)是FID的一个变体，它包含一条精确召回曲线，以更好地捕捉生成样本的质量。PRID的计算方法如下:</p><p id="d75b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">优先级= (1 / n) * sum_{i=1}^n (2 *精度_i *召回_i /(精度_i +召回_i))</p><p id="85e1" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">其中precision_i和recall_i是精度-召回曲线上第I个点的精度和召回，n是曲线上的点数。</p><p id="65c6" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">4.核初始距离(KID)是一种度量，用于测量再生核希尔伯特空间中真实样本和生成样本的分布之间的距离。KID计算如下:</p><p id="0215" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">KID = ||K_r — K_g|| / (2 * sigma)</p><p id="6c3e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">其中，K_r和K_g分别是真实样本和生成样本的核矩阵，sigma是控制指标灵敏度的超参数。</p><p id="20c1" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这些度量可用于评估gan中生成的样本的质量，并在给定数据集上比较不同gan的性能。</p><h1 id="1915" class="ks kt hh bd ku kv kw kx ky kz la lb lc in ld io le iq lf ir lg it lh iu li lj bi translated">DCGAN</h1><p id="2bf1" class="pw-post-body-paragraph ji jj hh jk b jl lk ii jn jo ll il jq jr lm jt ju jv ln jx jy jz lo kb kc kd ha bi translated">DCGAN代表深度卷积生成对抗网络。它是一种GAN，在生成和鉴别模型中都使用卷积层。</p><p id="61bc" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在DCGAN中，生成模型G是深度卷积神经网络，它将随机噪声向量z作为输入，并输出合成图像。G的目标是产生与训练数据中的真实图像相似的合成图像。</p><p id="d483" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">判别模型D也是深度卷积神经网络，它将真实或合成的图像作为输入，并输出图像是真实的概率。D的目标是正确地将真实图像分类为真实的，将合成图像分类为假的。</p><p id="314c" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">DCGAN的总损失函数定义为G和d的损失函数之和，G的损失函数定义为:</p><p id="39f7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_G = E[log(1 — D(G(z)))]</p><p id="14d6" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这个损失函数鼓励G产生被d分类为真实的合成图像。换句话说，它鼓励G产生与训练数据中的真实图像相似的图像。</p><p id="3b77" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">D的损失函数定义为:</p><p id="00ae" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">l _ D = E[log(D(x))]+E[log(1—D(G(z))]]</p><p id="3bdb" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这个损失函数促使D正确地将真实图像分类为真实的，将合成图像分类为假的。换句话说，它鼓励D准确区分真假图像。</p><p id="6035" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">DCGAN的总损耗函数定义为:</p><p id="288e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_DCGAN = L_G + L_D</p><p id="ea6b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">通过使用梯度下降更新G和D的权重，在训练期间最小化该损失函数。通过最小化该损失函数，DCGAN学习生成与训练数据中的真实图像相似的高质量合成图像。</p><div class="lv lw ez fb lx ly"><a href="https://github.com/dnyanshwalwadkar/Adv-Deep-Learning/tree/main/2.%20DCGAN" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">adv-深度学习/2。DCGAN at main dnyanshwalwadkar/Adv-深度学习</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">github.com</p></div></div><div class="mh l"><div class="ne l mj mk ml mh mm jg ly"/></div></div></a></div><h2 id="46ac" class="mn kt hh bd ku mo mp mq ky mr ms mt lc jr mu mv le jv mw mx lg jz my mz li na bi translated">摘要SimpleGAN和DCGAN</h2><p id="f2c1" class="pw-post-body-paragraph ji jj hh jk b jl lk ii jn jo ll il jq jr lm jt ju jv ln jx jy jz lo kb kc kd ha bi translated">简单GAN和DCGAN的相似之处在于，它们都使用生成模型G和判别模型D来生成合成图像。然而，两者之间有一些关键的区别。</p><p id="b784" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">简单GAN通常在G和D中使用全连接层，而DCGAN使用卷积层。这意味着DCGAN能够捕捉数据中的空间相关性，从而提高生成图像的质量。</p><p id="bf73" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">此外，通常使用批量归一化和转置卷积层来训练DCGAN，这可以稳定训练过程并提高生成模型的性能。</p><p id="a2d3" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">总之，虽然简单GAN和DCGAN在整体结构和目标上相似，但DCGAN使用更先进的技术来提高生成图像的质量。</p><h1 id="15c3" class="ks kt hh bd ku kv kw kx ky kz la lb lc in ld io le iq lf ir lg it lh iu li lj bi translated">WGAN</h1><p id="e2b9" class="pw-post-body-paragraph ji jj hh jk b jl lk ii jn jo ll il jq jr lm jt ju jv ln jx jy jz lo kb kc kd ha bi translated">WGAN或Wasserstein GAN是一种使用Wasserstein距离作为其损失函数的GAN。Wasserstein距离是两个概率分布之间差异的度量。在WGAN中，生成模型G被训练以从合成分布中产生尽可能接近来自训练数据的真实样本的样本。</p><p id="1604" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">WGAN中生成模型的损失函数定义为:</p><p id="7d32" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_G = E[f(G(z))]</p><p id="4cbe" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">其中f(x)是衡量G产生的合成分布和真实分布之间的距离的临界函数。生成模型的目标是最小化该损失函数，这鼓励它生成与训练数据中的真实样本相似的样本。</p><p id="9c4e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_D = -E[f(x)] + E[f(G(z))]</p><p id="e248" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">判别模型的目标是最大化这个损失函数，这鼓励它正确地将真实样本分类为真实的，将合成样本分类为假的。</p><p id="436e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">WGAN的总损耗函数定义为:</p><p id="f195" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_WGAN = L_G + L_D</p><p id="0870" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">通过使用梯度下降更新G和D的权重，在训练期间最小化该损失函数。通过最小化该损失函数，WGAN学习生成与训练数据中的真实样本相似的高质量合成样本。</p><div class="lv lw ez fb lx ly"><a href="https://github.com/dnyanshwalwadkar/Adv-Deep-Learning/tree/main/3.%20WGAN" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">adv-深度学习/3。WGAN at main dnyanshwalwadkar/Adv-深度学习</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">github.com</p></div></div><div class="mh l"><div class="nf l mj mk ml mh mm jg ly"/></div></div></a></div><h2 id="6005" class="mn kt hh bd ku mo mp mq ky mr ms mt lc jr mu mv le jv mw mx lg jz my mz li na bi translated">WGAN研究使用</h2><p id="fbfa" class="pw-post-body-paragraph ji jj hh jk b jl lk ii jn jo ll il jq jr lm jt ju jv ln jx jy jz lo kb kc kd ha bi translated">有许多使用WGANs生成高质量合成数据的研究实例。例如，WGANs已经被用于生成与真实图像无法区分的人脸合成图像。这在许多领域都有应用，例如面部识别和安全。</p><p id="cb90" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">WGANs还被用于生成合成医学图像，例如CT扫描和磁共振成像。这对于训练用于诊断目的的机器学习模型是有用的。</p><p id="f964" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">另一个使用WGANs的研究例子是在音乐生成领域。WGANs已被用于生成在音色和节奏方面类似于真实音乐的合成音乐样本。</p><p id="60c9" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">总之，WGANs已被广泛用于研究领域，为各种应用生成高质量的合成数据。</p><h1 id="0e11" class="ks kt hh bd ku kv kw kx ky kz la lb lc in ld io le iq lf ir lg it lh iu li lj bi translated">ProGAN</h1><p id="f51b" class="pw-post-body-paragraph ji jj hh jk b jl lk ii jn jo ll il jq jr lm jt ju jv ln jx jy jz lo kb kc kd ha bi translated">渐进生长GAN(Prog an)是一种在训练期间逐渐增加所生成图像的分辨率的GAN。这允许模型产生高分辨率图像，而不需要大量的训练样本或计算昂贵的模型。</p><p id="bd24" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">ProGAN遵循一种分级方法来训练GAN。最初，模型被训练以生成低分辨率图像。然后，将附加层添加到模型中，并在同一数据集上再次训练模型，以生成更高分辨率的图像。重复这个过程，直到达到所需的分辨率。</p><p id="b0a7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">数学上，假设G是生成模型，D是鉴别模型，x是来自训练数据的真实样本，z是随机噪声向量。创成式模型的损失函数定义为:</p><p id="75b8" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_G = E[log(1 — D(G(z)))]</p><p id="13b4" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">该损失函数促使生成模型产生被判别模型分类为真实的样本。判别模型的损失函数定义为:</p><p id="f78e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">l _ D = E[log(D(x))]+E[log(1—D(G(z))]]</p><p id="1f59" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这个损失函数促使判别模型正确地将真实样本分类为真实样本，将虚假样本分类为虚假样本。程序的总损失定义为生成模型和判别模型的损失之和:</p><p id="60d1" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">L_ProGAN = L_G + L_D</p><p id="3636" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">换句话说，程序的总损失等于生成模型的损失，生成模型鼓励模型产生被判别模型分类为真实的样本，加上判别模型的损失，判别模型鼓励模型正确地将真实样本分类为真实，将虚假样本分类为虚假。</p><h2 id="de02" class="mn kt hh bd ku mo mp mq ky mr ms mt lc jr mu mv le jv mw mx lg jz my mz li na bi translated">有几个关于GANs的重要事实需要理解:</h2><ol class=""><li id="e399" class="ke kf hh jk b jl lk jo ll jr nb jv nc jz nd kd kj kk kl km bi translated">gan是一种生成模型，这意味着它们能够生成与训练数据相似的新样本。</li><li id="10db" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs由两部分组成:一个生成模型，它生成假样本；一个判别模型，它试图区分真样本和假样本。</li><li id="f6fd" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">使用两部分损失函数来训练gan，该函数鼓励生成模型产生被判别模型分类为真实的样本，并且判别模型正确地分类真实和虚假样本。</li><li id="4643" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs可用于生成各种输出，包括图像、文本和音频。</li><li id="2942" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs是机器学习中的一种流行技术，已经被用于在许多应用中实现最先进的结果。然而，它们可能很难训练，并且需要大量的计算能力。</li><li id="8af1" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs是机器学习领域相对较新的发展，于2014年首次推出。</li><li id="3e2f" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">gan是一种无监督学习的形式，这意味着它们可以从数据中学习，而不需要标签或预定义的类别。</li><li id="15ab" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">训练GANs的主要挑战之一是平衡生成模型和判别模型的竞争目标。</li><li id="e185" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">尽管他们取得了成功，甘也不是没有限制。例如，它们可能很难训练，并且需要大量的数据和计算能力。此外，GANs的输出有时很难解释或控制。</li><li id="4d89" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs已被证明在多种应用中是有效的，包括图像生成、图像超分辨率、图像平移和图像修复。</li><li id="91aa" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GAN的最新进展包括新架构的开发，如剩余连接和批量标准化的使用，以及新训练技术的使用，如Wasserstein GAN和改进的GAN。</li><li id="5e84" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs已经被应用于广泛的领域，包括计算机视觉、自然语言处理和语音合成。</li><li id="d491" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">GANs也已经与其他机器学习技术结合使用，例如强化学习和迁移学习，以实现改进的性能。</li><li id="77cd" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">最近的一些研究侧重于改善GAN的可解释性和控制，以及解决与GAN生成的输出的偏差和公平性相关的问题。</li></ol><p id="a6d9" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">GAN实现</p><div class="lv lw ez fb lx ly"><a href="https://github.com/dnyanshwalwadkar/Adv-Deep-Learning" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">GitHub-dnyanshwalwadkar/Adv-深度学习</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">github.com</p></div></div><div class="mh l"><div class="ng l mj mk ml mh mm jg ly"/></div></div></a></div><h2 id="a0cb" class="mn kt hh bd ku mo mp mq ky mr ms mt lc jr mu mv le jv mw mx lg jz my mz li na bi translated">以下一些研究论文很好地介绍了GANs:</h2><ol class=""><li id="f314" class="ke kf hh jk b jl lk jo ll jr nb jv nc jz nd kd kj kk kl km bi translated">伊恩·古德菲勒等人的“生成性敌对网络”(2014年)</li><li id="8878" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">马丁·阿约夫斯基等人的《瓦瑟斯坦·甘》(2017年)</li><li id="0e57" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">Tim Salimans等人的“训练GANs的改进技术”(2016年)</li><li id="8c8f" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">亚历克·拉德福德等人(2015年)“深度卷积生成对抗网络的无监督表示学习”</li><li id="c53a" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">Meera Mohan等人的“条件生成对抗网络”(2015年)</li></ol><p id="7e57" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">此外，以下综述性论文对GAN研究的最新发展水平进行了很好的概述:</p><ol class=""><li id="eae2" class="ke kf hh jk b jl jm jo jp jr kg jv kh jz ki kd kj kk kl km bi translated">Shubham Tulsiani等人的“生成性敌对网络:概述”(2018年)</li><li id="831a" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">张子琪等人(2018)的“关于生成性对抗网络的调查”</li><li id="62ab" class="ke kf hh jk b jl kn jo ko jr kp jv kq jz kr kd kj kk kl km bi translated">Martin Arjovsky等人(2017年)的“生成性对抗网络训练的原则性方法”</li></ol><p id="8271" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这些论文为理解GANs的基础知识和该领域的最新发展提供了一个很好的起点。</p><div class="lv lw ez fb lx ly"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">medium.com</p></div></div><div class="mh l"><div class="nh l mj mk ml mh mm jg ly"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>“Toward GPU Utilization Prediction for Cloud Deep Learning” summary</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“面向云深度学习的GPU利用率预测”摘要</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/toward-gpu-utilization-prediction-for-cloud-deep-learning-3572d931be14?source=collection_archive---------2-----------------------#2022-05-10">https://medium.com/mlearning-ai/toward-gpu-utilization-prediction-for-cloud-deep-learning-3572d931be14?source=collection_archive---------2-----------------------#2022-05-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="47aa" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="aade" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">深度学习已经对许多计算领域产生了重大影响。这些工作负载需要很高的计算/内存要求。图形处理单元(GPU)是促进其执行的主要加速器。当前的挑战是集群上这些处理器的利用不足。这是由于GPU缺乏精细共享能力和虚拟内存，以及资源管理器和调度器采用的策略。为了提高GPU的利用率，想到的第一个解决方案是过度配置GPU。然而，硬件资源干扰会导致过度供应方法的性能降低。因此，在线分析是监控系统的一种常见解决方案。但是，这种方法<strong class="je hi">降低了资源可用性</strong>。Yeung等人[ <strong class="je hi"> 1 </strong>提出的机制使用机器学习模型来预测深度学习模型对GPU的利用。他们使用来自模型计算图的信息。他们的评估显示，与Kubernetes等基于插槽的调度程序和一个间隔为一分钟的在线分析机制相比，<strong class="je hi">的GPU集群利用率为61.5% </strong>而<strong class="je hi">为47.1% </strong>。</p><h1 id="710f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">拟议机制</h1><p id="bad8" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">建议的利用率估计器引擎位于集群队列和提交门户之间，如下图所示。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/bf94c1dbf025a4426bd26efe70d807d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*12RpD5XzIlgPaJ1eqF0iGA.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">Proposed GPU utilization prediction engine deployed within a cloud resource manager [<strong class="bd ig">1</strong>]</figcaption></figure><p id="0221" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">他们用不同的模型和数据集做实验，研究深度学习工作负载特征和GPU利用率之间的关系。下表显示了他们在不同配置下使用的模型，包括小批量大小、隐藏维度以及执行和构建数据集的层数，以学习和构建他们的估计器模型。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es kv"><img src="../Images/d4d2a39f09244e88e757a90108eff678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ny8MpjsoSw4NL4QGAzBgWQ.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="9a1d" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">作者在各种深度学习模型的训练下，对GPU的利用做了一个研究。下图显示了不同型号之间的利用率差异。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kw"><img src="../Images/1bb6820073e400c927d60ae45e88b244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*NHKzVoZLgXEAeRm-o18qsA.png"/></div><figcaption class="km kn et er es ko kp bd b be z dx">GPU utilization per model</figcaption></figure><p id="f44d" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">预测引擎遍历模型，并根据其输入、输出形状和参数[ <strong class="je hi"> 1 </strong> ]计算每个操作的FLOPs。例如，FLOPs中的标准矩阵乘法计算如下:</p><blockquote class="kx ky kz"><p id="faae" class="jc jd la je b jf kq jh ji jj kr jl jm lb ks jp jq lc kt jt ju ld ku jx jy jz ha bi translated"><strong class="je hi">输入形状*输出形状*批量</strong></p></blockquote><p id="885a" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">对于LSTM细胞，他们用两个线性层建模，因为LSTM细胞在细胞权重和输入(如输入嵌入和隐藏状态)之间执行矩阵乘法。一旦输入被分成门，门计算可以被建模为激活。它们显示了FLOPs和GPU利用率之间的关系，如下图所示:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es le"><img src="../Images/ff1a6aea928ea9b5451fb20d761c1af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*9dok7lUtZrJRxeSa9FOXhA.png"/></div><figcaption class="km kn et er es ko kp bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><p id="683c" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">下表列出了用于模型训练的所有功能:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lf"><img src="../Images/bbbfd61593388048f11783359e14ee74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*axDzSI8B0882sG9wXgmhsg.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><h2 id="cffb" class="lg if hh bd ig lh li lj ik lk ll lm io jn ln lo is jr lp lq iw jv lr ls ja lt bi translated">模特培训</h2><p id="514a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">总共81个样本被分成80%-20%用于训练和测试。他们用不同的回归模型进行测试，最终选择了随机森林[ <strong class="je hi"> 2 </strong>，因为它提供了最小的均方根对数误差(<strong class="je hi">RM LSE</strong>)0.154。</p><h2 id="0f0f" class="lg if hh bd ig lh li lj ik lk ll lm io jn ln lo is jr lp lq iw jv lr ls ja lt bi translated">估价</h2><p id="40b7" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">评估证明了增加的作业完成时间(<strong class="je hi"> JCT </strong>)，如前面的[ <strong class="je hi"> 3 </strong> ]所示。是因为GPU资源过度分配。下图显示了JCT和GPU利用率之间的相关性。然而，在配置调度中，利用率估计可用于作业的明智配置，并在管理性能开销的情况下提高利用率。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lu"><img src="../Images/9e2adde3b8c9556ab6319924502ca595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rilazdfEnJNEsMdfn1zkaQ.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><p id="2274" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">重要的是，作者建议的以下选项可以添加到该方法中以获得更好的结果:</p><ol class=""><li id="8b3a" class="lv lw hh je b jf kq jj kr jn lx jr ly jv lz jz ma mb mc md bi translated"><strong class="je hi">通过添加更多配置和更多模型来扩大数据集，如甘、</strong></li><li id="c711" class="lv lw hh je b jf me jj mf jn mg jr mh jv mi jz ma mb mc md bi translated"><strong class="je hi">将其推广到其他处理器，如FPGAs和加速器</strong></li><li id="8444" class="lv lw hh je b jf me jj mf jn mg jr mh jv mi jz ma mb mc md bi translated"><strong class="je hi">考虑TVM这样的深度学习编译器</strong>。就其重要性而言，例如，当执行卷积时，<strong class="je hi"> cuDNN </strong>为后面的配置选择最佳算法。了解这些决策将提高预测器的准确性。</li><li id="a318" class="lv lw hh je b jf me jj mf jn mg jr mh jv mi jz ma mb mc md bi translated"><strong class="je hi">考虑分布式培训</strong></li><li id="d96e" class="lv lw hh je b jf me jj mf jn mg jr mh jv mi jz ma mb mc md bi translated"><strong class="je hi">更智能的搭配调度策略</strong></li></ol><h2 id="a4e5" class="lg if hh bd ig lh li lj ik lk ll lm io jn ln lo is jr lp lq iw jv lr ls ja lt bi translated"><strong class="ak">结论</strong></h2><p id="26b9" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">GPU配置是解决GPU利用不足问题的常见解决方案之一。Yeung等人提出的机制根据模型的高层信息来估计GPU利用率，这些信息是从模型的计算图中获得的。这些信息可用于通过配置作业来提高GPU集群的利用率。但是，性能下降(完成时间增加)是该解决方案的伴随挑战，因为它考虑了非常高的利用率指标。</p><h1 id="40c9" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="0fa1" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">【<strong class="je hi">1</strong>】Yeung，Gingfung，等.<strong class="je hi">面向云深度学习的GPU利用率预测。</strong><em class="la">第十二届云计算热点话题USENIX研讨会(HotCloud 20) </em>。<strong class="je hi"> 2020 </strong>。</p><p id="6834" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated">[ <strong class="je hi"> 2 </strong> ] " <strong class="je hi">随机森林回归</strong>，链接:<a class="ae mj" href="https://bit.ly/37zUSj4" rel="noopener ugc nofollow" target="_blank">https://bit.ly/37zUSj4</a>，访问时间:10–05–2022</p><p id="eb05" class="pw-post-body-paragraph jc jd hh je b jf kq jh ji jj kr jl jm jn ks jp jq jr kt jt ju jv ku jx jy jz ha bi translated"><strong class="je hi"> 3 </strong>】肖，，等.<strong class="je hi"> Gandiva:深度学习的内省式集群调度。</strong><em class="la">第十三届USENIX操作系统设计与实现研讨会(OSDI 18) </em>。<strong class="je hi"> 2018 </strong>。</p><div class="mk ml ez fb mm mn"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mo ab dw"><div class="mp ab mq cl cj mr"><h2 class="bd hi fi z dy ms ea eb mt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mu l"><h3 class="bd b fi z dy ms ea eb mt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mv l"><p class="bd b fp z dy ms ea eb mt ed ef dx translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb kk mn"/></div></div></a></div></div></div>    
</body>
</html>
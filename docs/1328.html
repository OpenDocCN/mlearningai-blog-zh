<html>
<head>
<title>Bird Sound Calssification Using FastAudio (FastAi)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用FastAudio (FastAi)进行鸟声分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/bird-sound-calssification-using-fastaudio-fastai-49eea9b5953a?source=collection_archive---------0-----------------------#2021-11-23">https://medium.com/mlearning-ai/bird-sound-calssification-using-fastaudio-fastai-49eea9b5953a?source=collection_archive---------0-----------------------#2021-11-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="337e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">使用公共鸟类歌曲数据库和FastAudio(用于<em class="jc"> FastAi Python API的</em> n音频模块)来创建基于声音的深度学习鸟类分类器</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/e4b0dd9812551e132166e8cd5f98de61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*DR7JSI8WZeO5syYPfMSF6w.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Yellow-olive Flatbill. Source: <a class="ae jp" href="https://en.wikipedia.org/wiki/Yellow-olive_flatbill" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Yellow-olive_flatbill</a></figcaption></figure><p id="48df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">互联网上有几个例子可以说明如何使用<a class="ae jp" href="https://docs.fast.ai/" rel="noopener ugc nofollow" target="_blank"> FastAi </a> API来训练深度学习，以执行广泛的任务。正如我们所见，FastAi可以用于创建<a class="ae jp" href="https://www.kaggle.com/arunasna/liver-segmentation-with-fastai-v2" rel="noopener ugc nofollow" target="_blank">分割模型</a>、<a class="ae jp" href="https://towardsdatascience.com/deep-learning-image-classification-with-fast-ai-fc4dc9052106" rel="noopener" target="_blank">图像分类器</a>和<a class="ae jp" href="https://walkwithfastai.com/Audio" rel="noopener ugc nofollow" target="_blank">语音识别</a>算法。</p><p id="92fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，找到关于执行除语音识别之外的任务的音频分类模型的内容并不容易。此外，在互联网上找到的大多数例子使用为用于机器学习训练而创建的参数化数据集。</p><p id="c36d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">考虑到所有这些，我决定发表这篇文章，以展示如何使用公共协作数据集中的真实世界数据来训练深度学习音频分类器。在这个例子中，我使用了<a class="ae jp" href="https://fastaudio.github.io/" rel="noopener ugc nofollow" target="_blank">fast audio</a>(FastAi Python API的一个模块)和<a class="ae jp" href="https://www.xeno-canto.org/" rel="noopener ugc nofollow" target="_blank"> xeno-canto </a>数据库来创建一个模型，该模型可以根据鸟类独特的歌声对它们进行分类。</p><p id="4dd8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里有一个包含代码的github库<a class="ae jp" href="https://github.com/ffreller/BirdShazam" rel="noopener ugc nofollow" target="_blank"/></p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><h1 id="65b6" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">要求</h1><p id="4912" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">这些是我们将在这个项目中使用的所有库</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="0667" class="lf jy hh lb b fi lg lh l li lj">!pip install fastaudio<br/>!pip install pandas<br/>!conda install -c conda-forge ffmpeg<br/>## I had problems installing ffmpeg via pip<br/>!pip install pydub<br/>!pip install scikit-learn</span></pre><h1 id="74b0" class="jx jy hh bd jz ka lk kc kd ke ll kg kh ki lm kk kl km ln ko kp kq lo ks kt ku bi translated">下载文件并创建数据集</h1><p id="1297" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">在创建和训练我们的模型之前，我们需要下载鸟鸣的音频文件，并组织一个可以在以后使用的数据集。</p><p id="f8b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要放弃使用xeno-canto API来找出他们的数据库中有哪些可用的内容。在我的例子中，我将搜索限制在巴西制造的录音，但是您可以通过在下面的脚本中更改<strong class="ig hi"> <em class="jc"> country </em> </strong>变量来改变这一点:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="c85d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们需要选择要下载的文件。我决定下载《物种》中超过100个音频样本的所有文件。在将数据集限制为具有100多个样本的物种后，我最终得到了108种不同鸟类的14470个音频文件。用于过滤文件并下载它们的代码如下:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="a819" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下载所有的音频文件需要几个小时。为了加快这个过程，你可以将数据集重新划分为10个最常见的物种。如果您喜欢这样做，请将<code class="du lr ls lt lb b">downloader.py</code>的第13行改为<code class="du lr ls lt lb b">chosen = counts.head(10).index</code></p><p id="632a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我将在下面展示的结果是通过对前10个物种的音频文件进行分类获得的，即:<em class="jc">红腹鸫、黄橄榄扁嘴鸫、红眉胡椒伯劳、橄榄丘鹬、浅喉丘鹬、蓝海牛、长嘴鹪鹩、金冠莺、浅胸鸫、小丘鹬</em>。总共使用了2145段录音。</p><h1 id="1ad8" class="jx jy hh bd jz ka lk kc kd ke ll kg kh ki lm kk kl km ln ko kp kq lo ks kt ku bi translated">准备文件</h1><p id="6a14" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">接下来，我从我的数据集中删除没有下载的文件，并把剩下的10%按物种分类，用作测试集。</p><p id="bc18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我还创建了一个函数，将所有不同的mp3文件转换成一个16 kHz的wav文件，这将使它们更容易加载到模型中。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="fc29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们在<code class="du lr ls lt lb b">wav_files/train/</code>中有了所有的训练(和验证)文件，在<code class="du lr ls lt lb b">wav_files/test/</code>中有了我们的测试文件。</p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><h1 id="eec2" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">数据块和数据加载器准备</h1><p id="9838" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">让我们加载我们的数据集，存储在<code class="du lr ls lt lb b">downloaded.csv</code>并再次分离它们。(您也可以使用我们最近创建的dataframes进行训练和测试)。</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="c22b" class="lf jy hh lb b fi lg lh l li lj">downloaded = pd.read_csv('downloaded.csv')<br/>downloaded['filename'] = downloaded['filename'].str[:-4] + '.wav'<br/>downloaded.columns = ['filename', 'category']</span><span id="e9c2" class="lf jy hh lb b fi lu lh l li lj">train_files = listdir('wav_files/train')<br/>test_files = listdir('wav_files/test')</span><span id="ccbd" class="lf jy hh lb b fi lu lh l li lj">df = downloaded[downloaded['filename'].isin(train_files)]<br/>df_test = downloaded[downloaded['filename'].isin(test_files)]</span><span id="1f9a" class="lf jy hh lb b fi lu lh l li lj">print(df.shape)<br/>print(df_test.shape)</span></pre><p id="a2fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们加载fastaudio组件并创建一个音频到声谱图的转换。</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="8be3" class="lf jy hh lb b fi lg lh l li lj">from fastai.vision.all import *<br/>from fastaudio.core.all import *<br/>from fastaudio.augment.all import *<br/>from fastaudio.ci import skip_if_ci</span><span id="2150" class="lf jy hh lb b fi lu lh l li lj">path = Path('.')</span><span id="4c37" class="lf jy hh lb b fi lu lh l li lj">seconds = 15<br/>cfg = AudioConfig.BasicMelSpectrogram(n_fft=512)<br/>a2s = AudioToSpec.from_cfg(cfg)<br/>item_transforms = a2s</span></pre><p id="6335" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以创建我们的数据块了。由于我们的数据集中有不同长度的文件，AudioBlock会将信号裁剪为15，000毫秒</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="b33e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将它加载到数据加载器后，我们可以看一下我们的批处理:</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="55e8" class="lf jy hh lb b fi lg lh l li lj">batch_size = 64<br/>dbunch = auds.dataloaders(df, bs=batch_size, shuffle=False)<br/>dbunch.show_batch(figsize=(20, 8), nrows=2, ncols=3)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lv"><img src="../Images/6fa2aa868f0aaba3860c8e087fea13d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dSgR_p9xVtks_rBkFT5lVw.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Result of dbunch.show_batch</figcaption></figure></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><h1 id="8744" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">创建和训练模型</h1><p id="be63" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">现在我们可以实例化我们的模型了。我们将使用预训练的resnet34架构和CrossEntropyLossFlat作为我们的损失函数</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="f3fa" class="lf jy hh lb b fi lg lh l li lj">model_type = resnet34<br/>learn = cnn_learner(dbunch, <br/>                    model_type,<br/>                    n_in=1,<br/>                    loss_func=CrossEntropyLossFlat(),<br/>                    metrics=[accuracy])</span></pre><p id="88d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在可以使用lr_find方法来找到我们的理想学习率</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="6dd5" class="lf jy hh lb b fi lg lh l li lj">lr = learn.lr_find()[0]/10<br/>print(lr)</span></pre><p id="b036" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后我们将训练我们的模型。我们计划了20个时期，但是由于我们使用的是EarlyStoppingCallback，如果4个时期没有改善，模型就会停止。</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="f233" class="lf jy hh lb b fi lg lh l li lj">callbacks = [SaveModelCallback(),<br/>ReduceLROnPlateau(monitor='valid_loss', min_delta=0.1, patience=2), EarlyStoppingCallback(monitor='valid_loss', min_delta=0.05, patience=4)]</span><span id="aa24" class="lf jy hh lb b fi lu lh l li lj">learn.fine_tune(20, wd=0.1, base_lr=lr, cbs=callbacks)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/b2c19b12373dd3d9c0ce0d9d860b9edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*EFZAo9gYd7bSOsEzJKQY_w.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Epochs log</figcaption></figure><p id="c57d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在13个时期中，我们在验证集中达到了80.05%的准确率。模型在第17个时期后停止，因为验证损失在连续4个时期没有减少。</p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><h1 id="b4fa" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">模型评估</h1><p id="fca4" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">我们可以用show_results函数查看一些结果</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="9f27" class="lf jy hh lb b fi lg lh l li lj">learn.show_results()</span></pre><div class="je jf jg jh fd ab cb"><figure class="mb ji mc md me mf mg paragraph-image"><img src="../Images/3d09dfe0aef336c86309c7e19ee7ce13.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*FPCI-2O6vrtNEMsedMDpMA.png"/></figure><figure class="mb ji mh md me mf mg paragraph-image"><img src="../Images/a3c461c92c1450a4f4f42f102d18b4a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*w0aiw1u0uHgfCjQIr4lqRg.png"/><figcaption class="jl jm et er es jn jo bd b be z dx mi di mj mk">One example where the model fails (left) and another where it gets the result right (right)</figcaption></figure></div><p id="c754" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还可以检查混淆矩阵和模型产生的最常见错误。</p><pre class="je jf jg jh fd la lb lc ld aw le bi"><span id="dabe" class="lf jy hh lb b fi lg lh l li lj">interp = ClassificationInterpretation.from_learner(learn)<br/>interp.plot_confusion_matrix(figsize=(12,12), dpi=60)<br/>interp.most_confused()[:10]</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ml"><img src="../Images/357bbb8e742998bbce275e62c917250d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*4nRi1ipKYrNlZMp4_OWnoA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Most common errors</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mm"><img src="../Images/30eb2165e8da007a730f09704e101a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CoOP0YEIrY6HplN95XcSlA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Confusion matrix</figcaption></figure><h1 id="53cc" class="jx jy hh bd jz ka lk kc kd ke ll kg kh ki lm kk kl km ln ko kp kq lo ks kt ku bi translated">用新数据测试模型</h1><p id="02f2" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">现在我们可以用我们的测试数据集来测试我们的模型。让我们将它加载到一个新的数据加载器中，并检查模型预测新的未知数据的准确性。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="eaa1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在测试集中，模型达到了76%的准确率。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mn"><img src="../Images/c31b3269cdfbb5c1c461b640c79f5131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eG6jwod8Ul77b0QoZkJwgQ.png"/></div></div></figure><h1 id="2a97" class="jx jy hh bd jz ka lk kc kd ke ll kg kh ki lm kk kl km ln ko kp kq lo ks kt ku bi translated">结论</h1><p id="ea8a" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">通过几个时期，我们能够使用鸟鸣建立一个相当好的分类模型！</p><p id="e586" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">非常感谢您的阅读。如果您有任何改进代码和/或模型的建议，请告诉我。</p><p id="c147" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在f.freller@gmail.com联系我</p><div class="mo mp ez fb mq mr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hi fi z dy mw ea eb mx ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">medium.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf jj mr"/></div></div></a></div></div></div>    
</body>
</html>
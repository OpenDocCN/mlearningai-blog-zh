<html>
<head>
<title>What is the best clustering in my data when labels are unknown ?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当标签未知时，我的数据中的最佳聚类是什么？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/what-is-the-best-clustering-in-my-data-when-labels-are-unknown-64d2cd99dd6c?source=collection_archive---------1-----------------------#2021-03-10">https://medium.com/mlearning-ai/what-is-the-best-clustering-in-my-data-when-labels-are-unknown-64d2cd99dd6c?source=collection_archive---------1-----------------------#2021-03-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="fab4" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用轮廓分数的KMeans最佳聚类</h1><p id="72ae" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">无监督学习:在带有未知标签的数据中的最佳分割。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/96baad4e88e501bf8accfacf08b3b0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tZOKqawtaaoSLpmOkEvVRw.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">Ethereal clusters (photo by <a class="ae kq" href="https://unsplash.com/@splashabout" rel="noopener ugc nofollow" target="_blank">Nareeta Martin </a>on <a class="ae kq" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="cff5" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">想象一下，你有数百万个未标记的数据要探索，每个数据都由一个向量表示，所有这些向量都分组到一个矩阵或表格中，数据的数量和种类越多，你就越能捕捉到你试图描述的现象，如客户类别、机器状态或疾病的不同状态。在您的情况下，您不知道在您处理的数据中表示了多少个州或类，因为它们没有被标记，并且您没有业务专家来手动标记数百万个数据。你只知道标签的数量大于或等于2，换句话说，你必须解决一个无监督的分类问题，然后回答这样的问题:我的机器有多少种不同的状态？…我个人在真实用例中已经遇到过这种情况。</p><p id="c5d7" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">在本文中，为了简单和保密起见，我将生成数据，并尝试通过下面我将与您分享的Python代码片段找到原始聚类。</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><p id="9124" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">在本文中，我们将使用度量<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">剪影系数得分</strong> </a> <strong class="je hi"> </strong>，它计算数据集中所有示例的<a class="ae kq" href="http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient" rel="noopener ugc nofollow" target="_blank"><strong class="je hi"/></a>的<strong class="je hi">平均值</strong>。</p><p id="d9e2" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">事实上，当“基本事实”或标签未知时，我们需要使用模型本身来评估不同的聚类。<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">轮廓系数得分</strong> </a>是一个允许进行这种评估的指标。</p><p id="46d5" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">高<strong class="je hi">轮廓系数分数</strong> - <strong class="je hi">接近1 </strong> -与具有更好定义的<strong class="je hi">聚类</strong>的模型相关。这里，我们将使用<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi"> Kmeans </strong> </a> <strong class="je hi">实现Scikit-learn。</strong></p><p id="5320" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated"><strong class="je hi">轮廓系数</strong>是为每个样本定义的，由两个分数组成:</p><p id="0202" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated"><strong class="je hi"> a </strong>:一个样本与同一类中所有其他点之间的平均距离。</p><p id="910b" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated"><strong class="je hi"> b: </strong>一个样本与下一个最近的聚类中所有其他点之间的平均距离。</p><p id="7f39" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">单个样本的<strong class="je hi">轮廓系数s </strong>为:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ld"><img src="../Images/224ccae314bad4530c09a941bd294ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*gYuxH-ZKLse1htDXFh6ycQ.jpeg"/></div></figure><h1 id="51f4" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">1-导入一些有用的模块</h1><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="le lf l"/></div></figure><h1 id="a045" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">2-使用来自3种不同分布的变量生成数据集</h1><p id="59fe" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">为了简单起见，我们将生成3个数据集，每个数据集只有一个变量。但显然，第三部分中的代码旨在用于多元数据集。</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="le lf l"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lg"><img src="../Images/a357bc44bfa92ac01c84da9fa7c404c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z8S7fmsxHpFgSc4UK9kTFg.jpeg"/></div></div></figure><p id="18fb" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">现在让我们对数据进行分组和洗牌:</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="le lf l"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lh"><img src="../Images/7eb908eb2081420592829dd125c95a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*5NfKL_NS6YtxeEM6nrCAvQ.jpeg"/></div></figure><p id="d74f" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">在本文中，我们使用一个包含3000个示例和一个变量的人造数据集，当然，在现实世界中，我们会遇到包含数百万行的多元数据集，然后我们可能需要对初始样本进行子采样以缩短计算时间。子样本必须能代表原始样本总体。</p><h1 id="6ae6" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">3-编写一个利用silhouette_score度量的函数</h1><p id="1e42" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> <em class="li">该函数将帮助您评估带有未知标签的数据的最佳分割，同时也将为您提供一个带标签的数据集。</em> </strong></p><p id="3571" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">当变量的取值范围不同时，这会对算法的性能产生负面影响。这就是为什么我们需要将数据缩放作为预处理步骤的一部分。<br/>决策树和随机森林是少数几种我们不需要担心特征缩放的机器学习算法。这些算法是尺度不变的。重新缩放对于梯度下降等机器学习算法核心中使用的优化算法非常有用，对于回归和神经网络等加权输入的算法以及使用K-最近邻或<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi"> K-Means </strong> </a>等距离度量的算法也非常有用。我们可以使用例如scikit的<code class="du lj lk ll lm b"><a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank">MinMaxScaler</a></code>类来重新调整我们的数据。在下面的函数中，我们将参数“scaling”设置为True，以防我们想要缩放数据。注意，因为我们的数据是单变量的，所以我们不需要将这个参数设置为True。</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="le lf l"/></div></figure><h1 id="ff1b" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">4 —我的数据的最佳聚类是什么？</h1><p id="2ae4" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们现在将使用我在上面写的函数来评估我的数据中的最佳聚类。</p><ul class=""><li id="4907" class="ln lo hh je b jf kr jj ks jn lp jr lq jv lr jz ls lt lu lv bi translated"><strong class="je hi">最佳聚类的可视化:</strong></li></ul><pre class="kb kc kd ke fd lw lm lx ly aw lz bi"><span id="b871" class="ma if hh lm b fi mb mc l md me"># We don't need to scale the data since we only have one variable<br/>Best_Clustering(data = data, scaling = False)</span></pre><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es mf"><img src="../Images/1de6d76d9895ba93a9cb8e4d64823dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kpk_6C7flzakrgFF5GxasQ.jpeg"/></div></div></figure><ul class=""><li id="66f2" class="ln lo hh je b jf kr jj ks jn lp jr lq jv lr jz ls lt lu lv bi translated"><strong class="je hi">获取最佳参数和我标记的数据，以便我们以后使用:</strong></li></ul><pre class="kb kc kd ke fd lw lm lx ly aw lz bi"><span id="8444" class="ma if hh lm b fi mb mc l md me">best_params , my_labeled_data = Best_Clustering(data = data, scaling = False, visualization = False)<br/>best_params</span></pre><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es mg"><img src="../Images/060c325f7817f88f6e91e4c39dda3273.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*4RHSD3R12-lJF-OTKRTuLg.jpeg"/></div></figure><pre class="kb kc kd ke fd lw lm lx ly aw lz bi"><span id="3a07" class="ma if hh lm b fi mb mc l md me">my_labeled_data</span></pre><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es mh"><img src="../Images/9c5a565b47f48873e611c0ebeaa369c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*DXLiS2hobQfBUVrF8k6mow.jpeg"/></div></figure><p id="2f12" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated"><strong class="je hi">结论</strong></p><p id="8caa" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">使用这个函数，我们能够确定未标记数据中的聚类数。3正好是最初生成的数据中的聚类数。因此，我们能够自动标记最初未标记的数据集。</p><p id="5186" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated"><strong class="je hi"> <em class="li">注意:请不要犹豫使用我在Github中的</em> </strong> <a class="ae kq" href="https://github.com/rmerzouki/ml/blob/main/Best%20Clustering%20with%20silhouette%20score_v1.4.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi"> <em class="li">片段代码</em> </strong> </a> <strong class="je hi"> <em class="li">来评估多变量无标签数据集的最佳聚类，并为它们提供标签。</em>T13】</strong></p><p id="fccb" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated"><em class="li">如果您有任何问题或希望保持联系，请随时在LinkedIn上联系我:</em><a class="ae kq" href="https://www.linkedin.com/in/reda-merzouki-02843b/" rel="noopener ugc nofollow" target="_blank"><em class="li">Reda Merzouki</em></a></p><h1 id="dcbf" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">感谢您的阅读！</h1></div></div>    
</body>
</html>
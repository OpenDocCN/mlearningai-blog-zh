<html>
<head>
<title>Point Net for Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类点网</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/point-net-for-classification-968ca64c57a9?source=collection_archive---------3-----------------------#2022-12-11">https://medium.com/mlearning-ai/point-net-for-classification-968ca64c57a9?source=collection_archive---------3-----------------------#2022-12-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="f9e7" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">如何训练点网进行点云分类</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/94aba76b6841c28524bb12ac3d618850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4vluxugKXtfv8L4p"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/es/@cvgellhorn?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Christoph von Gellhorn</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a930" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这是点网系列的第三部分:</p><ol class=""><li id="8bc0" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated"><a class="ae jm" rel="noopener" href="/@itberrios6/introduction-to-point-net-d23f43aa87d2">点网直观介绍</a></li><li id="1ca7" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" rel="noopener" href="/@itberrios6/point-net-from-scratch-78935690e496">点网从无到有</a></li><li id="0735" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">用于分类的点网</strong></li><li id="96c5" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" rel="noopener" href="/@itberrios6/point-net-for-semantic-segmentation-3eea48715a62">用于语义分割的点网</a></li></ol><p id="8198" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在本教程中，我们将学习如何为<a class="ae jm" href="https://en.wikipedia.org/wiki/Statistical_classification" rel="noopener ugc nofollow" target="_blank">分类</a>训练点网。我们将主要关注数据和训练过程；演示如何从头开始编写点网络代码的教程位于<a class="ae jm" rel="noopener" href="/@itberrios6/point-net-from-scratch-78935690e496">这里</a>。本教程的代码位于这个<a class="ae jm" href="https://github.com/itberrios/3D/tree/main/point_net" rel="noopener ugc nofollow" target="_blank">库</a>中。我们将使用的笔记本位于该存储库中的<a class="ae jm" href="https://github.com/itberrios/3D/blob/main/point_net/pointnet_cls.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。一些代码的灵感来自这个<a class="ae jm" href="https://github.com/intel-isl/Open3D-PointNet" rel="noopener ugc nofollow" target="_blank">库</a>。</p><h1 id="a43d" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">获取数据</h1><p id="870b" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我们将使用只有16个类的较小版本的shapenet数据集。如果你正在使用<a class="ae jm" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Colab </a>，你可以运行下面的代码来获取数据。警告，这将需要很长时间。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="7fa8" class="lz ky hh lv b be ma mb l mc md">!wget -nv https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_segmentation_benchmark_v0.zip --no-check-certificate<br/>!unzip shapenetcore_partanno_segmentation_benchmark_v0.zip<br/>!rm shapenetcore_partanno_segmentation_benchmark_v0.zip</span></pre><p id="6a34" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果你想在本地工作，请访问上面第一行的链接，数据将自动下载为zip文件。</p><p id="c9ef" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">数据集包含16个带有类标识符的文件夹(在自述文件中称为“synsetoffset”)。文件夹结构是:</p><ul class=""><li id="a5f2" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki me kp kq kr bi translated"><strong class="jp hi"> synsetoffset </strong> <br/> -点:来自ShapeNetCore模型的均匀采样点<br/> - point_labels:逐点分割标签<br/> - seg_img:标签的可视化</li><li id="16d0" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki me kp kq kr bi translated"><strong class="jp hi"> train_test_split </strong>:带有训练/验证/测试分割的JSON文件</li></ul><p id="75aa" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">自定义PyTorch数据集位于<a class="ae jm" href="https://github.com/itberrios/3D/blob/main/point_net/shapenet_dataset.py" rel="noopener ugc nofollow" target="_blank">这里</a>，说明代码超出了本教程的范围。需要知道的重要事情是数据集可以获得(点云，类)或(点云，分段标签)。在训练和验证过程中，我们给点云添加高斯噪声，并随机地<a class="ae jm" href="https://www.brainm.com/software/pubs/math/Rotation_matrix.pdf" rel="noopener ugc nofollow" target="_blank">围绕垂直轴(本例中为y轴)旋转</a>。我们还对点云执行<a class="ae jm" href="https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)" rel="noopener ugc nofollow" target="_blank">最小-最大归一化</a>，使它们的范围为0-1。我们可以创建shapenet数据集的实例，如下所示:</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="9c71" class="lz ky hh lv b be ma mb l mc md">from shapenet_dataset import ShapenetDataset<br/><br/># __getitem__ returns (point_cloud, class)<br/>train_dataset = ShapenetDataset(ROOT, npoints=2500, split='train', classification=True)</span></pre><h1 id="12ce" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">探索数据</h1><p id="f0d5" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">在开始任何培训之前，让我们先来研究一些培训数据。为此，我们将使用Open3d版本0.16.0(必须是0.16.0或更高版本)。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="563e" class="lz ky hh lv b be ma mb l mc md">!pip install open3d==0.16.0</span></pre><p id="11c0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们现在可以用下面的代码来查看一个样本点云。您应该注意到，每次运行代码时，点云都以不同的方向显示。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="10e1" class="lz ky hh lv b be ma mb l mc md">import open3d as o3<br/>from shapenet_dataset import ShapenetDataset<br/><br/>sample_dataset = train_dataset = ShapenetDataset(ROOT, npoints=20000, split='train', <br/>                                                 classification=False, normalize=False)<br/><br/>points, seg = sample_dataset[4000]<br/><br/>pcd = o3.geometry.PointCloud()<br/>pcd.points = o3.utility.Vector3dVector(points)<br/>pcd.colors = o3.utility.Vector3dVector(read_pointnet_colors(seg.numpy()))<br/><br/>o3.visualization.draw_plotly([pcd])</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mf"><img src="../Images/a140878b6b8ebc67954f3f1b2e269f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*cx7RmHq5iaTxi4hE_KTXIw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 1. Noisy point cloud with random rotation. Y-axis is the vertical axis. Source: Author.</figcaption></figure><p id="bdcc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">你可能不会注意到噪音有很大的不同，因为我们添加的数量很少；我们添加了少量，因为不想大大破坏结构，但这少量足以对模型产生影响。现在我们来看看培训班的频率。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mg"><img src="../Images/32e9482713ce47b72f2ef8812d5092f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pLHdzSVXPDPWyeALmlaacA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 2. Frequencies of the training classes. Source: Author.</figcaption></figure><p id="c3e9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们可以在图2中看到，这绝对不是一个平衡的训练集。因此，我们可能想要应用类别加权，甚至使用<a class="ae jm" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank">焦点损失</a>来帮助我们的模型学习。</p><h1 id="d4e7" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">点净损失函数</h1><p id="db9c" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">当训练点网络进行分类时，我们可以使用PyTorch的标准<a class="ae jm" href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html" rel="noopener ugc nofollow" target="_blank">交叉熵损失</a>，但我们还想增加一项，以包括论文[ <a class="ae jm" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a>中提到的正则化项。正则项强制特征变换矩阵正交，但是为什么呢？特征变换矩阵旨在<a class="ae jm" href="https://en.wikipedia.org/wiki/Rotation_matrix" rel="noopener ugc nofollow" target="_blank">旋转</a> ( <a class="ae jm" href="https://en.wikipedia.org/wiki/Rigid_transformation" rel="noopener ugc nofollow" target="_blank">变换</a>)点云的高维表示。我们如何确定这种学习到的高维旋转实际上是在旋转点云呢？为了回答这个问题，让我们考虑旋转的一些期望的性质。我们希望学习到的旋转是<a class="ae jm" href="https://en.wikipedia.org/wiki/Affine_transformation" rel="noopener ugc nofollow" target="_blank">仿射</a>，这意味着它保留了结构。我们想确定它没有做什么奇怪的事情，比如把它映射回一个更低维度的空间或者打乱它的结构。我们不能仅仅绘制一个nx64点云来检查这一点，但是我们可以通过鼓励旋转是<a class="ae jm" href="https://en.wikipedia.org/wiki/Orthogonal_matrix" rel="noopener ugc nofollow" target="_blank">正交的</a>来让模型学习有效的旋转。这是因为正交矩阵保留了长度和角度，而旋转矩阵是一种特殊类型的正交矩阵[ <a class="ae jm" href="https://people.math.harvard.edu/~knill/teaching/math22b2019/handouts/lecture08.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]。我们可以“鼓励”模型通过正则化项来学习正交旋转矩阵:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mh"><img src="../Images/20af58d52847e32673f44ada62207b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*VVrN3YeIuh0_Sk2tBuwvFw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 3. Point Net Regularization term. <a class="ae jm" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><p id="2814" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们利用正交矩阵的一个基本性质，即它们的列和行是正交向量。对于完全正交的矩阵，图3中的正则项将等于零。[ <a class="ae jm" href="https://people.math.harvard.edu/~knill/teaching/math22b2019/handouts/lecture08.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a></p><p id="851e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在训练过程中，我们只是将这一项加入到我们的损失中。如果你已经过了<a class="ae jm" rel="noopener" href="/@itberrios6/introduction-to-point-net-d23f43aa87d2">之前关于如何对点网编码的教程</a>，你可能还记得特征变换矩阵A是由分类头返回的。</p><p id="9693" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在让我们编写点净损失函数。我们已经添加了加权(平衡)交叉熵损失和<a class="ae jm" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank">聚焦损失</a>的术语，但是解释它们超出了本教程的范围。这个代码位于<a class="ae jm" href="https://github.com/itberrios/3D/blob/main/point_net/point_net_loss.py" rel="noopener ugc nofollow" target="_blank">这里</a>。这段代码改编自这个<a class="ae jm" href="https://github.com/clcarwin/focal_loss_pytorch" rel="noopener ugc nofollow" target="_blank">库</a>。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="d23d" class="lz ky hh lv b be ma mb l mc md">import numpy as np<br/>import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/><br/><br/>class PointNetLoss(nn.Module):<br/>    def __init__(self, alpha=None, gamma=0, reg_weight=0, size_average=True):<br/>        super(PointNetLoss, self).__init__()<br/>        self.alpha = alpha<br/>        self.gamma = gamma<br/>        self.reg_weight = reg_weight<br/>        self.size_average = size_average<br/><br/>        # sanitize inputs<br/>        if isinstance(alpha,(float, int)): self.alpha = torch.Tensor([alpha,1-alpha])<br/>        if isinstance(alpha,(list, np.ndarray)): self.alpha = torch.Tensor(alpha)<br/><br/>        # get Balanced Cross Entropy Loss<br/>        self.cross_entropy_loss = nn.CrossEntropyLoss(weight=self.alpha)<br/><br/>    def forward(self, predictions, targets, A):<br/><br/>        # get batch size<br/>        bs = predictions.size(0)<br/><br/>        # get Balanced Cross Entropy Loss<br/>        ce_loss = self.cross_entropy_loss(predictions, targets)<br/><br/>        # reformat predictions and targets (segmentation only)<br/>        if len(predictions.shape) &gt; 2:<br/>            predictions = predictions.transpose(1, 2) # (b, c, n) -&gt; (b, n, c)<br/>            predictions = predictions.contiguous() \<br/>                                     .view(-1, predictions.size(2)) # (b, n, c) -&gt; (b*n, c)<br/><br/>        # get predicted class probabilities for the true class<br/>        pn = F.softmax(predictions)<br/>        pn = pn.gather(1, targets.view(-1, 1)).view(-1)<br/><br/>        # get regularization term<br/>        if self.reg_weight &gt; 0:<br/>            I = torch.eye(64).unsqueeze(0).repeat(A.shape[0], 1, 1) # .to(device)<br/>            if A.is_cuda: I = I.cuda()<br/>            reg = torch.linalg.norm(I - torch.bmm(A, A.transpose(2, 1)))<br/>            reg = self.reg_weight*reg/bs<br/>        else:<br/>            reg = 0<br/><br/>        # compute loss (negative sign is included in ce_loss)<br/>        loss = ((1 - pn)**self.gamma * ce_loss)<br/>        if self.size_average: return loss.mean() + reg<br/>        else: return loss.sum() + reg</span></pre><h1 id="623c" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">分类训练点网</h1><p id="10f2" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">现在我们已经了解了数据和损失函数，我们可以继续培训了。在我们的培训中，我们希望量化模型的表现。通常我们关注损失和准确性，但是对于这个分类问题，我们将需要一个度量来解释不正确的分类以及正确的分类。想想典型的混淆矩阵:真阳性、假阴性、真阴性和假阳性；我们需要一个在所有这些方面都表现良好的分类器。<a class="ae jm" href="https://en.wikipedia.org/wiki/Phi_coefficient" rel="noopener ugc nofollow" target="_blank">Matthews Correlation Coefficient</a>(MCC)量化了我们的模型在所有这些指标上的表现，被认为是比准确性或F1分数[ <a class="ae jm" href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]更可靠的单一性能指标。MCC的范围从-1到1，其中-1表示性能最差，1表示性能最佳，0表示随机猜测。我们可以通过<a class="ae jm" href="https://torchmetrics.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> torchmetrics </a>使用带有PyTorch的MCC。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="586c" class="lz ky hh lv b be ma mb l mc md">from torchmetrics.classification import MulticlassMatthewsCorrCoef<br/><br/>mcc_metric = MulticlassMatthewsCorrCoef(num_classes=NUM_CLASSES).to(DEVICE)</span></pre><p id="e9c1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">培训过程是一个基本的PyTorch培训循环，在培训和验证之间交替进行。我们使用Adam优化器和我们的点净损失函数以及上面图3中描述的正则化项。对于点净损失函数，我们选择设置α，它对每个样本的重要性进行加权。我们还设置伽马，其调节损失函数并迫使其集中于困难的例子，其中困难的例子是那些以较低概率分类的例子。详见<a class="ae jm" href="https://github.com/itberrios/3D/blob/main/point_net/pointnet_cls.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中的注释。注意到当使用<a class="ae jm" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CyclicLR.html" rel="noopener ugc nofollow" target="_blank">循环学习率</a>时，模型训练得更好，所以我们在这里实现了它。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="08de" class="lz ky hh lv b be ma mb l mc md">import torch.optim as optim<br/>from point_net_loss import PointNetLoss<br/><br/>EPOCHS = 50<br/>LR = 0.0001<br/>REG_WEIGHT = 0.001 <br/><br/># manually downweight the high frequency classes<br/>alpha = np.ones(NUM_CLASSES)<br/>alpha[0] = 0.5  # airplane<br/>alpha[4] = 0.5  # chair<br/>alpha[-1] = 0.5 # table<br/><br/>gamma = 1<br/><br/>optimizer = optim.Adam(classifier.parameters(), lr=LR)<br/>scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, <br/>                                              step_size_up=2000, cycle_momentum=False)<br/>criterion = PointNetLoss(alpha=alpha, gamma=gamma, reg_weight=REG_WEIGHT).to(DEVICE)<br/><br/>classifier = classifier.to(DEVICE)</span></pre><p id="f400" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">请按照<a class="ae jm" href="https://github.com/itberrios/3D/blob/main/point_net/pointnet_cls.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>进行训练循环，并确保你有一个GPU。如果没有，删除调度程序并将学习率设置为0.01，在几个时期后，您应该会得到足够好的结果。如果您遇到任何PyTorch用户警告(由于nn的未来更新。MaxPool1D)，您可以使用以下命令抑制它们:</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="6e73" class="lz ky hh lv b be ma mb l mc md">import warnings<br/>warnings.filterwarnings("ignore")</span></pre><h1 id="255d" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">培训结果</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mi"><img src="../Images/7eaa750dc76b1d4a06a2e83cdf989372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1Ue_bIyVUqu8mqYl0LFbg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 4. Training metrics. Source: Author.</figcaption></figure><p id="08c4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们可以看到，训练和验证的准确性都提高了，但MCC只在训练时提高，而在验证时没有提高。这可能是由于在验证和测试拆分中，某些类的样本量非常小；因此，在这种情况下，MCC可能不是验证和测试的最佳单一指标。这就需要对MCC何时是一个好的指标进行更多的调查；即多少不平衡对MCC来说是太多了？每个班级需要多少样本才能使MCC有效？</p><p id="a32c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们来看看测试结果:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mj"><img src="../Images/8363179f09d3c3467ffc9ca9e0c36a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HJqkYXxgTHA761zo13VyJA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 5. Test metrics. Source: Author.</figcaption></figure><p id="368a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们看到，测试的准确度在85%左右，但是MCC刚刚超过0。因为我们只有16个类，所以让我们查看笔记本中的<a class="ae jm" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>来更深入地了解测试结果。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mk"><img src="../Images/d4c4d31cb6048901845a72b566c57d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y3QoLWTf_Tn6FPZkWjSCcQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 6. Test data Confusion matrix. Source: Author.</figcaption></figure><p id="ca02" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在很大程度上，这种分类是可以的，但也有一些不太常见的类别，如“火箭”或“滑板”。该模型在这些类别上往往具有较差的预测性能，而在这些不太常见的类别上的性能是导致MCC下降的原因。另一件要注意的事情是，当你检查结果时(如<a class="ae jm" href="https://github.com/itberrios/3D/blob/main/point_net/pointnet_cls.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>所示)，你会在更频繁的课上获得良好的准确性和自信的表现。然而，在频率较低的类中，您会注意到置信度较低，准确性较差。</p><h1 id="a85a" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">检查临界集</h1><p id="bb1a" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">现在我们来看看本教程最有趣的部分，临界集。临界集是点云集合的本质潜在点。这些点定义了它的基本结构。这里有一些代码显示如何可视化它们。</p><pre class="ix iy iz ja fd lu lv lw bn lx ly bi"><span id="8432" class="lz ky hh lv b be ma mb l mc md">from open3d.web_visualizer import draw <br/><br/><br/>critical_points = points[crit_idxs.squeeze(), :]<br/>critical_point_colors = read_pointnet_colors(seg.numpy())[crit_idxs.cpu().squeeze(), :]<br/><br/>pcd = o3.geometry.PointCloud()<br/>pcd.points = o3.utility.Vector3dVector(critical_points)<br/>pcd.colors = o3.utility.Vector3dVector(critical_point_colors)<br/><br/># o3.visualization.draw_plotly([pcd])<br/>draw(pcd, point_size=5) # does not work in Colab</span></pre><p id="8a5b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这里有一些可视化效果，注意我使用了“draw()”来获得更大的点尺寸，但它在Colab中不起作用。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ml"><img src="../Images/222334b28e29a5e8a7ec3f0d58db0369.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jZ3dQhqtC83KG_9XlWBMIg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 7. Point Cloud Sets and their corresponding critical sets learned by Point Net. Source: Author.</figcaption></figure><p id="0a8f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们可以看到，临界集显示了它们对应的点云的整体结构，它们本质上是稀疏采样的点云。这表明经过训练的模型实际上已经学会区分不同的结构，并且表明它实际上能够基于它们的区分结构来对每个点云类别进行分类。</p><h1 id="6b91" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">结论</h1><p id="ddb0" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">如果你已经做到了这一步，祝贺你！你已经学会了如何从头开始训练一个点网络，我们甚至已经学会了如何可视化点集。我鼓励你回去，确保你理解了一切，如果你真的感兴趣，尝试提高整体分类性能。以下是一些帮助你开始的建议:</p><ul class=""><li id="7b88" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki me kp kq kr bi translated">使用不同的损失函数</li><li id="e521" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki me kp kq kr bi translated">在<a class="ae jm" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CyclicLR.html" rel="noopener ugc nofollow" target="_blank">循环学习率调度器</a>中尝试不同的设置</li><li id="3e7b" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki me kp kq kr bi translated">尝试对点网络架构进行修改</li><li id="25b9" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki me kp kq kr bi translated">尝试不同的数据扩充</li><li id="c03e" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki me kp kq kr bi translated">使用更多数据→尝试完整的<a class="ae jm" href="https://shapenet.org/" rel="noopener ugc nofollow" target="_blank"> shapenet数据集</a></li></ul><h1 id="27c4" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">参考</h1><p id="c6a6" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">[1]查尔斯，R. Q .，苏，h .，凯春，m .，&amp;吉巴斯，L. J. (2017)。PointNet:用于3D分类和分割的点集深度学习。<em class="mm"> 2017年IEEE计算机视觉与模式识别大会(CVPR) </em>。<a class="ae jm" href="https://doi.org/10.1109/cvpr.2017.16" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1109/cvpr.2017.16</a></p><p id="bab4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[2]克尼尔，未注明日期。<em class="mm">第八单元:正交组——哈佛大学</em>。people.math.harvard.edu。2022年12月10日检索，来自<a class="ae jm" href="https://people.math.harvard.edu/~knill/teaching/math22b2019/handouts/lecture08.pdf" rel="noopener ugc nofollow" target="_blank">https://people . math . Harvard . edu/~ knill/teaching/math 22b 2019/讲义/讲师08.pdf </a></p><p id="f85a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[3]奇科博士和朱尔曼博士(2020年)。马修斯相关系数(MCC)在二分类评估中相对于F1分数和准确性的优势。<em class="mm"> BMC基因组学</em>，<em class="mm"> 21 </em> (1)。<a class="ae jm" href="https://doi.org/10.1186/s12864-019-6413-7" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1186/s12864-019-6413-7</a></p><div class="mn mo ez fb mp mq"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hi fi z dy mv ea eb mw ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jg mq"/></div></div></a></div></div></div>    
</body>
</html>
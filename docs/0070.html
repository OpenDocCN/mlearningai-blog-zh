<html>
<head>
<title>Image Detection Using the VGG-19 Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用VGG-19卷积神经网络的图像检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/image-detection-using-convolutional-neural-networks-89c9e21fffa3?source=collection_archive---------0-----------------------#2021-01-01">https://medium.com/mlearning-ai/image-detection-using-convolutional-neural-networks-89c9e21fffa3?source=collection_archive---------0-----------------------#2021-01-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex ie if ig ih er es paragraph-image"><div class="ab fe cl ii"><img src="../Images/4cd66eb9938686d1299947f8d9991ec1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*d7BV_uwaP4lqRamA9ghxXA.jpeg"/></div></figure><p id="da7f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi jj translated">我使用VGG-19卷积神经网络从我的自然摄影收藏中筛选照片，并检测包含树木的图像。这是一次有趣的练习，我学到了很多关于CNN的幕后工作。<strong class="in hi">下面我描述了CNN的架构、流程和输入，并提供了我如何构建mine </strong>的八步实现。</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="b912" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak"> CNN架构，流程&amp;输入</strong></h1><p id="7215" class="pw-post-body-paragraph il im hh in b io kx iq ir is ky iu iv iw kz iy iz ja la jc jd je lb jg jh ji ha bi translated"><strong class="in hi">架构:</strong></p><p id="7393" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">CNN包含将图像转换成模型可以理解的输出的层的组合。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lc"><img src="../Images/cc20c8bb5458244e7d5e46cfbe10b56e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iy_04I9BvNyuow7ADB2RIg.png"/></div></div></figure><ul class=""><li id="c408" class="ll lm hh in b io ip is it iw ln ja lo je lp ji lq lr ls lt bi translated">卷积层:通过应用一次扫描图像几个像素的过滤器来创建特征图</li><li id="e794" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">汇集层:缩小卷积层生成的信息，以有效地存储它</li><li id="0f79" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">完全连接的输入层:将输出展平为单个矢量</li><li id="a7e2" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">完全连接的图层:对要素分析生成的输入应用权重</li><li id="3f93" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">完全连接的输出层:生成最终概率以确定图像类别</li></ul><p id="a628" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">流程:</strong></p><p id="d0fb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">前向和后向传播遍历网络中的所有训练样本，直到确定最佳权重，并且只有最强大和最具预测性的神经元被激活来进行预测</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lz"><img src="../Images/5ed38212d7716b25d58e00ab711d0ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*swiy1KpD-4xe6GWjT_BP9w.png"/></div></div></figure><ul class=""><li id="919f" class="ll lm hh in b io ip is it iw ln ja lo je lp ji lq lr ls lt bi translated">该模型通过每次对所有训练样本进行一次向前和一次向后的传递来贯穿许多时期进行训练</li><li id="6827" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">前向传播通过比较每个标记图像的实际目标和预测目标之间的差异来计算损失和成本函数</li><li id="97d6" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">反向传播使用梯度下降来更新每个神经元的权重和偏差，将更多影响归因于具有最大预测能力的神经元，直到它到达最佳激活组合</li><li id="ee10" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">随着模型看到的示例越来越多，它将学会更好地预测导致损失度量减少的目标</li><li id="9246" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">成本函数采用所有样本的平均损失来表示整体性能</li></ul><p id="7417" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">输入:</strong></p><p id="af42" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">模型输入必须是由(batch_size，height，width，depth)组成的4D数组</p><figure class="ld le lf lg fd ih er es paragraph-image"><div class="er es ma"><img src="../Images/ddc686de39e9a20db0837a62bee2b747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*vZ77hb-er22BSAqO-1v6Mg.png"/></div></figure><ul class=""><li id="603a" class="ll lm hh in b io ip is it iw ln ja lo je lp ji lq lr ls lt bi translated">批量大小:一个时期内训练样本的数量(批量越大，需要的内存就越多)</li><li id="4a2d" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">高度和宽度:图像的像素尺寸</li><li id="ff8e" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">深度:红色、绿色或蓝色(3)，或黑色和白色(1)</li></ul></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="258e" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">我的VGG19型号</h1><p id="fa90" class="pw-post-body-paragraph il im hh in b io kx iq ir is ky iu iv iw kz iy iz ja la jc jd je lb jg jh ji ha bi translated">下面是我的性能最好的VGG19模型的8步配置。VGG19是一种先进的CNN，具有预先训练的层，并且在形状、颜色和结构方面对定义图像的内容有很好的理解。VGG19非常深入，已经通过复杂的分类任务在数百万张不同的图像上进行了训练。我没有进一步训练VGG19，只是冻结了它的图层，并在其上附加了一个浅2层网络来执行我的分类任务，识别有树和无树的图像。</p><p id="dfc3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">1.加载您的模型。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mb"><img src="../Images/1ee7d11f8a2c20a3db17a5a549e04eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IP9_p20o6YJMoin33OYkrw.png"/></div></div></figure><p id="29ff" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">2.加载您的数据集大小。在这种情况下，指定用于训练、测试和验证的照片已经被随机地放入不同的文件夹中，并且被手动地在有树(目标= 1)和没有树(目标= 0)的照片之间进行分离。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mc"><img src="../Images/640e2d3f2854c33b50b5df2d6068c588.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cSXcQAHMUFoDF5pdaPj64w.png"/></div></div></figure><p id="111d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">3.设置一个功能来提取和冻结VGG-19的初始层，这些层处理引擎盖下图像的特征和标签。这将允许模型应用迁移学习，其中它可以从网络上的数百万张照片中回忆起它的预训练。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/1b5735a31870aa5b38b759af2829e0ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ru0i25I7aIOmrih_xNekww.png"/></div></div></figure><p id="f1fa" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">4.将该函数应用于训练、验证和测试数据集，以便从所有数据集中提取特征和标签。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es me"><img src="../Images/7d0c61d0dd45205e03db8e3cfe46d2ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0huI-NxZjaUIPkt3332q1Q.png"/></div></div></figure><p id="f928" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">5.确保数据的形状正确，以反映数据集的维度。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mc"><img src="../Images/3347127abd85bb6b1a0df3bd6b2acdad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i2WC9Rxx3Z17ojjsCsTp1A.png"/></div></div></figure><p id="d5de" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">6.将提取的特征和标签保存到一个“瓶颈”文件夹中，供最终的分类层参考并推断图像属于哪个二进制类别。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mb"><img src="../Images/8a5a7bf6d33f5cb0bf0ad2851d3e4f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CND_gxa4nGS2tcFDfHoZaw.png"/></div></div></figure><p id="e830" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">7.在VGG-10“大脑”的顶部构建图像分类器最后一层，并将其投入使用。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mf"><img src="../Images/2d440ecd365b969801057a3110422c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tb0DB4vC4GHynp47KvcrJA.png"/></div></div></figure><p id="0b9e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">8.要使用您的准确性和损失度量来直观显示您的模型的学习情况，请打印您的培训历史。正如您所看到的，随着每个时期(或迭代)，我们的精度增加，损失减少。</p><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mg"><img src="../Images/65ead9774decb4224f156fc28ba55c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5TZVNW8P4CzUMfbwCqHYFg.png"/></div></div></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><p id="05aa" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">除了试验不同的模型超参数，您还可以采取以下步骤来改进您的模型:</p><p id="1da1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">为了提高模型性能</strong>，添加逆境，这样你的模型就可以学会识别你的目标，即使是在不可能的情况下:</p><ul class=""><li id="9f7a" class="ll lm hh in b io ip is it iw ln ja lo je lp ji lq lr ls lt bi translated">翻转图像方向</li><li id="0c2c" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">整合与你的目标相似的图片</li><li id="fb5c" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">添加模糊和不清晰的版本</li></ul><p id="618c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">提高模型效率，</strong>降低模型负载:</p><ul class=""><li id="edc7" class="ll lm hh in b io ip is it iw ln ja lo je lp ji lq lr ls lt bi translated">通过压缩空间大小和参数，在层之间执行最大池化以降低图像维数</li><li id="4d53" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">尝试早期停止，以防止过度拟合；如果您的模型达到了最高精度，它将在特定的历元数后停止寻找更高的精度</li><li id="3f6c" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">训练更少的历元以减少处理时间</li><li id="f80b" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">尝试不同的激活功能，如ReLU，它只激活某些神经元，比sigmoid或tanh更有效</li><li id="e029" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">尝试放弃，以便在训练过程中忽略随机选择的神经元，从而减少网络计算</li><li id="13fc" class="ll lm hh in b io lu is lv iw lw ja lx je ly ji lq lr ls lt bi translated">避免大像素图像，因为增加图像清晰度并不能提高学习效果(224 x 224像素是标准)</li></ul></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><p id="8304" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这里是<a class="ae mh" href="https://github.com/melisabardhi/Project4-Image-Detection-Using-Convolutional-Neural-Networks" rel="noopener ugc nofollow" target="_blank"> github库</a>，包含完整的代码和一些用来训练我的模型的照片。</p><p id="7d9b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">感谢您的阅读！</p><div class="ld le lf lg fd ab cb"><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/cd3edbe0084b0aa75f406733a6b31eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*xLDePyOML6pviqbjP4aIAg.jpeg"/></div></figure><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/82925669a7174411186fe9bf96f28b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dIswwG673EpRnj2zBUMP5g.jpeg"/></div></figure></div><div class="ab cb"><figure class="mi ih mo mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/c8ad9f9e22cdf8aeaa5151f1482891b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Q_4qzLhaoCblcDTbLA2MJg.jpeg"/></div></figure><figure class="mi ih mp mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/7231ad4958c7068c11c31bdd609d8008.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*QT1CEjIa7ZsOQaJ4xIq4ZA.jpeg"/></div></figure></div><div class="ab cb"><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/94156efbd418603fb79c12423f0f274c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jieeDMozaSb1ZVJlURoOYQ.jpeg"/></div></figure><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/0a013f3676f073f86a6f319553492728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6ygIG67iuKNG15bpiZyh8A.jpeg"/></div></figure></div><div class="ab cb"><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/3c31bbacfbbddd5b37b30a79beb2197e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*gbh1YuSEf4RoK2bPBHH8-g.jpeg"/></div></figure><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/10bda51c8291882274c7a13305098d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*xVPRggz58Vf5zeLByN1XRA.jpeg"/></div></figure></div><figure class="ld le lf lg fd ih er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mq"><img src="../Images/eef460177b52af31db2da5a2102301ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8e8ZZmylPDSdLSOr8k8gCQ.jpeg"/></div></div></figure><div class="ld le lf lg fd ab cb"><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/93e8f5456cceff3e827d234f9ac91988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*K-lGPPttr-AsbDO7v83DmA.jpeg"/></div></figure><figure class="mi ih mj mk ml mm mn paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/45c6e325f1a90a7e93632e16e771fe26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*x1cPhMz2Qnr8TYr3FYG4Gw.jpeg"/></div></figure></div></div></div>    
</body>
</html>
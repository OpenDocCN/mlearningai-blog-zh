<html>
<head>
<title>Artificial Intelligence vs Artificial Consciousness: Does it matter?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能vs人工意识:重要吗？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/artificial-intelligence-vs-artificial-consciousness-does-it-matter-b39ebd788e93?source=collection_archive---------1-----------------------#2021-08-03">https://medium.com/mlearning-ai/artificial-intelligence-vs-artificial-consciousness-does-it-matter-b39ebd788e93?source=collection_archive---------1-----------------------#2021-08-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/efa5a03d91dda2e442845fe3d9ba25d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*2JvpHvy_iw1OaPGW0thnkQ.jpeg"/></div></figure><p id="c705" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在关于身心问题的讨论中，关于强与弱人工智能(AI)的争论，以及生物伦理中，意识起着至关重要的作用。令人惊讶的是，它没有出现在当前关于人工智能和机器人的伦理影响的争论中。本文研究了这一空白，并提出了两个主张:我们需要更多地讨论人工意识以及当今机器人和人工智能中缺乏意识的问题。</p><h1 id="2092" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">机器有可能拥有意识吗？</h1><p id="25a2" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">关于机器人是否有意识的争论并不新鲜；强人工智能(强AI)和弱人工智能(弱AI)的支持者已经交流了相当一段时间的哲学思想。约翰·r·塞尔(John R. Searle)对强人工智能的定义是，尽管他批评强人工智能(Searle，1980年，第417页)，但他认为“……正确设计的计算机确实是一种思维，在这个意义上，具有正确程序的计算机可以字面上理解和体验认知状态”。而弱AI则认为机器人缺乏意识、心智、和感性，取而代之的是简单地模仿认知和理解。</p><p id="98d3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当谈到人工意识时，有许多问题需要考虑(Manzotti和Chella，2018年)。解释意识的挑战，或者说主观性如何可能起源于物质(有时被称为“意识的难题”)是最基本的(Chalmers，1996)。此外，我们对人类意识的感知受到我们自身感官体验的影响。人工意识只会从第三人称视角对我们可用，不像人类意识，我们从第一人称视角了解。如何辨别计算机是否有知觉的话题与此有关。</p><p id="eb0e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">人工意识基于这样一种观念，即它可能在机器和机器人的物理世界中被发现(Manzotti和Chella，2018)。再者，人类对人工意识的任何定义，都必须来源于第三人称视角，而不是依赖于主观意识。</p><p id="d232" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一种方法是避免给机器意识下一个过于局限的定义，或者根本不要下定义。例如，David Levy (Levy，2009年，第210页)喜欢采取一种务实的方法，在这种方法中，有必要就我们所指的意识达成广泛的共识，并建议，“让我们简单地使用这个词并继续下去。”</p><p id="ab48" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">其他人专注于自我意识。“这些基本原则和方法将使机器人能够了解他们的环境，认识到他们在做什么，采取适当和及时的举措，从他们自己的经验中学习，并表明他们知道他们已经学习和如何学习，”Chatila等人(2018年，第1页)认为与自我意识机器人相关。另一方面，Kinouchi和Mackin强调系统级适应(Kinouchi和Mackin，2018，第1页):“意识被认为是成功的系统级适应的一个功能，基于匹配和安排底层并行处理单元的各个输出。”这种意识被认为与我们在日常生活中做决定时我们的头脑是如何“意识到”的相对应。"</p><p id="6df8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当试图回答关于人工意识的问题时，思考关于意识的哲学思考是很重要的，这种思考侧重于人类(和动物)的意识。意识可以用多种方式来定义。我们通常区分(a)有意识的实体，它是有知觉的、清醒的，并具有自我意识和主观的定性经验，(b)意识到某事，如玫瑰，以及{c}有意识的精神状态，这是实体意识到自己所处的精神状态，如意识到闻到玫瑰(Van Gulick，2018；Gennaro，2019)。</p><p id="2802" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Dehaene等人(2017年)确定了意识计算的两个关键方面:全球可用性(C1)和自我监控(C2) (C2)。他们将全球可用性与Ned Block的访问意识进行了比较，他们将访问意识定义为有机体全球可用的知识(Block，1995)。他们将自我监控(C2)定义为“一种自我参照连接，在这种连接中，认知系统能够监控自己的处理过程并接收关于自己的知识”(第486-487页)，他们认为这相当于内省。</p><p id="86c9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">不同的作者强调人工意识的不同元素，正如上面提供的定义人工意识的方法的例子所看到的。绝对有机会对人工意识的第三人称概念进行额外的思考和调查。</p><h1 id="81f6" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated"><strong class="ak">人机交互和人工意识</strong></h1><p id="834a" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">尽管大量科幻小说似乎表明了相反的情况，但专家们普遍认为现有的机器和机器人没有知觉。然而，在一项对184名学生的研究中，对“你认为现在的电子计算机是有意识的吗？”分别是:否:82%；不确定:15%；是:3%。(Reggia等人，2015年)。令人惊讶的是，调查的问题是关于“现代电子计算机”，而不是人工智能或机器人。</p><p id="3a22" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在社交机器人和人-机器人社交接触的情况下，意识相关的问题可能会最频繁地出现(Sheridan，2016)。根据凯特·达林的描述(达林，2012年，第2页)，社交机器人是“一个物理体现的、自主的实体，在社交层面上与人交流和互动。”麻省理工学院的Kismet、阿鲁迪巴机器人公司的阿鲁迪巴·NAO和汉森机器人公司的人形社交机器人索菲亚都是社交机器人的例子。</p><p id="6bff" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">社交机器人有许多区别于人类的特质:它们可以做出有限的决定并进行学习，它们可以显示行为，它们可以与人互动。此外，机器人社会行为的非语言即时性(Kennedy等人，2017年)、语音识别和语言交流(格里戈雷等人，2016年)、面部表情和机器人的感知“个性”(Hendriks等人，2011年)都在人们对机器人的反应中发挥了作用。</p><p id="f3ae" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，人们倾向于与社交机器人形成单向的情感关系，投射现实的特质，赋予人类属性(拟人化)，并赋予其意图(Scheutz，2011；亲爱的，2012；冈克尔，2018)。社交类人机器人索菲亚在2017年被授予沙特阿拉伯公民身份，这是这一趋势的典型例证，如果不是高潮的话(Katz，2017)。</p><p id="520a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">所有这些都引发了对机器人地位的担忧，以及如何应对和与它们互动(Gunkel，2018)。社交机器人只是物体吗？或者如彼得·阿萨罗所言，社交机器人是准智能体还是准人？其他社交活跃的人？准别人？机器人应该拥有和人类一样的权利吗？</p><p id="8b11" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">尽管大多数专家认为现有的机器人缺乏意识或意识，但某些作家(如Coeckelbergh，2010；亲爱的，2012；Gunkel，2018)曾声称机器人应该被赋予权利。例如，基于对机器人攻击行为的研究，凯特·达林认为将机器人更像宠物而不是普通物品一样对待符合我们的社会理想。</p><p id="b798" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">虽然支持赋予机器人权利的具体论点各不相同，但它们总是围绕着人类赋予它们的社会角色、人们与机器人形成的联系和情感依恋，或者人类与机器人互动的社会环境。他们倡导基于机器人为人类所扮演角色的权利，而不是基于机器人技能的地位。</p><p id="6a2c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然而，这种“社会角色”方法有一个根本性的缺陷。它关于如何与机器人互动的建议与我们如何与人类互动不一致(另见Katz，2017)。当应用于人类时，“社会角色”的概念断言，一个人的价值或权利受到他或她的社会责任或他人利益的严重影响。这一论断与人们普遍接受的信念背道而驰，即人类个体无论其社会角色如何，都具有道德地位。根据这种观点(Jaworska和Tannenbaum)，一个实体具有道德地位“当且仅当它或它的利益在某种程度上对实体本身有道德意义”</p><p id="bd0c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">人格对于人的地位和权利的归属至关重要。理性、意识、个人立场(对一个实体选择的态度)、回应个人立场的能力、语言交流和自我意识都是一个人的想法的关键特征(Dennett，1976)。丹尼尔·丹尼特认为，所有这些都是道德人格的必要前提。</p><p id="0e0b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">另一方面，“社会角色”方法根据机器人为他人履行的社会角色，而不是根据它们的道德地位或能力，来分配机器人的权利。这解释了为什么在这种情况下意识是无关紧要的。因为当代机器人缺乏意识或意识，所以不可能认为它们本身在伦理上是重要的。</p><p id="613e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然而，这在将来可能会改变。那么，考虑“机器人身份”的概念，并根据未来机器人的技能赋予它们道德地位，将是合理的。关于机器人是否应该被赋予法律人格，目前存在激烈而有争议的辩论(Bryson et al .，2017；Solaiman，2017)。关于机器人的道德和法律地位的讨论，以及如何对机器做出反应并与之互动的更大主题，需要对人工意识、人工理性、人工感知和相关思想有更深入的理解。我们需要更多地讨论人工意识，以及现有的AI和机器人是如何缺乏意识的。在这种情况下，关注人工意识和访问意识的第三人称概念将非常有益。</p></div></div>    
</body>
</html>
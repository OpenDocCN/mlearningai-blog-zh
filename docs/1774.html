<html>
<head>
<title>Fake News Detection Using Logistic Regression ML Project Tutorial (Beginners)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用逻辑回归ML项目检测假新闻教程(初学者)</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/fake-news-detection-using-logistic-regression-ml-project-tutorial-beginners-89b5c704d6ee?source=collection_archive---------1-----------------------#2022-01-28">https://medium.com/mlearning-ai/fake-news-detection-using-logistic-regression-ml-project-tutorial-beginners-89b5c704d6ee?source=collection_archive---------1-----------------------#2022-01-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/7adb246e512edb1ebfd492ed53912166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*8P76RkD5GVOdSa02TOQnyg.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">Photo from <a class="ae ip" href="https://www.europarl.europa.eu/news/sl/press-room/20191007IPR63550/eu-to-take-action-against-fake-news-and-foreign-electoral-interference" rel="noopener ugc nofollow" target="_blank">europarl</a></figcaption></figure><p id="659d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">对网上流传的错误信息的广泛信仰是现代社会的一个关键挑战。根据麻省理工学院的一项研究<a class="ae ip" href="https://news.mit.edu/2018/study-twitter-false-news-travels-faster-true-stories-0308" rel="noopener ugc nofollow" target="_blank"><strong class="is hi"><em class="jo"/></strong>这主要是通过点击诱饵来完成的，这些诱饵用华丽的标题或设计来吸引用户和好奇心，并欺骗他们点击链接以增加广告收入。因此，为了控制假新闻的流行，确定互联网上可用信息的完整性至关重要。</a></p><p id="0bdf" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">因此，我们现在将尝试使用<strong class="is hi">逻辑回归</strong>来建立一个简单的机器学习模型，以检测一篇新闻文章是否是假的。</p><h1 id="7b65" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">逻辑回归</h1><p id="403e" class="pw-post-body-paragraph iq ir hh is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn ha bi translated">在深入研究代码之前，让我们修改一下逻辑回归的概念。逻辑回归是一种统计分析方法，根据对数据集的先前观察来预测二元结果，如是或否(二元分类)。它是一种监督统计技术，用于发现因变量的概率。下图是一个<strong class="is hi"> Sigmoid函数</strong>，我们也称之为<strong class="is hi"> Logit </strong>。该函数将概率转换为二进制值，可进一步用于预测。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ks"><img src="../Images/4877d89ce21f50bf767a650b85d658ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-T9ykgInQzpk7SmqdtZu4g.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Sigmoid Function from <a class="ae ip" href="http://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression/" rel="noopener ugc nofollow" target="_blank">rasbt</a></figcaption></figure><p id="30d9" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">根据该图，如果我们获得的概率值为<strong class="is hi">小于0.5 </strong>，那么它被认为是属于第0类的<strong class="is hi">，如果该值为<strong class="is hi">大于0.5 </strong>，那么它将是第1类</strong>的<strong class="is hi">的一部分。</strong></p><p id="6c7e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">如果你想深入学习这个概念，可以查看<a class="ae ip" href="https://machinelearningmastery.com/logistic-regression-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jo">这个链接</em> </strong> </a>出来甚至观看<a class="ae ip" href="https://youtu.be/yIYKR4sgzI8" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jo">这个视频</em> </strong> </a>！</p><h1 id="380d" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">密码</h1><p id="e6ed" class="pw-post-body-paragraph iq ir hh is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn ha bi translated">现在终于从我们的代码开始了，你可以把它写在你的Jupyter笔记本或者Google Colab或者任何你喜欢的平台上。</p><p id="17b8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">也可以从<a class="ae ip" href="https://www.kaggle.com/c/fake-news/data?select=train.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jo">这里</em> </strong> </a>下载你的数据集。(我只使用了训练数据集，所以您也可以下载它本身。)</p><h2 id="69b0" class="lb jq hh bd jr lc ld le jv lf lg lh jz jb li lj kd jf lk ll kh jj lm ln kl lo bi translated"><strong class="ak">导入库/依赖关系</strong></h2><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="8e9c" class="lb jq hh lq b fi lu lv l lw lx"><strong class="lq hi">import</strong> numpy <strong class="lq hi">as</strong> np<br/><strong class="lq hi">import</strong> pandas <strong class="lq hi">as</strong> pd<br/><strong class="lq hi">import</strong> re<br/><strong class="lq hi">import</strong> nltk<br/><strong class="lq hi">from</strong> nltk.corpus <strong class="lq hi">import</strong> stopwords<br/><strong class="lq hi">from</strong> nltk.stem.porter <strong class="lq hi">import</strong> PorterStemmer<br/><strong class="lq hi">import </strong>sklearn<strong class="lq hi"><br/>from</strong> sklearn.feature_extraction.text <strong class="lq hi">import</strong> TfidfVectorizer<br/><strong class="lq hi">from</strong> sklearn.model_selection <strong class="lq hi">import</strong> train_test_split<br/><strong class="lq hi">from</strong> sklearn.linear_model <strong class="lq hi">import</strong> LogisticRegression<br/><strong class="lq hi">from</strong> sklearn.metrics <strong class="lq hi">import</strong> accuracy_score</span></pre><p id="1bb6" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">涵盖我们导入的每个库/模块/函数的重要性:</p><ul class=""><li id="ca7c" class="ly lz hh is b it iu ix iy jb ma jf mb jj mc jn md me mf mg bi translated">NumPy是一个通用的数组和矩阵处理包。</li><li id="0ec4" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi">熊猫</strong>:它允许我们对数据集进行各种操作。</li><li id="2470" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi"> re </strong>:这是一个内置的正则表达式包，可以用来处理正则表达式。</li><li id="4305" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated">NLTK :这是一套用于符号和统计自然语言处理(NLP)的库和程序。</li><li id="c81a" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi"> nltk.corpus </strong> : <strong class="is hi"/></li><li id="8250" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi">停用词</strong>:自然语言处理前一般被过滤掉的词称为停用词。这些实际上是任何语言中最常见的单词(如冠词、介词、代词、连词等)，不会给文本增加太多信息。(例-and，of，are等。)</li><li id="5d80" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated">PorterStemmer:一个帮助我们词干化的包。(在数据预处理一节中有更多关于词干的内容)</li><li id="b7a8" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi"> Sci-kit Learn (sklearn) </strong>:通过Python中的一致性接口，为机器学习和统计建模提供了一系列高效的工具，包括分类、回归、聚类和降维。</li><li id="76cf" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi">feature _ extraction . text</strong>:用于从包含文本的数据集中提取机器学习算法支持格式的特征。</li><li id="9d15" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated">TfidfVectorizer :它将文本转换成特征向量，这些向量可以作为估算器的输入。(关于TfidfVectorizer的更多信息，请参见数据预处理部分)</li><li id="b082" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi"> train_test_split </strong>:这是Sklearn模型选择中的一个功能，用于将数据阵列分成两个子集——训练数据和测试数据。</li><li id="15a0" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi"> LogisticRegression </strong>:代码的一个非常简单的部分，用于导入逻辑回归分类器。</li><li id="bf86" class="ly lz hh is b it mh ix mi jb mj jf mk jj ml jn md me mf mg bi translated"><strong class="is hi">指标</strong>和<strong class="is hi">准确度分数</strong>:从指标模块导入准确度分类分数。</li></ul><h2 id="f03c" class="lb jq hh bd jr lc ld le jv lf lg lh jz jb li lj kd jf lk ll kh jj lm ln kl lo bi translated">加载数据集</h2><p id="088b" class="pw-post-body-paragraph iq ir hh is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn ha bi translated">我希望你现在已经下载了数据集。现在您可以加载数据集，</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="b4d2" class="lb jq hh lq b fi lu lv l lw lx">data <strong class="lq hi">=</strong> pd<strong class="lq hi">.</strong>read_csv('fakenews.csv')<br/>data<strong class="lq hi">.</strong>head()</span></pre><p id="e968" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">在这里，我将我的csv文件重命名为<strong class="is hi"> fakenews.csv </strong>，并将其保存在与我的jupyter笔记本相同的文件夹中。如果您将数据集和jupyter笔记本保存在两个不同的文件夹中，您可以在代码中添加数据集文件的路径作为前缀，</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="88ed" class="lb jq hh lq b fi lu lv l lw lx">data <strong class="lq hi">=</strong> pd<strong class="lq hi">.</strong>read_csv('/Users/chandana/Documents/fakenews.csv')</span></pre><p id="ac2a" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">(这是一个macbook路径，因此如果您使用的是Windows或任何其他操作系统，该路径可能会有所不同。)</p><p id="d7fa" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">数据帧看起来会像这样，</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mm"><img src="../Images/6bf6e333de6224a5798aebe0c76b5bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9VU1NsW_LVY3RHmf_QAjxQ.png"/></div></div></figure><p id="d483" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这里标签表示一篇新闻文章是否是假的，0表示它是真的，1表示它是假的。</p><h2 id="ddac" class="lb jq hh bd jr lc ld le jv lf lg lh jz jb li lj kd jf lk ll kh jj lm ln kl lo bi translated">数据预处理</h2><p id="eb66" class="pw-post-body-paragraph iq ir hh is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn ha bi translated">在导入我们的库和数据集之后，在我们训练ML模型之前预处理数据是很重要的，因为可能会有一些异常和丢失的数据点，这可能会使我们的预测与实际值有些偏差。</p><p id="f668" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在，我们可以检查dataframe/table的大小，因为它将决定我们是否可以在不影响数据集大小的情况下删除具有null值的行。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="5c63" class="lb jq hh lq b fi lu lv l lw lx">data<strong class="lq hi">.</strong>shape</span></pre><p id="3c7e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这给了我们<strong class="is hi"> (20800，5) </strong>，这意味着我们有20800个条目和5列(特性)。</p><p id="8933" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">检查每列中缺失值的总数。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="8022" class="lb jq hh lq b fi lu lv l lw lx">data<strong class="lq hi">.</strong>isnull()<strong class="lq hi">.</strong>sum()  </span></pre><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mn"><img src="../Images/8b60ad302dbf3c1fe2968ed16d0ea1ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EeM2g5SgOZZ9ITB36oFjMQ.png"/></div></div></figure><p id="c3c6" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">从这里我们可以看到，我们将不得不删除至少1957行来删除所有的空值，因此最好用一个空字符串来填充这些空值。为此，我们可以使用<strong class="is hi">菲尔娜。</strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="3aec" class="lb jq hh lq b fi lu lv l lw lx">df1 <strong class="lq hi">=</strong> data<strong class="lq hi">.</strong>fillna('')</span></pre><p id="0efe" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">在这一步之后，我们不再有任何丢失的数据点，您可以使用<em class="jo">T5检查是否为空()。总和()</em></p><p id="543b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在，我们将尝试将这5列减少到只有2列，因为这对我们训练模型来说更容易。为此，我们将把<strong class="is hi">标题</strong>和<strong class="is hi">作者</strong>列合并成一列，命名为<strong class="is hi">内容</strong>。我们可以删除其他栏目，因为它们对确定文章的真伪没有太大影响。这一步将留给我们两列- <strong class="is hi">内容</strong>和<strong class="is hi">标签</strong>。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="52f0" class="lb jq hh lq b fi lu lv l lw lx">df1['content'] <strong class="lq hi">=</strong> df1['author'] <strong class="lq hi">+</strong> ' ' <strong class="lq hi">+</strong> df1['title']</span></pre><p id="c522" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">词干</strong></p><p id="9a1f" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在来看词干部分，它基本上是把一个单词简化成词干的过程，词干附加在后缀、前缀或词根上。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/c37854bfd78c16e83a5afc9953515c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*VxWbot4blW9txDi9RN4h0g.png"/></div><figcaption class="il im et er es in io bd b be z dx">Stemming example</figcaption></figure><p id="b8c4" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">单词的词干可能以有意义的词根结束，也可能不以有意义的词根结束，就像在这个例子中，chang实际上并不意味着改变或任何事情。为了让词根有意义，我们使用了<strong class="is hi">词汇化</strong>。但是对于这个项目来说，词干工作很好。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="9003" class="lb jq hh lq b fi lu lv l lw lx">stemmer <strong class="lq hi">=</strong> PorterStemmer()</span></pre><p id="bcb0" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们为自己创建了一个新的Porter词干分析器，这样我们就可以使用这个函数，而不必每次都显式地键入Porter stemmer()。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="53fc" class="lb jq hh lq b fi lu lv l lw lx"><strong class="lq hi">def</strong> stemming(content):<br/>    stemmed_content <strong class="lq hi">=</strong> re<strong class="lq hi">.</strong>sub('[^a-zA-Z]',' ', content) #1<br/>    stemmed_content <strong class="lq hi">=</strong> stemmed_content<strong class="lq hi">.</strong>lower() #2<br/>    stemmed_content <strong class="lq hi">=</strong> stemmed_content<strong class="lq hi">.</strong>split() #3<br/>    stemmed_content <strong class="lq hi">=</strong> [stemmer<strong class="lq hi">.</strong>stem(word) <strong class="lq hi">for</strong> word <strong class="lq hi">in</strong> stemmed_content <strong class="lq hi">if</strong> <strong class="lq hi">not</strong> word <strong class="lq hi">in</strong> stopwords<strong class="lq hi">.</strong>words('english')] #4<br/>    stemmed_content <strong class="lq hi">=</strong> ' '<strong class="lq hi">.</strong>join(stemmed_content) #5<br/>    <strong class="lq hi">return</strong> stemmed_content #6</span></pre><p id="33bb" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">好，让我们深入研究一下，看看这个函数实际上是做什么的。我将每一行从1到6进行了编号，以便您可以轻松区分不同的代码行，并理解每一行的用法。</p><p id="ed85" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">首先，我们使用<strong class="is hi"> re </strong>包，删除所有不是字母的东西(小写或大写字母)。</p><p id="73b8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">#2然后我们将每个大写字母转换成小写字母。</p><p id="55ea" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">#3然后，我们将每个句子分成一个单词列表。</p><p id="ad42" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">#4然后，我们使用词干分析器对列中存在的每个单词进行词干分析，并删除列表中存在的每个英语停用词。</p><p id="5bc8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">#5然后，我们将所有这些以列表形式出现的单词连接起来，并将它们转换回一个句子。</p><p id="8150" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">#6最后，我们返回经过预处理的词干内容。</p><p id="e0e4" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">将这个函数应用于我们的数据集，</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="430d" class="lb jq hh lq b fi lu lv l lw lx">df1['content'] <strong class="lq hi">=</strong> df1['content']<strong class="lq hi">.</strong>apply(stemming)<br/>df1['content']<strong class="lq hi">.</strong>head()</span></pre><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mp"><img src="../Images/7bf67a68ef85851c35779cd6c0dbbaae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ltp23FVVzjXn5xp6fO-yoA.png"/></div></div></figure><p id="fda8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">下一步是命名我们的输入和输出特性</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="4d2e" class="lb jq hh lq b fi lu lv l lw lx">X <strong class="lq hi">=</strong> df1<strong class="lq hi">.</strong>content<strong class="lq hi">.</strong>values<br/>y <strong class="lq hi">=</strong> df1<strong class="lq hi">.</strong>label<strong class="lq hi">.</strong>values</span></pre><p id="3a34" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们最后的预处理步骤是将文本X转换成数字，这样我们的ML模型就可以理解并使用它。这就是<strong class="is hi">tfidf矢量器</strong>发挥作用的地方。这里有一张简单解释它的图片，</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mq"><img src="../Images/a9fd2066ad5993bf7846bc4930de951c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bIb6yZVX4z5J20Ac4F2S-A.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Source: <a class="ae ip" href="https://becominghuman.ai/word-vectorizing-and-statistical-meaning-of-tf-idf-d45f3142be63" rel="noopener ugc nofollow" target="_blank">https://becominghuman.ai/word-vectorizing-and-statistical-meaning-of-tf-idf-d45f3142be63</a></figcaption></figure><p id="fb1b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">要深入了解，请访问<a class="ae ip" href="https://www.analyticsvidhya.com/blog/2021/11/how-sklearns-tfidfvectorizer-calculates-tf-idf-values/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hi"> <em class="jo">此链接</em> </strong> </a>。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="40f1" class="lb jq hh lq b fi lu lv l lw lx">X <strong class="lq hi">=</strong> TfidfVectorizer()<strong class="lq hi">.</strong>fit_transform(X)<br/>print(X)</span></pre><p id="823b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这段代码的输出应该是这样的，</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mr"><img src="../Images/5e630c69f413b2d02b835b4a54071309.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KTvrRH1daOAzHn-vXjFdGA.png"/></div></div></figure><p id="9747" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在我们有了想要的形式的X，我们可以进入下一步了。</p><h2 id="3a3b" class="lb jq hh bd jr lc ld le jv lf lg lh jz jb li lj kd jf lk ll kh jj lm ln kl lo bi translated">分割数据集</h2><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="9203" class="lb jq hh lq b fi lu lv l lw lx">X_train, X_test, y_train, y_test <strong class="lq hi">=</strong> train_test_split(X, y, test_size <strong class="lq hi">= </strong>0.2, stratify <strong class="lq hi">= </strong>y, random_state <strong class="lq hi">= </strong>2)</span></pre><p id="bd00" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这意味着我们将数据集分成80%作为训练集，20%作为测试集。<em class="jo">分层= y </em>意味着我们已经确保训练测试集的划分具有大约相等的类别分布(0和1或者真实和虚假)。<em class="jo"> random_state = 2 </em>将保证分割始终相同。</p><h2 id="ca4e" class="lb jq hh bd jr lc ld le jv lf lg lh jz jb li lj kd jf lk ll kh jj lm ln kl lo bi translated">训练模型</h2><p id="621e" class="pw-post-body-paragraph iq ir hh is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn ha bi translated">将模型拟合到我们的数据集</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="c0ef" class="lb jq hh lq b fi lu lv l lw lx">model <strong class="lq hi">=</strong> LogisticRegression()</span><span id="5484" class="lb jq hh lq b fi ms lv l lw lx">model<strong class="lq hi">.</strong>fit(X_train, y_train)</span></pre><p id="b1cf" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">既然我们已经训练了它，让我们检查我们的训练集预测的准确性，</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="a749" class="lb jq hh lq b fi lu lv l lw lx">X_train_prediction <strong class="lq hi">=</strong> model<strong class="lq hi">.</strong>predict(X_train)<br/>training_accuracy <strong class="lq hi">=</strong> accuracy_score(X_train_prediction, y_train)<br/>print(training_accuracy)</span></pre><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mt"><img src="../Images/16b81f920025beb98ba272590119096c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zf0jTc0uPbHSSWqll12pEw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Training accuracy score</figcaption></figure><p id="68a3" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">所以我考了98.66%左右，还算不错了。测试数据集也是如此。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="67b0" class="lb jq hh lq b fi lu lv l lw lx">X_test_prediction <strong class="lq hi">=</strong> model<strong class="lq hi">.</strong>predict(X_test)<br/>testing_accuracy <strong class="lq hi">=</strong> accuracy_score(X_test_prediction, y_test)<br/>print(testing_accuracy)</span></pre><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mu"><img src="../Images/f000f4d5c9c2ad960e1066ff5c7f04e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EJDZUAUC2cfNixjw9-IE4A.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Test accuracy score</figcaption></figure><p id="791d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">所以测试精度也相当不错。</p><p id="9b1c" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">(注意:如果您对此代码进行任何更改，分数可能会有所不同)</p><p id="b39b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这样我们就成功地训练了我们的ML模型！</p><h2 id="5866" class="lb jq hh bd jr lc ld le jv lf lg lh jz jb li lj kd jf lk ll kh jj lm ln kl lo bi translated">建立一个系统</h2><p id="7e08" class="pw-post-body-paragraph iq ir hh is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn ha bi translated">最后，为了让这个模型有用，我们需要建立一个系统。从测试集中抽取一个样本(我抽取了第一个样本)，</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="b307" class="lb jq hh lq b fi lu lv l lw lx">X_sample <strong class="lq hi">=</strong> X_test[0]</span></pre><p id="f5f2" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">检查我们对这个样本的预测，</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="6c5f" class="lb jq hh lq b fi lu lv l lw lx">prediction <strong class="lq hi">=</strong> model<strong class="lq hi">.</strong>predict(X_sample)<br/><strong class="lq hi">if</strong> prediction <strong class="lq hi">==</strong> 0:<br/>    print('The NEWS is Real!')<br/><strong class="lq hi">else</strong>:<br/>    print('The NEWS is Fake!')</span></pre><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mv"><img src="../Images/8e48668da6060147c7b9b0fafea7d6e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LaCaaKYBqd_fQ_f74OMmLA.png"/></div></div></figure><p id="9a07" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">有了这个，我们也建立了一个系统。现在，如果你想更进一步，尝试输入一个文本样本，并使用它进行预测。你现在可以拍拍自己的背，因为你现在知道如何只使用逻辑回归检测假新闻文章！！！</p></div><div class="ab cl mw mx go my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ha hb hc hd he"><p id="f9fb" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi"> <em class="jo">参考文献</em> </strong></p><div class="nd ne ez fb nf ng"><a href="https://github.com/chandana-21/ml-projects/blob/main/fake-news-detection/fake-news-detection.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">ml-projects/fake-news-detection . ipynb at main chandana-21/ml-projects</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">在GitHub上创建一个帐户，为chandana-21/ml项目的开发做出贡献。</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">github.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://news.mit.edu/2018/study-twitter-false-news-travels-faster-true-stories-0308" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">研究:在Twitter上，虚假新闻比真实故事传播得更快</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">三名麻省理工学院学者的一项新研究发现，虚假新闻在社交网络Twitter上的传播速度比……</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">news.mit.edu</p></div></div><div class="np l"><div class="nv l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://pubmed.ncbi.nlm.nih.gov/32571950/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">数字媒体素养干预增加了主流和虚假新闻之间的辨别力…</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">对网上流传的错误信息的广泛信仰是现代社会的一个关键挑战。当研究到…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">pubmed.ncbi.nlm.nih.gov</p></div></div><div class="np l"><div class="nw l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://searchbusinessanalytics.techtarget.com/resources/Big-data-analytics" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">大数据分析</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">阅读关于大数据分析的新闻和最佳实践建议。获取管理大数据分析项目的技巧，并了解…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">searchbusinessanalytics.techtarget.com</p></div></div><div class="np l"><div class="nx l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://www.w3schools.com/python/python_regex.asp" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">Python正则表达式</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">正则表达式是构成搜索模式的一系列字符。正则表达式可以用来检查是否…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.w3schools.com</p></div></div><div class="np l"><div class="ny l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="http://nltk.sourceforge.net/corpus.html" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">语料库读者</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">NLTK数据包包括一组不同的语料库，可以使用nltk.corpus包读取。每个语料库…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">nltk.sourceforge.net</p></div></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a" rel="noopener follow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">文本预处理:使用不同的库停止单词删除</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">Python中英文停用词移除的便捷指南！</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">towardsdatascience.com</p></div></div><div class="np l"><div class="nz l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://www.tutorialspoint.com/scikit_learn/scikit_learn_discussion.htm" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">讨论Scikit学习</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">Scikit-learn (Sklearn)是Python中最有用、最健壮的机器学习库。它提供了多种选择…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.tutorialspoint.com</p></div></div><div class="np l"><div class="oa l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://scikit-learn.org/stable/modules/feature_extraction.html" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">6.2.特征抽出</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">注意特征提取与特征选择有很大的不同:前者在于转换任意数据…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">scikit-learn.org</p></div></div><div class="np l"><div class="ob l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://www.bitdegree.org/learn/train-test-split" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">使用Train_test_split函数分割数据集的指南</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">TL；train _ test _ split函数是为了两个不同的目的分割单个数据集:训练和…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.bitdegree.org</p></div></div><div class="np l"><div class="oc l nr ns nt np nu ij ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">medium.com</p></div></div><div class="np l"><div class="od l nr ns nt np nu ij ng"/></div></div></a></div></div></div>    
</body>
</html>
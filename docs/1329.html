<html>
<head>
<title>Titanic XGBoost optimization without feature engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">没有特征工程的巨大XGBoost优化</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/titanic-xgboost-optimization-without-feature-engineering-8639e304ebd9?source=collection_archive---------1-----------------------#2021-11-23">https://medium.com/mlearning-ai/titanic-xgboost-optimization-without-feature-engineering-8639e304ebd9?source=collection_archive---------1-----------------------#2021-11-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8737907afacac1c582faa22e2a56a6c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2ORIjyV-FPQG6_Ke"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@alonsoreyes?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alonso Reyes</a> on <a class="ae it" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2d28" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我认为这个游戏比赛作为初学者的起点是众所周知的。您可以尝试不同的ML模型和方法，并比较结果。这将有助于您了解参数的工作原理，比较它们之间的准确性，并了解结果如何与模型复杂性一起评估。有很多关于如何在“泰坦尼克号”数据集上进行EDA(探索性数据分析)和执行特征工程的文章。尽管如此，最近我得到了一个令人兴奋的任务——在没有任何特征工程的情况下获得高于0.78的分数。我做到了。来看看我是怎么做到的吧！</p><h2 id="ccc3" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">数据准备</h2><p id="ae3d" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">对于boosting模型，我们不需要标准化或缩放数据。增强模型不能“按原样”与文本期货一起工作，所以我们将放弃它们，因为我们不执行任何特征工程。让我们加载数据:</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="d6e8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们加载了数据并删除了不需要的列。在查看“年龄”列时，我们可以看到有一些值缺失。让我们用平均值填充它们(因为在测试中也会有一些缺失值，我们不能简单地删除这些行，因为提交的行数应该是固定的):</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="05ae" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于“幸存”了我们的目标列，我们将特性指定为:</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="1f33" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们可以对我们的分类列执行一键编码:性别、P级、已登机:</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="cc06" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">并对测试数据集进行相同的转换:</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="c038" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以，上面所有代码所做的:</p><ul class=""><li id="6d1d" class="ky kz hh iw b ix iy jb jc jf la jj lb jn lc jr ld le lf lg bi translated">加载的测试和训练数据；</li><li id="d55e" class="ky kz hh iw b ix lh jb li jf lj jj lk jn ll jr ld le lf lg bi translated">用平均值填充缺失的年龄值；</li><li id="9ddf" class="ky kz hh iw b ix lh jb li jf lj jj lk jn ll jr ld le lf lg bi translated">删除了其他列缺少的值；</li><li id="b83d" class="ky kz hh iw b ix lh jb li jf lj jj lk jn ll jr ld le lf lg bi translated">一键编码我们的分类列；</li><li id="feaa" class="ky kz hh iw b ix lh jb li jf lj jj lk jn ll jr ld le lf lg bi translated">指定了正确的数据类型。</li></ul><p id="eedf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的下一步是交叉验证。</p><h2 id="4201" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">交叉验证</h2><p id="f2bd" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">在交叉验证方面，我们应该为我们的模型选择最佳参数。这是一个二元分类任务，所以我们将使用“误差”作为我们的评估指标。它被计算为#(错误情况)/#(所有情况)，并显示了我们的模型的准确性。让我们导入库并从我们的数据创建数据集:</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="a5ea" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们将指定不同的参数，并使用它们运行交叉验证:</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><pre class="ks kt ku kv fd lm ln lo lp aw lq bi"><span id="e191" class="js jt hh ln b fi lr ls l lt lu">[0]	train-error:0.14004+0.01089	test-error:0.19233+0.01700<br/>[10]	train-error:0.12767+0.00648	test-error:0.19459+0.01126<br/>[20]	train-error:0.12317+0.00596	test-error:0.19572+0.01258<br/>[30]	train-error:0.12036+0.00790	test-error:0.19347+0.01385<br/>[40]	train-error:0.11867+0.00790	test-error:0.19235+0.01259<br/>[50]	train-error:0.11530+0.00676	test-error:0.19122+0.01409<br/>[60]	train-error:0.11080+0.00692	test-error:0.19460+0.00967<br/>[70]	train-error:0.10855+0.00552	test-error:0.20023+0.00177<br/>[80]	train-error:0.10630+0.00597	test-error:0.20248+0.00304<br/>[90]	train-error:0.10461+0.00234	test-error:0.20136+0.00596<br/>[99]	train-error:0.10068+0.00484	test-error:0.20586+0.00760</span></pre><p id="8b4a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">培训和考试之间的差别是相当大的。这意味着我们应该给我们的参数增加一些正则化。还有。我们将增加早期停止，以避免过度拟合。</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><pre class="ks kt ku kv fd lm ln lo lp aw lq bi"><span id="eaff" class="js jt hh ln b fi lr ls l lt lu">[0]	train-error:0.31889+0.00824	test-error:0.32507+0.01740<br/>[10]	train-error:0.17323+0.02041	test-error:0.18785+0.01119<br/>[20]	train-error:0.15748+0.00558	test-error:0.18334+0.01363<br/>[25]	train-error:0.15242+0.00881	test-error:0.18672+0.00819<br/>CPU times: user 938 ms, sys: 105 ms, total: 1.04 s<br/>Wall time: 689 ms</span></pre><p id="9138" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">训练和测试之间的差异减小了。您可以使用不同的参数，尤其是看看“max_depth”并尝试几个值。</p><p id="da0e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后我们调整参数甚至更多…</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><pre class="ks kt ku kv fd lm ln lo lp aw lq bi"><span id="1071" class="js jt hh ln b fi lr ls l lt lu">[0]	train-error:0.28291+0.01604	test-error:0.31496+0.01826<br/>[76]	train-error:0.13330+0.00233	test-error:0.18448+0.00967</span></pre><p id="f723" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在测试和训练中的误差减少了，但它们之间的差异有所增加。此外，早期停止回合等于50，它建立76棵树。这是我们交叉验证的最佳结果。</p><h2 id="1aeb" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">训练和预测</h2><p id="08c5" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">我们可以看到早期停止的最佳迭代是76。所以，基本上，这是26次迭代，因为损失没有减少50轮。</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><pre class="ks kt ku kv fd lm ln lo lp aw lq bi"><span id="b4c6" class="js jt hh ln b fi lr ls l lt lu">76</span></pre><p id="5790" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这就是为什么，实际上，我决定写这篇文章。如果我们不为预测指定迭代范围，将使用整个模型来使用预测，模型可能会过拟合。</p><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="049d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这部分代码提交给Kaggle时得分为0.78468。</p><p id="c8dd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当您使用完全相同的参数，但没有“迭代范围”和更新“n估计值”参数时，得分为0.78229。可以是细微差别，但这是排行榜的巨大差别。</p></div><div class="ab cl lv lw go lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ha hb hc hd he"><p id="ff4e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你想查看整个笔记本，请使用这个<a class="ae it" href="https://github.com/varrek/prjct_ml/blob/main/hw8_boosting.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>。它还提供了LightGBM和Catboost提升算法的示例。</p><p id="d429" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其实有人告诉我，没有任何特征工程也有可能得0.79分。如果你成功了，请在评论中告诉我你是如何做到的！</p><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt in mf"/></div></div></a></div></div></div>    
</body>
</html>
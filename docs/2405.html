<html>
<head>
<title>What is Word2Vec?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Word2Vec是什么？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/what-is-word2vec-bf2c5090f0b8?source=collection_archive---------4-----------------------#2022-04-28">https://medium.com/mlearning-ai/what-is-word2vec-bf2c5090f0b8?source=collection_archive---------4-----------------------#2022-04-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7ef7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Word2Vec是用n维向量表示的单词。它从论文<a class="ae jc" href="https://arxiv.org/pdf/1301.3781.pdf" rel="noopener ugc nofollow" target="_blank">向量空间</a>中单词表示的有效估计开始。在这篇论文中，Mikolov等人。根据以下动机提出了两种新方法(跳格法和连续词袋法):</p><ol class=""><li id="31e1" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb ji jj jk jl bi translated">改变传统技术中对单词的处理方式。单词都是像n-gram或单词包这样的技术中的原子单位，它们之间的相似性没有被考虑在内。</li><li id="2479" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">另一个动机是处理方法的数据限制。本文以语音识别中领域相关数据的缺乏为例说明了这种局限性。</li><li id="1619" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">基于神经网络的语言模型明显优于N-gram模型。</li></ol><p id="4bd8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于这些原因，他们认为需要创建更先进的模型来提高NLP任务的质量。在这篇论文之前，我们已经尝试过将单词表示为向量，就像Mikolov在<a class="ae jc" href="http://www.fit.vutbr.cz/research/groups/speech/publi/2009/mikolov_ic2009_nnlm_4.pdf" rel="noopener ugc nofollow" target="_blank">的基于神经网络的高度屈折语言语言模型</a>中所做的那样。在这篇早期的论文中，他们使用简单的模型来学习连续的单词向量，并在这些表示的基础上训练神经网络模型。事实上，word2vec方法可以被认为是这种早期尝试的更完整和成功的版本。这个版本被称为Word2vec，在大多数NLP应用程序中被广泛用作预处理步骤。</p><p id="0363" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">连续词袋法</strong></p><p id="e1d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为Word2Vec表示提出的第一个模型是CBOW模型。一层网络被训练用于单词的表示。对于这个网络，作为一个参数，在一个训练步骤中作为输入的单词数可以由一个“窗口”来确定。窗口从输出字的两边取相同数量的字来创建输入。网络的输入是窗口中单词的一个热矢量表示的总和，真实输出是窗口中间单词的一个热矢量表示。换句话说，对一个单词的邻居进行分类，结果一定是那个单词(也就是很多单词:)。在处理过程中，窗口在单词列表中滑动，其中每个输出单词的权重不变。因此，当训练结束时，我们有与不同单词一样多的权重，这些权重将是输出单词的word2vec表示。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es jr"><img src="../Images/1abac7131cde30b3585e9fe34c4aab95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Miy-v8-3lVkO1D0ZjCiwg.png"/></div></div><figcaption class="kd ke et er es kf kg bd b be z dx">CBOW and Skip-gram models</figcaption></figure><p id="7bf5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">连续跳格模式</strong></p><p id="090b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">CBOW的相同逻辑适用于此，但方式相反。输入是一个热矢量表示的单词，输出是相邻单词的一个热矢量表示的总和。这一次，权重是输入单词的表示形式。</p><p id="a445" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，相似的单词应该有相似的表达。这是根据论文实现的，更重要的是，单词向量的加法和减法给出了有意义的结果。例如，向量(“最大”)-向量(“大”)+向量(“小”)给出的向量与向量(“最小”)的余弦相似度非常接近。作为另一个例子，“法国对巴黎就像德国对柏林”的关系可以通过单词向量之间的相同代数运算来观察。</p><p id="87fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，这种方法被用作NLP应用程序的开始步骤，因此单词首先被转换成数字表示，word 2 vectors。</p><div class="kh ki ez fb kj kk"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kl ab dw"><div class="km ab kn cl cj ko"><h2 class="bd hi fi z dy kp ea eb kq ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kr l"><h3 class="bd b fi z dy kp ea eb kq ed ef dx translated">如何成为移动人工智能的作者</h3></div><div class="ks l"><p class="bd b fp z dy kp ea eb kq ed ef dx translated">medium.com</p></div></div><div class="kt l"><div class="ku l kv kw kx kt ky kb kk"/></div></div></a></div></div></div>    
</body>
</html>
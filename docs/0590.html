<html>
<head>
<title>Training Convolutional Neural Network(ConvNet/CNN) on GPU From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在GPU上从头开始训练卷积神经网络(ConvNet/CNN)</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/training-convolutional-neural-network-convnet-cnn-on-gpu-from-scratch-439e9fdc13a5?source=collection_archive---------0-----------------------#2021-05-22">https://medium.com/mlearning-ai/training-convolutional-neural-network-convnet-cnn-on-gpu-from-scratch-439e9fdc13a5?source=collection_archive---------0-----------------------#2021-05-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="80f6" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">数据集— CIFAR 10 (acc &gt; 75%)</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/1231c3d2322766922dfcbf8afacf690b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IlPCa-H4JueTvWHo"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@jjying?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">JJ Ying</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c085" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在我之前的<a class="ae jm" href="https://gurjeet333.medium.com/training-feed-forward-neural-network-ffnn-on-gpu-beginners-guide-2d04254deca9#e235" rel="noopener">博客</a>中，我开发了一个前馈神经网络来在CIFAR 10数据集上进行训练。作为前向神经网络，在图像数据集上不强大。我们达到了50%的准确率。我将从头构建一个CNN模型，并在CIFAR 10数据集上验证其性能。但在我们开始之前，我将尝试回答几个基本问题。</p><ol class=""><li id="3441" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated"><strong class="jp hi">什么是CNN？<br/> </strong> A <strong class="jp hi">卷积神经网络(ConvNet/CNN) </strong>是一种深度学习算法，它可以接受输入图像，为图像中的各个方面/对象分配重要性(可学习的权重和偏差)，并能够区分它们。与其他分类算法相比，ConvNet中所需的预处理要低得多。</li><li id="ffe4" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">为什么CNN优于前馈神经网络？CNN比FFNN更倾向于理解图像。CNN能够通过应用相关过滤器成功地<strong class="jp hi">捕捉图像中的空间和时间相关性</strong>。<br/>人工神经网络适用于表格和文本数据，而CNN适用于处理图像。</strong></li></ol><h1 id="ac77" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">关于数据集</h1><p id="b967" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">CIFAR-10数据集(加拿大高级研究所)是一个图像集合，通常用于训练机器学习和计算机视觉算法。这是机器学习研究中使用最广泛的数据集之一。CIFAR-10数据集包含10个不同类别的60，000幅32x32彩色图像。这10个不同的类别代表飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。每个类有6000张图片。</p><h1 id="4b58" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">目录</h1><ol class=""><li id="8af4" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated"><a class="ae jm" href="#0598" rel="noopener ugc nofollow">简介</a></li><li id="66bb" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#4a49" rel="noopener ugc nofollow">数据预处理</a> <br/> 2.1 <a class="ae jm" href="#2dae" rel="noopener ugc nofollow">加载所需库</a> <br/> 2.2 <a class="ae jm" href="#8c57" rel="noopener ugc nofollow">获取数据</a></li><li id="aad7" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#e1f7" rel="noopener ugc nofollow">探索CIFAR数据集</a> <br/> 3.1 <a class="ae jm" href="#fc48" rel="noopener ugc nofollow">训练和测试数据集包含多少张图像？</a> <br/> 3.2 <a class="ae jm" href="#6dab" rel="noopener ugc nofollow">数据集包含多少个输出类？</a> <br/> 3.3 <a class="ae jm" href="#7cdf" rel="noopener ugc nofollow">来自数据集的图像张量是什么形状？</a> <br/> 3.4 <a class="ae jm" href="#d680" rel="noopener ugc nofollow">你能确定属于每一类的图像数量吗？</a></li><li id="2d7c" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#eff8" rel="noopener ugc nofollow">准备用于训练的数据</a> <br/> 4.1 <a class="ae jm" href="#becc" rel="noopener ugc nofollow">拆分成训练和验证集</a> <br/> 4.2 <a class="ae jm" href="#2bf8" rel="noopener ugc nofollow">可视化批处理</a> <br/> 4.3 <a class="ae jm" href="#7b6d" rel="noopener ugc nofollow">配置模型</a> <br/> 4.4 <a class="ae jm" href="#5257" rel="noopener ugc nofollow">将模型移动到GPU </a></li><li id="ec87" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#8ed0" rel="noopener ugc nofollow">训练模型</a></li><li id="c722" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#2cd4" rel="noopener ugc nofollow">使用单个图像进行测试</a></li><li id="ac18" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#9771" rel="noopener ugc nofollow">总结</a></li><li id="5858" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#dfdc" rel="noopener ugc nofollow">未来工作</a></li><li id="3359" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#3afd" rel="noopener ugc nofollow">参考文献</a></li></ol><p id="2c74" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果您已经通读了我之前的<a class="ae jm" href="https://gurjeet333.medium.com/training-feed-forward-neural-network-ffnn-on-gpu-beginners-guide-2d04254deca9#e235" rel="noopener">博客</a>，那么您可以跳过前三节，移动第4节，因为数据预处理和探索保持不变。</p><h1 id="0598" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№1:简介</h1><p id="182d" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">CIFAR-10数据集包含10个不同类别的60，000幅32x32彩色图像。CIFAR-10是一组图像，可用于教FFNN如何识别物体。由于CIFAR-10中的图像是低分辨率的(32x32)，这个数据集可以让研究人员快速尝试不同的算法，看看什么有效。</p><p id="eb04" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">CIFAR 10数据集下的类别列表—</p><ol class=""><li id="f696" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">✈️飞机公司</li><li id="a6e2" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">汽车🚗</li><li id="7a3e" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">鸟🐦</li><li id="09ab" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">猫😺</li><li id="b73a" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">鹿🐆</li><li id="320d" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">狗🐶</li><li id="9ac8" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">青蛙🐸</li><li id="9dc9" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">马🐴</li><li id="ae43" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">船🚢</li><li id="ecf6" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">卡车🚚</li></ol><h1 id="4a49" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№2:数据预处理</h1><h2 id="2dae" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">加载所需的库</h2><p id="9a10" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">因为我们用PyTorch来构建神经网络。我一次性导入了所有相关的库。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="8c57" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">检索数据</h2><p id="f469" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">该数据集可在torch视觉库中获得。或者，您也可以从<a class="ae jm" href="https://www.kaggle.com/c/cifar-10" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>访问数据集。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="e1f7" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№3:探索CIFAR10数据集</h1><h2 id="fc48" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:训练和测试数据集包含多少幅图像？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="6dab" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:数据集包含多少个输出类？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="7cdf" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:来自数据集的图像张量的形状是什么？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="d680" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:您能确定属于每个类别的图像数量吗？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="eff8" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№4:为培训准备数据</h1><h2 id="becc" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">分成训练集和验证集</h2><p id="4d88" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">在训练开始之前，将数据分成训练集和测试集是很重要的。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="ee86" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">数据集分为45000个训练集和5000个验证集。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="c76b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们现在可以创建数据加载器来批量加载数据。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="2206" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们使用Torchvision的make_grid helper函数来可视化一批数据。</p><h2 id="2bf8" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">可视化批处理</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="42cc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">你能通过观察给所有的图片贴上标签吗？尝试手动标记数据的随机样本是估计问题难度和识别标记中的错误(如果有的话)的好方法。</p><h2 id="7b6d" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">配置模型</h2><p id="7bf3" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我编写了一个精度函数，通过比较预测类和实际类标签来计算模型精度。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="4416" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我写了一个包含4个函数的<strong class="jp hi"> ImageClassificationBase </strong>类。实现损失和准确性的训练集和验证集各有一个函数。“validation_epoch_end”结合了每个epoch的损失和精度,“epoch_end”在每个epoch结束时打印“<strong class="jp hi"> val_loss </strong>和“<strong class="jp hi"> val_acc </strong>”。</p><p id="8a9f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们将使用<code class="du mn mo mp mq b">nn.Sequential</code>将层和激活功能链接到单个网络架构中。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="5257" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">将模型移动到GPU</h2><p id="f16e" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">在本节中，我们将把我们的模型转移到GPU上。</p><p id="ccf7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们首先检查一下GPU在您当前的系统中是否可用。如果可用，则将默认设备设置为GPU，否则将其设置为CPU。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="f1aa" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我将训练、验证和测试集加载到可用的默认设备上。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="8ed0" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№5:训练模型</h1><p id="7433" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">让我们首先定义输入和输出的大小</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="6ad2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">训练循环的某些部分特定于我们正在解决的特定问题(例如，损失函数、指标等)。)而其他的是通用的，可以应用于任何深度学习问题。</p><p id="805e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们将在一个名为<code class="du mn mo mp mq b">fit</code>的函数中包含与问题无关的部分，该函数将用于训练模型。特定于问题的部分将通过向<code class="du mn mo mp mq b">nn.Module</code>类添加新方法来实现</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="464c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><code class="du mn mo mp mq b">fit</code>函数记录每个时期的验证损失和度量。它返回训练的历史，对调试&amp;可视化很有用。</p><p id="6599" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在没有训练的情况下，val_acc在10%左右。这是随机猜测，预测正确类别的可能性是1/10。</p><p id="3ac9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们现在开始训练</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="6796" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在<strong class="jp hi"> 10个时期</strong>内，模型提供了76 %的<strong class="jp hi">准确度。这是惊人的，也是ANN(又名前馈神经网络)无法实现的。</strong></p><p id="219b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们也定义几个辅助函数来绘制损耗和精度。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="b7cc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">绘制损耗和精确度</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="7427" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">培训和验证损失</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="d160" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">最初，培训和验证损失似乎都随着时间的推移而减少。但是，如果你训练模型的时间足够长，你会注意到训练损失持续减少，而验证损失停止减少，甚至在某个点之后开始增加！</p><p id="a4df" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这种现象被称为<strong class="jp hi">过拟合</strong>，这也是许多机器学习模型在真实世界数据上给出相当糟糕的结果的首要原因。</p><p id="e6ad" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">以下是一些避免过度拟合的常用策略:</p><ul class=""><li id="a892" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki mr kp kq kr bi translated">收集和生成更多的训练数据，或者向其中添加噪声</li><li id="a1a1" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mr kp kq kr bi translated">使用规范化技术，如批量规范化和删除</li><li id="a90d" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mr kp kq kr bi translated">当验证损失开始增加时，提前停止模型的训练</li></ul><p id="8011" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我将在未来的笔记本中实现这些策略，以进一步提高模型的性能。</p><h1 id="2cd4" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№6:使用单个图像进行测试</h1><p id="3eb4" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">从Torchvision库加载测试集</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="9502" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们定义一个辅助函数predict_image，它返回单个图像张量的预测标签。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="3fba" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">检查少数样品的标签和预测值</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="6a06" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在测试集上模拟性能</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="b864" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">嗯，表现好的课有哪些，表现不好的课有哪些:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="25bc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">将来可以进一步分析该模型，以了解为什么少数班级表现不佳。</p><h1 id="9771" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№7:摘要</h1><p id="de8e" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">这里是文章的简要总结和我们在GPU上训练CNN的一步一步的过程。</p><ol class=""><li id="d1dd" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">我们简要了解了CNN神经网络及其优于ANN的优势。</li><li id="1e09" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">从火炬视觉图书馆下载了数据集。</li><li id="6ea9" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们研究了数据集，并试图理解每个类拥有的全部图像、训练和验证集中的全部图像等。</li><li id="4a47" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">训练前的数据准备<br/> i .分成训练集和验证集。<br/>二。我们可视化了一批数据集。<br/>三世。我们做了基本的模型配置，如定义精度、评估和拟合函数。我们还定义了ImageClassificationBase类。<br/>四。我们检查了GPU的可用性，并将数据集移动到GPU，如果可用，则将其移动到CPU。</li><li id="4ada" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们训练了CNN模型，实现了大约76%的<strong class="jp hi">准确率，比ANN的48%</strong>准确率<strong class="jp hi">好得多</strong></li><li id="335f" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们通过在几个测试样本上运行来随机检查模型性能</li></ol><h1 id="dfdc" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№8:未来的工作</h1><ol class=""><li id="8a2c" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated">未来可以通过使用批量标准化、数据增加和减少等正则化技术来提高模型性能</li><li id="6644" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">尝试实现另一个深度学习框架Tensorflow。</li><li id="a753" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">尝试通过更新CNN中的层数、更改优化器和损失函数来提高模型性能。</li></ol><h1 id="3afd" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№9:引用</h1><ol class=""><li id="da53" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated">您可以通过此链接访问并执行完整的笔记本—<a class="ae jm" href="https://jovian.ai/hargurjeet/cnn-cfar-10-dataset" rel="noopener ugc nofollow" target="_blank">https://jovian.ai/hargurjeet/cfar-10-dataset-6e9d9</a></li><li id="711b" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/</a></li><li id="d704" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/docs/stable/generated/torch . nn . crossentropyloss . html</a></li><li id="835b" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans" rel="noopener ugc nofollow" target="_blank">https://jovian . ai/learn/deep-learning-with-py torch-zero-to-gans</a></li></ol><p id="afb4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我真的希望你们能从这篇文章中学到一些东西。请随意给一个👏如果你喜欢你所学的。这让我保持动力。</p><p id="b541" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我将在本周内发表另一篇文章，讨论如何进一步提高CNN神经网络的性能。直到那个时候</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ms"><img src="../Images/59f08c79063b1608632540bdb88e8d64.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/0*H6EkfTfFrL25v70L.jpeg"/></div></figure><h2 id="08e9" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">感谢阅读这篇文章。快乐学习😃</h2></div></div>    
</body>
</html>
<html>
<head>
<title>Obstruction detection and tracking using OpenCV-Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用OpenCV-Python进行障碍物检测和跟踪</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/obstruction-detection-and-tracking-using-opencv-python-ea5838822945?source=collection_archive---------1-----------------------#2022-01-17">https://medium.com/mlearning-ai/obstruction-detection-and-tracking-using-opencv-python-ea5838822945?source=collection_archive---------1-----------------------#2022-01-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0720" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文将讨论一个用例，在这个用例中，我们尝试使用OpenCV-Python，使用对象检测和跟踪算法来检查视频馈送中指定区域内的障碍物。所描述的概念类似于遗弃物体检测的概念，其中我们检测物体并跟踪物体以在延长的时间段内确定静态物体。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jj"><img src="../Images/f4fc9b2e1a840a6414eb71fd762a799c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gaK6Yj9Khq6rE4Jr"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Photo by <a class="ae jz" href="https://unsplash.com/@stayandroam?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Gemma Evans</a> on <a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="5e64" class="ka kb hh bd kc kd ke kf kg kh ki kj kk ip kl km kn it ko kp kq ix kr ks kt ku bi translated">问题陈述</h2><p id="4e3a" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">对于此用例，需要使用视频分析来监控受控空间，并检测通道(如走廊、电梯大厅、紧急出口等)是否有障碍物。在这个用例中，障碍物的定义是相当通用的，它被定义为用于阻塞通路的物体。这些障碍物中的一些在本质上可能是暂时的，因此障碍物必须从空间中移除是有时间限制的。</p><p id="b0bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">视频的主要来源被定义为前提闭路电视。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es la"><img src="../Images/1f53cb402114ceb9783b34b792bf06ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KwbDwOpcvq3iQrkz"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Photo by <a class="ae jz" href="https://unsplash.com/@sharp_shutter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Joe Gadd</a> on <a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="b868" class="ka kb hh bd kc kd ke kf kg kh ki kj kk ip kl km kn it ko kp kq ix kr ks kt ku bi translated">输出量的希望值</h2><p id="6407" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">该解决方案的预期输出是在检测到潜在堵塞时发出警报。</p><h1 id="a617" class="lb kb hh bd kc lc ld le kg lf lg lh kk li lj lk kn ll lm ln kq lo lp lq kt lr bi translated">目标跟踪</h1><p id="8b08" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">在这个项目中，我们将质心跟踪算法应用于我们的输入视频流，以跟踪检测到的对象。本质上，该方法依赖于(1) <em class="ls">现有的</em>对象质心(即，质心跟踪器之前已经看到的对象)和(2)视频中后续帧之间的新对象质心之间的欧几里德距离。</p><p id="60a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是使用openCV库实现的。要进一步了解这个算法，可以参考这个<a class="ae jz" href="https://www.pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/" rel="noopener ugc nofollow" target="_blank">网站</a>。在本文中，我们将使用来自这个<a class="ae jz" href="https://github.com/mailrocketsystems/AIComputerVision" rel="noopener ugc nofollow" target="_blank"> github </a>的脚本。</p><h1 id="75be" class="lb kb hh bd kc lc ld le kg lf lg lh kk li lj lk kn ll lm ln kq lo lp lq kt lr bi translated"><strong class="ak">入门</strong></h1><p id="50af" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">在我们开始之前，必须安装以下库。这可以通过pip或conda完成。</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="7d28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将从为这个用例导入必要的依赖项开始</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="359a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来的几个步骤包括构造参数解析器、解析参数和初始化算法中使用的变量。</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="lt lu l"/></div></figure><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="8759" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jz" href="https://gist.github.com/xictus77/8f879d7b1b6c096bf33f02eae976b315" rel="noopener ugc nofollow" target="_blank">obstruct _ initialize _ var . py</a>的第16行定义了警报产生前检测到的静态障碍物的最大允许持续时间。</p><p id="c2a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意在<a class="ae jz" href="https://gist.github.com/xictus77/8f879d7b1b6c096bf33f02eae976b315" rel="noopener ugc nofollow" target="_blank">的第26–43行中，有一个坐标列表，它在创建的视频中形成了一个多边形或感兴趣的区域。使用</a><a class="ae jz" href="https://github.com/CSAILVision/LabelMeAnnotationTool" rel="noopener ugc nofollow" target="_blank"> LabelMe注释工具</a>可以很容易地获得这个多边形或点，其中多边形在屏幕截图上绘制，然后点以json格式保存。</p><p id="151e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在第41行中，需要将这些点重新缩放到较小的分辨率，如第59和60行中的输出视频所定义的。</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="cb8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还定义了一个名为NMS.py的函数。本质上，这个非最大值抑制函数能够忽略较小的重叠边界框，只返回图像或视频中检测到的对象的较大边界框。即使它们<em class="ls">与</em>重叠，重叠率也不会超过提供的阈值<em class="ls"> 0.3 </em>，该阈值可在下面主代码的<em class="ls">行72 </em>中修改。</p><p id="0812" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在对于<a class="ae jz" href="https://gist.github.com/xictus77/9fd7592764c8b999371ba5bf7ca3dd24" rel="noopener ugc nofollow" target="_blank">主代码</a>。当我们抓取视频输入的第一帧作为基础图像并与视频中的其余帧进行比较时，理想情况下，第一帧应该没有障碍物。感兴趣区域(ROI)也将从初始化阶段的坐标列表中绘制。当我们比较这些帧时，将只显示ROI内的边界矩形，我们还将通过解析最小面积参数来定义对象的最小尺寸。默认大小为500像素。</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="395f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在<a class="ae jz" href="https://gist.github.com/xictus77/9fd7592764c8b999371ba5bf7ca3dd24" rel="noopener ugc nofollow" target="_blank"> main_code_on_detect.py </a>的第122到131行，如果停留时间超过初始化阶段设定的允许时间，将会出现障碍物检测。我们还将保存包含检测到的对象的帧的快照。对象跟踪跟踪对象的质心，只要质心停留在绘制的ROI内，它就会被标记为障碍物。</p><p id="f728" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面显示了代码输出的快照。蓝色细线表示ROI，红色边框表示检测到的障碍物。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es lv"><img src="../Images/26310a4b95ad8a4e78f4ebece4fa2f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kG1f6FgeYzj9cYBs371kZw.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">A snapshot from the sample output showing the obstruction and its dwell time — Source: Author</figcaption></figure><h1 id="77b4" class="lb kb hh bd kc lc ld le kg lf lg lh kk li lj lk kn ll lm ln kq lo lp lq kt lr bi translated">限制</h1><p id="2cf2" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip kx ir is it ky iv iw ix kz iz ja jb ha bi translated">我们在此使用案例中使用启发式方法，因为没有明确指示哪些对象可能是障碍物。因此，我们只能设定一条规则，一旦物体达到一定的尺寸，我们就认为它是一个相当大的障碍物。</p><p id="1247" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们能够获得关于检测到的对象类型的数据，并使用它来训练模型，则在检测后使用对象识别或标识的潜力将会很高。</p><p id="5f52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法的另一个限制是使用第一帧作为基础图像。在视频监控中，我们可能无法确定第一帧，因此需要修改算法以捕捉“空”帧作为基础图像。这种方法也受限于一致的照明，因为它将帧与基础图像进行比较。可以进行进一步的改进，以使用较长时间段内的平均帧，或者使用更高级的帧差分算法来解决这种光照限制。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="9dc4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在这里下载我的完整代码</p><p id="0928" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jz" href="https://github.com/xictus77/obj_detection" rel="noopener ugc nofollow" target="_blank">https://github.com/xictus77/obj_detection</a></p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="aa66" class="lb kb hh bd kc lc lw le kg lf lx lh kk li ly lk kn ll lz ln kq lo ma lq kt lr bi translated">参考</h1><div class="mb mc ez fb md me"><a href="https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">用Python和OpenCV - PyImageSearch实现基本的运动检测和跟踪</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">最后更新于2021年7月8日。那个狗娘养的。我知道他拿走了我最后一瓶啤酒。这些话是一个男人永远不应该说的…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">www.pyimagesearch.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms jt me"/></div></div></a></div><div class="mb mc ez fb md me"><a href="https://www.pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">使用OpenCV - PyImageSearch进行简单的对象跟踪</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">最后更新于2021年7月8日。今天的教程开始了一个新的关于物体跟踪的博客系列，可以说是…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">www.pyimagesearch.com</p></div></div><div class="mn l"><div class="mt l mp mq mr mn ms jt me"/></div></div></a></div><div class="mb mc ez fb md me"><a href="https://github.com/mailrocketsystems/AIComputerVision" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">GitHub-mail rocket systems/AI computer vision:这个项目包含各种计算机视觉和AI…</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">这个项目包含各种计算机视觉和人工智能相关的python脚本链接到完整的播放列表…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">github.com</p></div></div><div class="mn l"><div class="mu l mp mq mr mn ms jt me"/></div></div></a></div><div class="mb mc ez fb md me"><a href="https://github.com/CSAILVision/LabelMeAnnotationTool" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">GitHub-CSAILVision/LabelMeAnnotationTool:label me注释工具的源代码。</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">在这里，您可以找到在服务器上安装LabelMe注释工具的源代码。LabelMe是一个注释工具…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">github.com</p></div></div><div class="mn l"><div class="mv l mp mq mr mn ms jt me"/></div></div></a></div><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mw l mp mq mr mn ms jt me"/></div></div></a></div></div></div>    
</body>
</html>
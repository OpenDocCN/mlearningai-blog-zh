<html>
<head>
<title>Textual Sentiment Analysis with Support Vector Machines — Part 3: Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于支持向量机的文本情感分析第3部分:实现</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/textual-sentiment-analysis-with-support-vector-machines-part-3-implementation-ab10b4a7847d?source=collection_archive---------2-----------------------#2022-10-30">https://medium.com/mlearning-ai/textual-sentiment-analysis-with-support-vector-machines-part-3-implementation-ab10b4a7847d?source=collection_archive---------2-----------------------#2022-10-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="er es hf"><img src="../Images/33bfe618daeedccd1078d02d4ec4cb88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*5bFgc-Lz9cvqB_-PqbT9nw.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Image generated by <a class="ae hq" href="https://stability.ai/blog/stable-diffusion-public-release" rel="noopener ugc nofollow" target="_blank">Stable Diffusion</a></figcaption></figure><div class=""/><p id="697c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这是本系列的第三篇也是最后一篇文章，我们试图建立一个能够对推文进行情感分析的机器学习模型。在前两部分中，我们解释了情感分析，支持向量机如何解决问题，什么是预处理管道，最后，如何在我们的场景中使用它。在这一部分，我们将做一些基本的“探索性数据分析”和“建模”步骤，通过定义需要评估的必要实验。</p><p id="e987" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这是一个由三部分组成的系列，您目前正在阅读第一部分。您可以在下面找到课程:</p><ol class=""><li id="68df" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">第1部分 —向读者介绍情感分析和支持向量机的概念</li><li id="e52e" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae hq" rel="noopener" href="/mlearning-ai/textual-sentiment-analysis-with-support-vector-machines-part-2-data-pre-processing-and-ee45f18083e4">第2部分</a> —解释训练分类器之前所需的数据预处理管道。</li><li id="7ab4" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">第3部分—描述实施步骤，并展示实际结果。</li></ol></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="30c3" class="kj kk ht bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">基本探索性数据分析</h1><p id="c768" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn ha bi translated">探索性数据分析是数据科学流程中的一个非常基础的步骤，我们通过尝试找到模式、异常或收集一些关于数据结构方式的有用见解来彻底调查手头的数据。在我们的例子中，我们有来自文本的“<a class="ae hq" href="https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text" rel="noopener ugc nofollow" target="_blank">情绪检测”数据集，该数据集包含40.000条推文以及以下13种不同情绪中的一种:</a></p><ul class=""><li id="757a" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lm ju jv jw bi translated">愤怒</li><li id="33a4" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“无聊”</li><li id="c752" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">'空'</li><li id="7d1b" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“热情”</li><li id="a215" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“有趣”</li><li id="8aee" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">快乐</li><li id="c899" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“仇恨”</li><li id="dfa2" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“爱”</li><li id="a848" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“中立”</li><li id="bd7b" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“救济”</li><li id="b372" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">悲伤</li><li id="09d7" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“惊喜”</li><li id="2510" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lm ju jv jw bi translated">“担心”</li></ul><p id="2396" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们需要知道的一个重要信息是不同的类在我们的数据集中是如何分布的。这可以通过下面的饼图获得:</p><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es ln"><img src="../Images/f1953dd157a560bfc8e9ae7d5bc98d2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/0*UQ7ArCgoR3heb9Qf"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Class distribution in pie chart</figcaption></figure><p id="6e24" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">马上，我们可以看到，阶级分布相当不平等。例如，只有0.4%的推文中有“无聊”一类，而“中性”和“焦虑”一类的比例最大。绘制同样的绝对值分布图可以更加突出这个问题:</p><figure class="lo lp lq lr fd hj er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/adfd8eb096748bcb84a433eff7122660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P9xFaeuwWFGrfHUf"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Absolute class distribution in bar chart</figcaption></figure><p id="384a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这个问题被称为“阶级不平衡”，一些阶级很少出现，而其他人更频繁。为什么这是一个问题？让我们考虑一个更简单的二进制分类问题，我们需要区分猫的图像。我们的数据集包含100张图片，其中99张是猫，1张不是。如果我们在这个集合上训练一个模型，它注定会失败，因为它看到的“不是猫”实例的数量远远少于对面的类。在这类问题中，一些广泛使用的度量标准可以欺骗我们相信我们的模型完美地工作，而事实上它悲惨地失败了。例如，如果我们在示例集上训练一个模型，它可能会对它收到的每个输入预测“cat”。在这个模型中，如果我们在训练集上计算“准确性”度量，我们将获得99%的准确性！然而，如果我们对50-50的集合计算相同的分数，我们将得到50%的准确度。很明显，不平衡的集合会“扰乱”我们的一些度量标准，并导致无效的结论。</p><p id="bfd6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">如何才能克服这个问题？首先，最好使用一些其他指标来识别问题。可以使用平衡准确度度量来计算每个类别的平均准确度，而不是将它们或F1分数相加。在这一步之后，我们需要找到处理这种异常的方法。有很多方法可以做到这一点，因为我们不想偏离主题，我们将只说我们将使用“SMOTE”方法。SMOTE代表“合成少数过采样技术”,其目标是为少数类创建合成样本，因此最终所有类都是平均分布的。</p><h1 id="e77b" class="kj kk ht bd kl km lx ko kp kq ly ks kt ku lz kw kx ky ma la lb lc mb le lf lg bi translated">韵律学</h1><p id="3bcd" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn ha bi translated">在选择了模型的类型之后，在我们的例子中，我们还必须选择评估的度量。请记住，我们正在处理一个多类问题，所以我们需要确保我们的度量标准能够很好地工作。首先，我们将使用典型的指标，即准确度、平衡准确度、精确度、F1分数和召回率。对于平均步骤，使用“宏”方法(更多详情，请查看<a class="ae hq" href="https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f#989c" rel="noopener" target="_blank">和</a>)。</p><p id="82ab" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">此外，我们还包括了两个在多类问题中广泛使用的度量标准。第一个是“科恩的卡帕系数”，它通过考虑偶然符合的概率来衡量预测结果和实际结果之间的一致性。其值的范围从-1到1，其中[0.6，0.8]的范围表示充分一致，当值大于0.8时，表示几乎完全一致。第二个是“马太相关系数”,它衡量预测值和实际值之间的相关性。同样，其值的范围是从-1到1，其中0表示随机，1表示完全相关，而-1表示逆相关。</p><h1 id="d98d" class="kj kk ht bd kl km lx ko kp kq ly ks kt ku lz kw kx ky ma la lb lc mb le lf lg bi translated">实验</h1><p id="f5e5" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn ha bi translated">为了定义实验，我们应该知道需要调整什么。SVM的主要超参数有三个:内核方法、C和伽马参数。第一篇文章中提到了内核方法。C参数表示我们希望在多大程度上避免样本的错误分类。C的高值会导致对训练集的过度拟合。gamma参数指示单个训练样本的影响程度。对于小值，影响是微不足道的，而对于大值，影响是巨大的。在这两种情况下，结果都被认为是差的。关于超参数的更多细节可以在<a class="ae hq" href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="aacb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">基于这些参数，我们选择了以下实验:</p><ol class=""><li id="e1b2" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">不打，默认SVM</li><li id="9a1b" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">击杀，默认SVM</li><li id="8973" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">Smote，GridSearch με线性核(C = [0.001，0.01，0.1，1，10，100])</li><li id="c247" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">Smote，GridSearch με Poly内核(C = [0.001，0.01，0.1，1，10，100，1000，10000]，degree = [2，3，4])</li><li id="2713" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">Smote，GridSearch με RBF核(C = [0.001，0.01，0.1，1，10，100，1000]，Gamma = [0.0001，0.001，0.01，0.1，1，10，100，1000])</li><li id="4f25" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">Smote，GridSearch με RBF核，窄搜索(C = [8，9，10，20，30，40]，Gamma = [8，9，9.5，10，10.5，11，50])</li><li id="b386" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">Smote，GridSearch με RBF核，更窄的搜索(C = [7，8]，Gamma = [7.2，7.5，7.7，7.9，8])</li></ol><p id="807d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">第一个实验只是为了指出阶级不平衡的问题。从第三次实验开始，我们使用GridSearch寻找最佳配置。本质上，GridSearch在给定的超参数范围内进行搜索，以找到度量方面的最佳解决方案。</p><p id="52d3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">在继续实验之前，我们必须提供SVM处理的类和索引值之间的映射。</p><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mc"><img src="../Images/dae11eff9e6b7bb03b32c7992a02471b.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/0*FTJiporYJYEoNJvV"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Class to index mapping</figcaption></figure><h2 id="84fc" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验1</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mr"><img src="../Images/17020d539299e6293b346401ead06cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/0*JgYsp_GM8aB_u2Gf"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 1st experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/6ae32bf20c9d936a81b190ef9f2fdc7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/0*XoXTZvr8_LOUBa3b"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 1st experiment</figcaption></figure><p id="8a8a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">正如我们所假设的，该模型主要预测索引为8和12的类别，这是最常见的类别(分别为“中性”和“担心”)，而指标则非常低。</p><h2 id="9966" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验二</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mt"><img src="../Images/2cdbbbe8b499d29b9f637129d03e02ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/0*YfbMg_ZyuXZBcD-5"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 2nd experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mu"><img src="../Images/31d357220004fa9e61f2de0599fe985a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/0*G-mTazCE7G7F7j6d"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 2nd experiment</figcaption></figure><p id="25aa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">通过使用SMOTE和默认的SVM配置，结果已经更好，也更有意义。预测更均匀地分布在各个类别中，并且指标开始显示出一些潜力。</p><h2 id="cc95" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验三</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mv"><img src="../Images/2874fce1e1a59c718ebb41c140b8e438.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/0*gRflH7catflaI2At"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 3rd experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mw"><img src="../Images/fc1fbc2f8b2852c44feb13176429bf19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*qAKBHQg-MZb_rWuW"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 3rd experiment</figcaption></figure><p id="538d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最佳模型是C=100的模型。尽管如混淆矩阵所示，分类误差分布更加均匀，但与之前的实验相比，线性核表现不佳。</p><h2 id="1433" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验4</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mx"><img src="../Images/dfba44957f918a86b3c2324002e2b484.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/0*A_8w_yQJepQ5yG_T"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 4th experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es my"><img src="../Images/11e5881b236cc81486c4881a374e7fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/0*qcOpfNk7U5UHlPl0"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 4th experiment</figcaption></figure><p id="7c85" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最佳模型是C=1和度=4的模型。与前两个实验相比，结果相差甚远，因为该模型过于频繁地预测“热情”类别(指数3)。</p><h2 id="9763" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验5</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es mz"><img src="../Images/b318f8157bba33548fe273a4adbbe358.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/0*qLK84g2B_BRhPy3v"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 5th experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es na"><img src="../Images/be58661ca0e7bdd678555bb693dd2363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/0*Mkl_2qsDxGkDJWoC"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 5th experiment</figcaption></figure><p id="f636" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最佳模型是C=10和γ= 10的模型。与“poly”内核相反，这个内核似乎错误分类了索引12，这是初始数据集中最常见的索引之一。但是，它从其他模型中获得了更好的性能，因此，我们决定缩小GridSearch的范围，以实现更好的调优。</p><h2 id="c042" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验6</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es nb"><img src="../Images/c5501813a5128ae4aa16399526648332.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/0*xmw993HYLdSC0BsH"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 6th experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es nc"><img src="../Images/153dcce601a8e68421d763b76cda1513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/0*1aVFUzwbTLaJrKC8"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 6th experiment</figcaption></figure><p id="5411" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最佳模型是C=8和γ= 9的模型。尽管结果相当好，但该模型仍然错误地将推文标记为令人担忧。</p><h2 id="710f" class="md kk ht bd kl me mf mg kp mh mi mj kt jb mk ml kx jf mm mn lb jj mo mp lf mq bi translated">实验7</h2><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es nd"><img src="../Images/f1aaa4dac9123d2865596cf2139c93b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*q3XdbPEkF05O59WCZ8RytQ.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Metrics of 7th experiment</figcaption></figure><figure class="lo lp lq lr fd hj er es paragraph-image"><div class="er es ne"><img src="../Images/c7a716f1c57a90e8e9816e58a97c4f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/0*6sRzE6VXNx0kzf7h"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Confusion matrix of 7th experiment</figcaption></figure><p id="aa5f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">最佳模型是C=7.2和γ= 7.7的模型。同样，结果似乎有所改善，但主要问题依然存在。进一步调整模型似乎无法解决这个问题。</p><h1 id="1491" class="kj kk ht bd kl km lx ko kp kq ly ks kt ku lz kw kx ky ma la lb lc mb le lf lg bi translated">后续步骤</h1><p id="bd93" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn ha bi translated">在这些情况下，你应该尝试改变整个过程的其他部分。一个这样的例子是不同类别的数量。在预处理阶段，我们可以将表达或多或少相同情感的类分组在一起。例如，类“乐趣”和“快乐”，或者类“惊喜”和“热情”可以捆绑在一起。此外，我们可以尝试另一种编码文本的方法。我们使用了TF-IDF方法，但是还有更强大的方法，比如“word2vec”。如果能尝试其中的一些，看看指标是否有任何提升，那就太好了，因为肯定还有改进的空间。整个代码库可以在这里找到<a class="ae hq" href="https://github.com/gkamtzir/svm-sentiment-analysis" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="476c" class="kj kk ht bd kl km lx ko kp kq ly ks kt ku lz kw kx ky ma la lb lc mb le lf lg bi translated">结论</h1><p id="4326" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn ha bi translated">本系列的第三篇也是最后一篇文章到此结束。当你完成这个系列的时候，你会知道什么是情感分析，为什么有人会尝试使用支持向量机，我们如何预处理文本，以及如何从头实现这样一个模型。如果你们中的一些人尝试了我建议的任何后续步骤，或者甚至是其他改变，请随意在这里发表你们的想法，或者在提供的存储库中创建拉请求。直到下一次，继续学习！</p><div class="hg hh ez fb hi nf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hu fi z dy nk ea eb nl ed ef hs bi translated">Mlearning.ai提交建议</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt hk nf"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Face recognition for superimposed facemasks using VGGFace2 in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras中的VGGFace2进行叠加面具的人脸识别</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/face-recognition-for-superimposed-facemasks-using-vggface2-in-keras-c13e610acd56?source=collection_archive---------0-----------------------#2020-11-05">https://medium.com/mlearning-ai/face-recognition-for-superimposed-facemasks-using-vggface2-in-keras-c13e610acd56?source=collection_archive---------0-----------------------#2020-11-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="5451" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用Keras中的VGGFace2对带有叠加面罩的人脸执行人脸识别。这篇文章是上一篇文章- <a class="ae jc" rel="noopener" href="/@xictus77/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">用OpenCV-dlib </a>做面膜的延续。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/a5986427ea11fa191fc867f3e783ab81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xht5zaQI_N0FLJUEV875Dw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jc" href="https://unsplash.com/@zvandrei?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Andrey Zvyagintsev</a> on <a class="ae jc" href="https://unsplash.com/s/photos/masked-face?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a> (Original image edited using <a class="ae jc" rel="noopener" href="/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">face mask overlay</a>)</figcaption></figure><p id="cf3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将尝试使用<em class="jt"> MTCNN(多任务级联卷积网络)</em>对使用OpenCV和dlib库生成的“被掩盖”的人脸进行人脸检测。此后，我们将在Keras中使用<em class="jt"> VGGFace2 </em>对“被掩盖”的面部进行面部识别测试。</p><p id="4174" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还将使用深度学习模型测试我们的“掩蔽”面部，以确定我们的面部“掩蔽”是否成功。不过，那会在另一篇帖子里。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="6886" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><span class="l kz la lb bm lc ld le lf lg di"> F </span> ace识别定义</h1><p id="4748" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">人脸识别是从人脸图像中识别和验证人的过程。根据<em class="jt">《人脸识别手册》</em>，人脸识别主要有两种模式——<em class="jt">人脸验证</em>和<em class="jt">人脸识别</em>。</p><ul class=""><li id="3254" class="lm ln hh ig b ih ii il im ip lo it lp ix lq jb lr ls lt lu bi translated"><strong class="ig hi">人脸验证</strong>。给定人脸与已知身份的一对一映射</li><li id="7d45" class="lm ln hh ig b ih lv il lw ip lx it ly ix lz jb lr ls lt lu bi translated"><strong class="ig hi">人脸识别</strong>。给定人脸与已知人脸数据库的一对多映射</li></ul><h1 id="2e82" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">基于MTCNN的人脸检测</h1><p id="ba53" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">然而，在人脸识别之前，我们需要检测人脸。人脸检测是人脸识别流程中一个重要且必不可少的阶段。正如在<a class="ae jc" rel="noopener" href="/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">上一篇文章</a>中提到的，面部检测可以通过多种方式进行。在本帖中，我们将使用<a class="ae jc" href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html" rel="noopener ugc nofollow" target="_blank"> MTCNN </a>或多任务级联卷积网络对我们的“蒙面”人脸进行人脸检测。它是一种用于人脸检测的现代深度学习模型，在2016年题为<em class="jt"/><a class="ae jc" href="https://arxiv.org/abs/1604.02878" rel="noopener ugc nofollow" target="_blank"><em class="jt">使用多任务级联卷积网络</em></a><em class="jt"/>的论文中进行了描述。这是一个强大的面部检测器，提供高检测分数。</p><h2 id="9d3c" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">了解多任务级联卷积网络</h2><p id="a775" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">MTCNN(多任务级联神经网络)是一种深度学习方法，用于检测图像和视频上的人脸和面部标志。它是作为人脸检测和人脸对齐的解决方案而开发的框架。MTCNN是人脸检测中的一种流行技术，因为它不仅能够在一系列基准数据集上获得最先进的结果，还能够识别其他关键的面部特征，如眼睛和嘴巴，我们称之为面部标志检测。关于面部标志的简要描述，请参考我之前的<a class="ae jc" rel="noopener" href="/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">帖子</a>。</p><p id="7e83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">网络采用三网级联结构；首先，将图像重新缩放到不同大小的范围(称为图像金字塔)，然后第一个模型(建议网络或P-Net)提出候选面部区域，第二个模型(细化网络或R-Net)过滤边界框，第三个模型(输出网络或O-Net)提出面部标志。图1展示了MTCNN的架构。图2显示了级联框架的流水线，包括三级多任务深度卷积网络。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mt"><img src="../Images/ae00c9453a0706f6a2e193c849357a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qzIPjF2EKoL0FOsbh1a7Iw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Figure 1 — MTCNN architecture : P-Net, R-Net, and O-Net [<a class="ae jc" href="https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/372e303ce8f9e62dd365907a97258688.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*4yubqhjXWyaENvbqdK-zJA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Figure 2 — MTCNN pipeline [<a class="ae jc" href="https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><p id="8c70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本帖中，我们将在<a class="ae jc" href="https://github.com/ipazc/mtcnn" rel="noopener ugc nofollow" target="_blank"> ipazc/mtcnn </a>项目中使用由<a class="ae jc" href="https://www.linkedin.com/in/ivandepazcenteno/" rel="noopener ugc nofollow" target="_blank"> Iván de Paz Centeno </a>提供的实现。这可以通过pip安装。(请参考下面的安装部分)</p><h1 id="1ec2" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">入门指南</h1><p id="586d" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">要开始使用这个脚本，<em class="jt">用本文末尾的链接克隆库</em>。</p><h1 id="f081" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">安装所需的软件包</h1><p id="2066" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">建议<a class="ae jc" href="https://towardsdatascience.com/setting-up-python-platform-for-machine-learning-projects-cfd85682c54b" rel="noopener" target="_blank">用Python 3.7制作一个新的虚拟环境</a>，并安装依赖项，使用MTCNN执行<em class="jt">面部检测。</em>其他用于<em class="jt">面部识别</em>的库将在稍后阶段根据需要安装。</p><pre class="je jf jg jh fd mv mw mx my aw mz bi"><span id="6388" class="mf kc hh mw b fi na nb l nc nd"># requirements.txt</span><span id="20fa" class="mf kc hh mw b fi ne nb l nc nd">numpy == 1.19.2<br/>keras == 2.3.1<br/>matplotlib &gt;=  3.3.2<br/>pillow &gt;= 7.2.0<br/>tensorflow == 2.0.0<br/>mtcnn == 0.1.0<br/>opencv-python == 4.4.0.44<br/>pip    &gt;= 20.2.2<br/>python &gt;= 3.7.9</span></pre><p id="e7bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于MTCNN要求使用特定版本的Tensorflow和Keras以及其他外设库，因此按照此<a class="ae jc" href="https://mc.ai/face-detection-using-mtcnn-part-2/" rel="noopener ugc nofollow" target="_blank">链接</a>按照特定步骤安装相关库至关重要。</p><h1 id="1e78" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">导入库</h1><p id="5af8" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">我们将从导入所需的必要库开始:<em class="jt"> numpy，os，</em> <em class="jt"> matplotlib，pillow </em>和<em class="jt"> mtcnn </em>。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nf ng l"/></div></figure><p id="728e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是设置导入图像的目录和路径。已知目录将包含所有被标记的已知人脸。该目录将用于<em class="jt">人脸验证</em>的后续部分。</p><p id="3e16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将创建一个MTCNN人脸检测器类。该检测器将用于检测加载图像中的所有人脸，并提取人脸以供后面部分中的VGGFace人脸检测器模型使用。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nf ng l"/></div></figure><p id="c457" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将继续定义一个函数<em class="jt">extract _ face _ from _ image()</em>，它将从加载的文件名中加载一个图像并返回提取的面部。该函数将检测并返回检测到的人脸列表。<em class="jt">extract _ face _ from _ image()</em>函数将在后期使用，我们需要将检测到的每个人脸与已知数据集进行比较。</p><p id="ef0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来自<em class="jt"> faces </em>(第10行)的结果是一个边界框列表，其中每个边界框定义了边界框的左下角，以及宽度和高度。第14–18行定义了边界框的像素坐标，它们用于提取检测到的面。第23 — 27行定义了如何使用PIL库将提取的人脸图像调整到所需的尺寸:在我们的例子中，模型需要形状为<em class="jt">224×224</em>的正方形输入人脸。</p><p id="5afd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们定义的接下来3个函数— <em class="jt"> highlight_faces()、draw_faces() </em>和<em class="jt"> print_faces() </em>将用于通过MTCNN进行的人脸检测。</p><p id="469a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> highlight_faces() </em>函数为图像中检测到的每个人脸绘制红色边框或矩形。</p><p id="9710" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> draw_faces() </em>函数将提取检测到的面部，并分别绘制每个面部。</p><p id="ac30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> print_faces() </em>功能的主要目的是打印出检测到的人脸数量，然后执行<em class="jt"> highlight_face() </em>功能。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nf ng l"/></div></figure><h1 id="efa0" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">结果</h1><p id="ef8c" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">在我们的测试图像上使用<em class="jt"> print_faces() </em>和<em class="jt"> draw_faces() </em>函数——奥巴马和著名的艾伦的wefie照片产生了以下结果——参见图3和图4。这两个测试图像都叠加了使用我上一篇文章中的脚本绘制的面具——用OpenCV-dlib 叠加面具。</p><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/5e2b55f1f2c7f7f8154ef663a93cfe1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MZBX0yyeZ5HAwi0kGCcFKg.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/26f57b5c14027bd99f1d3306494199a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*I3fR6za53_tPdGGaZHkJhw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 3 — (left image) bounding box drawn with detected “masked” face of Obama using print_face() function | (right image) extracted face from the detected face using draw_face() function</figcaption></figure></div><div class="ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/683cc2883ce03d1df9da1312da4a5cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ljZD3cCHdDZm2-lS6cjEbA.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/49cc1045348c7be5dbbc223ba8e0c5c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9TVzVR3HyOYrcOqx1pGHtA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 4— (left image) bounding box drawn with detected faces of wefie shot using print_face() function | (right image) extracted faces from the detected faces using draw_face() function</figcaption></figure></div><p id="0f25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从所获得的结果来看，很明显，MTCNN检测器在检测和提取遮挡的掩蔽人脸和未掩蔽人脸方面都是成功的。如图4所示，MTCNN不能只检测一个“被屏蔽”的面部，并且在对“被屏蔽”的面部的检测之一中返回两个面部。结果表明，我们可以使用这些函数来检测和提取“被掩盖”的人脸，作为后续部分中VGGFace人脸识别模型的输入。</p><p id="70a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图5到图7提供了使用OpenCV-dlib生成的合成面具脸在3个名人图像上运行这个脚本的更多例子。</p><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/6038f93f63b57b53df1f186866f96d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*RJxBrrTZQZswu8NkXjvW3Q.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/dead344e5cee2da0a4af5ac5845c1a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*aO-NBOmkwFeoD3nc1mU9tQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 5— (left image) bounding box drawn with detected “masked” face of Elton John using print_face() function | (right image) extracted face from the detected face using draw_face() function</figcaption></figure></div><div class="ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/c1111a1613f21adfc6df605453602119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tF2PJ_vrHAT1SMd6Z_9ndQ.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/0862335710be298174b81929e91026ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*hI_TLFNm88VPO--t6Mfxaw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 6— (left image) bounding box drawn with detected “masked” face of Ben Affleck using print_face() function | (right image) extracted face from the detected face using draw_face() function</figcaption></figure></div><div class="ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/b673e70c35d0a981f02e9d1aecb82ab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*G-4QVBfa4qXeTSWL6D3M9g.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/ee4058be4e729ff1d569bcca3e6b6c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FqFyEhxI-v1hijVs4gfHRw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 7— (left image) bounding box drawn with detected “masked” face of Mindy Kaling using print_face() function | (right image) extracted face from the detected face using draw_face() function</figcaption></figure></div><p id="5819" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着使用MTCNN成功检测和提取“被掩盖”的人脸，我们可以继续使用Keras中的<em class="jt"> VGGFace2 </em>执行人脸识别。如前所述，有两种识别模式— <em class="jt">人脸识别</em>和<em class="jt">人脸验证</em>。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="c793" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用VGGFace2执行面部识别</h1><p id="048b" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">在本节中，我们将使用<em class="jt"> VGGFace2 </em>模型对“蒙面”名人的图像执行人脸识别。在深入研究代码之前，我们需要了解什么是VGGFace2。</p><h2 id="6a20" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">了解VGGFace2</h2><blockquote class="nq nr ns"><p id="19c6" class="ie if jt ig b ih ii ij ik il im in io nt iq ir is nu iu iv iw nv iy iz ja jb ha bi translated"><a class="ae jc" href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/" rel="noopener ugc nofollow" target="_blank"> VGGFace2是大规模人脸识别数据集。图片是从谷歌图片搜索下载的，在姿势、年龄、光照、种族和职业方面有很大的差异。</a></p></blockquote><p id="a172" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该数据集包含9131个对象(身份)的331万幅图像，平均每个对象362.6幅图像。整个数据集被分成一个训练集(包括8631个身份)和一个测试集(包括500个身份)。</p><p id="ab8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，VGGFace2已经成为在该数据集上训练的用于人脸识别的预训练模型的同义词。</p><p id="4bfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在数据集上训练了各种模型，特别是ResNet-50和SqueezeNet-ResNet-50模型(称为SE-ResNet-50或SENet)。这些模型和相关代码可以通过<a class="ae jc" href="https://github.com/ox-vgg/vgg_face2" rel="noopener ugc nofollow" target="_blank">链接</a>下载。这些模型在标准人脸识别数据集上进行评估，展示了当时最先进的性能。还提到了基于SqueezeNet的模型总体上提供了更好的性能。</p><p id="4757" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">必须注意，VGGFace2的模型和预训练模型都不能直接用于TensorFlow或Keras库。需要进行转换才能在TensorFlow或Keras中使用它们。必须强调的是，这种转换工作已经完成，可以由第三方项目和库直接使用。我们在Keras中使用的VGGFace2(和VGGFace)模型是Refik Can Malli的<a class="ae jc" href="https://github.com/rcmalli/keras-vggface" rel="noopener ugc nofollow" target="_blank"> keras-vggface项目</a>和库。</p><h2 id="4803" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">安装用于人脸识别的keras-vggface库</h2><p id="abbf" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">该库可以通过pip安装:</p><pre class="je jf jg jh fd mv mw mx my aw mz bi"><span id="cf6a" class="mf kc hh mw b fi na nb l nc nd"># Most Recent One (Suggested)<br/>pip install git+https://github.com/rcmalli/keras-vggface.git<br/># Release Version<br/>pip install keras_vggface</span></pre><p id="26d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其他依赖项也可以通过pip安装:</p><pre class="je jf jg jh fd mv mw mx my aw mz bi"><span id="b097" class="mf kc hh mw b fi na nb l nc nd">keras-applications == 1.0.8<br/>keras-preprocessing == 1.1.0</span></pre><h2 id="d805" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">导入库和定义函数</h2><p id="4383" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">我们将继续导入必要的库，并使用VGGFace2为人脸识别定义新的函数。</p><pre class="je jf jg jh fd mv mw mx my aw mz bi"><span id="013e" class="mf kc hh mw b fi na nb l nc nd">from keras_vggface.utils import preprocess_input<br/>from keras_vggface.utils import decode_predictions<br/>from keras_vggface.vggface import VGGFace</span></pre><p id="f3c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，人脸识别是给定人脸与已知人脸数据库的一对多映射。我们将被要求从包含一个人的图像中只提取一张人脸。</p><p id="1a1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">类似于函数<em class="jt">extract _ face _ from _ image()</em>将从加载的文件名加载图像并返回提取的面部列表，<em class="jt"> extract_face() </em>函数将检测并返回单个面部。提取的面将使用PIL库调整到VGGFace2模型所需的输入尺寸。然后，这个提取的人脸将作为输入传递给<em class="jt"> model_pred() </em>函数，在这里，它将用于与<a class="ae jc" href="https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/" rel="noopener ugc nofollow" target="_blank"> MS-Celeb-1M数据集</a>中的8631个身份列表进行比较。</p><p id="5fcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> model_pred() </em>函数将提取的人脸加载并准备到预训练的模型中，该模型用于预测给定人脸属于八千多个已知名人中的一个或多个的概率。但是，在我们可以用一张脸进行预测之前，像素值必须按照VGGFace模型拟合时准备数据的相同方式进行缩放。具体来说，像素值必须使用训练数据集的平均值位于每个通道的中心。这是通过使用<em class="jt"> keras-vggface </em>库中提供的<em class="jt"> preprocess_input() </em>函数并指定“<em class="jt">version = 2”</em>来实现的，以便使用用于训练VGGFace2模型而不是VGGFace1模型(默认)的平均值来缩放图像。</p><p id="fd92" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用<em class="jt"> VGGFace() </em>构造函数创建预训练模型，并通过“<em class="jt"> model </em>”参数指定要创建的模型类型。见第13行。<em class="jt"> keras-vggface </em>库提供了三个预训练的VGGModels，一个VGGFace1模型通过<em class="jt">model = ' vgg 16 '</em>(默认)，两个VGGFace2模型'<em class="jt"> resnet50' </em>和'<em class="jt"> senet50' </em>。在我们的例子中，我们使用VGGFace2，我们可以选择'<em class="jt"> resnet50' </em>或'<em class="jt"> senet50' </em>。在这篇文章中，我们将使用'<em class="jt"> senet50' </em>。这个Keras模型将被直接用来预测一张给定的脸属于8000多名已知名人中的一个或多个的概率。</p><p id="ade3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给定模型将人脸嵌入预测为2048长度的向量。然后使用<a class="ae jc" href="https://machinelearningmastery.com/vector-norms-machine-learning/" rel="noopener ugc nofollow" target="_blank"> L2向量范数</a>(离原点的欧几里德距离)将向量的长度归一化，例如长度为1或单位范数。这被称为'<em class="jt">面部描述符'</em>。使用余弦相似度计算面部描述符(或称为“主题模板”的面部描述符组)之间的距离。余弦相似性得分越接近，匹配的概率越高。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nf ng l"/></div></figure><p id="bfcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦做出预测，类整数就被映射到名人的名字，通过<em class="jt"> keras-vggface </em>库中的<em class="jt"> decode_predictions() </em>函数可以检索出概率最高的前五个名字。</p><p id="a4a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们定义了<em class="jt"> decoder() </em>函数，它接受<em class="jt"> decode_predictions() </em>函数并打印出前五个概率。</p><p id="5526" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将和三位名人——马特·达蒙、迈克尔·乔丹和奥普拉·温弗瑞一起测试这个模型。这些名人在<a class="ae jc" href="https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/" rel="noopener ugc nofollow" target="_blank"> MS-Celeb-1M数据集</a>的8631个身份列表中。</p><p id="1bae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们图片的来源:马特·达蒙(维基百科)，迈克尔·B·乔丹(维基百科)和奥普拉·温弗瑞(<a class="ae jc" href="https://www.theguardian.com/tv-and-radio/2018/jan/12/oprah-winfrey-unlikely-to-run-for-us-president-but-could-win-if-she-did" rel="noopener ugc nofollow" target="_blank">《卫报》</a>)</p><div class="je jf jg jh fd ab cb"><figure class="nh ji nw nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/9b0e10431dfe8469243e05077e8bee8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*-hBywfnD8gHGdZAEexUa2A.jpeg"/></div></figure><figure class="nh ji nx nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/87380704ea2678f93661fe1c2fcab4c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*C4pNeIe1bYXZgo1wDgZtVw.jpeg"/></div></figure><figure class="nh ji ny nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/a9604e0812cebd4bb69fc2d83bbb874c.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*-yRvz2K6gvk3_B9beaHGRg.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx nz di oa np">Figure 8 — (From Left to Right) Test images of Matt Damon, Michael B. Jordan and Oprah Winfrey</figcaption></figure></div><p id="9ea2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在对原始和“被遮罩”的脸运行face_identity.py之前，我们需要使用我们的脚本叠加合成的面具。</p><h2 id="2828" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">人脸识别的结果</h2><p id="37e2" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">在分别对原始和“遮罩”人脸的每个测试图像运行face_identity.py脚本后，结果如下所示:</p><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><img src="../Images/aea8ababa1d2b391410972102673d4e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*-hBywfnD8gHGdZAEexUa2A.jpeg"/></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><img src="../Images/3bbf7dbaed8961f6eaecdcd458c9e33e.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*wKpGEpokvYvcjhnHW_NXGA.jpeg"/><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 10 — Matt Damon</figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ob"><img src="../Images/46f419cb5e46dc8bfae363d977c3c55d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qkQ4EyeUvuBKcW5NGT7E9w.png"/></div></div></figure><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/98037af776b4e850d24eb8403058a8ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*C4pNeIe1bYXZgo1wDgZtVw.jpeg"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/75f48a9e18330655ce2e5015acd110e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*y2jjlEg063kdS79C6EBvMQ.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 11 — <em class="oc">Michael B. Jordan</em></figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es od"><img src="../Images/a50d479d3c8d00bc18729d2093ad1342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B8vS-ysd_QbqN_1FNfJWGQ.png"/></div></div></figure><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/5473d10e479315ce2ea7721e7d8a1421.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*-yRvz2K6gvk3_B9beaHGRg.jpeg"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/9d28cae8d3d9f72576c7957ade918c1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1wzUFwtkA72Bowkr4WUI0Q.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 11 — <em class="oc">Oprah Winfrey</em></figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es oe"><img src="../Images/e46c5a9ca6e6ce20e23ce008ad87a098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QbZ1oxhcMlzvvEAiVfipnA.png"/></div></div></figure><p id="38a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从结果中，我们可以观察到合成人脸面具的添加不同程度地降低了人脸识别的置信度。预先训练的模型(<em class="jt"> senet50 </em>)能够识别所有三个名人的假面，但是具有不同程度的置信度。这一点在奥普拉·温弗瑞的案例中尤为明显，她的信任度随着“戴面具”从98.8%急剧下降到6.8%。与“蒙面”马特·达蒙和“蒙面”迈克尔·B·乔丹相比，前者的可信度分别下降了10%和40%，该模型在预测奥普拉·温弗瑞戴着“面具”的身份时最没有信心。</p><p id="d0a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这也表明，我的文章中的脚本— <a class="ae jc" rel="noopener" href="/@xictus77/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">使用OpenCV-dlib的人脸面具覆盖图</a>可以成为创建带有人脸面具的人的图像数据集的另一种选择，这些图像数据集可用于训练和评估人脸识别系统。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="8573" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用VGGFace2执行人脸验证</h1><p id="1168" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">在本节中，我们将使用VGGFace2模型进行人脸验证。如前所述，人脸验证是给定人脸与已知身份的一对一映射。我们将被要求从一幅图像中提取所有的人脸，并与另一幅具有已知身份的图像进行比较。</p><p id="89dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这包括计算测试未知人脸的人脸嵌入，并将该嵌入与系统已知人脸的嵌入进行比较。</p><p id="5f79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人脸嵌入是表示从人脸提取的特征的向量。这将用于与其他面生成的矢量进行比较。类似于给定模型预测的人脸嵌入，当两个向量接近时(通过某种度量)，这表明两个人脸可能是同一个人；另一方面，当两个向量相距很远时(通过某种度量)，将显示两个面可能不同(就同一性而言)。</p><p id="9981" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算两个嵌入之间的典型度量，例如欧几里德距离和余弦距离，并且如果距离低于预定义的阈值，则认为面匹配或验证，通常针对特定数据集或应用进行调整。</p><h2 id="84e9" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">导入库和定义函数</h2><p id="b6dd" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">必要的库与人脸识别相同。需要的额外的库是:<em class="jt"> glob </em>和<em class="jt"> SciPy </em>的<em class="jt">余弦</em>函数来计算两个面之间的距离。</p><pre class="je jf jg jh fd mv mw mx my aw mz bi"><span id="f508" class="mf kc hh mw b fi na nb l nc nd">#Additional libraries necessary in face verification<br/>import glob<br/>from scipy.spatial.distance import cosine</span></pre><p id="d278" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们将定义额外的人脸验证函数— <em class="jt"> get_model_scores() </em>和<em class="jt"> compare_face() </em>。</p><p id="f512" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> get_model_scores() </em>函数将提取的人脸作为输入，并返回计算的模型分数。该模型返回一个向量，该向量表示一个或多个面部的特征。与<em class="jt"> model_pred() </em>函数类似，使用<em class="jt"> keras-vggface </em>库中提供的<em class="jt"> preprocess_input() </em>函数准备输入，并指定“<em class="jt">version = 2”</em>，以便使用用于训练VGGFace2模型而非VGGFace1模型(默认)的平均值来缩放图像。</p><p id="053e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们通过将'<em class="jt"> include_top </em>'参数设置为'<em class="jt"> False' </em>，通过'<em class="jt"> input_shape' </em>指定输出的形状，并将'<em class="jt"> pooling' </em>设置为'<em class="jt"> avg' </em>，来加载没有分类器的VGGFace模型，以便使用全局平均池将模型输出端的过滤图简化为向量。然后，该模型将用于进行预测，该预测将返回作为输入提供的一个或多个人脸的人脸嵌入或矢量。</p><p id="77c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于每个人脸的模型分数是向量，我们需要找到两张人脸的分数之间的相似性。如前所述，我们将使用余弦函数来计算相似性，因为人脸的矢量表示适合余弦相似性。余弦函数计算两个向量之间的余弦距离。这个数字越低，两张脸就越匹配。在我们的例子中，我们将把阈值(<em class="jt"> thres_cosine </em>)设置为0.5的距离。该阈值可以改变，并会随着不同使用情况而变化。根据数据集，该阈值可以基于应用进行微调。两个向量或嵌入之间的最大距离是1.0分，这意味着面部完全不同；而最小距离是0.0，这意味着这些面是相同的。用于面部识别的典型截止值在0.4和0.6之间。</p><p id="5f35" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> compare_face() </em>函数取两幅图像的矢量作为输入，比较余弦距离。它返回分数，如果根据余弦分数发现两个人脸相似，则显示这两个人脸。</p><p id="aa23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> face_verification.py </em>脚本的最后一部分在执行时是一个循环，将遍历库(数据集)中的所有已知人脸，并将测试图像中检测到的人脸与这些已知人脸进行比较。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nf ng l"/></div></figure><p id="56c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用奥巴马和乔·拜登的测试图像运行脚本，thres_cosine = 0.5 。与上一节相似，在对原始和“被遮罩”的脸运行<em class="jt"> face_verification.py </em>之前，我们需要使用我们的脚本叠加合成的面具。</p><p id="3051" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图12显示了原始测试图像和在检测到的奥巴马和乔·拜登的面部上叠加了面罩的图像。示出了两个测试图像的结果比较的表格，其中thres_cosine值= 0.5</p><h2 id="29ca" class="mf kc hh bd kd mg mh mi kh mj mk ml kl ip mm mn kp it mo mp kt ix mq mr kx ms bi translated">人脸识别的结果</h2><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/fbfd481b5b8bdeec282e21c386a170f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FAoETJZg9CsJdnrRKMePAw.jpeg"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/0e5107231513e65c2ab3fd3e9000ad9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tz0nqBsMczSwFxFyn08BPg.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 12 — (Left Image) Photo of Joe Biden and Obama (<a class="ae jc" href="https://www.nytimes.com/2019/08/16/us/politics/biden-obama-history.html" rel="noopener ugc nofollow" target="_blank">image extracted from Source</a>) | (Right Image) Photo of Joe Biden and Obama with superimposed face masks</figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es of"><img src="../Images/75b1c0c98d5e55152d47b21079625f91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VE2rhYYkyz8PpeyGhSZwtw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Comparison of results between original image and “masked” faces</figcaption></figure><p id="8345" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从我们上面的结果来看，模型<em class="jt">(‘resnet 50’)</em>能够对原始图像(图12中的左图)中的乔·拜登和奥巴马的身份与已知数据库中的那些图像进行高精度的正确比较和验证。在我们已知的数据库中，有3张乔·拜登的照片和4张奥巴马的照片。乔·拜登的准确率是67%，奥巴马是100%。</p><p id="cbcd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，当我们在检测到的人脸上叠加面罩时(图12中的右图)，乔·拜登和奥巴马的模型精度分别下降了33%和25%。该模型只能正确地比较和验证已知数据库中乔·拜登的三分之一的图像，以及已知数据库中奥巴马的四分之三的图像。图13和14显示了匹配的面作为一个子图一起显示的子图。子图的左图像是从测试图像中提取的面部(被遮掩的面部)，而右图像是从已知数据库中提取的面部。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es og"><img src="../Images/e10b82afa5def65c6f7ab351fa7b70d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*unldboZ0EUuJrICt9xbDkA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Figure 13 — Subplot showing the extracted matched face of test image of masked Joe Biden with known face of Joe Biden in the database directory</figcaption></figure><div class="je jf jg jh fd ab cb"><figure class="nh ji oh nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/1d7d9f761ee1e475e807f2c06a1ec7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Cg9eNtk5m48w18yB8qRFyg.png"/></div></figure><figure class="nh ji oh nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/539cfe18d66624cd1bb79146fdfeae30.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ZxWjhAzODS_hNq74BVgyiA.png"/></div></figure><figure class="nh ji oh nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/66437e18d037e678fb7c3fc9db4e1475.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*HXYW9HzGLyreNcHUIcNSwQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx oi di oj np">Figure 14 — Subplots showing the extracted matched face of test image of masked Obama with known faces of Obama in the database directory</figcaption></figure></div><p id="50d2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以观察到，类似于人脸识别中使用的<em class="jt">‘senet 50’</em>模型，该模型<em class="jt">‘resnet 50’</em>也能够在阈值= 0.5的情况下相当准确地检测和验证被掩盖的人脸。</p><p id="496e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，当使用阈值0.6时，我们将对“伪装”的乔·拜登和奥巴马之间的匹配产生假阳性。图15示出了蒙面的乔·拜登和蒙面的奥巴马的测试图像与数据库目录中的奥巴马的已知面部的提取的匹配面部。还显示了比较分数的结果。</p><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/eef446210afef7e0b30e8839ddbbee69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*lszNzJ8JQDm6dPwJHOF-hA.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/fa8d07f249cd36c6d4dfd9af4025f0af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Cg9eNtk5m48w18yB8qRFyg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 15 — Subplots showing the extracted matched face of test image of masked Joe Biden and masked Obama with a known face of Obama in the database directory</figcaption></figure></div><p id="ce15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt">比较形象……/数据库\奥巴马(1)。jpeg <br/>有匹配！0 0 0.48499590158462524 <br/>有匹配！1 0 0.5521898567676544 </em></p><p id="6347" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从结果来看，两个图像匹配的分数都低于阈值0.6。因此，必须强调的是，还有其他因素，如面部情绪和面部角度，也会影响面部验证系统的准确性。因此，应微调阈值以匹配特定应用。</p><p id="d7be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用相同的模型，我们将使用使用OpenCV-dlib生成的合成面具人脸对3张名人图像[ <a class="ae jc" href="https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset" rel="noopener ugc nofollow" target="_blank">源</a> ]进行人脸验证—参见图5至图7。用于这种情况的阈值是0.6。为了避免结果中的假阳性，我们在多次实验后获得了这个值。</p><p id="50df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从与名人图像的测试图像相同的<a class="ae jc" href="https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset" rel="noopener ugc nofollow" target="_blank">源</a>中选择已知目录或数据库中的图像。</p><p id="8483" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果如图16至18所示。下面的表格显示了原始无遮罩面部和遮罩面部之间的结果。</p><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/63fa1e02d75c84ca58381d632c32ffa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*SFXuMLmhiOCnVXKPf-7LEg.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/603998e0ba7a2b3b3670369e0be9b562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*b6aAJ5QMIdLcpnnqv1EC7Q.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 16— Subplots showing the extracted matched face of test image of masked Ben Affleck with known faces of Ben Affleck in the database directory</figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ok"><img src="../Images/45f87074897852e27fd042b28de43ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q9yE7K17N9H4f2ywS_lbPA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Comparison of results between original image and “masked” face</figcaption></figure><div class="je jf jg jh fd ab cb"><figure class="nh ji oh nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/25a13df8e697f920e18105801b21240a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*uqij0LVHa18kBrweGKyrxw.png"/></div></figure><figure class="nh ji oh nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/40d8348422bc18225b70e1a9b0a22d94.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*eRUY9k59U-Bi4qQ6sjiw6g.png"/></div></figure><figure class="nh ji oh nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/6503549273deb79ddbf60b61155469a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*xtz0rSczYT8O0vdFLxzWgg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx oi di oj np">Figure 17 — Subplots showing the extracted matched face of test image of masked Elton John with known faces of Elton John in the database directory</figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ol"><img src="../Images/6d2840633a008fb6a79fca60746beb2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MqfSYM1d1FiQU5Y0E79YMQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Comparison of results between original image and “masked” face</figcaption></figure><div class="je jf jg jh fd ab cb"><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/848e53b1caa1a1544f831daa297cdf68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*HC-wg9BFLxnPOP3pRpGdNw.png"/></div></figure><figure class="nh ji ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/2f10f535580395a0353039186d582efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mO7F-mj7ze0ZUTyy4d7JdQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx nn di no np">Figure 18 — Subplots showing the extracted matched face of test image of masked Mindy Kaling with known faces of Mindy Kaling in the database directory</figcaption></figure></div><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es om"><img src="../Images/ac2b871caf729fd775848b14d23c7322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HJqbtR4UAdkzV5HlNk8cig.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Comparison of results between original image and “masked” face</figcaption></figure><p id="2226" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以观察到，对于本·阿弗莱克、埃尔顿·约翰和敏迪·卡灵的蒙面人脸，模型在人脸验证中的准确率分别下降了50%、25%和33%。正如前面所强调的以及从上面的结果中观察到的，不存在将两幅图像匹配在一起的通用阈值。随着新数据进入分析，有必要重新定义或微调<em class="jt">阈值</em>值。还观察到，除了合成的人脸面具之外，人脸的情绪和人脸的角度也是确定分数的因素，因此也是确定模型准确性的因素。</p><h1 id="2f5d" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">结论</h1><p id="6674" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">在这篇文章中，我们已经成功地检测到了使用OpenCV和dlib库生成的“蒙面”人脸，使用<em class="jt"> MTCNN(多任务级联卷积网络)</em>和<em class="jt"> </em>在图像中高亮显示它们，以确定模型是否正确工作。此后，我们使用Keras中的<em class="jt"> VGGFace2 </em>对“被掩盖”的面部执行面部识别测试——面部识别和面部验证。<em class="jt"> VGGFace2 </em>算法以矢量形式从人脸中提取特征，并匹配不同的人脸以将它们分组在一起。</p><p id="43dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在名人假面的人脸识别中，预先训练的模型(<em class="jt"> senet50 </em>)能够识别三个名人的假面，但具有不同程度的置信度。</p><p id="c586" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用预先训练的模型(<em class="jt">‘resnet 50’</em>)通过微调阈值，可以使用VGGFace2模型执行面部验证，以确认给定“被掩盖”面部照片的人的身份。人脸的情绪、人脸角度等其他因素也会影响人脸验证系统的准确性。</p><p id="b5bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果还表明，我的文章中的脚本— <a class="ae jc" rel="noopener" href="/@xictus77/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">使用OpenCV-dlib </a>进行面部遮罩叠加可以提供另一种备选解决方案来创建带有面部遮罩的人的图像数据集，这些图像数据集可以用于<strong class="ig hi"> <em class="jt">训练</em> </strong> <em class="jt"> </em>和<strong class="ig hi"> <em class="jt">评估</em> </strong> <em class="jt"> </em>面部识别系统。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="6940" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在这里下载我的完整代码:<a class="ae jc" href="https://github.com/xictus77/Maskedface_verify.git" rel="noopener ugc nofollow" target="_blank">https://github.com/xictus77/Maskedface_verify.git</a></p><h1 id="0375" class="kb kc hh bd kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky bi translated">参考资料:</h1><ol class=""><li id="1298" class="lm ln hh ig b ih lh il li ip on it oo ix op jb oq ls lt lu bi translated"><a class="ae jc" href="https://machinelearningmastery.com/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras/" rel="noopener ugc nofollow" target="_blank">如何在Keras中用VGGFace2进行人脸识别</a></li></ol><p id="0c77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.<a class="ae jc" href="https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/" rel="noopener ugc nofollow" target="_blank">如何用深度学习进行人脸检测</a></p><p id="17e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<a class="ae jc" href="https://mc.ai/face-detection-using-mtcnn-part-2/" rel="noopener ugc nofollow" target="_blank">使用MTCNN的人脸检测(第二部分)</a></p><p id="fb84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.斯坦. z .李和安尼尔. k .贾恩。2011.<i>人脸识别手册</i>(第2期。由…编辑).斯普林格出版公司。</p><p id="13d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.图片来源——开源和<a class="ae jc" href="https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset</a></p><p id="9ab8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6.<a class="ae jc" href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/" rel="noopener ugc nofollow" target="_blank">http://www.robots.ox.ac.uk/~vgg/data/vgg_face2</a></p></div></div>    
</body>
</html>
<html>
<head>
<title>Neural Networks from the beginnings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络从一开始</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/neural-networks-from-the-beginnings-470fbeab0fc8?source=collection_archive---------2-----------------------#2021-08-01">https://medium.com/mlearning-ai/neural-networks-from-the-beginnings-470fbeab0fc8?source=collection_archive---------2-----------------------#2021-08-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/3f9eb731811b7221189d7de6b0372bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*X45kBml43CY4CUmvn3J89g.png"/></div></figure><p id="8847" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在阅读了几本以不同复杂程度处理<strong class="in hi">神经网络</strong>主题的书籍后，我提议为那些希望从头开始理解这个主题，或者更确切地说，从线性回归模型的理解开始的人整理这篇文章(<a class="ae jj" href="https://rorjor.wixsite.com/empoweredatascience/post/riding-a-bicycle-on-the-regression-line" rel="noopener ugc nofollow" target="_blank">在此完成阅读</a>)，我们将在下面快速回顾。</p><p id="8eaa" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">回顾线性回归</strong></p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jk"><img src="../Images/2d49060b06dc85ee612f8696be3b6b76.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*h_PnjERViP2G6lF2P4hD3A.png"/></div></figure><p id="239e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">X =我们的数据集</p><p id="4601" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">x1，x2，x3，… =数据集的每个要素</p><p id="4eae" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">w1，w2，w3，…=权重<em class="jp">(乘以x的变量值)</em></p><p id="774c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">b =偏差<em class="jp">(加到σw * x上的常数值)</em></p><p id="117d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">所以我们有一个值<strong class="in hi"> y </strong>作为函数输出的结果，这是我们对目标值的<strong class="in hi">预测</strong>，我们必须将它与真实值进行比较。这些差异将由旨在最小化该误差的<strong class="in hi">损失函数</strong>进行评估。</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jq"><img src="../Images/516bed635367aaf05679abec6f610efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AH11fnsdgf8cdB_NB4ti5g.png"/></div></div></figure><p id="b877" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="jp">在线性回归中，我们使用最小二乘法找到最佳拟合线，使观测数据的预测误差最小化。</em></p><p id="e548" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好吧，但是这和神经网络有什么关系呢？</p><h1 id="a68f" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">神经网络基础</h1><p id="4340" class="pw-post-body-paragraph il im hh in b io kt iq ir is ku iu iv iw kv iy iz ja kw jc jd je kx jg jh ji ha bi translated"><em class="jp">神经网络</em>是一系列算法，旨在通过试图代表人脑工作方式的过程来识别数据集中的关系。</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es ky"><img src="../Images/0651a93bdc116202d5d0f976cf86edfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dtAddXUdI_fEiV17Osxp7g.png"/></div></div></figure><p id="8453" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="jp">我们用</em> <strong class="in hi"> <em class="jp">线性回归</em> </strong> <em class="jp">函数中的</em> <strong class="in hi"> <em class="jp">人工神经元</em> </strong> <em class="jp">(称为感知器)</em></p><p id="737f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">神经网络的一些特征:</p><ul class=""><li id="c032" class="kz la hh in b io ip is it iw lb ja lc je ld ji le lf lg lh bi translated">它们建立在由一系列人工神经元组成的层的基础上。最少3层(<em class="jp">输入、隐藏和输出层</em>)</li><li id="dc31" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">是多维数组流经的计算图</li><li id="7457" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">是一个通用函数逼近器，可以表示任何监督学习问题的解决方案</li></ul><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es ln"><img src="../Images/1f5be0430aa8de9e0b97de5d03a6990f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTh4Zfq1rP-gJW9s3YKoDQ.png"/></div></div></figure><p id="2923" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好，我们知道隐藏层的每个神经元将对输入值应用线性回归函数，获得其预测值(P)作为输出</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/671dfac2d49f3adb4a85594f0787c23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*0tIpx5_yNgr8OLmphotsXQ.png"/></div></figure><p id="28af" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">到目前为止，我们已经完成了一次<strong class="in hi">向前传球</strong>。</p><p id="6e20" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然后，这些预测值(P)与实际目标值(y)一起，将成为使预测误差最小化的函数的输入。我们称之为<strong class="in hi">损失函数。</strong></p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/9d1f521591e032ad9fdfc4e12fa77df0.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*8E3yY2RWvsFW1ul_V2CtsA.png"/></div></figure><p id="17c0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这种情况下，我们使用<strong class="in hi"> MSE </strong> ( <em class="jp">均方误差</em>)代替LSE ( <em class="jp">最小均方误差</em>)，就像损失函数一样。</p><p id="f9ab" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们有小误差，MSE工作得很好，有助于有效地收敛到最小值，但是对异常值(大误差)很敏感，给它们相对较高的权重(<em class="jp">惩罚</em>)。我们有其他指标，如RMSE或梅。</p><p id="3a86" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">(<em class="jp">为了更好的理解可以使用的损失函数，我推荐</em> <a class="ae jj" rel="noopener" href="/analytics-vidhya/a-comprehensive-guide-to-loss-functions-part-1-regression-ff8b847675d6"> <em class="jp">本帖</em> </a>)</p><p id="818b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">利用我们的损失函数获得的值加上初始权重，我们将必须获得<strong class="in hi">梯度</strong> <strong class="in hi">下降</strong>，这将允许我们重新计算权重，以便获得全局最小值。</p><p id="c9b2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">由梯度重新计算的这些权重将允许在我们称之为<strong class="in hi">反向传递</strong>中更新初始权重。</p><p id="e157" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了可视化梯度下降，想象一个MSE损失函数(y ),目标=0，权重(w)。我们必须得到y (dy)的导数和w (dw)的导数，才能得到斜率。</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/f4db792d4fce26214e5f5c228ec7a919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*wfZWaKl2SkE5H8qblvLwDw.png"/></div></figure><p id="f882" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了前任。:当w大于0时，dy/dw为正。正的dy/dw可以解释为w的正阶跃将导致y的正变化。</p><p id="e545" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了减少损失，需要在w方向上的负阶跃:w' ←负阶跃-w</p><p id="f335" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="jp"> w' = w — (+ (dy/dw) ) </em></p><p id="decd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">而当w小于0时，我们必须做的一个正步骤=&gt; <em class="jp"> w' = w — ( — (dy/dw) ) </em></p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/8f6f932dcee2eef93abb86509d48df0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*xkzyROYMuQ8l0lbbpUos1Q.png"/></div></figure><p id="bfc8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在我们已经通过反向传递更新了我们的权重，我们可以进行新的正向传递，以此类推，直到我们获得一个调整到最优的模型。基本上，我们使用基于梯度的迭代方法来训练回归，以沿着斜坡(<em class="jp">下降</em>)下降到某个最小全局误差水平。</p><p id="91ee" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">训练模型的步骤总结</strong></p><ol class=""><li id="f8a5" class="kz la hh in b io ip is it iw lb ja lc je ld ji ls lf lg lh bi translated">选择一批数据(x，w)</li><li id="395a" class="kz la hh in b io li is lj iw lk ja ll je lm ji ls lf lg lh bi translated">执行模型的<em class="jp">前进</em>行程</li><li id="d409" class="kz la hh in b io li is lj iw lk ja ll je lm ji ls lf lg lh bi translated">使用正向走刀计算的信息，执行模型的<em class="jp">反向</em>走刀</li><li id="aa74" class="kz la hh in b io li is lj iw lk ja ll je lm ji ls lf lg lh bi translated">使用反向传递中计算的梯度来更新权重(在深度学习中也称为<em class="jp">参数</em> <strong class="in hi"> </strong>)</li></ol><p id="dc5e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">学习算法的超参数(调整模型)</strong></p><ul class=""><li id="8a16" class="kz la hh in b io ip is it iw lb ja lc je ld ji le lf lg lh bi translated"><strong class="in hi">批次</strong>:在权重更新之前，模型在<strong class="in hi">时段</strong>中考虑的一个或多个样本</li><li id="98d7" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hi">时期</strong>:由一个或多个批次组成。一个时期意味着数据集的每个样本都有机会更新模型的内部参数(<em class="jp">权重</em>)</li><li id="17d1" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hi">优化器</strong>:用于训练网络的优化算法。您应该找到一组内部模型参数，这些参数在某些性能指标(<em class="jp"> MSE、RMSE等</em>)下表现良好。这个算法叫做<em class="jp">梯度下降</em>，是迭代的，由前面解释的步骤组成。在NN的情况下，使用<strong class="in hi">反向传播</strong>，它训练权重(<em class="jp">更新w </em>)。使用最简单的是SGD ( <em class="jp">随机梯度下降</em>)</li><li id="9394" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hi">学习率</strong>:表示优化算法所走路径的长度。如果值太小，更新会陷入局部最小值，而如果值太大，我们会冒重复跳到全局最小值的风险。</li></ul><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lt"><img src="../Images/2ab6b4dc6d70715bda61373b89af0650.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9HrrBgQpe-4zNPhM0iTPqw.png"/></div></div></figure><p id="61f9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">图片来源:<a class="ae jj" href="https://www.jeremyjordan.me/nn-learning-rate/" rel="noopener ugc nofollow" target="_blank">T15】https://www.jeremyjordan.me/nn-learning-rate/T17】</a></p><p id="3cdc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">批处理和优化器</strong></p><p id="53fe" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一个训练数据集可以分成一批或多批。在<em class="jp">随机GD </em>优化器的情况下，批量测量= 1个样本。</p><p id="c1f4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果测量的是整个数据集，我们将使用<em class="jp">批次GD </em>，如果是&gt; 1并且&lt;整个数据集，我们将使用<em class="jp">迷你批次GD </em>，典型值为32，64，128。</p><h1 id="179d" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">非线性关系</h1><p id="5e08" class="pw-post-body-paragraph il im hh in b io kt iq ir is ku iu iv iw kv iy iz ja kw jc jd je kx jg jh ji ha bi translated">到目前为止，我们已经看到我们的神经网络仅由线性回归函数组成，但是如果我们用于预测的一个或多个最重要的特征具有非线性关系呢？</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/adbc74cf6a54d0bac7c2d370bda14bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*OJqTjCBZneYoBFm2Yt7sEA.png"/></div></figure><p id="434d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">假设我们的数据有这个线性回归函数，这个模型的RMSE是:5.05。如果我们将这个数字除以目标值的平均值，我们可以得到一个预测值(平均)与实际值相差多少的度量。</p><p id="01bc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">y_test均值=24.08，所以5.05/24.08= 21%</p><p id="7524" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">将数据的每个特征换算成平均值0和标准偏差1是很重要的(<em class="jp">标准换算值</em>)，这样做的好处是我们可以将系数的绝对值(<em class="jp">权重</em>)解释为对应于不同特征的重要性(<em class="jp">越大=越重要</em>)</p><p id="cb89" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，假设我们有10个特性，最重要的特性如下图所示:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/f382d8f54419d2078eefd674867151ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*T10eP9K-doGYyc32s4geDw.png"/></div></figure><p id="ecd7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">该特征与目标密切相关，但具有非线性关系。</p><p id="5bf2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，如果我们在模型中只保留线性回归，我们将会丢失学习周期中非常重要的细节。</p><p id="f95f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为此，我们必须建立一个更复杂的模型，包括我们的特征与目标之间的非线性关系。</p><h1 id="669a" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">我们的第一个神经网络</h1><p id="711e" class="pw-post-body-paragraph il im hh in b io kt iq ir is ku iu iv iw kv iy iz ja kw jc jd je kx jg jh ji ha bi translated">在本节中，我们将解释具有单个隐藏层的神经网络，我们将为从波士顿房屋数据集获得的样本数据创建该神经网络(包含在sklearn 中的<em class="jp">)。</em></p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lw"><img src="../Images/b645e1f261debe40e626398c840f7d67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_M2EGCt5zqATKpDDQCauFw.png"/></div></div></figure><p id="b1c4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们的例子中，数据集中有13个特征，所以我们的输入层将有13个输入(<em class="jp"> 1对应每个特征</em>)和一个隐藏层(<em class="jp"> 13个神经元</em>)，有13个输入和明显的13个输出。</p><p id="ef02" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">最后，输出层有13个输入，只有1个输出值。</p><p id="7eab" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">主要思想是，我们将执行许多线性回归，然后我们将通过非线性函数发送结果，最后我们将进行最后一次线性回归，在最后一个实例中进行预测。</p><p id="42e9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">第一步——一系列线性回归</strong></p><p id="264a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们的数据(<em class="jp">输入</em>)有一个[batch_size ( <em class="jp">我们的样本</em>)，num_features (13)]的形状。</p><p id="616d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这里，我们必须将我们的输入乘以维度为[num_features (13)，num_outputs]的权重矩阵，得到维度为[batch_size，num_outputs]的输出。</p><p id="6853" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，对于每个样本，我们有[num_outputs]个不同的原始特征的加权和，将加权和视为一个<strong class="in hi">学习特征</strong>。</p><p id="2cbc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">步骤2 —无线性功能(激活功能)</strong></p><p id="03b1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，通过一个非线性函数，在我们的例子中是一个Sigmoid函数，输入每个加权和。</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/5033b884afdf2a2af611ba1ef79d1c62.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*AhSkwcAoiy_lsQn7KAkMqQ.png"/></div></figure><p id="80f5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> Sigmoid </strong>是神经网络中最常用的激活函数之一。</p><p id="3a1f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">它压缩0和1之间的一些输入，其中大的正值收敛到1，大的负值收敛到0。</p><p id="f7fe" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">有各种激活功能，如ReLU或Tanh。</p><p id="a488" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这一步中，我们使我们的神经网络能够模拟特征和目标之间的非线性关系</p><p id="c2f2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一个神经元的线性回归步骤和非线性激活函数的漂亮视图如下所示:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es ly"><img src="../Images/0443c55857bd610a0a9a5778d6a042fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lvrwm6TPEE2Sh8OidNAktA.png"/></div></div></figure><p id="c3d7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">步骤3 —另一个线性回归</strong></p><p id="2667" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们将获取步骤1和2中构建的层发出的13个值(<em class="jp">线性回归+激活函数。</em>)我们将输入最后一个线性回归，它将给出一个结果值。</p><p id="b394" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">最后，我们将训练我们的第一个神经网络，并评估该指标，以查看它是否提高了相对于线性回归模型的值。</p><p id="75e8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好，我们检查RMSE度规，得到3，67！！，比上一款的5.05要好。</p><p id="5284" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">但是这种改善的原因是什么呢？</p><p id="4f2f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">第一名。通过添加非线性函数，我们允许我们的模型更好地学习最重要的特征</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lz"><img src="../Images/8461c8e7cabf597901808aca160eeedd.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*ZRgGL6itqzJ13K2Kp-1k5Q.png"/></div></div></figure><p id="fc66" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这种关系现在是非线性的，更接近目标。</p><p id="222c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">第二。神经网络可以学习我们的特征和目标之间的组合，不像线性回归模型只学习单个特征。我们的神经网络执行矩阵乘法，并通过结合原始专长创建13个学习特征(<em class="jp">)。</em></p><p id="2c74" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，我们有两项改进:</p><ol class=""><li id="1e54" class="kz la hh in b io ip is it iw lb ja lc je ld ji ls lf lg lh bi translated">学习非线性关系</li><li id="32a2" class="kz la hh in b io li is lj iw lk ja ll je lm ji ls lf lg lh bi translated">学习单个特征的组合与目标之间的关系</li></ol><h1 id="94a6" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">使用Pytorch创建我们的第一个真正的神经网络</h1><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/b21d21a6cf153de98398227345aa9b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*WZahiJsYx9OACQJ2FqnRzg.png"/></div></figure><p id="ad84" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Pytorch是一个非常棒的用于神经网络和深度学习的python库。</p><p id="8c1d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">显然这里我们不会详细解释这个库的特征，所以理解这个库如何工作的主要细节，以及更好地理解张量的任务就留给了读者。</p><p id="d827" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我强烈推荐这本书:<a class="ae jj" href="https://www.manning.com/books/deep-learning-with-pytorch" rel="noopener ugc nofollow" target="_blank">深度学习用Pytorch(曼宁)</a>，尤其是第一部分(<em class="jp">第一章到第八章</em>)。</p><p id="46f1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们从加载数据和缩放数据开始</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/694d502136bc2fb87758d7a7aedc7ef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*qzEde5TuODjiaM2h0xp8cg.png"/></div></figure><p id="07a3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然后，我们将数据分成训练和测试数据集</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es mc"><img src="../Images/b41736f1ed589a943e1b4d580f76cd60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYXY0Qyqt3gK9ubzvqFoBQ.png"/></div></div></figure><p id="f310" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好了，让我们在Pytorch的帮助下开始构建我们的模型的代码。PyTorch能够将模型和层定义为易于使用的对象，这些对象处理向后发送渐变和自动存储参数，只需让它们从<em class="jp"> torch.nn.Module </em>类继承即可。</p><p id="0125" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们将创建一个基类，用一种向前的方法来模拟我们的神经网络，然后我们将创建一个子类来应用我们的<em class="jp">房价预测</em>模型，它将从我们的基类继承。</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es md"><img src="../Images/c1d3651c657a8693aa4d894a7fb15624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dg42gwFv_sX8XtFmdEsL2w.png"/></div></div></figure><p id="4da0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请等一分钟，<strong class="in hi">推理_模式</strong>方法是做什么的？</p><p id="c2da" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一个神经网络可以在已经训练好的模型的训练或者评估模式下执行(<em class="jp">推理</em>，所以Pytorch给了我们<em class="jp"> nn的方法。Module.eval() </em>。因此，推理包括将人工智能在训练中学到的东西付诸实践。此外，在该模式下，我们可以关闭标准化功能，例如<em class="jp">剔除</em>或<em class="jp">批量标准化</em>。</p><p id="5cb6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们的例子中，我们编写了一个没有规范化的简单模型。</p><p id="fe87" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好了，接下来我们的<em class="jp">房价预测</em> NN:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es me"><img src="../Images/134461898489c12e850b39619ebfb493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*9Bprh81OoFb9BeGksmx8nQ.png"/></div></figure><p id="107b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，我们将X数据张量(<em class="jp">和13个特征</em>)传递给第一个线性回归(<em class="jp"> self.fc1 </em>)，然后对其执行一个sigmoid非线性函数(<em class="jp">激活函数</em>)。最后将结果传递给第二个线性回归(<em class="jp">输出层</em>)</p><p id="0464" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们创建了新类的一个对象，并看到了它的结果:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/c3ab87c1ac9389837f46d0e99955ab6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*Bk_O_M_3cC85A6f28LYC1w.png"/></div></figure><p id="31c3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">房价模型(</p><p id="c290" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">(fc1):线性(输入特征=13，输出特征=13，偏差=真)</p><p id="22b2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">(fc2):线性(输入特征=13，输出特征=1，偏差=真)</p><p id="519c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi">)</p><p id="3be7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们创建一个类来训练我们的模型，因此它将有一个<em class="jp"> fit </em>方法，其中NN的学习将在n次迭代(<em class="jp">时期</em>)中执行。另一个需要澄清的问题是，我们已经制作了32个样本的批次(<em class="jp"> _generate_batches方法</em>)，因此由于我们的数据集有354个样本，因此我们将有11个32个样本的批次(<em class="jp"> + 1个仅2个样本的批次</em>)。</p><p id="e723" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">那么这11批中的每批32个样本将用于在每个时期训练模型。同样，在每次迭代之前，数据被混洗(<em class="jp">置换_数据方法</em>)</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es mg"><img src="../Images/4005354c31ce5c391b0a0f830aaba65d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lF63T7pG-LP58HBHbptWYw.png"/></div></div></figure><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es mh"><img src="../Images/fa1bec8d7a8b9f8b804934e4a5e80443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8UlT4Yk26hG_GIhbGkiSaA.png"/></div></div></figure><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es mi"><img src="../Images/aa4198c9edc21bc5ae7ed7a1caa28f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eEjU3xAqBzNIHZ6r8DeoRg.png"/></div></div></figure><p id="f1e9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在运行我们的训练器之前，我们必须创建:</p><ul class=""><li id="17cb" class="kz la hh in b io ip is it iw lb ja lc je ld ji le lf lg lh bi translated">我们NN模型的一个实例(<em class="jp">房价模型</em></li><li id="7a56" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">优化器的一个实例</li><li id="35e6" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">损失函数的一个实例</li><li id="2b7b" class="kz la hh in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">将我们的训练和测试数据转换为张量</li></ul><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es mj"><img src="../Images/291ca2294a55f669796ec535f095fe7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OU3iFqxnLS6eg-AWyUZPOA.png"/></div></div></figure><p id="5865" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们将打印每个时期损失函数的结果。让我们试试我们的训练器，看看它在执行200个纪元后会给我们什么结果:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/f3d64025d8355fcaadffb06a360370db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*cixcwA3MLANN7yrP2-TUcQ.png"/></div></figure><p id="bc2b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们获得了一个更好的MSE度量，与我们的单线性回归模型的25.48相比，为21.30。这看起来并不多，但我们仍然需要通过微调我们的模型来优化我们的神经网络，或者可能添加新的层。</p><p id="279a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好了，伙计们，我希望这是你们理解神经网络的一个好的起点。让我们记住，当我们谈论深度学习时，我们必须至少有两个隐藏层，我们只看到了只有一个模型的构建；当然，这是为了尽可能简化难度。</p><p id="91a9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">神经网络</strong>和<strong class="in hi">深度学习</strong>很棘手，所以慢慢理解每个主题很重要，花时间用代码练习你学习的每一步。</p><p id="e1ac" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">像往常一样，github与完整的<a class="ae jj" href="https://github.com/jrercoli/nn_intro_beginnings" rel="noopener ugc nofollow" target="_blank">神经网络jupyter nb </a>的链接被附上，这样你就可以自己验证代码。</p><p id="aa41" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">感谢您的评论。</p></div></div>    
</body>
</html>
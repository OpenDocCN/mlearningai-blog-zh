<html>
<head>
<title>Building Custom Datasets for PyTorch Deep Learning Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为PyTorch深度学习图像分类构建自定义数据集</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/building-custom-datasets-for-pytorch-deep-learning-image-classification-29989971652d?source=collection_archive---------0-----------------------#2022-11-22">https://medium.com/mlearning-ai/building-custom-datasets-for-pytorch-deep-learning-image-classification-29989971652d?source=collection_archive---------0-----------------------#2022-11-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d6b60e1221e4e55b0b7b20468f447c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E04cgoTUibm4dxpl"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@ravipalwe?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ravi Palwe</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="iu iv iw"><p id="799b" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">在我的其他文章中查看PyTorch在数据集上的完整实现(<a class="ae it" rel="noopener" href="/mlearning-ai/intel-image-classification-with-pytorch-f0f549b70af6">第1部分</a>、<a class="ae it" rel="noopener" href="/mlearning-ai/intel-image-classification-pt2-transfer-learning-with-pre-trained-ensemble-model-in-pytorch-5cf8e5c006e">第2部分</a>)。</p></blockquote><ol class=""><li id="e116" class="jw jx hh ja b jb jc jf jg jy jz ka kb kc kd jv ke kf kg kh bi translated"><strong class="ja hi">简介</strong></li></ol><p id="a8d5" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">在使用MNIS和CIFAR等内置数据集(直接从通用机器学习框架加载)一段时间后，你已经练习构建了你的第一个深度学习图像分类器。以使用自己的数据集为目标是很自然的一步。也许您在工作中有一个非常具体的用例，并希望根据您公司的图像数据库训练一个自定义模型。或者您只是想用从互联网上搜集的图片来实践其他用例。幸运的是，用PyTorch你可以(相当)容易地做到这一点，只要把你的图片整齐地组织在文件夹里。</p><p id="c988" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">本文使用英特尔图像分类数据集，可在<a class="ae it" href="https://www.kaggle.com/datasets/puneet6060/intel-image-classification" rel="noopener ugc nofollow" target="_blank">这里</a>找到。一旦下载，相同类别的图像被分组在以类别命名的文件夹中(例如，“建筑物”、“森林”...)，并且这些类标签在训练集和测试集中是一致的。在实践中，这是将图像组织到文件夹中的一种常见方式，因此可以作为一个很好的样本数据集。在这里，所有东西都放在名为<code class="du ki kj kk kl b">data</code>的父文件夹中，如下图所示。</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es km"><img src="../Images/e8f939bc68c9cedb21fe103be313351b.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/1*FfR9NJFZ0qs_VXLDRyx2EQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">the structure of the Intel dataset</figcaption></figure><p id="8924" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated"><strong class="ja hi"> 2。注释文件准备</strong></p><p id="a61e" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">首先，我们定义包含训练和测试数据的文件夹目录。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="8b4e" class="kv kw hh kl b be kx ky l kz la">train_folder = r'.\data\seg_train'<br/>test_folder = r'.\data\seg_test'</span></pre><p id="de9c" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">为了以后构造自定义数据集，找到一种将图像组织到注释文件中的方法是很有用的，这样我们就可以用它来指示PyTorch某个具有特定名称的图像属于某个特定的类。当然，用相同的类名重命名上面的类文件夹中的所有图像，并用一些数字ID来区分它们是不实际的。因此，我们将使用文件夹名作为类名，图像完整路径将作为图像的唯一地址。</p><p id="adef" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">这可以通过下面的功能<code class="du ki kj kk kl b">build_csv</code>来完成。每个步骤的解释都包含在注释中。本质上，该函数首先将列标签写入一个空白的csv文件，然后遍历指定目录中的每个文件夹(例如，training文件夹)并获取子文件夹名称作为类名。然后，所有图像的完整路径及其对应的类名(和索引)被逐行写入csv文件。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="9032" class="kv kw hh kl b be kx ky l kz la">def build_csv(directory_string, output_csv_name):<br/>    """Builds a csv file for pytorch training from a directory of folders of images.<br/>    Install csv module if not already installed.<br/>    Args: <br/>    directory_string: string of directory path, e.g. r'.\data\train'<br/>    output_csv_name: string of output csv file name, e.g. 'train.csv'<br/>    Returns:<br/>    csv file with file names, file paths, class names and class indices<br/>    """<br/>    import csv<br/>    directory = directory_string<br/>    class_lst = os.listdir(directory) #returns a LIST containing the names of the entries (folder names in this case) in the directory.<br/>    class_lst.sort() #IMPORTANT <br/>    with open(output_csv_name, 'w', newline='') as csvfile:<br/>        writer = csv.writer(csvfile, delimiter=',')<br/>        writer.writerow(['file_name', 'file_path', 'class_name', 'class_index']) #create column names<br/>        for class_name in class_lst:<br/>            class_path = os.path.join(directory, class_name) #concatenates various path components with exactly one directory separator (‘/’) except the last path component. <br/>            file_list = os.listdir(class_path) #get list of files in class folder<br/>            for file_name in file_list:<br/>                file_path = os.path.join(directory, class_name, file_name) #concatenate class folder dir, class name and file name<br/>                writer.writerow([file_name, file_path, class_name, class_lst.index(class_name)]) #write the file path and class name to the csv file<br/>    return<br/><br/>build_csv(train_folder, 'train.csv')<br/>build_csv(test_folder, 'test.csv')<br/>train_df = pd.read_csv('train.csv')<br/>test_df = pd.read_csv('test.csv')</span></pre><p id="ffc4" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">在定义了这个助手函数之后，我们创建了两个csv注释文件，一个用于训练，一个用于测试。然后，它们作为两个数据帧重新导入到下游步骤中。输出csv看起来像这样。</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/9c9f064e3bf85d4e031a55da2e105641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*S4v1GOatF1WFkBJYv25VEg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Annotaion CSV file</figcaption></figure><p id="00a3" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">如果更方便的话，可以考虑直接从函数中返回dataframe。如果您想将数据和注释文件传递到其他地方，使用csv只是提供了更多的便利，编写csv文件似乎比使用Pandas dataframes更简单。</p><p id="b55b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">请注意，我们故意写入图像文件的完整路径，因为稍后需要将图像加载到dataset类中。</p><p id="8bc6" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">另一个重要的注意事项是在函数中类列表的排序中突出显示为<code class="du ki kj kk kl b">IMPORTANT</code>。这个步骤是必要的，因为由<code class="du ki kj kk kl b"> os.listdir</code>产生的类列表是任意的，并且当应用于训练和测试集时可以产生不同的顺序，因此列表中的类的索引在训练和测试数据集之间可能不一致。</p><p id="416c" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">为了谨慎起见，我们可以压缩类名和索引，然后在训练数据集和测试数据集之间进行比较。正如您所看到的，类名和它们的索引在这两个集合中是一致的。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="7c14" class="kv kw hh kl b be kx ky l kz la">class_zip = zip(train_df['class_index'], train_df['class_name'])<br/>my_list = []<br/>for index, name in class_zip:<br/>  tup = tuple((index, name))<br/>  my_list.append(tup)<br/>unique_list = list(set(my_list))<br/>print('Training:')<br/>print(sorted(unique_list))<br/>print()<br/><br/>class_zip = zip(test_df['class_index'], test_df['class_name'])<br/>my_list = []<br/>for index, name in class_zip:<br/>  tup = tuple((index, name))<br/>  my_list.append(tup)<br/>unique_list = list(set(my_list))<br/>print('Testing:')<br/>print(sorted(unique_list))</span></pre><p id="b5a2" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">输出显示类名和索引是一致的。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="53da" class="kv kw hh kl b be kx ky l kz la">Training:<br/>[(0, 'buildings'), (1, 'forest'), (2, 'glacier'), (3, 'mountain'), (4, 'sea'), (5, 'street')]<br/><br/>Testing:<br/>[(0, 'buildings'), (1, 'forest'), (2, 'glacier'), (3, 'mountain'), (4, 'sea'), (5, 'street')]</span></pre><p id="6ace" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">最后，我们可以取出训练或测试数据集中的类名(最好是训练集，因为它应该包含所有的类)作为最终的引用。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="5ef2" class="kv kw hh kl b be kx ky l kz la">class_names = list(train_df['class_name'].unique())<br/>['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']</span></pre><p id="af4a" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated"><strong class="ja hi"> 3。创建定制的培训和测试数据集</strong></p><p id="5340" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">在处理完注释文件之后，我们将使用<code class="du ki kj kk kl b">torch.utils.data</code>中的<code class="du ki kj kk kl b">Dataset</code>类构建定制的训练和测试数据集。从文档教程(<a class="ae it" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" rel="noopener ugc nofollow" target="_blank">链接</a>)，<code class="du ki kj kk kl b">Dataset</code>是一个表示数据集的抽象类。为了构建一个定制数据集，我们应该继承<code class="du ki kj kk kl b">Dataset</code>本身并覆盖它的方法来定制我们的用例。</p><p id="2259" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">同样，每个步骤的解释都包含在注释中。总之，我们将向<code class="du ki kj kk kl b">__init__</code>方法传递两个重要的参数:注释csv文件和图像转换(稍后将详细介绍图像转换)。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="5426" class="kv kw hh kl b be kx ky l kz la">class IntelDataset(torch.utils.data.Dataset): # inheritin from Dataset class<br/>    def __init__(self, csv_file, root_dir="", transform=None):<br/>        self.annotation_df = pd.read_csv(csv_file)<br/>        self.root_dir = root_dir # root directory of images, leave "" if using the image path column in the __getitem__ method<br/>        self.transform = transform<br/><br/>    def __len__(self):<br/>        return len(self.annotation_df) # return length (numer of rows) of the dataframe<br/><br/>    def __getitem__(self, idx):<br/>        image_path = os.path.join(self.root_dir, self.annotation_df.iloc[idx, 1]) #use image path column (index = 1) in csv file<br/>        image = cv2.imread(image_path) # read image by cv2<br/>        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert from BGR to RGB for matplotlib<br/>        class_name = self.annotation_df.iloc[idx, 2] # use class name column (index = 2) in csv file<br/>        class_index = self.annotation_df.iloc[idx, 3] # use class index column (index = 3) in csv file<br/>        if self.transform:<br/>            image = self.transform(image)<br/>        return image, class_name, class_index</span></pre><p id="be93" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">最终结果是，对于定制类的每个实例，我们将拥有转换后的图像本身，以及根据上面准备的注释文件的相应类名和索引。</p><p id="907b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">注意，在这里，我们使用完整的图像路径来读取CV2的图像。使用CV2时，需要注意的是，它以蓝-绿-红(BGR)的顺序读取图像像素阵列，而不是正常的RGB顺序。因此，对于使用RGB的下游步骤，包括从BGR到RGB的转换。更多关于CV2及其与PIL的比较可以在下面的链接中找到。</p><div class="lc ld ez fb le lf"><a href="https://towardsdatascience.com/image-processing-opencv-vs-pil-a26e9923cdf3" rel="noopener follow" target="_blank"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hi fi z dy lk ea eb ll ed ef hg bi translated">图像处理— OpenCV与PIL</h2><div class="lm l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">利用Python库从图像中提取信息！</h3></div><div class="ln l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">towardsdatascience.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt in lf"/></div></div></a></div><p id="394d" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">另一个注意事项是，我们将保留“root_dir”参数为空(空字符串),因为我们已经在注释文件中存储了图像完整路径。</p><p id="e9c8" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">因此，您可以看到，准备一个好的注释文件有助于将我们需要的所有东西整齐地放在适当的位置。</p><p id="ea8a" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">现在，我们已经完成了构建我们自己的数据集的必要步骤。让我们从上面的类中创建一个未转换的样本训练数据集，并在迭代数据集中可视化一些随机图像及其类名和索引。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="6c26" class="kv kw hh kl b be kx ky l kz la">#test dataset class without transformation:<br/>train_dataset_untransformed = IntelDataset(csv_file='train.csv', root_dir="", transform=None)<br/><br/>#visualize 10 random images from the loaded dataset<br/>plt.figure(figsize=(12,6))<br/>for i in range(10):<br/>    idx = random.randint(0, len(train_dataset_untransformed))<br/>    image, class_name, class_index = train_dataset_untransformed[idx]<br/>    ax=plt.subplot(2,5,i+1) # create an axis<br/>    ax.title.set_text(class_name + '-' + str(class_index)) # create a name of the axis based on the img name<br/>    plt.imshow(image) # show the img</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/a11f5dc69819b79fe7c23d9020c6e307.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HPZJ3L8LTTzP35h54RT9Sg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">untransformed_sample_images</figcaption></figure><p id="cdf4" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated"><strong class="ja hi"> 4。图像变换</strong></p><p id="9979" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">图像分类任务的常见做法是变换输入图像。变换是将图像在大小、形状、像素范围等方面从一种形式转换成另一种形式的行为。，同时保持基本的图像信息基本不变。理想情况下，这是为了增加分类器的鲁棒性，因为它暴露于同一图像类的许多变化，而不仅仅是“好看”的图像。</p><p id="0811" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">一个重要的步骤是将图像阵列信息转换成张量。这是PyTorch使用的数据格式，而不是numpy或PIL数组。最终的张量数组将是通道*高度*宽度(C * H * W)的形式，而不是原始的(H * W * C)。因此，如果我们想形象化一幅图像，就用“置换”来恢复顺序。</p><p id="f18a" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">我们将使用的另一个重要转换步骤是规范化。如您所知，普通24位彩色图像的通道具有从0到255 (8位)的强度范围，不同图像之间的分布可能非常不同。通过将它们标准化(通常在0到1的范围内)，训练会遇到不太频繁的非零梯度，从而导致更快的学习。关于规范化和其他常见转换技术的更多信息可以在下面的链接中找到。</p><p id="7e4b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated"><a class="ae it" href="https://inside-machinelearning.com/en/why-and-how-to-normalize-data-object-detection-on-image-in-pytorch-part-1/" rel="noopener ugc nofollow" target="_blank">https://inside-machine learning . com/en/why-and-how-to-normalize-data-object-detection-on-image-in-py torch-part-1/</a></p><div class="lc ld ez fb le lf"><a href="https://towardsdatascience.com/improves-cnn-performance-by-applying-data-transformation-bf86b3f4cef4" rel="noopener follow" target="_blank"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hi fi z dy lk ea eb ll ed ef hg bi translated">通过应用数据转换提高CNN性能</h2><div class="lm l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">PyTorch和Torchvision中的一项实验，旨在提高您在计算机视觉中的神经元网络性能</h3></div><div class="ln l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">towardsdatascience.com</p></div></div><div class="lo l"><div class="lv l lq lr ls lo lt in lf"/></div></div></a></div><p id="0d9d" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">在PyTorch中，<code class="du ki kj kk kl b">torchvision.transforms</code>模块中提供了常用的图像变换方法。可以使用<code class="du ki kj kk kl b">Compose</code>将多个变换步骤(如调整大小、增大和规格化)链接在一起。现在，让我们创建转换管道，然后在数据集类<code class="du ki kj kk kl b">transform</code>参数中使用它，并可视化一些结果图像。</p><pre class="kn ko kp kq fd kr kl ks bn kt ku bi"><span id="272e" class="kv kw hh kl b be kx ky l kz la"># create a transform pipeline<br/>image_transform = transforms.Compose([<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),<br/>    transforms.Resize((224, 224), interpolation=PIL.Image.BILINEAR)<br/>])<br/>#create datasets with transforms:<br/>train_dataset = IntelDataset(csv_file='train.csv', root_dir="", transform=image_transform)<br/>test_dataset = IntelDataset(csv_file='test.csv', root_dir="", transform=image_transform)<br/><br/>#visualize 10 random images from the loaded transformed train_dataset<br/>plt.figure(figsize=(12, 6))<br/>for i in range(10):<br/>    idx = random.randint(0, len(train_dataset))<br/>    image, class_name, class_index = train_dataset[idx]<br/>    ax=plt.subplot(2,5,i+1) # create an axis<br/>    ax.title.set_text(class_name + '-' + str(class_index)) # create a name of the axis based on the img name<br/>    #The final tensor arrays will be of the form (C * H * W), instead of the original (H * W * C), <br/>    # hence use permute to change the order<br/>    plt.imshow(image.permute(1, 2, 0)) # show the img</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/053df5c24453e7fb78976c55e5110f1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lmfkDhYOg7wEmRo5Vb1NA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">transformed_sample_images</figcaption></figure><p id="a5f8" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">您可以看到这些图像看起来比原始版本“更暗”，因为亮度值现在介于0和1之间，而不是0和255之间。</p><p id="ca2d" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated"><strong class="ja hi"> 5。结论</strong></p><p id="146b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jy jk jl jm ka jo jp jq kc js jt ju jv ha bi translated">至此，我们已经完成了为训练CNN模型构建自定义数据集的工作。请继续关注我未来关于如何构建<code class="du ki kj kk kl b">Dataloader</code>的文章，并使用它将图像馈送到模型训练，以及迁移学习/整体迁移学习。</p><div class="lc ld ez fb le lf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hi fi z dy lk ea eb ll ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lm l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ln l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">medium.com</p></div></div><div class="lo l"><div class="lw l lq lr ls lo lt in lf"/></div></div></a></div></div></div>    
</body>
</html>
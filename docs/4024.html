<html>
<head>
<title>Architecture for extracting MCQ questions from text using Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用转换器从文本中提取MCQ问题的体系结构</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/architecture-for-extracting-mcq-questions-from-text-using-transformers-5953e174b488?source=collection_archive---------0-----------------------#2022-11-26">https://medium.com/mlearning-ai/architecture-for-extracting-mcq-questions-from-text-using-transformers-5953e174b488?source=collection_archive---------0-----------------------#2022-11-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="242e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在开发变压器之后，与RNN-LSTM的早期方法相比，序列到序列(seq2seq)生成任务变得更加容易和准确。</p><p id="cd37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我将展示一个架构，它可以使用基于转换器的模型，如T5，BERT，BART，从自由文本中提取MCQ类型的问题</p><p id="08f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">部分变压器型号概述</strong>:</p><ol class=""><li id="1ad1" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated"><strong class="ig hi"> T5 </strong> —代表“<strong class="ig hi">文本到文本转换变压器</strong>，其架构类似于原始变压器的架构，由编码器和解码器两部分组成。这是由谷歌建造的。</li><li id="7298" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi"> BERT </strong> —代表“变压器的<strong class="ig hi">双向编码器表示”，是原变压器的改进版本，仅由编码器部分组成。</strong></li><li id="f73c" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi"> BART </strong> —代表“<strong class="ig hi">双向自回归变换器</strong>”，是一种同时采用BERT(编码器-双向)&amp; GPT-2(解码器-自回归)的模型。它类似于t5架构。</li></ol><p id="e500" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些是一些可以用来从文本中提取MCQ问题的模型。</p><p id="a048" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">MCQ问题提取架构:</strong></p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es jq"><img src="../Images/d08f0e358a8bd6112b3ca0b163f55279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*-WHZmrs0_gHBmtBe3ZaNqQ.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx">Proposed architecture</figcaption></figure><p id="7d99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是对架构的简要描述:</p><h1 id="b93a" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">1.文本摘要</h1><p id="1722" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lc ir is it ld iv iw ix le iz ja jb ha bi translated">第一步是总结段落，以消除复杂性和删除不必要的单词，但保持原始内容的意义。在这里，我们可以使用来自拥抱脸的任何基于摘要的模型，在这个架构中，我们使用了基于BART的预训练模型。</p><h1 id="b545" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">2.关键词提取</h1><p id="b53f" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lc ir is it ld iv iw ix le iz ja jb ha bi translated">第二步是找到关键词，这些关键词将是我们将要提出的问题的真实答案。这里我们使用了python密钥提取器库。</p><h1 id="8d57" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">3.干扰物的产生(错误的选择)</h1><p id="54e4" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lc ir is it ld iv iw ix le iz ja jb ha bi translated">第三步是产生干扰物，即MCQs的错误答案。为此，使用了上下位词的概念。请参考下图，了解更多相关信息。我们已经使用了<strong class="ig hi"> wordnet </strong>字典，但是<strong class="ig hi"> conceptnet </strong>也可以用于这个用例。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lf"><img src="../Images/8c402cc7538c9cc537a5300f9f49b49d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XOW3I_fn8l1F05qxtXbg1A.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx">Source:wikipedia</figcaption></figure><h1 id="96d1" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">4.为干扰物寻找正确的意义句子</h1><p id="f2c9" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lc ir is it ld iv iw ix le iz ja jb ha bi translated">第四步是确定文章的正确干扰物。例如，如果提取的关键字its是'<strong class="ig hi">亚马逊</strong>，那么下位词可以是'<strong class="ig hi">公司</strong>或'<strong class="ig hi">河流'</strong>或'<strong class="ig hi">古代</strong> <strong class="ig hi">女人</strong> <strong class="ig hi">战士'</strong>。我们必须在这个特定的文本中确定我们指的是一家公司。这可以使用BERT词义消歧模型来完成。</p><h1 id="3c45" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">5.从文本生成问题</h1><p id="04da" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lc ir is it ld iv iw ix le iz ja jb ha bi translated">最后一步是基于关键字(答案)和文本作为输入生成一个问题。这里，我们使用了来自拥抱人脸库的基于T5的预训练模型，因为T5使用了变压器的编码器和解码器架构。</p><p id="8f6c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢阅读！！干杯！！</p><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb jw ln"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Understanding RetinaMask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解视网膜掩膜</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/understanding-retinamask-e6f6feb814e5?source=collection_archive---------4-----------------------#2021-03-17">https://medium.com/mlearning-ai/understanding-retinamask-e6f6feb814e5?source=collection_archive---------4-----------------------#2021-03-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="1f24" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="47a6" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> <em class="ka">为什么</em> </strong></p><p id="c792" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">单次检测器的精度与两级检测器相当，单次检测器在速度和计算资源是重要设计考虑因素的应用中非常受欢迎。</p><p id="9e82" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi"> <em class="ka">如何</em> </strong></p><p id="6123" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这是通过从三个方面改进对最先进的单次检测器RetinaNet的培训来实现的:</p><ol class=""><li id="4346" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">在训练期间向单触发视网膜检测器添加新的实例掩模预测头。</li><li id="5342" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">一种新的自调整损失函数，提高了训练期间的鲁棒性。</li><li id="03f0" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">在训练中包括更多的正面例子，甚至是重叠度低的例子。</li></ol><p id="9c9a" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">RetinaMask具有与原始RetinaNet相同的计算速度成本，但更精确。此外，可以仅评估视网膜掩膜的检测部分。</p><h1 id="eed3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">模型</h1><p id="07b9" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">RetinaMask建立在RetinaNet的基础上，对基线设置进行了三项修改。这三项修改是</p><ol class=""><li id="a8ef" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">最佳匹配策略</li><li id="ac33" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">自调节平滑L1损耗</li><li id="0e14" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">掩模预测模块</li></ol><p id="448e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">最佳匹配策略</strong></p><p id="953c" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">在边界框匹配阶段，RetinaNet策略如下。所有与基础事实对象的交集(IOU)重叠大于0.5的锚定框都被视为正面示例。如果重叠小于0.4，锚定框被分配一个负标签。重叠在0.4和0.5之间的所有锚都不用于训练</p><p id="8519" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">但是一些地面真实物体的长宽比和异常值，一边比另一边长得多。因此，没有锚盒可以匹配到那些根据RetinaNet策略的锚盒。</p><p id="b78f" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">因此，RetinaMask放松重叠IOU阈值以获得它们。具有任何非零重叠的最佳匹配锚给出最佳准确度。</p><p id="dd2b" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">自调节平滑L1损耗</strong></p><p id="89e7" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">平滑L1损失最初是在<a class="ae ku" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank"> Fast R-CNN </a>(第3页)中提出的，目的是通过取代过于严格的L2损失，使边界框回归更加稳健</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es kv"><img src="../Images/f7260561d747f47e6c82cb947d4d0beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*mDli3O9A1da2rf-bOm_5JA.png"/></div></figure><p id="0a98" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">RetinaMask论文中定义的参数为β的平滑L1损失函数:-</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es ld"><img src="../Images/108ff18e618ffa94fef302d867641889.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*Bw8-GPvDe1c1zRMJoz4hsA.png"/></div></figure><p id="72bc" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">它用于将轴分为两部分:L2损失用于范围[0，Beta]内的目标，L1损失用于超出范围的目标，以避免过度惩罚异常值。控制点(β)的选择通常通过超参数搜索来完成。</p><p id="77dc" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">在自调整平滑L1损失中，用momentum 0.9记录运行迷你批次平均值和绝对损失方差，以计算β。β被选择为等于运行均值和运行方差之间的差值，并且该值被限制在一个范围内:-</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es le"><img src="../Images/2ec1bafb5d42f06d78622b56a6510455.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*yoFvWAxs4Smcdt6-Mq3IWQ.png"/></div></figure><p id="b870" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">使用削波是因为在训练期间运行均值是不稳定的，因为每批中的正样本的数量是不同的。</p><p id="8550" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">掩码预测模块</strong></p><p id="f31e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">单次检测预测被视为屏蔽建议。在运行RetinaNet进行边界框预测后，我们提取前N个得分预测。然后，我们根据以下等式将这些掩膜建议分配给FPN相应图层的样本要素</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lf"><img src="../Images/017000fbf31a17be22d97623ec95c408.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*S4z0tEgqYIMBjXvlIdSj9A.png"/></div></figure><p id="e38a" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">其中常数= 4，w和h分别是检测的宽度和高度。</p><p id="3395" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我们使用{P3，P4，P5，P6，P7}(与<a class="ae ku" href="https://arxiv.org/pdf/1612.03144.pdf" rel="noopener ugc nofollow" target="_blank"> FPN </a>和<a class="ae ku" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank"> RetinaNet </a>中的定义相同)要素图层进行边界框预测，使用{P3，P4，P5}要素图层进行掩膜预测。</p><p id="27a7" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">整体网络</strong></p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lg"><img src="../Images/acb9443154c68f3152948c1ef5be994a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RT0KsrgGUAu7AJIB.png"/></div></div></figure><p id="3805" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">上图显示了该模型的高级概述。在<a class="ae ku" href="https://arxiv.org/pdf/1612.03144.pdf" rel="noopener ugc nofollow" target="_blank">特征金字塔网络</a>设置之后，添加额外的层(P6和P7)并形成自上而下的连接(P5、P4和P3)。边界框分类头由4个卷积层(conv3x3(256) + ReLU)组成，并使用1个具有逐点sigmoid非线性的卷积(conv3x3(锚的数量*类的数量))。对于包围盒回归，采用类别不可知的设置。我们还运行4个卷积层(conv3x3(256)+ ReLU)和1个输出层(conv3x3(锚点数量* 4))来细化锚点。预测边界框后，我们将它们聚集起来并分布到要素金字塔图层，如上所述。ROI-Align操作在指定的特征层执行，产生14x14分辨率的特征，这些特征被馈送到4个连续的卷积层(conv3x3)和一个变换卷积层(convtranspose2d 2x2 ),后者将地图上采样到28x28分辨率。最后，应用预测卷积层(conv1x1)。我们预测特定类别的掩码。</p><h1 id="46f0" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">培训点</h1><p id="f86b" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">锚盒跨越5种比例和9种组合(3种长宽比[0.5，1，2]和3种尺寸[20，21/3，22/3])。在P3到P7的特征金字塔等级上，基础锚尺寸的范围从322到5122。每个锚定框匹配不超过一个基本事实边界框。具有大于0.5的地面真值框的交集/并集重叠的锚点被视为正面示例。另一方面，如果重叠小于0.4，则这样的锚被视为反面例子。然后，我们使用建议的最佳匹配策略，如第3节所述，它只能添加正面的例子。</p><p id="d73e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">对于训练期间的每个图像，我们还运行预测框的抑制和前100个选择(在推断期间应用与单次检测器相同的处理)。然后，我们将基础事实框添加到建议集中，并运行掩码预测模块。因此，在训练期间，掩码提议的数量是(100+Gt)。</p><p id="be61" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">损失</strong></p><p id="e6a4" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">最终损失函数是三个损失之和:盒子分类损失+盒子回归损失+掩模损失</p><p id="5a50" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">在哪里，</p><ol class=""><li id="a2ab" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">盒分类损失作为焦点损失，如<a class="ae ku" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank"> RetinaNet </a> :-</li></ol><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es ll"><img src="../Images/522d9ad52ea7bbce37146a5eb6e2d4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*87Jgg6YBXc2TeW4vcXshZA.png"/></div></figure><p id="a500" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">2.盒回归损失作为自调整平滑L1，将控制点限制在[0，0.11]范围内</p><p id="381e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">3.掩模损失可以定义为平均二进制交叉熵损失，如这里描述的<a class="ae ku" href="https://blog.zenggyu.com/en/post/2019-01-07/beyond-retinanet-and-mask-r-cnn-single-shot-instance-segmentation-with-retinamask/" rel="noopener ugc nofollow" target="_blank"/>:-</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lm"><img src="../Images/05140a04d416b774a5ee6d38fd6eb96d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*quo4awYlUmUT-fs5ECA1bQ.png"/></div></div></figure><h1 id="75b2" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结果</h1><p id="1b51" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><em class="ka">(注意研究论文中用于训练的数据集是COCO数据集，它提供了包围盒和分割掩膜标注。他们遵循常见的做法，使用COCOtrainval135k分割(2014train 80k和2014val 40k的35k图像的子集)进行训练，使用minival(2014 val 40k的剩余5k图像)进行评估。)</em> <strong class="je hi">与RetinaNet </strong>的比较</p><p id="3474" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">平均精度的每类差异:-</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ln"><img src="../Images/5625d2a5c16007690750566478402fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dyCaXxquNFSZIhcG.png"/></div></div></figure><p id="fa0a" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">注意toaster类，它的mAP减少了7.9点(从28.9到21.0)，在验证集中只有9个地面真实对象。</p><p id="1a15" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">RetinaNet和RetinaMask之间的定性结果:-</p><ol class=""><li id="5a5b" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">具有大纵横比(如1.1)的类的改进。Tie 1.2没有多次检测。更好地回忆天空</li><li id="5351" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">更少的假阴性</li><li id="17ad" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">更少的失败案例</li></ol><p id="c076" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">RetinaMask与RetinaNet在不同主干网络和输入分辨率上的比较(在COCOtest-dev上的<em class="ka">):-</em></p><p id="de95" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">RetinaMask显示了主干网选择和分辨率的所有组合的更好的准确性。它显示了与RetinaNet相比，在输入比例为800时，ResNet-50和ResNet-101上的1.84地图和1.3地图改进。</p><p id="3ad2" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">与最先进方法的比较</strong></p><p id="a3a6" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">参见<a class="ae ku" href="https://arxiv.org/pdf/1901.03353.pdf" rel="noopener ugc nofollow" target="_blank">这里的</a>(第8页)的实施细节</p><p id="d915" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">在COCOtest-dev上与最先进的方法进行了比较。与RetinaNet相比，基于ResNet-101-FPN的RetinaMask要好于2.6 mAP。与Mask R-CNN相比，它显示了基于ResNet-101-FPN的3.5倍地图改进</p><p id="9a80" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">与Mask R-CNN在实例屏蔽预测上的比较</strong></p><p id="f597" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">为了与Mask R-CNN在COCOminival上使用ResNet-101进行掩模预测进行比较，RetinaMask模型以与<a class="ae ku" href="https://arxiv.org/pdf/1703.06870.pdf" rel="noopener ugc nofollow" target="_blank"> MaskRCNN </a>中的+e2e训练非常相似的方式进行训练。掩模R-CNN在掩模预测上仍然表现出更好的准确性，但差异仅在1.2 mAP左右。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Multinomial Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多项式逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/multinomial-logistic-regression-adb2a76eedcf?source=collection_archive---------6-----------------------#2022-04-08">https://medium.com/mlearning-ai/multinomial-logistic-regression-adb2a76eedcf?source=collection_archive---------6-----------------------#2022-04-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/043ac0a9d26c275805d0e0286dd01978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wRxovuNfqVzLcHfAlMuvg.jpeg"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Photo by <a class="ae hu" href="https://unsplash.com/@chollz?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Charlie M</a> on <a class="ae hu" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="3b06" class="pw-subtitle-paragraph iu hw hx bd b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl dx translated">讨论逻辑回归的概念并为一个简单的分类问题实现逻辑函数</h2></div><p id="b448" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">嗨，伙计们！</p><p id="bb5b" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">本文将讲述对<strong class="jo hy">分类问题</strong>最有帮助的<strong class="jo hy">回归模型</strong>之一。</p><p id="04eb" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在深入概念之前，我们先来问一个常见的问题！</p><p id="d7f5" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">假设你决定去野餐，你会问自己的第一个问题是<em class="ki">天气如何</em>因为如果天气不好，你会过得很糟糕！所以你的答案可能是晴天、刮风、阵雨等。，但我们知道它不像一个实数，不可能是无穷大。<br/>但你是怎么回答的？你会用很多参数比如风速，湿度，季节，还有你过去一年在那个地方的经历来回答！</p><p id="219c" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我们可以说，你试图通过考虑每个参数在天气突变预测中的重要性来得到一个具体的答案。</p><p id="7a0b" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">现在你扮演的是天气预测的机器学习模型角色！但是机器怎么能学会这种思维方式呢！除了逻辑回归什么都做不了。</p><p id="e889" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">首先让我们仔细看看这个概念。</p><h2 id="27cd" class="kj kk hx bd kl km kn ko kp kq kr ks kt jv ku kv kw jz kx ky kz kd la lb lc ld bi translated">什么是逻辑回归？</h2><p id="2743" class="pw-post-body-paragraph jm jn hx jo b jp le iy jr js lf jb ju jv lg jx jy jz lh kb kc kd li kf kg kh ha bi translated">考虑到你知道回归的基本原理，我们可以说逻辑回归是线性回归的高级模型，因为它使用了几个与线性回归相关的概念。</p><p id="5887" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">有什么不同？为什么不用线性？</strong> <br/>线性回归将所有数据自由绘制成图，将每一个X匹配到对应的Y，会给出无穷大的输出！但是如你所见，我们没有无限状态！逻辑回归产生了在两个可接受值1和0之间的周围结果的机制；这些值是一对“是”和“否”</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lj"><img src="../Images/7de4dfff23aee7dd27eb45a6a6e27774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twuf8iGIUoTtmjmz7pO0KA.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Linear Regression Graph vs. Logistic Regression Graph by <a class="ae hu" href="https://www.analyticsvidhya.com/blog/2020/12/beginners-take-how-logistic-regression-is-related-to-linear-regression/" rel="noopener ugc nofollow" target="_blank">analyticsvidhya</a></figcaption></figure><p id="7dc9" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">逻辑回归使用<strong class="jo hy"> Sigmoid </strong>函数来挤压该范围内的值，并最终制作一个S曲线图形。</p><p id="ff3e" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">什么是乙状结肠功能？</strong></p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lo"><img src="../Images/429d5572e2c70f62a992a8243651f1a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Js1E9QNAOnA0BYwu2NQ-Xw.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">sigmoid function formula Image by Author</figcaption></figure><p id="0dee" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">sigmoid是统计学和机器学习中著名的函数之一，它将实数的值映射为0和1或-1和1。统计学学生知道它是Logit函数的反函数。</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lp"><img src="../Images/cfc21d96a0b886aa2870f08f886de8ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vbhHOsWHXvdmDweE_dXIdQ.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Sigmoid Function graph Image by Author</figcaption></figure><p id="3aee" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">每个不同输入的输出显示，如果x等于+ꝏ，那么我们得到1，如果它等于-ꝏ，它将给出0输出。</p><p id="9dd0" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">现在我们对幕后有了足够的了解，让我们更进一步，找出我们应该如何在现实世界的问题中使用这些理论。</p></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><h2 id="79b6" class="kj kk hx bd kl km kn ko kp kq kr ks kt jv ku kv kw jz kx ky kz kd la lb lc ld bi translated"><strong class="ak">逻辑回归实施</strong></h2><p id="a809" class="pw-post-body-paragraph jm jn hx jo b jp le iy jr js lf jb ju jv lg jx jy jz lh kb kc kd li kf kg kh ha bi translated">我将使用python和Jupiter notebook来实现。<br/>首先要一窥数据集；这可以从<a class="ae hu" href="https://github.com/sinadalvand/LogisticRegression/blob/master/dataset.xls" rel="noopener ugc nofollow" target="_blank">这里</a>进入</p><p id="40e7" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">数据集如下图所示:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lx"><img src="../Images/cd78f4fb6148c488493f68517b46d832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TwMEffNAVhynycUpP_zM4g.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">a small sample from the whole Dataset Image by Author</figcaption></figure><p id="ca9b" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我们通过第一眼就意识到了一些技巧:</p><ul class=""><li id="aea4" class="ly lz hx jo b jp jq js jt jv ma jz mb kd mc kh md me mf mg bi translated">数据集有14列，包含13个要素</li><li id="6d3b" class="ly lz hx jo b jp mh js mi jv mj jz mk kd ml kh md me mf mg bi translated">最后一列显示了三个标签，我们知道这是一个多项式问题</li><li id="a21a" class="ly lz hx jo b jp mh js mi jv mj jz mk kd ml kh md me mf mg bi translated">特征值不在同一个范围内，需要调整</li></ul></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="13db" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">从数据集获取数据并解析成数据帧<br/> </strong>在这个项目中，我们使用了两个著名的库，Pandas和NumPy</p><blockquote class="mm mn mo"><p id="b1d3" class="jm jn ki jo b jp jq iy jr js jt jb ju mp jw jx jy mq ka kb kc mr ke kf kg kh ha bi translated">这增加了对大型多维数组和矩阵的支持，以及对这些数组进行操作的大量高级数学函数。</p></blockquote><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Fetch data from Dataset</figcaption></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mu"><img src="../Images/0a1c0491c4e407cfb4e0752a053251f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DU9WFr9d6QokDuPLa7-ThA.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">the output of Logestic_regression_Imports.py Image by Author</figcaption></figure></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="d2e9" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">数据拆分</strong></p><p id="8945" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">现在，我们需要将数据分为训练集和测试集，因为模型将通过考虑每个记录的特征和标签来训练和调整其参数(thetas ),并最终使用训练集(包含看不见的数据)来评估精确度。根据这个描述，我们应该将数据集的70%用于训练阶段，30%用于测试集！</p><blockquote class="mm mn mo"><p id="0db9" class="jm jn ki jo b jp jq iy jr js jt jb ju mp jw jx jy mq ka kb kc mr ke kf kg kh ha bi translated">常用的比率有:<strong class="jo hy"> 70%训练，30%测试</strong>。<strong class="jo hy"> 80%训练，20%测试</strong></p></blockquote><p id="af97" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了实现这个splitter函数，我使用了一种简单的方法:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="2141" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在第二行中，完整数据记录的计数将从数据集中获得，并计算70%的数据大小，它将是大约144/0.7~ 101条记录。</p><p id="85c5" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">然后在第三行中，我们创建一个数组，它包含整个数据记录大小的True和False值，但我们通过为训练集生成True和为测试集生成False来区分它。现在我们有一个包含70%真值和30%假值的数组。</p><p id="5968" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">数据应该随机拆分，我们不知道当前数据集是否按特定方式排序！因此，让我们打破它，并洗牌生成真/假数组，以确保它将随机收集。所以我使用了随机播放功能。</p><p id="7058" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">然后尝试将每个真和假压缩到数据集中相应的索引，并将它们放在一起。</p><p id="9368" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">最后，通过过滤成对的数据，我们可以得到两个分离列表:训练集和测试集。</p></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="2667" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">从集合中提取特征和标签</strong></p><p id="c05c" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了更直接地访问数据，我决定区分特征和标注，并将它们放入一个单独的数组中。</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="35b5" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">那么训练集将是这样的:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mv"><img src="../Images/756ad19fa52dd73e130931250ce91364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X75DG8Yo9DX_iASYbyreog.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">X_train values Image by Author</figcaption></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mw"><img src="../Images/38c50057c28666c287d4d0896d026228.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*deQ8-H3XqQW-sg0iqmHcvQ.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Y-train values Image by Author</figcaption></figure></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="d0a5" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">将特性值缩放到所需大小</strong></p><p id="40d2" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">正如我们在数据集提示中提到的，要素值需要在相同的范围内，我们可以通过对其应用归一化并快速将值置于0和1之间来实现这一点:)</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div class="er es mx"><img src="../Images/d66544e0c6df6962fd5c205fcb37fb8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*GN5ODujYL8liBgiXocZmwQ.jpeg"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Normalization statistic formula Image by Author</figcaption></figure><p id="2d92" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">根据正确的公式，为了实现，我们需要在Numpy中使用两个函数，“Numpy.mean()”和“Numpy.std()”用于计算一组特征中每个单个元素的平均值。</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="a58a" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">首先，我定义了<em class="ki"> normalize </em>函数，该函数获取特性作为输入，然后将所有值解析为float类型以防止编程错误。</p><p id="5cdb" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">然后，我对训练集和测试集特性进行了缩放。</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es my"><img src="../Images/5061bf5f0321502e181b689c67199258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qyfDSGrcKOr7e_d9ZBd5A.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">X_train before applying normalization Image by Author</figcaption></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mz"><img src="../Images/c5e1329ccf7bb10b7223167d5671a26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RxBfUkDn4KKjri1H--89ig.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">X_train after using normalization Image by Author</figcaption></figure><p id="69ec" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如顶部表格所示；所有值都介于0和1之间。</p></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="1c25" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">每个theta都需要一个对应的特征</strong></p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es na"><img src="../Images/1f3f0f9d12fa5176b660e2d3f1ab87b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4N2XwwHD25nx9CYcgxJZoA.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Linear Regression Hypothesis function Image by Author</figcaption></figure><p id="c61c" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如果你还记得线性回归假设函数，我们假设xₒ <br/>等于1，以使矩阵计算更方便。</p><p id="00f3" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">这里我们有相同的，但是有一点不同的假设公式:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div class="er es nb"><img src="../Images/0da5d7f96e22e9daa110691d373ceb54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vIB8Ads0S7Akwtx5APoLjw.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Logistic Regression Hypothesis function Image by Author</figcaption></figure><p id="608e" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我们需要在特性中插入一个one列作为第一个索引。</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nc"><img src="../Images/84a76539a804bed81b11674bcdf3a7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5zfqZ1iW21XbdkxkrCzvFg.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Ones column added to features Image by Author</figcaption></figure></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="a851" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">触摸核心</strong></p><p id="7f27" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">现在是时候说说这个过程的主要部分了！<br/>在开始实施之前，让我们先讨论一下这个概念，了解一下围绕它发生了什么。</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div class="er es nd"><img src="../Images/b52c16463298f79d5e15699eb47ac741.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/0*WUl5DMK-TQaBQFcg.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Linear Regression Cost Function Image by Author</figcaption></figure><p id="d0df" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我们记得在线性回归中，我们用成本函数(损失函数)<em class="ki"> J </em> ( <em class="ki"> θ </em>)来表示优化目标，用梯度下降进行最小化。</p><p id="cbd5" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">幸运的是，我们在逻辑回归中有相同的方法！但是请问<em class="ki">为什么这些问题</em>我们不用线性回归的代价函数，答案是很多局部极小！</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div class="er es ne"><img src="../Images/e0f464e33023a11b903ea6abab1e63f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*p5RUtLvi4ZhbMcqeDKD0wQ.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Using the Linear Regression cost function for Logistic Regression Image by Author</figcaption></figure><p id="4869" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如图所示，我们有许多局部最小值，而且它不是凸图！这使得寻找最佳的情况变得复杂，因为当你认为你处于全局最小点时，可能存在更好的情况，但你被困在你有限的视野中:)</p><p id="cebb" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">因此，为了解决这个问题，我们必须使用另一个与逻辑回归相关的成本函数，这就是:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nf"><img src="../Images/3e28306dbf695a81468ceeabc79e8b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ydGo9NX9d7aAulWN.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Logistic Regression Cost Function Image by Author</figcaption></figure><p id="24f1" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如果我们把这些功能压缩成一个，它会是这样的:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ng"><img src="../Images/82c88d161f6aecbb28c5bacac622c707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GOg9SWyfs-xsRnJe.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Logistic Regression Cost Function Image by Author</figcaption></figure><p id="b5d9" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">好了，现在是使用梯度下降来最小化成本函数的时候了:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nh"><img src="../Images/708eb64e925c239be8243c57df05183e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_4chRIkj5TgK1OtQScVRPw.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Gradient descent formula Image by Author</figcaption></figure><p id="4f05" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在导数之前有一个α，这就是学习率，我希望你们之前知道</p><p id="a0ef" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如您所见，我们需要导数成本函数，其计算方式如下:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ni"><img src="../Images/1177b62fa8ee757d8a164a2af7778ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M6PJmpi1wFXuWR9qLwLK1g.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">derivate of cost function Image by Author</figcaption></figure><p id="b497" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">最后，我们有:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nj"><img src="../Images/1f0863a847b73a16fbfaa12310ec6a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68Su7oVLlV91goxXsy0Ftw.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Derivated Logistic Cost function Image by Author</figcaption></figure></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="ceb7" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">理论上，任务成功完成了，现在让我们动手吧:</p><p id="8703" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">没有预先构建的sigmoid函数，我们看到的比任何东西都多<br/>,所以需要编写的第一个函数是sigmoid，我们之前讨论过</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">sigmoid function implementation</figcaption></figure><p id="5528" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">第二个常见的函数是逻辑回归中的假设函数:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Hypothesis Function in Logistic Regression</figcaption></figure><p id="7477" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">好了，现在是梯度下降的时候了:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="0a06" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">哇，与其他代码相比，这是很多复杂的代码！🤯<br/>让我们尽可能简单地逐行描述</p><p id="2b93" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">输入参数:</p><ul class=""><li id="7303" class="ly lz hx jo b jp jq js jt jv ma jz mb kd mc kh md me mf mg bi translated">x:将特征训练为2d矩阵</li><li id="2c42" class="ly lz hx jo b jp mh js mi jv mj jz mk kd ml kh md me mf mg bi translated">y:功能集的相应类别标签</li><li id="1fe9" class="ly lz hx jo b jp mh js mi jv mj jz mk kd ml kh md me mf mg bi translated">阿尔法:学习率</li><li id="f69a" class="ly lz hx jo b jp mh js mi jv mj jz mk kd ml kh md me mf mg bi translated">iter:用于停止算法的迭代次数</li></ul><p id="aafb" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在第一行中，我们获取要素的计数以了解需要多少个thetas，然后在第二行中，我们尝试使用pure python将所有标签转换为一个唯一的集合，其工作方式如下:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">set function sample</figcaption></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nk"><img src="../Images/4fba3f2256eae79a5019f4942204bb5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNgIvR19JRIZLMLH339OmA.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">set function sample result Image by Author</figcaption></figure><p id="dd69" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">然后在第三行，我们为将来的thetas创建了一个空数组。</p><p id="ab68" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">第一个循环是多项式和二元逻辑回归的不同点。为了更容易理解，让我们来看看:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div class="er es nl"><img src="../Images/84fb0a6eb69a62e9506cbce230a57cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*Xg1xW0t-n5MplmpziuYUig.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Binary classification Image by Author</figcaption></figure><p id="2947" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在二进制分类中，我们只有两类！当你想训练你的模型时，你只有两种类型的数据，三角形和正方形。当你试图调整thetas时，因为类型只有两个，它属于三角形；否则属于正方。这种比较可以一步完成。正因如此，你不需要一个一个的互相比较！因此二元逻辑回归的代码应该是这样的:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Binary Logistic Regression Implementation</figcaption></figure><p id="4804" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">但是在多项式分类中，我们有两个以上的类别标签，这使得过程更加困难。让我们从一个简单的图形形状示例开始:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div class="er es nm"><img src="../Images/c937737dd374e1aac98437809ef5349d.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*R3awdgK142PdxYL0T9eMvg.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Multinomial Problem Image by Author</figcaption></figure><p id="c986" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我们本能的知道Logistic回归是二进制的，所以要根据工作风格来改变问题！我们需要将类分组为二进制模式，并将三角形作为一个类，将所有其他类型作为另一个类；使用这种方法，我们有一个二进制问题，但应该考虑到它需要为每个类重复。即，在下一步中，正方形将是一个类，而另外两个将是另一个类。</p><div class="lk ll lm ln fd ab cb"><figure class="nn hj no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><img src="../Images/2a48ad824d877260b11e3e052aef932d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*nknM_AiZhP5ICotkkXjZ1A.png"/></div></figure><figure class="nn hj no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><img src="../Images/0337831ce4dabebed0d12ab448f76cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*IFno8QOqPgDgj0m55pggww.png"/></div></figure><figure class="nn hj no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><img src="../Images/e576e6f370e9d87eb1d306de2b6c8412.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*atyUc0asudn3K81rw0zaEg.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx nt di nu nv">Classes group in multinomial Logistic Regression Image by Author</figcaption></figure></div><p id="df4e" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">按照这个方法，现在我们知道第一个循环的原因了！它试图对每种类型进行分组，并为特定类型的类调整教学大纲！<br/>此外，它为特定类型生成初始θ，然后区分索引Y和其他<br/> Ops！还有一点功能之前没有提到:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">extract specific label from Y_train</figcaption></figure><p id="c6ed" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">并且这种区分是由上述函数和过滤器Y针对特定的类标签而发生的:即，过滤是通过使所选择的类型值为1而其他的为0来完成的。</p><p id="6874" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">从现在开始，一切就像二元逻辑回归</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="7fbe" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">上述功能正是以下功能的实现:</p><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nj"><img src="../Images/1f0863a847b73a16fbfaa12310ec6a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68Su7oVLlV91goxXsy0Ftw.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">theta updated simultaneously Image by Author</figcaption></figure><p id="6d01" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在函数结束时，我们返回用于下一步的标签和类标签。</p><p id="1cfd" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">让我们运行逻辑回归:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nw"><img src="../Images/e520279f6b47372151e8c69bd984acc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bbJvPeCwfXmHcJG73goqdQ.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">classes variable value Image by Author</figcaption></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es nx"><img src="../Images/fef33df120aad4ae2258ee44784d173b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jd5HkjVBMJS7DqSVJ7DJGg.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">theta variable values Image by Author</figcaption></figure></div><div class="ab cl lq lr go ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ha hb hc hd he"><p id="c636" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">评估你的火车</strong></p><p id="d0e4" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在所有这些步骤之后，让我们进行最后一步，评估模型预测准确性；我们先用训练数据试试！<br/>期望达到100%:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">evaluate the Model by training data</figcaption></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ny"><img src="../Images/ebf62b21c4fc258f62790e97dde8d417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oC42cFzLFwVyMZPbQlzynQ.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">evaluation result for train data Image by Author</figcaption></figure><p id="49a3" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">现在转到测试集(这是一个更可靠的原因，你可能会陷入过度拟合的问题)</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><figure class="lk ll lm ln fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ny"><img src="../Images/7f6dde39673e17f8070f36f0e5aed17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DkHkyyAMCATy2ijaFyNfmA.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">evaluation result for test data Image by Author</figcaption></figure><p id="848c" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">98%对于一个模型来说是很高的准确率，听起来不错。</p><p id="9061" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">但是</strong>什么是<strong class="jo hy"> predict() </strong>函数？</p><p id="86ac" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如您所见，我们使用<em class="ki">预测</em>函数通过提供θ将X(特征)应用到假设函数中，并且<em class="ki">预测</em>如下所示:</p><figure class="lk ll lm ln fd hj"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="0729" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">注意:@运算符是对两个矩阵的点积运算</p><p id="08b9" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">应用参数后，在逻辑回归假设函数中，使用argmax检测哪个输出最大，以将其分配给特定的类标签。</p><p id="326e" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">如需联系，请随意:</strong></p><p id="cffe" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">电子邮件</strong>:<a class="ae hu" href="mailto: dalvandsina@yahoo.com" rel="noopener ugc nofollow" target="_blank">dalvandsina@yahoo.com</a></p><p id="9805" class="pw-post-body-paragraph jm jn hx jo b jp jq iy jr js jt jb ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hy">Github</strong>:<a class="ae hu" href="https://github.com/sinadalvand" rel="noopener ugc nofollow" target="_blank">www.github.com/sinadalvand</a></p><div class="hg hh ez fb hi nz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="oa ab dw"><div class="ob ab oc cl cj od"><h2 class="bd hy fi z dy oe ea eb of ed ef hw bi translated">Mlearning.ai提交建议</h2><div class="og l"><h3 class="bd b fi z dy oe ea eb of ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="oh l"><p class="bd b fp z dy oe ea eb of ed ef dx translated">medium.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ho nz"/></div></div></a></div></div></div>    
</body>
</html>
# Word2Vec:关键要点

> 原文：<https://medium.com/mlearning-ai/word2vec-key-insights-ff08f5a1f698?source=collection_archive---------8----------------------->

# 基于 Mikolov 等人 2013 年对向量空间中单词表示的有效估计

# 概观

**问题:**如何才能创建一个语言模型，从拥有数百万不同单词的数据集中准确地学习单词向量？

**他们做了什么来回答这个问题:**作者使用词向量算法开发了一个词相似性任务，他们用这个任务研究了现有语言模型的准确性，然后分析了他们基于之前的分析结果创建的另外两个模型。

**动机/原理:**之前的研究没有成功训练出超过几亿个单词。如果我们比较以前模型的准确性，并根据研究结果提出新的模型方法，我们可以提出更好的模型。

**发现:**使用非常简单的模型架构训练高质量的单词向量是可能的。

**解读:**由于计算复杂度低，所以可以从非常大的数据集中计算出非常精确的高维词向量。

# 重要概念

## 词向量

## 神经网络语言模型(NNLM)

*   一个版本由具有线性投影层和非线性隐藏层的前馈神经网络组成。这两层学习单词向量表示和统计语言模型。
*   另一个版本由一个具有一个隐藏层的神经网络组成，该网络首先学习单词向量。这些单词向量然后被用于训练 NNLM。Mikolov 等人后来用一个模型扩展了这个架构，该模型只关注学习单词向量的第一步。他们这样做是因为单词向量已经被证明可以显著地改进和简化许多 NLP 应用程序。

## 估计单词的连续表示

作者考虑了许多模型来估计单词的连续表征，包括潜在语义分析(LSA)和潜在狄利克雷分配(LDA)。

**潜在语义分析(LSA)**

使用 SVD 在文档中查找主题。

**潜在狄利克雷分配(LDA)**

一种按主题对文档进行排序的方法。

**神经网络**

作者决定使用神经网络模型，因为 LSA 在保持单词之间的线性规则性方面不太有效，并且 LDA 在大型数据集上的计算非常昂贵。

## 比较模型架构

步骤:

1.  定义模型的计算复杂度
2.  尝试最大化精确度，同时最小化计算复杂度

对于分析的所有模型体系结构，训练复杂性与以下因素成正比:

O = E × T × Q

*   e:训练时期的数量
*   t:训练集中的单词数
*   问:特定于每个模型架构的数字

使用随机梯度下降和反向传播来训练所有模型。

**前馈神经网络语言模型(NNLM)**

模型的层是:输入、投影、隐藏和输出。

作者在他们的模型中使用了层次化的 softmax，其中词汇表被表示为霍夫曼二叉树。

关于霍夫曼树的更多信息:

**递归神经网络语言模型(RNNLM)**

模型的层是:输入、投影、隐藏和输出(除了投影层之外，与 NNLM 相同)。

与 NNLM 不同，不需要指定上下文长度(模型 N 的阶)，并且，理论上，RNNs 可以比浅层神经网络有效地表示更复杂的模式。

想了解更多关于什么使循环神经网络独一无二的信息，请看这个视频。

**神经网络的并行训练**

作者使用一个框架来并行运行同一模型的多个副本。

## **建议型号**

作者利用以前模型的信息提出了两个新的更简单的模型，这两个模型将降低计算的复杂性。

**连续单词包模型(CBOW)**

该模型学习在给定周围单词的情况下预测缺失的单词。

类似于前馈 NNLM，但是非线性隐藏层被移除，并且投影层被所有单词共享。与标准的词袋模型不同，它使用上下文的连续分布式表示。

**连续跳格模型**

该模型学习预测给定输入单词周围的单词。

与 CBOW 类似，但它不是根据上下文来预测当前单词，而是试图根据同一句子中的另一个单词来最大化地分类一个单词。

有关这两个模型的更多信息，请查看 DeepLearning 的 Coursera [自然语言处理与概率模型](https://www.coursera.org/learn/probabilistic-models-in-nlp)课程。人工智能

## 相似性任务

要找到一个与 small 相似的单词，就像 maximum 与 big 相似一样，我们可以简单地计算 vector X = vector(" maximum ")-vector(" big ")+vector(" small ")，然后使用余弦距离来确定向量空间中最近的单词向量。

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
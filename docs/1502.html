<html>
<head>
<title>Face Emotion Recognition (FER)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人脸情感识别(FER)</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/face-emotion-recognition-fer-114ccb359604?source=collection_archive---------3-----------------------#2021-12-27">https://medium.com/mlearning-ai/face-emotion-recognition-fer-114ccb359604?source=collection_archive---------3-----------------------#2021-12-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0699" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博客中，我将解释如何使用不同的深度学习模型从图像中识别面部情绪。</p><h2 id="d5c6" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">目录:</h2><ol class=""><li id="879e" class="jx jy hh ig b ih jz il ka ip kb it kc ix kd jb ke kf kg kh bi translated">FER——使用DeepFace和OpenCV</li><li id="a1ab" class="jx jy hh ig b ih ki il kj ip kk it kl ix km jb ke kf kg kh bi translated">FER- VGG</li></ol></div><div class="ab cl kn ko go kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ha hb hc hd he"><h1 id="3cb8" class="ku jd hh bd je kv kw kx ji ky kz la jm lb lc ld jp le lf lg js lh li lj jv lk bi translated">1.FER——使用DeepFace和OpenCV</h1><p id="829d" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">在下面的例子中，我们已经认识到不同的面部情绪，如快乐、悲伤、愤怒等。使用<strong class="ig hi"> DeepFace </strong>人脸识别包<strong class="ig hi"> </strong>和OpenCV。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/e72586814ce7a211004f656942be9953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwohE0vsDR_8HzB4nkKKWQ.png"/></div></div></figure><p id="dadd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DeepFace是Sefik Ilkin Serengil创建的人脸识别和面部属性分析Python库。此外，我们将使用OpenCV来检测图像中的人脸，以便我们可以在人脸周围绘制边界框。</p><p id="614c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用DeepFace包，我们只需要几行代码就可以识别面部情绪。您可以在链接中找到该代码的Jupyter文件。(<a class="ae ma" href="https://github.com/Prabhitha/FaceEmotionRecognition/blob/main/FaceEmotionDetection_DeepFace.ipynb" rel="noopener ugc nofollow" target="_blank">朱庇特笔记本</a>)</p><p id="b32f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，导入所需的库，如cv2和DeepFace。加载输入图像。然后，使用DeepFace来识别该人的面部情绪。使用OpenCV库绘制人脸周围的包围盒。有关人脸检测的详细说明，请参考此链接。(<a class="ae ma" href="https://prabhitha3.medium.com/?p=d71f78870271" rel="noopener">使用OpenCV的人脸检测</a>)</p><figure class="lp lq lr ls fd lt"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="4d04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输入:</strong></p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="ab fe cl md"><img src="../Images/0a46c432d471964ac4d6636900563003.png" data-original-src="https://miro.medium.com/v2/format:webp/1*uylLwsx06QxpXS3AmrwhkQ.png"/></div><figcaption class="me mf et er es mg mh bd b be z dx">Face Emotion Recognition</figcaption></figure><p id="c52e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输出:</strong>我们的模型预测主导情绪为快乐，年龄为53，性别为男性，主导种族为白人。</p><pre class="lp lq lr ls fd mi mj mk ml aw mm bi"><span id="529f" class="jc jd hh mj b fi mn mo l mp mq">{'emotion': {'angry': 5.69619108083056e-08,<br/>  'disgust': 3.1070864423150083e-13,<br/>  'fear': 2.130725735972857e-11,<br/>  'happy': 99.9999463558165,<br/>  'sad': 1.3578462719752345e-06,<br/>  'surprise': 7.25795497813735e-11,<br/>  'neutral': 5.4453287083243254e-05},<br/> 'dominant_emotion': 'happy',<br/> 'region': {'x': 35, 'y': 78, 'w': 258, 'h': 258},<br/> 'age': 53,<br/> 'gender': 'Man',<br/> 'race': {'asian': 0.024189992109313607,<br/>  'indian': 0.2852343022823334,<br/>  'black': 0.016142033564392477,<br/>  'white': 72.07229137420654,<br/>  'middle eastern': 13.463360071182251,<br/>  'latino hispanic': 14.138786494731903},<br/> 'dominant_race': 'white'}</span></pre><h1 id="771b" class="ku jd hh bd je kv mr kx ji ky ms la jm lb mt ld jp le mu lg js lh mv lj jv lk bi translated">FER -VGG:</h1><p id="095b" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">在这里，我们不是使用DeepFace人脸识别包，而是要训练我们自己的定制VGG模型来识别面部情绪。</p><p id="06ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将在FER 2013数据集上训练我们的模型。该数据集包含大小为48*48像素的灰度人脸图像。它有6个分类标签:愤怒、厌恶、恐惧、快乐、悲伤、惊讶和中立。训练集由28，709幅图像组成，测试集由3，589个示例组成。但是我们将用11，448幅训练图像和4，798幅测试图像来训练我们的模型。</p><p id="3ece" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">训练图像示例:</strong></p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/c3f428ff47e8a30f74de69028c00a008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VCdCuiDstoNvv6lu_-5RXw.png"/></div></div><figcaption class="me mf et er es mg mh bd b be z dx">Happy Faces</figcaption></figure><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/630b3db0de13271a60fd2711ed65687d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sl2DUyZkt4jH2jaH8WpdgA.png"/></div></div><figcaption class="me mf et er es mg mh bd b be z dx">Sad Faces</figcaption></figure><h2 id="2dbe" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">步骤:</h2><ul class=""><li id="f0da" class="jx jy hh ig b ih jz il ka ip kb it kc ix kd jb mw kf kg kh bi translated">数据扩充</li><li id="1055" class="jx jy hh ig b ih ki il kj ip kk it kl ix km jb mw kf kg kh bi translated">建立和训练模型</li></ul><h2 id="9809" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak"> a)数据扩充:</strong></h2><p id="063a" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">一般来说，要训练一个高精度低误差的模型，需要在大数据上进行训练。但实际操作起来，就没那么容易了。所以在这里，我们将做数据增强来增加训练数据。数据扩充没什么，但是给定一个输入图像，我们通过改变图像的不同属性来创建它的多个副本。我们执行图像旋转，移位，翻转，修改其亮度，改变角度等。我们也可以通过将图像除以最高像素值(1)来标准化图像。/255).</p><p id="e85e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">主要优点是，它不会将转换后的图像添加到我们的原始数据集中。当我们训练模型时，我们同时变换图像。此外，我们分批加载训练图像，这减少了过拟合的问题，并降低了内存的使用。</p><p id="6f88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">原始图像:</strong></p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mx"><img src="../Images/14e48e42ea27f853e8b3a52089ab540f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XCz5A1IuWHbxYJClx0qIxg.jpeg"/></div></div><figcaption class="me mf et er es mg mh bd b be z dx">Tesla Roadster</figcaption></figure><h2 id="4626" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">代码:</h2><figure class="lp lq lr ls fd lt"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="0db2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">图像旋转:</strong>我们可以指定图像需要在0到360度之间旋转多少度。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/603b47d9bb4f907f365c7b106902b7b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bt2R1bJOab003-2e7p0WWQ.png"/></div></div></figure><p id="0128" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">图像移动:</strong>我们可以水平和垂直移动图像。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/0789b5751a412a26db445a36c2255f30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85piT1pEAqz1uQN8b60SNw.png"/></div></div></figure><p id="30f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">图像翻转:</strong>我们可以翻转图像。第一个图像水平翻转，第三个图像垂直翻转。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/3337c56a43e9461a79ff594505ba6438.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ywbmrLoTDunlEQf9MCN0Yw.png"/></div></div></figure><p id="2105" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">图像亮度:</strong>我们可以调节图像的亮度。第一张图像比上一张暗。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/bb59ea4ea51bf3dff13c38254ddf4247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VBZwTIYqU0nw36fU_gR9iQ.png"/></div></div></figure><p id="cd7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">图像缩放:</strong>我们可以放大和缩小图像。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/9fdd5aca1702f5a860612b5256156705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0wctz-eRJyTG1yVR4M-6JA.png"/></div></div></figure><p id="3632" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将通过执行旋转、剪切、缩放、宽度移动、高度移动和水平翻转来增加我们的训练数据。我们不应该增加试验数据。</p><figure class="lp lq lr ls fd lt"><div class="bz dy l di"><div class="mb mc l"/></div></figure><h2 id="52cd" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">b)构建和训练模型:</h2><p id="91d2" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">在我们的模型中，我们总共有7个块，具有多个卷积层和最大池层。我们使用批量标准化和退出来避免过度拟合。我们的最终模型将有1，325，861个可训练参数。</p><figure class="lp lq lr ls fd lt"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="60d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们使用分类交叉熵损失和Adam优化器编译和拟合我们的模型。我们用不同的学习速率、时期和批量大小来训练我们的模型。</p><p id="554f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们将使用OpenCV Haar级联分类器来检测人脸，并在其周围绘制边界框。</p><figure class="lp lq lr ls fd lt"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="5b5b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">最终输出:</strong></p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lo"><img src="../Images/092ac1dacbf00edc6a608f4511cfb4cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bV2VDcz3KpXeu89BOMdP4Q.png"/></div></div></figure><p id="4a3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，我们可以从直播/录制的视频中识别面部情绪。</p></div><div class="ab cl kn ko go kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ha hb hc hd he"><p id="3249" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">我的GitHub页面上有实现:</strong></p><p id="7c88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae ma" href="https://github.com/Prabhitha/FaceEmotionRecognition" rel="noopener ugc nofollow" target="_blank">https://github.com/Prabhitha/FaceEmotionRecognition</a></p><p id="3483" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献:</strong></p><ol class=""><li id="c0fe" class="jx jy hh ig b ih ii il im ip my it mz ix na jb ke kf kg kh bi translated"><a class="ae ma" href="https://viso.ai/computer-vision/deepface/" rel="noopener ugc nofollow" target="_blank">https://viso.ai/computer-vision/deepface/</a></li><li id="013b" class="jx jy hh ig b ih ki il kj ip kk it kl ix km jb ke kf kg kh bi translated"><a class="ae ma" href="https://github.com/pydeveloperashish/Facial-Expressions-Recognition" rel="noopener ugc nofollow" target="_blank">https://github . com/pydeveloperashish/face-Expressions-Recognition</a></li></ol><div class="nb nc ez fb nd ne"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nf ab dw"><div class="ng ab nh cl cj ni"><h2 class="bd hi fi z dy nj ea eb nk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nl l"><h3 class="bd b fi z dy nj ea eb nk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nm l"><p class="bd b fp z dy nj ea eb nk ed ef dx translated">medium.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ly ne"/></div></div></a></div></div></div>    
</body>
</html>
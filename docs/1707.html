<html>
<head>
<title>Demystifying Spectral Embedding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解开光谱嵌入之谜</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/demystifying-spectral-embedding-b2368bba580?source=collection_archive---------2-----------------------#2022-01-22">https://medium.com/mlearning-ai/demystifying-spectral-embedding-b2368bba580?source=collection_archive---------2-----------------------#2022-01-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="9664" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">一种降维技术</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/b0e60713f149e17790cd1ab7c135728d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vxjP0Vchggia83GwjhInw.png"/></div></div></figure><h2 id="cb3d" class="ji jj hh bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">大家好，</h2><p id="7645" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">在这篇博客中，我们将去除<strong class="ki hi">光谱嵌入</strong>的所有复杂性，这是一种用于非线性降维的技术。如果你对什么是降维以及降维的目的不熟悉，那么可以参考我之前的<a class="ae kz" href="https://elemento.medium.com/dimensionality-reduction-c4727ad078e6" rel="noopener"> <em class="la">博客</em> </a>。事不宜迟，让我们快速回顾一下本文将涉及的内容。</p><h1 id="809b" class="lb jj hh bd jk lc ld le jo lf lg lh js in li io jw iq lj ir ka it lk iu ke ll bi translated">概观</h1><ul class=""><li id="9d1a" class="lm ln hh ki b kj kk km kn jt lo jx lp kb lq ky lr ls lt lu bi translated">谱嵌入和拉普拉斯特征映射简介</li><li id="3010" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated">理解算法的先决条件</li><li id="316e" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated">算法</li><li id="8a6b" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated">直觉</li><li id="a993" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated">额外资源</li></ul></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="b9e3" class="lb jj hh bd jk lc mh le jo lf mi lh js in mj io jw iq mk ir ka it ml iu ke ll bi translated">谱嵌入和拉普拉斯特征映射简介</h1><p id="400a" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">光谱嵌入是一种用于<strong class="ki hi">非线性降维</strong>的技术。在它的引擎盖下，正在运行的算法是<strong class="ki hi">拉普拉斯特征映射</strong>。拉普拉斯特征映射非常类似于<strong class="ki hi">等距特征映射</strong>(也称为Isomap)。如果您对Isomap不熟悉，可以在本节的末尾找到一个惊人的参考。Isomap和Laplacian特征映射之间的<strong class="ki hi">主要区别</strong>在于Isomap的目标是直接保持全局(非线性)几何形状，而Laplacian特征映射的目标是保持局部几何形状(即原始空间中的邻近点在缩减空间中保持邻近)。</p><p id="526e" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">这种技术依赖于基本假设，即<strong class="ki hi">数据位于高维空间</strong>的低维流形中。现在，这个陈述，可能会让很多读者犯错误，因为术语“流形”本身就是一个完整的数学概念，也是一个重要的概念。如果你熟悉<strong class="ki hi">流形</strong>的概念，并且稍微熟悉<strong class="ki hi">流形假设</strong>的概念，那么你就可以开始了，否则，你可以在本节的末尾找到一个非常容易理解的参考。</p><p id="b2a9" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">频谱嵌入(拉普拉斯特征映射)算法包括三个阶段:</p><ol class=""><li id="df16" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky mu ls lt lu bi translated">构建邻接图</li><li id="d738" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky mu ls lt lu bi translated">选择砝码</li><li id="fe3b" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky mu ls lt lu bi translated">获得特征图</li></ol><p id="b84c" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">在第三部分(即算法)，我们将深入这些步骤，看看我们如何以不同的方式执行这些步骤。</p><div class="mv mw ez fb mx my"><a href="https://towardsdatascience.com/isomap-embedding-an-awesome-approach-to-non-linear-dimensionality-reduction-fc7efbca47a0" rel="noopener follow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">Isomap嵌入——一种令人敬畏的非线性降维方法</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">如何用等距映射“展开瑞士卷”？</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">towardsdatascience.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm jg my"/></div></div></a></div><div class="mv mw ez fb mx my"><a href="https://bjlkeng.github.io/posts/manifolds/" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">流形:一个温和的介绍</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">继我上一篇文章中的数学内容之后，我将看看另一个出现在…</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">bjlkeng.github.io</p></div></div><div class="nh l"><div class="nn l nj nk nl nh nm jg my"/></div></div></a></div></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="4efb" class="lb jj hh bd jk lc mh le jo lf mi lh js in mj io jw iq mk ir ka it ml iu ke ll bi translated">理解算法的先决条件</h1><p id="5932" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">在本节中，我们将讨论理解拉普拉斯特征映射的先决条件。为了保持围绕拉普拉斯特征映射的焦点，我将外包对这些先决条件的解释。此外，以一种更全面的方式重复已经存在的东西没有任何好处。</p><ol class=""><li id="5e09" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky mu ls lt lu bi translated">图形基础与术语<em class="la">、</em>、<a class="ae kz" href="https://www.geeksforgeeks.org/introduction-to-graphs/" rel="noopener ugc nofollow" target="_blank">、T3】参考、</a></li><li id="01c2" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky mu ls lt lu bi translated">邻接矩阵/邻接图，<a class="ae kz" href="https://www.geeksforgeeks.org/graph-and-its-representations/" rel="noopener ugc nofollow" target="_blank"> <em class="la">参考</em> </a></li><li id="f4a9" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky mu ls lt lu bi translated">广义特征向量问题，特征向量和特征值，<a class="ae kz" href="https://www.statlect.com/matrix-algebra/generalized-eigenvector" rel="noopener ugc nofollow" target="_blank"> <em class="la">参考</em> </a>和<a class="ae kz" href="https://arxiv.org/abs/1903.11240" rel="noopener ugc nofollow" target="_blank"> <em class="la">参考</em> </a></li><li id="5ee7" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky mu ls lt lu bi translated"><a class="ae kz" href="https://en.wikipedia.org/wiki/Laplacian_matrix" rel="noopener ugc nofollow" target="_blank"> <em class="la">拉普拉斯矩阵，参考</em> </a></li></ol></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="cf94" class="lb jj hh bd jk lc mh le jo lf mi lh js in mj io jw iq mk ir ka it ml iu ke ll bi translated">算法</h1><p id="c029" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">在本节中，我们将深入探讨算法的三个主要步骤。</p><h2 id="b038" class="ji jj hh bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">1.构建邻接图</h2><p id="5869" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">第一步是基于给定的数据构建一个邻接图。如果相应的数据点是“接近的”,我们在节点I和j之间放置一条边。现在，有多种方法来定义“接近”。我将坚持在研究论文中定义的那些，这样，如果你想探索原始的研究工作，你将很容易能够起草类比。</p><ul class=""><li id="698b" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky lr ls lt lu bi translated"><em class="la">最近邻:</em>两个点，xᵢ和xⱼ，如果其中一个是彼此的k个最近邻，则通过一条边连接。</li><li id="f8fe" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated"><em class="la">ε邻域:</em>两个点，比如说xᵢ和xⱼ，通过一条边连接如果Norm(xᵢ-xⱼ) &lt; eps，其中范数(x)是通常的欧几里德范数</li></ul><h2 id="7487" class="ji jj hh bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">2.选择砝码</h2><p id="f131" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">现在，下一步是加权边，这是我们在第一步中定义的。这里也有两种不同的变化。</p><ul class=""><li id="4209" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky lr ls lt lu bi translated"><em class="la">高斯权重</em>:如果节点I和j不相连，则Wᵢⱼ = 0，否则使用公式，Wᵢⱼ = exp[-||xᵢ - xⱼ|| / t]</li><li id="2e13" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated"><em class="la"> 0/1权重</em>:如果顶点I和j由一条边连接，则Wᵢⱼ = 1，否则设Wᵢⱼ = 0。</li></ul><h2 id="87c5" class="ji jj hh bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">3.获得特征图</h2><p id="7583" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">在第二步之后，我们将得到权重矩阵(W)。使用w，我们将获得对角权重矩阵(d ),其元素是w的列(或行，因为w是对称的)和，即Dᵢᵢ = ∑ⱼ Wⱼᵢ.一旦我们获得了D，我们将获得拉普拉斯矩阵(L)，其中L = D-W。</p><blockquote class="no np nq"><p id="cd96" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">L <!-- --> aplacian是一个对称的半正定矩阵，它可以被认为是定义在g的顶点上的函数的一个算子。</p></blockquote><p id="e9bd" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">现在，最后，我们提出广义特征向量问题，</p><blockquote class="no np nq"><p id="170e" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">Lf=λDf</p></blockquote><p id="38d4" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">并找出这个问题的解决方法。再次，如果你有兴趣学习如何解决广义特征向量问题，参考这个伟大的<a class="ae kz" href="https://arxiv.org/abs/1903.11240" rel="noopener ugc nofollow" target="_blank"> <em class="la">教程</em> </a>。但是我向你保证，你不需要它，因为scikit-learn会为你处理它。所以，假设我们解决了这个问题，我们得到了这个问题的解如下:</p><blockquote class="no np nq"><p id="02d3" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">f₀ =λ₀Df₀</p><p id="9194" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">f₁ =λ₁Df₁</p><p id="bafe" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi">…</p><p id="9395" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">fₖ -₁ =λₖ -₁Dfₖ -₁</p></blockquote><p id="94bc" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">其中，f₀,f₁ … fₖ -₁，代表这个问题的特征向量，按其特征值排序，即0 = λ₀ ≤ λ₁ … ≤ λₖ -₁.在这k个特征向量中，我们省去特征值0对应的特征向量f₀，使用下一个<em class="la"> m个</em>特征向量来获得<strong class="ki hi">个低m维表示</strong>，即，</p><blockquote class="no np nq"><p id="7020" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">xᵢ=[f₁(i]，…fₘ(i]</p></blockquote><p id="18ff" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">虽然，我已经描述了拉普拉斯特征映射背后的整个算法，但是，如果你想更深入地探索它，请查看原始的研究工作，链接可以在最后一节找到。</p></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="0aa8" class="lb jj hh bd jk lc mh le jo lf mi lh js in mj io jw iq mk ir ka it ml iu ke ll bi translated">直觉</h1><p id="3976" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">在上一节中，我们详细讨论了算法。然而，我没有提供任何关于这些步骤的动机和意义的解释，以及这些确切的步骤如何将我们引向低维嵌入。这主要是因为两个原因。首先，这些步骤背后的理由是相当全面的，试图在这篇博客中总结它，会使它变得非常长。所以，如果你想得到证明，我强烈建议你查阅原始的研究工作，它提供了非常详细的证明。第二个原因是，我不是很有资格总结研究工作中提供的理由。</p><p id="9346" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">尽管如此，让我强调一下原始研究工作中提供的理由，这样你就可以自己决定，是否要探索它们。</p><ul class=""><li id="8862" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky lr ls lt lu bi translated">作者首先表明由拉普拉斯特征映射算法提供的嵌入在某种意义上最佳地保持了局部信息。</li><li id="2588" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated">然后，他们提供了一个理由，说明为什么拉普拉斯Beltrami算子的本征函数具有嵌入所需的性质。</li><li id="28da" class="lm ln hh ki b kj lv km lw jt lx jx ly kb lz ky lr ls lt lu bi translated">最后，他们证明了流形上可微函数的拉普拉斯Beltrami算子如何与热流密切相关。</li></ul><blockquote class="no np nq"><p id="3634" class="kg kh la ki b kj mm ii kl km mn il ko nr mo kq kr ns mp kt ku nt mq kw kx ky ha bi translated">图的拉普拉斯算子类似于流形上的拉普拉斯Beltrami算子。</p></blockquote></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="6d28" class="lb jj hh bd jk lc mh le jo lf mi lh js in mj io jw iq mk ir ka it ml iu ke ll bi translated">额外资源</h1><ul class=""><li id="7491" class="lm ln hh ki b kj kk km kn jt lo jx lp kb lq ky lr ls lt lu bi translated">下面你可以找到这个天才技术背后的原始研究工作的链接。你可以一边喝着茶或者咖啡，一边随意阅读。</li></ul><div class="mv mw ez fb mx my"><a href="https://ieeexplore.ieee.org/document/6789755" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">用于降维和数据表示的拉普拉斯特征映射</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">机器学习和模式识别中的一个中心问题是为机器学习和模式识别开发合适的表示。</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">ieeexplore.ieee.org</p></div></div><div class="nh l"><div class="nu l nj nk nl nh nm jg my"/></div></div></a></div><ul class=""><li id="689d" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky lr ls lt lu bi translated">下面你可以在Scikit-Learn的用户指南中找到光谱嵌入的简短描述</li></ul><div class="mv mw ez fb mx my"><a href="https://scikit-learn.org/stable/modules/manifold.html#spectral-embedding" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">2.2.流形学习</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">寻找最基本的必需品简单的最基本的必需品忘记你的忧虑和冲突我是说最基本的…</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">scikit-learn.org</p></div></div><div class="nh l"><div class="nv l nj nk nl nh nm jg my"/></div></div></a></div><ul class=""><li id="1900" class="lm ln hh ki b kj mm km mn jt mr jx ms kb mt ky lr ls lt lu bi translated">下面你可以找到Scikit-Learn的光谱嵌入实现</li></ul><div class="mv mw ez fb mx my"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html#sklearn.manifold.SpectralEmbedding" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">sk learn . manifold . spectra嵌入</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">用于非线性降维的谱嵌入。形成一个由指定函数给出的亲和矩阵…</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">scikit-learn.org</p></div></div><div class="nh l"><div class="nw l nj nk nl nh nm jg my"/></div></div></a></div></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><h1 id="3c06" class="lb jj hh bd jk lc mh le jo lf mi lh js in mj io jw iq mk ir ka it ml iu ke ll bi translated">关于我的一点点👋</h1><p id="81c3" class="pw-post-body-paragraph kg kh hh ki b kj kk ii kl km kn il ko jt kp kq kr jx ks kt ku kb kv kw kx ky ha bi translated">如果你没有兴趣认识作者，或者你已经认识我，你可以安全地跳过这一节。我保证这里没有隐藏的宝藏😆。</p><p id="5668" class="pw-post-body-paragraph kg kh hh ki b kj mm ii kl km mn il ko jt mo kq kr jx mp kt ku kb mq kw kx ky ha bi translated">我是一个机器学习和深度学习的爱好者，这是我基于相同内容的第二篇文章。如果你喜欢，请把你的手放在一起👏如果你想阅读更多基于机器学习和深度学习的文章。</p><div class="mv mw ez fb mx my"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">medium.com</p></div></div><div class="nh l"><div class="nx l nj nk nl nh nm jg my"/></div></div></a></div></div></div>    
</body>
</html>
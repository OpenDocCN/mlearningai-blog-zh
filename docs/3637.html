<html>
<head>
<title>Inference Azure Cognitive Custom Vision model in Jetson Xavier in ONNX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ONNX中Jetson Xavier的推理Azure认知定制视觉模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/inference-azure-cognitive-custom-vision-model-in-jetson-xavier-in-onnx-c8a44524d10?source=collection_archive---------5-----------------------#2022-10-01">https://medium.com/mlearning-ai/inference-azure-cognitive-custom-vision-model-in-jetson-xavier-in-onnx-c8a44524d10?source=collection_archive---------5-----------------------#2022-10-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="8190" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">定制视觉紧凑型S1模型导出到ONNX</h1><h1 id="941f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">设置</h1><ul class=""><li id="a534" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="3ac7" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure存储</li><li id="9703" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure认知定制视觉服务</li><li id="3e03" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">我使用customvision.ai网站上传图像并创建模型</li><li id="bbe8" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">将模型导出为ONNX格式</li><li id="de0b" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">jetson Xavier NX huehd.com的Usb摄像头</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="ba2e" class="ki if hh ke b fi kj kk l kl km">Note: working with Xavier is not super easy with open source packages</span></pre><h1 id="819d" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">设置Xavier</h1><ul class=""><li id="b715" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">我只有喷气背包4.6</li><li id="92a3" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">将python 3.6.9升级到python 3.7.5</li><li id="d4f1" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">跟随本教程—<a class="ae kn" href="https://www.itsupportwale.com/blog/how-to-upgrade-to-python-3-7-on-ubuntu-18-10/" rel="noopener ugc nofollow" target="_blank">https://www . itsupportwale . com/blog/how-to-upgrade-to-python-3-7-on-Ubuntu-18-10/</a></li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="a507" class="ki if hh ke b fi kj kk l kl km">sudo apt-get install python3.7</span></pre><ul class=""><li id="c9a3" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">安装pip</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="543e" class="ki if hh ke b fi kj kk l kl km">sudo apt install python3-pip</span></pre><ul class=""><li id="daa2" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">设置备选方案</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="5f64" class="ki if hh ke b fi kj kk l kl km">sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1<br/>sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 2</span><span id="e3d2" class="ki if hh ke b fi kt kk l kl km">sudo update-alternatives --config python3</span></pre><ul class=""><li id="cb3a" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">选择2将3.7设置为默认值</li><li id="7cad" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">现在检查python3版本</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="4c23" class="ki if hh ke b fi kj kk l kl km">python3 --version</span></pre><ul class=""><li id="3720" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">应显示3.7.5</li></ul><h1 id="77ae" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">现在设置杰特森推理</h1><ul class=""><li id="f24f" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">设置jetson推理包</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="7841" class="ki if hh ke b fi kj kk l kl km">sudo apt-get update<br/>sudo apt-get install git cmake libpython3-dev python3-numpy<br/>git clone --recursive https://github.com/dusty-nv/jetson-inference<br/>cd jetson-inference<br/>mkdir build<br/>cd build<br/>cmake ../<br/>make<br/>sudo make install<br/>sudo ldconfig</span></pre><ul class=""><li id="7520" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">从那里开始跟随教程—<a class="ae kn" href="https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md" rel="noopener ugc nofollow" target="_blank">https://github . com/dusty-NV/jetson-inference/blob/master/docs/building-repo-2 . MD</a></li><li id="5d81" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">python 3.7安装后再安装Pillow，imutils，matlabplot，opencv-python</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6b68" class="ki if hh ke b fi kj kk l kl km">pip3 install pillow, imutils, opencv-python<br/>sudo python3 -m pip uninstall matplotlib<br/>sudo python3 -m pip install matplotlib<br/>pip3 install tensorflow<br/>pip3 install pytorch</span></pre><ul class=""><li id="af60" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">用于访问Azure Cognitive Custom vision导出模型的示例URL—<a class="ae kn" href="https://github.com/Azure-samples/customvision-export-samples" rel="noopener ugc nofollow" target="_blank">https://github . com/Azure-samples/Custom vision-export-samples</a></li><li id="98e4" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">现在安装onnx运行时</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="79bb" class="ki if hh ke b fi kj kk l kl km">pip3 install onnx<br/>pip3 install onnxruntime</span></pre><h1 id="8757" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">从Azure认知服务自定义视觉导出模型</h1><ul class=""><li id="0060" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">go tho<a class="ae kn" href="http://customvision.ai/" rel="noopener ugc nofollow" target="_blank">http://custom vision . ai</a></li></ul><figure class="jz ka kb kc fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ku"><img src="../Images/8a99d2947b37c6b408b126c22fa7841f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D0LtcNRZNB-SqD-Qq_nphg.jpeg"/></div></div></figure><ul class=""><li id="7d00" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">转到导出选择onnx格式</li></ul><figure class="jz ka kb kc fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lc"><img src="../Images/9647a3d188f6eb21b9b651d49e8d4c02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*z14gqLxJK_0595gY.jpg"/></div></div></figure><h1 id="9a8d" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用图像文件测试示例代码</h1><ul class=""><li id="74b6" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">这是为了在我们集成到主代码之前测试onnx运行时是否工作</li><li id="86be" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">下面是代码repo—<a class="ae kn" href="https://github.com/balakreshnan/aipinbothack/tree/main/AIPinBall/camera" rel="noopener ugc nofollow" target="_blank">https://github . com/balakreshnan/aipinbothack/tree/main/AIPinBall/camera</a></li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="677b" class="ki if hh ke b fi kj kk l kl km">python3 predictonnx.py steelball/model.onnx pinballframe8890.jpg</span></pre><h1 id="aff5" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">jetson xavier nx中使用Onnx进行推理的代码</h1><ul class=""><li id="41db" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">下面是代码repo—<a class="ae kn" href="https://github.com/balakreshnan/aipinbothack/tree/main/AIPinBall/camera" rel="noopener ugc nofollow" target="_blank">https://github . com/balakreshnan/aipinbothack/tree/main/AIPinBall/camera</a></li><li id="5f02" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">现在导入必要的库</li><li id="6639" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">模型路径—<a class="ae kn" href="https://github.com/balakreshnan/aipinbothack/tree/main/AIPinBall/camera/steelball" rel="noopener ugc nofollow" target="_blank">https://github . com/balakreshnan/aipinbothack/tree/main/ai pinball/camera/steel ball</a></li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="f228" class="ki if hh ke b fi kj kk l kl km">from jetson_inference import detectNet<br/>from jetson_utils import videoSource, videoOutput<br/>import jetson.inference<br/>import jetson.utils<br/>import argparse<br/>import pathlib<br/>import numpy as np<br/>import onnx<br/>import onnxruntime<br/>import PIL.Image<br/>import time</span></pre><ul class=""><li id="c247" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">设置阈值</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="7c19" class="ki if hh ke b fi kj kk l kl km">PROB_THRESHOLD = 0.40  # Minimum probably to show results.</span></pre><ul class=""><li id="6dba" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在创建用onnx预测的类</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="5022" class="ki if hh ke b fi kj kk l kl km">class Model:<br/>    def __init__(self, model_filepath):<br/>        self.session = onnxruntime.InferenceSession(str(model_filepath))<br/>        assert len(self.session.get_inputs()) == 1<br/>        self.input_shape = self.session.get_inputs()[0].shape[2:]<br/>        self.input_name = self.session.get_inputs()[0].name<br/>        self.input_type = {'tensor(float)': np.float32, 'tensor(float16)': np.float16}[self.session.get_inputs()[0].type]<br/>        self.output_names = [o.name for o in self.session.get_outputs()]</span><span id="6b7b" class="ki if hh ke b fi kt kk l kl km">        self.is_bgr = False<br/>        self.is_range255 = False<br/>        onnx_model = onnx.load(model_filepath)<br/>        for metadata in onnx_model.metadata_props:<br/>            if metadata.key == 'Image.BitmapPixelFormat' and metadata.value == 'Bgr8':<br/>                self.is_bgr = True<br/>            elif metadata.key == 'Image.NominalPixelRange' and metadata.value == 'NominalRange_0_255':<br/>                self.is_range255 = True</span><span id="59e0" class="ki if hh ke b fi kt kk l kl km">    def predict(self, image_filepath):<br/>        # image = PIL.Image.open(image_filepath).resize(self.input_shape)<br/>	#height = image_filepath.shape[0]<br/>	#width = image_filepath.shape[1]<br/>        image_array = jetson.utils.cudaToNumpy(image_filepath)<br/>        image = PIL.Image.fromarray(image_array, 'RGB').resize(self.input_shape)<br/>        # image = PIL.Image.frombuffer("RGBX", (720,1280), image_filepath).resize(self.input_shape)<br/>        # image = image_filepath.resize(320,320)<br/>        input_array = np.array(image, dtype=np.float32)[np.newaxis, :, :, :]<br/>        input_array = input_array.transpose((0, 3, 1, 2))  # =&gt; (N, C, H, W)<br/>        if self.is_bgr:<br/>            input_array = input_array[:, (2, 1, 0), :, :]<br/>        if not self.is_range255:<br/>            input_array = input_array / 255  # =&gt; Pixel values should be in range [0, 1]</span><span id="2fed" class="ki if hh ke b fi kt kk l kl km">        outputs = self.session.run(self.output_names, {self.input_name: input_array.astype(self.input_type)})<br/>        return {name: outputs[i] for i, name in enumerate(self.output_names)}<br/></span><span id="d71f" class="ki if hh ke b fi kt kk l kl km">def print_outputs(outputs):<br/>    assert set(outputs.keys()) == set(['detected_boxes', 'detected_classes', 'detected_scores'])<br/>    for box, class_id, score in zip(outputs['detected_boxes'][0], outputs['detected_classes'][0], outputs['detected_scores'][0]):<br/>        if score &gt; PROB_THRESHOLD:<br/>            # print("{class_id}")<br/>            print(f"Az Cog Label: {class_id}, Probability: {score:.5f}, box: ({box[0]:.5f}, {box[1]:.5f}) ({box[2]:.5f}, {box[3]:.5f})")</span></pre><ul class=""><li id="75e5" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">调用ssd基本模型</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="0f73" class="ki if hh ke b fi kj kk l kl km">net = detectNet("ssd-mobilenet-v2", threshold=0.5)<br/># net = jetson.inference.detectNet(argv=["-model=home/office/project/camera/steelball/model.onnx",  "--labels=home/office/project/camera/steelball/ labels.txt", "--input-blob=input_0", "--output-cvg=scores", "--output- bbox=boxes"], threshold=0.5)</span></pre><ul class=""><li id="0e38" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">初始onnx模型</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="0700" class="ki if hh ke b fi kj kk l kl km">camera = videoSource("/dev/video0")      # '/dev/video0' for V4L2<br/>display = videoOutput("display://0") # 'my_video.mp4' for file<br/>model_path = "steelball/model.onnx"</span><span id="f7bd" class="ki if hh ke b fi kt kk l kl km">model = Model(model_path)</span></pre><ul class=""><li id="8ea4" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在运行模型库并创建自定义模型</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="a178" class="ki if hh ke b fi kj kk l kl km">while display.IsStreaming():<br/>	img = camera.Capture()<br/>	detections = net.Detect(img)<br/>	display.Render(img)<br/>	dimensions = img.shape<br/>	# print(dimensions)<br/>	display.SetStatus("Object Detection | Network {:.0f} FPS".format(net.GetNetworkFPS()) + " {:.0f} Frame Rate display".format(display.GetFrameRate()))<br/>	print("Object Detection | N&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;etwork {:.0f} FPS".format(net.GetNetworkFPS()))<br/>	# for detection in detections:<br/>	    # print(detection)<br/>	#     print(net.GetClassDesc(detection.ClassID) + " " + str(detection.Confidence) + " " + str(detection.Left) + " " + str(detection.Top) + " " + str(detection.Right) + " " + str(detection.Bottom) + " " + str(detection.Width) + " " + str(detection.Height))<br/>	    # print(net.GetClassDesc(detection.ClassID))<br/>	# print("{:.0f} FPS".format(display.GetFrameRate()))<br/>	outputs = model.predict(img)<br/>	print_outputs(outputs)</span></pre><ul class=""><li id="5b38" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在你应该看到一个视频源，终端也应该显示onnx模型的输出</li><li id="65fd" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">帧以4或5帧速率运行</li><li id="62d4" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">SSD型号每秒可运行70帧</li><li id="2a5a" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure Cognitive Custom Vision Onnx导出模型的单个类别预测大约需要210到230毫秒</li><li id="f1f6" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">onnx型号的大小接近10MB</li><li id="4da0" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">下面你可以看到模型检测钢珠的输出。</li></ul><figure class="jz ka kb kc fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ld"><img src="../Images/5d18e641b664fff4b5011f3ebf60a583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*awaFiLm0gK4pVtwT.png"/></div></div></figure></div><div class="ab cl le lf go lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ha hb hc hd he"><ul class=""><li id="bf40" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">仅限1.11.0版本的onnxruntime-gpu</li><li id="8523" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">我卸载了onnxruntime和onnxruntime 1 . 21 . 1——两个版本</li><li id="665b" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">1.12.1不适用于jetson xavier nx和jetpack 4.6.1</li></ul><figure class="jz ka kb kc fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ll"><img src="../Images/83b780dca4c2ca92dab798e1179ff8b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MXotcuuBVRQcMpSN.jpg"/></div></div></figure><ul class=""><li id="eb96" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">从0.220秒到0.03或0.04秒</li><li id="74d8" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">超级快</li></ul></div><div class="ab cl le lf go lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ha hb hc hd he"><p id="239c" class="pw-post-body-paragraph lm ln hh je b jf ko lo lp jh kp lq lr jj ls lt lu jl lv lw lx jn ly lz ma jp ha bi translated"><em class="mb">最初发表于</em><a class="ae kn" href="https://github.com/balakreshnan/Samples2022/blob/main/AzureAI/CustomVisioninfxavier.md" rel="noopener ugc nofollow" target="_blank"><em class="mb">【https://github.com】</em></a><em class="mb">。</em></p><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt la mf"/></div></div></a></div></div></div>    
</body>
</html>
# ä½¿ç”¨ Keras çš„æƒ…ç»ªæ£€æµ‹å™¨â€”â€”å¸¦æºä»£ç â€”â€”æœ€ç®€å•çš„æ–¹æ³•

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/emotion-detector-using-keras-with-source-code-easiest-way-easy-implementation-6f62ad9e2528?source=collection_archive---------5----------------------->

æ‰€ä»¥åœ¨ä»Šå¤©çš„åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œåœ¨ Keras ä¸­æ„å»ºä¸€ä¸ªæƒ…ç»ªæ£€æµ‹å™¨æ¨¡å‹ã€‚è¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„é¡¹ç›®ä¹‹ä¸€ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘å¾ˆå…´å¥‹å¼€å§‹å®ƒï¼Œæ‰€ä»¥æ²¡æœ‰ä»»ä½•è¿›ä¸€æ­¥çš„åŸå› ã€‚

**åœ¨è¿™é‡Œé˜…è¯»å¸¦æºä»£ç çš„æ•´ç¯‡æ–‡ç« â€”**[https://machine learning projects . net/emotion-detector-using-keras/](https://machinelearningprojects.net/emotion-detector-using-keras/)

![](img/e0adc9f2521551c52d1eb5703fafcf26.png)

Emotion detector

# è®©æˆ‘ä»¬å¼€å§‹å§â€¦

## æ­¥éª¤ 1-å¯¼å…¥æƒ…æ„Ÿæ£€æµ‹å™¨æ‰€éœ€çš„åº“ã€‚

```
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,BatchNormalization,Flatten
from keras.models import Sequential
from keras.optimizers import rmsprop_v2
from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint
from keras.models import load_model
import cv2
from PIL import Image
import numpy as np
import pandas as pd
import os
from keras.utils.np_utils import to_categorical
import seaborn as sns
```

## æ­¥éª¤ 2-è¯»å–æ‰€æœ‰å›¾åƒï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨æ•°æ®å¸§ä¸­ã€‚

```
int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}
emotions2int = {'Angry':0,'Fear':1,'Happy':2,'Neutral':3,'Sad':4,'Surprise':5}

dic = {'images':[], 'labels':[], 'purpose':[]}

for d in os.listdir('fer2013/'):
    print(d)
    for emotion in os.listdir(f'fer2013/{d}'):
        print(emotion)
        for i in os.listdir(f'fer2013/{d}/{emotion}'):
            img = cv2.imread(f'fer2013/{d}/{emotion}/{i}',0)
            img = img.reshape(48,48,1)

            dic['images'].append(img)
            dic['labels'].append(emotion)

            if d=='train':
                dic['purpose'].append('T')
            else:
                dic['purpose'].append('V')

df = pd.DataFrame(dic)
df.head()
```

*   åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªæ˜¯è¯»å–æˆ‘ä»¬çš„æ•°æ®ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªç†ŠçŒ«æ•°æ®å¸§ä¸­ã€‚
*   å›¾åƒåŒ…å«å½¢çŠ¶ä¸º 48X48X1 çš„å›¾åƒã€‚
*   æ ‡ç­¾æè¿°äº†å›¾åƒçš„æƒ…æ„Ÿã€‚
*   ç›®çš„æœ‰ä¸¤ä¸ªå€¼ T å’Œ Vï¼ŒT ç”¨äºè®­ç»ƒï¼ŒV ç”¨äºéªŒè¯ã€‚

![](img/89658fbca1a42f7ee9747a31003d9c18.png)

## æ­¥éª¤ 3 â€”æå–è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®ã€‚

```
train_data = df[df['purpose']=='T']
val_data = df[df['purpose']=='V']
```

*   åˆ›å»º 2 ä¸ªä¸åŒçš„æ•°æ®æ¡†ã€‚
*   ç¬¬ä¸€æ¬¡ç”¨äºè®­ç»ƒï¼Œç¬¬äºŒæ¬¡ç”¨äºéªŒè¯ã€‚

æ£€æŸ¥è´Ÿè´£äººçš„åŸ¹è®­æ•°æ®ã€‚

```
train_data.head()
```

![](img/d24e03a59afce87646db07c63be3d11c.png)

æ£€æŸ¥éªŒè¯æ•°æ®çš„æ ‡é¢˜ã€‚

```
val_data.head()
```

![](img/94c6f44d2f161760e6d0df9d28bc116a.png)

## æ­¥éª¤ 4-æ£€æŸ¥è®­ç»ƒæ•°æ®çš„æ ‡ç­¾åˆ—ä¸­çš„å€¼ã€‚

```
train_data[â€˜labelsâ€™].value_counts()
```

*   æ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹å›¾ä¸­çœ‹åˆ°çš„ï¼Œæ ‡ç­¾åœ¨è®­ç»ƒæ•°æ®ä¸­éå¸¸ä¸å¹³è¡¡ï¼Œå› æ­¤æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€æ­¥ä¸­å¹³è¡¡å®ƒä»¬ã€‚

![](img/61d4c02d262b78a02c11d98dd6e84897.png)

## æ­¥éª¤ 5â€”â€”è·å–æ‰€æœ‰ç±»çš„ç›¸åŒå®ä¾‹ã€‚

```
happy_df = train_data[train_data['labels']=='Happy'].sample(n=3171)
neutral_df = train_data[train_data['labels']=='Neutral'].sample(n=3171)
sad_df = train_data[train_data['labels']=='Sad'].sample(n=3171)
fear_df = train_data[train_data['labels']=='Fear'].sample(n=3171)
angry_df = train_data[train_data['labels']=='Angry'].sample(n=3171)
surprise_df = train_data[train_data['labels']=='Surprise'].sample(n=3171)

train_data = pd.concat([happy_df,neutral_df,sad_df,fear_df,angry_df,surprise_df])

train_data = train_data.sample(frac=1)
train_data.reset_index(inplace=True)
train_data.drop('index',inplace=True,axis=1)

train_data.head()
```

*   åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰å–äº† 3171 ä¸ªæ¯ç§æƒ…æ„Ÿå¹¿å‘Šçš„å®ä¾‹ï¼Œå¹¶ä¸å®ƒä»¬è”ç³»èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªæœ€ç»ˆçš„æ•°æ®æ¡†æ¶ã€‚

![](img/4d1b0dfc5242fa669f39ea0beb715f4b.png)

## æ­¥éª¤ 6-å†æ¬¡æ£€æŸ¥åˆ—è½¦æ•°æ®æ ‡ç­¾åˆ—ä¸­çš„å€¼ã€‚

```
train_data[â€˜labelsâ€™].value_counts()
```

*   ç°åœ¨å†æ¬¡æ£€æŸ¥è®¡æ•°ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„ç±»éƒ½æ˜¯å¹³è¡¡çš„ã€‚

![](img/dc78037e8dd2bc477edb6e09308af112.png)

ç»˜åˆ¶åˆ—ã€‚

```
sns.countplot(train_data[â€˜labelsâ€™])
```

![](img/c707d4a3ae09a644590511a011ea0aa1.png)

## æ­¥éª¤ 7-å£°æ˜ä¸€äº›å¸¸é‡ã€‚

```
batch_size= 32
classes = 6
rows,columns=48,48
```

## ç¬¬ 8 æ­¥â€”â€”ä»¥æ­£ç¡®çš„å½¢å¼è·å–æƒ…ç»ªæ£€æµ‹å™¨æ¨¡å‹çš„æ•°æ®ã€‚

```
train_labels = list(train_data['labels'].replace(emotions2int))
train_labels = to_categorical(train_labels)

val_labels = list(val_data['labels'].replace(emotions2int))
val_labels = to_categorical(val_labels)

train_data = list(train_data['images'])
train_data = np.array(train_data)

val_data = list(val_data['images'])
val_data = np.array(val_data)
```

*   ç¬¬ 1â€“2 è¡Œâ€”å°†æƒ…ç»ªè½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦‚æ„¤æ€’è½¬æ¢ä¸º 0ï¼Œææƒ§è½¬æ¢ä¸º 1ï¼Œç­‰ç­‰ï¼Œç„¶åä½¿ç”¨ to _ categorical å°†è¿™äº›æ•°å­—è½¬æ¢ä¸º one-hot ç¼–ç ã€‚è¿™æ˜¯ç”¨äºè®­ç»ƒæ•°æ®çš„ã€‚
*   ç¬¬ 4â€“5 è¡Œâ€”å¯¹éªŒè¯æ•°æ®æ‰§è¡Œä¸ä¸Šè¿°ç›¸åŒçš„æ“ä½œã€‚
*   ç¬¬ 7â€“8 è¡Œâ€”å‡ºäºè®­ç»ƒç›®çš„ï¼Œå°†å›¾åƒåˆ—è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç„¶åè½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸ä¼šå°† dataframe åˆ—ç”¨äºè®­ç»ƒç›®çš„ï¼Œå› æ­¤æˆ‘ä»¬å°†å®ƒä»¬è½¬æ¢ä¸ºæ•°ç»„ã€‚
*   ç¬¬ 10â€“11 è¡Œâ€”å¯¹éªŒè¯æ•°æ®æ‰§è¡Œä¸ä¸Šè¿°ç›¸åŒçš„æ“ä½œã€‚

æ£€æŸ¥è®­ç»ƒæ•°æ®å½¢çŠ¶ã€‚

```
train_data.shape
```

![](img/2c59989756c53ec10e464012c95a37ca.png)

æ£€æŸ¥éªŒè¯æ•°æ®å½¢çŠ¶ã€‚

```
val_data.shape
```

![](img/381322fbe963bb596ad2ab208bc9e872.png)

## æ­¥éª¤ 9â€”â€”åˆ›å»ºæƒ…ç»ªæ£€æµ‹å™¨æ¨¡å‹ã€‚

```
model = Sequential()

# First Block
model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

# Second Block
model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

# Third Block
model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

# Fourth Block
model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

# Fifth Block
model.add(Flatten())
model.add(Dense(256,activation='elu',kernel_initializer='he_normal'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# Sixth Block
model.add(Dense(128,activation='elu',kernel_initializer='he_normal'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# Seventh Block
model.add(Dense(64,activation='elu',kernel_initializer='he_normal'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# Eighth Block
model.add(Dense(classes,activation='softmax',kernel_initializer='he_normal'))

print(model.summary())
```

![](img/320567450889e836b6f83cce61c363fd.png)

*   åˆ›å»ºæˆ‘ä»¬çš„å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚
*   åˆ›å»º 4 å—[ã€Conv2Dã€‘](https://keras.io/api/layers/convolution_layers/convolution2d/)â€”[â€”](https://keras.io/api/layers/normalization_layers/batch_normalization/)â€”[Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/)â€”[batch normalization](https://keras.io/api/layers/normalization_layers/batch_normalization/)â€”[maxpooli2d](https://keras.io/api/layers/pooling_layers/max_pooling2d/)â€”[Dropout](https://keras.io/api/layers/regularization_layers/dropout/)å±‚ã€‚
*   åˆ›å»º 3 å—[å¯†é›†](https://keras.io/api/layers/core_layers/dense/)â€”â€”æ‰¹é‡â€”â€”å‰”é™¤å±‚ï¼Œæœ€ç»ˆåˆ›å»º 1 ä¸ªå…·æœ‰ 6 ä¸ªç¥ç»å…ƒ/èŠ‚ç‚¹çš„å¯†é›†å±‚ã€‚

## æ­¥éª¤ 10-å£°æ˜å›è°ƒã€‚

```
checkpoint = ModelCheckpoint('model\\6_class_emotion_detector_V2.h5',
                             save_best_only=True,
                             mode='min',
                             monitor='val_loss',
                             verbose=1)

earlystopping = EarlyStopping(patience=10,
                             verbose=1,
                             min_delta=0,
                             monitor='val_loss',
                             restore_best_weights=True)

callbacks = [checkpoint, earlystopping]

model.compile(metrics=['accuracy'],
             optimizer='rmsprop',
             loss='categorical_crossentropy')
```

*   åˆ›å»º[æå‰åœæ­¢](https://keras.io/api/callbacks/early_stopping/)å’Œ[æ£€æŸ¥ç‚¹](https://keras.io/api/callbacks/model_checkpoint/)å›è°ƒã€‚

## æ­¥éª¤ 11 â€”è®­ç»ƒæ¨¡å‹ã€‚

```
train_samples = 28273
validation_samples = 3534
batch_size = 64
epochs=30

history = model.fit(train_data,
                    train_labels,
                    epochs=epochs,
                    steps_per_epoch=train_samples//batch_size,
                    validation_data=(val_data,val_labels),
                    validation_steps=validation_samples//batch_size,
                    callbacks=callbacks)
```

*   æœ€åè®­ç»ƒæ¨¡å‹ã€‚

![](img/67838304b6e7089708b0d53465fc800b.png)

## ç¬¬ 12 æ­¥â€”å®æ—¶é¢„æµ‹ã€‚

```
import cv2
from keras.models import load_model
import numpy as np

int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}
model = load_model('model\\6_class_emotion_detector_V2.h5')
cap = cv2.VideoCapture(0)

classifier = cv2.CascadeClassifier('Haarcascades\\haarcascade_frontalface_default.xml')

def detect_face(frame):
    faces=classifier.detectMultiScale(frame,1.3,4)
    if faces==():
        return frame
    for x,y,w,h in faces:
        cv2.rectangle(frame,(x,y),(x+w,y+h),(172,42,251),2)
        face = frame[y:y+h,x:x+w]
        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)
        face = cv2.resize(face,(48,48))
        face = face.reshape(1,48,48,1)
        cv2.putText(frame,text=int2emotions[np.argmax(model.predict(face))],
                    org=(x,y-15),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(106,40,243),thickness=2)
    return frame

while 1:
    ret,frame= cap.read()
    if ret==True:
        cv2.imshow('emotion_detector',detect_face(frame))
        if cv2.waitKey(1)==27:
            break
cap.release()
cv2.destroyAllWindows()
```

![](img/e0adc9f2521551c52d1eb5703fafcf26.png)

Emotion detector

å¦‚æœå¯¹æƒ…ç»ªæ£€æµ‹å™¨æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·é€šè¿‡ç”µå­é‚®ä»¶æˆ– LinkedIn è”ç³»æˆ‘ã€‚

***æ¢ç´¢æ›´å¤šæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€NLPã€Flask é¡¹ç›®è®¿é—®æˆ‘çš„åšå®¢â€”*** [***æœºå™¨å­¦ä¹ é¡¹ç›®***](https://machinelearningprojects.net/)

**å¦‚éœ€è¿›ä¸€æ­¥çš„ä»£ç è§£é‡Šå’Œæºä»£ç ï¼Œè¯·è®¿é—®æ­¤å¤„â€”**[https://machine learning projects . net/emotion-detector-using-keras/](https://machinelearningprojects.net/emotion-detector-using-keras/)

è¿™å°±æ˜¯æˆ‘å†™ç»™è¿™ä¸ªåšå®¢çš„æ‰€æœ‰å†…å®¹ï¼Œæ„Ÿè°¢ä½ çš„é˜…è¯»ï¼Œæˆ‘å¸Œæœ›ä½ åœ¨é˜…è¯»å®Œè¿™ç¯‡æ–‡ç« åï¼Œèƒ½æœ‰æ‰€æ”¶è·ï¼Œç›´åˆ°ä¸‹æ¬¡ğŸ‘‹â€¦

***çœ‹æˆ‘ä»¥å‰çš„å¸–å­:*** [***çŒ´å­å“ç§åˆ†ç±»åˆ©ç”¨è¿ç§»å­¦ä¹ ***](https://machinelearningprojects.net/monkey-breed-classification/)

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai æäº¤å»ºè®®

### å¦‚ä½•æˆä¸º Mlearning.ai ä¸Šçš„ä½œå®¶

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
<html>
<head>
<title>Mask Detection using Detectron2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用检测器2进行掩模检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/mask-detection-using-detectron2-225383c7d069?source=collection_archive---------6-----------------------#2021-06-05">https://medium.com/mlearning-ai/mask-detection-using-detectron2-225383c7d069?source=collection_archive---------6-----------------------#2021-06-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1bac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用检测器2进行掩模检测。这篇文章是上一篇文章的继续——OpenCV-dlib的<a class="ae jc" rel="noopener" href="/@xictus77/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">面具叠加</a>和Keras的<a class="ae jc" rel="noopener" href="/mlearning-ai/face-recognition-for-superimposed-facemasks-using-vggface2-in-keras-c13e610acd56">使用VGGFace2的叠加面具的人脸识别</a></p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><div class="jk jl jm jn fd ab cb"><figure class="jo jp jq jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/17286c5561b202c8392bf1e9c0145ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*e3GoM6RccfdDzh-zYfIvzg.jpeg"/></div></figure><figure class="jo jp jq jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/431a4e8ca65085a4f5e1d7fd170debf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Pmxr51QIGlfYS6yBPG3TzA.jpeg"/></div><figcaption class="kb kc et er es kd ke bd b be z dx kf di kg kh">Photo by <a class="ae jc" href="https://unsplash.com/@zvandrei?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Andrey Zvyagintsev</a> on <a class="ae jc" href="https://unsplash.com/s/photos/masked-face?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a> (Original image (left)) and edited image (right) using <a class="ae jc" rel="noopener" href="/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">face mask overlay</a> and author)</figcaption></figure></div><p id="3158" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将通过facebook实现新的<a class="ae jc" href="https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/" rel="noopener ugc nofollow" target="_blank"> Detectron2库</a>，在我们的“蒙面人脸”数据集上进行对象检测训练。此后，我们将在我们的测试图像上运行我们的Detectron2推理，其中使用openCV和dlib库合成叠加了人脸遮罩。</p><p id="e195" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将在<em class="ki"> Google Colab </em>上运行，因为我们将利用它的免费GPU资源来训练我们的对象检测器。我们正在使用的数据集可以从<a class="ae jc" href="https://www.kaggle.com/andrewmvd/face-mask-detection/notebooks" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载。我们选择该数据集，因为在该数据集中有3个类别，即戴口罩、口罩佩戴不当、未戴口罩。你可以在这篇文章的末尾找到<em class="ki"> colab笔记本</em>。</p><h1 id="d995" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">检测器2概述</h1><p id="f26e" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di">D</span><a class="ae jc" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"><em class="ki">etectron 2</em></a>是一个高级模型动物园，提供最先进的检测和分割算法。由脸书人工智能研究(FAIR)集团于2020年2月首次发布，是<a class="ae jc" href="https://github.com/facebookresearch/Detectron/" rel="noopener ugc nofollow" target="_blank"> Detectron </a>和<a class="ae jc" href="https://github.com/facebookresearch/maskrcnn-benchmark/" rel="noopener ugc nofollow" target="_blank"> maskrcnn-benchmark </a>的继任者。它包括:</p><ul class=""><li id="8f3d" class="lv lw hh ig b ih ii il im ip lx it ly ix lz jb ma mb mc md bi translated">对象检测、实例分割、全景分割、语义分割和关键点检测的训练配方。</li><li id="5b8e" class="lv lw hh ig b ih me il mf ip mg it mh ix mi jb ma mb mc md bi translated">80多个预训练模型用于微调(或重新训练)。</li><li id="8a46" class="lv lw hh ig b ih me il mf ip mg it mh ix mi jb ma mb mc md bi translated">数据集支持流行的视觉数据集，如COCO、Cityscapes、LVIS、PASCAL VOC、ADE20k。</li></ul><p id="6e83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Detectron2以COCO JSON格式注册数据集。</p><h1 id="2962" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">我们的数据集概述</h1><p id="d289" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">我们将在Kaggle的面罩数据集上训练我们的custom Detectron2探测器。该数据集由853幅图像组成，分为3类——戴面具的人、面具佩戴不当的人、未戴面具的人。</p><p id="8f03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于Detectron2没有接受过检测面罩的训练，我们需要训练底层网络来适应我们的定制任务。在此之前，让我们对数据集执行探索性数据分析。[ <a class="ae jc" href="https://github.com/xictus77/Facial-mask-overlay-with-OpenCV-Dlib/blob/master/EDAwithxml_mask_detection_dataset.ipynb" rel="noopener ugc nofollow" target="_blank">源代码</a></p><p id="90c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据的分布可以在图1中显示，其中明显存在跨3个类的类类型的不平衡。这个比例是80%戴口罩的人，17%不戴口罩的人和3%戴口罩的人。我们深入检查图像中边界框的分布。图2使用直方图描述了分布，很明显，大约70%(接近600个图像)的图像具有少于5个边界框。</p><figure class="jk jl jm jn fd jp er es paragraph-image"><div class="er es mj"><img src="../Images/714139ef2df15857ee56d291a50ccb75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*UMsf6jcctQnvgkgvK6__CA.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx">Figure 1 — Imbalance distribution across 3 classes</figcaption></figure><figure class="jk jl jm jn fd jp er es paragraph-image"><div class="er es mj"><img src="../Images/06a56026503df5a4e84b0b5186647ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*EAgg8gDCiti5lKJAmGfJvQ.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx">Figure 2— Most images have less than 5 bounding boxes per image</figcaption></figure><p id="9d0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有几种方法可以处理这种类型的不平衡数据集—合成少数过采样技术(SMOTE)、过采样少数类、欠采样多数类等。然而，出于本文的目的，我们将继续用我们的数据集训练我们的对象检测器，并记住我们的数据集是有偏差的。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><h1 id="24ac" class="kj kk hh bd kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc mo le lf lg bi translated">入门指南</h1><p id="44e8" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">当我们使用Google Colab时，安装Detectron2会相对简单。它可以用以下几行安装:</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="cb2a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此时，我们需要重启笔记本运行时来继续。</p><p id="3dee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来我们将继续导入必要的<strong class="ig hi">检测器2 </strong>依赖项。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="8f36" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">注册数据集</h1><p id="f6c4" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">要使用带有Detectron2的数据集，我们需要注册它，以便我们可以使用预定义的数据加载器。由于我们的数据集不是COCO格式，我们将需要编写一个函数，以列表的形式返回所有需要的数据信息，并将结果传递给DatasetCatalog.register。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div><figcaption class="kb kc et er es kd ke bd b be z dx">Reformat detectron2_dataset from xml2coco json format</figcaption></figure><p id="0e88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Detectron2在一个<code class="du mr ms mt mu b">registry</code>中跟踪可用数据集的列表，因此我们必须向Detectron2注册我们的自定义数据，以便可以调用它进行训练。我们注册我们的元数据，它告诉Detectron2哪个类id对应于哪个类，这有助于以后的可视化。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="a2fa" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">可视化探测器2训练数据</h1><p id="56d1" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">这一步是可选的，因为我们已经在探索性数据分析阶段查看了我们的训练数据集。但是，我们可以利用Detectron2中的visualizer库轻松查看我们的训练数据，以确保数据已正确导入。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><div class="jk jl jm jn fd ab cb"><figure class="jo jp mv jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/39cca5a8fc3b2c6ce699012b668d0817.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*jBQXRD_HgggDr1d5WtTPSw.png"/></div></figure><figure class="jo jp mw jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/9c164ba17cb2d6189e129728a99ca92e.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*RJ_5qo-H2b7ZD0u6rYUI7w.png"/></div></figure><figure class="jo jp mx jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/d23d82cc2b3895f1ee6b7c1250dbdbcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*f17BzxukSeHRxmgfIEnbjg.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx my di mz kh">Visualization on training dataset</figcaption></figure></div><h1 id="b1c8" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">使用迁移学习微调预训练模型</h1><p id="3e87" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">注册数据集后，我们可以使用<a class="ae jc" href="https://github.com/facebookresearch/detectron2/blob/master/detectron2/engine/defaults.py#L181" rel="noopener ugc nofollow" target="_blank"> DefaultTrainer类</a>在预训练模型上简单地执行迁移学习。Detectron2允许你在确定你的模型架构时有很多选择，你可以参考使用<a class="ae jc" href="https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank"> Detectron2模型动物园</a>。</p><figure class="jk jl jm jn fd jp er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es na"><img src="../Images/b8d516980662fa4c9ab2419fe7c38687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XHqLJE7D0jMS9t8osrO1EQ.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx">Object detection models available in the <a class="ae jc" href="https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank">Detectron2 model zoo</a>.</figcaption></figure><p id="4315" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的例子中，我们使用下面的脚本来微调我们选择的预训练模型。这可能不是理想的配置，我们可以修改某些参数，如学习速率、最大迭代次数、批量大小，以获得更好的结果。然而，对于这篇文章，我们将使用这些值作为默认值，因为测试结果将显示训练模型的良好性能。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="8768" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以开始训练我们的模型了。训练过程将持续近一个小时，我们可以使用tensorboard可视化训练和损失图。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><figure class="jk jl jm jn fd jp er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es nb"><img src="../Images/0db8dae87031f44af297210e766ee0c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzxzT_ofgLKt9FoTLePjkQ.png"/></div></div></figure><p id="d6de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里有许多感兴趣的指标——最值得注意的是<code class="du mr ms mt mu b">total_loss</code>我们可以看到，总损耗在999次迭代后收敛到一个合理的低值。我们当然可以通过将最大迭代次数增加到1500次或更多来提高模型性能和微调模型。</p><h1 id="5761" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">对测试图像运行Detectron2推理</h1><p id="2846" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">随着模型被训练，我们可以使用我们的自定义检测器2对测试集进行推断，这些测试集是我们使用<a class="ae jc" rel="noopener" href="/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d"> mask-overlay-opencv-Dlib </a>创建的图像。</p><p id="a60c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以通过创建一个预测器对象来对我们的测试集进行推断。</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="e600" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">测试图像的结果如下图1和图2所示。我们可以观察到，定制训练的检测器2在检测是否佩戴了所绘制的面罩方面表现良好。它不能正确地检测和分类不正确地佩戴绘制的面罩的人。主要原因是由于训练数据集具有非常少量的带有不正确佩戴面具的人的图像。</p><p id="1ace" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还可以考虑使用<code class="du mr ms mt mu b">SCORE_THRESH_TEST</code>来改变模型进行预测所需的置信度阈值。</p><div class="jk jl jm jn fd ab cb"><figure class="jo jp nc jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/c6d8cfec26555bf25da16c84a3542f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*ZbfN0mHIPxboUeJfqWDkPQ.png"/></div></figure><figure class="jo jp nd jr js jt ju paragraph-image"><img src="../Images/62d25149b101c08063631ec2a4a1a72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*0tQ11-vGprRK2Jxs06xQwA.png"/></figure><figure class="jo jp ne jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/6ae53e6bb76a59f22ce660489bb9a344.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*m4sAaJe_Y78snIbablyugQ.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx nf di ng kh">Figure 1 —Face mask drawn on the image on the right cannot be detected</figcaption></figure></div><div class="ab cb"><figure class="jo jp nh jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/1d859f775d0e8f0f03fce8fe38900c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*gFbaJTRaCHan4l_O87TmDA.png"/></div></figure><figure class="jo jp ni jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/97e300c9b8533fb21dc2c6ca35ec66e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*tLA_G-VqGH5cjl0-ezO2PA.png"/></div></figure><figure class="jo jp nj jr js jt ju paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/f399c56d3e4cb548a2356933d6c3d2d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*qwgFru1UHLbae_6xGVn-OA.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx nk di nl kh">Figure 2— Face mask drawn on the image on the right incorrectly labelled</figcaption></figure></div><h1 id="0e7b" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">保存您的模型和配置</h1><p id="cdb3" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">我们现在可以将权重保存在<code class="du mr ms mt mu b">os.path.join(cfg.OUTPUT_DIR, "model_final.pth")</code>中，以便将来通过导出到Google Drive进行推断。</p><p id="1fe7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要使用模型进行推理，您需要模型权重和配置。要保存配置，请使用:</p><figure class="jk jl jm jn fd jp"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="b612" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">结论</h1><p id="9e09" class="pw-post-body-paragraph ie if hh ig b ih lh ij ik il li in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">在这篇文章中，我们已经成功地使用一个自定义的人脸遮罩数据集训练了一个Detectron2对象检测模型，并使用它在我们使用OpenCV和dlib库生成的“遮罩”人脸上进行测试。结果表明，预先训练的模型能很好地检测出被戴上的面具，但不能检测出面具是否被正确戴上。如果我们能够用具有更平衡的类的数据集进行训练，结果应该会改善，特别是在类上——面具佩戴不正确。</p><p id="01d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果还表明，我的文章中的脚本— <a class="ae jc" rel="noopener" href="/@xictus77/facial-mask-overlay-with-opencv-dlib-4d948964cc4d">使用OpenCV-dlib </a>的面部面具覆盖可以提供另一种替代解决方案来创建具有面部面具的人的图像数据集，这些图像数据集可以用于<strong class="ig hi"> <em class="ki">训练</em> </strong> <em class="ki"> </em>和<strong class="ig hi"> <em class="ki">评估</em> </strong> <em class="ki"> </em>面部识别系统。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="b187" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参考</p><div class="nm nn ez fb no np"><a href="https://gilberttanner.com/blog/detectron2-train-a-instance-segmentation-model" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hi fi z dy nu ea eb nv ed ef hg bi translated">检测器2训练实例分割模型</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">在本文中，您将学习如何创建自己的实例分割数据集，以及如何训练Detectron2模型…</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">gilberttanner.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od jz np"/></div></div></a></div><div class="nm nn ez fb no np"><a href="https://gilberttanner.com/blog/detectron-2-object-detection-with-pytorch" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hi fi z dy nu ea eb nv ed ef hg bi translated">探测器2 -使用PyTorch进行物体探测</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">2020年2月更新:脸书研究所发布了预建的Detectron2版本，这使得本地安装变得更加容易…</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">gilberttanner.com</p></div></div><div class="ny l"><div class="oe l oa ob oc ny od jz np"/></div></div></a></div><div class="nm nn ez fb no np"><a href="https://www.kaggle.com/gozyssj4/mask-detection-starting-with-the-xml-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hi fi z dy nu ea eb nv ed ef hg bi translated">掩码检测——从XML数据集开始</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自面罩检测的数据</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">www.kaggle.com</p></div></div><div class="ny l"><div class="of l oa ob oc ny od jz np"/></div></div></a></div><p id="0e9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图像来源</p><div class="nm nn ez fb no np"><a href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hi fi z dy nu ea eb nv ed ef hg bi translated">面罩检测</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">属于3类的853个图像。</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">www.kaggle.com</p></div></div><div class="ny l"><div class="og l oa ob oc ny od jz np"/></div></div></a></div><p id="3591" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在这里下载我的完整代码</p><p id="e4d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://github.com/xictus77/Facial-mask-overlay-with-OpenCV-Dlib.git" rel="noopener ugc nofollow" target="_blank">https://github . com/xictus 77/face-mask-overlay-with-OpenCV-dlib . git</a></p></div></div>    
</body>
</html>
<html>
<head>
<title>How to use embeddings for feature extraction?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用嵌入进行特征提取？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-use-embeddings-for-feature-extraction-4956db52b5f5?source=collection_archive---------3-----------------------#2022-10-07">https://medium.com/mlearning-ai/how-to-use-embeddings-for-feature-extraction-4956db52b5f5?source=collection_archive---------3-----------------------#2022-10-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a7c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在现实世界的数据集中，我们可以有价格这样的数字特征，也可以有性别这样的分类特征。</p><p id="2fc7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，分类特征可以通过编码器进行处理，如创建稀疏二进制矩阵的one-hot编码器、为每个类别分配标签的label编码器，甚至更复杂的方法，如catboost编码器，在分类的情况下可以将其视为条件概率，在回归问题的情况下可以将其视为移动平均值。</p><p id="9634" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们有一个小的类别集时，这些技术可能非常强大和有用，但是如果我们有一个平均85个单词的描述产品的文本呢？</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="5826" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">数据集和问题定义:</strong></p><p id="3a63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种情况下，我们有一个27列的数据集，目标是预测每个食谱在未来几周内将产生的销售额。</p><p id="9312" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们有几个特点，如:</p><ul class=""><li id="8b04" class="jj jk hh ig b ih ii il im ip jl it jm ix jn jb jo jp jq jr bi translated"><strong class="ig hi">数字</strong>:卡路里、碳水化合物、蛋白质、脂肪等。</li><li id="c19d" class="jj jk hh ig b ih js il jt ip ju it jv ix jw jb jo jp jq jr bi translated"><strong class="ig hi">分类</strong>:难度，烹饪_时间等。</li><li id="7356" class="jj jk hh ig b ih js il jt ip ju it jv ix jw jb jo jp jq jr bi translated"><strong class="ig hi">文本:</strong>描述和配方名称</li></ul><figure class="jy jz ka kb fd kc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es jx"><img src="../Images/a0c025c603a156dd93696c19c2b870f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHcHItlwJNVOSdw7c7TWAw.png"/></div></div><figcaption class="kj kk et er es kl km bd b be z dx">sample of the dataset</figcaption></figure></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="1c15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">如何使用嵌入从描述和recipe_name中提取信息？</strong></p><p id="32c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将利用令人难以置信的拥抱脸🤗框架从这些特性中提取信息。</p><p id="7c49" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">首先:</strong>我们需要导入模型和标记器:</p><p id="f010" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以尝试不同的模式，你可以在这里查看:<a class="ae kn" href="https://huggingface.co/models?pipeline_tag=feature-extraction" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/models?pipeline _ tag =特征提取</a></p><p id="4b1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用模型的记号赋予器很重要，这样它就能以正确的格式接收数据，而且它们也很有用，因为它们已经为您清理了数据。</p><p id="af42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个记号赋予器都有不同的处理数据的方法，因此了解它们是很重要的。</p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="f7dd" class="kt ku hh kp b fi kv kw l kx ky">from transformers import AutoModel, AutoTokenizer</span><span id="6b0b" class="kt ku hh kp b fi kz kw l kx ky">model_ckpt <strong class="kp hi">=</strong> "distilbert-base-uncased"<br/>tokenizer <strong class="kp hi">=</strong> AutoTokenizer<strong class="kp hi">.</strong>from_pretrained(model_ckpt)<br/>model <strong class="kp hi">=</strong> AutoModel<strong class="kp hi">.</strong>from_pretrained(model_ckpt)</span></pre><p id="28b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第二:</strong>我们提取与代表整个文本序列的标记CLS相关联的隐藏状态，而不是为字符串中的每个标记处理一个768数组，我们只需要处理一个数组(768维因型号而异)。</p><p id="9908" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DistilBert的CLS令牌是第一个，因此我们可以使用下面的代码来访问隐藏状态:</p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="e216" class="kt ku hh kp b fi kv kw l kx ky">df_train_clean['recipe_name'] = df_train_clean['recipe_name'].apply(lambda x: model(**tokenizer(x, return_tensors="pt")).last_hidden_state[:,0,:].detach().numpy()[0])</span><span id="c67d" class="kt ku hh kp b fi kz kw l kx ky">df_train_clean['description'] = df_train_clean['description'].apply(lambda x: model(**tokenizer(x, return_tensors="pt")).last_hidden_state[:,0,:].detach().numpy()[0])</span></pre></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="559d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">绘制嵌入图</strong></p><p id="efeb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以使用一些降维技术，如主成分分析或UMAP来绘制这些嵌入，并试图了解这些特征是否有一些预测能力。</p><p id="356b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们以recipe_name为例。</p><p id="02ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们首先从嵌入创建一个数据框:</p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="7958" class="kt ku hh kp b fi kv kw l kx ky">recipe_name_df = helper.get_embeddings_df(df_train_clean, 'recipe_name')</span></pre><p id="6498" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们对这个新数据集应用主成分分析:</p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="a586" class="kt ku hh kp b fi kv kw l kx ky">from sklearn.decomposition import PCA</span><span id="1513" class="kt ku hh kp b fi kz kw l kx ky">pca = PCA(n_components=2)</span><span id="a65c" class="kt ku hh kp b fi kz kw l kx ky">recipe_name_2_components = pd.DataFrame(pca.fit_transform(recipe_name_df), columns = ['X', 'Y'])</span></pre><p id="542b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的例子中，由于我们有一个连续的目标，我们应该在箱中离散它，以便我们可以很容易地绘制它。</p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="feb0" class="kt ku hh kp b fi kv kw l kx ky">from sklearn.preprocessing import KBinsDiscretizer</span><span id="6d12" class="kt ku hh kp b fi kz kw l kx ky">bin = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')</span><span id="d510" class="kt ku hh kp b fi kz kw l kx ky">df_train_clean['bin_sales'] = bin.fit_transform(df_train_clean['sales'].values.reshape(-1, 1))</span><span id="bde1" class="kt ku hh kp b fi kz kw l kx ky">sns.countplot(df_train_clean.bin_sales)</span><span id="c93d" class="kt ku hh kp b fi kz kw l kx ky">plt.title("Number of samples in each bin level")</span><span id="5ad5" class="kt ku hh kp b fi kz kw l kx ky">plt.show()</span></pre><figure class="jy jz ka kb fd kc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es la"><img src="../Images/9957ec66372a8b091428912e0a8d9413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkqXvqREHn_ErHIV67T0fg.png"/></div></div></figure><p id="132e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以创建一个散点图，其中包含两种成分，并基于容器使用不同的颜色。</p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="5a4b" class="kt ku hh kp b fi kv kw l kx ky">recipe_name_2_components['bin_sales'] = df_train_clean['bin_sales']</span><span id="0a5c" class="kt ku hh kp b fi kz kw l kx ky">sns.scatterplot(data=recipe_name_2_components, x='X', y='Y', hue='bin_sales', palette="tab10")</span><span id="72f7" class="kt ku hh kp b fi kz kw l kx ky">plt.show()</span></pre><figure class="jy jz ka kb fd kc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es lb"><img src="../Images/9b240fd82acf45cffba259fe9c663bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eiNlmfY6Yb9jjrqGR9041Q.png"/></div></div></figure><p id="6024" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上面的图表中不清楚这两个成分的预测能力，可能是因为这个特征对这个问题并不重要！</p><p id="a9e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，这里的目标是展示如何处理具有高基数的分类特性，所以让我们在模型中使用这些特性！！</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="0690" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">型号</strong></p><pre class="jy jz ka kb fd ko kp kq kr aw ks bi"><span id="8f67" class="kt ku hh kp b fi kv kw l kx ky"><em class="lc"># get a 768 column data frame for recipe_name and description</em><br/>recipe_name_df <strong class="kp hi">=</strong> helper<strong class="kp hi">.</strong>get_embeddings_df(df_train_clean, 'recipe_name')<br/>description_df <strong class="kp hi">=</strong> helper<strong class="kp hi">.</strong>get_embeddings_df(df_train_clean, 'description')<br/>recipe_name_df_test <strong class="kp hi">=</strong> helper<strong class="kp hi">.</strong>get_embeddings_df(df_test_clean, 'recipe_name')<br/>description_df_test <strong class="kp hi">=</strong> helper<strong class="kp hi">.</strong>get_embeddings_df(df_test_clean, 'description')</span><span id="45c4" class="kt ku hh kp b fi kz kw l kx ky"><em class="lc"># identify the number of components needed based on variance explained</em><br/>recipe_name_components, recipe_name_components_test <strong class="kp hi">=</strong> helper<strong class="kp hi">.</strong>apply_PCA(recipe_name_df, recipe_name_df_test, 'recipe_name', variance_explained<strong class="kp hi">=</strong>0.8)<br/>description_components, description_components_test <strong class="kp hi">=</strong> helper<strong class="kp hi">.</strong>apply_PCA(description_df, description_df_test, 'description', variance_explained<strong class="kp hi">=</strong>0.8)</span><span id="33e5" class="kt ku hh kp b fi kz kw l kx ky"><em class="lc"># merge with data frame</em><br/>df_train_clean <strong class="kp hi">=</strong> pd<strong class="kp hi">.</strong>merge(df_train_clean, recipe_name_components, left_index<strong class="kp hi">=True</strong>, right_index<strong class="kp hi">=True</strong>, how<strong class="kp hi">=</strong>'left')<br/>df_train_clean <strong class="kp hi">=</strong> pd<strong class="kp hi">.</strong>merge(df_train_clean, description_components, left_index<strong class="kp hi">=True</strong>, right_index<strong class="kp hi">=True</strong>, how<strong class="kp hi">=</strong>'left')<br/>df_test_clean <strong class="kp hi">=</strong> pd<strong class="kp hi">.</strong>merge(df_test_clean, recipe_name_components_test, left_index<strong class="kp hi">=True</strong>, right_index<strong class="kp hi">=True</strong>, how<strong class="kp hi">=</strong>'left')<br/>df_test_clean <strong class="kp hi">=</strong> pd<strong class="kp hi">.</strong>merge(df_test_clean, description_components_test, left_index<strong class="kp hi">=True</strong>, right_index<strong class="kp hi">=True</strong>, how<strong class="kp hi">=</strong>'left')</span></pre><p id="2d6d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然我们的训练集和测试集中已经有了所有的特性，我们就可以选择一个模型来预测销售了！😁</p><p id="f8ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以在这里查看完整代码:<a class="ae kn" href="https://github.com/rjguedes8/feature_embedding/blob/main/notebooks/feature_embedding.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/rjguedes 8/feature _ embedding/blob/main/notebooks/feature _ embedding . ipynb</a></p><div class="ld le ez fb lf lg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hi fi z dy ll ea eb lm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">medium.com</p></div></div><div class="lp l"><div class="lq l lr ls lt lp lu kh lg"/></div></div></a></div></div></div>    
</body>
</html>
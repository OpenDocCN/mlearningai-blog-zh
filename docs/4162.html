<html>
<head>
<title>A very quick start to TFGNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TFGNN快速入门</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/a-very-quick-start-to-tfgnn-fe10f222c36d?source=collection_archive---------0-----------------------#2022-12-17">https://medium.com/mlearning-ai/a-very-quick-start-to-tfgnn-fe10f222c36d?source=collection_archive---------0-----------------------#2022-12-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6f7b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://github.com/tensorflow/gnn" rel="noopener ugc nofollow" target="_blank"> TFGNN </a>是基于TensorFlow的GNN库，它同时实现了MessagePassing和GraphNets框架，这意味着你可以在框架中轻松设置上下文(全局)值。</p><p id="d0eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">开始前的一些有用链接:<a class="ae jc" href="https://distill.pub/2021/gnn-intro/" rel="noopener ugc nofollow" target="_blank">图形神经网络的温和介绍【TFGNN入门者的最佳入门博客)，TFGNN发表的</a><a class="ae jc" href="https://arxiv.org/abs/2207.03522" rel="noopener ugc nofollow" target="_blank">论文</a> (CoRR 2022)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4ed9c9e3e269ea5db4b1aaacc6272d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Ld-orroY4SwtZmiFhpSkA.png"/></div></div></figure><h2 id="df82" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated"><strong class="ak">基本数据结构:GraphTensor </strong></h2><p id="3f98" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">构建GNN训练管道的第一步是构建数据集。TFGNN的基本数据结构是tfgnn。<strong class="ig hi"> GraphTensor </strong>，带<strong class="ig hi">节点集/边集/上下文</strong>，每个集都有自己的<strong class="ig hi">特征。</strong></p><p id="3b4c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">详细介绍文档:<a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/graph_tensor.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/graph _ tensor . MD</a></p><h2 id="cce2" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">输入施工管线</h2><p id="b673" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">在建模之前，我们首先需要逐步构建我们的训练集。<a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/input_pipeline.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/input _ pipeline . MD</a></p><p id="dcf4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第一步:描述图模式:</strong><a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/schema.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/schema . MD</a></p><p id="be9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这一步，我们定义了<strong class="ig hi">节点集/边集特征</strong>和<strong class="ig hi">上下文特征</strong>；以下是一些注意事项:</p><ul class=""><li id="fae4" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated">在tfgnn文档中提到‘标量特征不需要维度标识。’但是实践表明，如果要在建模中直接处理那些标量特征，可以将它们的形状设置为“{ dim { size: 1} }”，并将数据类型定义为FLOAT。</li><li id="5b0e" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">TFGNN模型可以在“定向”边的两个方向上传播消息，默认情况下，TFGNN在消息传递阶段采用定向边。因此在数据准备步骤中不需要指定“无方向”的边。</li><li id="0a98" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">有各种各样的图任务类型:单图分类/回归(给出一堆小图进行分类)，单节点分类/回归(从大图中抽取一个子图)等。</li></ul><p id="a7e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第二步:数据样本准备&amp;采样:</strong><a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/data_prep.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/Data _ prep . MD</a></p><p id="9b1f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">python内编码的步骤:</p><ul class=""><li id="b8f5" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated">使用GraphTensor.from_pieces()函数为GraphTensor类型构造一个eager实例。</li><li id="c395" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用tfgnn.write_example(图形)和writer.write(示例。SerializeToString())来序列化内存实例，并将其写入磁盘上的文件中。</li></ul><p id="c1a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第三步:将文件读入数据集:</strong><a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/input_pipeline.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/input _ pipeline . MD</a></p><p id="9b3d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要读取一个GraphTensor(复合张量)，我们需要根据定义的Spec:tfg nn . parse _ single _ example/parse _ example()解析<em class="ld">serializable</em>；</p><h2 id="3646" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">建模管道<strong class="ak">(使用Keras API): </strong></h2><p id="2b5c" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">通常，我们为预处理和实际建模构建2个Keras模型:1个预处理模型+ 1个主训练模型；请注意，这两个模型都是在标量采样模式下定义的…</p><p id="abb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">管道摘要:读取数据集-&gt;解析为张量-&gt;构建预处理模型-&gt;构建训练模型-&gt;拟合训练模型-&gt;导出用于服务</p><p id="3a4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">预处理模型定义:</strong><a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/input_pipeline.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/input _ pipeline . MD</a></p><p id="82ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预处理模型的动机是将原始特征从离散特征处理成输入向量，例如将INT特征映射成8长度向量；或者<em class="ld">将</em>几个功能串联在一起。预处理函数的返回值应该是节点/边的起始隐藏状态。</p><p id="c12e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">步骤:</p><ul class=""><li id="20ee" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated">对于预处理函数，最好使用tf.keras.layers的内置函数。</li><li id="c801" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">TFGNN将在一个具有独立组件的大图(没有连接的子图)中合并一批图样本，然后应用更新功能，将该批作为标量样本。这样做的原因是为了使基于批处理的计算可行，因为每个样本可能具有不同的大小，这与传统的表格数据集显著不同(用图张量'<em class="ld">size</em>' =[<em class="ld">total _ size</em>，]，其中<em class="ld">total _ size</em>=<em class="ld">batch _ size</em>*(<em class="ld">set _ size</em>)*<em class="ld">channel _ size</em>)。</li></ul><p id="796a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">主模型定义:</strong></p><p id="24aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://github.com/tensorflow/gnn/blob/main/tensorflow_gnn/docs/guide/gnn_modeling.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/gnn/blob/main/tensor flow _ gnn/docs/guide/gnn _ modeling . MD</a></p><p id="47dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在TFGNN中有三种方法可以构建GNN图层:</p><ol class=""><li id="8b73" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb le kv kw kx bi translated">使用本机支持的层的XXXGraphUpdate函数，如GATv2、GCN等。</li></ol><p id="5d18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.从TensorFlow-Keras' scratch自定义<em class="ld"> tf.keras.layers.Layer </em>。</p><p id="bd22" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.利用<em class="ld">tfgnn . keras . layers . xxxgraphupdate</em><strong class="ig hi"><em class="ld"/></strong>在tfg nn的帮助下建立图层。</p><h2 id="aabd" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">祝你好运！</h2><div class="lf lg ez fb lh li"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lj ab dw"><div class="lk ab ll cl cj lm"><h2 class="bd hi fi z dy ln ea eb lo ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lp l"><h3 class="bd b fi z dy ln ea eb lo ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lq l"><p class="bd b fp z dy ln ea eb lo ed ef dx translated">medium.com</p></div></div><div class="lr l"><div class="ls l lt lu lv lr lw jn li"/></div></div></a></div></div></div>    
</body>
</html>
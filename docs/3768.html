<html>
<head>
<title>Convolutional Neural Networks — Learning From What Matters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络——从重要事物中学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/convolutional-neural-networks-learning-from-what-matters-b05e6121cb7a?source=collection_archive---------8-----------------------#2022-10-18">https://medium.com/mlearning-ai/convolutional-neural-networks-learning-from-what-matters-b05e6121cb7a?source=collection_archive---------8-----------------------#2022-10-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6d14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我将介绍什么是卷积神经网络，并展示一个使用Tensorflow的Python示例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/dfca4f767d6dd5606b91f5432e0b9755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZhXlql7fiGCASq8j"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@pawelskor?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Paul Skorupskas</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5ac3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人工神经网络用于在机器能力的帮助下解决任何类型的复杂问题。如果你需要回顾一下，我在这里写了一篇关于这个主题的文章。</p><p id="29f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积神经网络出现的主要原因是一些深度学习任务非常复杂，以至于<strong class="ig hi">全连接神经网络</strong> ( <em class="jt">神经网络，它的每个神经元都与后续层中的每个其他神经元相连；也称为密集层— </em> AlgoExpert.io)不能有效地解决它们。事实上，在<strong class="ig hi">自然语言处理</strong>中，尤其是在<strong class="ig hi">计算机</strong> <strong class="ig hi">视觉</strong>问题中，特征(参数)的数量通常非常多，这导致优化需要大量的能力和时间。例如，从100×100像素(10 000像素)的图片学习的神经网络将需要数百万个连接和权重，因为它使用整个图像来学习。</p><p id="4b0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以用我们所说的<strong class="ig hi"> Neocognitron </strong>来引入CNN，这是一个多层的神经网络，主要从输入(第一层中的S细胞)中发现简单的模式，并通过第二层(C细胞)发现更复杂的模式。这是卷积神经网络背后的想法，我们现在就来看看。</p><h1 id="b041" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">卷积神经网络是如何工作的？</h1><p id="d3f3" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">卷积神经网络是深度学习神经网络，主要用于计算机视觉任务。它们以两种类型的层为特征:<strong class="ig hi">卷积</strong> <strong class="ig hi">层</strong>和<strong class="ig hi">汇聚</strong> <strong class="ig hi">层</strong>。</p><h2 id="9bd9" class="kx jv hh bd jw ky kz la ka lb lc ld ke ip le lf ki it lg lh km ix li lj kq lk bi translated">卷积层</h2><p id="dec8" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">这些是CNN的主要组成部分，因为网络正是从它们那里学习图像模式的。</p><p id="e06f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个重要的因素是，与完全连接的神经网络不同，卷积层中的每个神经元并不连接到输入图像(或后续层)中的每个像素，而是仅连接到<strong class="ig hi">感受域</strong>中的一些像素。</p><p id="cfcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在继续之前，我们必须记住，图像是由像素的<strong class="ig hi">红、绿、蓝</strong>、T2强度或者经过<strong class="ig hi">灰度</strong>(将像素颜色空间转换为0到255之间的唯一数字)来表示的。在第一种情况下，我们有3个通道，而在第二种情况下，我们只有1个通道。我们可以认为<strong class="ig hi">通道</strong>是由RGB表示中的每种颜色或灰度化后的每个像素的数字表示的图像。在这两种情况下，图层将完成几乎相同的工作。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ll"><img src="../Images/32207cdcb18e9933e2f7aecc17f51246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tCgOsHYquaxaTlUpH1l2Eg.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">A gray scaled channel</figcaption></figure><p id="2ba8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">什么是感受野？</strong></p><p id="2c2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积层中的感受域是:</p><blockquote class="lm ln lo"><p id="df3a" class="ie if jt ig b ih ii ij ik il im in io lp iq ir is lq iu iv iw lr iy iz ja jb ha bi translated">与相邻神经元层相连的前一层神经元的数量。最大的感受野是一个全连接的神经网络。</p></blockquote><p id="a983" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其背后的想法是专注于每个像素周围的一部分，而不是整个图像。因此，它允许识别由感受野内的权重所代表的模式。这些字段变得像小图像一样，它被称为，<strong class="ig hi">过滤</strong> <strong class="ig hi">内核</strong>内部由权重表示，并关联到特定的模式，如直线、角点…</p><p id="7fc4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个小图像在整个输入图像上滑动，并应用它过滤内核，以便有一个新的图像，如下图所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ls"><img src="../Images/aacc31ffd5c45275d37082cf15cfb58d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8lW44Ue-wOGiPeDgoUqig.jpeg"/></div></div></figure><p id="dcc2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，根据内核，新图像将突出显示出现内核图案的部分。如果是水平白线，新图像将主要由水平白线组成。</p><p id="63b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个例子中，我们为输入图像和新图像保持了相同的大小，这可以通过使用我们称之为<strong class="ig hi">的零填充</strong>来实现，它在前面图层图像的边缘添加0。我们可以通过不使用填充来减少下一层的尺寸，这样感受野计算的神经元就少了。</p><p id="a137" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">这一层的目的是什么？</strong></p><p id="de60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">…通过<strong class="ig hi">优化基于损失函数的过滤内核中的权重</strong>，找到构成输入图像的模式。</p><p id="305f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">CNN的大目标是为自己找到描述图像的过滤内核。因此，网络不是固定权重，而是从一些基本权重开始，并优化权重(感受野的像素)。网络中的层越高级，模式就越精确和复杂。</p><p id="4d86" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你需要知道的是，图像的每个像素都有一个感受野，这意味着新图像代表一种模式。但是卷积层通常有许多“新图像”,每个图像代表一种不同的模式。它们被称为<strong class="ig hi">特征图</strong>，一般范围从1到500+。每个特征映射由特定的过滤内核支持，因此，具有其自己的权重的唯一模式被优化。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lt"><img src="../Images/79b163f65391ad1a8377134e842c1687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QWmxzzB1szrc5uUoFW5pwA.jpeg"/></div></div></figure><p id="9a9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特征图的一个很大的优点是，如果一个图案在图像中改变了位置，知道特征图表示图案在图像中的任何位置，它将能够识别它。</p><p id="464a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，包含过滤核的感受野具有3×3、5×5或7×7的尺寸，这大大减少了每个神经元必须计算的权重数量(对于3×3感受野，神经元计算9个权重)。</p><p id="0314" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，卷积层的最后一个要素是步幅的使用，即感受野从一个像素到另一个像素的步长。如果将其初始化为2，图层上的要素地图的维度将会减少。</p><blockquote class="lm ln lo"><p id="95b6" class="ie if jt ig b ih ii ij ik il im in io lp iq ir is lq iu iv iw lr iy iz ja jb ha bi translated">卷积层的目的是将输入图像中包含的最重要的模式汇总到特征图中。</p></blockquote><h2 id="2a7a" class="kx jv hh bd jw ky kz la ka lb lc ld ke ip le lf ki it lg lh km ix li lj kq lk bi translated">池层</h2><p id="be79" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">网络使用汇集层来<strong class="ig hi">减少维度</strong>以便改进模式的汇总，并且使神经网络<strong class="ig hi">移位不变</strong>。</p><p id="cc72" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它们是两种类型的池:</p><ul class=""><li id="3a55" class="lu lv hh ig b ih ii il im ip lw it lx ix ly jb lz ma mb mc bi translated"><strong class="ig hi"> Max pooling </strong>:具有无内核过滤的感受野，对每个像素进行过滤，并选择感受野内的最大像素值(无填充)。</li><li id="4552" class="lu lv hh ig b ih md il me ip mf it mg ix mh jb lz ma mb mc bi translated"><strong class="ig hi">平均池</strong>:与最大池相同，但不是选择最大像素值，而是对所有像素值进行平均。</li></ul><p id="e5ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个想法是为了捕捉图像中最重要的元素，即使它们改变了位置(在图像之间)。</p><h2 id="606d" class="kx jv hh bd jw ky kz la ka lb lc ld ke ip le lf ki it lg lh km ix li lj kq lk bi translated">CNN的最终表现</h2><p id="62a1" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">通常，卷积神经网络由各种卷积层和各种汇集层表示。在网络的末端，我们有一个<strong class="ig hi">展平</strong> <strong class="ig hi">层</strong>，最后特征图的每个像素都有一个神经元。最后，一个<strong class="ig hi">输出</strong> <strong class="ig hi">神经元</strong>，其目的是对输入进行分类。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mi"><img src="../Images/b46eed5fed9de9a2b78a220c20ca1b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvue_qCzCV11g4yLD_wvWw.jpeg"/></div></div></figure><h2 id="0df7" class="kx jv hh bd jw ky kz la ka lb lc ld ke ip le lf ki it lg lh km ix li lj kq lk bi translated">最著名的CNN架构</h2><p id="7536" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">以下是一些自诞生以来最著名的CNN架构:</p><ul class=""><li id="cdd1" class="lu lv hh ig b ih ii il im ip lw it lx ix ly jb lz ma mb mc bi translated">Yann LeCun的LeNet-5</li><li id="b76e" class="lu lv hh ig b ih md il me ip mf it mg ix mh jb lz ma mb mc bi translated">亚历克斯·克里兹维、伊利亚·苏茨基弗和杰弗里·辛顿。</li><li id="dd47" class="lu lv hh ig b ih md il me ip mf it mg ix mh jb lz ma mb mc bi translated">奇斯蒂安·塞格迪</li><li id="13ca" class="lu lv hh ig b ih md il me ip mf it mg ix mh jb lz ma mb mc bi translated">何</li></ul><h1 id="5182" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">CNN的一个基本实现</h1><p id="bce2" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">在创建网络架构之前，从一些图像预处理开始很重要:</p><ul class=""><li id="9ee5" class="lu lv hh ig b ih ii il im ip lw it lx ix ly jb lz ma mb mc bi translated">将图像转换成数组</li><li id="1a44" class="lu lv hh ig b ih md il me ip mf it mg ix mh jb lz ma mb mc bi translated">调整大小以提高效率</li></ul><p id="7983" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后是CNN的构建(Tensorflow和Keras API的例子) :</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="79f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于要解决的问题，一切都是可定制的。</p><h1 id="4bd5" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="3f7f" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">卷积神经网络是深度学习领域发展的最重要的架构之一。它主要用于<strong class="ig hi">计算机视觉任务</strong>，由<strong class="ig hi">卷积</strong> <strong class="ig hi">层</strong>以及<strong class="ig hi">汇聚</strong> <strong class="ig hi">层</strong>组成。</p><p id="9621" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢你阅读这篇文章，我希望你喜欢它，现在对CNN有了更好的了解！如果你对数据科学和机器学习感兴趣，可以在这里查看我的其他文章<a class="ae js" href="https://www.npogeant.com/#articles" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="1405" class="kx jv hh bd jw ky kz la ka lb lc ld ke ip le lf ki it lg lh km ix li lj kq lk bi translated">资源</h2><div class="ml mm ez fb mn mo"><a href="https://www.tensorflow.org/tutorials/images/cnn" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">卷积神经网络(CNN) |张量流核心</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">为了完成这个模型，你将把卷积基(形状为(4，4，64))的最后一个输出张量输入到一个…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.tensorflow.org</p></div></div><div class="mx l"><div class="my l mz na nb mx nc jm mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://www.manning.com/books/inside-deep-learning" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">内部深度学习</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">通过现代深度学习的理论和实践之旅，并应用创新技术解决日常数据…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.manning.com</p></div></div><div class="mx l"><div class="nd l mz na nb mx nc jm mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://www.eyrolles.com/Informatique/Livre/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow-9781492032649/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">使用scikit-learn、keras和TensorFlow进行机器实践学习...-图书馆</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">通过最近的一系列突破，深度学习推动了整个机器学习领域。现在，甚至…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.eyrolles.com</p></div></div><div class="mx l"><div class="ne l mz na nb mx nc jm mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://www.algoexpert.io/machine-learning/product" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">算法专家|赢得编码面试</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">准备编码面试的领先平台。掌握基本的算法和数据结构，并土地你的…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.algoexpert.io</p></div></div><div class="mx l"><div class="nf l mz na nb mx nc jm mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">medium.com</p></div></div><div class="mx l"><div class="ng l mz na nb mx nc jm mo"/></div></div></a></div></div></div>    
</body>
</html>
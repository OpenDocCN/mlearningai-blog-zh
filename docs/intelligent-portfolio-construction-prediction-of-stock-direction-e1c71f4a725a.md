# æ™ºèƒ½æŠ•èµ„ç»„åˆæž„å»º:è‚¡ç¥¨æ–¹å‘é¢„æµ‹

> åŽŸæ–‡ï¼š<https://medium.com/mlearning-ai/intelligent-portfolio-construction-prediction-of-stock-direction-e1c71f4a725a?source=collection_archive---------0----------------------->

åœ¨ç½‘ä¸Šæœç´¢å…³äºŽé‡‘èžé¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡åž‹çš„æœ‰è¶£å†…å®¹æ—¶ï¼Œæˆ‘çœ‹åˆ°äº†ä¸€ç¯‡æäº¤ç»™ä¼¦æ•¦å¸å›½ç†å·¥å­¦é™¢æ•°å­¦å’Œé‡‘èžç¡•å£«çš„è®ºæ–‡ã€‚è¿™è¢«å‘½åä¸ºæ™ºèƒ½æŠ•èµ„ç»„åˆæž„å»º:æœºå™¨å­¦ä¹ æ”¯æŒå‡å€¼-æ–¹å·®ä¼˜åŒ–ï¼Œæˆ‘å‘çŽ°å®ƒéžå¸¸é…·ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘å–œæ¬¢ç¬¬äºŒéƒ¨åˆ†ï¼Œåœ¨é‚£é‡Œå­¦ç”Ÿä½¿ç”¨éšæœºæ£®æž—æ¨¡åž‹æ¥é¢„æµ‹è‚¡ç¥¨æ–¹å‘ã€‚æˆ‘å†³å®šå°è¯•ç”¨ Python å¤åˆ¶ä»–çš„æ­¥éª¤(è¿™é‡Œæ˜¯ [GitHub åº“](https://github.com/RiccardoHub/Intelligent-Portfolio-Construction-Prediction-of-Stock-Direction))ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å±•ç¤ºæˆ‘æ˜¯å¦‚ä½•å®žçŽ°å¹¶æ‰©å±•è®ºæ–‡ä¸­æå‡ºçš„æƒ³æ³•çš„([é“¾æŽ¥æ­¤å¤„](https://www.imperial.ac.uk/media/imperial-college/faculty-of-natural-sciences/department-of-mathematics/math-finance/Ghali_Tadlaoui_01427211.pdf))ã€‚

ä½¿ç”¨éšæœºæ£®æž—é¢„æµ‹è‚¡ç¥¨æ–¹å‘çš„ä»»åŠ¡åˆ—è¡¨å¦‚ä¸‹:

1.  è¾“å…¥æ•°æ®
2.  æ•°æ®åŠ å·¥
3.  ç‰¹å¾æŽ¨å¯¼
4.  éšæœºæ£®æž—åˆ†ç±»å™¨

# è¾“å…¥æ•°æ®

è¯¥é¡¹ç›®æ‰€éœ€çš„æ•°æ®æ˜¯ OHLC å’Œ 8 åªè‚¡ç¥¨çš„æˆäº¤é‡ï¼Œå³è‹¹æžœã€äºšé©¬é€Šã€èŠ±æ——é›†å›¢ã€CVS Healthã€3Mã€æ˜Ÿå·´å…‹ã€å˜‰ä¿¡ç†è´¢å…¬å¸å’ŒåŸƒå…‹æ£®ç¾Žå­šã€‚æ ·æœ¬æ—¶é—´è·¨åº¦ä¸º 2000 å¹´ 6 æœˆ 1 æ—¥â€”2016 å¹´ 4 æœˆ 25 æ—¥ï¼Œç”¨äºŽè®­ç»ƒå’Œæµ‹è¯•æ¨¡åž‹ï¼Œ2016 å¹´ 4 æœˆ 25 æ—¥â€”2021 å¹´ 7 æœˆ 26 æ—¥ï¼Œç”¨äºŽéªŒè¯ã€‚

```
import yfinance as yf

tickers = ['AAPL', 'AMZN', 'C', 'CVS', 'MMM', 'SBUX', 'SCHW', 'XOM']
start = '2000-06-02'
end = '2016-04-26'

AdjClose = yf.download(tickers, start=start, end=end)['Adj Close']
Volume = yf.download(tickers, start=start, end=end)['Volume']
High = yf.download(tickers, start=start, end=end)['High']
Low = yf.download(tickers, start=start, end=end)['Low']
Close = yf.download(tickers, start=start, end=end)['Close']
```

# æ•°æ®åŠ å·¥

é‡‘èžæ•°æ®é€šå¸¸éžå¸¸å˜ˆæ‚ï¼Œè¿™æ„å‘³ç€ä¸€æ®µæ•°æ®æºå¸¦äº†ä¸€äº›å®žé™…ä¸Šå¹¶ä¸æœ‰ç”¨çš„ä¿¡æ¯ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ä¸ªæ–¹æ³•æ˜¯æ•°æ®å¹³æ»‘ï¼Œè¿™æ˜¯ä¸€ç§è¯•å›¾æŠ‘åˆ¶çŸ­æœŸå¯å˜æ€§ï¼ŒåŒæ—¶ä¿æŒé•¿æœŸè¶‹åŠ¿å¯è§çš„æ–¹æ³•ã€‚æœ¬æ–‡ä½¿ç”¨çš„æ–¹æ³•æ˜¯æŒ‡æ•°å¹³æ»‘æ³•ï¼Œå®ƒä½¿ç”¨ä¸€ä¸ªå¸¸æ•°ð›¼.å°† t+1 æ—¶çš„å¹³æ»‘è°ƒæ•´åŽçš„æ”¶ç›˜å€¼ç¡®å®šä¸º t+1 æ—¶çš„è§‚æµ‹å€¼å’Œ t æ—¶çš„å¹³æ»‘æ•°æ®ä¹‹é—´çš„åŠ æƒå¹³å‡å€¼

![](img/6538de37c7c0ed768c67b56d12080c50.png)

è®ºæ–‡ä¸­ä½¿ç”¨çš„ð›¼å¸¸æ•°ä¸º 0.20ã€‚

å¯¹äºŽè¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘å†³å®šä¸ä½¿ç”¨ä»»ä½•é¢„åˆ¶å‡½æ•°æ¥æé«˜æˆ‘çš„ç¼–ç¨‹æŠ€èƒ½ã€‚å› æ­¤ï¼Œè¿™äº›ä»£ç è¿œä¸æ˜¯æœ€é«˜æ•ˆæˆ–æœ€ä¼˜é›…çš„ã€‚ç„¶è€Œï¼Œå¦‚æžœä½ èƒ½æä¾›ä¸€ä¸ªæ›´æœ‰æ•ˆ/ä¼˜é›…çš„ä»£ç ï¼Œè¯·è¿™æ ·åšï¼

```
def exponential_smoothing(df, alpha):
    DF = df.copy().reset_index(drop=True) 
    DF.loc[1] = (DF.loc[1]*alpha)+(DF.loc[0]*(1-alpha))

    for i in range(2, len(DF)-1):
        DF[i] = (DF[i]*alpha)+(DF[i-1]*(1-alpha))

    return DF

# Apply the function to all tickers
E = {}
for n in AdjClose.columns:
    E[f'{n}']= exponential_smoothing(AdjClose[n], 0.2)
```

ç»“æžœå¦‚å›¾ 1 æ‰€ç¤ºã€‚æ­£å¦‚æˆ‘ä»¬åœ¨å·¦ä¾§çœ‹åˆ°çš„ï¼Œå¾ˆéš¾æ³¨æ„åˆ°æ•´ä¸ªæ•°æ®é›†çš„ä»»ä½•å·®å¼‚ã€‚ç„¶è€Œï¼Œé€šè¿‡æ”¾å¤§ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æŒ‡æ•°å¹³æ»‘çš„æ•ˆæžœã€‚

![](img/b4e2678c40684410d9aa06e38d52bcc9.png)

Figure 1: Exponential Smoothing on AAPL

# ç‰¹å¾æŽ¨å¯¼

ä¸‹ä¸€æ­¥æ˜¯åˆ›å»ºå°†åœ¨éšæœºæ£®æž—åˆ†ç±»å™¨ä¸­ç”¨ä½œè§£é‡Šå˜é‡çš„æŒ‡æ ‡ã€‚

ç¬¬ä¸€ä¸ªæŒ‡æ ‡å«åš On Balance Volumeï¼Œè¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æ€§çš„äº¤æ˜“åŠ¨é‡æŒ‡æ ‡ï¼Œç”¨æˆäº¤é‡æ¥é¢„æµ‹è‚¡ä»·çš„å˜åŒ–ã€‚

![](img/0b6d52ee984f23486322a233d9c7b126.png)

```
def OBV(df_price, df_volume):
    OBV_df = pd.DataFrame(index=range(len(df_volume.index)), columns=['OBV'])
    OBV_df.iloc[0] = 0

    for i in range(1, len(df_price)):
        if df_price[i] > df_price[i-1]:
            OBV_df.loc[i] = (OBV_df.loc[i-1] + df_volume[i])
        elif df_price[i] < df_price[i-1]:
            OBV_df.loc[i] = (OBV_df.loc[i-1] - df_volume[i])
        else:
            OBV_df.loc[i] = (OBV_df.loc[i-1] + 0)

    OBV_df.index = df_volume.index
    return OBV_df

# Apply the function to all tickers
O = {}
for n in AdjClose.columns:
    O[f'{n}']= OBV(E[n], Volume[n])
```

å›¾ 2 æ˜¾ç¤ºäº†æ­£å¸¸åŒ–çš„ OBV å’Œå¹³æ»‘è°ƒæ•´åŽçš„ AAPL æ”¶ç›˜ä»·ã€‚æˆ‘ä»¬ç¨åŽä¼šå‘çŽ°ï¼ŒOBV æ˜¯æ¨¡åž‹ä¸­ä¿¡æ¯é‡æœ€å°‘çš„ç‰¹å¾ã€‚

![](img/58693f061a85adec636409e2ea3a5b53.png)

Figure 2: OBV and Smoothed AdjClose (AAPL)

ç¬¬äºŒä¸ªæŒ‡æ ‡æ˜¯éšæœºæŒ¯è¡å™¨%Kï¼Œå®ƒå°†å¹³æ»‘ä»·æ ¼ä¸Žç»™å®šæ—¶é—´æ®µ K å†…çš„é«˜ä½Žä»·æ ¼èŒƒå›´è¿›è¡Œæ¯”è¾ƒã€‚å®ƒç”¨äºŽç”Ÿæˆè¶…ä¹°å’Œè¶…å–äº¤æ˜“ä¿¡å·ï¼Œåˆ©ç”¨ 0-100 çš„æœ‰ç•Œå€¼èŒƒå›´ã€‚

![](img/30eafe887e4746d1b0d9aa6b51aa6dbf.png)

```
def stochastic_oscillator(close, df_low, df_high, K):
    low = df_low.rolling(K).min().reset_index(drop=True)
    high = df_high.rolling(K).max().reset_index(drop=True)

    stoch_oscillator = pd.DataFrame()
    stoch_oscillator['Oscillator'] = 100*((close - low)/(high - low))

    return stoch_oscillator

# Apply the function to all tickers
S = {}
for n in AdjClose.columns:
    S[f'{n}']= stochastic_oscillator(close=E[n], df_low=E[n], df_high=E[n], K=14)
```

ç¬¬ä¸‰ä¸ªä¹Ÿæ˜¯æœ€åŽä¸€ä¸ªæŒ‡æ ‡æ˜¯ç§»åŠ¨å¹³å‡çº¿æ”¶æ•›èƒŒç¦»ã€‚è¿™å¯¼è‡´äº†ä¸¤ä¸ªç‰¹å¾ã€‚ç¬¬ä¸€ä¸ªæ˜¯ MACDï¼Œå®šä¹‰ä¸º 12 æœŸå‡çº¿å’Œ 26 æœŸå‡çº¿ä¹‹å·®ã€‚ç¬¬äºŒä¸ªæ˜¯ MACD çš„ä¿¡å·ï¼Œä¹Ÿå°±æ˜¯ MACD çš„ 9 æœŸå‡çº¿ã€‚

![](img/a08478b2b2f357788b72270cf461dd35.png)![](img/bf74ed9a4247d9adf12d25d90cdd7ba8.png)

```
def MACD(data):
    MA_Fast = data.ewm(span=12,min_periods=12).mean()
    MA_Slow = data.ewm(span=26,min_periods=26).mean()
    MACD = MA_Fast - MA_Slow
    Signal = MACD.ewm(span=9,min_periods=9).mean()

    return pd.DataFrame(index=['MACD', 'Signal'], data [MACD,Signal]).T

# Apply the function to all tickers
M = {}
for n in AdjClose.columns:
    M[f'{n}'] = MACD(data=E[n])z
```

æœ€åŽï¼Œæˆ‘å°†æ‰€æœ‰å˜é‡è¿žæŽ¥åœ¨ä¸€ä¸ªå­—å…¸ä¸­ã€‚

```
dict_data = {}
for n in AdjClose.columns:
    dict_data[f'{n}'] = (pd.concat([E[n], 
                                    O[n].reset_index(drop=True), 
                                    S[n], 
                                    M[n]],
                                   axis=1)).set_index(O[n].index)
```

# éšæœºæ£®æž—åˆ†ç±»å™¨

æœ¬æ–‡è®­ç»ƒäº†ä¸€ä¸ªéšæœºæ£®æž—åˆ†ç±»å™¨æ¥é¢„æµ‹è‚¡ç¥¨æ–¹å‘ã€‚åŽè€…ç”±ä¸€ä¸ªäºŒè¿›åˆ¶å˜é‡è¡¨ç¤ºï¼Œå¦‚æžœè‚¡ç¥¨ä»·æ ¼åœ¨ m æœŸåŽä¸‹è·Œï¼Œå–å€¼ä¸º-1ï¼›å¦‚æžœè‚¡ç¥¨ä»·æ ¼ä¸Šæ¶¨ï¼Œå–å€¼ä¸º 1ã€‚å¦‚æžœä½ æƒ³äº†è§£æ›´å¤šå…³äºŽéšæœºæ£®æž—çš„çŸ¥è¯†ï¼Œå¯ä»¥çœ‹çœ‹æˆ‘çš„å¦ä¸€ç¯‡æ–‡ç« ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œéšæœºæ£®æž—æ˜¯å¦‚å›¾ 3 æ‰€ç¤ºçš„å†³ç­–æ ‘çš„é›†åˆã€‚æ ‘ä¸­çš„æ¯ä¸ªåˆ†è£‚éƒ½æ˜¯ä¸ºäº†ä¼˜åŒ–ä¸€ä¸ªä½¿æ‚è´¨æœ€å°åŒ–çš„æ ‡å‡†ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒè¯•å›¾æ‰¾åˆ°ä½¿æ¨¡åž‹å°½å¯èƒ½æ˜Žæ˜¾åœ°å†³å®šæ•°æ®åº”è¯¥å¯¹åº”äºŽç‰¹å®šç±»åˆ«çš„é˜ˆå€¼ã€‚éšæœºæ£®æž—åˆ†ç±»å™¨ç”±ä»»æ„æ•°é‡çš„æ ‘ç»„æˆï¼Œè¿™äº›æ ‘è¿›è¡Œé¢„æµ‹ï¼ŒèŽ·å¾—æ›´å¤šæŠ•ç¥¨çš„ç±»è¢«é€‰ä¸ºæœ€ç»ˆé¢„æµ‹ã€‚

![](img/ff27f8b22d07e21ee0fb0bb33d5c09bd.png)

Figure 3: Decision Tree Example

åœ¨è®­ç»ƒæ¨¡åž‹ä¹‹å‰ï¼Œåº”è¯¥ä½¿ç”¨ä»¥ä¸‹é€»è¾‘å°†å¹³æ»‘ä»·æ ¼è½¬æ¢ä¸ºåˆ†ç±»å˜é‡ã€‚

![](img/cb3c1cc2c90c42e4fcc05486040e14a5.png)

```
def finalise_data(DF, column, n):
    df = copy.deepcopy(DF)
    df[column][column] = np.sign(np.log(df[column][column]/df[column][column].shift(n-1)))

    return df[column]
```

çŽ°åœ¨ï¼Œåˆ›å»ºæ¨¡åž‹çš„ä¸€åˆ‡éƒ½å‡†å¤‡å¥½äº†ã€‚è¿™æ˜¯ä½¿ç”¨ Scikit-learn è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯çš„ã€‚è¯¥æ¨¡åž‹æ‹Ÿåˆäº†ä»Ž 2000 å¹´ 1 æœˆ 6 æ—¥åˆ° 2016 å¹´ 4 æœˆ 25 æ—¥çš„æ•°æ®ï¼Œå…¶ä¸­ 80%ç”¨äºŽè®­ç»ƒï¼Œ20%ç”¨äºŽæµ‹è¯•ã€‚2021 å¹´ 7 æœˆ 26 æ—¥ä¹‹å‰çš„å‰©ä½™æ•°æ®ç”¨äºŽéªŒè¯ã€‚ç”¨äºŽè¯„ä¼°é¢„æµ‹çš„æŒ‡æ ‡æ˜¯å‡†ç¡®åº¦ã€ç²¾ç¡®åº¦ã€å¬å›žçŽ‡å’Œ f1_scoreã€‚

```
def RFClassifier(DF, column, n, validation=False, validation_DF=None, feature_importance=False):
    data = finalise_data(DF=DF, column=column, n=n)
    data.dropna(axis=0, inplace=True)

    X = data[['OBV', 'Oscillator', 'MACD', 'Signal']]
    y = data[column]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train,y_train)
    prediction= model.predict(X_test)

    Accuracy = metrics.accuracy_score(y_test, prediction)
    Precision = metrics.average_precision_score(y_test, prediction)
    Recall = metrics.recall_score(y_test, prediction)
    F1_score = metrics.f1_score(y_test, prediction)

    if validation ==  True:
        validation_data = finalise_data(DF=validation_DF, column=column, n=n)
        validation_data.dropna(axis=0, inplace=True)

        X_validation = validation_data[['OBV', 'Oscillator', 'MACD', 'Signal']]
        y_validation = validation_data[column]
        validation_prediction = model.predict(X_validation)

        Accuracy_validation = metrics.accuracy_score(y_validation, validation_prediction)
        Precision_validation = metrics.average_precision_score(y_validation, validation_prediction)
        Recall_validation = metrics.recall_score(y_validation, validation_prediction)
        F1_score_validation = metrics.f1_score(y_validation, validation_prediction)

        return n, column,Accuracy_validation, Precision_validation, Recall_validation, F1_score_validation

    elif feature_importance == True:
        return pd.Series(model.feature_importances_,(X).columns)

    else:
        return n, column, Accuracy, Precision, Recall, F1_score
```

è¯¥æ¨¡åž‹é¢„æµ‹æ¯ä¸ªè‚¡ç¥¨æœªæ¥ 2 åˆ° 30 å¤©çš„èµ°åŠ¿ã€‚

éªŒè¯é›†çš„æ€»ä½“ç»“æžœå¦‚ä¸‹:

![](img/073190b83d769c2159605d536f632ca4.png)

Figure 4: Validation Set Statistics

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ‰€æœ‰æŠ¥ä»·æœºçš„å¹³å‡å‡†ç¡®çŽ‡ä¸º 0.90ã€‚æŸ¥çœ‹æ¯ä¸ª n çš„ç»“æžœï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°é¢„æµ‹çº¿æ€§æé«˜ï¼Œç›´åˆ° n=11ï¼Œç„¶åŽåœ¨ç”± n=[11ï¼Œ12ï¼Œ13ï¼Œ14]ç»„æˆçš„æœ€ä½³è¡¨çŽ°åŒºåŸŸæ³¢åŠ¨ï¼Œç„¶åŽæ€¥å‰§ä¸‹é™åˆ°å¹³å‡å€¼çº¦ä¸º 0.90 çš„å€¼ã€‚

![](img/be939d1a46bcd1f1b045bedf1a54cb08.png)

Figure 5: Accuracy

æ­¤å¤–ï¼Œè°ƒæŸ¥å˜é‡çš„é‡è¦æ€§è¡¨æ˜Žï¼Œä»–ä»¬çš„è§£é‡Šèƒ½åŠ›éš n å˜åŒ–ã€‚

![](img/4f951fa85fd794cd5e8dc93786c83cf6.png)

Figure 6: Feature Importances

åœ¨ n = 18 ä¹‹å‰ï¼ŒéšæœºæŒ¯è¡å™¨æ˜¯æœ€æœ‰å¸®åŠ©çš„å˜é‡ï¼Œåœ¨ n = 18 ä¹‹åŽï¼Œå®ƒä¸æ–­ä¸‹é™ï¼Œæœ€ç»ˆæˆä¸ºæœ€ä¸å…·è§£é‡ŠåŠ›çš„å˜é‡ã€‚ç›¸åï¼Œåœ¨çŸ­æœŸå†…ï¼ŒMACD å’Œ OBV çš„é¢„æµ‹èƒ½åŠ›å¤§è‡´ç›¸å½“ï¼Œç„¶è€Œï¼Œå®ƒé€æ¸æˆä¸ºæœ€æœ‰ç”¨çš„å˜é‡ã€‚MACD ä¿¡å·éµå¾ªå…·æœ‰è¾ƒä½Žå¹…åº¦çš„ç±»ä¼¼è·¯å¾„ã€‚

# ç»“è®º

è¿™ç¯‡æ–‡ç« å±•ç¤ºäº†è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯ä¸€ä¸ªéšæœºæ£®æž—æ¨¡åž‹çš„æ­¥éª¤ï¼Œè¯¥æ¨¡åž‹ç”¨äºŽé¢„æµ‹ 8 åªè‚¡ç¥¨çš„èµ°å‘ã€‚æ‰€èŽ·å¾—çš„ç»“æžœæ˜¯ä»¤äººæ»¡æ„çš„ï¼ŒéªŒè¯é›†çš„é¢„æµ‹çš„å¹³å‡å‡†ç¡®åº¦ä¸º 90%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡åž‹åœ¨é¢„æµ‹æœªæ¥ 13 å¤©çš„æ–¹å‘æ—¶è¾¾åˆ°äº†æœ€é«˜çš„ç²¾ç¡®åº¦ã€‚
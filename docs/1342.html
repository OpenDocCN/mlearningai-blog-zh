<html>
<head>
<title>How to Build an ML Pipeline for more efficient Disaster Response</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何构建ML管道以实现更高效的灾难响应</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/building-a-ml-pipeline-for-more-efficient-disaster-response-226350cdbff8?source=collection_archive---------3-----------------------#2021-11-26">https://medium.com/mlearning-ai/building-a-ml-pipeline-for-more-efficient-disaster-response-226350cdbff8?source=collection_archive---------3-----------------------#2021-11-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="b875" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">我在乌达城数据科学之旅的下一个项目</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/1cee430d6281d128549a795cc79c7199.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qegAXRZ5QcvoYQ_6EBrZhQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@karosu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">苏 静斋</a> on <a class="ae jm" href="https://unsplash.com/s/photos/pipeline?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="ba4f" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">简介</strong></h2><p id="4213" class="pw-post-body-paragraph kl km hh kn b ko kp ii kq kr ks il kt jy ku kv kw kc kx ky kz kg la lb lc ld ha bi translated">想象一下，有一场环境灾难影响了世界上许多人居住的地方。他们中的一些人确实需要药物、食物、机器等形式的帮助。为了吸引注意力，他们可能会发送紧急信息，希望信息能被阅读，并采取正确的行动。该项目提供了一个引擎，可以将这些灾难消息分类到不同的类别中，以使为那些真正需要帮助的人组织帮助的过程尽可能高效。</p><p id="9af7" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">以下项目为<a class="ae jm" href="https://www.udacity.com/" rel="noopener ugc nofollow" target="_blank">乌达城</a>数据科学家<a class="ae jm" href="https://www.udacity.com/course/data-scientist-nanodegree--nd025" rel="noopener ugc nofollow" target="_blank">纳米度</a>的一部分，数据由<a class="ae jm" href="https://appen.com/" rel="noopener ugc nofollow" target="_blank">图八</a>提供。该项目可分为三个不同的部分:</p><ol class=""><li id="700d" class="lj lk hh kn b ko le kr lf jy ll kc lm kg ln ld lo lp lq lr bi translated">创建一个ETL管道，接收两个csv文件，合并并清理它们，并将结果存储在一个SQLite数据库中。</li><li id="59cf" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld lo lp lq lr bi translated">创建一个从数据库中获取数据、处理文本并执行多输出分类的ML管道。该脚本使用NLTK，即scikit-learn和GridSearchCV的管道。</li><li id="4fca" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld lo lp lq lr bi translated">在Flask web应用程序中使用经过训练的模型，在该应用程序中，新消息可以被分类为不同的类别。</li></ol></div><div class="ab cl lx ly go lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ha hb hc hd he"><h2 id="9cb4" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">提取、转换和加载(ETL)</h2><p id="b3e4" class="pw-post-body-paragraph kl km hh kn b ko kp ii kq kr ks il kt jy ku kv kw kc kx ky kz kg la lb lc ld ha bi translated">为了获得对该项目的机器学习部分有用的数据，有必要使数据具有正确的形状和尺寸。这个过程最初是在Jupiter笔记本上完成的，然后被转换成Python脚本。</p><p id="d84a" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">提供的数据由两个csv文件组成:消息数据和类别数据。对于熊猫<em class="me"> read_csv </em>，我们只需将它们读入笔记本，并对其进行进一步研究。</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="8832" class="jn jo hh mg b fi mk ml l mm mn"># load messages/categories dataset<br/>messages = pd.read_csv('../data/disaster_messages.csv')<br/>categories = pd.read_csv('../data/disaster_categories.csv')</span></pre><p id="a799" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">此时，可以进行以下观察:</p><ul class=""><li id="a152" class="lj lk hh kn b ko le kr lf jy ll kc lm kg ln ld mo lp lq lr bi translated">两个数据帧中没有丢失数据。</li><li id="4d45" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld mo lp lq lr bi translated">数据帧可以通过属性“id”连接起来。</li><li id="e0f5" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld mo lp lq lr bi translated">类别基本上形成良好，但需要额外处理才能变成二元(0或1)。</li></ul><p id="4b0b" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">首先，类别数据必须采用正确的形式。要定义类别为真或假，我们必须减少列，并将结果声明为整数:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mp mq l"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">ETL-Pipeline Transformation</figcaption></figure><p id="362b" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">由于“相关”类别由几个输出(0、1、2)组成，2必须转换为1，使其成为二进制(这是一种处理方式，另一种是忽略行):</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="0e98" class="jn jo hh mg b fi mk ml l mm mn">df['related'] = df['related'].replace(2,1)</span></pre><p id="70dd" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">其次，我们需要通过公共特征“id”连接两个数据帧:</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="1c0e" class="jn jo hh mg b fi mk ml l mm mn">df = pd.concat([df, categories_df], axis=1)</span></pre><p id="3271" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">最后，我们需要从数据框中删除重复项:</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="2539" class="jn jo hh mg b fi mk ml l mm mn">df = df.drop_duplicates()</span></pre><p id="6b2a" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">产生的数据帧df现在已准备好用于下面的ML管道。为此，我们将其存储在SQLite数据库中。</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="06ea" class="jn jo hh mg b fi mk ml l mm mn">engine = create_engine('sqlite:///DisasterResponse.db')<br/>df.to_sql('disaster_respond', engine, if_exists='replace',index=False)</span></pre></div><div class="ab cl lx ly go lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ha hb hc hd he"><h2 id="d4c4" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">机器学习管道</h2><p id="07e0" class="pw-post-body-paragraph kl km hh kn b ko kp ii kq kr ks il kt jy ku kv kw kc kx ky kz kg la lb lc ld ha bi translated">在运行ETL管道之后，是时候在提供的数据库上训练一个功能模型了。首先，我们需要在之前创建的数据库上导入数据框。基本上，我们希望用消息数据来拟合一个模型，以将其分类到不同的类别中。</p><p id="dc6e" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">为了获得适用于ML模型的数据，我们对消息数据执行以下转换:</p><ul class=""><li id="2f7e" class="lj lk hh kn b ko le kr lf jy ll kc lm kg ln ld mo lp lq lr bi translated">计数矢量器(tokenize=tokenizer*)</li><li id="f652" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld mo lp lq lr bi translated">TfidfTransformer()</li></ul><p id="870d" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">*以下函数用于将文本输入转换为规范化和词条化字符的符号。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mp mq l"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">ML-Pipeline Tokenizer</figcaption></figure><p id="2932" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">因此，在这个函数的基础上，我们首先用CountVectorizer进行转换，用TfidfTransformer进行输出。两个变压器的顺序应用具有这样的优点，即我们可以根据加权输入来训练我们的模型。关于这两款变压器的更多信息可以在<a class="ae jm" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="3686" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">在转换之后，我们现在添加第三个估计器，即多输出分类器。这一步是必要的，因为我们的目标不仅是分类二进制，而是36个不同的类别。对于最终分类，使用了RandomForestClassifier。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mp mq l"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">ML-Pipeline Build Model</figcaption></figure><p id="57aa" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">为了改进我们的分类，我们使用GridSearchCV进行了参数调整。现在，训练模型所需的时间比以前长得多。为了获得额外的速度，我们使用“<em class="me"> n_jobs=-1”在所有可用的处理器之间分配工作。</em></p><p id="bee9" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">为了评估模型，我们对预测变量“y_pred”使用“分类_报告”。你可以在这里找到更多关于报告<a class="ae jm" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">的信息</a>。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mp mq l"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">ML-Pipeline Evaluate Model</figcaption></figure><p id="e08b" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">管道的最后一部分是将模型保存在pickle文件中:</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="2904" class="jn jo hh mg b fi mk ml l mm mn">with open(model_filepath, 'wb') as f:<br/>    pickle.dump(model, f)</span></pre></div><div class="ab cl lx ly go lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ha hb hc hd he"><h2 id="c1ec" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结果</h2><p id="9f2f" class="pw-post-body-paragraph kl km hh kn b ko kp ii kq kr ks il kt jy ku kv kw kc kx ky kz kg la lb lc ld ha bi translated">您可以在这里找到相应的GitHub资源库:</p><p id="a2fe" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated"><a class="ae jm" href="https://github.com/jonastheiler/disaster-respond-pipeline" rel="noopener ugc nofollow" target="_blank">https://github.com/jonastheiler/disaster-respond-pipeline</a></p><p id="1b51" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">如前所述，这个项目的成果是一个网络应用程序，可用于将事件分为不同的类别，以便将信息转发给相关的救灾机构。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mr"><img src="../Images/5950e91d3409fd38e768806608b7b18a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gFO7JlzuXzmvol34rvzP4Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Screenshot Disaster Response Web App</figcaption></figure><p id="a427" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">我对结果和功能齐全的web应用程序感到满意。尽管一切正常，但仍有足够的改进空间:</p><ul class=""><li id="b52f" class="lj lk hh kn b ko le kr lf jy ll kc lm kg ln ld mo lp lq lr bi translated">测试不同的估计量以优化分类(本项目中使用了RandomForestClassifier())。</li><li id="e367" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld mo lp lq lr bi translated">为GridSearchCV设置扩展的参数列表以优化模型(长性能时间问题)</li><li id="3c98" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld mo lp lq lr bi translated">使用FeatureUnion通过其他转换来扩展管道，以获得更好的结果。例如，在NLP中可以使用不同的转换。</li><li id="34b8" class="lj lk hh kn b ko ls kr lt jy lu kc lv kg lw ld mo lp lq lr bi translated">此外，web应用程序可能已经部署到Heroku(或类似的提供商)以便于访问结果。</li></ul></div><div class="ab cl lx ly go lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ha hb hc hd he"><h2 id="790e" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h2><p id="f31a" class="pw-post-body-paragraph kl km hh kn b ko kp ii kq kr ks il kt jy ku kv kw kc kx ky kz kg la lb lc ld ha bi translated">该模型具有良好的准确性和精度。使用GridSearchCV进行优化是对分类器的一个很好的补充，使管道更加稳定。一般来说，管道有能力一步一步地不断重复这个过程。创建ETL/ML管道是练习一些基本Python技能和学习处理数据的正确方法的好机会。</p><p id="1c02" class="pw-post-body-paragraph kl km hh kn b ko le ii kq kr lf il kt jy lg kv kw kc lh ky kz kg li lb lc ld ha bi translated">此外，我要感谢Udacity团队的大力支持和强大的纳米学位项目。</p><div class="ms mt ez fb mu mv"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mw ab dw"><div class="mx ab my cl cj mz"><h2 class="bd hi fi z dy na ea eb nb ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nc l"><h3 class="bd b fi z dy na ea eb nb ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nd l"><p class="bd b fp z dy na ea eb nb ed ef dx translated">medium.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj jg mv"/></div></div></a></div></div></div>    
</body>
</html>
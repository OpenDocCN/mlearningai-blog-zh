<html>
<head>
<title>How to use Machine learning optimization for Trading signals with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python对交易信号进行机器学习优化</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-use-machine-learning-optimization-for-trading-signals-with-python-558ba25e638b?source=collection_archive---------0-----------------------#2021-04-01">https://medium.com/mlearning-ai/how-to-use-machine-learning-optimization-for-trading-signals-with-python-558ba25e638b?source=collection_archive---------0-----------------------#2021-04-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/53502101f92b6b7d6303eb0f579ed2fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLw426yIBbLTtPaK72JZAA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">signals in power !</figcaption></figure><p id="34f3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">使用交易技术信号和机器学习技术，从头开始创建和编码交易策略。在这篇文章中使用的模型将是决策树，随机森林树，K最近邻(KNN)。</p><h1 id="e288" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">介绍</h1><p id="4a96" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">我比较了最流行的分类器，并通过分层交叉验证过程评估了每个分类器的平均准确度、精确度和召回率。</p><h1 id="6846" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">算法:</strong></h1><ul class=""><li id="bcc9" class="kv kw hh iv b iw kq ja kr je kx ji ky jm kz jq la lb lc ld bi translated">下载市场数据。</li><li id="97e8" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">计算我们将用作预测变量的指标。</li><li id="ffd3" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">定义目标变量。</li><li id="f898" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">将数据分为训练集和测试集。</li><li id="f087" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">运行模型</li><li id="11e4" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">显示性能和策略绘图</li></ul><h1 id="3c09" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">下载数据</h1><p id="b91e" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">我们将使用名为q(【https://pypi.org/project/quantrautil/】)的库quantrautil。我们将在网飞数据上测试机器移动学习技术，并将使用基准SPY(SP500指数上的STF)。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="dc29" class="lt jt hh lp b fi lu lv l lw lx">ticker = ‘NFLX’<br/>benchmark = ‘SPY’<br/>data = q.get_data([ticker,benchmark],’2000–1–1', ‘2020–2–26’)</span></pre><h1 id="0e30" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">创建预测器</strong></h1><p id="2691" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">预测变量是可能与市场行为相关的特征。这些数据可以是技术指标、市场数据、情绪数据、广度数据、基本面数据、政府数据等。我们将使用talib python库来创建这些预测器</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="8b91" class="lt jt hh lp b fi lu lv l lw lx">df = pd.DataFrame(index = data.index)<br/> df[‘EMA_10’] = ta.EMA(data[‘Close’, ticker].values, timeperiod=10)<br/> df[‘EMA_30’] = ta.EMA(data[‘Close’, ticker].values, timeperiod=30)<br/> df[‘ATR’] = ta.ATR(data[‘High’, ticker].values, data[‘Low’, ticker].values, data[‘Close’, ticker].values, timeperiod=14)<br/> df[‘ADX’] = ta.ADX(data[‘High’, ticker].values, data[‘Low’, ticker].values, data[‘Close’, ticker].values, timeperiod=14)<br/> df[‘RSI’] = ta.RSI(data[‘Close’, ticker].values, timeperiod=14)<br/> macd, macdsignal, macdhist = ta.MACD( data[‘Close’, ticker].values, fastperiod=12, slowperiod=26, signalperiod=9)<br/> df[‘MACD’] = macd<br/> df[‘MACDsignal’] = macdsignal</span></pre><ul class=""><li id="9250" class="kv kw hh iv b iw ix ja jb je ly ji lz jm ma jq la lb lc ld bi translated">EMA(指数移动平均线)，我们感兴趣的是价格何时高于平均线，最快的平均线何时高于最慢的平均线。</li><li id="50c7" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">ATR(14)(14天的平均真实范围)，我们对触发信号的阈值感兴趣。</li><li id="ca72" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">ADX(14)，我们感兴趣的是触发信号的阈值</li><li id="36d5" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">RSI(14)，我们感兴趣的是触发信号的阈值。</li><li id="0bad" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">MACD，我们对MACD信号何时出现在MACD上空感兴趣。</li></ul><p id="3706" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，我们介绍用于机器学习模型的特征:</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="e56c" class="lt jt hh lp b fi lu lv l lw lx">df[‘Close_EMA_10’] = np.where(data[‘Close’, ticker]&gt; df[‘EMA10’], 1, -1)<br/> df[‘EMA_10_EMA_30’] = np.where(df[‘EMA10’] &gt; df[‘EMA30’], 1, -1)<br/> df[‘MACD_Signal_MACD’] = np.where(df[‘MACD_signal’] &gt; df[‘MACD’], 1, -1)</span></pre><h1 id="0ed8" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">创建目标变量</h1><p id="2d2b" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">这些变量的值将由其他变量建模和预测。决策树分析中必须有且只有一个目标变量。</p><p id="9d12" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">分类算法的目标变量也使用滞后回报，但是因为输出是分类的，所以我们必须转换它。如果回报是正的，我们指定1，如果是负的，我们指定0。</p><p id="8398" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因此，决策树算法应该帮助我们选择指标及其参数的最佳组合，以最大化作为目标的预期输出。</p><p id="722c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们将在这里为ticker和benchmark创建目标变量。</p><p id="3971" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">目标向量由1和0组成。</p><p id="f5dc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">1表示收益为正，0表示收益为负。因此这个优化问题是一个监督学习分类问题。概括地说，分类是一项需要使用机器学习算法的任务，这些算法学习如何为来自问题领域的示例分配类别标签。这个案例是为了理解如何将退货分类为“<em class="jr">正</em>或“<em class="jr">非正</em>”</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="71c7" class="lt jt hh lp b fi lu lv l lw lx">df[‘return’] = np.log(data[‘Close’, ticker]/data[‘Close’, ticker].shift(1))<br/>df[‘return_’+benchmark] = np.log(data[‘Close’, benchmark]/data[‘Close’, benchmark].shift(1))</span><span id="fce6" class="lt jt hh lp b fi mb lv l lw lx">df[‘target’] = np.where(df.return &gt; 0, 1, 0)</span></pre><p id="7eb0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，我们可以定义特征的X矩阵和目标的y向量，用于我们的每个模型中。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="9f6a" class="lt jt hh lp b fi lu lv l lw lx"> X = df[[‘ATR’, ‘ADX’,’RSI’, ‘Close_EMA_10’, ‘EMA_10_EMA_30’, ‘MACD_Signal_MACD’]]<br/> y = df.target</span></pre><h1 id="4686" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">拆分数据</h1><p id="af87" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">在对数据进行一些清理之后(在机器学习研究中总是这样)，我们可以使用sklearn的train_test_split函数，使用数据的拆分来区分训练数据和测试数据。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="c24a" class="lt jt hh lp b fi lu lv l lw lx">#splitting the data and building the training and testing set<br/> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)</span></pre><p id="2666" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，我们必须使用GridSearchCV为每个模型找到最佳参数:</p><ul class=""><li id="36df" class="kv kw hh iv b iw ix ja jb je ly ji lz jm ma jq la lb lc ld bi translated">决策树</li><li id="29ff" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">随机森林树</li><li id="d6b8" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">额外的树</li><li id="19f0" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">逻辑回归</li><li id="27b1" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">线性判别分析</li><li id="7df5" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">K-最近邻</li><li id="ca3f" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">朴素贝叶斯</li><li id="d200" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">adaboost算法</li><li id="79a4" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">支持向量机</li><li id="fcd0" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">梯度推进</li><li id="9ca3" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">逻辑回归</li><li id="0085" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">线性判别分析</li><li id="1d82" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">多层感知器</li></ul><h1 id="3019" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">去结果之前的一些机器学习的一些解释。</h1><p id="eda4" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated"><em class="jr">来源:sklearn官网</em></p><p id="8d57" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">高斯分布:<strong class="iv hi">逻辑回归</strong>是一种线性算法(对输出进行非线性变换)。它假设输入变量与输出变量之间存在线性关系。输入变量的数据转换可以更好地揭示这种线性关系，从而产生更精确的<strong class="iv hi">模型。</strong></p><p id="4a7f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">线性判别分析</strong>是一种监督分类方法，用于创建<strong class="iv hi">机器学习</strong>模型。这些基于降维的模型在应用中使用，例如营销预测<strong class="iv hi">分析</strong>和图像识别等。</p><p id="e958" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">决策树</strong>帮助你评估你的选择。决策树是帮助你在几个行动方案中选择T21的优秀工具。</p><p id="d1cc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">随机森林</strong>由多个单独的<strong class="iv hi">树</strong>组成，每个树基于训练数据的<strong class="iv hi">随机</strong>样本。它们通常比单个<strong class="iv hi">决策树</strong>更准确<strong class="iv hi">。下图显示了随着更多的<strong class="iv hi">树</strong>被添加，决策<strong class="iv hi">边界变得更加精确和稳定。</strong></strong></p><p id="8289" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> KNN </strong>算法可以与最精确的模型竞争，因为它做出高度精确的预测。因此，你可以<strong class="iv hi">将</strong><strong class="iv hi">KNN</strong>算法用于需要高精度但不需要人类可读模型的应用。预测的质量取决于距离度量。</p><p id="4b29" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> SVM </strong>或<strong class="iv hi">支持向量机</strong>是用于分类和回归问题的线性模型。它可以解决线性和非线性问题，并能很好地解决许多实际问题。<strong class="iv hi"> SVM </strong>的想法很简单:算法创建一条线或一个超平面，将数据分类。我们将使用RBF核:径向基函数核不仅仅帮助我们避免计算一些额外的特征。RBF特征空间有无限多个维度。这意味着我们可以利用内核来构建非常复杂的决策边界。维度越多，我们就越有可能找到一个将我们的数据整齐分开的超平面。</p><p id="dd4a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">多层感知器(MLP) </strong>是一种监督学习算法，通过在数据集上训练来学习函数f(⋅):Rm→Ro，其中m是输入的维数，o是输出的维数。给定一组特征X=x1，x2，…，xm和一个目标y。</p><p id="9c49" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">高斯朴素贝叶斯</strong>是<strong class="iv hi">朴素贝叶斯</strong>的变体，遵循<strong class="iv hi">高斯</strong>正态分布，支持连续数据。<strong class="iv hi">朴素贝叶斯</strong>是一组基于<strong class="iv hi">贝叶斯</strong>定理的监督<strong class="iv hi">机器学习</strong>分类算法。这是一种简单的分类技术，但功能性很强。</p><p id="f3e1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> Boosting </strong>算法是一组弱分类器创建一个强分类器。</p><p id="433d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">梯度推进</strong>是一种用于回归和分类问题的<strong class="iv hi">机器学习</strong>技术，它以弱预测模型集合的形式产生预测模型，通常是决策树。</p><h1 id="f9b0" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">机器学习模型</h1><p id="ed9a" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">我们将使用python库sklearn来构建我们的分类模型。这里是我们将使用的导入。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="d26e" class="lt jt hh lp b fi lu lv l lw lx">from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold<br/>from sklearn.model_selection import KFold<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.metrics import classification_report<br/>from sklearn.tree import DecisionTreeRegressor<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.ensemble import ExtraTreesClassifier <br/>from sklearn.ensemble import AdaBoostClassifier <br/>from sklearn.ensemble import GradientBoostingClassifier<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.model_selection import RandomizedSearchCV<br/>from sklearn import svm<br/>from sklearn.neural_network import MLPClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis<br/>from sklearn.naive_bayes import GaussianN</span></pre><p id="2405" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先，我们可以在分类模型中搜索，最好的分类模型。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="1092" class="lt jt hh lp b fi lu lv l lw lx">def model_selection(X,Y):<br/> seed = 7<br/> models = []<br/> models.append((‘LogisticRegression’, LogisticRegression(random_state=seed)))<br/> models.append((‘LinearDiscriminantAnalysis’, LinearDiscriminantAnalysis()))<br/> models.append((‘KNeighborsClassifier’, KNeighborsClassifier()))<br/> models.append((‘DecisionTreeClassifier’, DecisionTreeClassifier()))<br/> models.append((‘GaussianNB’, GaussianNB()))<br/> models.append((‘RandomForestClassifier’, RandomForestClassifier()))<br/>     models.append((‘ExtraTreesClassifier’,ExtraTreesClassifier(random_state=seed)))<br/> models.append((‘AdaBoostClassifier’,AdaBoostClassifier(DecisionTreeClassifier(random_state=seed),random_state=seed,learning_rate=0.1)))<br/> models.append((‘SVM’,svm.SVC(random_state=seed)))<br/> models.append((‘GradientBoostingClassifier’,GradientBoostingClassifier(random_state=seed)))<br/> models.append((‘MLPClassifier’,MLPClassifier(random_state=seed)))</span><span id="e655" class="lt jt hh lp b fi mb lv l lw lx"># evaluate each model in turn<br/> results = []<br/> names = []<br/> scoring = ‘accuracy’<br/> for name, model in models:<br/> kfold = KFold(n_splits=10, shuffle=True, random_state=seed) <br/> cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)<br/> results.append(cv_results)<br/> names.append(name)<br/> msg = “%s: %f (%f)” % (name, cv_results.mean(), cv_results.std())<br/> print(msg) return results, names</span></pre><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mc"><img src="../Images/171cb948bfb29187e657f56d744c2dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*AXnfqb2T8Vj3h9XKyrWz_A.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es md"><img src="../Images/5ec2fc5eaeffbe2f6bc4a4c7a8bdb270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*48l5zw0-6g_YZTgAFFMlgg.png"/></div></figure><p id="92f3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">乍一看，我们可以看到梯度推进，逻辑回归和线性判别分析可能是最好的模型使用。</p><p id="40dc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，我们使用函数GridSearchCV在每个估计器的定义中的可用参数中搜索最佳参数(有关更多信息，请参见sklearn网站)。</p><p id="c224" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Scikit-Learn的GridSearchCV会搜索我们。我们需要做的只是告诉它我们希望它试验哪些超参数，以及试验哪些值，它将使用交叉验证评估所有可能的超参数值组合。</p><p id="70d5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">完成后，我们可以致电:</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="c22e" class="lt jt hh lp b fi lu lv l lw lx">grid_search = GridSearchCV(estimator = model, param_grid = param_grid, <br/> cv = 3, n_jobs = -1, verbose = 2)</span><span id="cb3c" class="lt jt hh lp b fi mb lv l lw lx">grid_search.fit(X_train, y_train)</span></pre><p id="3c67" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们用属性best_params_获得最佳参数，然后我们可以使用方法set_params()设置best_params</p><h1 id="b67a" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">技术性能分析</h1><p id="49fd" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">该报告显示了一些有助于我们评估算法优劣的参数:</p><ul class=""><li id="3139" class="kv kw hh iv b iw ix ja jb je ly ji lz jm ma jq la lb lc ld bi translated"><strong class="iv hi">准确度</strong>:准确度分数是真阳性和真阴性在指定标签总数中所占的比例</li><li id="197b" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated"><strong class="iv hi">精度</strong>:表明我们预测的质量。这告诉我们有多少我们预测在某个类中的值实际上在那个类中。本质上，这告诉我们如何在假阳性方面表现。</li><li id="9ca4" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated"><strong class="iv hi">回忆</strong>:表明我们预测的质量。这告诉我们每个类中有多少值被赋予了正确的标签，从而告诉use它相对于假阴性的表现如何。</li><li id="59e0" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated"><strong class="iv hi">F1-得分</strong>:显示精度和召回率的调和平均值。这是一个精度和召回规模的加权平均值，1为最好，0为最差。这使用了调和平均值，因此该值更接近较小的数字，并防止在一个参数高而另一个参数低的情况下高估模型的性能。</li><li id="871e" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated"><strong class="iv hi">支持</strong>:作为权重计算精度、召回率和F-1的平均值。</li></ul><p id="0f56" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">任何高于0.5的数字通常被认为是一个好数字。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="e816" class="lt jt hh lp b fi lu lv l lw lx">report = classification_report(y_test, y_pred)<br/>print(report)</span></pre><p id="800a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后我们可以构建一个图表来显示测试数据上的策略:</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="4fe8" class="lt jt hh lp b fi lu lv l lw lx">plt.plot((df.strategy_returns[train_length:]+1).cumprod(),’b-’,label=’Strategy returns decision tree ‘)<br/>plt.plot((df.return[train_length:]+1).cumprod(),’g-’,label=’Strategy returns Buy and Hold ‘)<br/>plt.plot((df[‘return_’+benchmark][train_length:]+1).cumprod(),’r-’,label=benchmark+’ returns Buy and Hold ‘)</span><span id="f499" class="lt jt hh lp b fi mb lv l lw lx">plt.ylabel(‘Strategy returns(%)’)<br/>plt.legend()<br/>plt.show()</span></pre><h1 id="3d3c" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">如何创建一个函数来测试sklearn库中的所有模型以进行分类</h1><p id="a2b2" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">10重交叉验证程序用于评估每种算法，重要的是使用相同的随机种子进行配置，以确保对训练数据执行相同的分割，并以完全相同的方式评估每种算法。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="3912" class="lt jt hh lp b fi lu lv l lw lx">def model_selection(X,Y):<br/> seed = 5<br/> models = []<br/> models.append((‘LR’, LogisticRegression()))<br/> models.append((‘LDA’, LinearDiscriminantAnalysis()))<br/> models.append((‘KNN’, KNeighborsClassifier()))<br/> models.append((‘CART’, DecisionTreeClassifier()))<br/> models.append((‘NB’, GaussianNB()))<br/> models.append((‘SVM’, svm.SVC()))<br/> models.append((‘RFT’, RandomForestClassifier()))<br/><br/> results = []<br/> names = []<br/> scoring = ‘accuracy’<br/> for name, model in models:<br/> kfold = KFold(n_splits=10, shuffle=True, random_state=seed) <br/> cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)<br/> results.append(cv_results)<br/> names.append(name)<br/> msg = “%s: %f (%f)” % (name, cv_results.mean(), cv_results.std())<br/> print(msg)<br/> return results, names</span><span id="4953" class="lt jt hh lp b fi mb lv l lw lx">def plot_models(results, names):<br/> fig = plt.figure()<br/> fig.suptitle(‘Algorithm Comparison’)<br/> ax = fig.add_subplot(111)<br/> plt.boxplot(results)<br/> ax.set_xticklabels(names)<br/> plt.show()</span></pre><p id="1574" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">运行该示例会提供每个算法的简称、平均精度和标准偏差精度的列表。</p><p id="dc75" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从这些结果中，我们可以看出，逻辑回归和线性判别分析都可以更好地拟合我们建模研究的数据。</p><h2 id="cd05" class="lt jt hh bd ju me mf mg jy mh mi mj kc je mk ml kg ji mm mn kk jm mo mp ko mq bi translated">模型逻辑回归的绘图性能</h2><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/d03d96aae88bdf02829e454285672fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXtod1wLLm9gog4Kid6-7A.png"/></div></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/aaa89318843197d0d6aed4fd521edcb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*NfuiPDvuGeL9tKxa1TnhZA.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/40d7aa4dfe18b6762bbdddb7d126f330.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*-5-CsDY9EfgkXOJ7bsSYkg.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/1f9623685079270262f9cddeec70b796.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*TsAYSr-9BBO44bpb7VNCFQ.png"/></div></figure><h2 id="bcc6" class="lt jt hh bd ju me mf mg jy mh mi mj kc je mk ml kg ji mm mn kk jm mo mp ko mq bi translated"><strong class="ak">绘制模型决策树的性能</strong></h2><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/a85d19e9f26327c12c72c56c00ece637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ry54jgDdOOis3lrQkDgH0A.png"/></div></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/d330c54395d62d714cd3c6e4311ea1c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*tQAMY3W8eLC40tyKeaPpng.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/804bfa75122c721201685b4c0c432aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*euCFtO3p8uQBVxly3Bkz1g.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">histogram of strategy returns</figcaption></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/5aa365f8c3c76f96878ba9c201a62c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*M5ZOUiT1-hx33Wr92ggACg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">strategy plotting for decision trees algorithm comparing to the benchmark and classical buy&amp;hold strat</figcaption></figure><h2 id="2621" class="lt jt hh bd ju me mf mg jy mh mi mj kc je mk ml kg ji mm mn kk jm mo mp ko mq bi translated">模型随机森林树的绘图性能</h2><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mx"><img src="../Images/40f6acad0143fb3e62da6e10f1965d94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t5NMRGJXuzOulg_K6q4H0w.png"/></div></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/3cd08874997ed58fdaf24cebbac9dde8.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*XQ8RXJaw2fJaayDOeToHOw.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/2efd277c2437f6d5389271697ef80727.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*L5HvkoYUgs3WM0akUR40oQ.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/dc2ca36a22ca68571fca31e153b0c0f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*_rC4QAxLv5J3-y5RBDK_8g.png"/></div></figure><h2 id="0bcf" class="lt jt hh bd ju me mf mg jy mh mi mj kc je mk ml kg ji mm mn kk jm mo mp ko mq bi translated">模型K最近邻的绘图性能</h2><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es my"><img src="../Images/d44aebc5a30ddc340dc03b11e0c0f9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0e84ZBLu5W1pRdxkmC3nDQ.png"/></div></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/4e05b875331f7e3d1f97724bde71a191.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*7ivcxzZu9lTzX0zsGmt7WA.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/3fab2379c41a1a4c7b0a697bdfce9737.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*QthVNlyNFTAi-me1yZu8iA.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/3ccf20a1d319487b79891a5d007cff99.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*W-3vDNxe0D-PmxviA60NhQ.png"/></div></figure><h2 id="48b1" class="lt jt hh bd ju me mf mg jy mh mi mj kc je mk ml kg ji mm mn kk jm mo mp ko mq bi translated">模型支持向量机的绘图性能:SVM</h2><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/3e1b8702c065a1e93fb17bbb30a1a652.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*w6BtsQHhV06V52f8HsD7_w.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/6e3a1e5bb6b8226016384e5bd17421bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fcb_QDB7a0cSA-U4hgGJXQ.png"/></div></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/ac5bed5c9a7ecff53cfdd53b185d7339.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*n_VeyWseHCq4M9Q7y5xUlA.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/c6f2144f7d8af3cd81649c140d41e192.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*UiCGlcoYcC7OjuNIxPVtzQ.png"/></div></figure><h2 id="bbd4" class="lt jt hh bd ju me mf mg jy mh mi mj kc je mk ml kg ji mm mn kk jm mo mp ko mq bi translated">模型神经网络的绘图性能:<strong class="ak">多层感知器</strong></h2><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mz"><img src="../Images/90629e6c5958be0c29b421d9308165ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p6B_dHSIglhroEOUdz6BDg.png"/></div></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/c984487b9287a153bae5f310f1b00ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*Hh3sgK-P-PtXA9Shn8ZuRw.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/c3c492b27faa10c2827fceb1b8e02da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*UodNCF8HvCPsLIj_he0Syw.png"/></div></figure><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/7bb6984ec3d2d666ec542402907180c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*mpvvvqKkJ5AWtbWqYHEJng.png"/></div></figure><p id="1b67" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">结论</strong></p><p id="0583" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">感谢你阅读这篇文章。关于机器学习和交易，我甚至还没有触及我所能谈论的一切的表面，但是我希望这篇文章已经成为这个领域中一些话题的介绍。看到机器学习在未来几年将走向何方，以及它将如何改善我们的生活，这将是令人兴奋的。</p><p id="fb98" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">法律免责声明(请仔细阅读！)</strong></p><p id="9862" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — -</p><p id="5526" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">本课程仅用于一般信息和教育目的。它既不是直接也不是间接的建议、意见或号召投资、交易或采取任何行动。任何观点、新闻、研究、分析、价格、代码示例或其他信息都是作为一般市场评论提供的，并不构成投资建议。课程中展示的例子仅用于说明目的，并非投资建议或交易诱因。过去的表现并不代表未来的表现。</p><p id="a4a7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">所有内容、视频、Python代码、Jupyter笔记本和其他材料都没有担保或陈述。作者不保证所提供信息的正确性或完整性。作者不承担任何损失或损害的责任，包括但不限于任何利润损失，这些损失可能直接或间接由使用或依赖此类信息引起。</p></div></div>    
</body>
</html>
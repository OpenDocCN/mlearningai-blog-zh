<html>
<head>
<title>Implementation of GoogLeNet on Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Keras上实施GoogLeNet</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c?source=collection_archive---------0-----------------------#2021-03-26">https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c?source=collection_archive---------0-----------------------#2021-03-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="37a7" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">1.介绍</h1><p id="489a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">GoogLeNet是由<a class="ae ka" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html" rel="noopener ugc nofollow" target="_blank"> Szegedy等人</a> [1]提出的深度卷积神经网络。该网络赢得了2014年ImageNet大规模视觉识别挑战赛(ILSVRC-2014)，取得了92.3%的分类性能。特别是，该模型是在一个特殊的体系结构中设计的，允许增加网络的深度和宽度，但保持计算资源。</p><p id="1fa1" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">VGG模型总共有22层，由9个初始模块组成。每个先启块由四个并行路径组成，在这些路径上应用了不同内核大小的卷积层[图1]:</p><ul class=""><li id="0b50" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">第一条路径使用窗口大小为1 × 1的卷积层。</li><li id="de78" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">在第二和第三路径中，在应用两个昂贵的3 × 3和5 × 5卷积之前，使用大小为1 × 1的卷积层。1×1卷积有助于减少滤波器通道的数量，从而降低模型复杂度。</li><li id="e412" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">第四条路径使用max-pooling层来降低输入的分辨率，其后是1 × 1卷积层来降低维度。</li></ul><p id="e208" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这四个路径使用适当的填充，以便输入和输出具有相同的大小。这四个路径的连接允许以不同的分辨率扫描输入。特别是，由于在每条路径中应用了1 × 1卷积层，模型复杂度被最小化。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/49225c6243d22bec9c246485c5e33380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zIcot5nm9q_TC8zqcGQ7Dg.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Figure 1: Inception block. <a class="ae ka" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="9a74" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">以下是GoogLeNet的结构和所有的附加功能:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lk"><img src="../Images/b1a325e6f262c5fe73ff57e75e7ad852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*4nb4lVJnaKJZAu6Lthuz2Q.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx">Figure 2: GoogLeNet architecture. <a class="ae ka" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><ul class=""><li id="d7b1" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">输入尺寸图像为224 × 224。</li><li id="8b64" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">在这个网络中有九个初始块。</li><li id="8d6f" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">在初始块之外有四个最大池层，其中两层位于块3–4和块7–8之间。这些最大池层有助于减少输入数据的大小，从而降低模型复杂性以及计算成本。</li><li id="b24e" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">这个网络继承了NiN使用平均池层的思想，这有助于提高模型性能和减少过拟合。</li><li id="e648" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">在线性层之前使用了一个下降层(40%)。这也是减少过拟合现象的有效正则化方法。</li><li id="9692" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">输出层使用softmax激活函数给出1000个输出，这些输出对应于ImageNet数据集中的类别数。</li></ul><p id="fcff" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">此外，在侧面添加了一些额外的网络，这促进了分类器中较低阶段的区分，增加了得到反向传播的梯度信号，并提供了额外的正则化。这些网络的结构包括:</p><p id="b79c" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">→一个平均池层，池大小为5 × 5，跨度为3。</p><p id="b1b5" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">→1×1卷积层，具有128个用于降维的滤波器和一个整流线性激活。</p><p id="1655" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">→具有1024个单位和整流线性激活的全连接层。</p><p id="41c2" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">→输出比率为70%的辍学。</p><p id="95be" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">→使用softmax激活功能将对象分类为1000个类别之一的输出层。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ll"><img src="../Images/e350f0cb14e84a3a056138e661bef3b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*udmzXcXVzgXx2xXoHFnTlw.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Table 1: Summarization of GoogLeNet architecture. <a class="ae ka" href="https://arxiv.org/pdf/1409.4842.pdf" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h1 id="0cd0" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">2.在Keras上实施GoogLeNet</h1><p id="daf0" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">首先，我们需要导入一些必要的库:</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="1c12" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">创建一个先启块:</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="fb70" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">实现GoogLeNet模型的函数:</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="d2b2" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这个模型的总参数数是10，532，397。请参考我的<a class="ae ka" href="https://github.com/KhuyenLE-maths/Implementation-of-GoogLeNet-on-Keras/blob/main/Implementation_of_GoogLeNet_on_Keras.ipynb" rel="noopener ugc nofollow" target="_blank">代码</a>了解该型号的详细信息。</p><p id="1147" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">虽然模型实现起来比较复杂，但是整个模型的参数个数并不大。密集层总是采用大部分参数。此外，全局平均池层的出现有助于显著减少参数数目，从而降低模型的计算复杂度。</p><p id="33bb" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">结论:</strong>我们已经在Keras平台上发现了GoogLeNet模型的架构和实现。它由初始块组成。每个模块都有特殊的架构，通过四条并行路径同时提取输入特征。此外，在这些路径中最大限度地应用1×1卷积层来降低信道维数。此外，在一些启始块之间应用最大池层起到了降低分辨率的作用，从而降低了计算复杂度。总之，这个模型的参数数量比Alexnet模型小6倍，比VGG模型小得多。尤其是它胜过这些模型。GoogLeNet的这种有趣的架构也是后来模型出现的灵感。</p></div><div class="ab cl lo lp go lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ha hb hc hd he"><p id="f87f" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">希望这篇帖子对你有帮助。</p><p id="6a5c" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">感谢阅读！</p><p id="a6f1" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi"> Github代码</strong>:<a class="ae ka" href="https://github.com/KhuyenLE-maths/Implementation-of-GoogLeNet-on-Keras/blob/main/Implementation_of_GoogLeNet_on_Keras.ipynb" rel="noopener ugc nofollow" target="_blank">https://Github . com/khu yenle-maths/Implementation-of-Google net-on-Keras/blob/main/Implementation _ of _ Google net _ on _ Keras . ipynb</a></p><p id="df37" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi">____________________________________________________________</p><p id="0733" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">参考文献:</strong></p><p id="4457" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">[1]塞格迪、克里斯蒂安等人，“用卷积深入研究”<em class="lv">IEEE计算机视觉和模式识别会议论文集</em>。2015.</p></div></div>    
</body>
</html>
# 在 GPU 上从头开始训练卷积神经网络(ConvNet/CNN)

> 原文：<https://medium.com/mlearning-ai/training-convolutional-neural-network-convnet-cnn-on-gpu-from-scratch-439e9fdc13a5?source=collection_archive---------0----------------------->

## 数据集— CIFAR 10 (acc > 75%)

![](img/1231c3d2322766922dfcbf8afacf690b.png)

Photo by [JJ Ying](https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

在我之前的[博客](https://gurjeet333.medium.com/training-feed-forward-neural-network-ffnn-on-gpu-beginners-guide-2d04254deca9#e235)中，我开发了一个前馈神经网络来在 CIFAR 10 数据集上进行训练。作为前向神经网络，在图像数据集上不强大。我们达到了 50%的准确率。我将从头构建一个 CNN 模型，并在 CIFAR 10 数据集上验证其性能。但在我们开始之前，我将尝试回答几个基本问题。

1.  **什么是 CNN？** A **卷积神经网络(ConvNet/CNN)** 是一种深度学习算法，它可以接受输入图像，为图像中的各个方面/对象分配重要性(可学习的权重和偏差)，并能够区分它们。与其他分类算法相比，ConvNet 中所需的预处理要低得多。
2.  **为什么 CNN 优于前馈神经网络？CNN 比 FFNN 更倾向于理解图像。CNN 能够通过应用相关过滤器成功地**捕捉图像中的空间和时间相关性**。
    人工神经网络适用于表格和文本数据，而 CNN 适用于处理图像。**

# 关于数据集

CIFAR-10 数据集(加拿大高级研究所)是一个图像集合，通常用于训练机器学习和计算机视觉算法。这是机器学习研究中使用最广泛的数据集之一。CIFAR-10 数据集包含 10 个不同类别的 60，000 幅 32x32 彩色图像。这 10 个不同的类别代表飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。每个类有 6000 张图片。

# 目录

1.  [简介](#0598)
2.  [数据预处理](#4a49)
    2.1 [加载所需库](#2dae)
    2.2 [获取数据](#8c57)
3.  [探索 CIFAR 数据集](#e1f7)
    3.1 [训练和测试数据集包含多少张图像？](#fc48)
    3.2 [数据集包含多少个输出类？](#6dab)
    3.3 [来自数据集的图像张量是什么形状？](#7cdf)
    3.4 [你能确定属于每一类的图像数量吗？](#d680)
4.  [准备用于训练的数据](#eff8)
    4.1 [拆分成训练和验证集](#becc)
    4.2 [可视化批处理](#2bf8)
    4.3 [配置模型](#7b6d)
    4.4 [将模型移动到 GPU](#5257)
5.  [训练模型](#8ed0)
6.  [使用单个图像进行测试](#2cd4)
7.  [总结](#9771)
8.  [未来工作](#dfdc)
9.  [参考文献](#3afd)

如果您已经通读了我之前的[博客](https://gurjeet333.medium.com/training-feed-forward-neural-network-ffnn-on-gpu-beginners-guide-2d04254deca9#e235)，那么您可以跳过前三节，移动第 4 节，因为数据预处理和探索保持不变。

# №1:简介

CIFAR-10 数据集包含 10 个不同类别的 60，000 幅 32x32 彩色图像。CIFAR-10 是一组图像，可用于教 FFNN 如何识别物体。由于 CIFAR-10 中的图像是低分辨率的(32x32)，这个数据集可以让研究人员快速尝试不同的算法，看看什么有效。

CIFAR 10 数据集下的类别列表—

1.  ✈️飞机公司
2.  汽车🚗
3.  鸟🐦
4.  猫😺
5.  鹿🐆
6.  狗🐶
7.  青蛙🐸
8.  马🐴
9.  船🚢
10.  卡车🚚

# №2:数据预处理

## 加载所需的库

因为我们用 PyTorch 来构建神经网络。我一次性导入了所有相关的库。

## 检索数据

该数据集可在 torch 视觉库中获得。或者，您也可以从 [Kaggle](https://www.kaggle.com/c/cifar-10) 访问数据集。

# №3:探索 CIFAR10 数据集

## 问:训练和测试数据集包含多少幅图像？

## 问:数据集包含多少个输出类？

## 问:来自数据集的图像张量的形状是什么？

## 问:您能确定属于每个类别的图像数量吗？

# №4:为培训准备数据

## 分成训练集和验证集

在训练开始之前，将数据分成训练集和测试集是很重要的。

数据集分为 45000 个训练集和 5000 个验证集。

我们现在可以创建数据加载器来批量加载数据。

让我们使用 Torchvision 的 make_grid helper 函数来可视化一批数据。

## 可视化批处理

你能通过观察给所有的图片贴上标签吗？尝试手动标记数据的随机样本是估计问题难度和识别标记中的错误(如果有的话)的好方法。

## 配置模型

我编写了一个精度函数，通过比较预测类和实际类标签来计算模型精度。

我写了一个包含 4 个函数的 **ImageClassificationBase** 类。实现损失和准确性的训练集和验证集各有一个函数。“validation_epoch_end”结合了每个 epoch 的损失和精度,“epoch_end”在每个 epoch 结束时打印“ **val_loss** 和“ **val_acc** ”。

我们将使用`nn.Sequential`将层和激活功能链接到单个网络架构中。

## 将模型移动到 GPU

在本节中，我们将把我们的模型转移到 GPU 上。

让我们首先检查一下 GPU 在您当前的系统中是否可用。如果可用，则将默认设备设置为 GPU，否则将其设置为 CPU。

现在，我将训练、验证和测试集加载到可用的默认设备上。

# №5:训练模型

让我们首先定义输入和输出的大小

训练循环的某些部分特定于我们正在解决的特定问题(例如，损失函数、指标等)。)而其他的是通用的，可以应用于任何深度学习问题。

我们将在一个名为`fit`的函数中包含与问题无关的部分，该函数将用于训练模型。特定于问题的部分将通过向`nn.Module`类添加新方法来实现

`fit`函数记录每个时期的验证损失和度量。它返回训练的历史，对调试&可视化很有用。

在没有训练的情况下，val_acc 在 10%左右。这是随机猜测，预测正确类别的可能性是 1/10。

让我们现在开始训练

在 **10 个时期**内，模型提供了 76 %的**准确度。这是惊人的，也是 ANN(又名前馈神经网络)无法实现的。**

让我们也定义几个辅助函数来绘制损耗和精度。

绘制损耗和精确度

培训和验证损失

最初，培训和验证损失似乎都随着时间的推移而减少。但是，如果你训练模型的时间足够长，你会注意到训练损失持续减少，而验证损失停止减少，甚至在某个点之后开始增加！

这种现象被称为**过拟合**，这也是许多机器学习模型在真实世界数据上给出相当糟糕的结果的首要原因。

以下是一些避免过度拟合的常用策略:

*   收集和生成更多的训练数据，或者向其中添加噪声
*   使用规范化技术，如批量规范化和删除
*   当验证损失开始增加时，提前停止模型的训练

我将在未来的笔记本中实现这些策略，以进一步提高模型的性能。

# №6:使用单个图像进行测试

从 Torchvision 库加载测试集

让我们定义一个辅助函数 predict_image，它返回单个图像张量的预测标签。

检查少数样品的标签和预测值

在测试集上模拟性能

嗯，表现好的课有哪些，表现不好的课有哪些:

将来可以进一步分析该模型，以了解为什么少数班级表现不佳。

# №7:摘要

这里是文章的简要总结和我们在 GPU 上训练 CNN 的一步一步的过程。

1.  我们简要了解了 CNN 神经网络及其优于 ANN 的优势。
2.  从火炬视觉图书馆下载了数据集。
3.  我们研究了数据集，并试图理解每个类拥有的全部图像、训练和验证集中的全部图像等。
4.  训练前的数据准备
    i .分成训练集和验证集。
    二。我们可视化了一批数据集。
    三世。我们做了基本的模型配置，如定义精度、评估和拟合函数。我们还定义了 ImageClassificationBase 类。
    四。我们检查了 GPU 的可用性，并将数据集移动到 GPU，如果可用，则将其移动到 CPU。
5.  我们训练了 CNN 模型，实现了大约 76%的**准确率，比 ANN 的 48%**准确率**好得多**
6.  我们通过在几个测试样本上运行来随机检查模型性能

# №8:未来的工作

1.  未来可以通过使用批量标准化、数据增加和减少等正则化技术来提高模型性能
2.  尝试实现另一个深度学习框架 Tensorflow。
3.  尝试通过更新 CNN 中的层数、更改优化器和损失函数来提高模型性能。

# №9:引用

1.  您可以通过此链接访问并执行完整的笔记本—[https://jovian.ai/hargurjeet/cfar-10-dataset-6e9d9](https://jovian.ai/hargurjeet/cnn-cfar-10-dataset)
2.  [https://pytorch.org/](https://pytorch.org/)
3.  [https://py torch . org/docs/stable/generated/torch . nn . crossentropyloss . html](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)
4.  [https://jovian . ai/learn/deep-learning-with-py torch-zero-to-gans](https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans)

我真的希望你们能从这篇文章中学到一些东西。请随意给一个👏如果你喜欢你所学的。这让我保持动力。

我将在本周内发表另一篇文章，讨论如何进一步提高 CNN 神经网络的性能。直到那个时候

![](img/59f08c79063b1608632540bdb88e8d64.png)

## 感谢阅读这篇文章。快乐学习😃
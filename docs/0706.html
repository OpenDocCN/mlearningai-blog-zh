<html>
<head>
<title>Quantum Kernel Machine Learning — Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">量子核机器学习—简介</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/quantum-kernel-machine-learning-introduction-fbf133afebc2?source=collection_archive---------1-----------------------#2021-06-19">https://medium.com/mlearning-ai/quantum-kernel-machine-learning-introduction-fbf133afebc2?source=collection_archive---------1-----------------------#2021-06-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/eec125dee916b786453089ff46809a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*dxaGsVC2BXfxG0mZMGgmEA.png"/></div></figure><p id="bc73" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">机器学习(ML)是机器识别数据中的模式。模式可以是数据点可以分组或分段的类或簇。ML旨在让机器从数据中直接自动识别这些模式(无需人类编程)。机器可以使用预先标记的(标记很可能由人类完成)数据进行训练，然后留给它自己的设备对新数据进行分类。这就是所谓的监督学习。或者，机器被给予未标记的数据，并被分派任务来识别有效的聚类并自己创建标签。这就是无监督学习。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div class="er es jj"><img src="../Images/6ac48e0a523454b8ca00582c864999da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dM5a0lcgnPYoHLkQLn0FwA.jpeg"/></div></figure><p id="408f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在许多情况下，数据很难以原始形式理解。通常对数据进行一些变换，以帮助识别模式。例如，表格列中的数据被转换成二维图形，从而更容易发现趋势。前面的例子是一个可以扩展的类比。如果我们将数据转换到更高的维度，事实证明模式在更高的维度中更容易识别和表达。支持向量机使用这种思想作为它们如何执行分类和聚类的基础。YouTube上有非常好的关于内核(以及使用内核的支持向量机)的教程。我推荐这个<a class="ae jo" href="https://youtu.be/efR1C6CvhmE" rel="noopener ugc nofollow" target="_blank">关于支持向量机的三部分系列</a>。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jp"><img src="../Images/b4cffa2f02d71e072881745960500a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*699xSo_3FQ2uEU-NwJaBrw.png"/></div></div></figure><p id="53a0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">基本思想是采用数据点，并使用特征图将它们从较低的m维特征空间转换到较高的n维特征空间。图1显示了将数据从2D转换到3D的过程，其中一个简单的平面就可以分割数据，而在2D则需要“蜿蜒”的直线。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ju"><img src="../Images/a234cb9466b593f162c044f731ad8111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l31UBSL4CM5DQ_l7NPVmdQ.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Figure 1. A feature map transforms data points from a lower m dimensional (here 2 dimensions) to a higher n dimensional (3 dimensions) feature space. Here, the data segmentation in 2D was a ‘wiggly’ complex pattern, but simplified to a plane in 3D.</figcaption></figure><p id="be0f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们把数据点叫做<em class="jz"> x </em>和<em class="jz">x’。</em>这些由特征映射<em class="jz"> f </em>映射到特征空间，成为<em class="jz"> f(x) </em>和<em class="jz">f(x’)</em>。在这个更高维度的特征空间中，我们可以通过取两者之间的点积即内积来检查<em class="jz"> f(x) </em>和<em class="jz">f(x’)</em>，<em class="jz"> &lt; f(x)，f(x’)&gt;</em>。于是，一个核<em class="jz"> k(x，x') </em>是<em class="jz"> f(x) </em>和<em class="jz">f(x ')</em>之间相似性的度量，即<em class="jz"> k(x，x') = &lt; f(x)，f(x') &gt;。</em>对于一个有限的数据集，这可以对所有的数据点对进行，并组合成一个矩阵。</p><p id="d784" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在谈谈“量子”方面。有趣的是,“量子”方面可以从符号模式中识别出来。在量子力学中，两个量子态<em class="jz"> S(x) </em>和<em class="jz"> S(x') </em>之间的重叠可以用所谓的bra-ket符号表示为<em class="jz"> &lt; S(x)|S(x') &gt;，</em>与一个核非常相似！事实证明，相似之处(或者更确切地说是类比？)不仅仅是符号。量子计算涉及从输入空间中取出一些数据点<em class="jz"> x </em>，通过映射状态<em class="jz"> |S(x) &gt; </em>将其转换到更高维度的希尔伯特空间。高维空间是通过测量来访问的，这类似于内核。关于详细的讨论，我推荐Maria Schuld在YouTube上关于量子增强内核方法的视频。</p><p id="40ce" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">只有当特征图高度复杂，而不仅仅是产品状态时，核方法才能获得量子优势。这已经在几篇标志性论文中进行了研究。我们将在教程中使用玩具数据模型、sklearn和Qiskit来跟踪这些调查。</p><h1 id="b254" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">Qiskit + sklearn教程</h1><ol class=""><li id="ed4e" class="ky kz hh in b io la is lb iw lc ja ld je le ji lf lg lh li bi translated"><a class="ae jo" href="https://verreaux.medium.com/classification-using-quantum-kernels-tutorial-8a2f442fd188" rel="noopener">教程—使用量子核和各种编码进行分类。</a></li><li id="8d6d" class="ky kz hh in b io lj is lk iw ll ja lm je ln ji lf lg lh li bi translated"><a class="ae jo" href="https://verreaux.medium.com/clustering-using-quantum-kernels-tutorial-dcd90bf6440c" rel="noopener">教程—使用量子内核和各种编码进行聚类。</a></li><li id="67b0" class="ky kz hh in b io lj is lk iw ll ja lm je ln ji lf lg lh li bi translated">教程—在真实硬件上实现。</li></ol><h2 id="65c6" class="lo kb hh bd kc lp lq lr kg ls lt lu kk iw lv lw ko ja lx ly ks je lz ma kw mb bi translated">参考</h2><ol class=""><li id="f0fb" class="ky kz hh in b io la is lb iw lc ja ld je le ji lf lg lh li bi translated">havlíek，v .，Córcoles，A.D .，Temme，K. <em class="jz">等</em>利用量子增强特征空间的监督学习。<em class="jz">性质</em> <strong class="in hi"> 567，</strong>209–212(2019)。<a class="ae jo" href="https://doi.org/10.1038/s41586-019-0980-2" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1038/s41586-019-0980-2</a></li><li id="26a0" class="ky kz hh in b io lj is lk iw ll ja lm je ln ji lf lg lh li bi translated"><a class="ae jo" href="https://arxiv.org/abs/2101.11020" rel="noopener ugc nofollow" target="_blank"> arXiv:2101.11020 </a> <strong class="in hi">【定量ph】</strong></li><li id="dac2" class="ky kz hh in b io lj is lk iw ll ja lm je ln ji lf lg lh li bi translated">、y、矢野、h、高、Q. <em class="jz">等</em>基于核的量子分类器的特征图分析与合成。<em class="jz">量子马赫。智能。</em> <strong class="in hi"> 2、</strong> 9 (2020)。<a class="ae jo" href="https://doi.org/10.1007/s42484-020-00020-y" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/s42484-020-00020-y</a></li><li id="7849" class="ky kz hh in b io lj is lk iw ll ja lm je ln ji lf lg lh li bi translated"><a class="ae jo" href="https://qiskit.org/documentation/machine-learning/tutorials/03_quantum_kernel.html" rel="noopener ugc nofollow" target="_blank">量子内核机器学习— Qiskit机器学习0.1.0文档</a></li></ol></div></div>    
</body>
</html>
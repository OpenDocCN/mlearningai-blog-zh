<html>
<head>
<title>Standardization vs Normalization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">标准化与规范化</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/standardization-vs-normalization-907bb0f3c74a?source=collection_archive---------3-----------------------#2022-05-29">https://medium.com/mlearning-ai/standardization-vs-normalization-907bb0f3c74a?source=collection_archive---------3-----------------------#2022-05-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1e62" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">特征缩放</strong>:一种用于将数据中存在的独立特征带入固定范围的技术。</p><p id="9223" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它是我们在进行特征变换、构造、选择和提取之后在特征工程中做的最后一件事。然后我们衡量价值。</p><h2 id="da27" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">为什么需要扩展的示例:</h2><p id="de49" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">考虑一个例子，一个人的身高和体重，其中身高以米为单位，如1米、2米等。重量单位是50公斤、65公斤等。因此，在计算距离值时，由于较大的值，权重特征将在不同的算法中占主导地位，如果您直接将这些值提供给算法而不进行缩放，则模型往往会有偏差。</p><h2 id="fccb" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">类型:</h2><p id="05e9" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">特征缩放分为两种。</p><ol class=""><li id="86ab" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">标准化</li><li id="ea19" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">正常化</li></ol><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/fa935c36884d8053ed2cb3af93630787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZdjFBa-GmlBRwMUTszvhUA.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx"><a class="ae lg" href="https://365datascience.com/tutorials/statistics-tutorials/standardization/" rel="noopener ugc nofollow" target="_blank">Understanding Standard Normal Distribution | 365 Data Science</a></figcaption></figure><h1 id="c733" class="lh jd hh bd je li lj lk ji ll lm ln jm lo lp lq jp lr ls lt js lu lv lw jv lx bi translated"><strong class="ak">标准化:</strong></h1><p id="1c4e" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">当数据遵循正态分布时，这很有用。从几何角度来看，它将数据转换(移位)为原始数据的平均值到原点(<em class="ly"> μ </em> =o)，并将这些点分别压缩或扩展到单位标准偏差(σ=1)，而不会影响分布的形状。</p><blockquote class="lz ma mb"><p id="2e28" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated">当数据采用不同的比例/单位或范围差异较大，并且不受异常值的影响时，可使用该方法，因为没有预定义的变换要素范围。</p></blockquote><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mf"><img src="../Images/030797e880d7dfe994605fb823c57321.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*8PlLKKEjvyEpuAcRUoLRmA.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Standardization Formula</strong></figcaption></figure><blockquote class="lz ma mb"><p id="77c6" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated"><em class="hh">也就是说，通过标准化这些值，我们得到了以下关于数据分布的统计数据:</em></p><p id="359f" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated"><em class="hh">均值= 0(均值居中)</em></p><p id="1888" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated"><em class="hh">标准偏差= 1(比例值可以是+ve和-ve) </em></p></blockquote><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mg"><img src="../Images/bd0d535274bc6dae2fab9c7a7780110a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*-ImD9ih0khsakaCc3G6wlQ.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><a class="ae lg" href="https://stackoverflow.com/questions/50007810/principle-component-analysis" rel="noopener ugc nofollow" target="_blank"><strong class="bd je">Before and After standardization - Geometric Intuition</strong></a></figcaption></figure><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mh"><img src="../Images/c3e38c811ba90710dbf68785200ab0e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*qwvuoqlgGvfWWyTr1wBlFA.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Before and After standardization- KDE Plot</strong></figcaption></figure><h2 id="7818" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">代码直觉:</h2><pre class="kr ks kt ku fd mi mj mk ml aw mm bi"><span id="1f88" class="jc jd hh mj b fi mn mo l mp mq"><em class="ly">#from sklearn module we are importing standard scalar</em><strong class="mj hi"><br/>from sklearn.preprocessing import StandardScaler</strong></span><span id="ee9b" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#creating a standard scalar object as scalar<br/></em><strong class="mj hi">scaler=StandardScaler()</strong></span><span id="d87e" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#fit the data into scaler it will learn parameters<br/></em><strong class="mj hi">scaler.fit(x_train)</strong></span><span id="fd70" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#transform train and test split into requirement for standardization<br/></em><strong class="mj hi">x_train_scaled=scaler.transform(x_train)<br/>x_test_scaled=scaler.transform(x_test)</strong></span></pre><h2 id="d00e" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">何时使用标准化:</h2><p id="01ab" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">缩放时，某些算法中模型的精确度会提高。</p><ol class=""><li id="dc3a" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated"><em class="ly">梯度下降:θ</em>计算会变得更快，随机梯度下降中的学习速率对每个参数都是一样的。</li><li id="401b" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">人工神经网络:应用梯度下降。</em></li><li id="1a8c" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">前K近邻:测量样本对之间的距离，它们的距离受测量单位的影响。</em></li><li id="8619" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">在K-均值聚类之前:</em>由于欧几里德距离测量</li><li id="8253" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">在SVM之前:</em>由于欧几里得距离的测量。</li><li id="6133" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">套索和岭回归</em>:它将每个变量的系数大小限制在w.r.t .的量级上，不会有截距。</li><li id="5cc8" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">主成分分析(PCA)前:</em>尽量得到方差最大的特征。</li><li id="b528" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated"><em class="ly">变量重要性度量之前</em>:具体在回归模型中。</li></ol><h2 id="bdf6" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">当没有必要应用时:</h2><ol class=""><li id="4989" class="kc kd hh ig b ih jx il jy ip ms it mt ix mu jb kh ki kj kk bi translated">决策树，XG-Boost，梯度提升:对准确率没有影响。</li><li id="8d3f" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">随机森林、装袋技术(基于树的算法对特征的比例相当不敏感)。</li></ol><h1 id="c7e6" class="lh jd hh bd je li lj lk ji ll lm ln jm lo lp lq jp lr ls lt js lu lv lw jv lx bi translated"><strong class="ak">正常化</strong>:</h1><p id="4142" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">这是在ML中的数据准备期间经常应用的技术。目标是更改数值列的值以使用通用的刻度，而不会扭曲不同范围的值或丢失信息。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mv"><img src="../Images/67efd1d137610cd1d096a1dce6b8f7b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*gFdTEuFC1dD_vanH3FZa4Q.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><a class="ae lg" href="https://stackoverflow.com/questions/50007810/principle-component-analysis" rel="noopener ugc nofollow" target="_blank"><strong class="bd je">Before and After normalization - Geometric Intuition</strong></a></figcaption></figure><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es mw"><img src="../Images/77e5a5b7b448b64e50e10e1594619537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*imMCayu5S1GiBfA3wS2hUA.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Before and After normalization- KDE Plot</strong></figcaption></figure><ol class=""><li id="4d5f" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">最小最大标量</li><li id="5f7c" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">均值归一化</li><li id="0e53" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">最大绝对值</li><li id="e8f6" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">鲁棒标量</li></ol><p id="7e74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。最小最大标量:</strong>该估计器单独缩放和翻译每个特征，使得它在训练集的给定范围内，例如，在零和一之间。它可以作为标准标量的替代品。</p><blockquote class="lz ma mb"><p id="4acc" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated">异常值也被压缩到0到1的范围内，所以影响也是存在的。</p></blockquote><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mx"><img src="../Images/3e45a082eb5ae62ed1cffdce19433492.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*i_VXuFH7WvfRbi8RNEkq2g.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Min-max scalar Formula</strong></figcaption></figure><h2 id="5eac" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">代码直觉:</h2><pre class="kr ks kt ku fd mi mj mk ml aw mm bi"><span id="53f5" class="jc jd hh mj b fi mn mo l mp mq"><em class="ly">#from sklearn module we are importing minmax-scalar</em><br/><strong class="mj hi">from sklearn.preprocessing import MinMaxScaler</strong></span><span id="dc3f" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#creating a minmax-scalar object as scalar<br/></em><strong class="mj hi">scaler=MinMaxScaler()</strong></span><span id="95ba" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#fit the data into scaler it will learn parameters</em><br/><strong class="mj hi">scaler.fit(x_train)</strong></span><span id="585f" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#transform train and test split into requirement for standardization</em><br/><strong class="mj hi">x_train_scaled=scaler.transform(x_train)<br/>x_test_scaled=scaler.transform(x_test)</strong></span></pre><p id="b563" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。</strong> <strong class="ig hi">均值归一化:</strong>当我们需要在0和1之间缩放每个特征，并且需要居中的数据(均值居中)时，我们使用均值归一化。scikit-learn中没有代码；我们需要硬编码，所以通常我们使用标准标量。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es my"><img src="../Images/808ff49e2d4b8a5d3e1b112fcafb41c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*08WupT21ZDvwEv8EEcWRJQ.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Mean normalization scalar Formula</strong></figcaption></figure><p id="960e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。最大绝对值:</strong>根据绝对最大值缩放每个特征。该估计器单独缩放和转换每个特征，使得训练集中每个特征的最大绝对值为1。</p><blockquote class="lz ma mb"><p id="6ce4" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated">它不会移动/居中数据，因此不会破坏任何稀疏性。因此用于稀疏数据。</p></blockquote><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mz"><img src="../Images/a8fee69c2fb9e2834ffbb7a397cedb27.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*AyJJGVisVwtOk0RP0kcKlA.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Max absolute scalar Formula</strong></figcaption></figure><h2 id="d508" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">代码直觉:</h2><pre class="kr ks kt ku fd mi mj mk ml aw mm bi"><span id="0cd7" class="jc jd hh mj b fi mn mo l mp mq"><em class="ly">#from sklearn module we are importing </em>MaxAbsoluteScaler<br/><strong class="mj hi">from sklearn.preprocessing import MaxAbsScaler</strong></span><span id="7136" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#creating a </em>MaxAbsoluteScaler <em class="ly">object as scalar<br/></em><strong class="mj hi">scaler=MaxAbsScaler()</strong></span><span id="536c" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#fit the data into scaler it will learn parameters</em><br/><strong class="mj hi">scaler.fit(x_train)</strong></span><span id="bfdd" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#transform train and test split into requirement for standardization</em><br/><strong class="mj hi">x_train_scaled=scaler.transform(x_train)<br/>x_test_scaled=scaler.transform(x_test)</strong></span></pre><p id="530c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.<strong class="ig hi">稳健标量:</strong>此标量移除中值，并根据分位数范围(默认为IQR:四分位数范围)缩放数据。<a class="ae lg" rel="noopener" href="/@mahendragundeti/five-point-summary-boxplot-explained-a3629e3712f7"> IQR是第一个四分位数(第25个四分位数)和第三个四分位数(第75个四分位数)之间的范围。</a></p><blockquote class="lz ma mb"><p id="f21a" class="ie if ly ig b ih ii ij ik il im in io mc iq ir is md iu iv iw me iy iz ja jb ha bi translated">由于使用了中值和单位方差的标度，它对异常值是稳健的。</p></blockquote><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es na"><img src="../Images/4a2a4831616f060982dd1359924351ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*Wmgod4L1EpL0Jng6KiLrqQ.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx"><strong class="bd je">Robust scalar Formula</strong></figcaption></figure><h2 id="845f" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">代码直觉:</h2><pre class="kr ks kt ku fd mi mj mk ml aw mm bi"><span id="9fd7" class="jc jd hh mj b fi mn mo l mp mq"><em class="ly">#from sklearn module we are importing </em>RobustScaler<br/><strong class="mj hi">from sklearn.preprocessing import RobustScaler</strong></span><span id="18d0" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#creating a </em>RobustScaler <em class="ly">object as scalar<br/></em><strong class="mj hi">scaler=RobustScaler()</strong></span><span id="ec20" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#fit the data into scaler it will learn parameters</em><br/><strong class="mj hi">scaler.fit(x_train)</strong></span><span id="6439" class="jc jd hh mj b fi mr mo l mp mq"><em class="ly">#transform train and test split into requirement for standardization</em><br/><strong class="mj hi">x_train_scaled=scaler.transform(x_train)<br/>x_test_scaled=scaler.transform(x_test)</strong></span></pre><h2 id="2546" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">结论:</h2><ul class=""><li id="05d3" class="kc kd hh ig b ih jx il jy ip ms it mt ix mu jb nb ki kj kk bi translated">了解数据并查看是否需要进行要素缩放。</li><li id="c056" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb nb ki kj kk bi translated">当您知道数据的分布不符合高斯分布时，可以使用归一化。标准化，反之亦然。</li><li id="8b9a" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb nb ki kj kk bi translated">然而，这并不一定是真的。此外，与标准化不同，标准化没有边界范围。因此，即使您的数据中有异常值，它们也不会受到标准化的影响。</li><li id="ec53" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb nb ki kj kk bi translated">如果异常值使用稳健标量，如果稀疏数据使用最大绝对标量，如果我们知道数据的最小值和最大值，则使用最小最大标量</li><li id="60a9" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb nb ki kj kk bi translated">总是从将模型与原始的、规范化的和标准化的数据进行拟合开始，并比较性能以获得最佳结果。</li><li id="133c" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb nb ki kj kk bi translated">让定标器适合训练数据，然后用它来转换测试数据，这是一个很好的做法。这将避免模型测试过程中的任何数据泄漏。此外，通常不需要目标值的缩放。</li></ul><p id="2612" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢阅读！</p><p id="807c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关注我了解更多关于DS和ML的内容。</p><div class="nc nd ez fb ne nf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hi fi z dy nk ea eb nl ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt la nf"/></div></div></a></div></div></div>    
</body>
</html>
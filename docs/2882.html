<html>
<head>
<title>Text Data Preprocessing for NLP Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理模型的文本数据预处理</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/text-data-preprocessing-for-nlp-model-4c030a7ab476?source=collection_archive---------1-----------------------#2022-06-22">https://medium.com/mlearning-ai/text-data-preprocessing-for-nlp-model-4c030a7ab476?source=collection_archive---------1-----------------------#2022-06-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/baa683a49218ee2a507aa16407283683.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5hj0Qin_6RTEN1Iy-CzHtA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Floor cleaning photo created by rawpixel.com — <a class="ae it" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank">www.freepik.com</a></figcaption></figure><h1 id="ee7b" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">❓为什么文本数据预处理很重要？</h1><p id="b7c0" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi kq translated"><span class="l kr ks kt bm ku kv kw kx ky di"> T </span>自然语言处理(NLP)的目标是让计算机像人类一样理解文本和口语。</p><p id="35ac" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">自然语言处理将统计、机器学习和深度学习模型应用于大量文本数据，以理解说话者或作者的意图和情感。</p><p id="eab6" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">输入数据会极大地影响自然语言处理模型的性能。在将文本数据馈送到模型之前，从文本数据中去除噪声至关重要，以减少不必要的计算并提供干净的数据。</p><h1 id="a0af" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">📖本文内容</h1><ul class=""><li id="6350" class="le lf hh ju b jv jw jz ka kd lg kh lh kl li kp lj lk ll lm bi translated">删除重音字符</li><li id="ec2a" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">扩张收缩</li><li id="9c33" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除URL和HTML链接</li><li id="bd83" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除号码</li><li id="4b46" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除停止词</li><li id="110b" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除提及</li><li id="3a47" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除标签</li><li id="ebfc" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除标点符号</li><li id="41a3" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">词干和引理化</li><li id="43f4" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">更改为小写</li><li id="a3e6" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">删除剩余的空白</li></ul><h1 id="b81d" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">📥要求</h1><ul class=""><li id="6903" class="le lf hh ju b jv jw jz ka kd lg kh lh kl li kp lj lk ll lm bi translated">安装Python</li></ul><p id="e553" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated"><strong class="ju hi">需求库</strong></p><p id="cba5" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">请确保安装了这些库。<br/>您可以通过命令行或Anaconda提示符，键入以下命令来安装库。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="febb" class="mb iv hh lx b fi mc md l me mf">pip install &lt;library_name&gt;</span></pre><ul class=""><li id="190c" class="le lf hh ju b jv kz jz la kd mg kh mh kl mi kp lj lk ll lm bi translated">熊猫</li><li id="0267" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated"><a class="ae it" href="https://docs.python.org/3/library/unicodedata.html" rel="noopener ugc nofollow" target="_blank">unicode数据</a>:用于删除重音字符的步骤</li><li id="b023" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated"><a class="ae it" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank"> re </a>:移除提及和移除标签步骤的正则表达式</li><li id="602c" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated">收缩:对于扩张收缩步骤</li><li id="b4b9" class="le lf hh ju b jv ln jz lo kd lp kh lq kl lr kp lj lk ll lm bi translated"><a class="ae it" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> nltk </a>:著名的NLP库</li></ul><h1 id="9262" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">💽资料组</h1><p id="e86d" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">本文中使用的数据来自</p><div class="mj mk ez fb ml mm"><a href="https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification/download" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab dw"><div class="mo ab mp cl cj mq"><h2 class="bd hi fi z dy mr ea eb ms ed ef hg bi translated">卡格尔:您的数据科学之家</h2><div class="mt l"><h3 class="bd b fi z dy mr ea eb ms ed ef dx translated">Kaggle是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现数据…</h3></div><div class="mu l"><p class="bd b fp z dy mr ea eb ms ed ef dx translated">www.kaggle.com</p></div></div></div></a></div><p id="9d65" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">这些数据是在疫情节期间从推特上收集的，将情绪分为非常积极、积极、中立、消极和非常消极。</p><p id="bdc4" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">此数据集包含41157行和5列。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/44df87f5dc83b6a21176bd19a61f5f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WTt3uf9H-3NVLO1g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">data sample</figcaption></figure><p id="58e1" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">您可以使用熊猫加载此数据。read_csv</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="96c9" class="mb iv hh lx b fi mc md l me mf">import pandas as pd</span><span id="3d9a" class="mb iv hh lx b fi mw md l me mf">file location = "C:/Corona_NLP_train.csv"<br/>train =pd.read_csv(file_location, encoding = "ISO-8859-1")</span></pre><p id="9c35" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">在本文中，我将只关注“原始weet”列，即文本数据。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="ff14" class="mb iv hh lx b fi mc md l me mf">train['text'] = train['OriginalTweet'].astype(str)<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="ed2f" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">这是我们的文本数据中的4个样本(***用于分隔样本)。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mx"><img src="../Images/0e3265edb126bc584793c3f3d4c66268.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QvVD3DYqxIDL7_PJbRXj0w.png"/></div></div></figure><p id="5bb5" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我们的数据很脏。让我们看看如何清洁它！</p></div><div class="ab cl my mz go na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="ha hb hc hd he"><h1 id="8548" class="iu iv hh bd iw ix nf iz ja jb ng jd je jf nh jh ji jj ni jl jm jn nj jp jq jr bi translated">删除重音字符</h1><blockquote class="nk nl nm"><p id="067a" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">将<strong class="ju hi"> é </strong>转换为<strong class="ju hi"> e </strong></p></blockquote><p id="a5af" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">发音符号，通常松散地称为“口音”，是各种各样的小点和曲线，在许多语言中，写在字母表的某些字母的上面、下面或上面，以表示它们的发音。</p><p id="ffba" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">通常，重音符号对单词的意思没有影响。如果我们不删除这些发音符号，模型会将有或没有重音符号的单词视为不同的单词，而它是同一个单词。</p><p id="d6ae" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我使用unicodedata.normalize来处理带有重音字符的文本数据。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="8f22" class="mb iv hh lx b fi mc md l me mf">import unicodedata</span><span id="91ad" class="mb iv hh lx b fi mw md l me mf">def remove_accent(text):<br/>    try:<br/>        text = unicode(text, 'utf-8')<br/>    except NameError:<br/>        pass<br/>    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode("utf-8")<br/>    return str(text)</span><span id="8633" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x: remove_accent(x))</span></pre><h1 id="84cc" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">扩张收缩</h1><blockquote class="nk nl nm"><p id="57ab" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">将<strong class="ju hi">非</strong>转换为<strong class="ju hi">非</strong></p></blockquote><p id="5eb7" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">缩写是像are not或don't这样的单词的缩写形式。它会误导计算机的理解。该模型将把一个缩略词和一个扩展词视为两个独立的词。如果我们去掉标点符号，去掉撇号，情况会更糟。</p><p id="ee5c" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">在这一步，我使用了收缩库，它有一个收缩和展开的收缩字典。</p><p id="b7d2" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">这是缩略词典。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="1761" class="mb iv hh lx b fi mc md l me mf">import contractions</span><span id="c180" class="mb iv hh lx b fi mw md l me mf">contractions.contractions_dict</span></pre><figure class="ls lt lu lv fd ii er es paragraph-image"><div class="er es nr"><img src="../Images/8f8d0d9c5e776906797728dc9a058ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*Grd6StFMwuTa8hKu-SO67A.png"/></div></figure><p id="078a" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">使用contractions.fix扩展收缩。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="2551" class="mb iv hh lx b fi mc md l me mf">train['text']=train['text'].apply(lambda x: contractions.fix(x))</span><span id="a746" class="mb iv hh lx b fi mw md l me mf">contractions.contractions_dict</span></pre><h1 id="52d9" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">删除URL和HTML链接</h1><p id="aa66" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">URL和HTML通常与句子的意思无关，所以被认为是噪音。</p><p id="3b73" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">首先，我使用re库来执行一个正则表达式。</p><blockquote class="nk nl nm"><p id="ebde" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">在处理正则表达式的时候，我会写<strong class="ju hi"> 2个函数</strong> : 1个函数用来检查数据集中是否存在指定的模式，另一个函数用来执行一个动作。</p></blockquote><p id="7110" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">在下面的代码中，check_urls函数用于查找所有匹配模式的文本(以http://或www。).remove_urls函数将删除所有匹配该模式的文本。</p><p id="8a30" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">将显示check_urls和remove_urls函数的示例结果(***用于分隔tweets)。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="8af0" class="mb iv hh lx b fi mc md l me mf">import re</span><span id="6d0b" class="mb iv hh lx b fi mw md l me mf">def check_urls(text):<br/>    return re.findall(r'https?://\S+|www\.\S+',text)</span><span id="3081" class="mb iv hh lx b fi mw md l me mf">def remove_urls(text):<br/>    url_remove = re.compile(r'https?://\S+|www\.\S+')<br/>    return re.sub(r'https?://\S+|www\.\S+','',text)</span><span id="6a98" class="mb iv hh lx b fi mw md l me mf">train['check']=train['text'].apply(lambda x:check_urls(x))<br/>print("-----check-----")<br/>[print(x) for x in train['check'][:4]]</span><span id="ff9f" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_urls(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="a60b" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ns"><img src="../Images/8f5ec7f94058831f653e56d96f574a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6OIfdaOb_Ipq0r6vnU-CzQ.png"/></div></div></figure><h1 id="58cd" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">删除号码</h1><p id="8c4f" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">如果你认为文本中的数字没有重要意义，你可以删除它们。</p><p id="e916" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我用与上一步相同的步骤再次使用re。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="7946" class="mb iv hh lx b fi mc md l me mf">def check_num(text):<br/>    return re.findall(r'\d+',text)</span><span id="6599" class="mb iv hh lx b fi mw md l me mf">def remove_num(text):<br/>    return re.sub(r'\d+','',text)</span><span id="5119" class="mb iv hh lx b fi mw md l me mf">train['check']=train['text'].apply(lambda x:check_num(x))<br/>print("-----check-----")<br/>[print(x) for x in train['check'][:4]]</span><span id="bb30" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_num(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="c7af" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nt"><img src="../Images/0fdfc716d31d86fa6c3677589e1d21b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gwZewKlwFHafKJVQwECXQ.png"/></div></div></figure><h1 id="79e5" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">删除停用词</h1><blockquote class="nk nl nm"><p id="537f" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">去掉常用词如<strong class="ju hi"> a、</strong></p></blockquote><p id="6d35" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">停用词是任何语言中的一组常用词。停用词(不重要的词)被删除，以使模型能够专注于重要的词。</p><p id="ccd0" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">幸运的是，我们在nltk库中已经有了一个停用词列表。</p><p id="a7a3" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">停用词列表如下所示。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="22ab" class="mb iv hh lx b fi mc md l me mf">from nltk.corpus import stopwords</span><span id="08f1" class="mb iv hh lx b fi mw md l me mf">", ".join(stopwords.words('english'))<br/>STOPWORDS = set(stopwords.words('english'))<br/>STOPWORDS</span></pre><figure class="ls lt lu lv fd ii er es paragraph-image"><div class="er es nu"><img src="../Images/f6abc9b26f0ac36a36ad5d33d84993ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:220/format:webp/1*fAAtnPDoOB1uhsVSet9lrA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Stopword samples</figcaption></figure><p id="3b1e" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">remove_stopwords函数将返回文本数据中不在非索引词列表中的单词列表。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="e6fb" class="mb iv hh lx b fi mc md l me mf">def remove_stopwords(text):<br/>    """custom function to remove the stopwords"""<br/>    return " ".join([word for word in str(text).split() if word not in STOPWORDS])</span><span id="c35c" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_stopwords(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="09a8" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nv"><img src="../Images/fa16d1024bfe711b0e48beda906c7ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ibwW_ytKs1hroWcuybLyeQ.png"/></div></div></figure><h1 id="1487" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">删除提及</h1><blockquote class="nk nl nm"><p id="8cfb" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">删除社交媒体文本中的提及(<strong class="ju hi"> @ </strong>)。</p></blockquote><p id="2b64" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">来自Twitter或脸书等社交媒体的文本数据可能包含对其他账户的提及。大部分提及与文本意义无关，我们可以去掉。</p><p id="7d9f" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我使用re查找以@开头的单词，并使用与删除URL和HTML链接步骤相同的过程。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="677a" class="mb iv hh lx b fi mc md l me mf">def check_mention(x):<br/>    return re.findall(r'@\w+',x)</span><span id="bd89" class="mb iv hh lx b fi mw md l me mf">def remove_mention(x):<br/>    return re.sub(r'@\w+','',x)</span><span id="7def" class="mb iv hh lx b fi mw md l me mf">train['check']=train['text'].apply(lambda x:check_mention(x))<br/>print("-----check-----")<br/>[print(x) for x in train['check'][:4]]</span><span id="135c" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_mention(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="65f8" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nw"><img src="../Images/c1a6cc94aa68c4e73e71e687df267274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wXLWoz4gkrzP9lryWQbUOg.png"/></div></div></figure><h1 id="e1d6" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">移除标签</h1><blockquote class="nk nl nm"><p id="7387" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">删除社交媒体文本中的标签(<strong class="ju hi"> # </strong>)。</p></blockquote><p id="6c3c" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">来自Twitter或脸书等社交媒体的文本数据可能包含标签，以表明他们正在谈论的话题。大多数标签与文本意义无关，所以我们可以删除它们。</p><p id="5603" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我使用re查找以#开头的单词，并使用与删除URL和HTML链接步骤相同的过程。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="4e19" class="mb iv hh lx b fi mc md l me mf">def check_hash(text):<br/>    return re.findall(r'#\w+',text)</span><span id="5006" class="mb iv hh lx b fi mw md l me mf">def remove_hash(text):<br/>    return re.sub(r'#\w+','',text)</span><span id="cb94" class="mb iv hh lx b fi mw md l me mf">train['check']=train['text'].apply(lambda x:check_hash(x))<br/>print("-----check-----")<br/>[print(x) for x in train['check'][:4]]</span><span id="8324" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_hash(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="1ab8" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mx"><img src="../Images/c024b5633cb9cd2f2f29512743a640a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZTGjHQqCMqqihyr9NRjjw.png"/></div></div></figure><h1 id="c372" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">删除标点符号</h1><blockquote class="nk nl nm"><p id="7e69" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">拆下<strong class="ju hi">。；</strong></p><p id="9d0d" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">T <!-- -->该步骤必须在展开缩写、移除提及和移除标签步骤之后执行。</p></blockquote><p id="f21a" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">标点符号是书写中用来分隔句子及其成分并阐明意思的符号，如句号、逗号和括号。</p><p id="10ed" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">标点符号对于人类理解内容可能是至关重要的，但是对于机器来说，当标点符号存在时，很难对文本数据进行统计。</p><p id="50d7" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我使用re来查找标点符号，并使用与删除URL和HTML链接步骤相同的过程。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="a390" class="mb iv hh lx b fi mc md l me mf">def check_punct(text):<br/>    return re.findall(r'[^\w\s\d]',text)</span><span id="57a4" class="mb iv hh lx b fi mw md l me mf">def remove_punct(text):<br/>    return re.sub(r"[^\w\s\d]","", text)</span><span id="7ce2" class="mb iv hh lx b fi mw md l me mf">train['check']=train['text'].apply(lambda x:check_punct(x))<br/>print("-----check-----")<br/>[print(x) for x in train['check'][:4]]</span><span id="d760" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_punct(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="fc05" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果呢</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nx"><img src="../Images/8c569a0dd9fd0b2ad82c1a7c8d7e5273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LKzp1AFzTi_EZqmpsV0qVg.png"/></div></div></figure><h1 id="a2d3" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">词干化和词汇化</h1><blockquote class="nk nl nm"><p id="3d5a" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">将<strong class="ju hi">运行</strong>改为<strong class="ju hi">运行。</strong></p></blockquote><p id="07c1" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">词干化和词汇化的目的是一样的，都是将单词简化为它的词根，例如run，run是从与run相同的单词派生出来的。</p><p id="1ce7" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">这两者的区别在于，<br/> <strong class="ju hi">词干</strong>只是移除或阻止一个单词的最后几个字符<strong class="ju hi"/>，经常导致不正确的意思和拼写。<br/> <strong class="ju hi">引理化</strong>考虑<strong class="ju hi">上下文</strong>并将单词转换为其有意义的基本形式，这称为引理。</p><p id="5898" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">词汇化的计算代价很高，所以如果你有一个很大的数据集，并且性能是一个问题，那么就使用词干。</p><p id="3f20" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">由于我的数据集并不大，我就实现了引理化。</p><p id="af52" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">nltk库提供了一个单词分类器。我会把一个句子拆分成单词，每个单词在再次连接到句子之前都会被词条化。(您可以调整这段代码来实现词干。)</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="c012" class="mb iv hh lx b fi mc md l me mf">from nltk.stem import WordNetLemmatizer</span><span id="b188" class="mb iv hh lx b fi mw md l me mf"># nltk.download('wordnet')<br/>wordnet_lemmatizer = WordNetLemmatizer()<br/>def lemmatizer(text):<br/>    lemm_text = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in text.split()])<br/>    return lemm_text</span><span id="d532" class="mb iv hh lx b fi mw md l me mf">train['temp'] = train['text'].apply(lambda x:lemmatizer(x))<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="d6f3" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">引理化后的结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nx"><img src="../Images/5996b91ce6168ae3fa7cba42ed4ba5cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8faRjG7zSsZscLOsDhU25Q.png"/></div></div></figure><h1 id="20c5" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">改为小写</h1><blockquote class="nk nl nm"><p id="af97" class="js jt nn ju b jv kz jx jy jz la kb kc no lb kf kg np lc kj kk nq ld kn ko kp ha bi translated">将A更改为A</p></blockquote><p id="63af" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">使用lower函数更改为小写。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="d368" class="mb iv hh lx b fi mc md l me mf">train['text']=train['text'].apply(lambda x: x.lower())<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="db8b" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ny"><img src="../Images/1298ed84732b26a991c656421e7834eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-0G3TYOqi95Zat3bt3yHyg.png"/></div></div></figure><h1 id="d88b" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">删除多余的空白</h1><p id="fca2" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在我们执行前面的数据准备步骤后，单词之间可能会留下空白。</p><p id="1f0a" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">我用re来解决这个问题。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="bb4d" class="mb iv hh lx b fi mc md l me mf">def remove_space(text):<br/>    return re.sub(r"\s+"," ",text).strip()</span><span id="fc4e" class="mb iv hh lx b fi mw md l me mf">train['text']=train['text'].apply(lambda x:remove_space(x))<br/>print("\n-----result-----")<br/>[print("*** "+x) for x in train['text'][:4]]</span></pre><p id="7c2e" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">结果呢</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nz"><img src="../Images/4725c87d0c165656d004cde80978a1b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftBvXZaUtcItEzx9LVs0Pg.png"/></div></div></figure></div><div class="ab cl my mz go na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="ha hb hc hd he"><p id="2110" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">请注意，没有必要完成所有步骤。每个预处理步骤都可能导致信息丢失。例如，标签可以告诉演讲者/作者的情绪，或者大写的单词可以是兴奋的标志。因此，了解您的问题和背景以找到最佳的数据预处理方法非常重要。</p><h1 id="1866" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结论</h1><p id="8e6a" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">数据预处理对于自然语言处理模型的训练非常重要。在本文中，您将学习基本的文本数据预处理，包括扩展缩写、删除重音字符/数字/停用词/URL和HTML链接/提及/标签/标点/额外空格、词干和词汇化、更改为小写</p><p id="7431" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">数据清理完成后，在数据为模型训练做好准备之前，下一步是标记化。我将在下一篇文章中讨论这个问题。</p><p id="1d9a" class="pw-post-body-paragraph js jt hh ju b jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl ld kn ko kp ha bi translated">如果您觉得这篇文章有帮助，请关注我以获得更多关于数据科学的文章。</p><div class="mj mk ez fb ml mm"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mn ab dw"><div class="mo ab mp cl cj mq"><h2 class="bd hi fi z dy mr ea eb ms ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mt l"><h3 class="bd b fi z dy mr ea eb ms ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mu l"><p class="bd b fp z dy mr ea eb ms ed ef dx translated">medium.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of in mm"/></div></div></a></div></div></div>    
</body>
</html>
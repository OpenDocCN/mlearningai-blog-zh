<html>
<head>
<title>Azure Machine learning processing Audio Deep Learning Model — Custom</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Azure机器学习处理音频深度学习模型-自定义</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/azure-machine-learning-processing-audio-deep-learning-model-custom-dd8094469ccb?source=collection_archive---------6-----------------------#2022-09-17">https://medium.com/mlearning-ai/azure-machine-learning-processing-audio-deep-learning-model-custom-dd8094469ccb?source=collection_archive---------6-----------------------#2022-09-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="814d" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">用音频标记的数据集构建深度学习模型</h1><h1 id="7e91" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">先决条件</h1><ul class=""><li id="3c6e" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="7fa2" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure存储</li><li id="8ea7" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure机器学习</li><li id="817d" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Kaggle数据集来自—<a class="ae jz" href="https://www.kaggle.com/datasets/chrisfilo/urbansound8k" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets/chrisfilo/urbansound8k</a></li><li id="c561" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">我测试的代码来自—<a class="ae jz" href="https://www.section.io/engineering-education/machine-learning-for-audio-classification/" rel="noopener ugc nofollow" target="_blank">https://www . section . io/engineering-education/machine-learning-for-audio-class ification/</a></li><li id="b895" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">这里的想法是展示我们可以像使用Azure机器学习一样处理开源</li><li id="a4af" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">上面的kaggle已经标记了数据集</li><li id="1f35" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">如果没有数据集，我们使用Audacity之类的工具来获取音频和标签，并将标签导出为文本文件</li></ul><h1 id="b443" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">密码</h1><ul class=""><li id="e36b" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">用python 3.8和Azure ML创建笔记本</li><li id="384b" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">这已经安装了tensorflow</li><li id="1799" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">安装库</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="8a5e" class="kj if hh kf b fi kk kl l km kn">pip install librosa</span></pre><ul class=""><li id="b438" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">打印AML版本</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="3f2d" class="kj if hh kf b fi kk kl l km kn">import azureml.core<br/>print(azureml.core.VERSION)</span></pre><ul class=""><li id="c21c" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">当我写这段代码时，版本是1.43.0</li><li id="e280" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">打印tensorflow版本</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="a96a" class="kj if hh kf b fi kk kl l km kn">import tensorflow as tf<br/>print(tf.__version__)</span></pre><ul class=""><li id="34fa" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">是2.2.0</li><li id="f497" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">进口</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="dc0a" class="kj if hh kf b fi kk kl l km kn">import pandas as pd<br/>import os<br/>import librosa<br/>import librosa.display<br/>import numpy as np<br/>import IPython.display as ipd<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>import opendatasets as od</span></pre><ul class=""><li id="e818" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">下载kaggle</li><li id="bc92" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">获取用户名和令牌</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="ca4a" class="kj if hh kf b fi kk kl l km kn">od.download("https://www.kaggle.com/datasets/chrisfilo/urbansound8k/download?datasetVersionNumber=1")</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kt"><img src="../Images/e70a532885162573578e013924460ad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DSmnC4E5kZ3YdolH.jpg"/></div></div></figure><ul class=""><li id="3685" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">阅读音频文件</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="9f88" class="kj if hh kf b fi kk kl l km kn">file_name='urbansound8k/fold5/100263-2-0-121.wav'</span><span id="1b3a" class="kj if hh kf b fi lb kl l km kn">audio_data, sampling_rate = librosa.load(file_name)<br/>#librosa.display.waveplot(audio_data,sr=sampling_rate)<br/>ipd.Audio(file_name)</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lc"><img src="../Images/6f3e5b9135dd6cbe4f825abc2416e914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q61Jjz6SbzlfJCs4.jpg"/></div></div></figure><ul class=""><li id="682a" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">显示音频内容</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="6ca5" class="kj if hh kf b fi kk kl l km kn">audio_data</span><span id="274d" class="kj if hh kf b fi lb kl l km kn">audio_dataset_path='urbansound8k/'<br/>metadata=pd.read_csv('urbansound8k/UrbanSound8K.csv')<br/>metadata.head()</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es ld"><img src="../Images/c6e8362488819a576330338698ed7f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G9krle5tfXNy0KVY.jpg"/></div></div></figure><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="9fa7" class="kj if hh kf b fi kk kl l km kn">metadata['class'].value_counts()</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es le"><img src="../Images/fc03ea8ab86f41c5d83c094c4af69072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/0*ZFYwEvujwMRrQ8Dx.jpg"/></div></div></figure><ul class=""><li id="039c" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">特征抽出</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="04a6" class="kj if hh kf b fi kk kl l km kn">mfccs = librosa.feature.mfcc(y=audio_data, sr=sampling_rate, n_mfcc=40)<br/>mfccs</span></pre><ul class=""><li id="80d0" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在创建一个函数来提取更多的特征以用于深度学习</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="b312" class="kj if hh kf b fi kk kl l km kn">def features_extractor(file):<br/>    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') <br/>    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)<br/>    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)<br/>    <br/>    return mfccs_scaled_features</span></pre><ul class=""><li id="ae3d" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在，在班级中加入一些功能</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="c89b" class="kj if hh kf b fi kk kl l km kn">from tqdm import tqdm<br/>extracted_features=[]<br/>for index_num,row in tqdm(metadata.iterrows()):<br/>    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row["fold"])+'/',str(row["slice_file_name"]))<br/>    final_class_labels=row["class"]<br/>    data=features_extractor(file_name)<br/>    extracted_features.append([data,final_class_labels])</span></pre><ul class=""><li id="f5d1" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">显示特征</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="021d" class="kj if hh kf b fi kk kl l km kn">extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])<br/>extracted_features_df.head(10)</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lf"><img src="../Images/f150e6eddfa1df68bdf74fea2259f7ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KSUfHiHB89kszkZe.jpg"/></div></div></figure><ul class=""><li id="deeb" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">转换成列表供我们在深度学习算法中使用</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="294a" class="kj if hh kf b fi kk kl l km kn">X=np.array(extracted_features_df['feature'].tolist())<br/>y=np.array(extracted_features_df['class'].tolist())</span></pre><ul class=""><li id="fb52" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">编码分类特征</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="21c4" class="kj if hh kf b fi kk kl l km kn">from tensorflow.keras.utils import to_categorical<br/>from sklearn.preprocessing import LabelEncoder<br/>labelencoder=LabelEncoder()<br/>y=to_categorical(labelencoder.fit_transform(y))</span></pre><ul class=""><li id="20cc" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">用于培训和测试的拆分</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="6023" class="kj if hh kf b fi kk kl l km kn">from sklearn.model_selection import train_test_split<br/>X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)</span></pre><ul class=""><li id="6476" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在开始为神经网络创建网络</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="f2e1" class="kj if hh kf b fi kk kl l km kn">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten<br/>from tensorflow.keras.optimizers import Adam<br/>from sklearn import metrics</span><span id="71fd" class="kj if hh kf b fi lb kl l km kn">num_labels=y.shape[1]</span><span id="f501" class="kj if hh kf b fi lb kl l km kn">model=Sequential()<br/>###first layer<br/>model.add(Dense(100,input_shape=(40,)))<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.5))<br/>###second layer<br/>model.add(Dense(200))<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.5))<br/>###third layer<br/>model.add(Dense(100))<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.5))</span><span id="522f" class="kj if hh kf b fi lb kl l km kn">###final layer<br/>model.add(Dense(num_labels))<br/>model.add(Activation('softmax'))</span><span id="4597" class="kj if hh kf b fi lb kl l km kn">model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')<br/>model.summary()</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lg"><img src="../Images/58d47154809b605dec5fdb5eee3b2c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A_gsg9A10Pl5Pz_4.jpg"/></div></div></figure><ul class=""><li id="137b" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">使用fit运行模型训练</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="dad4" class="kj if hh kf b fi kk kl l km kn">from tensorflow.keras.callbacks import ModelCheckpoint<br/>from datetime import datetime </span><span id="9239" class="kj if hh kf b fi lb kl l km kn">num_epochs = 200<br/>num_batch_size = 32</span><span id="4c37" class="kj if hh kf b fi lb kl l km kn">checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', <br/>                               verbose=1, save_best_only=True)<br/>start = datetime.now()</span><span id="5b8f" class="kj if hh kf b fi lb kl l km kn">#model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)<br/>model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)<br/></span><span id="6ff5" class="kj if hh kf b fi lb kl l km kn">duration = datetime.now() - start<br/>print("Training completed in time: ", duration)</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lh"><img src="../Images/9396df434b7a5381b64d6d78a68ed4a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sbhXFj8irGBGWtSv.jpg"/></div></div></figure><ul class=""><li id="9746" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">现在计算指标</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="fd0d" class="kj if hh kf b fi kk kl l km kn">test_accuracy=model.evaluate(X_test,y_test,verbose=0)<br/>print(test_accuracy[1])</span></pre><ul class=""><li id="32b1" class="jc jd hh je b jf ko jh kp jj kq jl kr jn ks jp jq jr js jt bi translated">取一个测试样本</li><li id="9aa7" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">预测并查看输出</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="974b" class="kj if hh kf b fi kk kl l km kn">filename="urbansound8k/fold8/103076-3-0-0.wav"<br/>audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') <br/>mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)<br/>mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)</span><span id="762b" class="kj if hh kf b fi lb kl l km kn">print(mfccs_scaled_features)<br/>mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)<br/>print(mfccs_scaled_features)<br/>print(mfccs_scaled_features.shape)<br/>predicted_label=model.predict(mfccs_scaled_features)<br/>print(predicted_label)<br/>classes_x=np.argmax(predicted_label,axis=1)<br/>prediction_class = labelencoder.inverse_transform(classes_x)<br/>prediction_class</span></pre><figure class="ka kb kc kd fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es li"><img src="../Images/e20864412d0595b64ed9e84fa1cd3363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6sa5NnTJpEu8Tg10.jpg"/></div></div></figure><h1 id="6a50" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">【https://github.com】最初发表于<a class="ae jz" href="https://github.com/balakreshnan/Samples2022/blob/main/AzureML/audioml.md" rel="noopener ugc nofollow" target="_blank"><em class="lj"/></a><em class="lj">。</em></h1><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb kz ln"/></div></div></a></div></div></div>    
</body>
</html>
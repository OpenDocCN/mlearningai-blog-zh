<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/random-forest-for-classification-tasks-5e64fc5e5511?source=collection_archive---------4-----------------------#2022-06-05">https://medium.com/mlearning-ai/random-forest-for-classification-tasks-5e64fc5e5511?source=collection_archive---------4-----------------------#2022-06-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="eb97" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">集合模型(随机森林)</h2><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ie"><img src="../Images/bb2cbabf47f1bfdca1b52182d47e7dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2QQux_PiJTUGIRnifyEAg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Image Credit: Gurkikirat (One who paints beautifully)</figcaption></figure><p id="0da0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在我们以前的线性回归和逻辑回归方法中，我们使用单一模型，并使用该特定模型提高模型的准确性。然而，在集合模型的情况下，我们采用多个模型并试图得出一个结果(可以是回归结果或逻辑分类结果)。</p><p id="a332" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">随后，这些模型被汇总以提供最终结果。这非常类似于你向你的朋友寻求投票来支持你可能要做的决定。<strong class="iw jp">更多的头脑更多的想法&amp;更好的结果</strong>是这些模型背后的基本思想。</p><p id="e2ef" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在集合模型的情况下，我们通常采用单个训练数据集，并将其划分为子模型。这种方法可以通过以下方式之一(或混合)实现:</p><ul class=""><li id="ae9f" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo jv jw jx jy bi translated">将数据集划分为每个子模型的子集(水平划分)</li><li id="b9fb" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">划分训练数据集中的特征，并在有限的特征集上进行训练(垂直划分)<br/>我们一般从水平和垂直两个方向划分数据来训练集成模型。</li></ul><p id="cca8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">通过下图可以了解集合模型:</p><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ke"><img src="../Images/9df7ffa39c9a426d21fe9a30f3124d45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k0FC1q88aRxxQoBqxxwsNg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Image generated via Notability app in iPad</figcaption></figure></div><div class="ab cl kf kg go kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ha hb hc hd he"><p id="44ce" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated"><strong class="iw jp">装袋</strong>，这个术语你可能听过很多次了。这基本上就是自举和聚合的结合。自举意味着划分数据基础特征或数据点，而聚合意味着聚合来自多个模型的结果。</p><p id="be57" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在我们真正开始实现最常见的集成方法之一<strong class="iw jp">随机森林</strong>之前，我们还需要了解一些技术术语。</p><ul class=""><li id="d8a4" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo jv jw jx jy bi translated"><strong class="iw jp">引导</strong>:引导就是从替换的数据中选择样本。选择的每个样本称为一个袋，不构成袋的观察值称为袋外样本。</li><li id="18c9" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated"><strong class="iw jp">超级参数</strong>:与随机森林相关的超级参数有:</li><li id="1469" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">决策树的数量</li><li id="8094" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">要采样的记录/特征的数量</li><li id="51a9" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">深度和搜索标准(与分类树相同——基尼/熵)</li><li id="b9b7" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated"><strong class="iw jp">特征选择</strong>:与自举不同，(用替换选择特征)随机森林中的特征选择是在没有替换的情况下完成的。这意味着如果其中一个子模型已经接收到一组特定的特征，比如支票账户，那么下一个子模型将不会获得支票账户作为特征。</li><li id="7ee8" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated"><strong class="iw jp">参数</strong>:我们在这里使用了多个函数，这些函数有一些参数(强制参数)，我将介绍其中一些:</li></ul><ol class=""><li id="88a0" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo km jw jx jy bi translated">train _ test _ split获取数据帧(X和Y)以及您需要的百分比分割</li><li id="2bb5" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo km jw jx jy bi translated">RandomForestClassifier获取数据帧(训练X和训练Y)</li><li id="5127" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo km jw jx jy bi translated">RandomForestClassifier采用数据帧(测试X)来预测可与训练Y值进行比较的预测值。</li></ol><p id="695d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">还有一些我们使用的其他功能，你可以通过<em class="kn">查看它们的描述？函数名</em>来理解它们接受的参数。</p><p id="2e9f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">随机森林本质上试图创建多个决策树，并且因为特征是在没有替换的情况下选择的，所以树的结果彼此不相关(这降低了过度拟合的可能性)。</p><p id="588f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">随机森林的实现</p><p id="84b5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">我们将使用德国信用评分数据来构建我们的随机森林模型。您可以看到该模型的描述:</p><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/f8e44e3557cfa5dd15483ca9ec303c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zABTntH5n8DLrriWbWqlww.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Data Description of German Credit Data</figcaption></figure><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/e9c534d78bdcc289415bd7ee952664e9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*wngWP0WCP6GFL_ESiSQ4UQ.png"/></div></figure><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="9431" class="hf hg hh kt b fi kx ky l kz la">['checkin_acc',<br/> 'duration',<br/> 'credit_history',<br/> 'amount',<br/> 'savings_acc',<br/> 'present_emp_since',<br/> 'inst_rate',<br/> 'personal_status',<br/> 'residing_since',<br/> 'age',<br/> 'inst_plans',<br/> 'num_credits',<br/> 'job']</span></pre><p id="da6c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在我们开始实现分类器之前，让我们了解创建模型所需的参数。<em class="kn"> RandomForestClassifier </em>在<em class="kn"> sklearn.ensemble </em>库中可用，它采用以下参数:</p><ol class=""><li id="2d21" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo km jw jx jy bi translated"><strong class="iw jp"> n_estimators(整数)</strong>:森林中的树木数量(这些基本上是我们的子模型)</li><li id="a64c" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo km jw jx jy bi translated"><strong class="iw jp"> criterion (String) </strong>:衡量分割准确性的标准(Gini或熵)要了解它们，您可以在此处阅读<strong class="iw jp">(插入链接)</strong></li><li id="43f8" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo km jw jx jy bi translated"><strong class="iw jp">max _ features(Integer/Float/String)</strong>:每棵树(子模型)使用的特征数。</li></ol><ul class=""><li id="8d68" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo jv jw jx jy bi translated"><em class="kn">自动/无</em>:所有特征用于单棵树</li><li id="da21" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated"><em class="kn"> sqrt </em>:取数据中可用特征数量的平方根</li><li id="a60c" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated"><em class="kn"> float </em>:取数据中特征数量的%</li></ul><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/d98cdaea44aa9a5e0875264507bec6c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dNEFr2zv0mlo9sXDseWNJA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Output from Random Forest Generator</figcaption></figure><p id="a240" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated"><strong class="iw jp">评估模型</strong></p><p id="1fd3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">现在我们将评估<code class="du lc ld le kt b">random forest</code>模型，我们将使用随机森林分类器的<code class="du lc ld le kt b">predict_proba</code>参数来检查模型在测试预测上的准确性。</p><p id="78b6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated"><code class="du lc ld le kt b">predict_proba</code>以pair的形式给出输出，如果你注意到每行的总和是1。proba表中的每个数字分别给出了获得0和1的概率。</p><p id="3b9e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在第一行的例子中，我们可以看到得到0的概率是0.853859，1是0.146141。现在，假定0的概率大于0.5，第一条记录将被归类为0。</p><p id="2588" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">“随机森林”分类器的默认截止值为0.5。让我们看看我们的<code class="du lc ld le kt b">predict_proba</code>数据框架是什么样的。</p><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="9fbd" class="hf hg hh kt b fi kx ky l kz la">pd.DataFrame(rforest_clf.predict_proba(test_X)).head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/60f828703954161526e560c439738aba.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Mz1sfOHr3lHaw0QfepS4QA.png"/></div></figure><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/8d31e32d123d724e833c71611b4fe189.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Dv8OVfD4x02c6kjcGBhF8w.png"/></div></figure><p id="70a5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">让我们创建混淆矩阵来查看输出。我们希望在预测不良信贷方面有很高的准确性。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/899c385edcdd4eb2d3ba2e4f9d52090b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*HRjh5tNb4BGSwMpGMmoiiQ.png"/></div></figure><p id="6686" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在我们的逻辑回归模型<a class="ae lf" rel="noopener" href="/mlearning-ai/classification-using-logistic-regression-6f2927b82c63">的情况下，我们的模型预测0具有相当好的准确性，我们可以使用像<code class="du lc ld le kt b">Youlden's</code>指数等指标来进一步改进模型。我们还可以使用<code class="du lc ld le kt b">classification_report</code>查看精确度和召回率等指标。</a></p><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="ce4a" class="hf hg hh kt b fi kx ky l kz la">print(metrics.classification_report(predicted_dataframe.Actual,predicted_dataframe.Predicted_Classification))</span><span id="224c" class="hf hg hh kt b fi lg ky l kz la">precision    recall  f1-score   support<br/><br/>           0       0.76      0.88      0.82       214<br/>           1       0.51      0.30      0.38        86<br/><br/>    accuracy                           0.72       300<br/>   macro avg       0.63      0.59      0.60       300<br/>weighted avg       0.69      0.72      0.69       300</span></pre><p id="47a5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">我们可以看到在预测“良好信用”方面有一个很好的预测。然而，我们希望改进对1的预测。我们会尝试几件事:</p><ul class=""><li id="5f9e" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo jv jw jx jy bi translated">网格搜索找出正确的超参数</li><li id="49d4" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">找到正确的截止概率以增加1的正确性</li></ul><p id="66b3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">让我们看看ROC曲线，并确定哪个是正确的临界值，我们还会看看精确度和召回曲线，以了解正确的临界值。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/158a0f27f3eab303c76fb2b7337257ea.png" data-original-src="https://miro.medium.com/v2/format:webp/1*dngydE36tmS47DKPBbYAlA.png"/></div></figure><p id="d9ea" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">正如我们所知，默认截止限值为0.5，我们可以看到，在0.4左右，模型似乎具有最大增益，因此截止值应为0.4。让我们看看精确回忆图来进一步理解这一点。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/7f4c05c9bf387667576c0f16f400ceb1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1T8F_OQwBzjAAeEepLUSCA.png"/></div></figure><p id="3ce3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">从上面可以看出，适当的截止值可以取为0.4。让我们根据新的临界值0.4来改变预测值，并尝试查看分类报告。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="f6f4" class="hf hg hh kt b fi kx ky l kz la">precision    recall  f1-score   support<br/><br/>           0       0.86      0.42      0.56       214<br/>           1       0.36      0.83      0.50        86<br/><br/>    accuracy                           0.53       300<br/>   macro avg       0.61      0.62      0.53       300<br/>weighted avg       0.71      0.53      0.54       300</span></pre><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/8b76dc41ba884220cba3bf2f8fac1a33.png" data-original-src="https://miro.medium.com/v2/format:webp/1*8CHPlyphgJ3WLHT_XYZGHA.png"/></div></figure><p id="b574" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">通过使用0.4的截止值，我们提高了欺诈预测的召回率和精确度。然而，增益并不大，我们可能必须使用较低的截止值。</p><p id="183d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">一般的经验法则是，如果第二类错误的成本很高(意味着选择了不应该被选择的人)，那么截止概率应该保持较低。</p><p id="005e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">在这种情况下，如果一个客户有很高的欺诈可能性，并给予贷款可能会导致违约。因此，我们通常会保持较低的临界值，这样大多数有违约可能性的客户都应该被正确分类。</p><p id="4e4b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">请记住，这可能意味着您最终会将一些没有违约可能性的客户归类为可能违约的人。然后，业务用户可以对分类进行个案访问。企业可以采取的一些方法有:</p><ul class=""><li id="9f3e" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo jv jw jx jy bi translated">保持一个硬概率，比如0.3，任何低于这个数字的人都将被归类为良好信用</li><li id="2ce1" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">保持一个软限制，比如0.5，超过这个值就是不良信用</li><li id="0a3f" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">在软硬限制之间，商家可以更仔细地审视顾客</li></ul><p id="f40f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">这可以通过下图来理解。</p><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/f646f0fde94522cb1cd6116d7aad1564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*faaWXgtjo7OkWUDrkf9qQw.jpeg"/></div></div></figure><h2 id="408a" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">网格搜索最佳参数:</h2><p id="2fd6" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je hr lk jg jh hv ll jj jk hz lm jm jn jo ha bi translated">我们已经使用了默认值来创建我们的模型，我们可以使用gridsearch来确定最佳参数以获得更好的准确性，从而进一步改进模型。</p><p id="9745" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated"><em class="kn">注意:</em>使用超调参数，计算的默认概率仍然是0.5。我们可以进一步优化模型，改变我们的<code class="du lc ld le kt b">cut-off</code></p><p id="7d2d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">我们将优化以下参数:</p><ol class=""><li id="40c1" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo km jw jx jy bi translated">树的最大深度— 5，10，15，20，30</li><li id="23ed" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo km jw jx jy bi translated">n _估计值— 5，10，15，20，30</li><li id="4b21" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo km jw jx jy bi translated">max _ features-sqrt或0.2</li></ol><p id="8d18" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">Gridsearch对于我们家用机器上的随机森林模型来说可能有点耗时。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/1033e1d1703aed752a42f9009d7bf8a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jfd-b03a3stXPjFFGsK8qA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Gridsearch Output</figcaption></figure><p id="fd75" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated"><code class="du lc ld le kt b">print(clf.best_score_)<br/>print(clf.best_params_)</code></p><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="15c3" class="hf hg hh kt b fi kx ky l kz la">0.7747096372542235<br/>{'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 30}</span></pre><p id="40f1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">如我们所见，所选参数的最佳AUC分数为0.77，最佳参数为:</p><ul class=""><li id="9d74" class="jq jr hh iw b ix iy jb jc hr js hv jt hz ju jo jv jw jx jy bi translated">最大深度:30</li><li id="aa9a" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">最大功能:sqrt</li><li id="4e30" class="jq jr hh iw b ix jz jb ka hr kb hv kc hz kd jo jv jw jx jy bi translated">n _估计值:30</li></ul><p id="6252" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">因此，我们完成了超参数调整。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/ba8b82ce3744fdf2d986ec02f71cba59.png" data-original-src="https://miro.medium.com/v2/format:webp/1*40cYb6q5ZLbM4X1hiW9twA.png"/></div></figure><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/968d26bf3797a8bfea6ba46cc48b8bf1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*K-gpnZYgxAvkxgbn8hB7Mg.png"/></div></figure><p id="253e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">ROC曲线指向我们可能必须在0.4分开。我们将尝试绘制精度和阈值图以进一步了解。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><p id="7ba7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">精确召回率指向0.4的分裂。我们会用同样的分割线。</p><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/a29feebbc8b3c48687496c8a0c7e2827.png" data-original-src="https://miro.medium.com/v2/format:webp/1*DHDZngMfBrULU4R-iGqPsg.png"/></div></figure><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="cc7e" class="hf hg hh kt b fi kx ky l kz la">print(metrics.classification_report(predicted_dataframe.Actual, predicted_dataframe.Predicted_Classification))</span><span id="c1af" class="hf hg hh kt b fi lg ky l kz la">precision    recall  f1-score   support<br/><br/>           0       0.77      0.90      0.83       214<br/>           1       0.57      0.33      0.41        86<br/><br/>    accuracy                           0.74       300<br/>   macro avg       0.67      0.61      0.62       300<br/>weighted avg       0.71      0.74      0.71       300</span><span id="685f" class="hf hg hh kt b fi lg ky l kz la">pd.crosstab(predicted_dataframe.Actual, predicted_dataframe.Predicted_Classification, <br/>             normalize = False,margins= True)</span></pre><p id="7a9e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">我们在1分类上的准确度较低，因此我们可以通过进一步增加分类点来提高0概率。让我们用0.2试试，看看精度和召回率。</p><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/23fa93c1e051b4cd9f04c2204adc5d34.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Je6d9j0QicTP8Xr7aFqrAA.png"/></div></figure><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="6ce2" class="hf hg hh kt b fi kx ky l kz la">predicted_dataframe.Predicted_Classification = predicted_dataframe['Predicted_Probability'].map(lambda x: 1<br/>                                                                                                if x &gt; 0.2 else 0)</span><span id="23e8" class="hf hg hh kt b fi lg ky l kz la">print(metrics.classification_report(predicted_dataframe.Actual, predicted_dataframe.Predicted_Classification))</span><span id="a806" class="hf hg hh kt b fi lg ky l kz la">precision    recall  f1-score   support<br/><br/>           0       0.89      0.51      0.65       214<br/>           1       0.41      0.85      0.55        86<br/><br/>    accuracy                           0.61       300<br/>   macro avg       0.65      0.68      0.60       300<br/>weighted avg       0.75      0.61      0.62       300</span><span id="26e9" class="hf hg hh kt b fi lg ky l kz la">pd.crosstab(predicted_dataframe.Actual, predicted_dataframe.Predicted_Classification, <br/>             normalize = False,margins= True)</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/2fc30bde6772921a2b3a2a4d95ed9288.png" data-original-src="https://miro.medium.com/v2/format:webp/1*BeFrLnkTGrimrkY9kLuMdg.png"/></div></figure><pre class="if ig ih ii fd ks kt ku kv aw kw bi"><span id="e3cf" class="hf hg hh kt b fi kx ky l kz la">We can see that we have improved the accuracy of bad-credit significantly, there is some loss in terms of predicting good-credit. However, this model performs pretty well against the normal logistic regression model.</span></pre><p id="2345" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">我们可以看到，我们已经显著提高了不良信贷的准确性，但在预测良好信贷方面有所损失。但是，该模型仍优于常规逻辑回归，如下所示:</p><div class="lo lp ez fb lq lr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/classification-using-logistic-regression-6f2927b82c63"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd jp fi z dy lw ea eb lx ed ef ly bi translated">使用逻辑回归分类</h2><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">medium.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf io lr"/></div></div></a></div><h2 id="131b" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">最佳参数的选择</h2><p id="2f32" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je hr lk jg jh hv ll jj jk hz lm jm jn jo ha bi translated">模型的feature_imporance_ parameter给出了模型中每个特征的重要性。我们可以创建一个柱状图来了解哪些特性是最重要的。鉴于我们使用了标准的默认值，因此参数是根据基尼系数排序的。</p><figure class="if ig ih ii fd ij"><div class="bz dy l di"><div class="kp kq l"/></div></figure><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kr"><img src="../Images/22b5bb3175f157c46051044a561abf3c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Sbxcf8adw7v3mcEPAjASpA.png"/></div></figure><p id="bc4b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">随机森林是一个非常通用的算法，它可以被广泛用于分类或回归等任务。这个模型在处理高维数据时非常有效，随机森林也能够很好地处理异常值。</p><p id="de11" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je hr jf jg jh hv ji jj jk hz jl jm jn jo ha bi translated">我希望你喜欢读这篇文章，请提供反馈，这样我可以更好地提高我的写作。我试图每周创作2-3篇文章。如果有人想贡献并共同创作一些好文章，请联系我。</p><div class="lo lp ez fb lq lr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd jp fi z dy lw ea eb lx ed ef ly bi translated">Mlearning.ai提交建议</h2><div class="mg l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">medium.com</p></div></div><div class="ma l"><div class="mh l mc md me ma mf io lr"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Faster RCNN : Towards Real-Time Object Detection with Region Proposal Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">更快的RCNN:用区域建议网络实现实时目标检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/faster-rcnn-towards-real-time-object-detection-with-region-proposal-networks-9d2db3e23c06?source=collection_archive---------2-----------------------#2021-03-17">https://medium.com/mlearning-ai/faster-rcnn-towards-real-time-object-detection-with-region-proposal-networks-9d2db3e23c06?source=collection_archive---------2-----------------------#2021-03-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="3a81" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><h2 id="1c98" class="jc if hh bd ig jd je jf ik jg jh ji io jj jk jl is jm jn jo iw jp jq jr ja js bi translated">为什么</h2><p id="a064" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd jj ke kf kg jm kh ki kj jp kk kl km kn ha bi translated">区域建议是当前检测系统中测试时的计算瓶颈。区域建议步骤仍然消耗与检测网络一样多的运行时间。</p><h2 id="0778" class="jc if hh bd ig jd je jf ik jg jh ji io jj jk jl is jm jn jo iw jp jq jr ja js bi translated">怎么</h2><p id="2f23" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd jj ke kf kg jm kh ki kj jp kk kl km kn ha bi translated">我们引入了一个区域建议网络(RPN ),它与检测网络共享完整图像的卷积特性，从而实现几乎无成本的区域建议。RPN是一个完全卷积的网络，它同时预测每个位置的对象边界和对象性分数。RPN被端到端地训练以生成高质量的区域提议，其被快速R-CNN用于检测。</p><h1 id="596b" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">模型</h1><p id="de81" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd jj ke kf kg jm kh ki kj jp kk kl km kn ha bi translated">更快的RCNN建立在两个模块之上:</p><ol class=""><li id="c38a" class="ko kp hh jv b jw kq ka kr jj ks jm kt jp ku kn kv kw kx ky bi translated">第一个模块是提议区域的深度完全卷积网络(区域提议网络或“RPN”)。</li><li id="f0ee" class="ko kp hh jv b jw kz ka la jj lb jm lc jp ld kn kv kw kx ky bi translated">第二个模块是快速R-CNN检测器，它使用建议的区域来检测对象。</li></ol><p id="bcdb" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">这两个模块共同构成了一个单一的、统一的目标检测网络，如下图所示:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es lh"><img src="../Images/4243fdcc8fb3e9be035444d220ddf862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/0*-KDU799QKUQv_iA2"/></div></figure><h2 id="2b15" class="jc if hh bd ig jd je jf ik jg jh ji io jj jk jl is jm jn jo iw jp jq jr ja js bi translated">区域提案网络</h2><p id="4863" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd jj ke kf kg jm kh ki kj jp kk kl km kn ha bi translated">区域提议网络(RPN)将图像(任何大小)作为输入，并输出一组矩形对象提议，每个提议都有一个对象分数。这是使用CNN完成的，通过共享卷积层，CNN的计算与快速RCNN对象检测网络共享。</p><p id="f6b7" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">为了生成区域建议，我们在最后共享的卷积层的特征映射输出上滑动一个n×n窗口。该特征被提供给两个完全连接的兄弟层-盒回归层(reg)和盒分类层(cls)。</p><p id="b307" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">RPN的简化视图:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lp"><img src="../Images/def5fae0a6ea9b7543b91aea274883dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UidE_JhlXZzpYZdI"/></div></div></figure><p id="792b" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated"><strong class="jv hi">RPN中的锚</strong></p><p id="39ef" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">在每个滑动窗口位置，我们同时预测多个区域提议，其中每个位置的最大可能提议的数量被表示为k。因此reg层具有编码k个框的坐标的4k个输出，并且cls层输出2k个分数，这些分数估计每个提议的对象或非对象的概率。这k个建议相对于k个参考框被参数化，称为<em class="lu">锚</em>。</p><p id="653d" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">本文中用于快速RCNN的锚定器以滑动窗口为中心，具有3个尺度和3个纵横比。因此，每个滑动位置有9个锚。</p><p id="5d3e" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">注意:锚点是<em class="lu">平移不变量</em>。如果一个人翻译一个图像中的对象，该建议应该翻译，并且相同的功能应该能够预测在任何位置的建议</p><p id="db2a" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">锚的图像化:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lv"><img src="../Images/95ee8378ae24d0560f1b8ae89976fcea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0ioFUwQGT8pLjEwZ"/></div></div></figure><p id="ebba" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated"><strong class="jv hi">RPN的损失函数</strong></p><p id="93f3" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">对于训练rpn，我们给每个锚点分配一个二进制类标签(是否为对象)。我们给两种锚分配正标签:(I)具有最高交集-并集(IoU)的锚与基础事实框重叠，或者(ii)与任何基础事实框具有高于0.7的IoU重叠的锚。</p><p id="3139" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">如果非正锚的IoU比率对于所有地面实况框都低于0.3，则我们将负标签分配给非正锚。其他主播对RPN的训练没有贡献。</p><p id="d552" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">根据这些定义，我们最小化以下目标函数:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es lw"><img src="../Images/f407e1972c81b6a9207327a6d00b6538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*agJs6aUsK37tbj6n"/></div></figure><p id="3287" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated"><strong class="jv hi">RPN培训</strong></p><p id="f5fa" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">RPN可以通过反向传播和随机梯度下降(SGD)进行端到端的训练。每个小批量从包含许多正面和负面示例锚点的单个图像中产生。为了防止偏向负样本，我们在图像中随机采样256个锚来计算小批量的损失函数，其中采样的正锚和负锚的比率高达1:1。如果图像中的阳性样本少于128个，我们用阴性样本填充小批量。</p><p id="7d4c" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">使用高斯分布初始化新层，并且通过在ImageNet分类上预先训练模型来初始化共享卷积层。</p><h2 id="d1d5" class="jc if hh bd ig jd je jf ik jg jh ji io jj jk jl is jm jn jo iw jp jq jr ja js bi translated">4步交替训练</h2><p id="bcc6" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd jj ke kf kg jm kh ki kj jp kk kl km kn ha bi translated">本文采用4步训练算法，通过交替优化来学习共享特征。这些步骤是:</p><ol class=""><li id="eedb" class="ko kp hh jv b jw kq ka kr jj ks jm kt jp ku kn kv kw kx ky bi translated">按照上一节所述训练RPN。</li><li id="331b" class="ko kp hh jv b jw kz ka la jj lb jm lc jp ld kn kv kw kx ky bi translated">使用步骤1训练的RPN产生的建议，通过快速RCNN训练单独的检测网络。注意<em class="lu">此时，两个网络不共享任何卷积层</em></li><li id="a1b4" class="ko kp hh jv b jw kz ka la jj lb jm lc jp ld kn kv kw kx ky bi translated">使用检测器网络来初始化RPN训练，保持共享卷积层固定，仅微调RPN独占层。<em class="lu">现在两个网络共享卷积层。</em></li><li id="1db2" class="ko kp hh jv b jw kz ka la jj lb jm lc jp ld kn kv kw kx ky bi translated">最后，保持共享卷积层固定，我们微调快速R-CNN的独特层。</li></ol><h2 id="1fe4" class="jc if hh bd ig jd je jf ik jg jh ji io jj jk jl is jm jn jo iw jp jq jr ja js bi translated">结果</h2><h2 id="40e7" class="jc if hh bd ig jd je jf ik jg jh ji io jj jk jl is jm jn jo iw jp jq jr ja js bi translated"><strong class="ak">在帕斯卡VOC上</strong></h2><p id="3f4c" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd jj ke kf kg jm kh ki kj jp kk kl km kn ha bi translated">在PASCAL VOC 2007测试集(在VOC 2007 trainval上训练)上，具有与具有ZF的快速R-CNN一样的检测器，但是不同的区域提议方法，RPN方法给出比选择性搜索和edgebox更好的1.3 mAP。</p><p id="1ef9" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">当检测器为快速RCNN和VGG16时，在VOC 2007测试集上78.8%的mAP，在COCO+07+12(VOC 2007 trainval和VOC 2012 trainval的联合集)上训练。</p><p id="4bde" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated"><strong class="jv hi">关于田蜜女士</strong></p><p id="6f9a" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">与快速RCNN相比，当在COCO训练数据集上训练时，在COCO测试-dev上，更快的RCNN(在VGG-16上)将mAP@0.5提高了2.8%，mAP@[0.5，0.95]提高了2.2%。</p><p id="3e19" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">仅通过将VGG-16替换为101层残差网(ResNet-101)，更快的R-CNN系统在COCO train数据集上训练时，将mAP@0.5/mAP@[0.5，0.95]从COCO val集上的41.5%/21.2% (VGG- 16)提高到48.4%/27.2% (ResNet-101)。</p><p id="45f7" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated"><strong class="jv hi">整个物体检测系统的运行时间</strong></p><p id="b579" class="pw-post-body-paragraph jt ju hh jv b jw kq jy jz ka kr kc kd jj le kf kg jm lf ki kj jp lg kl km kn ha bi translated">使用ZF网络，速度是17帧/秒，使用VGG 16，速度是5帧/秒。</p></div></div>    
</body>
</html>
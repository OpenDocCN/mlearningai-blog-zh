<html>
<head>
<title>Convolutional Neural Networks for Image Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于图像识别的卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/convolutional-neural-networks-for-image-recognition-7148a19f981f?source=collection_archive---------3-----------------------#2022-03-11">https://medium.com/mlearning-ai/convolutional-neural-networks-for-image-recognition-7148a19f981f?source=collection_archive---------3-----------------------#2022-03-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="218b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第三课2020年DeepMind系列讲座笔记</p><p id="5f9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里展示的大部分图片来自DeepMind讲座3的 <a class="ae jd" href="https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L3%20-%20UUCLxDeepMind%20DL2020.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jc">幻灯片</em> </strong> <em class="jc">。</em>T9】</a></p><h2 id="2157" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">背景:</h2><p id="8221" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">根据我在<a class="ae jd" rel="noopener" href="/@nghihuynh_37300/neural-networks-ba6fa76eb719"> <strong class="ig hi"> <em class="jc">第二课</em> </strong> </a>的笔记，我们已经知道了什么是神经网络(<em class="jc">图1) </em>。现在，我们希望使用这些网络来检测、分析和分类图像，以实现特定任务的自动化。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ke"><img src="../Images/8e787fbee288202f37594e518b43dd53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F2ivXL3rjrlJ1PyLOHQoog.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 1</strong>: A recap of a neural network with 2 hidden layers</figcaption></figure><p id="1885" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">例如</strong>:给定下面的一棵树图像(<em class="jc">图2 </em>，我们的目标是训练我们的神经网络来识别并分类它为一棵树。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ku"><img src="../Images/c34e47af64188e6db98780159c2446fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7eIZmlZou7yEvfvy-972ew.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 2</strong>: A tree image. On the left is the original digital image, on the right is the simplified pixelated tree image</figcaption></figure><p id="65d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们知道神经网络接收一个数字向量作为输入。那么，我们如何给它输入图像呢？</p><p id="67c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单这么说吧。数字图像是像素的2D网格。每个像素记录了产生图像的光的强度<em class="jc">(图2)。</em>将这些像素表示为数字向量的一种方法是逐行展平它们(<em class="jc">图3 </em>)。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es kv"><img src="../Images/acf21b8c469995a5eb115824cc37b4dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dTDD9wYZVzzjaUgeIzJpFA.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 3</strong>: A representation of a vector of numbers from the image</figcaption></figure><p id="769c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们知道如何将图像表示为神经网络的数字向量。我们来探讨一个<strong class="ig hi"> <em class="jc">卷积神经网络</em></strong>(<strong class="ig hi"><em class="jc">CNN</em></strong>或<strong class="ig hi"> <em class="jc"> ConvNet </em> </strong>)的一些积木。</p><blockquote class="kw kx ky"><p id="f2ea" class="ie if jc ig b ih ii ij ik il im in io kz iq ir is la iu iv iw lb iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>conv net的输入和输出是张量，即宽度x高度x通道的3D对象(图4)。</p></blockquote><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lc"><img src="../Images/58f19d0c936110f0b897feea5dda29e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I21fgwTDx7aMzw8wsyE8gQ.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 4</strong>: Inputs and outputs are tensors</figcaption></figure><h2 id="916e" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated"><strong class="ak">积木:</strong></h2><p id="1136" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">构建ConvNet架构有三种主要的层类型:</p><p id="a64e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc"> 1。全连接层</em> </strong>:传统层，将输入向量的每个元素连接到该层中的每个隐藏单元(神经元)<em class="jc">(图5)。</em></p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ld"><img src="../Images/04fa0895c04fe0b68a197808c8681085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HI6TMG0HRSotNN9o7BbGig.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 5</strong>: Fully connected layer</figcaption></figure><p id="5359" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">2<em class="jc">。卷积层:</em></strong>conv net的核心构建块，完成大部分繁重的计算工作。该层应用权重共享来保持图像的拓扑结构。内核(过滤器或小窗口)滑过图像，并在每个位置产生一个输出值。然后我们对多个内核进行卷积，得到多个<em class="jc">特征图</em>或<em class="jc">通道</em> <em class="jc">(图6) </em>。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es le"><img src="../Images/aed1718a31b417405d3cefa28629b9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B7cEGy1xgxuz_bMImdHAvg.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 6</strong>: Convolutional layer</figcaption></figure><p id="660b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">卷积运算的变体(表1): </em> </strong></p><figure class="kf kg kh ki fd kj"><div class="bz dy l di"><div class="lf lg l"/></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="ak">Table 1:</strong> Convolution operations</figcaption></figure><p id="2bc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc"> 3。</em>共用层:通常插入连续Conv层之间的层。该层计算小窗口上的<em class="jc">平均值</em>或<em class="jc">最大值</em>以降低分辨率。因此，它减少了网络中的参数和计算的数量(<em class="jc">图7) </em>。</strong></p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lh"><img src="../Images/22fcd23054035bf771f69291ed0ccf28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*grcmWasadTt2N72Ies3UgQ.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 7:</strong> Pooling layer</figcaption></figure><h2 id="fd03" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated"><strong class="ak">什么是卷积神经网络？</strong></h2><p id="e6c4" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">一个<strong class="ig hi"> <em class="jc">卷积神经网络</em></strong>(<strong class="ig hi"><em class="jc">CNN</em></strong>或<strong class="ig hi"> <em class="jc"> ConvNet </em> </strong>)是一个层序列，ConvNet的每一层都通过一个可微函数将一个激活量转化为另一个激活量。ConvNets通常用于图像分类和其他计算机视觉任务。</p><p id="2b96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们堆叠这些构建模块来创建一个简单的卷积神经网络。</p><p id="dd8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们从前面的<a class="ae jd" rel="noopener" href="/@nghihuynh_37300/neural-networks-ba6fa76eb719"> <strong class="ig hi"> <em class="jc">笔记中回忆一下如何将一个神经网络表示为一个计算图。</em></strong></a><strong class="ig hi"><em class="jc"/></strong><em class="jc">(图8)。</em></p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es li"><img src="../Images/3d7d04d84e7f010d380c19a05bb7f163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u5fF8knFfCDIY_1inkfBlg.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 8</strong>: A neural network as a computational graph</figcaption></figure><p id="21c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们简化上图，使参数和损耗包含在内<em class="jc">(图9) </em>。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lj"><img src="../Images/5aad62c8378ef9c6eed00d7a239fd72a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hm6IW9YJlpNfoxoRzmVLBw.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 9</strong>: A simplified diagram: implicit parameters and loss</figcaption></figure><p id="ba02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们交替使用卷积层和池层来创建ConvNet，特别是LeNet-5-a convnet，用于手写数字识别<em class="jc">(图10) </em>。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lk"><img src="../Images/135d243c7bc8cf2c840b0ab255a17154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CebIb1kn-yGwza0Yoh_ZDQ.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 10</strong>: The architecture of LeNet-5</figcaption></figure><blockquote class="kw kx ky"><p id="b3fe" class="ie if jc ig b ih ii ij ik il im in io kz iq ir is la iu iv iw lb iy iz ja jb ha bi translated"><strong class="ig hi">注</strong>:二次抽样=合并</p></blockquote><p id="d102" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，网络总共有五层，其中三层是卷积的，最后两层是全连接的。卷积层在汇集层之间交替。输出层使用Softmax激活函数将图像分类到各自的类别中。</p><p id="a116" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们更详细地理解这个架构(<em class="jc">图11 </em>)。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es ll"><img src="../Images/2b24c1283ec76706751d1aac3fd61239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*DuNLm4R4VRqLhy8ndkWLKw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 11</strong>: LeNet-5 in detail</figcaption></figure><p id="eafb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第一层是输入层，要素地图大小为32 x 32 x 1 (32 x 32灰度图像)。</p><p id="e851" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们有第一个卷积层，由6个大小为5 x 5、步距为1的滤波器组成。这一层使用的激活函数是tanh。生成的特征地图为28 x 28 x 6。</p><p id="5af2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们有第一个平均池层，过滤器大小为2 x 2，步幅为2。这一层降低了图像的分辨率，而不影响通道的数量。生成的特征地图为14 x 14 x 6。</p><p id="9aec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来是16个滤波器的第二卷积层，滤波器大小为5 x 5，步长为1。生成的特征地图为10 x 10 x 16。该层中使用的活化也是tanh。</p><p id="f3d2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们有第二个平均池层，过滤器大小为2 x 2，步幅为2。生成的特征图缩小到5×5×16。</p><p id="ab04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最终卷积层有120个滤波器，滤波器大小为5 x 5，步长为1。再次，tanh激活函数用在这一层。输出要素地图的大小为1 x 1 x 120。</p><p id="0d41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们有了第一个有84个神经元的全连接层。我们也使用tanh作为这一层的激活函数。输出尺寸为84。</p><p id="6f02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们有最后一个完全连接的层，有10个神经元。该层使用Softmax激活函数来给出10个类别中的每一个类别中的数据点的概率。然后选择具有最高值的类。</p><p id="b5a4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是LeNet-5模型的整体架构。现在，让我们更深入地研究其他模型。</p><h2 id="1a2f" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">案例研究:</h2><p id="e464" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">让我们探索一下赢得了ImageNet大规模视觉识别挑战赛 <em class="jc">(图12) </em>的一些最先进的CNN。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lm"><img src="../Images/f32a943fdd5d8e35cf4847bf77e28f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eyvMBCywdyALqSg3ExZPsg.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 12:</strong> Top-5 classification error rate of the competition winners in the ImageNet challenge</figcaption></figure><ul class=""><li id="b841" class="ln lo hh ig b ih ii il im ip lp it lq ix lr jb ls lt lu lv bi translated"><a class="ae jd" href="https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"><em class="jc">Alex net</em></strong></a>(2012):与LeNet-5的架构类似，但更深更大，五个Conv层堆叠在一起，后面是三个完全连接的层<em class="jc">(图13) </em>。</li></ul><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lw"><img src="../Images/1f869dc632f9197e6a99f33285762b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lLseITy9AKLk-Ueg1UwabQ.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 13</strong>: The architecture of AlexNet</figcaption></figure><ul class=""><li id="580d" class="ln lo hh ig b ih ii il im ip lp it lq ix lr jb ls lt lu lv bi translated"><a class="ae jd" href="https://www.robots.ox.ac.uk/~vgg/research/very_deep/" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"><em class="jc">VGGNet</em></strong></a><strong class="ig hi"><em class="jc"/></strong>(2014):是一个很深的convnet。它在汇集之前堆叠许多卷积层。此外，它使用“相同的”卷积来避免分辨率降低。VGGNet的架构有多达19层，3 x 3个内核和2 x 2个池<em class="jc">(图14) </em>。</li></ul><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lx"><img src="../Images/7c8587e618526202ee6a24ab2a73ab5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvSs-xrZkJ6i7JqgIF46Cw.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 14:</strong> The architecture of VGGNet</figcaption></figure><ul class=""><li id="0e8a" class="ln lo hh ig b ih ii il im ip lp it lq ix lr jb ls lt lu lv bi translated"><a class="ae jd" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"><em class="jc">ResNet</em></strong></a>(2015):是残差网络，其特点是特殊的<em class="jc">跳过</em>【残差】<em class="jc">连接</em>并大量使用<a class="ae jd" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jc">批量归一化</em> </strong> </a>层。剩余连接有助于训练深层网络。ResNets是当前最先进的卷积神经网络模型，并且在实践中在大多数主干中实现。</li></ul><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ly"><img src="../Images/ace5c4e8e2dd3e9d2dc3d928b0b539fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xrl-OZqsKUXniMB-LFiQg.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 15</strong>: A residual block of ResNet</figcaption></figure><h2 id="d05f" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated"><strong class="ak">超越图像识别:</strong></h2><p id="bcce" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">除了图像识别，我们还可以使用convnets执行其他计算机视觉任务，例如:<em class="jc">(图16) </em></p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lz"><img src="../Images/69ea65b9ed786d489a011cf4c9d0eb61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xP8MudVwIva5ikQ5iZ3AIg.jpeg"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 16</strong>: Other computer vision tasks beyond image recognition</figcaption></figure><ul class=""><li id="ede0" class="ln lo hh ig b ih ii il im ip lp it lq ix lr jb ls lt lu lv bi translated"><strong class="ig hi"> <em class="jc">图像识别:</em> </strong>对图像中的一个或多个物体进行识别或分类。</li><li id="8841" class="ln lo hh ig b ih ma il mb ip mc it md ix me jb ls lt lu lv bi translated"><strong class="ig hi"> <em class="jc">对象检测:</em> </strong>对图像中的一个或多个对象进行定位和分类，为每个检测到的对象生成包围盒。</li><li id="fd19" class="ln lo hh ig b ih ma il mb ip mc it md ix me jb ls lt lu lv bi translated"><strong class="ig hi"> <em class="jc">语义分割:</em> </strong>标注图像中一个或多个特定的感兴趣区域。它将单个类别中的多个对象视为一个实体。</li><li id="e1c4" class="ln lo hh ig b ih ma il mb ip mc it md ix me jb ls lt lu lv bi translated"><strong class="ig hi"> <em class="jc">实例分割:</em> </strong>检测并描绘出图像中每个感兴趣的物体。它识别这些类别中的单个对象。</li></ul><h2 id="c759" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">下一步是什么？</h2><blockquote class="mf"><p id="2ba8" class="mg mh hh bd mi mj mk ml mm mn mo jb dx translated"><a class="ae jd" rel="noopener" href="/@nghihuynh_37300/vision-beyond-classification-task-i-object-detection-d2f32a5ea4ca">接下来是DeepMind深度学习系列第4讲的笔记:超越分类的视觉:任务一:物体检测。</a></p></blockquote><div class="mp mq mr ms mt mu"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">medium.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni ko mu"/></div></div></a></div></div></div>    
</body>
</html>
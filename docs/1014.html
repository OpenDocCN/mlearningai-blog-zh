<html>
<head>
<title>Ch 2. Iterative Data Collection for Source Domain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甲烷。源域的迭代数据收集</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/chapter-2-source-domain-data-collection-d00cb426d559?source=collection_archive---------3-----------------------#2021-09-15">https://medium.com/mlearning-ai/chapter-2-source-domain-data-collection-d00cb426d559?source=collection_archive---------3-----------------------#2021-09-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="0831" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">如何创造性地为你的ML问题设计数据</h2></div><p id="c4ea" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="js">背景:</em> </strong> <em class="js">我正在分享我在多伦多大学攻读机器学习硕士学位的计算机视觉研究项目经历。一家机场给了我x光行李扫描图像，让我开发一个自动检测危险物品的模型。给定少量的x射线图像，我使用域自适应，首先从互联网上收集大量危险物体的正常(非x射线)图像，仅使用这些正常图像训练模型，然后调整模型以在x射线图像上表现良好。</em></p><p id="7df6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我之前的<a class="ae jt" rel="noopener" href="/@lucrece.shin/chapter-1-data-inspection-and-pre-processing-for-xray-images-d95f717684b7">帖子</a>中，我分享了我对给定x射线图像的初始数据检查和预处理步骤。我已经把要探测的危险物体的种类缩小到<strong class="iy hi">枪和</strong>刀。在这篇文章中，我将分享用于领域适应的普通相机图像的数据收集过程。以下是我将讨论的主题列表:</p><ol class=""><li id="6bf5" class="ju jv hh iy b iz ja jc jd jf jw jj jx jn jy jr jz ka kb kc bi translated"><strong class="iy hi">动机</strong></li><li id="1e9a" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iy hi">源域和目标域</strong></li><li id="3c25" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iy hi">数据收集—基本框架</strong></li><li id="d4c8" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iy hi">数据设计—迭代思维</strong></li><li id="416c" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iy hi">网络图像的数量与x光图像的数量</strong></li></ol><h1 id="33e0" class="ki kj hh bd kk kl km kn ko kp kq kr ks in kt io ku iq kv ir kw it kx iu ky kz bi translated">动机</h1><p id="14cb" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">为了给这个步骤提供一个动机，让我解释一下关于<strong class="iy hi">领域适配</strong>的一些事情。<a class="ae jt" href="https://en.wikipedia.org/wiki/Domain_adaptation" rel="noopener ugc nofollow" target="_blank">维基百科</a>将其定义为能够:</p><blockquote class="lf"><p id="e986" class="lg lh hh bd li lj lk ll lm ln lo jr dx translated"><strong class="ak">将使用[源域]训练的算法应用到不同的[目标域] </strong></p></blockquote><p id="d3bc" class="pw-post-body-paragraph iw ix hh iy b iz lp ii jb jc lq il je jf lr jh ji jj ls jl jm jn lt jp jq jr ha bi translated">那么为什么不先用目标域来训练算法呢？可能有多种原因，如数据不足(如我们的情况)或标记目标域数据的高成本。正如我在<a class="ae jt" rel="noopener" href="/@lucrece.shin/chapter-1-data-inspection-and-pre-processing-for-xray-images-d95f717684b7">上一篇</a>中提到的，我们只有<strong class="iy hi"> 117张包含枪的x光图像和</strong>31张包含刀的x光图像。如此小的数量将使神经网络过拟合，该神经网络仅在用大量图像训练时表现良好。因此，我们可以转向互联网来收集大量库存照片般的枪和刀的相机图像，并使用它们来训练模型。然后，我们可以使模型适应x射线图像来很好地执行相同的工作。</p><h1 id="96dc" class="ki kj hh bd kk kl km kn ko kp kq kr ks in kt io ku iq kv ir kw it kx iu ky kz bi translated">源域和目标域</h1><p id="f75e" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">参考维基百科对域适配的定义，本项目中的<em class="js">源域</em>将指危险物体的正常相机图像，<em class="js">目标域</em>指包含相同物体的x光行李扫描图像。因此，本项目上下文中的术语<strong class="iy hi">“域”</strong>对应于图像的<strong class="iy hi">风格和纹理</strong>。借用维基百科的话，我希望:</p><blockquote class="lf"><p id="57bc" class="lg lh hh bd li lj lk ll lm ln lo jr dx translated">应用用[s<strong class="ak">stock-photo style images]</strong>到<strong class="ak">[x射线行李扫描图像]训练的自动威胁检测算法。</strong></p></blockquote><figure class="lv lw lx ly lz ma er es paragraph-image"><div class="er es lu"><img src="../Images/ae5c4c2268df0fb9a02cc439d22551c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*KJH4UsVPXIZzoiocTRxNdg.png"/></div><figcaption class="md me et er es mf mg bd b be z dx">Normal camera image (source domain) of knife vs. Xray baggage scan image (target domain) of knife.</figcaption></figure><p id="ce03" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我该怎么做？我首先需要源域和目标域的适当图像数据。对于目标领域，我已经有机场提供的x光行李扫描图像。对于源域，我必须从网上搜集公开可用的图片。对于抓取任务，有一个方便的<a class="ae jt" href="https://docs.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>库，可以让我们轻松地从谷歌图片搜索中下载图片。让我们开始吧。</p><h1 id="fe62" class="ki kj hh bd kk kl km kn ko kp kq kr ks in kt io ku iq kv ir kw it kx iu ky kz bi translated">数据收集——基本框架</h1><ol class=""><li id="b7cc" class="ju jv hh iy b iz la jc lb jf mh jj mi jn mj jr jz ka kb kc bi translated">进入<a class="ae jt" href="https://www.google.com/imghp?hl=en" rel="noopener ugc nofollow" target="_blank">谷歌图片搜索主页</a>，输入合适的搜索关键词(我用的是谷歌Chrome浏览器)。</li><li id="7691" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated">要获得最大数量的图像，请滚动到底部，单击<em class="js">显示更多结果</em>按钮，并滚动到最底部，显示<em class="js">看起来您已经到达最后</em>。</li><li id="b19b" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated">对于Mac键入<code class="du mk ml mm mn b">command + opt + j</code>或对于Windows键入<code class="du mk ml mm mn b">ctrl + shift + j</code>来打开Chrome的控制台。</li><li id="607b" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated">您可能需要禁用任何广告拦截器扩展。</li><li id="8fa2" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr jz ka kb kc bi translated">将下面几行复制粘贴到控制台，然后按<code class="du mk ml mm mn b">enter</code>。我对javascript了解不多所以无法解释这些代码，抱歉！</li></ol><pre class="mo mp mq mr fd ms mn mt mu aw mv bi"><span id="df0b" class="mw kj hh mn b fi mx my l mz na">urls = Array.from(document.querySelectorAll(‘.rg_di .rg_meta’)).map(el=&gt;JSON.parse(el.textContent).ou);<br/>window.open(‘data:text/csv;charset=utf-8,’ + escape(urls.join(‘\n’)));</span></pre><p id="ea1f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这将自动从搜索中下载一个包含低分辨率图像URL的<code class="du mk ml mm mn b">download.csv</code>文件。如果以上行不通，请尝试:</p><pre class="mo mp mq mr fd ms mn mt mu aw mv bi"><span id="458e" class="mw kj hh mn b fi mx my l mz na">var urls=Array.from(document.querySelectorAll(‘.rg_i’)).map(el=&gt; el.hasAttribute(‘data-src’)?el.getAttribute(‘data-src’):el.getAttribute(‘data-iurl’)); var hiddenElement = document.createElement(‘a’); hiddenElement.href = ‘data:text/csv;charset=utf-8,’ + encodeURI(urls.join(‘\n’)); hiddenElement.target = ‘_blank’; hiddenElement.download = ‘myFile.csv’; hiddenElement.click();</span></pre><p id="214a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">6.更改csv文件的名称以匹配搜索关键字。例如，如果您搜索“菜刀”，请将文件重命名为<code class="du mk ml mm mn b">kitchen_knife.csv</code>。</p><p id="970a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">7.使用此功能创建一个文件夹，使用csv文件将图像下载到其中，压缩文件夹，最后下载zip文件。这里我们使用的是<code class="du mk ml mm mn b">fastai.vision</code>库。</p><figure class="mo mp mq mr fd ma"><div class="bz dy l di"><div class="nb nc l"/></div></figure><p id="71c2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从现在开始，我将把刮下来的图片称为“网络图片”。请记住:</p><ul class=""><li id="9fc9" class="ju jv hh iy b iz ja jc jd jf jw jj jx jn jy jr nd ka kb kc bi translated">来源域名:<strong class="iy hi">网页图片</strong></li><li id="2312" class="ju jv hh iy b iz kd jc ke jf kf jj kg jn kh jr nd ka kb kc bi translated">目标域:<strong class="iy hi">x射线图像</strong></li></ul><h1 id="1cde" class="ki kj hh bd kk kl km kn ko kp kq kr ks in kt io ku iq kv ir kw it kx iu ky kz bi translated">数据设计——迭代思维</h1><p id="c267" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">到目前为止，该程序是数据收集的“基本框架”。你可以找到许多其他文章解释同样的事情。程序中没有包括的是如何<em class="js">有效地</em>收集图像数据，以便建立一个更健壮的机器学习算法。以下是我为了更有效而做的事情:</p><h2 id="8855" class="mw kj hh bd kk ne nf ng ko nh ni nj ks jf nk nl ku jj nm nn kw jn no np ky nq bi translated">I .使用不同的搜索关键词(迭代过程)</h2><p id="78b5" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">当我有枪和刀两个类的时候，很自然的只用关键词“枪”和“刀”来搜索相关图片。人类语言有时会简化事物，因为我们能够通过使用集体术语来相互理解(例如，单词“tree”可以指任何颜色、形状或大小的树)。但是为了展示一个婴儿机器学习模型👶对于代表单个对象的更多样的图像，重要的是要有丰富的搜索关键词池。</p><h2 id="609b" class="mw kj hh bd kk ne nf ng ko nh ni nj ks jf nk nl ku jj nm nn kw jn no np ky nq bi translated">1)不同语言的对象名称</h2><p id="95ee" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi">This is quite useful since searching an object in different languages give images from different countries’ product websites. In addition to increasing the number of images, it gives a variety of types and shapes of the object that each country offers. I used the word “knife” and “gun” in English, Korean (칼 and 총) and Japanese (包丁 and 銃). It was interesting to see that using the Japanese keyword for knife resulted in a large amount of images of a skinny, long knife with wooden handle as shown in the rightmost image below.</p><figure class="mo mp mq mr fd ma er es paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="er es nr"><img src="../Images/038485436e587837e723881527d25318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*neFwXARlH2WsYc7xbgEUGg.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Sample knife image with English, Korean, and Japanese search keywords.</figcaption></figure><h2 id="022d" class="mw kj hh bd kk ne nf ng ko nh ni nj ks jf nk nl ku jj nm nn kw jn no np ky nq bi translated">2)不同类型的对象</h2><p id="6a22" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">起初，我只使用了搜索关键字“刀”在3种不同的语言，如上所述。但是当我用web刀图像训练一个模型时(记住，为了适应领域，我们只使用web图像来训练模型，x射线图像只用于测试模型。我会在下一篇文章中详细解释训练过程。)，我看到对x光刀图像的召回率相对较低。我后来发现<strong class="iy hi">90%以上的网刀图片都有菜刀造型</strong>，如下图饼状图所示。这种形状确实是最普遍的、被广泛接受的“刀形”。</p><figure class="mo mp mq mr fd ma er es paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="er es nw"><img src="../Images/a439cd20eb2bc6a05dd19c58c93fb744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t85Q7FyGioLTaIPMwdCJIg.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Shape distribution of scraped images of knife.</figcaption></figure><p id="7928" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当我看着包含刀的x光图像时；然而，我看到不同刀形的分布更加均匀:</p><figure class="mo mp mq mr fd ma er es paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="er es nx"><img src="../Images/9cc4ed1e6895629b5e4b0b3f89505223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*phmeBunEA4_ZCO1JoJvEQg.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Shape distribution of Xray images containing knife.</figcaption></figure><p id="a770" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个分析让我意识到，收集各种类型的刀可能有助于模型检测不同形状的刀。于是我用以下搜索关键词刮出了更多图片:<em class="js">切肉刀、黄油刀、塑料刀、切肉刀、</em>和<em class="js">银刀</em>。使用额外的图像进行训练确实使模型更加健壮，提高了对x光刀图像的回忆。</p><h2 id="bdab" class="mw kj hh bd kk ne nf ng ko nh ni nj ks jf nk nl ku jj nm nn kw jn no np ky nq bi translated">3)适合您自己问题的特殊搜索关键字</h2><p id="0667" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">这一步需要更多的思考，因为它特别适用于你自己的问题。就我而言，我注意到大多数网上的刀的图片在刀刃和刀柄之间有明显的区别，用不同的颜色和深度来标记。但是如果你看看上面x光照片中的刀，它们中的许多都是单一色调的蓝色，刀身和刀柄之间没有明显的区别。所以我假设源域(web)图像和目标域(x射线)图像之间的差异可能会导致模型混淆。</p><p id="9c0f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以想了一会儿之后🤔什么样的网络图像有助于解决这个问题，我尝试使用搜索关键字<em class="js">黑刀</em>，它给我这样的图像:</p><figure class="mo mp mq mr fd ma er es paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="er es ny"><img src="../Images/1c20c1e93ac9e071ac99381e5060139f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*piu7uSmWlN5UpqkhQo52UQ.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Examples of images from search keyword “black knife”.</figcaption></figure><p id="9162" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您可以看到，与x射线图像中的刀相似，整把刀都是单一色调。此外，由于普通刀片很少是黑色的，从头到脚都是黑色的刀片可以让模特将焦点转移到刀的形状上，而不是刀的颜色或纹理上。这在手头的领域适应任务中非常重要，因为我们试图让模型在不同纹理的图像中检测相同的对象(web vs. Xray)。因此，黑刀图像成为构建健壮模型时对网络图像的有用补充。</p><p id="3a8d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">回想起来，这个产生不同搜索关键词的过程教会了我<strong class="iy hi">数据收集是一个<em class="js">迭代</em>过程</strong>。我甚至称之为<strong class="iy hi">创造性</strong> <strong class="iy hi">数据设计过程</strong>，在其中我不断地填补漏洞，以解决之前迭代的不足。我经常花一些时间离开电脑，独自思考如何创造性地解决问题，这让我学到了机器学习教科书甚至研究论文都没有告诉我的东西。这是一次真实世界研发的体验。</p><h2 id="01c7" class="mw kj hh bd kk ne nf ng ko nh ni nj ks jf nk nl ku jj nm nn kw jn no np ky nq bi translated">二。移除不具代表性的图像</h2><p id="620e" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">在为每个类下载了一堆图像后，我浏览了这些图像，删除了任何不代表类“对象”的图像。以下是我为刀枪类移除的一些图片:</p><figure class="mo mp mq mr fd ma er es paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="er es nz"><img src="../Images/cdce3d52e6c76c22425371d9e0a47745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ppxg7lIoLZ4JgDH2NGFluA.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Examples of images I removed for knife class (first 2) and gun class (last 2).</figcaption></figure><h2 id="433f" class="mw kj hh bd kk ne nf ng ko nh ni nj ks jf nk nl ku jj nm nn kw jn no np ky nq bi translated">三。删除或裁剪包含多个类对象的图像</h2><figure class="mo mp mq mr fd ma er es paragraph-image"><div class="er es oa"><img src="../Images/66b518e31c1f02abeb6aeb3000bfddaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*tOWOc-iZarAUnaHOx8vnNA.png"/></div><figcaption class="md me et er es mf mg bd b be z dx">Example of an image containing both gun and knife.</figcaption></figure><p id="4a95" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，我删除了包含多个类对象的图像。如果可能的话，我把这些图片裁剪成只包含一个类对象。这对于不混淆具有用于分类的softmax图层的模型非常重要，因为该模型被训练为将每个输入图像仅分类到其中一个类别中。这确实看起来相当不灵活，后来我想出了一种方法，在处理多对象图像时使模型更加灵活，我将在我未来的一篇帖子中谈到这一点。</p><h1 id="e338" class="ki kj hh bd kk kl km kn ko kp kq kr ks in kt io ku iq kv ir kw it kx iu ky kz bi translated">网络图像数量与x射线图像数量</h1><p id="8233" class="pw-post-body-paragraph iw ix hh iy b iz la ii jb jc lb il je jf lc jh ji jj ld jl jm jn le jp jq jr ha bi translated">下表总结了网络图像和x光图像的数量:</p><figure class="mo mp mq mr fd ma er es paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="er es ob"><img src="../Images/63b6c8d6a39f8475f93e6a5c149fa18c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BYH4tC-TdvNHnBYZ5bPdEA.png"/></div></div></figure><p id="9541" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您可以看到，与x射线图像相比，每个类都有大量独特的web图像。</p><p id="0ad3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我的项目的<em class="js">初始</em>网络图像数据收集到此结束。请记住，这可能(或者肯定不会)是最后一次收集数据，因为<em class="js">设计</em>数据是一个迭代过程。在下一篇文章中，我将讨论ResNet50架构下使用抓取的web图像进行迁移学习。寻找更多的乐趣和批判性思维！</p><p id="49a3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如有任何问题/意见/反馈，请随时给我发信息或电子邮件至lucrece.shin@mail.utoronto.ca。感谢你阅读🥰</p><p id="af1f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">-☾₊˚.</p></div></div>    
</body>
</html>
<html>
<head>
<title>Elbow Method vs Silhouette Co-efficient in Determining the Number of Clusters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">肘形法与剪影系数在确定聚类数中的比较</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/elbow-method-vs-silhouette-co-efficient-in-determining-the-number-of-clusters-33baff2fbeee?source=collection_archive---------1-----------------------#2021-02-20">https://medium.com/mlearning-ai/elbow-method-vs-silhouette-co-efficient-in-determining-the-number-of-clusters-33baff2fbeee?source=collection_archive---------1-----------------------#2021-02-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8e41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我将讨论k-means聚类中计算聚类数的最佳方法。K-means聚类算法有一个称为“K”的特定参数，用于检测聚类数。其他算法，例如，分级聚类、DBSCAN(基于密度的带噪声应用的空间聚类)、OPTICS(用于识别聚类结构的排序点)不需要参数“K ”,因为这些不是基于质心的算法。[1]</p><p id="bb99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有几种方法可以计算出不同工作方式的集群数量。今天我来讨论肘法和廓形系数，并进行比较。</p><p id="c240" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我将使用来自UCI知识库的聚类示例数据集来讨论整个过程。</p><p id="8d8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要预处理数据集。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="2cb4" class="jm jn hh ji b fi jo jp l jq jr"><strong class="ji hi">#import libraries</strong><br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import LabelEncoder</span><span id="9f4f" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">#Importing the dataset</strong><br/>dataset = pd.read_csv('Live.csv')<br/>dataset=dataset.drop(['Column1','Column2','Column3','Column4'],axis=1)</span><span id="3942" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">#Label Encoding</strong><br/>lb_make = LabelEncoder()<br/>dataset['status_type']=lb_make.fit_transform(dataset['status_type'])lb_2 = LabelEncoder()<br/>dataset['status_published']=lb_2.fit_transform(dataset['status_published'])</span><span id="00a3" class="jm jn hh ji b fi js jp l jq jr">X = dataset.values</span><span id="5a8b" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">#Splitting the dataset into the Training set and Test set</strong><br/>X_train, X_test = train_test_split(X,test_size = 0.2, random_state = 0)</span></pre><p id="7932" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你对数据预处理不熟悉，可以看看这个<a class="ae jc" href="https://www.upgrad.com/blog/data-preprocessing-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">数据预处理</a></p><h2 id="cc57" class="jm jn hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated"><strong class="ak">肘法:</strong></h2><p id="a60a" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">肘法的概念来自于手臂的结构。但是，根据参数“metric”的值，elbow方法的结构可能会改变。首先，k-means聚类算法应用于k个聚类(我使用k = 2到15)的数据集，以在未标记的数据中找到数据中的组。[2]</p><p id="a1b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，根据参数“metric”计算平均分数。度量参数的默认值是“失真”,它计算距指定质心的平方距离的总和。[3]</p><p id="5e20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当绘制“扭曲”值的图形时，它给出了显示肘部的手臂结构，并表示簇的数量，如图1所示。</p><figure class="jd je jf jg fd ks er es paragraph-image"><div class="er es kr"><img src="../Images/cc48faa634f598bc924096444c2af595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*RnvrdhlUxHWss3vOffHT5g.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx">Figure 1: Elbow method with metric parameter ‘distortion’ (Image from google)</figcaption></figure><p id="4cbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，我使用了这个“度量”参数的另一个值，称为“calinski_harabasz”。该参数计算簇之间和簇内的散射比率[3],给出了比其他参数更好的假设。对于此参数，肘部的结构看起来颠倒了。</p><p id="238a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，使用yellowbrick visualizer [3]将平均分绘制在图表上(k与calinski_harabasz平均分)，如图2所示。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="bdee" class="jm jn hh ji b fi jo jp l jq jr"><strong class="ji hi">#Kmeans Clustering</strong></span><span id="57d9" class="jm jn hh ji b fi js jp l jq jr">range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</span><span id="29b5" class="jm jn hh ji b fi js jp l jq jr">for n_clusters in range_n_clusters:<br/>    <strong class="ji hi">#Initializing the clusterer with n_clusters value and a random   generator</strong><br/>    clusterer = KMeans(n_clusters=n_clusters, random_state=10)<br/>    cluster_labels = clusterer.fit_predict(X_train)</span><span id="64df" class="jm jn hh ji b fi js jp l jq jr">    <strong class="ji hi">#Using Elbow Plot</strong><br/>    visualizer= KElbowVisualizer(clusterer,k=(2,15),<br/>    metric  ='calinski_harabasz',locate_elbow=False, timings= False)</span><span id="21c1" class="jm jn hh ji b fi js jp l jq jr">    <strong class="ji hi">#Fitting the data to the visualizer</strong><br/>    visualizer.fit(X_train)  </span><span id="d998" class="jm jn hh ji b fi js jp l jq jr">    <strong class="ji hi">#Render the figure</strong><br/>    visualizer.show()        </span></pre><p id="d9c8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从图2可以看出，肘部指向k = 11。因此，可以说对于这种方法，最佳聚类的数量是11。</p><figure class="jd je jf jg fd ks er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/fe3eef4e5cb53e7ebd35a16acc87fa7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhYVIZ8wYKrVGdLaEtOuuA.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx">Figure 2: Elbow plot using metric parameter ‘Calinski _Harabasz’</figcaption></figure><h2 id="7046" class="jm jn hh bd jt ju jv jw jx jy jz ka kb ip kc kd ke it kf kg kh ix ki kj kk kl bi translated"><strong class="ak">剪影评分法</strong></h2><p id="6cba" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">轮廓图显示一个测量值，范围为[-1，1]其中[4]，</p><p id="a3a4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> +1:这意味着集群被清楚地区分</strong></p><p id="3d3a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 0:这意味着集群本质上是中性的，无法正确区分</strong></p><p id="875e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> -1:这意味着聚类分配方式错误</strong></p><p id="17c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们看看，这个轮廓分数是如何计算的，</p><p id="dea9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单一轮廓系数的公式为:</p><figure class="jd je jf jg fd ks er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es le"><img src="../Images/aaa2f1d286082cd20f950eef632dd685.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*obYn5e5d19fdwjWu1rznvA.png"/></div></div></figure><p id="7cb2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中，a =平均聚类内距离，b =平均最近聚类距离</p><p id="8590" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在计算每个轮廓系数之后，已经计算了位于[-1，+1]范围内的平均分数。这个平均轮廓分数定义了最佳聚类的数量。</p><p id="8969" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们深入研究代码，</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="9db2" class="jm jn hh ji b fi jo jp l jq jr"><strong class="ji hi">#import libraries</strong><br/>from sklearn.metrics import silhouette_score<br/>from yellowbrick.cluster import SilhouetteVisualizer</span><span id="e41e" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">#Kmeans Clustering</strong></span><span id="379a" class="jm jn hh ji b fi js jp l jq jr">range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</span><span id="b052" class="jm jn hh ji b fi js jp l jq jr">for n_clusters in range_n_clusters:<br/>    <strong class="ji hi">#Initializing the clusterer with n_clusters value and a random   generator<br/>    </strong>clusterer = KMeans(n_clusters=n_clusters, random_state=10)<br/>    cluster_labels = clusterer.fit_predict(X_train)</span><span id="57c4" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">    #The silhouette_score gives the average value for all the   samples.<br/>    #Calculating number of clusters</strong><br/>    silhouette_avg = silhouette_score(X_train, cluster_labels)<br/>    print("For n_clusters =", n_clusters,"The average   silhoutte_score is :", silhouette_avg</span><span id="52ff" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">    #Using Silhouette Plot<br/>    </strong>visualizer = SilhouetteVisualizer(clusterer,colors =  'yellowbrick')</span><span id="c06a" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">    #Fit the data to the visualizer</strong><br/>    visualizer.fit(X_train)       </span><span id="95a2" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">    #Render the figure</strong><br/>    visualizer.show()</span></pre><p id="9f84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输出:</strong></p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="7278" class="jm jn hh ji b fi jo jp l jq jr">For n_clusters = 2 The average silhouette_score is : 0.9419743880621418</span><span id="37bd" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 3 The average silhouette_score is : 0.8925568467675032</span><span id="4cf8" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 4 The average silhouette_score is : 0.8854468255579183</span><span id="dc7e" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 5 The average silhouette_score is : 0.8859344049988384</span><span id="c87b" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 6 The average silhouette_score is : 0.896222949688388</span><span id="ff22" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 7 The average silhouette_score is : 0.9531228433846561</span><span id="0527" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 8 The average silhouette_score is : 0.9882303235394505</span><span id="98ba" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 9 The average silhouette_score is : 0.9942722572401562</span><span id="f47e" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 10 The average silhouette_score is : 0.9860105575225317</span><span id="22e0" class="jm jn hh ji b fi js jp l jq jr"><strong class="ji hi">For n_clusters = 11 The average silhouette_score is : 0.9999999922837097</strong></span><span id="37c8" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 12 The average silhouette_score is : 0.906560275971653</span><span id="252c" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 13 The average silhouette_score is : 0.6440635368489311</span><span id="d1be" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 14 The average silhouette_score is : 0.7165267612201155</span><span id="8e63" class="jm jn hh ji b fi js jp l jq jr">For n_clusters = 15 The average silhouette_score is : 0.6440635368489311</span></pre><p id="6e30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上面的输出可以看出，对于集群11的数量，得到了最高的轮廓分数。然而，在图3中，我绘制了12个聚类的轮廓得分图，因为在跨越n_clusters = 12之后，轮廓得分开始下降，这意味着聚类被以错误的方式分配。因为我们知道轮廓分数越高，达到最佳值的机会就越高，所以可以说可能的聚类数应该是11。</p><p id="990e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们来讨论一下哪种方法更合适。</p><p id="1844" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，我们应该始终记住，如果数据不是非常聚类，肘方法就不能很好地工作。如果你没有看到一个倾斜的图表，那么你将无法找到集群的数量[3]。此外，倾斜图并不总是给出正确的答案。如果有许多重复的数据，那么肘方法可能不会给出正确的输出。在重叠数据的情况下，轮廓系数工作得更好，因为它识别重复的数据。</p><p id="6110" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，在轮廓分数的情况下，定义聚类的数量不取决于图形的偏斜程度。这取决于剪影分数，它越接近+1，成为最佳剪影的机会就越大。</p><p id="fe17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，可以说肘方法的功效取决于数据集的性质。如果相关数据集的模式是有利的，那么肘方法工作良好。另一方面，轮廓分数不依赖于数据集的性质。因为剪影是一种基于距离的方法，所以使用类内对象和最近的类之间的平均距离来找出剪影分数。</p><p id="997b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，在唯一的情况下，当只有一个聚类时，轮廓分数不起作用，因为轮廓分数要求最少2个聚类或更多[5]。此外，可以简单地说，如果数据集中只有一个聚类，则该数据集不适合聚类。</p><p id="7641" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总之，可以说，考虑到更高的准确性，得到一个清晰的集群剪影系数的方法是更合适的。然而，在训练集中不包含重复数据的简单且无噪声的数据集的情况下，肘方法将工作良好。</p></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><p id="ebf7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考</strong></p><p id="9965" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]维基百科贡献者。(2021年2月8日)。<em class="lm">确定数据集中的聚类数</em>. Wikipedia . https://en . Wikipedia . org/wiki/Determining _ the _ number _ of _ clusters _ in _ a _ data _ set</p><p id="96a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2] <em class="lm"> fw_error_www </em>。(未注明)。甲骨文。<a class="ae jc" href="https://blogs.oracle.com/datascience/introduction-to-k-means-clustering" rel="noopener ugc nofollow" target="_blank">https://blogs . Oracle . com/data science/introduction-to-k-means-clustering</a></p><p id="b0c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3] <em class="lm">弯头法—黄砖v1.3.post1文档</em>。(未注明)。黄砖。<a class="ae jc" href="https://www.scikit-yb.org/en/latest/api/cluster/elbow.html" rel="noopener ugc nofollow" target="_blank">https://www.scikit-yb.org/en/latest/api/cluster/elbow.html</a></p><p id="0a28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4] Bhardwaj，A. (2020年5月28日)。<em class="lm">剪影系数——走向数据科学</em>。中等。<a class="ae jc" href="https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c" rel="noopener" target="_blank">https://towards data science . com/silhouette-coefficient-validating-clustering-techniques-e 976 bb 81d 10c</a></p><p id="eead" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[5]<em class="lm">sk learn . metrics . silhouette _ score—sci kit-learn 0 . 24 . 1文档</em>。(未注明)。Scikit-Learn.Org。<a class="ae jc" href="https://scikitlearn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank">https://scikit learn . org/stable/modules/generated/sk learn . metrics . silhouette _ score . html</a></p></div></div>    
</body>
</html>
<html>
<head>
<title>“Themis: Fair and Efficient GPU Cluster Scheduling” summary</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《Themis:公平高效的GPU集群调度》摘要</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/themis-fair-and-efficient-gpu-cluster-scheduling-c641441580a?source=collection_archive---------4-----------------------#2022-01-14">https://medium.com/mlearning-ai/themis-fair-and-efficient-gpu-cluster-scheduling-c641441580a?source=collection_archive---------4-----------------------#2022-01-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="bd94" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="d97e" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">为了便于分布式<strong class="je hi"> M </strong>机器<strong class="je hi"> L </strong>收益(<strong class="je hi"> ML </strong>)训练负载的执行，GPU集群是主流的基础设施。然而，当多个这样的工作负载在一个共享集群上执行时，就会发生严重的争用。这种争用导致底层硬件的利用率和效率降低。Themis [ <strong class="je hi"> 1 </strong>的作者提到，可用的集群调度机制不适合ML训练工作负载的独特特征。ML培训工作量通常是需要<strong class="je hi">联合调度</strong>的长时间运行的任务，它们的性能对任务的相对位置很敏感。他们提出<strong class="je hi">Themis</strong>[<strong class="je hi">1</strong>]<strong class="je hi"/>作为ML训练工作量的新调度框架。该机制是一种GPU分配策略，以<strong class="je hi">结束时间公平的方式</strong>强制完成ML训练工作负载<em class="ka">(<em class="ka">具有N个应用的共享集群中的运行时间与在1/N集群中单独运行的运行时间之比</em>)。Themis的目标是最小化所有ML应用的最大结束时间公平性，同时有效利用集群GPU。Themis使用两级调度架构，ML作业对中央仲裁机构拍卖的可用资源进行投标。这种类型的调度被认为是为了捕捉布局敏感性并确保效率。拍卖(仲裁)通过在短期内以公平换取效率，但在长期内确保结束时的公平，将GPU分配给获胜的投标人。Themis在<a class="ae kb" href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"><strong class="je hi">Apache YARN 3 . 2 . 0</strong></a>之上实现，并通过重放大型企业跟踪的工作负载进行评估。评估显示公平性提高了2.25倍以上，集群效率提高了5%到250%。</em></p><h1 id="5d17" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">背景</h1><p id="5316" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">能够让人们分享某样东西的<strong class="je hi">分享激励</strong> ( <strong class="je hi">斯</strong>)就是公平。如果<strong class="je hi"> N个用户</strong>共享一个由<strong class="je hi"> C个GPU</strong>组成的集群，那么每个用户的性能一定不会低于使用一个大小为<strong class="je hi"> C/N </strong>的私有集群。此外，他们不能忍受长时间的等待。试图提供共享集群激励的现有集群调度框架[ <strong class="je hi"> 2 </strong>、<strong class="je hi"> 3 </strong>、<strong class="je hi"> 4 </strong> ]是针对<strong class="je hi">大数据工作负载</strong>(对ML工作负载无效)而设计的。他们没有考虑ML任务的长持续时间和ML应用的放置偏好。</p><h2 id="e563" class="kc if hh bd ig kd ke kf ik kg kh ki io jn kj kk is jr kl km iw jv kn ko ja kp bi translated">使当前大数据调度器不公平的ML工作负载特征</h2><ol class=""><li id="d3f5" class="kq kr hh je b jf jg jj jk jn ks jr kt jv ku jz kv kw kx ky bi translated">ML作业具有需要一起调度的长时间运行的任务，即，联合调度</li><li id="c81a" class="kq kr hh je b jf kz jj la jn lb jr lc jv ld jz kv kw kx ky bi translated">ML工作是位置敏感的。作业中的每个任务通常会运行几次迭代，同时在每次迭代结束时同步模型更新。这表明沟通在ML工作负载中变得很重要。如果一项工作的所有任务都放在同一台机器或同一机架上，由于更快的通信，这将导致显著的加速。</li></ol><p id="51c4" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated"><strong class="je hi">基于对5000个独立用户共享的50个GPU上的执行跟踪的观察结果</strong></p><ol class=""><li id="ebb7" class="kq kr hh je b jf le jj lf jn lj jr lk jv ll jz kv kw kx ky bi translated">ML应用程序在资源使用、提交的作业数量和运行时间方面是异构的。它们比大数据分析工作要长得多。大数据作业通常需要几个小时才能完成。</li><li id="1ec3" class="kq kr hh je b jf kz jj la jn lb jr lc jv ld jz kv kw kx ky bi translated"><strong class="je hi"> ~10% </strong>的应用有1个作业，约<strong class="je hi"> ~90% </strong>的应用进行超参数勘探，多达<strong class="je hi"> 100个</strong>作业。</li></ol><h2 id="bc15" class="kc if hh bd ig kd ke kf ik kg kh ki io jn kj kk is jr kl km iw jv kn ko ja kp bi translated">帕累托效率(PE)和嫉妒自由(EF)表达式</h2><p id="69d4" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><a class="ae kb" href="https://en.wikipedia.org/wiki/Pareto_efficiency" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">帕累托效率</strong> </a>是指在不使至少一个个体或偏好标准恶化或没有任何损失的情况下，没有一个个体或偏好标准能够变得更好。</p><p id="8f92" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated"><a class="ae kb" href="https://en.wikipedia.org/wiki/Envy-freeness" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi"> Envy-Freedom </strong> </a>说的是，当资源在权利平等的人之间分配时，每个人都应该得到一份，也就是说，在他们看来，至少和任何其他代理人得到的那份一样好。</p><h1 id="5116" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">拟议机制</h1><h2 id="59d2" class="kc if hh bd ig kd ke kf ik kg kh ki io jn kj kk is jr kl km iw jv kn ko ja kp bi translated">术语</h2><ul class=""><li id="30a8" class="kq kr hh je b jf jg jj jk jn ks jr kt jv ku jz lm kw kx ky bi translated"><strong class="je hi"> ML应用</strong>:一个或多个ML模型训练任务的集合，对应于一个用户，用于高级目标，如<strong class="je hi">语音识别</strong>或<strong class="je hi">对象检测</strong>(用户训练这些模型，知道适当的超参数<strong class="je hi">或</strong>通过训练一组超参数来探索它们)</li><li id="5456" class="kq kr hh je b jf kz jj la jn lb jr lc jv ld jz lm kw kx ky bi translated"><strong class="je hi">作业</strong>:并行任务的集合。在任何给定的时间，作业的所有任务共同处理一个小批量的训练数据。</li><li id="8764" class="kq kr hh je b jf kz jj la jn lb jr lc jv ld jz lm kw kx ky bi translated"><strong class="je hi">任务</strong>:处理批次的子集，从模型的初始版本开始，执行基础学习算法的多次迭代以改进模型。</li></ul><h2 id="c937" class="kc if hh bd ig kd ke kf ik kg kh ki io jn kj kk is jr kl km iw jv kn ko ja kp bi translated">动机</h2><p id="fa29" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">由于应用程序执行持续时间长，控制容量的用户会给许多其他用户带来很长的等待时间。一些受压迫的用户被迫退出并购买他们的硬件。虽然拥有一个调度程序来确保底层硬件的高利用率是很重要的，但是调度程序应该在ML应用程序之间公平地共享资源。</p><p id="7dec" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated"><strong class="je hi">结束时间公平性指标。</strong>如下式所示:</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div class="er es ln"><img src="../Images/c4526ac279d529e35256499d75321f1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*iwC9mo4NyWtylikDByUoLw.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="03d4" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">T <em class="ka"> sh </em>是共享完成时间，T <em class="ka"> id </em>是独立完成时间。</p><p id="3304" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">分配机制必须为不同的GPU分配估计完成时间度量的值<em class="ka"> </em>。但是，对于调度引擎来说，预测或确定度量值是不可管理的。因此，Themis建议在应用程序和调度引擎之间建立一个更广泛的接口，允许应用程序表达对每个分配的偏好。<em class="ka">建议应用程序将该信息编码为如下表格</em>。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es lz"><img src="../Images/fb0de3fb35a37e9262ffb980bf00d917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HefwD_Vn6y4Jt2oWTpNMfA.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="cbc1" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">每一列都有一个潜在GPU分配的排列，以及接收到该分配时的结束时间公平性度量的估计。</p><p id="e027" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">ML应用的结束时间公平性是它接收的GPU分配的函数。分配策略采用这些结束时间公平性度量和输出分配。</p><h2 id="8473" class="kc if hh bd ig kd ke kf ik kg kh ki io jn kj kk is jr kl km iw jv kn ko ja kp bi translated">机制</h2><p id="68a3" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">一个简单的策略是根据应用程序报告的结束时间公平性指标对应用程序进行排序，并根据它们分配GPU，这可能是第一个想到的解决方案。然而，应用程序可以提交关于其结束时间公平性度量值的错误信息，增加其赢得分配的机会。为了解决这个问题，作者建议使用拍卖。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es me"><img src="../Images/9f1c54fcd7c7edee2fd6849714b206ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgQfkCbxgadcnH_MmImQXA.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="8882" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">两级调度设计在底层包含一个集中式的应用程序间调度器，在顶层包含一个窄API来集成现有的超参数调优框架。现有的几个框架[ <strong class="je hi"> 5 </strong>，<strong class="je hi"> 6 </strong> ]可以在单个应用程序中的各个作业之间智能地共享GPU资源，并且在某些情况下，如果某个作业的进度不乐观，也可以提前终止该作业。</p><p id="24e0" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">作者认为应用程序的完成时间是最佳模型和相关超参数被识别的时间。在识别这种模型的过程中，应用程序可能会决定提前终止它的一些组成作业。这些模型的次优性可以通过检查验证准确性来识别(例如，最小的一个终止)。对于包含单个作业的应用程序，完成时间是将此模型训练到目标精度或最大迭代次数所需的时间。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es mf"><img src="../Images/d0b0a4c132400816bba343008f6d70d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vaSjquVdTlqzsWb5Dhco4g.png"/></div></div></figure><h1 id="f1e8" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">结论</strong></h1><p id="960c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在集群上调度ML工作负载时，传统的大数据拟合框架无法提供帮助。这些工作负载具有独特的特征，必须考虑这些特征才能拥有高效的激励式共享集群(高利用率)。Themis通过基于类似于真实世界拍卖的概念提出两级调度和资源分配来解决这个问题。但是，当ML工作负载没有充分利用底层资源时，应该考虑应用程序在配置时的争用。</p><h1 id="a774" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="54fd" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">【<strong class="je hi">1</strong>k . maha Jan<em class="ka">等</em>，<strong class="je hi"> Themis:公平高效的GPU集群调度，</strong>在<strong class="je hi"> <em class="ka">第17届USENIX研讨会</em> </strong> <em class="ka">关于网络化系统设计与实现(NSDI 20) </em>，<strong class="je hi"> 2020 </strong>，bll 289–304。</p><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="30b0" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">【<strong class="je hi">2</strong>】gho DSI，Ali等人】<strong class="je hi">显性资源公平(DRF):多种资源类型的公平分配。</strong><em class="ka">Nsdi</em>。第十一卷。№2011.<strong class="je hi"> 2011年</strong>。</p><div class="mi mj ez fb mk ml"><a href="https://www.usenix.org/conference/nsdi11/dominant-resource-fairness-fair-allocation-multiple-resource-types" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">主导资源公平性:多种资源类型的公平分配</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">USENIX致力于开放我们活动中展示的研究成果。论文和会议记录可以免费获得…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">www.usenix.org</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz lt ml"/></div></div></a></div><p id="b05a" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">【<strong class="je hi">3</strong>】Isard，Michael，等】<strong class="je hi"> Quincy:分布式计算集群的公平调度。</strong><em class="ka">ACM SIGOPS第22届操作系统原理研讨会会议录</em>。<strong class="je hi"> 2009 </strong>。</p><p id="a133" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">【<strong class="je hi">4</strong>Grandl，Robert等】<strong class="je hi">多资源集群中的利他调度。</strong><em class="ka">第十二届{USENIX}操作系统设计与实施研讨会({OSDI} 16) </em>。<strong class="je hi"> 2016 </strong>。</p><div class="mi mj ez fb mk ml"><a href="https://www.usenix.org/conference/osdi16/technical-sessions/presentation/grandl_altruistic" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">多资源集群中的利他调度</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">USENIX致力于开放我们活动中展示的研究成果。论文和会议记录可以免费获得…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">www.usenix.org</p></div></div><div class="mu l"><div class="na l mw mx my mu mz lt ml"/></div></div></a></div><p id="b3ae" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">【<strong class="je hi">5</strong>】Bergstra，James等.<strong class="je hi"> Hyperopt:一个用于模型选择和超参数优化的python库。</strong><em class="ka">计算科学&amp;发现</em> 8.1 ( <strong class="je hi"> 2015 </strong> ): 014008。</p><p id="2079" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">[ <strong class="je hi"> 6 </strong> ] Rasley，Jeff，等.<strong class="je hi">超光速引擎:探索超参数与pop调度</strong><em class="ka">第18届ACM/IFIP/USENIX中间件会议论文集</em>。<strong class="je hi"> 2017 </strong>。</p><p id="f5bf" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated">【<strong class="je hi"> 7 </strong>】顾，军成，等.<strong class="je hi">面向分布式深度学习的GPU集群管理器。</strong><em class="ka"/><strong class="je hi"><em class="ka">USENIX</em></strong><em class="ka">网络化系统设计与实现研讨会(NSDI 19) </em>。<strong class="je hi"> 2019 </strong>。</p><div class="mi mj ez fb mk ml"><a href="https://www.usenix.org/conference/nsdi19/presentation/gu" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">忒瑞西阿斯:用于分布式深度学习的GPU集群管理器</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">USENIX致力于开放我们活动中展示的研究成果。论文和会议记录可以免费获得…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">www.usenix.org</p></div></div><div class="mu l"><div class="nb l mw mx my mu mz lt ml"/></div></div></a></div><p id="c926" class="pw-post-body-paragraph jc jd hh je b jf le jh ji jj lf jl jm jn lg jp jq jr lh jt ju jv li jx jy jz ha bi translated"><strong class="je hi">最少获得服务(LAS)分配策略</strong>:GPU(或资源)被租用一定的期限，当租约到期时，可用的GPU被给予接收最少GPU时间的作业。</p><h1 id="7011" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">很高兴知道</h1><div class="mi mj ez fb mk ml"><a href="https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9" rel="noopener follow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">10种梯度下降优化算法</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">深度学习你应该知道的随机梯度下降优化算法</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="nc l mw mx my mu mz lt ml"/></div></div></a></div><div class="mi mj ez fb mk ml"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.com</p></div></div><div class="mu l"><div class="nd l mw mx my mu mz lt ml"/></div></div></a></div></div></div>    
</body>
</html>
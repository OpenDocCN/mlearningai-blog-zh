<html>
<head>
<title>Hands-on Graph Neural Networks with PyTorch Geometric (1): Cora Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch几何图形神经网络实验(1): Cora数据集</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/ultimate-guide-to-graph-neural-networks-1-cora-dataset-37338c04fe6f?source=collection_archive---------0-----------------------#2022-07-23">https://medium.com/mlearning-ai/ultimate-guide-to-graph-neural-networks-1-cora-dataset-37338c04fe6f?source=collection_archive---------0-----------------------#2022-07-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/22bb90cd9279cb83aaa43f92a396c08a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vfCG9lnmfQwhmmGc"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@jjying?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">JJ Ying</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="50d8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">社交媒体近年来变得流行，用户通过关注者-关注者关系相互联系。还有许多其他类型的数据具有网络结构，其中数据相互连接。一个可以应用于此类数据的机器学习模型是<strong class="iw hi">图形神经网络(GNNs) </strong>，它吸引了很多关注。在本文中，我们将解释图形数据的特征，以及与图形神经网络相关的库和可视化技术的使用。</p><p id="4232" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过这篇文章，你将学到以下内容；</p><ul class=""><li id="2f75" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">如何处理PyTorch几何和networkx</li><li id="5cd3" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">Cora数据集的特征</li><li id="2fd9" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">如何有效地可视化数据</li></ul><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="0d5c" class="kp kq hh kl b fi kr ks l kt ku">import os<br/>import collections</span><span id="3864" class="kp kq hh kl b fi kv ks l kt ku">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import scipy.sparse as sp<br/>import torch<br/>from torch import Tensor<br/>import torch_geometric<br/>from torch_geometric.utils import to_networkx<br/>from torch_geometric.datasets import Planetoid<br/>import networkx as nx<br/>from networkx.algorithms import community</span><span id="4386" class="kp kq hh kl b fi kv ks l kt ku">device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')</span><span id="ca94" class="kp kq hh kl b fi kv ks l kt ku">data_dir = "./data"<br/>os.makedirs(data_dir, exist_ok=True)</span></pre><h1 id="e2b6" class="kw kq hh bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">科拉数据集</strong></h1><p id="c978" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">Cora数据集是图研究领域中众所周知的数据集。这包括2708份科学出版物，分为七类。引文网络由5429个链接组成。数据集中的每个出版物由0/1值的词向量来描述，该词向量指示字典中相应词的存在与否。这部词典由1433个独特的单词组成。</p><p id="f035" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">顺便提一下，有一项服务可以显示通过引用关系连接的论文网络。这在寻找相关研究时非常有用。详见<a class="ae it" href="http://connectedpapers.com" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="22b9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，通过运行下面的命令下载数据集。在本文中，我们将使用<strong class="iw hi">py torch</strong>G<strong class="iw hi">geometric</strong>和<strong class="iw hi"> networkx </strong>处理数据。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="20e8" class="kp kq hh kl b fi kr ks l kt ku">dataset = Planetoid(root=data_dir, name='Cora')<br/>data = dataset[0]</span></pre><h2 id="3ae7" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated"><strong class="ak">节点</strong></h2><p id="fba8" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">Cora数据集包含<strong class="iw hi"> 2708 </strong>篇论文，在图中表示为节点。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="ed37" class="kp kq hh kl b fi kr ks l kt ku">print(f'Number of nodes: {data.num_nodes}')<br/># Number of nodes: 2708</span></pre><h2 id="49e5" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated"><strong class="ak">边缘</strong></h2><p id="e112" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">Cora数据集中的论文有<strong class="iw hi"> 5429 </strong>引用连接，在图中表示为边。边信息对于图形数据是唯一的。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="c540" class="kp kq hh kl b fi kr ks l kt ku">print(f'Number of edges: {data.num_edges}')<br/># Number of edges: 10556</span></pre><p id="9289" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">边数好像是<strong class="iw hi"> 10556 </strong>。我们来看看为什么边数是5429的两倍。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="3795" class="kp kq hh kl b fi kr ks l kt ku">print(f'Has isolated nodes: {data.has_isolated_nodes()}')  # False<br/>print(f'Has self-loops: {data.has_self_loops()}')  # False<br/>print(f'Is undirected: {data.is_undirected()}')  # True</span></pre><p id="d8d4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第一行代码确认没有不通过边连接的节点，第二行代码显示没有自循环，第三行代码显示边没有方向。这意味着边计数是实际计数的两倍，因为包括了双向边信息。</p><p id="b259" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们看看边缘信息是如何存储的。我们以第30个节点持有的边为例来看。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="9cac" class="kp kq hh kl b fi kr ks l kt ku">edge_index = data.edge_index.numpy()<br/>print(edge_index.shape)<br/>edge_example = edge_index[:, np.where(edge_index[0]==30)[0]]<br/>edge_example</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ml"><img src="../Images/794579a35c3e4e9a15e744f13061e38c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yWJkxLewtmsLgFOo44yDkA.png"/></div></div></figure><p id="01cb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们已经以边所连接的节点对的形式获得了数据。</p><p id="61f0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们试着画一个以这个节点为中心的网络。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="1b7c" class="kp kq hh kl b fi kr ks l kt ku">node_example = np.unique(edge_example.flatten())</span><span id="3ca8" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize=(10, 6))<br/>G = nx.Graph()<br/>G.add_nodes_from(node_example)<br/>G.add_edges_from(list(zip(edge_example[0], edge_example[1])))<br/>nx.draw_networkx(G, with_labels=False)</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mm"><img src="../Images/e26d528232d4140907445c4167613563.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*emhFS3MJ3ar35ppNvOOObQ.png"/></div></div></figure><h2 id="5f54" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated">节点度</h2><p id="be46" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">图论中的度是指一个图中连接一个顶点(节点)的边数。我们前面看到每个节点总有一条边，那么每个节点平均有多少条边呢？</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="83b7" class="kp kq hh kl b fi kr ks l kt ku">print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')<br/># Average node degree: 3.90</span></pre><p id="f074" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们发现平均节点度为3.9。你可能觉得低得惊人。我们可以通过绘制度的直方图来检查总体分布。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="6613" class="kp kq hh kl b fi kr ks l kt ku">G = to_networkx(data, to_undirected=True)<br/>degrees = [val for (node, val) in G.degree()]</span><span id="3022" class="kp kq hh kl b fi kv ks l kt ku">display(pd.DataFrame(pd.Series(degrees).describe()).transpose().round(2))</span><span id="ef36" class="kp kq hh kl b fi kv ks l kt ku">print(len(degrees))<br/>print(sum(degrees))</span><span id="3e89" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize=(10, 6))<br/>plt.hist(degrees, bins=50)<br/>plt.xlabel("node degree")<br/>plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/cf2d2ed95542cafc1b821024c8a13af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEB9I05-wL5aVNWWpYPqdg.png"/></div></div></figure><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/be4244a748719ed66628467e85ad3fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HsVWe1AE-p_w3LKsFpc0FQ.png"/></div></div></figure><p id="6b93" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">高学位意味着它们与许多节点(论文)相连。换句话说，度数高的<strong class="iw hi">节点很可能是重要的</strong>。记住，找论文的时候，总是可以通过看论文被引用的次数来推断论文的好坏。</p><p id="5a56" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们绘制图表，看看具有最高程度的前10个节点位于何处。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="4639" class="kp kq hh kl b fi kr ks l kt ku">G = to_networkx(data, to_undirected=True)<br/>pos = nx.spring_layout(G, seed=42)</span><span id="0eed" class="kp kq hh kl b fi kv ks l kt ku">cent = nx.degree_centrality(G)<br/>node_size = list(map(lambda x: x * 500, cent.values()))</span><span id="71fa" class="kp kq hh kl b fi kv ks l kt ku">cent_array = np.array(list(cent.values()))<br/>threshold = sorted(cent_array, reverse=True)[10]<br/>print("threshold", threshold)<br/>cent_bin = np.where(cent_array &gt;= threshold, 1, 0.1)</span><span id="16cf" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize=(12, 12))<br/>nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,<br/>                               cmap=plt.cm.plasma,<br/>                               node_color=cent_bin,<br/>                               nodelist=list(cent.keys()),<br/>                               alpha=cent_bin)</span><span id="3893" class="kp kq hh kl b fi kv ks l kt ku">edges = nx.draw_networkx_edges(G, pos, width=0.25, alpha=0.3)</span><span id="2b0c" class="kp kq hh kl b fi kv ks l kt ku">plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/0fdb998f6cc67c785506c22350cbf9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7MEsWOKJRm2gfNW2NHKIA.png"/></div></div></figure><p id="9ebc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">度最高的前10个节点用黄点表示，其他节点用灰点表示。黄点与度数的大小成正比。你可以看到黄色的点都位于网络的中心部分。</p><h2 id="92bb" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated">特征</h2><p id="d525" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">Cora数据集中的论文具有<strong class="iw hi"> 1433 </strong>特征。</p><p id="705f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于1433个单词中的每一个，如果该单词在论文中被包括或不被包括，则特征的数量被表示为0和1。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="b969" class="kp kq hh kl b fi kr ks l kt ku">print(f'Number of features: {data.num_node_features}')<br/># Number of edge features: 0</span></pre><p id="5fda" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们展示一些特征，你可以看到它们是由0和1组成的。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="1de8" class="kp kq hh kl b fi kr ks l kt ku">print(len(data.x[0]))<br/>data.x[0][:20]</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/1505bb6b67e9704d4ebcd05947382702.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmzO24xk8YVNP0BDDeUdig.png"/></div></div></figure><p id="a305" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请注意，我们现在正在查看节点功能。边也可能具有特征值(边要素)，但它们不包含在Cora数据集中。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="5e8b" class="kp kq hh kl b fi kr ks l kt ku">print(f'Number of edge features: {data.num_edge_features}')<br/># Number of edge features: 0</span></pre><h2 id="b6f8" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated"><strong class="ak">学习班</strong></h2><p id="827c" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">Cora数据集中的论文标有<strong class="iw hi"> 7 </strong>不同的标签。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="d1a6" class="kp kq hh kl b fi kr ks l kt ku">print(f'Number of classes: {dataset.num_classes}')<br/># Number of classes: 7</span></pre><p id="a7a9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们显示这个类的一部分，我们可以看到它由0到6之间的整数组成。每个数字对应一个主题，如下所示。详见<a class="ae it" href="https://keras.io/examples/graph/gnn_citations/" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="9f71" class="kp kq hh kl b fi kr ks l kt ku">label_dict = {<br/>    0: "Theory",<br/>    1: "Reinforcement_Learning",<br/>    2: "Genetic_Algorithms",<br/>    3: "Neural_Networks",<br/>    4: "Probabilistic_Methods",<br/>    5: "Case_Based",<br/>    6: "Rule_Learning"}<br/>data.y[:10]</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/707cfac717f12db3ede937e6cc6c17ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*dthMloE-ZU-8x5N7nt_jPA.png"/></div></figure><p id="f557" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通常班级的数量是不相等的。让我们找出每个班级的人数。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="57c7" class="kp kq hh kl b fi kr ks l kt ku">counter = collections.Counter(data.y.numpy())<br/>counter = dict(counter)<br/>print(counter)</span><span id="94a3" class="kp kq hh kl b fi kv ks l kt ku">count = [x[1] for x in sorted(counter.items())]</span><span id="e539" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize=(10, 6))<br/>plt.bar(range(7), count)<br/>plt.xlabel("class", size=20)<br/>plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/a25e8e41c0d580a097e1da9393d17038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h9oZlaZ3v-VR83WFvOkZig.png"/></div></div></figure><p id="fdb4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">班级人数最高的是3班818人，最低的是6班180人。在训练机器学习模型时，我们需要小心谨慎。</p><p id="9410" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，画一个网络图，看看这些类的分布是否连贯。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="e72b" class="kp kq hh kl b fi kr ks l kt ku">G = to_networkx(data, to_undirected=True)</span><span id="a6d4" class="kp kq hh kl b fi kv ks l kt ku">node_color = []<br/>nodelist = [[], [], [], [], [], [], []]</span><span id="220c" class="kp kq hh kl b fi kv ks l kt ku">colorlist = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']<br/>labels = data.y<br/>for n, i in enumerate(labels):<br/>    node_color.append(colorlist[i])<br/>    nodelist[i].append(n)</span><span id="e0e8" class="kp kq hh kl b fi kv ks l kt ku">pos = nx.spring_layout(G, seed = 42)</span><span id="cef3" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize = (10, 10))<br/>labellist = list(label_dict.values())</span><span id="05d4" class="kp kq hh kl b fi kv ks l kt ku">for num, i in enumerate(zip(nodelist, labellist)):<br/>    n, l = i[0], i[1]<br/>    nx.draw_networkx_nodes(G, pos, nodelist=n, node_size = 5, node_color = colorlist[num], label=l)</span><span id="1a1c" class="kp kq hh kl b fi kv ks l kt ku">nx.draw_networkx_edges(G, pos, width = 0.25)<br/>plt.legend(bbox_to_anchor=(1, 1), loc='upper left')</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/67eff7a934178e0c8bb8bec69109ed3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDYExxbktEgtczg2zZzv7A.png"/></div></div></figure><p id="f33e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因为它是在二维空间中绘制的，所以看起来有点困难，但是看起来好像这些类被组合在一起了。我们将在下一节从不同的角度分析这一点。</p><h2 id="fd06" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated"><strong class="ak">同性</strong></h2><p id="86f3" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">具有相同特征的节点通常是相连的。这种性质叫做同质性。对于我们之前看到的七个类，我们将看到有多少相同类的节点通过边连接，反之亦然。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="5db6" class="kp kq hh kl b fi kr ks l kt ku">labels = data.y.numpy()<br/>connected_labels_set = list(map(lambda x: labels[x], data.edge_index.numpy()))<br/>connected_labels_set = np.array(connected_labels_set)</span><span id="198a" class="kp kq hh kl b fi kv ks l kt ku">def add_missing_keys(counter, classes):<br/>    for x in classes:<br/>        if x not in counter.keys():<br/>            counter[x] = 0<br/>    return counter</span><span id="a879" class="kp kq hh kl b fi kv ks l kt ku">label_connection_counts = []<br/>for i in range(7):<br/>    print(f"label: {i}")<br/>    connected_labels = connected_labels_set[:, np.where(connected_labels_set[0] == i)[0]]<br/>    print(connected_labels.shape[1], "edges")<br/>    counter = collections.Counter(connected_labels[1])<br/>    counter = dict(counter)<br/>    print(counter)<br/>    counter = add_missing_keys(counter, range(7))<br/>    items = sorted(counter.items())<br/>    items = [x[1] for x in items]<br/>    label_connection_counts.append(items)</span><span id="09e5" class="kp kq hh kl b fi kv ks l kt ku">label_connection_counts = np.array(label_connection_counts)</span><span id="391b" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize=(9, 7))<br/>plt.rcParams["font.size"] = 13<br/>hm = sns.heatmap(label_connection_counts, annot=True, cmap='hot_r', cbar=True, square=True)<br/>plt.xlabel("class",size=20)<br/>plt.ylabel("class",size=20)<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mt"><img src="../Images/9a47a100c48d7edeb7aba263d5ffa99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDRQ3B0MLrTimlMvwHjARw.png"/></div></div></figure><p id="54d3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以看到，有许多属于同一个类的相互连接的节点。</p><p id="fc1c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过将矩阵的对角线分量的和除以所有分量的和，我们计算出在同一类内连接的边的百分比。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="7163" class="kp kq hh kl b fi kr ks l kt ku">label_connection_counts.diagonal().sum() / label_connection_counts.sum()<br/># 0.8099658961727927</span></pre><p id="02ac" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">似乎有81%左右的边是在同一个类内连接的。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="ba1c" class="kp kq hh kl b fi kr ks l kt ku">def scaling(array):<br/>    return array / sum(array)</span><span id="eeb9" class="kp kq hh kl b fi kv ks l kt ku">label_connection_counts_scaled = np.apply_along_axis(scaling, 1, label_connection_counts)</span><span id="582c" class="kp kq hh kl b fi kv ks l kt ku">plt.figure(figsize=(9, 7))<br/>plt.rcParams["font.size"] = 13<br/>hm = sns.heatmap(<br/>    label_connection_counts_scaled,<br/>    annot=True,<br/>    cmap='hot_r',<br/>    fmt="1.2f",<br/>    cbar=True,<br/>    square=True)<br/>plt.xlabel("class",size=20)<br/>plt.ylabel("class",size=20)<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mu"><img src="../Images/57389cd189c4e3855e9595bbc5d06190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZL8NI1r_F20iQJxEjipVw.png"/></div></div></figure><p id="3a91" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">太棒了。我们可以看到，对于所有类，最高数量的边与同一个类相关联。对于类2也是如此，其中大约91%的边在同一类内连接。另一方面，趋势在类0中相对较弱，大约70%的边在同一类内。</p><h2 id="f1d5" class="kp kq hh bd kx ly lz ma lb mb mc md lf jf me mf lj jj mg mh ln jn mi mj lr mk bi translated">列车测试分离</h2><p id="0819" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">最后但同样重要的是，我们将讨论数据拆分。我们现在处理的数据类具有掩码形式的拆分信息，可以分为训练数据、验证数据和测试数据。首先，让我们看看每个包含多少数据。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="6632" class="kp kq hh kl b fi kr ks l kt ku">print(f'Number of training nodes: {data.train_mask.sum()}')<br/>print(f'Number of validation nodes: {data.val_mask.sum()}')<br/>print(f'Number of test nodes: {data.test_mask.sum()}')</span></pre><p id="9717" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">数据被分成140个训练数据、500个验证数据和1000个测试数据。然而，这些案件的总数加起来不到2708起。让我们检查一下哪些数据被使用，哪些数据没有被使用。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="688a" class="kp kq hh kl b fi kr ks l kt ku">split_type_array = np.zeros(data.num_nodes)<br/>split_type_array[np.where(data.train_mask == True)[0]] = 1<br/>split_type_array[np.where(data.val_mask == True)[0]] = 2<br/>split_type_array[np.where(data.test_mask == True)[0]] = 3<br/>split_type_array</span><span id="679f" class="kp kq hh kl b fi kv ks l kt ku">plt.scatter(range(2708), split_type_array)<br/>plt.xlabel("index")<br/>plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/4f488ae680de4c9d89c4b887d6f7a85a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W3Duiqp6Bj9VKib2Qjtknw.png"/></div></div></figure><p id="f950" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将x轴标为索引，y轴标为0表示未使用的数据，1表示训练数据，2表示验证数据，3表示测试数据。这是一个奇怪的分割，但看起来数据是如上分割的。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="1f3f" class="kp kq hh kl b fi kr ks l kt ku">titles = ["Training", "Validation", "Test"]<br/>fig, axes = plt.subplots(ncols=3, figsize=(21, 6))</span><span id="1512" class="kp kq hh kl b fi kv ks l kt ku">for i in range(3):<br/>    counter = collections.Counter(data.y.numpy()[np.where(split_type_array == i + 1)[0]])<br/>    counter = dict(counter)<br/>    print(titles[i], counter)</span><span id="5a3f" class="kp kq hh kl b fi kv ks l kt ku">count = [x[1] for x in sorted(counter.items())]</span><span id="d72c" class="kp kq hh kl b fi kv ks l kt ku"># plt.figure(figsize=(10, 6))<br/>    axes[i].bar(range(7), count)<br/>    axes[i].set_xlabel("class", size=20)<br/>    axes[i].set_title(titles[i])</span><span id="6dc3" class="kp kq hh kl b fi kv ks l kt ku">plt.show()</span></pre><figure class="kg kh ki kj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mw"><img src="../Images/39f246d0ee69e5c60895d9925c258c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3WCq3HFVq4WLPTmYzb3dCA.png"/></div></div></figure><p id="00e2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有意思！训练数据包含每个类别的<strong class="iw hi"> 20个数据。验证和测试数据不具有相等的类别比例，但是两者具有相似的分布。这些类似于在类部分看到的总体数据中类的百分比。</strong></p><h1 id="06c9" class="kw kq hh bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">结论</h1><p id="70fb" class="pw-post-body-paragraph iu iv hh iw b ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn lx jp jq jr ha bi translated">在本文中，我们使用Cora数据集来解释具有图形结构的数据的特征以及如何绘制图表。我们希望你已经提高了对PyTorch Geometric和networkx的处理能力。</p><p id="7fc9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以后会讲解图形神经网络，一定要关注我，不要错过。</p><div class="mx my ez fb mz na"><a rel="noopener follow" target="_blank" href="/@koki_noda/ultimate-guide-to-graph-neural-networks-2-texas-dataset-f70782190f80"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hi fi z dy nf ea eb ng ed ef hg bi translated">图形神经网络终极指南(2):德克萨斯数据集</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">近年来，社交媒体变得流行起来，用户通过关注者-关注者相互联系…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">medium.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no in na"/></div></div></a></div><div class="mx my ez fb mz na"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hi fi z dy nf ea eb ng ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">medium.com</p></div></div><div class="nj l"><div class="np l nl nm nn nj no in na"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Helping Machines Visualize Our World</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">帮助机器可视化我们的世界</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/helping-machines-visualize-our-world-f1c489bb2da9?source=collection_archive---------4-----------------------#2021-05-22">https://medium.com/mlearning-ai/helping-machines-visualize-our-world-f1c489bb2da9?source=collection_archive---------4-----------------------#2021-05-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="e9fe" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">作为特征提取器的无头卷积神经网络</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/7700810f02627eed4570648f70524db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rZP6QoV3-9qCxmzH"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@budhelisson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Bud Helisson</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><p id="3133" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">帮助机器理解数字图像的内容允许各种应用，例如图像分割、对象检测、面部识别、边缘检测、模式检测、图像分类、特征匹配等等！在这篇文章中，我们将重点讨论特征匹配，即从一幅图像中学习特征，并将其与其他图像进行匹配以进行图像检索！注意，下面的代码也可以在这个<a class="ae jm" href="https://github.com/koohaoming/SnapItFindIt/blob/main/CNN_Keras_Feature_Extractor.ipynb" rel="noopener ugc nofollow" target="_blank">链接中找到。</a></p><p id="026c" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">这是一系列由4名新加坡国立大学硕士研究生(理学硕士。工业4.0中)谁在拿ISY5004智能传感系统。以下是我们将要分享的内容的快照:</p><ul class=""><li id="f617" class="kq kr hh jw b jx jy ka kb kd ks kh kt kl ku kp kv kw kx ky bi translated"><a class="ae jm" rel="noopener" href="/@jensen_wong/snap-it-find-it-your-shopping-companion-bot-8101494545a8">网络报废、使用CNN的特征提取和图像搜索。</a></li><li id="cbbd" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" rel="noopener" href="/@renxiang91/object-detection-using-yolov3-51baa2bbac94">使用YOLOv3进行物体检测。</a></li><li id="92cd" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" href="https://jzys-low.medium.com/object-detection-and-background-removal-with-detectron2-2242a863cc51" rel="noopener">使用Detectron2进行目标检测和背景去除。</a></li><li id="b54a" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" href="https://haomingkoo.medium.com/helping-machines-visualize-our-world-f1c489bb2da9" rel="noopener">使用各种CNN模型的进一步改进</a>(你现在在这里！)</li><li id="a248" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" href="https://jensen-wong.medium.com/a-telegram-bot-with-the-power-of-computer-vision-f415fd2efae8" rel="noopener">电报机器人和云端托管。</a></li></ul><h1 id="54c4" class="le lf hh bd lg lh li lj lk ll lm ln lo in lp io lq iq lr ir ls it lt iu lu lv bi translated">迁移学习</h1><p id="0855" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">预训练的卷积神经网络(CNN)模型是计算机视觉任务的良好起点，因为开发神经网络模型需要大量的时间和资源。使用迁移学习，模型可以重新用于第二个任务。在这个项目中，迁移学习被用于特征提取。该模型的顶层通常涉及汇集到用于分类的1D向量中，并且该模型的剩余部分用于使用从Imagenet训练的权重作为起点的特征提取。该图像通过一系列权重以给出特征向量，该特征向量可用于与另一图像的距离匹配。较短的距离意味着更接近的匹配。</p><h2 id="2151" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">预处理</h2><p id="b318" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">让我们加载您首选的数据集，并获取图像的路径。用于此简短记录的数据集具有以下结构:</p><pre class="ix iy iz ja fd mp mq mr ms aw mt bi"><span id="a1f0" class="mb lf hh mq b fi mu mv l mw mx">hipvan_image/<br/>    beds/<br/>    decor/<br/>    kids/<br/>    ....</span><span id="8db3" class="mb lf hh mq b fi my mv l mw mx">ikea_image/<br/>    Acuoustic panels &amp; acoustic arts/<br/>    Baby product/<br/>    Children/<br/>    ....</span></pre><p id="819b" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">因此，下面的代码被用来遍历文件夹以创建一个file_paths列表。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="2a62" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">分割训练集/测试集</h2><p id="4ea0" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">在这里，我们将为性能评估准备我们的训练/测试集，这将用于选择我们的图像检索使用的理想模型</p><ul class=""><li id="6021" class="kq kr hh jw b jx jy ka kb kd ks kh kt kl ku kp kv kw kx ky bi translated">删除少于5个对象的类，因为它们会在稍后拆分数据集时造成一些麻烦。</li><li id="4045" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated">将数据分成80/20训练/测试</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="dc49" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">Keras特征提取器</h2><p id="29b2" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">现在我们已经准备好了所有的数据，让我们开始有趣的部分。运行下面的代码将请求一个user_input，您可以调用它来生成一个headless模型。我们所说的无头是指神经网络的末端没有分类器。因此，我们将有一个特征向量，可用于图像检索情况下的匹配。</p><p id="6d1a" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">继续输入你看到的模型。比如xception，vgg16，inceptionv3，efficientnetb7。有关更多可用型号，请参考以下链接，了解它们在imagenet上的性能。<a class="ae jm" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank">https://keras.io/api/applications/</a></p><p id="5355" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">需要注意的是，参数越多的模型运行越慢。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="871e" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">特征提取函数</h2><p id="2425" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">随着模型摘要的显示，这意味着您已经成功地加载了模型！为了提取每幅图像的特征向量，我们将遍历之前生成的path_list。上述无头模型的conv特征在2D。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="b491" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">执行特征提取</h2><p id="de3a" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">前面定义的函数将被调用，每个图像的特征向量将被存储在numpy数组中，我们可以保存它以备将来使用！</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h1 id="df50" class="le lf hh bd lg lh li lj lk ll lm ln lo in lp io lq iq lr ir ls it lt iu lu lv bi translated">绩效指标</h1><p id="2473" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">对五个流行的模型EfficientNetB7、InceptionV3、NASNetLarge、Resnet50和VGG16进行了三次运行，以获得评估指标的平均值。为了挑选用例的最佳模型，有必要使用良好建立的评估度量和修改的度量来处理多标签方法。选择的指标是准确度、精确度和参数。宏软F1和宏F1也进行了评估，但由于多类问题而被放弃，将在本节稍后讨论。</p><h2 id="33e1" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">定义绩效矩阵</h2><p id="80d1" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">这些将在随后的部分中进一步阐述</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="f2a4" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">生成性能指标</h2><p id="1a98" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">下面的代码字符串将执行先前定义的性能指标，以确定模型的准确性/精确度。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="7aba" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">准确(性)</h2><p id="4473" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">准确性是指在所有预测中，具有正确匹配标签的图像数量。由于多标签挑战，我们选择了前5名的准确度。</p><p id="90a8" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">前5名准确度是目标类落入前5名预测类的频率的度量。在图像分类问题中，它是softmax分布的前5个值。对于用例，这是一种使标签在与被查找的单个目标标签的距离最短的前5个图像内匹配的度量。</p><p id="8978" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">前5名准确度=正确的单一类别预测数/预测数</p><p id="be01" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在本文中，使用了Top 5准确性的稍微修改的版本，其中预测的标签与目标对象多标签相匹配。</p><p id="d8ad" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">修改后的前5名准确度=多类别的正确预测数/预测总数</p><p id="0271" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">图像增强总体上提高了准确性，因为观察到错误分类的项目主要来自具有较小数据集的标签。该团队试图加入权重来平衡标签，但没有提高模型的性能。基于如图1所示和表4中汇编的前5个平均准确度和修正准确度，发现EfficientNetB7在该度量中表现优于其他模型，表明该模型最有可能在前5个最接近的匹配中返回准确的标签。NASNetLarge和ResNet50是仅次于它们的最佳型号，彼此具有可比性。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nb"><img src="../Images/29737e781593d85a2d4a5fb96c2bb799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/0*gaX3piHIYuPmjHg1"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nb"><img src="../Images/83230de0f9e4b176647ab0a546a94c15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/0*jMiAiz_xlH1MK-gF"/></div></figure><p id="a278" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">图1:前5名平均准确度和前5名修正平均准确度的条形图</p><h2 id="cf31" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">精确</h2><p id="d752" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">精度也称为正预测值，是检索实例中相关实例的比例。这对于用户接收相关搜索结果很重要。该团队建议使用与目标单个标签最接近的前5个匹配标签的精度，以及稍微修改的版本，以使前5个最接近的匹配标签与目标的多标签匹配。</p><p id="ee8f" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">前5个精度= 5个搜索中的真阳性单个标签/(真阳性+假阳性)</p><p id="1e30" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">前5个修改精度=多标签中的真阳性/(真阳性+假阳性)在5个搜索中</p><p id="64da" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">如图2的条形图所示，EfficientNetB7在精度性能指标方面名列前茅，ResNet50和NASNetLarge紧随其后。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nc"><img src="../Images/5fe73f7bdb639f13d81a4ee0ad0abd9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/0*ArbmZ1QQ_P9LRfkE"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nb"><img src="../Images/8a53de4c89746beb5315971516ab359d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/0*Syy78toLcC94FfAL"/></div></figure><p id="ea68" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">图2:前5位平均精度和前5位修正平均精度的条形图</p><h2 id="2676" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">因素</h2><p id="6866" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">需要使用更少的每秒浮点运算(FLOPS)来允许接近实时的推断。这是为了实现更快的搜索和更少的计算成本。因此，图3分享了几个散点图，这些散点图是根据前面提到的模型参数的准确度和精确度绘制的。最理想的模型落在散点图的左上方。该团队选择了EfficientNetB7作为模型，它具有中等数量的参数，同时实现了高准确度和精确度。在我们的一组实验中，性能最差的模型是VGG16，它的准确度和精度较低，但需要大量的参数。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nd"><img src="../Images/549f43c71afe00a2456c5a472a91e1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*w7NPOju7HgyU3K0Z"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nd"><img src="../Images/0db171a8051e82823d99ef17f06c09ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*YUSyj9snBruIi2NV"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nd"><img src="../Images/f7200f9c69dd3c4ec92613b5a29889c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*djhasSrb8ou5F2Rx"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nd"><img src="../Images/0917c9b1639c18578fdfd8e451562eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*43C902CqKwxXs9z0"/></div></figure><p id="0b6f" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">图3:前1/5平均准确度/精度与参数的散点图</p><p id="4d30" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">该团队尝试执行的最后一个指标是宏观F1得分，这是精确度和召回率之间的调和平均值，其中每个标签都计算平均值，并对所有标签进行平均。p和r分别是精度和召回率。这些值存储在表6中，似乎已经饱和。放下超过5个标签的对象会恶化宏F1值。最初的意图是在对权重进行微调之前获得足够高的宏观F1分数。值得注意的是，该团队也尝试过执行加权类，但没有提高宏观F1分数的性能。因此，团队根据准确度、精确度和参数确定了CNN特征提取。</p><h1 id="4e6b" class="le lf hh bd lg lh li lj lk ll lm ln lo in lp io lq iq lr ir ls it lt iu lu lv bi translated">结论</h1><p id="0c7a" class="pw-post-body-paragraph ju jv hh jw b jx lw ii jz ka lx il kc kd ly kf kg kh lz kj kk kl ma kn ko kp ha bi translated">在这次分享中，我们介绍了如何使用Keras应用程序中可用的CNN模型提取特征。同样，在EfficientNetB7很好地转移到scraped数据集并在准确性、精确度和效率方面优于各种CNN模型的情况下，模型的性能将在后面的实验结果中讨论。因此，选择EfficientNetB7作为用于特征提取的CNN，与几个流行的模型相比，它产生了更多的相关匹配。</p><p id="5b58" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">现在，有了我们手头的正确模型，让我们看看如何将它集成到您自己的Telegram bot中，并在云上托管它。继续第5部分！</p><div class="nf ng ez fb nh ni"><a href="https://jensen-wong.medium.com/a-telegram-bot-with-the-power-of-computer-vision-f415fd2efae8" rel="noopener follow" target="_blank"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">具有计算机视觉能力的电报机器人</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">Snap-it Find-it:您的购物伴侣机器人</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">jensen-wong.medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw jg ni"/></div></div></a></div><h2 id="62e2" class="mb lf hh bd lg mc md me lk mf mg mh lo kd mi mj lq kh mk ml ls kl mm mn lu mo bi translated">内容页面</h2><ul class=""><li id="b4d3" class="kq kr hh jw b jx lw ka lx kd nx kh ny kl nz kp kv kw kx ky bi translated"><a class="ae jm" rel="noopener" href="/@jensen_wong/snap-it-find-it-your-shopping-companion-bot-8101494545a8">网页废弃、使用CNN的特征提取和图像搜索</a></li><li id="f208" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" rel="noopener" href="/@renxiang91/object-detection-using-yolov3-51baa2bbac94">使用YOLOv3进行物体检测</a></li><li id="8999" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" href="https://jzys-low.medium.com/object-detection-and-background-removal-with-detectron2-2242a863cc51" rel="noopener">使用探测器2进行物体探测和背景去除</a></li><li id="557f" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" href="https://haomingkoo.medium.com/helping-machines-visualize-our-world-f1c489bb2da9" rel="noopener">使用各种CNN模型的进一步改进</a>(你现在在这里！)</li><li id="0ff2" class="kq kr hh jw b jx kz ka la kd lb kh lc kl ld kp kv kw kx ky bi translated"><a class="ae jm" href="https://jensen-wong.medium.com/a-telegram-bot-with-the-power-of-computer-vision-f415fd2efae8" rel="noopener">电报机器人和云端托管</a></li></ul></div></div>    
</body>
</html>
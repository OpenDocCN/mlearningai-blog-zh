<html>
<head>
<title>Pre-Training Strategy for Vision Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">视觉变形者的预训练策略</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/pre-training-strategy-for-vision-transformers-5b5179a15a9b?source=collection_archive---------4-----------------------#2022-04-05">https://medium.com/mlearning-ai/pre-training-strategy-for-vision-transformers-5b5179a15a9b?source=collection_archive---------4-----------------------#2022-04-05</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><h2 id="e099" class="hj hk hl bd b fp hm hn ho hp hq hr dx hs translated" aria-label="kicker paragraph"><a class="ae ge" href="https://mlearning.substack.comhttps://mlearning.substack.com" rel="noopener ugc nofollow" target="_blank">机器学习艺术</a></h2><div class=""/><figure class="ev ex is it iu iv er es paragraph-image"><a href="https://mlearning.substack.com"><div class="er es ir"><img src="../Images/52c4d84e12c33f943b0166cd018915e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3XmALzk94LBDx-_7qnvaFQ.png"/></div></a><figcaption class="iy iz et er es ja jb bd b be z dx"><a class="ae jc" href="https://mlearning.substack.com" rel="noopener ugc nofollow" target="_blank">https://mlearning.substack.com</a></figcaption></figure><p id="0066" class="pw-post-body-paragraph jd je hl jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka he bi translated">在本文中，作者提出了一种创建多模态模板的方法，该模板可用于视觉转换器的预训练。给定一个来自多个模态的小随机样本，<strong class="jf hv">多模态</strong>预训练的目标是<strong class="jf hv">重建已经被屏蔽掉的</strong>。这允许高效和有效的预训练，并具有优异的结果。</p></div></div>    
</body>
</html>
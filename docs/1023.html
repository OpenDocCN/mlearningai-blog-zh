<html>
<head>
<title>Multicollinearity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多重共线性</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/multicollinearity-6b00447a677a?source=collection_archive---------1-----------------------#2021-09-17">https://medium.com/mlearning-ai/multicollinearity-6b00447a677a?source=collection_archive---------1-----------------------#2021-09-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="9d5c" class="hf hg hh bd b fp hi hj hk hl hm hn dx ho translated" aria-label="kicker paragraph"><a class="ae ge" href="https://machine-learns.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">机器学习</a></h2><div class=""/><div class=""><h2 id="7a13" class="pw-subtitle-paragraph in hq hh bd b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je dx translated"><strong class="ak">什么</strong>、<strong class="ak">为什么、</strong>和<strong class="ak">如何解决</strong>多重共线性。</h2></div><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/543257e39de53f7f89c862785fe743fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ZGYVUEWHC5Zi5O70Lmbtg.jpeg"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx">Image by <a class="ae jv" href="https://www.analyticsvidhya.com/" rel="noopener ugc nofollow" target="_blank">Analytics Vidhya</a></figcaption></figure><p id="9767" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi ks translated"><span class="l kt ku kv bm kw kx ky kz la di">你知道</span>多重共线性对机器学习模型的<strong class="jy hr">最终精度</strong>几乎没有影响<strong class="jy hr">吗？<strong class="jy hr">那么为什么多重共线性是一个问题</strong>，它首先是什么？</strong></p><p id="3aad" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">在这篇文章中，我们将学习这些问题的答案。</p><h1 id="d27f" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">描述—</h1><ul class=""><li id="a71a" class="lt lu hh jy b jz lv kc lw kf lx kj ly kn lz kr ma mb mc md bi translated">回归模型中的假设。</li><li id="af4d" class="lt lu hh jy b jz me kc mf kf mg kj mh kn mi kr ma mb mc md bi translated">什么是Coliniarity？</li><li id="ff2d" class="lt lu hh jy b jz me kc mf kf mg kj mh kn mi kr ma mb mc md bi translated">关于多重共线。</li><li id="ff08" class="lt lu hh jy b jz me kc mf kf mg kj mh kn mi kr ma mb mc md bi translated">为什么多重共线是一个问题？</li><li id="700b" class="lt lu hh jy b jz me kc mf kf mg kj mh kn mi kr ma mb mc md bi translated">如何去除多重共线性？</li></ul><blockquote class="mj mk ml"><p id="1e9a" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated">1.<strong class="jy hr">使用VIF </strong>及其代码实现</p><p id="dfab" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated">2.<strong class="jy hr">使用相关性</strong>及其代码实现</p><p id="1139" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated">3.一个自动化上述方法的<strong class="jy hr"> python库</strong>。</p></blockquote><h1 id="9592" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">假设—</h1><p id="9dad" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">非常重要的是要知道基于回归的模型的一个假设是—</p><ul class=""><li id="eec5" class="lt lu hh jy b jz ka kc kd kf mt kj mu kn mv kr ma mb mc md bi translated"><strong class="jy hr">没有或几乎没有多重共线性，即</strong>输入要素彼此之间<strong class="jy hr">没有相关性</strong>，或者换句话说，它们彼此<strong class="jy hr">独立</strong>。</li></ul><p id="abe1" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">但通常情况并非如此，即数据集包含彼此显著相关的要素。这导致多重共线性。</p><p id="4235" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">让我们简单地看一下什么是Coliniarity。</p><h1 id="96fc" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">什么是共线性？</h1><p id="250d" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated"><strong class="jy hr">共线性</strong>或<strong class="jy hr">相关性</strong>是一种统计度量，表示两个或多个变量一起移动的程度。换句话说，<strong class="jy hr">它只是一个数字(+ve或-ve)来表示两个特征如何相互作用，就像如果一个特征增加，另一个特征增加、减少或显示随机增长。</strong></p><p id="f796" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated"><strong class="jy hr">相关性可以是正的，也可以是负的。</strong>正相关表示变量一起增加或减少。负相关表示如果一个变量增加，另一个变量减少，反之亦然。</p><h1 id="6971" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">关于多元共线—</h1><p id="040f" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">众所周知，了解影响商业公司增长的因素非常重要，这可以通过多种方式完成，其中一种方式是了解我们的机器学习模型给出的方程。让我们举个例子-</p><p id="b881" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated"><strong class="jy hr">covied 19</strong>的数量<strong class="jy hr">= 4 *面积+截距</strong>(只是一个假设)</p><p id="ce12" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">假设我们的模型给出了上述等式，该等式基本上说明了如果截距为0，那么我们可以直接说，如果面积加倍，covid案例的数量将增加4 的<strong class="jy hr">倍。你可以理解，尽可能准确地了解这个因素<strong class="jy hr"/>是非常重要的<strong class="jy hr">，因为基于此，我们应该决定每天生产的疫苗和病床数量。</strong></strong></p><h1 id="8402" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">为什么多重共线是一个问题？</h1><p id="081e" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">那么多重共线性和上面的例子有什么关系呢？</p><p id="28b1" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated"><strong class="jy hr">由于多重共线性</strong>，我们可能会获得相同因素的不同<strong class="jy hr">系数</strong>，从而导致<strong class="jy hr">错误解释</strong>，这可能会产生严重影响。例如，我们可能得到一个因子为<strong class="jy hr">2 *面积</strong>，但这将导致每日生产的<strong class="jy hr">床位</strong>和<strong class="jy hr">疫苗</strong>数量<strong class="jy hr">短缺</strong>，因此将导致每日死亡人数<strong class="jy hr">增加。</strong></p><h2 id="2c79" class="mw lc hh bd ld mx my mz lh na nb nc ll kf nd ne ln kj nf ng lp kn nh ni lr hn bi translated">总的来说，我们可以说—</h2><blockquote class="mj mk ml"><p id="6f8f" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated"><strong class="jy hr">多重共线性对这些系数有很大的负面影响，并可能导致错误的推断。</strong></p><p id="868c" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated"><strong class="jy hr">从技术上讲，它也会影响p值，而p值又会影响特征选择过程。</strong></p></blockquote><h1 id="7f37" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">如何去除多重共线性？</h1><p id="0048" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">一般来说，有两种不同的方法可以消除多重共线性—</p><blockquote class="mj mk ml"><p id="17fc" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated">1.使用相关性</p><p id="c7f3" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated">2.使用VIF(变动通货膨胀系数)</p></blockquote><h2 id="4c8f" class="mw lc hh bd ld mx my mz lh na nb nc ll kf nd ne ln kj nf ng lp kn nh ni lr hn bi translated">1.使用相关性</h2><p id="4c20" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">通常，两个特征之间的相关性大于0.7，这表明那些特征</p><p id="5a39" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">两个特征之间的相关性大于0.7表明存在多重共线性，我们应该丢弃两个特征中的一个来解决它。</p><h2 id="88a5" class="mw lc hh bd ld mx my mz lh na nb nc ll kf nd ne ln kj nf ng lp kn nh ni lr hn bi translated">代码—</h2><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="nj nk l"/></div><figcaption class="jr js et er es jt ju bd b be z dx"><a class="ae jv" href="https://gist.github.com/Sudhanshu1304/ef10339c6f78a65e3015493f053585a0" rel="noopener ugc nofollow" target="_blank">Github Gist on Multicoliniarity(Correlation)</a></figcaption></figure><h2 id="9df9" class="mw lc hh bd ld mx my mz lh na nb nc ll kf nd ne ln kj nf ng lp kn nh ni lr hn bi translated">2.<strong class="ak">变动通货膨胀系数(VIF)——</strong></h2><p id="eafd" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">有一个识别多重共线性的简单测试叫做<strong class="jy hr"> VIF </strong>(方差膨胀因子)。<strong class="jy hr"> VIF </strong>从1开始，没有上限。1到5之间的VIF被认为是适中的，但是如果VIF超过5，那么这些将被删除。</p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="08e0" class="mw lc hh nm b fi nq nr l ns nt"><strong class="nm hr">VIF = 1/(1-R2)</strong></span></pre><p id="97dd" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">R2是一个决定系数，它表明了一个预测因子能够解释响应变量变化的程度。</p><p id="57ef" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated"><strong class="jy hr">VIF为10意味着如果没有共线性，则预测值系数的方差比应有值大10倍。</strong></p><h2 id="5d54" class="mw lc hh bd ld mx my mz lh na nb nc ll kf nd ne ln kj nf ng lp kn nh ni lr hn bi translated">代码—</h2><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="nj nk l"/></div><figcaption class="jr js et er es jt ju bd b be z dx"><a class="ae jv" href="https://gist.github.com/Sudhanshu1304/e880c22aadbfb3ef23b7c2dfe174d011" rel="noopener ugc nofollow" target="_blank">Github Gist on Multicoliniarity(VIF)</a></figcaption></figure><h2 id="0bc8" class="mw lc hh bd ld mx my mz lh na nb nc ll kf nd ne ln kj nf ng lp kn nh ni lr hn bi translated">图书馆支持—</h2><p id="c400" class="pw-post-body-paragraph jw jx hh jy b jz lv ir kb kc lw iu ke kf mq kh ki kj mr kl km kn ms kp kq kr ha bi translated">您可以使用Python库<strong class="jy hr"> ModelAuto来</strong>轻松解决多列性。</p><p id="31cc" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">它有一个内置的包，可以通过这两种方法消除多重共线性。</p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="c49a" class="mw lc hh nm b fi nq nr l ns nt"><strong class="nm hr">pip install ModelAuto</strong></span><span id="3982" class="mw lc hh nm b fi nu nr l ns nt"><strong class="nm hr">from ModelAuto.Multicollinearity import handel_Multico_Corr</strong></span><span id="d4ff" class="mw lc hh nm b fi nu nr l ns nt">OR</span><span id="a7f3" class="mw lc hh nm b fi nu nr l ns nt"><strong class="nm hr">from ModelAuto.Multicollinearity import handel_Multico_VIF</strong></span></pre><h1 id="cc20" class="lb lc hh bd ld le lf lg lh li lj lk ll iw lm ix ln iz lo ja lp jc lq jd lr ls bi translated">结论—</h1><blockquote class="mj mk ml"><p id="113d" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated">多重共线性会影响系数和p值，<strong class="jy hr">，但不会影响预测、预测精度和拟合优度。因此，如果我们的主要目标只是进行预测，我们就不需要减少多重共线性。</strong></p><p id="8381" class="jw jx mm jy b jz ka ir kb kc kd iu ke mn kg kh ki mo kk kl km mp ko kp kq kr ha bi translated"><strong class="jy hr">多重共线性主要影响线性模型，如线性回归、物流回归。对KNN、决策树等非线性算法没有太大影响。</strong></p></blockquote><p id="1fc0" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">如果你觉得这些信息有帮助，可以考虑留下👏😏。</p></div></div>    
</body>
</html>
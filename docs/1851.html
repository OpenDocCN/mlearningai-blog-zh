<html>
<head>
<title>InfoGAN: learning to generate controllable images from scratch (Pytorch)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">InfoGAN:学习从零开始生成可控图像(Pytorch)</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/infogan-learning-to-generate-controllable-images-from-scratch-pytorch-31a49ffc7b98?source=collection_archive---------3-----------------------#2022-02-04">https://medium.com/mlearning-ai/infogan-learning-to-generate-controllable-images-from-scratch-pytorch-31a49ffc7b98?source=collection_archive---------3-----------------------#2022-02-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/4717e1276914d8b10a098a702c704031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4J9xmrx6zP1dLvfwW2fOA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://proceedings.neurips.cc/paper/2016/file/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Paper.pdf" rel="noopener ugc nofollow" target="_blank">https://proceedings.neurips.cc/paper/</a></figcaption></figure><p id="f9bf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">InfoGAN是原始对抗性训练方法的一种特殊变体，其中生成器学习以一种<em class="js">无监督的方式生成不同类别和属性的图像。</em>这意味着，例如，如果在使用InfoGAN训练生成器生成MNIST(数字从0到9)的图像后，您想只生成额外的<em class="js">数字“8”</em>的图像，该数字有一定程度的向右倾斜(想象一个倾斜的8)，那么在设置相应的参数后，您将能够很容易地做到这一点。</p><p id="0f83" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最棒的是，你可以在训练中不用任何标签就能做到这一点。这意味着你的模型会自动学习区分数字的类别和它们的显著属性(旋转、粗细等)，这正是我们下面要做的...</p><blockquote class="jt ju jv"><p id="81c0" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">页（page的缩写）S —本条分述如下；我们首先解释GAN理论并指出其缺点，然后继续理解InfoGAN如何修改原始架构，最后给出代码。</p></blockquote></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><h1 id="b37c" class="kg kh hh bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">甘理论🦕</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es le"><img src="../Images/8f97a41e0af5f39fbd1685297e3429b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7IU-31uImkJjpLQ2.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fgenerative-adversarial-network-gan-using-keras-ce1c05cfdfd3&amp;psig=AOvVaw0V-9nrw0oonDGDgi1vdnLu&amp;ust=1644128499845000&amp;source=images&amp;cd=vfe&amp;ved=0CAsQjRxqFwoTCLCYzJX25_UCFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">medium.datadriveninvestor.com</a></figcaption></figure><p id="5c38" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以上面的图像为参考，GAN生成器的目标是生成类似于真实数据分布的图像，以便鉴别器认为它来自真实数据而不是伪造的。另一方面，鉴别器具有相反的目的，即区分真实数据和生成的数据(假的)。</p><p id="1959" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通常，我们希望生成器学习从高维分布空间到真实数据图像空间的<strong class="iw hi"> </strong>映射，例如<strong class="iw hi">高斯分布或均匀分布</strong>。这就是为什么我们对发生器的输入是从高斯分布中采样的高维(约100)随机噪声向量，我们将其表示为<strong class="iw hi"> <em class="js"> Z </em> </strong>，并将实际数据表示为<strong class="iw hi"> X <em class="js">。</em> </strong></p><p id="af58" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们优化如下所示的最小-最大损失函数，其中<strong class="iw hi">θ</strong>分别是鉴频器的参数，<strong class="iw hi">φ</strong>分别是发生器的参数。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/0360124eced9eae3b98eee3e8323db23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*31OOIgVdI8W6Y0UBy0zjtg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">GNR 638 IIT Bombay slides</figcaption></figure><h2 id="7fbf" class="lk kh hh bd ki ll lm ln km lo lp lq kq jf lr ls ku jj lt lu ky jn lv lw lc lx bi translated">缺点</h2><p id="5e6e" class="pw-post-body-paragraph iu iv hh iw b ix ly iz ja jb lz jd je jf ma jh ji jj mb jl jm jn mc jp jq jr ha bi translated">在训练生成器之后，我们给它任意一个随机的<strong class="iw hi"> <em class="js"> Z </em> </strong>值，我们将得到一个随机生成的图像，类似于真实数据集中的图像。然而，问题是我们对生成的图像没有任何控制。比方说，我们使用每个数字有10个类别的MNIST数据集作为我们的真实数据集，并且我们想要生成许多具有某些属性的图像(<strong class="iw hi">旋转、厚度、大小<em class="js">、</em> </strong> <strong class="iw hi">等)..</strong>)但只有一个数字“7”。不幸的是，我们不能使用普通的GAN来实现这一点，我们必须使用InfoGAN来实现。</p></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><h1 id="4015" class="kg kh hh bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">信息根理论🦖</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div class="ab fe cl md"><img src="../Images/75843fb303f65dad3e00eb2679698d7d.png" data-original-src="https://miro.medium.com/v2/format:webp/0*0I3SGqrKhFhdntKU.png"/></div></figure><p id="b03a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如上图所示，与原始GAN相比，InfoGAN中的额外修改是<strong class="iw hi">潜在变量c1和c2 </strong>，它们作为生成器的输入，由鉴别器从生成的图像(假图像)中强制预测。</p><h2 id="a08b" class="lk kh hh bd ki ll lm ln km lo lp lq kq jf lr ls ku jj lt lu ky jn lv lw lc lx bi translated">输入</h2><p id="dd2d" class="pw-post-body-paragraph iu iv hh iw b ix ly iz ja jb lz jd je jf ma jh ji jj mb jl jm jn mc jp jq jr ha bi translated">现在，这些潜在变量基本上是随机数的别出心裁的名字，随机数有两种类型:</p><ol class=""><li id="b08f" class="me mf hh iw b ix iy jb jc jf mg jj mh jn mi jr mj mk ml mm bi translated"><strong class="iw hi"> c1 —一个热点编码</strong> —例如在MNIST，我们有10个类，如果我们想学习生成特定于类的图像，那么c1是一个随机的一个热点变量是有意义的。在训练之后，该模型自动学习将独热编码标签与特定类别相关联，并且仅生成该类别的图像。</li><li id="9cc7" class="me mf hh iw b ix mn jb mo jf mp jj mq jn mr jr mj mk ml mm bi translated"><strong class="iw hi">C2——在<strong class="iw hi"> -1 &amp; 1 </strong>之间的一个随机连续实数</strong>。生成的图像的其他方面，如向左或向右倾斜的程度，在本质上是连续的，如果我们想对它们建模，它们需要一个连续的随机变量。例如，如果我想控制我的手指的<strong class="iw hi">旋转角度</strong>，那么将c2从<strong class="iw hi"> -1改变为1 </strong>将意味着从向左倾斜到向右倾斜改变旋转角度，反之亦然。</li></ol><blockquote class="jt ju jv"><p id="10a5" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><em class="hh">注意——这些潜在变量是随机的，这里的任何地方都没有使用类别标签Y。该模型自动学习将一个类附加到一个独热编码中。</em></p></blockquote></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><h2 id="f672" class="lk kh hh bd ki ll lm ln km lo lp lq kq jf lr ls ku jj lt lu ky jn lv lw lc lx bi translated">该模型如何将潜在变量与生成的图像相关联？</h2><p id="a855" class="pw-post-body-paragraph iu iv hh iw b ix ly iz ja jb lz jd je jf ma jh ji jj mb jl jm jn mc jp jq jr ha bi translated">如上图所示，还有一个修改，即来自生成图像的<strong class="iw hi"> Q </strong>网络预测<strong class="iw hi">C1&amp;C2</strong>(潜在变量)——<strong class="iw hi">G(X/C1，C2)</strong>。不要害怕<strong class="iw hi"> Q </strong>，这个网络可以只是一个普通的<strong class="iw hi"> softmax </strong>或<strong class="iw hi"> nn.linear层</strong>在鉴别器的上面，事实上这就是原作者使用的。</p><p id="fff1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，这样做的整个逻辑是，我们首先使用我们的生成器'<strong class="iw hi"> G </strong>'生成假图像，通过给它<strong class="iw hi"> Z，c_1和c_2 </strong>作为我们的输入，我们将生成的图像表示为<strong class="iw hi"> G(X / c_1，c_2 ) </strong>。现在，我们将生成的图像传递给鉴别器，鉴别器输出真实/伪造分数，我们还强制它完全从图像中预测输入值<strong class="iw hi">C1和C2</strong>。这样，在正确训练我们的模型后，鉴别器自动学习将潜在变量C的某些值附加到生成的图像，类似地，生成器也根据潜在变量C生成某些类别/属性的图像。</p><p id="224a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们必须有一个适当的损失函数，其目标是实现上述目标。幸运的是，这可以通过在<strong class="iw hi">原始g an损耗</strong>上增加一项来轻松实现。这个术语叫做<strong class="iw hi">互信息</strong>，用<strong class="iw hi">‘I’</strong>表示。并且它的目标是在给定潜变量<strong class="iw hi"> C (c_1 &amp; c_2) </strong>的指定值的情况下，最小化生成图像X中的不确定性。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/9b52897be1de76a21f91a6291393ec44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*naDmaKvcMBiafZ_QB6RDLA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">GNR 638 IIT Bombay slides</figcaption></figure><p id="b682" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">互信息通常是鉴别器给出的<strong class="iw hi"> C </strong>的<strong class="iw hi">地真值</strong>输入值<strong class="iw hi"> </strong>与<strong class="iw hi">预测值</strong>之间的<strong class="iw hi">交叉熵损失</strong>或<strong class="iw hi"> MSE损失</strong>。</p></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><h1 id="8de2" class="kg kh hh bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">Pytorch代码👩‍💻</h1><p id="1fa4" class="pw-post-body-paragraph iu iv hh iw b ix ly iz ja jb lz jd je jf ma jh ji jj mb jl jm jn mc jp jq jr ha bi translated">在本例中，我们使用Pytorch数据加载器加载MNIST数据集，批量大小为64。除此之外，我们还将所有图像归一化，使像素值介于-1和1之间。这有助于稳定的训练和更快的收敛。</p><blockquote class="jt ju jv"><p id="0213" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><em class="hh">注—查看</em><a class="ae it" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank"><em class="hh"/></a><a class="ae it" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank"><em class="hh">https://github.com/soumith/ganhacks</em></a><em class="hh">了解更多训练技巧。</em></p></blockquote><p id="839d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于我们的G<strong class="iw hi">generator神经网络，</strong>注意我们如何在输入中包括Z、c_1(称为“标签”，因为与数据集的类数量相同)和c_2(表示为“代码”，我们使用2个连续变量)。我们通过CNN层传递输入，直到我们得到一个和MNIST一样大小的上采样图像。</p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mt mu l"/></div></figure><p id="a083" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来对于<strong class="iw hi">鉴别器神经网络</strong>，我们对其进行编码，以将输入作为我们生成的图像，并在我们的最后一层给出三个输出。正如您在forward函数中看到的，我们使用<strong class="iw hi"> sigmoid </strong> (self)输出一个<strong class="iw hi">真实度分数</strong>。adv)，标签预测使用<strong class="iw hi"> softmax </strong>用于<strong class="iw hi"> c_1 </strong> (self.catag)，以及一个<strong class="iw hi">线性层</strong>用于回归代码或连续变量<strong class="iw hi"> c_2 </strong> (self。续)。我们在CNN层之后使用退出和批量规范，因为在实践中观察到它导致更稳定的训练。</p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mt mu l"/></div></figure><p id="d987" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面我们定义<strong class="iw hi">损失函数</strong>用于训练发生器、鉴别器和两个网络的互信息损失。对于信息损失，我们对C1使用<strong class="iw hi">交叉熵，对C2</strong>使用<strong class="iw hi"> MSE损失。</strong></p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mt mu l"/></div></figure><p id="d00a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，我们使用<strong class="iw hi"> Adam优化器</strong>来训练两个网络，并使用<strong class="iw hi"> itertools.chain </strong>来堆叠两个网络参数以训练信息丢失，因为我们希望在优化互信息的同时更新生成器和鉴别器的权重。</p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mt mu l"/></div></figure><p id="93f2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们将上述所有内容放入一个训练循环中，我们就完成了。</p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mt mu l"/></div></figure></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><h1 id="9468" class="kg kh hh bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结果🐈</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/42b1c60b80a3003c563a272ed4744e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*oT7e6H3Ap0-862tNnk8P0Q.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://proceedings.neurips.cc/paper/2016/file/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Paper.pdf" rel="noopener ugc nofollow" target="_blank">https://proceedings.neurips.cc/paper/2016/file/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Paper.pdf</a></figcaption></figure><p id="7642" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们以矩阵形式绘制图像，其中沿着每一行我们改变独热编码向量C1，并且我们看到模型已经学会在类别之间分离。在各列中，我们使用两个连续的潜在变量，所以我们保持一个不变，而将另一个从-1变化到1。我们对另一幅图像重复同样的操作。我们观察到第一幅图像捕捉旋转，第二幅图像捕捉笔画的粗细。这些属性随潜在变量C2成比例变化。</p><p id="9045" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有了这个模型，我们就有能力从数据集生成新的图像，同时控制类和属性，只需指定C1和C2的值作为生成器的输入。</p></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><p id="498a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">谢谢你走到这一步，我希望你能学到一些新东西！</p><div class="mw mx ez fb my mz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hi fi z dy ne ea eb nf ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">medium.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn in mz"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Hugging Face + Keras: a Modern Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">拥抱脸+角膜:一种现代的方法</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/hugging-face-keras-a-modern-approach-980aa3e5b38e?source=collection_archive---------6-----------------------#2022-09-28">https://medium.com/mlearning-ai/hugging-face-keras-a-modern-approach-980aa3e5b38e?source=collection_archive---------6-----------------------#2022-09-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f423" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">受众— Keras (DL Pyton framework)用户，他们有兴趣改善拥抱脸集成，提高计算时间、准确性并简化代码结构。</p><p id="19bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您曾经使用HF + Keras构建过文本分类器，这是为您准备的。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/7b8be9bdfe11e6f295263a439aa429b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/0*qLSsVaNZpkKBY1Ds.jpg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Yes this is the original quote from the movie.</figcaption></figure><h1 id="3dd6" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><p id="b338" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">为什么我会想到这个？因为我已经创建了一个Distilbert的扩展，作为一个序列模型，但是有固定的输入。这样做实际上迫使我有固定的输入，完全填充到512。这浪费了大量的计算周期。</p><p id="dba6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这让我很困扰，HF是如何在没有固定输入的情况下实现Keras模型的？我必须弄清楚。</p><p id="28e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，我可能是地球上最后一个使用Keras进行深度学习的人，因为每个人都在PyTorch火车上跳跃。但作为忠实于一夫一妻制框架的我(弗朗索瓦·乔莱是罪魁祸首)，我不得不想办法适应时代。</p><p id="4fc6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个博客是对这段有趣旅程的回忆。</p><h1 id="58f4" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">你会学到什么</strong></h1><ol class=""><li id="41de" class="kr ks hh ig b ih km il kn ip kt it ku ix kv jb kw kx ky kz bi translated">创建Keras HF模型<br/>的所有不同方法——最有效——通过子类化</li><li id="bc3f" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">子类化带来的问题的解决方案</li><li id="8000" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">对HF Bert模型实施的深入理解</li></ol><h1 id="ed27" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">词汇</h1><p id="47c8" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated"><strong class="ig hi">首选车型</strong>——<a class="ae lf" href="https://huggingface.co/distilbert-base-uncased" rel="noopener ugc nofollow" target="_blank">蒸馏酒脱壳</a>除了受欢迎没有具体原因。仅这个月就有750万次下载</p><p id="b19a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输入维度</strong> — Distilbert接受多达510个单词片段，向它们添加一个开始标记和一个结束标记，我们得到已知的512个数字。为了简化，我们可以把单词想象成单词片段，作为一种有用的类比。这意味着Distilbert可以计算多达510个单词的句子。</p><p id="158b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">HF  — Fugging Face，加载SOTA预训练模型的框架。基本模型可用于微调您的数据。</p><p id="d916" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">计算时间</strong>——所有以“ms”表示的计算时间都是在我的CPU上完成的，我将它们视为数量级的记录，而不是精确的数字。</p><p id="e39a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">灵感</strong> —这篇<a class="ae lf" href="https://huggingface.co/blog/tensorflow-philosophy" rel="noopener ugc nofollow" target="_blank"> HF文章</a>提出了这条途径，但缺乏全面的实施和警告概述</p><p id="7fa5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Keras背景</strong>—Keras的神给了我们3种实现Keras模型的方法。顺序、功能和子类化。子类化在大多数用例中很少见，这就是我要利用的。你可以阅读<a class="ae lf" href="https://pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/" rel="noopener ugc nofollow" target="_blank">这篇</a>来获得关于差异的可靠解释。</p><h1 id="c598" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">TF/Keras + HF的常见实现</h1><ol class=""><li id="3139" class="kr ks hh ig b ih km il kn ip kt it ku ix kv jb kw kx ky kz bi translated">标准—端对端使用高频，Keras是培训师。<a class="ae lf" href="https://huggingface.co/docs/transformers/main/en/training" rel="noopener ugc nofollow" target="_blank"> HF教程</a></li><li id="6104" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">中级—使用Keras API在HF分类器之上构建</li></ol><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lg lh l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Example of intermediate way — GlobalMaxPool you are my favorite layer</figcaption></figure><h2 id="d063" class="li jp hh bd jq lj lk ll ju lm ln lo jy ip lp lq kc it lr ls kg ix lt lu kk lv bi translated">为什么不用<strong class="ak">标准的</strong>方式？</h2><ol class=""><li id="4d14" class="kr ks hh ig b ih km il kn ip kt it ku ix kv jb kw kx ky kz bi translated">这实现了动态输入的目标，但是<strong class="ig hi">将你绑定到</strong>我认为是<strong class="ig hi">的参数化分类器</strong>。</li><li id="9c6e" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated"><strong class="ig hi">除了标准的softmax分类器，您还需要什么吗？</strong>即使添加基于多标签的sigmoid NN也不是HF的直截了当。</li><li id="df8f" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated"><strong class="ig hi">你想提高精度</strong> — HF通过使用最后一个隐藏状态的第一个向量——CLS向量(768维)来实现分类器。阅读<a class="ae lf" href="https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently" rel="noopener ugc nofollow" target="_blank">这个关于如何改进的</a>建议(例如，我更喜欢最大池)</li></ol><h2 id="1b0c" class="li jp hh bd jq lj lk ll ju lm ln lo jy ip lp lq kc it lr ls kg ix lt lu kk lv bi translated">为什么不用中间的方式呢？</h2><ol class=""><li id="72bb" class="kr ks hh ig b ih km il kn ip kt it ku ix kv jb kw kx ky kz bi translated">计算时间长—常用的方法是定义固定输入。这将需要对所有后面的样本进行填充，而不管它们的长度如何。假设您设置了维度输入512，那么每个样本平均需要400-500毫秒。<strong class="ig hi">即使是只有一个字的句子:“嘿”，为了避免因形状不匹配而导致的网络错误，你也必须完全填充它。</strong></li><li id="7a9a" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">由于截断而降低精度-为了避免计算时间过长，您可以将输入维度设置为128，然后进行约100毫秒的推断。长句怎么办？你将不得不截断它们，到128，这有可能降低精确度。想象一下，你可以阅读这篇文章，但只能阅读它的前128个单词。这可能会妨碍你的理解。同样，短句不必要地增加到了128个。</li></ol><h1 id="7f1b" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">子类化Keras模型类</h1><p id="d2ba" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">对Keras模型进行子类化是一种创建神经网络架构的方法，而无需显式声明。这是一种更高级、更简单的方法，但也为您提供了最大的灵活性。<strong class="ig hi">这就是让HF拥有非固定输入维度的果汁！</strong></p><p id="aaa0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里有一个来自HF代码库的例子</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es lw"><img src="../Images/623dce65cc92768dcdc4682de03c1db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4WQD_sEIaDXeLIefnVb67w.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Here is my proof — tf.keras.Model. TFPreTrainedModel is inheriting a Keras Model</figcaption></figure><p id="5215" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我为自己的例子添加了一个要点——解释如下</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lg lh l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Keras model that accepts many types of HF models</figcaption></figure><h2 id="f466" class="li jp hh bd jq lj lk ll ju lm ln lo jy ip lp lq kc it lr ls kg ix lt lu kk lv bi translated">逐行</h2><p id="1961" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">这是与我在上面添加的<code class="du mb mc md me b">get_model</code>相同的神经架构(在通用实现下),所以我不会再赘述。</p><p id="5e83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第5行:<code class="du mb mc md me b">class HFKerasModel(tf.keras.Model)</code>我们继承了tf.keras.Model，它为我们的类提供了预定义的方法，比如默认的<code class="du mb mc md me b">build</code>、<code class="du mb mc md me b">fit</code>等等。</p><p id="6a3d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第11行:<code class="du mb mc md me b">self.base_model = TFAutoModel.from_pretrained(base_model_path)</code>我们可以接受各种HF模型，例如基于蒸馏的外壳、基于蒸馏的非外壳等等。</p><p id="3ccb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第17–21行:为了构建架构，您必须<code class="du mb mc md me b">call</code>建模。</p><p id="9e23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第23–25行:装载重量(如果提供)</p><p id="4334" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第27行:我们定义了向前传球，<code class="du mb mc md me b">training</code>是一个参数，因为一些层的行为不同，取决于我们是否在训练中。</p><p id="6826" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么为什么我们不需要固定输入呢？因为我们隐式地定义了我们的前向传递，神经网络变量将被延迟地创建。这意味着性能的巨大提升！没必要把一切都推给麦克斯。</p><h2 id="5230" class="li jp hh bd jq lj lk ll ju lm ln lo jy ip lp lq kc it lr ls kg ix lt lu kk lv bi translated">警告</h2><ol class=""><li id="d7f0" class="kr ks hh ig b ih km il kn ip kt it ku ix kv jb kw kx ky kz bi translated">需要给类添加一个<code class="du mb mc md me b">call</code>方法</li><li id="d514" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">需要在预测或加载权重之前调用模型</li><li id="d8a7" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">需要<code class="du mb mc md me b">fit</code>总结之前的模式</li><li id="5a8e" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">通过<code class="du mb mc md me b">model = HFKerasModel(targets=1); model.save_weights(save_path)</code>保存模型</li></ol><h1 id="2a10" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">摘要</h1><p id="b2f4" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我从一个观察开始，HF使用动态输入来提高性能。理解HF如何实现这一壮举使我进入了这个有趣的兔子洞，它实际上允许更多令人兴奋的机会，比如在我的模型中有更多的定制逻辑。例如，我可以使用3-4种不同的HF模型，并连接它们的输出。我为什么要这么做？也许我想有几种形式，如语音、文本和视觉。</p><p id="7c69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除此之外，即使对于文本分类器的原始用例，我认为采用最佳标准并通过Keras子类化充分利用HF也是很重要的。</p><p id="d8af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望你觉得这很有用！</p><p id="5eb9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不要脸的插头——如果你对改善公司的客户服务感兴趣，请访问<a class="ae lf" href="http://www.loris.ai" rel="noopener ugc nofollow" target="_blank"> www.loris.ai </a>了解更多信息。</p><div class="mf mg ez fb mh mi"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hi fi z dy mn ea eb mo ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">medium.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw ji mi"/></div></div></a></div></div></div>    
</body>
</html>
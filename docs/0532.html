<html>
<head>
<title>COVID/Non-COVID Classifier with SOTA Vision Transformer Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有SOTA视觉转换器模型的COVID/非COVID分类器</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/covid-non-covid-classifier-with-sota-vision-transformer-model-97375c774ff7?source=collection_archive---------1-----------------------#2021-05-10">https://medium.com/mlearning-ai/covid-non-covid-classifier-with-sota-vision-transformer-model-97375c774ff7?source=collection_archive---------1-----------------------#2021-05-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="680f" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">《变形金刚》重访——为什么是当下的需要？</h2></div><p id="b9b2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">作者:</strong><strong class="iy hi">Ajay Arunachalam——高级数据科学家&amp;研究员(AI) </strong></p><p id="132a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://github.com/ajayarunachalam" rel="noopener ugc nofollow" target="_blank"> Github </a></p><p id="0bf2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://www.linkedin.com/in/ajay-arunachalam-4744581a/" rel="noopener ugc nofollow" target="_blank">领英</a></p><p id="968f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你好，朋友们。我希望这对你来说是一次愉快的阅读经历。我会尽量把这篇文章限制在一定范围内&amp;更侧重于实践和应用演示，而不仅仅是理论解释。通过这篇博文，我们将了解最先进的(SOTA)模型——“T8”变压器。首先，我们将快速浏览transformer模型的基础知识，给你一个简要的概述。最后，我们将通过实施视觉转换器网络架构来展示一个实际的计算机视觉问题。</p><p id="ab81" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">计算机视觉问题和应用已经取得了巨大的成功，无论是将图像表示为像素阵列，还是对高度局部化的特征进行卷积等等。CNN作为最先进的架构已经使用了很长时间，在机器视觉领域具有广泛的可用性。但是，卷积网络的一个主要缺点是<strong class="iy hi">卷积对所有图像像素一视同仁，不管它们的重要性如何</strong>；<strong class="iy hi">不考虑上下文，无法将空间上距离较远的概念联系起来</strong>。在本文中，我们将看到变压器如何成为取代CNN的理想候选？但是，在此之前，让我们简单了解一下什么是变压器模型？为什么这些架构现在变得越来越流行&amp;越来越多的使用？与变形金刚相关的最新发展有哪些？等等等等。</p><ul class=""><li id="ba4f" class="jt ju hh iy b iz ja jc jd jf jv jj jw jn jx jr jy jz ka kb bi translated"><strong class="iy hi">通俗地说有哪些变压器型号？</strong></li></ul><p id="fed8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">变形金刚是一个非常有趣的<strong class="iy hi">深度学习架构家族，</strong>于2017年推出(谷歌大脑)。它主要用于自然语言处理(NLP)领域，但最近的研究也将其应用于计算机视觉的其他复杂任务。任何变压器架构的基本操作都是<strong class="iy hi">自关注操作</strong>。那么自我关注到底是什么呢？注意机制是变压器网络最关键的方面。注意力机制使得这个SOTA模型超越了典型的RNN或LSTM模型的注意力限制。传统的序列到序列模型丢弃所有中间状态，并且在初始化解码器网络以生成关于输入序列的预测时，仅使用最终状态/上下文向量。丢弃一切，但是当输入序列相当小时，最终的上下文向量工作正常。当输入序列的长度增加时，使用这种方法时模型的性能会下降。这是因为很难将一个长的输入序列概括为一个向量。解决方案是增加模型的<strong class="iy hi">注意力</strong><strong class="iy hi">，利用中间编码器状态为解码器构建上下文向量。</strong>因此，简而言之，当为任何给定的标记创建编码时，注意机制定义了其他输入标记对模型的重要性。</p><p id="1502" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在注意机制中，你期望数据'<strong class="iy hi"> V' </strong>的表示与某个<strong class="iy hi">概率质量函数</strong>相关，从而计算上下文向量，它本质上是你的数据的汇总统计(加权平均值)</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es kc"><img src="../Images/f56253dc9a1b3e7205597f31e56b2238.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*byQNPyJ6F3oZAKKbEgQ-Xw.png"/></div></div></figure><p id="29ee" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">转换器是许多神经网络设计中使用的组件，用于<strong class="iy hi">处理顺序数据</strong>，如<strong class="iy hi">文本数据</strong>、<strong class="iy hi">基因组序列</strong>、<strong class="iy hi">声音信号或时间序列数据</strong>。变压器神经网络的大多数应用是在自然语言处理(NLP)领域。<strong class="iy hi"> Transformer模型已经成为NLP任务的领跑者。作为一个例子，我相信你已经看过了令人惊叹的GPT2/GPT3变压器演示和相关资料。但即使在NLP之外，你也能在计算机视觉和音乐生成领域找到变形金刚。</strong>在过去，语言建模问题(简单地说，预测下一个单词)和翻译系统的最新方法是LSTM和GRU架构以及注意力机制。然而，这些架构的主要问题是它们本质上是循环的，并且它们的运行时间随着序列长度的增加而增加。换句话说，这些体系结构接受一个句子，并按顺序处理每个单词，因此随着句子长度的增加，整个运行时也会增加。</p><p id="eaed" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">transformer体系结构首先在论文“<strong class="iy hi">注意力是你所需要的全部</strong>”中进行了解释，它放弃了这种循环，而是完全依靠注意力机制来绘制输入和输出之间的全局依赖关系。</p><h2 id="31a7" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">下面是完整变压器的图片，取自本文中引用的论文<a class="ae js" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">。</a></h2><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es lj"><img src="../Images/f600168b2a920d385ee47a72793e1110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wpBcNdRQ1PVIN3yDLDl_kg.png"/></div></div></figure><p id="f36d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">那么，transformer模型具体做什么呢？</strong>transformer模型可以执行几乎所有的NLP任务。我们可以用它来进行<strong class="iy hi">语言建模</strong>、<strong class="iy hi">翻译</strong>，或者<strong class="iy hi">分类</strong>，它通过去除问题的顺序性来快速完成这些任务。在机器翻译应用程序中，转换器将一种语言转换成另一种语言。对于分类问题，它使用适当的输出层提供分类概率。一切都取决于网络的最终输出层，但转换器的基本结构对于任何任务都非常相似。作为一个例子，让我们仔细看看机器翻译过程。</p><p id="d1fe" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从远处看，下图显示了变压器模型的平移效果。它接受一个英语句子作为输入，并返回一个瑞典语句子。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es lk"><img src="../Images/cec658043d7aa08da3ad273c8faf70ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zEKcAMGWB9DNPcYMcn7dQ.png"/></div></div></figure><p id="b179" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">变压器本质上是编码器和<strong class="iy hi">解码器</strong>层的<strong class="iy hi">堆栈。因此，对于语言建模问题(英语到瑞典语的翻译)，编码器层的作用是使用注意机制将我们的英语句子编码成数字形式。另一方面，解码器的目标是使用来自编码器层的编码信息来为我们提供瑞典语翻译。在下图中，变压器被给予一个英语句子作为输入，该句子使用6个编码器层进行编码。最终编码器层的输出然后进入每个解码器层，将英语翻译成瑞典语。</strong></p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es ll"><img src="../Images/b7888063c9388882062f3d98c859f2d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qn4BWApg-uUBE04ji-dsQA.png"/></div></div></figure><ul class=""><li id="a8ab" class="jt ju hh iy b iz ja jc jd jf jv jj jw jn jx jr jy jz ka kb bi translated"><strong class="iy hi">变压器神经网络的应用？</strong></li></ul><p id="7acf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">变压器神经网络可用于许多序列相关的深度学习任务，例如机器翻译(如上所述)、信息检索、文本分类、文档摘要、图像字幕、基因组分析、音乐生成、声音信号或时间序列数据、机器视觉任务等。</p><ul class=""><li id="ffb6" class="jt ju hh iy b iz ja jc jd jf jv jj jw jn jx jr jy jz ka kb bi translated"><strong class="iy hi">为什么这些架构如今变得越来越流行&amp;越来越常用？</strong></li></ul><p id="1913" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从2019年开始，谷歌搜索开始使用谷歌的transformer神经网络<strong class="iy hi"> BERT </strong>进行超过70种语言的搜索查询。在这一变化之前，许多信息检索是基于关键词的，这意味着谷歌在没有强有力的上下文线索的情况下检查其抓取的网站。以单词“bank”为例，它可以根据上下文有多种含义。谷歌搜索引入了transformer神经网络，这意味着谷歌可以更好地理解诸如“<strong class="iy hi"> from </strong>或“<strong class="iy hi"> to </strong>”等词影响含义的查询。用户可以用更自然的英语进行搜索，而不是根据他们认为谷歌能理解的内容来调整他们的搜索查询。来自谷歌博客的一个例子是查询“<strong class="iy hi"> 2019巴西旅行者去美国需要签证。</strong>“单词“<strong class="iy hi">到</strong>的位置对于正确解释查询非常重要。以前的Google Search实现不能捕捉到这种细微差别，并返回关于美国公民去巴西旅游的结果，而transformer模型返回更多相关页面。transformer架构的另一个优点是，一种语言的学习可以通过迁移学习转移到其他语言。谷歌能够采用经过训练的英语模型，并将其轻松应用于其他语言的谷歌搜索。</p><p id="acb6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此外，这里的另一个重要问题是，为什么我们试图取代卷积神经网络(CNN)用于计算机视觉应用？这是因为变压器可以有效地使用更多的内存，并且在处理非常复杂的任务时更加强大。这当然是根据你有数据训练它的事实。注意力允许transformer架构以并行方式进行计算。与CNN相比，它可以同时从输入及其相互关系中提取我们需要的所有信息。</p><ul class=""><li id="84bd" class="jt ju hh iy b iz ja jc jd jf jv jj jw jn jx jr jy jz ka kb bi translated">与变形金刚相关的最新发展有哪些？(仅2021件作品* —有很多，但只是随机选取了一件作品)</li></ul><p id="7a00" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一)<a class="ae js" href="https://arxiv.org/abs/2103.14030" rel="noopener ugc nofollow" target="_blank">来自微软研究院的畅游变形金刚</a></p><p id="9def" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">提出了一种使用移位窗口的分层视觉变换器。</p><p id="5a14" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第一阶段流程:-</p><p id="99b3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，像大多数计算机视觉任务一样，一幅RGB图像被发送到网络。该图像被分割成小块，每个小块被视为一个令牌。这些表征特征是像素本身的RGB值。与NLP相比，您可以将此视为整体图像是句子，每个补丁是该句子的单词。自我关注被应用在每个补丁上，这里被称为窗口。然后，窗口被移动，导致新的窗口配置来再次应用自我注意。这允许在窗口之间创建连接，同时保持这种窗口结构的计算效率。与卷积神经网络相比，这是非常有趣的，因为它允许出现长距离像素关系。</p><p id="9311" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第二阶段及后续阶段:-</p><p id="e76b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第二阶段与第一阶段非常相似，但在这里，它将每组两个相邻面片的特征连接起来，将分辨率下采样为原来的两倍。这个过程在阶段3和4中重复两次，产生与典型卷积网络(如雷斯网和VGG)相同的特征映射分辨率。</p><p id="d8cd" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">既然我们已经对这个SOTA架构有了清晰的了解，那么让我们来看看它在现实世界中的应用。</p><h1 id="c208" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">用例</h1><p id="e34d" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated"><strong class="iy hi">我们将通过实现一个视觉转换器模型来看到一个实际动手的演示示例。</strong></p><p id="c0d9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">今天，全人类都在与疫情病毒作斗争，这场危机是由去年1月初影响数百万人生命的高传染性新冠肺炎病毒引起的。我们正在尝试所有不同的方法来诊断新冠肺炎:逆转录聚合酶链反应(RT-PCR)测试，抗体测试，CT扫描等。虽然RT-PCR是最推荐的新冠肺炎诊断方法，但测试可能需要几个小时/几天才能完成。此外，抗体测试只有在患者对病毒产生免疫力后才有用。使用CT扫描进行诊断是有前途的，并且可以用于补充RT-PCR/抗原检测过程。然而，许多最近的研究已经使用人工智能来诊断新冠肺炎感染的肺部图像，以增强放射科医生的分析。</p><p id="44ec" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的<strong class="iy hi">视觉转换器covid型号</strong>如下图所示。该模型是将输入分类为COVID样本/非COVID样本的二元分类器。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mc"><img src="../Images/474aee3a76880cbf147adb5ce401d60f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_hmsaIf0mKfmVwmq"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Vision Transformer Neural Network — COVID Classifier</figcaption></figure><h1 id="8fd0" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">资料组</h1><p id="bf33" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">我们将使用来自新冠肺炎CT大挑战的开源数据集，这是一组超过750个PNG的肺部CT图像，其中大约一半是新冠肺炎阳性。或者，您可以直接从<a class="ae js" href="https://drive.google.com/file/d/1qyg2_WtnMpusXfgnFV16vFpyraUV48vx/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>下载重命名的数据文件。为了简单起见，这些文件被重命名为目录结构“<em class="mh">训练</em>”&amp;“<em class="mh">测试</em>”下的covid &amp; non_covid样本，并带有编号。</p><p id="cf01" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们来看看数据集中的一些示例图像。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mi"><img src="../Images/b94cb57d185f07520d4b63599845484e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ueif6y48h33a8N-yGXPCIA.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx">Non-Covid vs. Covid Sample (L-R)</figcaption></figure><p id="9e3b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你也许能猜到右边的图像可能是新冠肺炎阳性。为什么？因为左叶浑浊的白色区域是磨玻璃样阴影(GGO)的一个例子，这是在肺部CT扫描中识别新冠肺炎的关键特征之一。正如你在左边的图片上看到的，没有这种毛玻璃外观的痕迹。但是，注意包含毛玻璃特征的肺部CT扫描<strong class="iy hi">并不总是新冠肺炎阳性</strong>；还有其他疾病，如传染病、间质性肺病和急性肺泡疾病，也在肺部CT扫描中显示GGO。让我们看看另一个随机的例子。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es mj"><img src="../Images/9349c3ace83362e8b7f8fb26ea51766e.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/0*J8G0DAoKrXb3ZLOI"/></div><figcaption class="md me et er es mf mg bd b be z dx">COVID infected lung CT scan</figcaption></figure><p id="760f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你怎么想呢?这被证明是新冠肺炎阳性，因为两个肺叶都有GGO。这不是一个更难的例子吗，因为GGO地区看不清楚？免责声明:-并不是所有的图像都很容易根据多云的白色区域特征进行分类。</p><p id="3863" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们看看，如果一个变压器网络可以更好地分类这些图像。</p><p id="bbf5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">那么，我们开始吧。请注意，这篇博客中的所有代码都可以在我的<a class="ae js" href="https://github.com/ajayarunachalam/vision-transformer-demo" rel="noopener ugc nofollow" target="_blank"> GitHub Transformer模型库</a>中找到。</p><h1 id="d2b8" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">模型管道</h1><p id="eae8" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">下图说明了一般的工作流程-预处理数据、构建模型、训练网络和测试模型性能。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mk"><img src="../Images/5e9899347f50cc65f57c63e63bdf6105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtPyNqxgfq1CIlvYUDEq3g.png"/></div></div></figure><h2 id="13f5" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">导入必要的库</h2><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="0e19" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">配置模型设置</h2><p id="3621" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">在这里，我们定义和配置训练参数。我们设置了训练模型的时期数、学习率、批量大小、默认图像大小、gamma，并为可重复性固定了一个种子。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="069f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，完成硬件选择，然后设置目录结构，将“png”和“jpg”图像附加到训练和测试列表，使用分割和适当的标识符基于文件名读取标签，显示来自训练集的少量随机图像，并创建训练验证测试集。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="560a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第一步是决定是否要在GPU上训练。我有一个<strong class="iy hi"> Nvidia GeForce GTX GPU </strong>，但对于这个演示，我将坚持CPU，如果假设，我们没有GPU。注意:-如果您的本地设备上没有CUDA，设置GPU可能是一个非常复杂的过程。</p><h2 id="d190" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">数据预处理</h2><ol class=""><li id="88bc" class="jt ju hh iy b iz lx jc ly jf mn jj mo jn mp jr mq jz ka kb bi translated">读取图像并将它们标记为COVID/NON-COVID</li><li id="325d" class="jt ju hh iy b iz mr jc ms jf mt jj mu jn mv jr mq jz ka kb bi translated">调整图像大小</li><li id="afe5" class="jt ju hh iy b iz mr jc ms jf mt jj mu jn mv jr mq jz ka kb bi translated">将数据分成训练集、验证集和测试集</li><li id="3ec2" class="jt ju hh iy b iz mr jc ms jf mt jj mu jn mv jr mq jz ka kb bi translated">将图像转换为PyTorch张量</li><li id="94c2" class="jt ju hh iy b iz mr jc ms jf mt jj mu jn mv jr mq jz ka kb bi translated">添加图像增强</li></ol><p id="e64d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于train &amp; test目录中的每个图像，我们读入具有RGB通道的图像，将图像的大小调整为(224，224)并将图像及其相关标签附加到列表中。然后我们给图像加标签，<strong class="iy hi"> 1 </strong>代表<strong class="iy hi"> COVID阳性</strong>，而<strong class="iy hi"> 0 </strong>代表<strong class="iy hi"> COVID阴性</strong>。注意:tqdm库用于创建进度条。现在，我们必须将数据分为训练集、验证集和测试集，并将它们转换为PyTorch张量。</p><p id="04a1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在PyTorch中，数据加载器用于创建成批的训练图像，并对图像应用变换。因此，我们必须将我们的代码包装到一个数据集类中，我们可以将该数据集类与任何相关的转换一起提供给DataLoader对象。<strong class="iy hi"> __init__ </strong>方法被格式化以适合数据集类。必须覆盖<strong class="iy hi"> __len__ </strong>和<strong class="iy hi"> __getitem__ </strong>函数，以指定如何访问我们的图像。你可以在<a class="ae js" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class" rel="noopener ugc nofollow" target="_blank"> PyTorch文档</a>中读到更多关于Dataset类的内容。最后，我们必须创建数据加载器对象以及可以应用于图像的转换<strong class="iy hi">(图像增强)</strong>。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="7b2c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总的来说，这些图像增强技术将使模型更健壮，并可推广到低质量的图像。</p><h2 id="8cda" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">模型开发和培训</h2><p id="f2d1" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">接下来，我们使用Pytorch实现了一个<strong class="iy hi">视觉转换器</strong>模型，仅用一个转换器编码器就实现了视觉分类中的SOTA。我们创建一个视觉转换器对象，并使用<strong class="iy hi">线性转换器</strong> : <em class="mh">线性复杂度的自我关注。</em>线性变压器是一种<strong class="iy hi">线性变压器</strong>，它利用线性自关注机制来解决与变压器模型相关的自关注瓶颈。视觉转换器(VIT)接受以下参数。</p><p id="daa1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="mh">参数:- </em> </strong></p><p id="7f88" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> image_size: int。</strong> <br/>图像大小。如果您有矩形图像，请确保您的图像大小是宽度和高度的最大值</p><p id="d778" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">补丁大小:整数。</strong> <br/>补丁数量。image_size必须能被patch_size整除。<br/>面片数为:n = (image_size // patch_size) ** 2且n必须大于16。</p><p id="3f64" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">数量类:整数。 <br/>数类来分类。</p><p id="a53a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">dim: int。 <br/>线性变换nn后输出张量的最后维数。线性(…，dim)。</p><p id="a42d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">深度:智力。 <br/>变压器块数。</p><p id="40e8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">头:智力。 <br/>多头关注层中的人头数。</p><p id="3456" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">mlp_dim: int。T34】MLP(前馈)层的尺寸。</p><p id="99ee" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">通道:int，默认3。</strong> <br/>图像的通道数。</p><p id="a250" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> dropout:在[0，1]之间浮动，默认为0..</strong> <br/>辍学率。</p><p id="60f2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> emb_dropout:在[0，1]之间浮动，默认为0。</strong> <br/>嵌入辍学率。</p><p id="9ee9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">池:字符串，cls令牌池或均值池</strong></p><p id="72b6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们在这里使用的损失函数是<strong class="iy hi"> CrossEntropyLoss </strong>，带有<strong class="iy hi"> ADAM </strong>优化器和学习率调度器(<strong class="iy hi"> StepLR </strong> )—它在每个<strong class="iy hi"> step_size </strong>时期通过伽马衰减每个参数组的学习率。在<strong class="iy hi"> Pytorch </strong>中，你可以使用交叉熵损失来完成二进制分类任务。你只需要确保在模型的最后一层有两个神经元。此外，还要确保没有添加softmax函数。我鼓励读者也尝试使用<strong class="iy hi">二元交叉熵损失</strong> &amp;来验证模型的结果。可以直接用<code class="du mw mx my mz b">nn.BCELoss()</code></p><p id="4223" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们遍历训练数据加载器中的图像和目标类，找到模型的预测，将模型的预测与实际情况进行比较(计算损失函数)，并相应地更新权重。接下来，我们计算验证损失和准确性。我们计算正确预测的数量和总预测，这样我们就可以计算准确度。该过程类似于训练步骤，除了模型不应该在该步骤中学习。这意味着我们不会更新该数据的权重。我们在每个时期之后打印出损失和准确性度量。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es na"><img src="../Images/e674ff1e9529d8e941288812d8302807.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PwNVJQ1R_53QZ7lLthl5Ig.png"/></div></div></figure><h2 id="94a2" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">保存模型</h2><p id="8af4" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">在最终确定和微调您的模型之后，一个好的做法是保存构建好的模型，以便用于将来的推理。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="4a01" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">评估测试数据的性能</h2><p id="74f3" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">最后，对测试数据进行模型测试。我们使用的是经过培训和验证的相同模型。名为<strong class="iy hi"> test() </strong>的方法接受模型、测试加载器和损失函数的参数。它将返回对测试数据的推断，该推断返回测试损失、测试准确性、预测的类概率值和实际值。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="676a" class="ko kp hh bd kq kr ks kt ku kv kw kx ky jf kz la lb jj lc ld le jn lf lg lh li bi translated">结果</h2><p id="d682" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">在评估了模型的准确性以及针对训练和验证数据的时期数的损失度量之后，我们继续基于<strong class="iy hi">接收器操作特性(ROC) </strong>曲线来评估我们的模型，该曲线是假阳性率对真阳性率的曲线图。ROC曲线表明该模型能够很好地区分这两个类别。曲线下面积(AUC)值接近1表明很少有假阳性和假阴性。直线的AUC为0.5，表示随机猜测的二元分类器。另一个可分性评估是<strong class="iy hi">混淆矩阵</strong>。二元分类器的混淆矩阵以易于阅读的矩阵格式显示真阳性、真阴性、假阳性和假阴性的数量。为了增强我们对假阳性和假阴性的分析，我们还可以可视化一些我们分类错误或正确的图像。我写了一个自定义函数来显示假阳性(FP) &amp;假阴性(FN)样本。本质上，该函数遍历测试集，并将错误标记的数据组织到适当的类别中。这将允许我们看到分类器正在犯什么样的错误。最后，根据该函数是用于显示假阴性还是假阳性，我们使用Matplotlib中的figure和subplot函数在一个网格中显示错误标记的数据。此外，还编写了一个自定义函数来绘制混淆矩阵和ROC曲线。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es nb"><img src="../Images/56e9b561a17ef5df270e5ba8abc4b109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OETuDJJx5MVFFSnnelJI7A.png"/></div></div></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es nc"><img src="../Images/effc4323ca1625f731cabb6c830c3fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LFnaTK3QxA45ZqNfDUqiHA.png"/></div></div></figure><h1 id="8269" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">结论</h1><p id="b916" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">在这篇文章中，我们看到了如何使用Dataset类和Dataloader对象为分类预处理CT扫描。然后，我们在CT图像上实现了一个<strong class="iy hi">变换器模型</strong>，将它们分类为<strong class="iy hi">COVID/非COVID </strong>样本。然后，我们用<strong class="iy hi">测井损失</strong>、<strong class="iy hi">准确度</strong>、<strong class="iy hi"> ROC曲线</strong>和<strong class="iy hi">混淆矩阵</strong>进一步评估建立的模型。</p><p id="315d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，朋友们，我们成功地为一项计算机视觉任务建立了最先进的(SOTA)模型——“<strong class="iy hi">transformer</strong>”,并评估了模型性能。干杯:)</p><h1 id="97e0" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">重要链接</h1><p id="6cae" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">点击此处查看该博客的完整代码</p><p id="164d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://github.com/ajayarunachalam/vision-transformer-demo/blob/main/Visual-Transformer-Covid_NonCovid_TESTED-PUBLISH.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/vision-Transformer-demo/blob/main/Visual-Transformer-Covid _ non vid _ TESTED-publish . ipynb</a></p><h1 id="c436" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">联系我</h1><p id="a9a3" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated">你可以打<strong class="iy hi"><em class="mh">ajay.arunachalam08@gmail.com</em></strong>联系我，或者通过<a class="ae js" href="https://www.linkedin.com/in/ajay-arunachalam-4744581a/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我</p><p id="de02" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢阅读。希望这篇文章对读者有用。</p><p id="7c2b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">自豪地坚持学习。</p><h1 id="3564" class="lm kp hh bd kq ln lo lp ku lq lr ls ky in lt io lb iq lu ir le it lv iu lh lw bi translated">参考资料:-</h1><p id="cce1" class="pw-post-body-paragraph iw ix hh iy b iz lx ii jb jc ly il je jf lz jh ji jj ma jl jm jn mb jp jq jr ha bi translated"><a class="ae js" href="https://arxiv.org/abs/1802.05751" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1802.05751</a></p><p id="6e4d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://arxiv.org/abs/1804.00247" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1804.00247</a></p><p id="0164" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1706.03762.pdf</a></p><p id="b452" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://arxiv.org/pdf/2006.03677.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2006.03677.pdf</a></p><p id="181c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="http://peterbloem.nl/blog/transformers" rel="noopener ugc nofollow" target="_blank">http://peterbloem.nl/blog/transformers</a></p><p id="c502" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://arxiv.org/pdf/2103.14030v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2103.14030v1.pdf</a></p><p id="fa57" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Transformer _(machine _ learning _ model)</a></p><p id="525a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://pub.towardsai.net/will-transformers-replace-cnns-in-computer-vision-55657a196833" rel="noopener ugc nofollow" target="_blank">https://pub . toward sai . net/will-transformers-replace-CNN-in-computer-vision-55657 a 196833</a></p><p id="28f8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://towardsdatascience.com/a-demonstration-of-using-vision-transformers-in-pytorch-mnist-handwritten-digit-recognition-407eafbc15b0" rel="noopener" target="_blank">https://towards data science . com/a-demo-of-using-vision-transformers-in-py torch-mnist-handled-digital-recognition-407 eafbc 15 b 0</a></p><p id="2838" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">https://arxiv.org/pdf/2006.03677.pdf<a class="ae js" href="https://arxiv.org/pdf/2006.03677.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="c5d3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">【https://nlp.seas.harvard.edu/2018/04/03/attention.html T4】</p><p id="d0d6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">http://jalammar.github.io/illustrated-transformer/</a></p><p id="0a10" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2017/08/transformer-novel-neural-network . html</a></p><p id="d74a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://deepai.org/machine-learning-glossary-and-terms/transformer-neural-network" rel="noopener ugc nofollow" target="_blank">https://deepai . org/machine-learning-glossary-and-terms/transformer-neural-network</a></p><p id="b113" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://www.unite.ai/what-are-transformer-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://www.unite.ai/what-are-transformer-neural-networks/</a></p><p id="8d81" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" href="https://lionbridge.ai/articles/what-are-transformer-models-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://lionbridge . ai/articles/what-is-transformer-models-in-machine-learning/</a></p><p id="5eb1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" rel="noopener" href="/analytics-vidhya/vision-transformers-bye-bye-convolutions-e929d022e4ab">https://medium . com/analytics-vid hya/vision-transformers-bye-bye-convolutions-e 929d 022 E4 ab</a></p></div></div>    
</body>
</html>
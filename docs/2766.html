<html>
<head>
<title>Ensemble Learning — Bagging with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成学习——用Python打包</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/ensemble-learning-bagging-with-python-59bd7732fd01?source=collection_archive---------0-----------------------#2022-06-08">https://medium.com/mlearning-ai/ensemble-learning-bagging-with-python-59bd7732fd01?source=collection_archive---------0-----------------------#2022-06-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="69eb" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">关于如何用scikit-learn实现打包的指南。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/ad51c27309aa7ccf9f162cf883f8f90a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-HrBvEIdB9eU3swy"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@chuklanov?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Avel Chuklanov</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="645f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">集成学习通过组合几个模型来帮助提高机器学习模型的性能。与单一模型相比，这种方法提供了更好的预测性能。在这篇文章中，我将讨论以下主题。</p><ul class=""><li id="e7bd" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">什么是装袋？</li><li id="cec9" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">使用scikit-learn构建模型</li><li id="52c2" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">决策树与装袋</li></ul><p id="9a78" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在开始之前，我们创建与数据科学、人工智能、机器学习和深度学习相关的内容。请不要忘记关注我们的YouTube频道。</p><p id="f392" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们开始吧！</p></div><div class="ab cl kx ky go kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ha hb hc hd he"><h1 id="3d1b" class="le lf hh bd lg lh li lj lk ll lm ln lo in lp io lq iq lr ir ls it lt iu lu lv bi translated">什么是装袋？</h1><p id="5f7c" class="pw-post-body-paragraph jn jo hh jp b jq lw ii js jt lx il jv jw ly jy jz ka lz kc kd ke ma kg kh ki ha bi translated">Bagging是一种使用引导技术的集成学习技术。打包也称为引导聚合。所以你可能会问什么是自举？Bootstrapping是一种统计过程，它通过替换采样数据来创建多个数据集。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mb"><img src="../Images/f40dc05c0b498a6cdaea4a4aaa8389d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YYom-NKDaZ-B7RB_891DgQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx"><a class="ae jm" href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting" rel="noopener ugc nofollow" target="_blank">Bootstraping Technique</a></figcaption></figure><p id="f36f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">假设你有一个数据集。不是使用相同的训练数据集，而是从初始训练数据集中提取引导样本。对于每个bootstrap样本，您需要拟合一个基本估计量。这种技术可以用来减少基本估计量的方差。因此，您可以使用bagging估计量来克服过度拟合问题。</p><h1 id="ba5f" class="le lf hh bd lg lh mc lj lk ll md ln lo in me io lq iq mf ir ls it mg iu lu lv bi translated">用Scikit装袋-学习</h1><p id="f529" class="pw-post-body-paragraph jn jo hh jp b jq lw ii js jt lx il jv jw ly jy jz ka lz kc kd ke ma kg kh ki ha bi translated">现在，我将向您展示如何使用scikit-learn和真实数据集实现bagging分类器。在加载数据集之前，让我导入熊猫。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="43e0" class="mm lf hh mi b fi mn mo l mp mq">import pandas as pd</span></pre><p id="dd02" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了展示如何实现bagging分类器，我将使用乳腺癌威斯康星州数据集。让我们加载数据集。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="42ca" class="mm lf hh mi b fi mn mo l mp mq">df = pd.read_csv("data.csv")</span></pre><p id="ad25" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">你可以在这里找到这个数据集<a class="ae jm" href="https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data" rel="noopener ugc nofollow" target="_blank"/>。让我们看一下数据集的前五行。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="7273" class="mm lf hh mi b fi mn mo l mp mq">df.head()</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mr"><img src="../Images/34ce99a63cdc6e68dd10e6f1f56a3e51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*elX4i1z0GzrBYL2CH02Azg.png"/></div></div></figure><p id="5199" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">该数据集由恶性和良性肿瘤细胞的例子组成。数据集中的第一列显示唯一的ID号，第二列显示诊断，假设M表示恶性，B表示良性。其余栏目是我们的特色。让我们来看看数据集的形状。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="1bcf" class="mm lf hh mi b fi mn mo l mp mq">df.shape</span><span id="a8fc" class="mm lf hh mi b fi ms mo l mp mq">#Output:<br/>(569, 33)</span></pre><h1 id="42da" class="le lf hh bd lg lh mc lj lk ll md ln lo in me io lq iq mf ir ls it mg iu lu lv bi translated">数据预处理</h1><p id="0d94" class="pw-post-body-paragraph jn jo hh jp b jq lw ii js jt lx il jv jw ly jy jz ka lz kc kd ke ma kg kh ki ha bi translated">让我们从数据集中删除不必要的列。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="1202" class="mm lf hh mi b fi mn mo l mp mq">df = df.drop(["Unnamed: 32"], axis=1)</span></pre><p id="1b3d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，让我们创建输入和目标变量。为此，我将使用iloc方法。首先，让我将特性转换成一个numpy数组。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="818f" class="mm lf hh mi b fi mn mo l mp mq">X = df.iloc[:,2:].values</span></pre><p id="5cb9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">之后，我将创建一个目标变量，然后将这个变量转换成一个numpy数组。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="ec96" class="mm lf hh mi b fi mn mo l mp mq">y = df.iloc[:,1].values</span></pre><p id="1c68" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们的目标变量有两个类别，M和b。让我们用一个标签编码器对目标变量进行编码。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="9855" class="mm lf hh mi b fi mn mo l mp mq">from sklearn.preprocessing import LabelEncoder<br/>le = LabelEncoder()<br/>y = le.fit_transform(y)</span></pre><p id="21b7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">太棒了，我们编码了目标标签。在构建模型之前，让我们将数据集分成训练集和测试集。为此，我将使用train_test_split函数。首先，让我导入这个函数。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="ff85" class="mm lf hh mi b fi mn mo l mp mq">from sklearn.model_selection import train_test_split</span></pre><p id="5518" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们使用这个函数分割数据集。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="dd2f" class="mm lf hh mi b fi mn mo l mp mq">X_train, X_test, y_train, y_test = train_test_split(<br/>                                       X, y, <br/>                                       stratify=y, <br/>                                       random_state=0)</span></pre><p id="9703" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">酷毙了。我们的数据集已经可以分析了。现在我将使用bagging技术用scikit-learn分析数据。</p><h1 id="891c" class="le lf hh bd lg lh mc lj lk ll md ln lo in me io lq iq mf ir ls it mg iu lu lv bi translated">决策树与装袋</h1><p id="fdc8" class="pw-post-body-paragraph jn jo hh jp b jq lw ii js jt lx il jv jw ly jy jz ka lz kc kd ke ma kg kh ki ha bi translated">为了构建bagging模型，首先，让我从ensemble子模块中导入BaggingClassifier。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="a503" class="mm lf hh mi b fi mn mo l mp mq">from sklearn.ensemble import BaggingClassifier</span></pre><p id="3835" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我将使用决策树分类器作为基本估计器。让我导入这个类。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="9be4" class="mm lf hh mi b fi mn mo l mp mq">from sklearn.tree import DecisionTreeClassifier</span></pre><p id="6ccf" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">太美了。我们的课准备好了。首先，我将使用DecisionTreeClassifier构建模型。之后，我将使用装袋来建立模型。最后，我将比较这些模型。让我们从DecisionTreeClassifier类创建一个对象。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="7b7f" class="mm lf hh mi b fi mn mo l mp mq">tree = DecisionTreeClassifier(random_state = 0)<br/># fitting the model<br/>tree = tree.fit(X_train, y_train)<br/># Predicting the training set<br/>y_train_pred = tree.predict(X_train)<br/># Predicting the test set<br/>y_test_pred = tree.predict(X_test)</span></pre><p id="0256" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，让我们看看模型在训练集和测试集上的性能。为此，我将使用accuracy_score函数。让我导入这个函数。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="11a6" class="mm lf hh mi b fi mn mo l mp mq">from sklearn.metrics import accuracy_score</span></pre><p id="0d64" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，让我们来看看训练集的准确度分数。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="3e02" class="mm lf hh mi b fi mn mo l mp mq">tree_train = accuracy_score(y_train, y_train_pred)</span></pre><p id="1406" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">之后，我们来看看测试集的准确率得分。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="0240" class="mm lf hh mi b fi mn mo l mp mq">tree_test = accuracy_score(y_test, y_test_pred)</span></pre><p id="26aa" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">太美了。我们计算了准确度分数。现在，让我们打印这些分数。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="7e4b" class="mm lf hh mi b fi mn mo l mp mq">print(f’Decision tree train/test accuracies: {tree_train:.3f}/{tree_test:.3f}’)</span><span id="0f7f" class="mm lf hh mi b fi ms mo l mp mq">#Output:<br/>Decision tree train / test accuracies:  1.000 /  0.944</span></pre><p id="78f7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">给你。树模型在训练集上的得分是100%。但是树模型在测试集上的得分是94%。请注意，较低的测试精度表明模型的方差较大。换句话说，在树模型中存在过拟合问题。现在，让我们建立一个装袋模型。为此，让我从BaggingClassifier创建一个对象。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="890c" class="mm lf hh mi b fi mn mo l mp mq">bag = BaggingClassifier(<br/>          base_estimator=tree,<br/>          n_estimators=100,<br/>          random_state=0)</span></pre><p id="984b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">太棒了。我们的目标准备好训练了。让我们使用训练集来拟合bagging模型。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="ba84" class="mm lf hh mi b fi mn mo l mp mq">bag = bag.fit(X_train, y_train)</span></pre><p id="6137" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">酷毙了。模型已经建立。现在，让我们使用这个模型来预测训练集和测试集。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="bf57" class="mm lf hh mi b fi mn mo l mp mq"># Predicting the training set<br/>y_train_pred = bag.predict(X_train)<br/># Predicting the test set<br/>y_test_pred = bag.predict(X_test)</span></pre><p id="0098" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，让我们看看bagging模型在训练和测试集上的性能。为此，我将再次使用accuracy_score函数。首先，我们来看看模型在训练集上的准确率得分。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="5aef" class="mm lf hh mi b fi mn mo l mp mq">bag_train = accuracy_score(y_train, y_train_pred)</span></pre><p id="ca2d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">之后，我们来看看模型在测试集上的准确率得分。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="10f9" class="mm lf hh mi b fi mn mo l mp mq">bag_test = accuracy_score(y_test, y_test_pred)</span></pre><p id="7ba5" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">太美了。我们计算了准确度分数。现在，让我们打印这些分数。</p><pre class="ix iy iz ja fd mh mi mj mk aw ml bi"><span id="689c" class="mm lf hh mi b fi mn mo l mp mq">print(f’Bagging train/test accuracies: {bag_train:.3f}/{bag_test:.3f}’)</span><span id="dde2" class="mm lf hh mi b fi ms mo l mp mq">#Output<br/>Bagging train/test accuracies:  1.000/ 0.958</span></pre><p id="2922" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">给你。bagging模型在训练集上的得分是100%。但是bagging模型在测试集上的得分是96%。当比较bagging模型和tree模型时，我可以说bagging分类器具有稍好的泛化性能。</p><h1 id="e0b5" class="le lf hh bd lg lh mc lj lk ll md ln lo in me io lq iq mf ir ls it mg iu lu lv bi translated">结论</h1><p id="7985" class="pw-post-body-paragraph jn jo hh jp b jq lw ii js jt lx il jv jw ly jy jz ka lz kc kd ke ma kg kh ki ha bi translated">Bagging是一种简单而非常强大的集合方法。bagging背后的想法是将多个模型的结果结合起来，得到一个概括的结果。您可以使用bagging来减少模型的方差。但是bagging在减少模型偏差方面是无效的。在这里可以找到笔记本<a class="ae jm" href="https://www.kaggle.com/tirendazacademy/ensemble-learning-bagging" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a573" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">就是这样。感谢您的阅读。我希望你喜欢它。别忘了在YouTube上关注我们👍</p><div class="mt mu ez fb mv mw"><a rel="noopener follow" target="_blank" href="/geekculture/6-steps-to-become-a-machine-learning-expert-5a1f155f7207"><div class="mx ab dw"><div class="my ab mz cl cj na"><h2 class="bd hi fi z dy nb ea eb nc ed ef hg bi translated">成为机器学习专家的6个步骤</h2><div class="nd l"><h3 class="bd b fi z dy nb ea eb nc ed ef dx translated">成为机器学习专家需要知道的一切。</h3></div><div class="ne l"><p class="bd b fp z dy nb ea eb nc ed ef dx translated">medium.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk jg mw"/></div></div></a></div><div class="mt mu ez fb mv mw"><a rel="noopener follow" target="_blank" href="/geekculture/8-best-seaborn-visualizations-20143a4b3b2f"><div class="mx ab dw"><div class="my ab mz cl cj na"><h2 class="bd hi fi z dy nb ea eb nc ed ef hg bi translated">8个最好的Seaborn可视化</h2><div class="nd l"><h3 class="bd b fi z dy nb ea eb nc ed ef dx translated">使用企鹅数据集与Seaborn一起动手绘制统计图。</h3></div><div class="ne l"><p class="bd b fp z dy nb ea eb nc ed ef dx translated">medium.com</p></div></div><div class="nf l"><div class="nl l nh ni nj nf nk jg mw"/></div></div></a></div><h1 id="263b" class="le lf hh bd lg lh mc lj lk ll md ln lo in me io lq iq mf ir ls it mg iu lu lv bi translated">参考</h1><ul class=""><li id="6ec2" class="kj kk hh jp b jq lw jt lx jw nm ka nn ke no ki ko kp kq kr bi translated"><a class="ae jm" href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting" rel="noopener ugc nofollow" target="_blank">装袋与增压</a></li><li id="218c" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312" rel="noopener ugc nofollow" target="_blank">使用PyTorch和Scikit-Learn进行机器学习</a></li></ul><p id="9ff7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果这篇文章有帮助，请点击拍手👏按钮几下，以示支持👇</p><div class="mt mu ez fb mv mw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mx ab dw"><div class="my ab mz cl cj na"><h2 class="bd hi fi z dy nb ea eb nc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nd l"><h3 class="bd b fi z dy nb ea eb nc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ne l"><p class="bd b fp z dy nb ea eb nc ed ef dx translated">medium.com</p></div></div><div class="nf l"><div class="np l nh ni nj nf nk jg mw"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Image Generation using Generative Adversarial Networks (GANs)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用生成对抗网络的图像生成</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/image-generation-using-generative-adversarial-networks-gans-cd82afd71597?source=collection_archive---------0-----------------------#2021-03-24">https://medium.com/mlearning-ai/image-generation-using-generative-adversarial-networks-gans-cd82afd71597?source=collection_archive---------0-----------------------#2021-03-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8a684fbff690cf58eacbb5f1611b32fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*DV-loln6HX8C8e8bYznJLw.gif"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Image generation using Super Resolution GAN architecture</figcaption></figure><blockquote class="it iu iv"><p id="0fe1" class="iw ix iy iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated"><strong class="iz hi">理解生成性对抗网络</strong></p></blockquote><p id="c0e8" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">生成对抗网络，俗称GANs，是2014年通过<a class="ae jy" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">这篇研究论文</a>提出的一种深度学习、无监督的机器学习技术。该架构的主要模块包括:</p><ol class=""><li id="9a64" class="jz ka hh iz b ja jb je jf jv kb jw kc jx kd ju ke kf kg kh bi translated"><strong class="iz hi">生成器:</strong>该块通过将噪声作为输入，试图生成与原始数据集非常相似的图像。它试图学习输入数据(X)和输出数据(Y)的连接概率；P(X|Y)。</li><li id="1eff" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju ke kf kg kh bi translated"><strong class="iz hi">鉴别器:</strong>该模块试图接受两个输入，一个来自主数据集，另一个来自生成器生成的图像，并将它们分为真或假。</li></ol><p id="ec4d" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">为了使这种生成和对抗过程简单，这两个块都由基于深度神经网络的体系结构制成，该体系结构可以通过前向和后向传播技术来训练。</p><p id="c4da" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">自GANs问世以来，GANs取得了巨大的进步。存在专门为某些任务制造GAN架构。</p><ul class=""><li id="7982" class="jz ka hh iz b ja jb je jf jv kb jw kc jx kd ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">使用深度卷积GANs生成图像。</a></li><li id="13a9" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1708.05509.pdf" rel="noopener ugc nofollow" target="_blank">用GANs生成动漫角色。</a></li><li id="7191" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1611.07004.pdf" rel="noopener ugc nofollow" target="_blank">使用GANs生成草图到彩色照片。</a></li><li id="d5f5" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">使用CycleGANs的不成对图像到图像翻译。</a></li><li id="7405" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1612.03242.pdf" rel="noopener ugc nofollow" target="_blank">使用堆叠GAN的文本到图像合成。</a></li><li id="4c5c" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1705.09368.pdf" rel="noopener ugc nofollow" target="_blank">使用GANs生成新的人类姿势。</a></li><li id="afa8" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1609.04802.pdf" rel="noopener ugc nofollow" target="_blank">使用GANs的单幅图像超分辨率。</a></li><li id="9121" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated"><a class="ae jy" href="https://arxiv.org/pdf/1607.07539.pdf" rel="noopener ugc nofollow" target="_blank">基于GAN的照片修复。</a></li></ul></div><div class="ab cl ko kp go kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="ha hb hc hd he"><p id="225c" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">为了深入理解这一概念，我们将通过tensorflow-keras实现GAN架构。我们将关注通过<strong class="iz hi">简单GANs </strong>和<strong class="iz hi">深度卷积GANs </strong>以及<strong class="iz hi">超分辨率GANs </strong>生成MNIST图像，并给出工作示例。</p></div><div class="ab cl ko kp go kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="ha hb hc hd he"><blockquote class="it iu iv"><p id="644b" class="iw ix iy iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated"><strong class="iz hi"> <em class="hh">【简单生成对抗网络】</em> </strong></p></blockquote><p id="fd2a" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">有了上面简单gan的架构，我们再来看看生成器模型的架构。</p><p id="e039" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated">enerator由四个密集层组成，其中一个100维的噪声数据作为输入被传递。生成器的最后一个密集层产生784(28×28 = 784)维向量，该向量主要是对应于每个单独MNIST图像的平坦向量。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es le"><img src="../Images/abe1a0e4d9cf34a071597f39997c8e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*CtiJ6xtuD6ode_Orwv9fZw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Generator of Simple GAN</figcaption></figure><p id="17d9" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">对于最后一个密集层，我们使用了<em class="iy"> tanh </em>激活单元，因为我们从[-1，+1]开始归一化每个图像。来自发生器的这个发生器向量然后被传递到下一个模块，该模块是GANs的鉴别器网络。</p><p id="462f" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated"><span class="l kw kx ky bm kz la lb lc ld di"> D </span>是一个鉴别器，它的主要任务是在预测真实或虚假数据时获得最大概率，我们将我们的784维生成器输出向量传递给它。该块也包括如下所示的四个致密层。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/c05cd064c8608b4f3561507985b18c1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*_RrcWtWN-HRHr8aEl92Uog.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Discriminator of Simple GAN</figcaption></figure><p id="ca67" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">对最后一层使用s形激活，这给出了输入图像是真的还是假的概率。</p><p id="bf8e" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">LeakyRelu激活函数用于生成器和鉴别器中，这有助于模型的更快收敛。</p><p id="dd14" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">这些生成块和判别块组合在一起如下:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/272cb276a994c0cc11fe1269e8c482eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*zAsP9lH2lApZ6EKaXonhdg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Simple GAN model</figcaption></figure><p id="f2a9" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">为了执行实际的训练，我们将通过初始化每个功能块来初始化生成器、鉴别器和gan对象。我们将为生成器生成100维的噪声输入。当我们在[-1，+1]之间归一化图像时，我们将从范围[-1，+1]的正态分布中得到随机噪声。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es ll"><img src="../Images/c7291cc30ab7b5fdeea1be19e9ba1506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*Iss6AhPxKGuzgXaxRDBsOQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Prediction of Real and Fake images through GAN Discriminator</figcaption></figure><p id="4471" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">使用上面的代码，我们将首先通过向生成器传递随机噪声来生成样本图像。然后将这些图像与真实图像相结合，生成一批真实和伪造的图像。这一批被传递到一个鉴别器，该鉴别器预测图像是真的还是假的概率。</p><p id="70f4" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">直到鉴别器预测的这个阶段，我们保持鉴别器是可训练的，因为预测的损失需要通过网络反向传播以更新对应于每一层的权重。</p><p id="4855" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">现在，通过冻结鉴频器的层，我们试图通过生成器反向传播GAN损耗，以更新每层的权重。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/2cbba663889db1c77026fb93ee1b56ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*nkuflUdgMIBj5rDB1YlL1A.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Freezing Discriminator, we backpropagate loss through Generator</figcaption></figure><p id="af24" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">下图显示了GAN架构的进展，通过简单的噪声输入，生成器能够创建与原始数据相似的MNIST图像。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ln"><img src="../Images/1ae4edbdf637c5196fe47788bf22bd8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHepwaDsdkUuDM0xQIxPNQ.png"/></div></div></figure></div><div class="ab cl ko kp go kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="ha hb hc hd he"><blockquote class="it iu iv"><p id="39ff" class="iw ix iy iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated"><strong class="iz hi"> <em class="hh">深度卷积生成对抗网络(DC·甘斯)</em> </strong></p></blockquote><p id="493d" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">在深度神经网络的帮助下生成类似的MNIST图像非常有趣，但该模型未能实现架构中的主要深度学习算法，即卷积神经网络。</p><p id="10e2" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">从今以后，我们将使用卷积滤波器从噪声输入中生成图像，而不是将图像展平成致密层。</p><p id="6e13" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated">DC GAN发生器由致密层和随后的批量正火层组成。这里，我们首先将噪声作为输入，乘以FxFxK个元素。这个输出然后被整形为FxFxK形状。</p><p id="a84d" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">卷积2d转置层用于DC GANs，其主要目的是对输入图像进行上采样。完整的架构如下:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lo"><img src="../Images/fd8ece39e404fbf6894c1d8d52abb84c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N0t3Od0gaeWZ0_EIIP6s0A.png"/></div></div></figure><p id="e1c1" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated"><span class="l kw kx ky bm kz la lb lc ld di"> D </span>与前面的例子不同，DC GANs的识别器接受图像而不是矢量格式的输入。通过发生器和原始数据生成的图像被采样，以将其传递给鉴别器。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lp"><img src="../Images/ca69b2224e4735bd713ae2bebb1bb926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qX34PeWmF4pBFcUmjGli4w.png"/></div></div></figure><p id="770a" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">LeakyRelu激活与Dropout的低值一起使用，以避免模型的过度拟合。</p><p id="3925" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">DC甘斯的其余流程与简单甘斯相同，其中我们让鉴别器首先通过训练损失的反向传播来更新它的权重。鉴别器更新后，我们冻结鉴别器，并用假数据安装生成器。发电机的损耗然后通过它反向传播，以便更新权重。</p><p id="b84d" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">下图向我们展示了DC-GAN在400个时期的MNIST数据上的性能进展。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ln"><img src="../Images/4c2dab3bb00d87f1525d102a8c12bbba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZxZkG0KZs_TQyqjBpTVZww.png"/></div></div></figure></div><div class="ab cl ko kp go kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="ha hb hc hd he"><blockquote class="it iu iv"><p id="78f3" class="iw ix iy iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated"><strong class="iz hi"> <em class="hh">超分辨率生成对抗网络</em> </strong></p></blockquote><p id="106c" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">现在，我们将研究一种称为SR GANs的高级GAN架构。这样做的主要目的是:</p><p id="fd4d" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">通过接受低分辨率图像作为输入使用生成器生成超分辨率图像。这个超分辨率图像非常类似于原始数据集的原始高分辨率图像。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/bad669adc272004d0764803388202cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*bOilXIO8wGLG_P_Kx9NrLw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">SR GANs block diagram</figcaption></figure><p id="5cee" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated">从上面的方框图看SR GANs的工作；</p><ul class=""><li id="5f97" class="jz ka hh iz b ja jb je jf jv kb jw kc jx kd ju kn kf kg kh bi translated">原始数据集由高分辨率(HR)图像组成，对其进行下采样以获得低分辨率(LR)图像。</li><li id="3e03" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated">这些LR图像然后被传递到SR GAN发生器，该发生器产生与HR图像的超分辨率(SR)图像接近匹配的SR图像。</li><li id="3725" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated">这些SR和HR图像的批次然后被传递到SR GAN鉴别器，该鉴别器预测图像是真的还是假的。</li><li id="f074" class="jz ka hh iz b ja ki je kj jv kk jw kl jx km ju kn kf kg kh bi translated">SR GAN的最终损耗然后被反向传播到发生器和鉴别器网络，用于更新权重。</li></ul><p id="e638" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">既然我们理解了架构的工作原理，我们现在可以理解每个核心模块的细节；发生器和鉴别器。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/5fe0fca1d110a3739626f663f09d4b24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t9daACB-GsgH4ZRue1Gmvw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">SR GAN Generator</figcaption></figure><p id="e438" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated"><span class="l kw kx ky bm kz la lb lc ld di">如实际研究论文中的</span>所述，上图为SR GAN发生器的框图。LR输入图像通过卷积层，随后是参数ReLU激活。然后，输出被传递给16个剩余块的集合。来自残差块的输出然后被传递到一对卷积块，卷积块然后被传递到上采样块，上采样块将图像的分辨率提高到期望的水平。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/56dbeb950d42cece18f0a8b3e792d16b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*uFT3K9F5xNvL-LVkMdZtZw.png"/></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lt"><img src="../Images/12aeb4c9ba9054e0e3cafea213dd3b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Sd3mub6Cb2DibfO7aMILg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">SR GAN Discriminator</figcaption></figure><p id="5c4d" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated">与所有其他GAN架构一样，SR GAN的鉴别器通过同时接受两幅图像来预测真假图像，在这里我们可以看到，与之前看到的架构相比，它实现的复杂结构很少。</p><p id="d93e" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">鉴频器输出然后被用来寻找模型的损失。</p><p id="9edd" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi kv translated">SR GAN中的oss功能可以是内容丢失和对抗性丢失的组合。这里，可以使用HR和SR图像之间的MSE逐像素捕获内容损失。这可以通过将输入图像通过VGG19网络来提取对应于每个输入图像的密集向量来计算。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/8a2db9111ebc4f1b7ec1e75086d92eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*buIRpctkCH6kABJvORDdZA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">vgg19 Content Loss</figcaption></figure><p id="c30a" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">在运行完整的SR GAN模型时，我们将初始化生成器、鉴别器和SR-GAN对象。</p><p id="8fc3" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">生成器对象将用<em class="iy"> Adam optimizer </em>编译，并且只有<em class="iy">内容丢失</em>(即VGG19像素级MSE)。</p><p id="9bf2" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">另一方面，鉴别器对象将使用<em class="iy"> binary_crossentropy </em>和<em class="iy"> Adam optimizer </em>进行编译。</p><p id="0a83" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">我们不是训练一批混合的HR和LR图像，而是首先将HR图像传递给鉴别器，然后通过使用<strong class="iz hi"> <em class="iy">生成器，用一批LR图像对其进行训练。</em></strong></p><p id="aa08" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">现在，为了训练鉴别器，我们将冻结鉴别器，并用LR图像训练srgan对象，并将[HR_images，REAL_IMAGE_LABELS]作为所需的输出。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/6612c9c000494eff2e29cc8c6e611b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*lXG7eqESwN65FSBqrMeHTg.png"/></div></figure><p id="940e" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">在批量大小为64、周期数为400的网络上运行，我们能够从SE GAN架构获得显著的输出。</p><p id="da5b" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">本文开头的GIF是使用SR GAN架构本身生成的。从下面，我们可以清楚地看到，模型能够非常清楚地预测桥梁和运河的边缘。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/439cbbfc4a87b3a993f7cfb9d0c769c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-5kuUNCoA1bUE9EpTbnOog.png"/></div></div></figure><p id="11c3" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">随着模型在各个时期的进展，我们可以看到从纪元1到纪元200，桥梁结构非常清晰可见，clif，它的绿色植物和一些文明在SR图像中清晰可见(中间)。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/82dd745431925802c01c109c3a74ad87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kb-02XqK0tSWdm7SM_-cWw.png"/></div></div></figure><p id="5701" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">这是Epoch400结束时的一个结果，天空的颜色改善了很多，包括桥上的水。因此，考虑到低层次的图像，我们的眼睛可以看到小像素，模型能够重新生成具有更精细细节的图像。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/7e62a0dd45abb0bb50b7e3dbc8d3db8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fm4hyzH0lsGHsrsGdRcIEg.png"/></div></div></figure><p id="d080" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">这里有一些其他的图像生成；</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/c1f1b05a3d4593e662ea5008bdb31b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dkBtcEW-sI9HLW-eOTAAOA.png"/></div></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lx"><img src="../Images/5074b0bf2aebe799494c346725fac4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nhrGdARRIz8fNiupX39eDA.png"/></div></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ly"><img src="../Images/587c215ac442065e426e073904689f11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_JCH9d3zBwueEiuZrfPug.png"/></div></div></figure><p id="e86e" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">不太好，但也不太坏。哈哈…！！！！</p></div><div class="ab cl ko kp go kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="ha hb hc hd he"><blockquote class="lz"><p id="6b10" class="ma mb hh bd mc md me mf mg mh mi ju dx translated">结论</p></blockquote><p id="d45a" class="pw-post-body-paragraph iw ix hh iz b ja mj jc jd je mk jg jh jv ml jk jl jw mm jo jp jx mn js jt ju ha bi translated">然而，通过简单的建模架构，我们能够通过所有三种形式的GAN架构重新创建不是最好而是更好的图像输出。通过提供更多的图像数据，并给予更多的时间来学习图像的特征和深入细节，模型肯定会优于原始数据。</p></div><div class="ab cl ko kp go kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="ha hb hc hd he"><p id="19b8" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">希望你喜欢这篇文章。如果你已经走了这么远，那么一定要看看我的其他媒体故事。</p><p id="b60a" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">快乐编码…！！！</p></div></div>    
</body>
</html>
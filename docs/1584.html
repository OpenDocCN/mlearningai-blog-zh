<html>
<head>
<title>Automatic Generation of Emotionally Expressive Poetry By Fine-tuning GPT-2 Using Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过使用Pytorch微调GPT-2自动生成表达情感的诗歌</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/automatic-generation-of-emotionally-expressive-poetry-by-fine-tuning-gpt-2-using-pytorch-68dace59fca0?source=collection_archive---------2-----------------------#2022-01-08">https://medium.com/mlearning-ai/automatic-generation-of-emotionally-expressive-poetry-by-fine-tuning-gpt-2-using-pytorch-68dace59fca0?source=collection_archive---------2-----------------------#2022-01-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="9f7c" class="hf hg hh bd b fp hi hj hk hl hm hn dx ho translated" aria-label="kicker paragraph">方便的指南</h2><div class=""/><div class=""><h2 id="a4df" class="pw-subtitle-paragraph in hq hh bd b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je dx translated">使用Huggingface库创作嵌入您选择的情感的原创诗歌</h2></div><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/4f54a315ba2648991e98b73a61e8ca45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pg_FcUkWWYJC5BAi"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx">Photo by <a class="ae jv" href="https://unsplash.com/@dearseymour?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ksenia Makagonova</a> on <a class="ae jv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="35a9" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">自过去几年以来，NLP世界经历了一场大繁荣，类似于2012年的计算机视觉繁荣。这一成功在很大程度上归功于<a class="ae jv" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"> transformer架构</a>和对下游任务使用<a class="ae jv" href="https://lena-voita.github.io/nlp_course/transfer_learning.html" rel="noopener ugc nofollow" target="_blank">迁移学习</a>。</p><blockquote class="ks kt ku"><p id="a0fa" class="jw jx kv jy b jz ka ir kb kc kd iu ke kw kg kh ki kx kk kl km ky ko kp kq kr ha bi translated"><a class="ae jv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">“关注是你所需要的一切”</a>是谷歌员工发表的一篇研究论文。阿希什·瓦斯瓦尼等人。艾尔。发表了这篇革新了NLP产业的论文。这是第一次提到<em class="hh">变形金刚</em>的概念。</p></blockquote><p id="e7bf" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">2020年，OpenAI推出了GPT-3，这是一个具有1750亿个参数的自回归语言模型，比以前的任何非稀疏语言模型都多10倍。该模型在文本生成方面表现出惊人的性能。然而，从头开始训练这样的大型模型需要仔细的超参数调整，数千个计算小时和数百万个AWS信用。而不是这样，我们将从<a class="ae jv" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> Huggingface </a>模型中心微调一个预训练的GPT-2模型。</p><div class="kz la ez fb lb lc"><a href="https://colab.research.google.com/drive/1_8UUlOjd_KnSIxlSdsF72MeSK3lprnbo?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hr fi z dy lh ea eb li ed ef hq bi translated">谷歌联合实验室</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">包含用于微调模型的整个工作流的笔记本</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">colab.research.google.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq jp lc"/></div></div></a></div></div><div class="ab cl lr ls go lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ha hb hc hd he"><p id="aebc" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">在这个项目中，我们将开发GPT-2模型，每个模型都能够产生带有特定情感基调的原创诗歌。整个项目的代码可以在这个<a class="ae jv" href="https://github.com/prajwalcr/AutoCompose" rel="noopener ugc nofollow" target="_blank"> GitHub存储库中找到。</a>所有模特都托管在<a class="ae jv" href="https://huggingface.co/prajwalcr" rel="noopener ugc nofollow" target="_blank"> HuggingFace </a>上。您还可以在资源库中找到一个<a class="ae jv" href="http://autocompose.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"> Flask App </a>的代码，它提供了一个与模型交互的API。Flask应用程序已经使用Heroku 部署并上线。部署的应用程序利用<a class="ae jv" href="https://algorithmia.com/" rel="noopener ugc nofollow" target="_blank">算法ia </a>来运行<strong class="jy hr"> GPU </strong>中的模型，这对于<strong class="jy hr">也是免费的！</strong>如果您有兴趣了解这是如何实现的(GPU通常非常昂贵)，可以在本文的<a class="ae jv" href="http://example.com/" rel="noopener ugc nofollow" target="_blank">第2部分</a>中找到整个部署过程。类似的策略也可以用于部署其他人工智能应用程序。</p><h1 id="1faa" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">方法学</h1><h2 id="9e64" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">古腾塔格</h2><p id="e745" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><a class="ae jv" href="http://www.cs.toronto.edu/~jbrooke/gutentag/" rel="noopener ugc nofollow" target="_blank">古腾堡工具</a>用于从<a class="ae jv" href="https://www.gutenberg.org/" rel="noopener ugc nofollow" target="_blank">古腾堡项目</a>网站建立所需的诗歌语料库，这是一个包含超过59，000本电子书的大型在线数据库。</p><h2 id="9220" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">Emolex</h2><p id="e5e6" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">EmoLex 是一个众包式的词汇和情绪关联数据集。它用于根据诗歌的情感对诗歌语料进行分类。通过使用对应于每种情绪的诗歌，为该情绪建立语言模型。</p><h2 id="e0c7" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">拥抱脸</h2><p id="9642" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">从HuggingFace的模型中心获得预训练的GPT-2模型，该模型稍后将针对每种情绪在相应的诗歌语料库上进行微调。</p><h1 id="ace1" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">资料组</h1><p id="0e95" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">这些数据是从古腾堡项目网站上获得的。<a class="ae jv" href="http://www.cs.toronto.edu/~jbrooke/gutentag/" rel="noopener ugc nofollow" target="_blank">古腾堡工具</a>是古腾堡项目数据库的一个很好的语料库阅读器。它提供了一个简单的界面，您可以逐步添加过滤器来分离和获取所需的文本。在应用了所有必要的过滤器之后，我们得到了一个大约三百万行的诗歌语料库。你也可以看看这个很酷的<a class="ae jv" href="https://github.com/aparrish/gutenberg-poetry-corpus" rel="noopener ugc nofollow" target="_blank"> github知识库</a>，作者是<em class="kv"> Allison Parrish </em>，可以很容易地从古登堡计划数据库中获得一个大型诗歌语料库。</p><h1 id="b286" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">对数据集进行分区</h1><p id="a83c" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">一旦获得数据，下一步就是根据诗歌所表达的情感对诗歌进行分类。我们将它们分为9个不同的类别:<em class="kv">愤怒、期待、厌恶、恐惧、喜悦、中立、悲伤、惊讶和信任</em>。中性诗歌将用于训练所有的模型。然后，剩下的每一类诗歌将被用来训练相应情感的模型。可以使用各种技术来分割数据，但是<a class="ae jv" href="https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm" rel="noopener ugc nofollow" target="_blank"> Emolex </a>似乎是一个简单方便的工具。</p><p id="2be3" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">使用<a class="ae jv" href="https://pypi.org/project/NRCLex/" rel="noopener ugc nofollow" target="_blank"> NRCLex </a> python库可以很容易地将Emolex集成到您的代码中。我们遍历每首诗，分别记录这首诗所表达的8种情绪的强度。如果一首诗明显属于八种情绪之一，即其中一种情绪比其他任何情绪都要高，我们就用这种情绪来标记这首诗。如果一首诗没有表现出任何情绪或者属于大量情绪，我们就给它贴上缺失/中性的标签。</p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="ni nj l"/></div></figure><h1 id="bbe6" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">为模型准备数据</h1><p id="a2e6" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">我们将使用Pytorch加载数据并微调模型。我们将使用来自Huggingface的GPT-2标记器和适当的bos、eos和pad标记来标记诗歌。这个记号赋予器基于<a class="ae jv" href="https://leimao.github.io/blog/Byte-Pair-Encoding/" rel="noopener ugc nofollow" target="_blank"> BPE(字节对编码)</a>。</p><p id="c109" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">为了优化数据生成过程，防止训练过程中出现瓶颈，我们创建了pytorch数据集和数据加载器。对于每首诗，数据集创建包含编码诗和注意力屏蔽(用于填充标记)的张量。DataLoader用于将数据输入到模型中，并定义某些参数，如批量大小和采样技术。</p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="ni nj l"/></div></figure><h1 id="7e02" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">微调模型</h1><p id="1c7f" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">对于基于变压器的模型，AdamW 是首选的优化器。我们将使用Huggingface的实现以及所有默认参数。我们还创建了一个具有线性预热的调度器，它在预热阶段线性增加学习速率，之后学习速率变得恒定。这有助于减少早期培训阶段的波动性。</p><p id="b355" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">接下来，我们从Huggingface加载GPT-2模型及其配置类，并用预训练的权重实例化该模型。我们从配置类中设置模型的参数。该模型被训练大约4个时期。不需要大量的历元，因为我们只是微调预训练的模型。训练加载模型的完整代码可以在这个<a class="ae jv" href="https://colab.research.google.com/drive/1_8UUlOjd_KnSIxlSdsF72MeSK3lprnbo?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>中找到。</p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="ni nj l"/></div></figure><p id="4578" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">通过查看训练和验证的损失曲线，您可以很好地了解何时停止训练。在最后一个时期之后，最好使训练损失刚好低于验证损失，以确保它不会下降得太低，从而避免过度拟合。下图显示了一个停止训练的好点。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es nk"><img src="../Images/124965944daeec5b27e1ca693f787026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*abiHt3vi6iRl2rx6RtTQCw.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx">Image by Author</figcaption></figure><h1 id="3b13" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">将一切缝合在一起</h1><p id="37e4" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">使用上面提到的技术，我们为每一类诗歌创建一个单独的GPT-2模型，也就是说，我们对每个模型重复相同的过程，数据是唯一的区别。</p><p id="c8af" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">首先，我们通过微调预先训练好的中性诗歌GPT-2模型，建立了一个生成中性情感诗歌的模型。让我们称之为<strong class="jy hr">基础模型</strong>。这个模型已经学习了诗歌的句法、语义、风格和各种特征。因此，我们将使用基础模型来创建其他情绪的模型，而不是使用来自Huggingface的预训练GPT-2模型。对于其余8种情绪中的每一种，我们在相应的数据集上微调基础模型。这给了我们更有希望的结果。</p><h1 id="d2c1" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">结果</h1><p id="c4e1" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">现在是激动人心的部分。让我们看看模型生成的一些诗歌，看看它是否能跟上实际诗人创作的作品。下面列出了模型为每种情绪创作的一些最佳诗歌。</p><h2 id="f290" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">愤怒</h2><p id="b8d0" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">愤怒的想法</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="9d45" class="mq lz hh nm b fi nq nr l ns nt">I am not jealous; but this does vex<br/>My heart so full of misery that I cannot stop<br/>From angry thoughts.  This brings me relief,<br/>And a painful torment; and I<br/>Am content to part from thee alone.</span></pre><h2 id="128a" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">希望</h2><p id="56bf" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">神秘中的上帝</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="4368" class="mq lz hh nm b fi nq nr l ns nt">Thence down the river to the mountain-side<br/>I travelled with my boats and my oarsmen,<br/>To seek a haven near the southern cape<br/>Where dwelt some mighty god in mystery,<br/>Unknowing I wandered therefrom, so<br/>Unconscious I lay, and rested there.</span></pre><h2 id="45cf" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">厌恶</h2><p id="44e8" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">雏菊和污秽</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="8b06" class="mq lz hh nm b fi nq nr l ns nt">The little pool, by the house-wall,<br/>Is covered with daisies and filth;<br/>The fountains are withered and dim,<br/>And the lizards writhe in rags.</span></pre><h2 id="5a8f" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">害怕</h2><p id="6e43" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">我看见你在遥远的角落</p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="fc92" class="mq lz hh nm b fi nq nr l ns nt">I see thee in a far corner,<br/>With a stealthy stride, and a trembling soul<br/>I know thou, Dear, who should'st not fear<br/>That I should come near thee!<br/>I know thee.</span></pre><h2 id="d280" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">高兴</h2><p id="f8d6" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">温柔的喉咙</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="bcd8" class="mq lz hh nm b fi nq nr l ns nt">Thy soul has joy, and thy soul is free,<br/>And all the things it loves can live<br/>In thy love for me and thee!<br/>O gentle-throat, why sing so low,<br/>Or do thy music too loudly?<br/>Whence are all thy numbers fit?<br/>If that thy mind is fix'd upon one,<br/>It joys not to hear thee speak.</span></pre><h2 id="abaa" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">中立的</h2><p id="67ca" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">月亮</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="6ba6" class="mq lz hh nm b fi nq nr l ns nt">He took them home, and soon set them down<br/>In a chest at the door of his room,<br/>And asked them if they knew<br/>What the moon was about.</span></pre><h2 id="e341" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">悲哀</h2><p id="d2a5" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">亲爱的心</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="ebba" class="mq lz hh nm b fi nq nr l ns nt">For you, dear heart, so lone and worn and weary,<br/>Hear me, and the silence dies,<br/>That still I think you must come near me,<br/>And not so be blest.</span></pre><h2 id="21dd" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">惊喜</h2><p id="413a" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">自然自有</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="f62f" class="mq lz hh nm b fi nq nr l ns nt">He is a wild magician,<br/>Who takes up the air and vanishes<br/>As though his name were Nature's own,<br/>And that it were Nature's own prompting,<br/>That he should leave school in such a way.</span></pre><h2 id="adcb" class="mq lz hh bd ma mr ms mt me mu mv mw mi kf mx my mk kj mz na mm kn nb nc mo hn bi translated">信任</h2><p id="3084" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated"><em class="kv">乔装打扮的少女</em></p><pre class="jg jh ji jj fd nl nm nn no aw np bi"><span id="8c28" class="mq lz hh nm b fi nq nr l ns nt">He sees the aged damsels in disguise,<br/>And how the princely damsels are dressed;<br/>The queen of Sariola, as she stands,<br/>Is clad in rich embroidery;<br/>And every thing that she does wear<br/>Is a royal dame in finest form,<br/>And a queen in fairest posture too.</span></pre></div><div class="ab cl lr ls go lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ha hb hc hd he"><p id="e65e" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">这些模型有点粗糙，但是考虑到我们只需要对它们进行4个时期的训练，它们显示出了非常有希望的结果。有些诗写得非常好，就好像是一个真正的诗人写的一样，这给人印象非常深刻。</p><h1 id="00c6" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">结论</h1><p id="304b" class="pw-post-body-paragraph jw jx hh jy b jz nd ir kb kc ne iu ke kf nf kh ki kj ng kl km kn nh kp kq kr ha bi translated">我希望我已经能够通过这篇文章来说明变压器的力量。这些深度语言模型能够轻松地针对下游任务进行微调，而不需要庞大的数据集，这是它们背后所有宣传的主要原因。</p><p id="6c12" class="pw-post-body-paragraph jw jx hh jy b jz ka ir kb kc kd iu ke kf kg kh ki kj kk kl km kn ko kp kq kr ha bi translated">我还展示了一个简单的微调生成器模型的工作流程，这篇关于为<em class="kv">万智牌</em>生成风味文本的<a class="ae jv" rel="noopener" href="/swlh/fine-tuning-gpt-2-for-magic-the-gathering-flavour-text-generation-3bafd0f9bb93">文章给了我很大的启发。</a></p><h1 id="3cfb" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">未来的工作</h1><ul class=""><li id="862c" class="nu nv hh jy b jz nd kc ne kf nw kj nx kn ny kr nz oa ob oc bi translated">这种方法最大的缺陷之一是我们最终得到了9种不同的模型。理想情况下，我们需要一个端到端的模型来执行某项任务。当然可以构建一个单一的模型来生成各种情绪的诗歌，用户可以在其中指定所需的情绪，但我将让读者对此进行进一步的探索(也许我们可以在生成欢乐的诗歌时，在开始生成之前，在输入中添加一个特殊的标记，如<joy>)。</joy></li><li id="201c" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr nz oa ob oc bi translated">更好的超参数调整肯定会改善结果，我在这里为我的模型留了很多空间。</li><li id="0635" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr nz oa ob oc bi translated">更大的模型肯定会给出更好的结果，尽管你需要更多的计算和时间。</li><li id="6640" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr nz oa ob oc bi translated">对生成的诗歌进行统计评估有助于优化模型。困惑是文本生成的一个常用度量。您还可以执行<a class="ae jv" href="https://searchenterpriseai.techtarget.com/definition/Turing-test" rel="noopener ugc nofollow" target="_blank">图灵测试</a>来评估您的模型。</li></ul><h1 id="ad52" class="ly lz hh bd ma mb mc md me mf mg mh mi iw mj ix mk iz ml ja mm jc mn jd mo mp bi translated">参考文献和致谢</h1><ol class=""><li id="8a71" class="nu nv hh jy b jz nd kc ne kf nw kj nx kn ny kr oi oa ob oc bi translated">A.瓦斯瓦尼、n .沙泽尔、n .帕尔马等。、<a class="ae jv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a> (2017)，第31届神经信息处理系统会议</li><li id="288d" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr oi oa ob oc bi translated">布伦丹·李炳然，朱加尔·卡利塔，<a class="ae jv" href="https://arxiv.org/abs/2002.02511" rel="noopener ugc nofollow" target="_blank">介绍自动诗歌生成的创造性方面</a> (2020)</li><li id="33f9" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr oi oa ob oc bi translated">杰伊·阿拉姆马的插图版GPT-2。这是了解GPT新协议的极好资源，我强烈推荐你阅读它。</li><li id="2247" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr oi oa ob oc bi translated"><a class="ae jv" rel="noopener" href="/swlh/fine-tuning-gpt-2-for-magic-the-gathering-flavour-text-generation-3bafd0f9bb93">微调GPT-2为幻世拢味文生成</a>。这个项目的工作流程在很大程度上受到了这篇文章的启发。</li><li id="48f0" class="nu nv hh jy b jz od kc oe kf of kj og kn oh kr oi oa ob oc bi translated"><a class="ae jv" href="https://lena-voita.github.io/nlp_course/transfer_learning.html" rel="noopener ugc nofollow" target="_blank">迁移学习简介</a>。深入了解迁移学习和使用预训练模型完成下游任务。</li></ol><div class="kz la ez fb lb lc"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hr fi z dy lh ea eb li ed ef hq bi translated">Mlearning.ai提交建议</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">medium.com</p></div></div><div class="ll l"><div class="oj l ln lo lp ll lq jp lc"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Evaluating Federated Learning from FELT Labs on MNIST Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在MNIST数据集上评估FELT Labs的联合学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/evaluating-federated-learning-from-felt-labs-on-mnist-dataset-cbe081b28786?source=collection_archive---------0-----------------------#2022-12-04">https://medium.com/mlearning-ai/evaluating-federated-learning-from-felt-labs-on-mnist-dataset-cbe081b28786?source=collection_archive---------0-----------------------#2022-12-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b0e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在MNIST数据集上测试不同的联邦学习模型</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/e64d32c640299972e9de9d98fde16459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fbj19TLmzwVWwoBPHG0QlQ.png"/></div></div></figure><p id="4d83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jo" href="https://feltlabs.ai/" rel="noopener ugc nofollow" target="_blank"> FELT Labs </a>是一个关于去中心化数据的数据科学工具。你可以用它在多个分散的数据集上训练机器学习模型，并聚合结果——联邦学习。本文将尝试回答这个简单的问题，“它实际上有效吗？”我们将使用FELT支持的模型来评估和比较联合学习与在<a class="ae jo" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>上的集中训练。</p><p id="66ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里提供了本文中用于生成图表的源代码:</p><div class="jp jq ez fb jr js"><a href="https://github.com/FELT-Labs/mnist-demo" rel="noopener  ugc nofollow" target="_blank"><div class="jt ab dw"><div class="ju ab jv cl cj jw"><h2 class="bd hi fi z dy jx ea eb jy ed ef hg bi translated">GitHub - FELT-Labs/mnist-demo:在mnist数据集上演示测试FELT</h2><div class="jz l"><h3 class="bd b fi z dy jx ea eb jy ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ka l"><p class="bd b fp z dy jx ea eb jy ed ef dx translated">github.com</p></div></div><div class="kb l"><div class="kc l kd ke kf kb kg jm js"/></div></div></a></div><p id="2828" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kh">储存库包含</em> <a class="ae jo" href="https://github.com/FELT-Labs/mnist-demo/blob/main/main_tests.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="kh"> jupyter笔记本</em> </a> <em class="kh">所有结果在此呈现。</em></p><h1 id="2a4d" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">评估流程</h1><p id="12bd" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">在我们研究单个模型之前，我们必须定义如何测量性能。我们使用MNIST数据集，分为训练和测试数据。在训练和评估模型时，我们将遵循以下规则:</p><ul class=""><li id="a96a" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated">对于联合学习，我们将训练集随机划分为X个分区(我们固定随机种子，因此划分对所有模型都是一样的)。</li><li id="8252" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">对于集中训练，我们使用整个训练数据集。</li><li id="b877" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">使用准确性度量在测试集上评估产生的每个模型。</li><li id="948d" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">如果我们运行联合学习的X次迭代，我们将为集中式模型运行相同数量的迭代(时期)。</li></ul><p id="972a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更好地控制这一过程，培训在当地环境中进行，遵循与分散设置相同的程序。记住这些规则，我们就可以开始训练一些模型了！</p><h2 id="2131" class="lz kj hh bd kk ma mb mc ko md me mf ks ip mg mh kw it mi mj la ix mk ml le mm bi translated">数据预处理</h2><p id="3d62" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">MNIST数据集包含大小为28x28像素的图像。大多数scikit-learn模型只期望一个一维向量作为输入。出于这个原因，我们把每张图片展平成一个矢量。此外，我们将像素值从[0，255]缩放到[0，1]范围。</p><h2 id="e0c6" class="lz kj hh bd kk ma mb mc ko md me mf ks ip mg mh kw it mi mj la ix mk ml le mm bi translated">如何阅读图表</h2><p id="28a9" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">每个图表包含三个主要数据点:集中式模型、本地模型和聚合模型:</p><ul class=""><li id="facc" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated"><strong class="ig hi">集中式模型</strong>是在全MNIST数据集上训练产生的模型。</li><li id="ce08" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">局部模型</strong>是分别在数据集的每个分区上训练的模型。(图表显示平均精度和误差范围)</li><li id="1e83" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">聚合模型</strong>是通过聚合本地模型产生的模型。这是毛毡的最终输出。</li></ul><p id="6ff1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们主要寻找局部模型(在单个数据集上训练的)和由它们的组合产生的聚集模型(<strong class="ig hi">平均模型的权重</strong>)之间的比较。</p><h1 id="d2c9" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">简单模型</h1><p id="0ff6" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">我们将从评估scikit-learn库中的简单模型开始。对于这种情况，我们选择了两个模型:<a class="ae jo" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>和<a class="ae jo" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html#sklearn.neighbors.NearestCentroid" rel="noopener ugc nofollow" target="_blank">最近质心分类器</a>。我们可以称这些模型为简单模型的主要原因是，它们可以在联邦学习的一次迭代中被训练。我们使用了scikit-learn库中的所有默认超参数。</p><p id="ad8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将针对不同数量的分区评估这些模型。对于每个划分，我们将运行一次联合学习的迭代。</p><div class="jd je jf jg fd ab cb"><figure class="mn jh mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/81fbec521c52a1986b49765d66c01e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*SiM0d-joWD0X4n_5nPcB8g.png"/></div></figure><figure class="mn jh mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/672be1f17f0a3030901cc3e3cd9a4452.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*BbPHEoquN-kKqi16Wlr82A.png"/></div><figcaption class="mu mv et er es mw mx bd b be z dx my di mz na">Comparison between the accuracy of local and aggregated models for different numbers of partitions (separate datasets).</figcaption></figure></div><p id="39e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们从图表中看到的，聚合对于这些模型非常有效。随着分区数量的增加，本地模型的准确性会降低(这是意料之中的，因为每个分区中的数据量会减少)。这也是意料之中的，因为两个模型都具有线性结构，使得平均聚合非常适合。此外，我们看到，随着分区数量的增加，聚合带来的<strong class="ig hi">额外好处也会增加</strong>。</p><h1 id="4cf7" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">神经网络</h1><p id="298a" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">由scikit-learn提供并由FELT支持的一个更复杂的模型是<a class="ae jo" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlp+classifier#sklearn.neural_network.MLPClassifier" rel="noopener ugc nofollow" target="_blank"> MLP分类器</a>，一个简单的神经网络。在我们的例子中，我们使用了一个有两个隐藏层的网络，都有50个神经元。同样值得一提的是，在每次迭代中，我们只运行50个训练步骤，批量大小为50。这确保了来自每个分区的本地模型不会相差太多，并且平均聚合具有有益的效果。</p><blockquote class="nb nc nd"><p id="ef6a" class="ie if kh ig b ih ii ij ik il im in io ne iq ir is nf iu iv iw ng iy iz ja jb ha bi translated">从现在开始，所有展示的图表将来自3个分区的培训。</p></blockquote><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nh"><img src="../Images/c33674d4252f483f6a582fd0f19264e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*m2er1R6CB3-sxoqDK_VB8w.png"/></div><figcaption class="mu mv et er es mw mx bd b be z dx">Accuracy of MLP Classifier trained using 8 iterations of federated learning on 3 partitions (datasets).</figcaption></figure><p id="7991" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们所看到的，第一次迭代主要初始化模型权重。因为来自第一次迭代的本地模型有很大的不同，所以聚合没有什么好处。从第二次迭代开始，聚合的效果更加明显。</p><h1 id="bbb4" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">张量流CNN模型</h1><p id="ca41" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">MNIST包含图像，如果不包括至少一个卷积神经网络CNN，这将不是一个正确的评价。我们最近在FELT中添加了对TensorFlow模型的支持，这仍然是一个实验性的功能。这一部分主要是为了表明，事实上，我们可以在一个联合设置中训练这些网络，即使是简单的平均聚合。</p><p id="1a68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们尝试训练一个具有一个卷积层和一个全连接层的简单网络。</p><div class="jd je jf jg fd ab cb"><figure class="mn jh ni mp mq mr ms paragraph-image"><img src="../Images/f825da6d3bb76dfce378367ff3f606dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*gLaRd11eK84HAta3jW2V7A.png"/></figure><figure class="mn jh nj mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/a2203cfb73911a82aee82cdbcd1f2062.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*VDpsovSFfEi31sNqlG8CEg.png"/></div><figcaption class="mu mv et er es mw mx bd b be z dx nk di nl na">Accuracy of CNN model trained on 10 iterations of federated learning trained on 3 partitions.</figcaption></figure></div><p id="2f7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从图表中，我们可以看到聚合的好处低于以前的模型。聚合的第一次迭代不会产生好的结果，因为模型差异很大。我们至少需要运行两次迭代才能从聚合中获益。</p><p id="ed4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们疯狂一点，试着训练高效的网络。这是一个拥有数百万参数的庞大网络，我们从零开始训练它。重点主要是说明FELT甚至可以处理大型模型。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nm"><img src="../Images/bb1d8edee8c227fd6f1a4b7792ffab39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*n3oxRKtrw1LQvevewnUiPA.png"/></div><figcaption class="mu mv et er es mw mx bd b be z dx">Accuracy of Efficient Net model trained using federated learning on 3 partitions (datasets).</figcaption></figure><p id="ffa5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的聚合方法对于这样的大型模型并不理想。尽管如此，在几次迭代之后，聚集模型提供了与最佳局部训练模型相当的结果。这意味着由FELT产生的模型至少不会导致更差的准确性。</p><h2 id="ce51" class="lz kj hh bd kk ma mb mc ko md me mf ks ip mg mh kw it mi mj la ix mk ml le mm bi translated">后续步骤</h2><p id="8397" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">正如现在所做的，使用高效网络的联合学习不是一个好方法。它从头开始训练所有参数。我们仍然包括结果，以表明我们可以训练这些模型。更好的方法是采用预先训练好的模型，只对最后一层进行微调。我们将在下面的文章中尝试这种方法！</p><h1 id="b1da" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">结论</h1><p id="0e9d" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">我们评估了当地环境中几种不同型号的毛毡的性能。很高兴看到，事实上，对多个分散的数据集进行聚合是有好处的。然而，在大型模型方面还有很多工作要做。微调可能是处理这些模型的一个可能的解决方案。</p><p id="924c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kh">在Twitter上关注我们</em><a class="ae jo" href="https://twitter.com/FELT_labs" rel="noopener ugc nofollow" target="_blank"><em class="kh">@ FELT _ Labs</em></a><em class="kh">了解我们开发的更多更新。</em></p><div class="jp jq ez fb jr js"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jt ab dw"><div class="ju ab jv cl cj jw"><h2 class="bd hi fi z dy jx ea eb jy ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="jz l"><h3 class="bd b fi z dy jx ea eb jy ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ka l"><p class="bd b fp z dy jx ea eb jy ed ef dx translated">medium.com</p></div></div><div class="kb l"><div class="nn l kd ke kf kb kg jm js"/></div></div></a></div></div></div>    
</body>
</html>
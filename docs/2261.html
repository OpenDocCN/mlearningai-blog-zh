<html>
<head>
<title>Solving GANs: NN architecture &amp; feedback</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">求解GANs:神经网络架构与反馈</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/solving-gans-nn-architecture-feedback-5f7ef6a8a5eb?source=collection_archive---------3-----------------------#2022-04-03">https://medium.com/mlearning-ai/solving-gans-nn-architecture-feedback-5f7ef6a8a5eb?source=collection_archive---------3-----------------------#2022-04-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1abd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">过去几周，我在库塞拉上完了一堂很棒的基础甘斯课。在课堂上和网上的很多地方都使用PyTorch软件；我很少看到GANs在Tensorflow Keras上实现。在这篇文章中，我使用Tensorflow Keras练习执行一个基本的GANs。我使用了MINST数字数据集，为每张图片生成一个数字。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/78fe8462f0f221656eb29c287f0f24a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*PVFuwJL2jKXTBA-nVQuFzQ.png"/></div></figure><p id="aa9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我了解到，使用Keras，您必须运行许多时期(3000+时期)的模型，在获得复制原始数字的结果之前，获得许多时期的深蓝色图像。下面是我处理这个问题的方法，集中在不同的模型架构和反馈方法上。使用梯度磁带反馈的解码器-编码器模型获得了最好的结果。梯度带反馈程序在Tensorflow网站上的教程中给出。</p><ul class=""><li id="9b7f" class="jk jl hh ig b ih ii il im ip jm it jn ix jo jb jp jq jr js bi translated"><strong class="ig hi">鉴别器&amp;生成器架构:</strong> 1)神经网络，2)深度卷积生成对抗网络(DCGANs)，3)解码器-编码器，</li><li id="2572" class="jk jl hh ig b ih jt il ju ip jv it jw ix jx jb jp jq jr js bi translated"><strong class="ig hi">鉴别器&amp;发生器反馈:</strong> 1)通过GradientTape使用损耗更新鉴别器&amp;发生器的成本函数梯度，2)将鉴别器&amp;发生器模型组合成单个模型，使得发生器接收反馈，3)使用监督标签向发生器和鉴别器给出反馈。</li></ul><h1 id="139c" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">子功能</h1><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kw kx l"/></div></figure><h1 id="69bd" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">加载数据</h1><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ky"><img src="../Images/f01cad72cf6e958192ad1f27939a1340.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*aTDpwCtJcYBpCj6PEk_Sxg.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx">Original images</figcaption></figure><p id="6d9a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是使用tf执行GANs。GradientTape、Tensorflow在https://www.tensorflow.org/tutorials/generative/dcgan<a class="ae ld" href="https://www.tensorflow.org/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank">的网站上给出了教程。我发现只有tf。GANs作品的GradientTape执行！Tf。GradientTape使用鉴别器和发生器损耗更新梯度。</a></p><p id="6ae4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，以下反馈方法不起作用:1)将发生器和鉴别器放入相同的模型中不能给出正确的结果，2)将来自鉴别器的预测的标签信息馈送到发生器，同时混合鉴别器的真实和伪造样本，仅给出数字的印象，而不能创建数字的图像。在这两种情况下，人们只获得背景图像，如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/bdce0f0464b8cd14f812942a5198398b.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*Kb9GXyAgfOwOy3WJ5-QNFw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx">After 2000 epochs using the two feedback approaches mentioned above</figcaption></figure><p id="792d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是我使用tf.GradientTape成功生成数字的主要代码。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kw kx l"/></div></figure><h1 id="f995" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">神经网络结构和使用tf的结果。梯度胶带</h1><p id="8c9e" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">我使用了一种经典的神经网络方法，将图像拉平，然后输入到几个密集的层中；模型细节见上面的代码。GANs的这种方法可以使用PyTorch，但我无法让它在Tensorflow中生成数字。下面是1000个纪元后的结果。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lo"><img src="../Images/83b997b82f0f6b9eb468857f1344b140.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*booC4RCU1PBYt_v3PSJqDA.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx">1000 epochs</figcaption></figure><h1 id="4c6d" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">使用tf的DCGANs架构和结果。梯度胶带</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lp"><img src="../Images/84a625c63efb0484e71a80484a7388cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OI2cEu9zsCa3QDluQ0axw.png"/></div></div></figure><p id="eb1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">令人高兴的是，1000个纪元后，我开始看到数字用这种架构形成；如果我再运行2000或3000个周期，我想我会得到完美的数字。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lq"><img src="../Images/c9a268cc157607e578de9079c98c6464.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*jZZjtFLucj-09e7zRUNrMQ.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx">1000 epochs</figcaption></figure><h1 id="c59f" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">使用tf的编码器-解码器架构和结果。梯度胶带</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lr"><img src="../Images/dd52a26835f3e338ea4105d5d16e8b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kNsGM_Q9s-SsXQHzBdul7g.png"/></div></div></figure><p id="6f2c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用编码器-解码器架构，我开始获得看起来像1000个历元的数字的斑点。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ls"><img src="../Images/0be5831ccdc0853f7f148323f6650480.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*-7tT6-wTj8EFtRO_KROpYQ.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx">1000 epochs</figcaption></figure><h1 id="eedf" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结论:什么可行，什么不可行</h1><p id="7f62" class="pw-post-body-paragraph ie if hh ig b ih lj ij ik il lk in io ip ll ir is it lm iv iw ix ln iz ja jb ha bi translated">工程:CNN(包括DCGANs和编码器-解码器)使用tf。梯度胶带</p><p id="9ece" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不起作用:神经网络结构，以及使用不改变关于损失的梯度的反馈方法。我必须阅读更多的资料，看看损失是如何被用来改变梯度的，但它似乎改变了足够的权重，以至于它开始模仿正确的输出。</p><p id="4775" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有趣的是，PyTorch使用少得多的时间获得了工作结果。我必须做更多的阅读，但可能PyTorch中的成本函数实现可能与Tensorflow略有不同。因此，对于某些问题，使用PyTorch可能比Tensorflow更好地解决它们，反之亦然。因此，如果您无法使用一种建模软件获得成功的模型，那么尝试使用其他几种类型的软件，如scikit-learn、Tensorflow和PyTorch，似乎是一个不错的主意。</p><p id="8ea7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在PyTorch中，使用相同的神经网络模型，在199个时期后，我获得了下面一代数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lt"><img src="../Images/47ba6ae68c0eefda18eca9d7d305a247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HhR8BDt6iIV-dVVPtZrHlA.png"/></div></div></figure><div class="lu lv ez fb lw lx"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hi fi z dy mc ea eb md ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">medium.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml ji lx"/></div></div></a></div></div></div>    
</body>
</html>
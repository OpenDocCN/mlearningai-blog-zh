<html>
<head>
<title>Vokenization: Multimodal Learning for Vision and Language</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语音化:视觉和语言的多模态学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/vokenization-multimodel-learning-for-vision-and-language-84e62f2dc808?source=collection_archive---------0-----------------------#2021-04-17">https://medium.com/mlearning-ai/vokenization-multimodel-learning-for-vision-and-language-84e62f2dc808?source=collection_archive---------0-----------------------#2021-04-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="1b68" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">机器学习@伯克利博客上的原始帖子:</p><div class="jj jk ez fb jl jm"><a href="https://ml.berkeley.edu/blog/posts/vokens/" rel="noopener  ugc nofollow" target="_blank"><div class="jn ab dw"><div class="jo ab jp cl cj jq"><h2 class="bd hi fi z dy jr ea eb js ed ef hg bi translated">语音化:视觉和语言的多模式学习</h2><div class="jt l"><h3 class="bd b fi z dy jr ea eb js ed ef dx translated">💡计算机视觉遇到自然语言处理语音化是视觉监督语言和计算机语言之间的桥梁</h3></div><div class="ju l"><p class="bd b fp z dy jr ea eb js ed ef dx translated">ml.berkeley.edu</p></div></div><div class="jv l"><div class="jw l jx jy jz jv ka kb jm"/></div></div></a></div></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="56c3" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">简介:人类学习</h1><p id="b17a" class="pw-post-body-paragraph il im hh in b io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji ha bi translated">人类是如何学习语言的？</p><p id="ddb0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当人类辨别单词时，他们会听基于时间和频率的差异来确定正在说什么。当我们蹒跚学步时，我们通过被动地<em class="lf">倾听</em>父母的谈话来习得我们的第一语言。随着年龄的增长，我们学会了与周围的人进行<em class="lf">阅读</em>、<em class="lf">写作</em>和<em class="lf">交谈</em>。这四个组成部分(听、读、写、说)帮助我们与世界互动，更好地了解我们的周围环境。如果有办法跨越所有这些领域，像人类一样更好地理解计算机模型中的语言，会怎么样？</p><p id="7cc1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">❗️Spoiler警报:vokenization(继续阅读了解更多)</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="d98f" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">计算机视觉和自然语言处理背景</h1><p id="ce11" class="pw-post-body-paragraph il im hh in b io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji ha bi translated">在我们进入什么是vokenization以及它是如何工作的之前，让我们了解一下CV和NLP中的一些关键概念和模型。</p><p id="2f36" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">NLP的突破使机器能够理解人类语言，包括文本预测、情感分析和语音识别等任务。一些流行的预训练NLP模型是深度学习文本生成框架OpenAI的GPT-3，以及谷歌的BERT，它在提供的句子上下文中生成代表每个单词的嵌入。</p><p id="d39e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">计算机视觉和深度学习的进步通常来自于只处理一个领域的数据。例如，StyleGAN模型，一种用于在每个卷积层调整图像样式的GAN，仅在视觉图像数据上训练。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lg"><img src="../Images/c6ab970a66afbf46811ef4e0a212a803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s6YnYmmTPUmzyeXj.png"/></div></div></figure><blockquote class="lr ls lt"><p id="e205" class="il im lf in b io ip iq ir is it iu iv lu ix iy iz lv jb jc jd lw jf jg jh ji ha bi translated">图NVIDIA研究人员为GANs (StyleGAN)创建的基于风格的生成器架构，用于生成人工图像，有时看起来比原始图像更真实。</p></blockquote><p id="91e8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">类似地，被认为是2021年最强大的语言模型的GPT-3只在文本数据上进行训练。尽管如此，有人对伯特和GPT-3语言模型提出了批评，因为很难从纯文本输入中学习单词的意思。这些自我监督的框架不考虑来自外部视觉世界的信息。如果人类不仅仅通过阅读来学习，那么为什么现有的语言模型仅仅基于纯文本的自我监督？</p><p id="86af" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了解决这一问题，人工智能社区对创建视觉语言表示学习的兴趣越来越大，利用来自图像的信息来学习语言表示，反之亦然。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="f527" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">✨Vokenization✨</h1><p id="3258" class="pw-post-body-paragraph il im hh in b io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji ha bi translated">到目前为止，基于视觉的语言数据集和纯语言数据集是有区别的。为了弥补这一差距，一种被称为Vokenization的新技术被开发出来。随着其他图像-文本神经网络在NLP中的突破，如OpenAI的DALL-E和CLIP，Vokenization是视觉语言多模态建模的最新进展之一。</p><p id="9b3b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">名字vokenization名字源于视觉和记号的结合，形成vokens。voken是与给定语言标记相对应的图像，并且可以被认为是标记的可视化。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lx"><img src="../Images/f64c51d863f42bea47cc8a0834984e39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hToXzW5G9RSQXIMd.jpg"/></div></div></figure><blockquote class="lr ls lt"><p id="c937" class="il im lf in b io ip iq ir is it iu iv lu ix iy iz lv jb jc jd lw jf jg jh ji ha bi translated">图2:模型生成的voken的可视化，其中模型对与语言标记相对应的视觉voken进行分类。</p></blockquote><p id="d585" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">动词化利用视觉信息监督语言学习。它通过上下文映射语言标记到vokens，一个标记的相关图像，将多模态比对外推至纯语言数据。从两个各自的深度神经网络中检索图像和标记嵌入，然后对齐嵌入。</p><p id="ce27" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">语音化技术的新颖之处在于，不仅预测语言标记，还预测图像标记，这是普通BERT模型无法生成的。此外，无需对架构进行任何更改，预训练的BERT模型就可以在Voken分类上进行训练，从而提高情感分类等纯语言任务的性能。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es ly"><img src="../Images/b7305b5794da55021e5b0f7fd9cf02d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TGzuAl2Dq-hCd-VQ.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lz"><img src="../Images/fb9e429fe00f107f285b190bb968c3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XDHWpClc5RllDSaf.png"/></div></div></figure><blockquote class="lr ls lt"><p id="ecec" class="il im lf in b io ip iq ir is it iu iv lu ix iy iz lv jb jc jd lw jf jg jh ji ha bi translated">图3:语言标记和标记相关图像的组合。语言模型由与标记相关的图像(称为vokens)进行视觉监督。语音化过程生成这些上下文标记图像对的数据集。</p></blockquote><h1 id="de2e" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">这有什么意义呢？</h1><p id="57a4" class="pw-post-body-paragraph il im hh in b io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji ha bi translated">平均而言，具有voken分类任务的BERT模型比没有voken分类的BERT模型平均高出约3%(这对于平均值来说是巨大的！)</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="e3fd" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">Vokenization过程</h1><p id="6b27" class="pw-post-body-paragraph il im hh in b io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji ha bi translated">总的来说，动词化过程是一个上下文标记到图像的匹配模型。</p><p id="0090" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当前的挑战:</p><ol class=""><li id="1507" class="mf mg hh in b io ip is it iw mh ja mi je mj ji mk ml mm mn bi translated">基础语言更喜欢简短和有启发性的描述，因此句子长度和活跃词的分布与其他语言类型不同。</li><li id="cc98" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mk ml mm mn bi translated">自然语言中的大多数单词都没有视觉基础(在英文维基百科中只有28%)。</li></ol><p id="6323" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们分两部分来解决两个挑战:</p><p id="6883" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">挑战1</p><ul class=""><li id="34df" class="mf mg hh in b io ip is it iw mh ja mi je mj ji mt ml mm mn bi translated">我们使用我们的vokenization方法，其中我们使用相对较小的数据集来训练vokenizer (vokenization处理器)。然后，我们为像英语维基百科这样的大型语言语料库生成语音。视觉监督语言模型然后将从大型数据集获取输入。这有助于弥合不同数据源之间的差距，有助于解决挑战1。</li></ul><p id="b4b4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">挑战2</p><ul class=""><li id="7a8f" class="mf mg hh in b io ip is it iw mh ja mi je mj ji mt ml mm mn bi translated">在考虑句子的上下文时，可以将一些视觉上不接地的标记映射到相关图像。vokenizer内部的上下文标记-图像匹配模型通过查看上下文将标记映射到图像，这允许我们为英文维基百科生成标记。</li></ul><p id="a483" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">传统的语言模型预测语言标记。但是使用动词化，不仅仅预测语言符号，还预测图像符号。图像标记是从图像的一组预定义的固定词汇/语音中分类的。本质上，语言模型具有不同记号的词汇集，这些记号被映射到嵌入表，然后被映射到其他记号的预测中。</p><p id="df16" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">输入:模型接受一个由一系列标记组成的句子和一幅图像。</p><p id="82c1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">输出:图像与其句子上下文中的每个标记之间的相关性分数</p><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es mu"><img src="../Images/5dadea5e4256693fed5481f44a0cb9ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/0*X-ySHw655E4Nz1HT.png"/></div></figure><blockquote class="lr ls lt"><p id="34b9" class="il im lf in b io ip iq ir is it iu iv lu ix iy iz lv jb jc jd lw jf jg jh ji ha bi translated">将语言符号的例子映射到被分类的图像中。voken BERT模型对哪个voken对应于语言标记进行分类。例如，上图的示例1，口语令牌与手中的电话相匹配。</p></blockquote><p id="4894" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">考虑到图像的上下文，该模型沿着图像对整个句子进行交叉注意，以预测voken。上图显示了示例1和示例2中的语言标记“by”。然而，在第一个句子(示例1)的上下文中,“by”图像标记是正在打电话的人，而在示例2中,“by”被映射到公园的长椅上。这种视觉信息有助于模型进一步区分上下文中的单词，并导致改进。</p><p id="bba3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">首先，我们得到一个投票者的数据集，然后我们可以训练真正的投票者。</p><p id="d8dc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">警告:下一部分将深入模型。让我们深入了解一下这个过程的难点！</p><h1 id="a823" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">令牌和图像关联:</h1><h1 id="c4b9" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">建模</h1><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es mv"><img src="../Images/66f212357cf89592e34e2a7c57650ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*Q8jkuAWqyZyLbMaksrLPdg.png"/></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mw"><img src="../Images/12e4c0dfb0f3ec27f2379a72011f6c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*43wz8Yk3Xdr-BNLR.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mx"><img src="../Images/5b3417b290051d8aff0b86cb52b71b91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yKe0HqTzXcm7QxV-bHa96g.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es my"><img src="../Images/c656d6dacf86f2e3b91639bf300fe420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pyEoV2jO9MOSkIp2.png"/></div></div></figure><p id="5705" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这类似于OpenAI最近在CLIP上的工作，该工作将图像分类转化为文本相似性问题。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es mz"><img src="../Images/ff0933af4f869010001510a58878b3f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*2F-DmNpCO5VnpfVA.png"/></div></figure><blockquote class="lr ls lt"><p id="189f" class="il im lf in b io ip iq ir is it iu iv lu ix iy iz lv jb jc jd lw jf jg jh ji ha bi translated">以上是OpenAI的片段中的部分代码。请注意图像和文本嵌入之间的内积的相似性。</p></blockquote><h1 id="97eb" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">培训:监管不力</h1><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es na"><img src="../Images/3f7957830927820103c9710c46d818f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVjT0CNvcn5t5qDikerxUA.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es nb"><img src="../Images/a9abd85ab7bbe79b83692a6626db5bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lg6hqwhs0iRWWPos.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es nc"><img src="../Images/0dcffd1d45905b9bfc328d34be50f1c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*Os7bc2M_jKtVNXiLeUAxVw.png"/></div></figure><h1 id="b3ad" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">推理</h1><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es nd"><img src="../Images/954bd5c052a8beb912555bbd936070c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*pmHpp_KIzNZyumlZQ5ypRg.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mz"><img src="../Images/bf301a7ce5490c852ebf40a9a35968dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*WozUWSi_GuOfmtdw.png"/></div></div></figure><blockquote class="lr ls lt"><p id="314e" class="il im lf in b io ip iq ir is it iu iv lu ix iy iz lv jb jc jd lw jf jg jh ji ha bi translated">图4:为了实现动词化过程，对于语言语料库中的标记，使用类似最近邻算法的东西从作为动词的图像集中检索图像。这些生成的标记用于从视觉监督到语言模型</p></blockquote><h1 id="022d" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">Vokenization过程概述</h1><ol class=""><li id="027f" class="mf mg hh in b io la is lb iw ne ja nf je ng ji mk ml mm mn bi translated">该模型接受一个句子(由标记组成)和一个图像作为输入。</li><li id="ae1a" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mk ml mm mn bi translated">将句子中的每个单词分配给其对应的相关图像</li><li id="143a" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mk ml mm mn bi translated">该句子在vokenizer中变成一系列记号，这输出了该句子上下文中记号和图像的相关性分数。</li></ol><h1 id="0cfe" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">结果:</h1><h2 id="fc7e" class="nh kd hh bd ke ni nj nk ki nl nm nn km iw no np kq ja nq nr ku je ns nt ky nu bi translated">表1(具有和不具有voken分类的预训练模型):</h2><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es nv"><img src="../Images/30eeeafe08ab820d49e3a960369bc7c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WyXGJCv5_rnzEm83.png"/></div></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es nw"><img src="../Images/e3eb87c2b87e7164dfd342863acce50e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xrt14xq2O0I5Yi49EUiNZw.png"/></div></div></figure><h1 id="b626" class="kc kd hh bd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz bi translated">应用:</h1><p id="c2a7" class="pw-post-body-paragraph il im hh in b io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji ha bi translated">将视觉和语言学习相结合的想法将在医学成像应用中流行，特别是用于自动医学图像诊断的视觉表示。例如，本文<a class="ae nx" href="https://https//paperswithcode.com/paper/contrastive-learning-of-medical-visual" rel="noopener ugc nofollow" target="_blank">从成对的图像和文本</a>中对比学习医学视觉表示，探索了具有短文本描述的射线照片图像，其中语义分割是耗时的。这种语音化技术有可能引导这些表示，并使用文本信息来改进自动医学成像。</p><p id="3468" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">vokens和其他基础语言系统的应用还有很多其他的可能性(下面仅举几个例子)。</p><ul class=""><li id="7d1b" class="mf mg hh in b io ip is it iw mh ja mi je mj ji mt ml mm mn bi translated">机器人视觉触摸</li><li id="a377" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mt ml mm mn bi translated">视觉-听觉</li><li id="28d6" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mt ml mm mn bi translated">语言-音频</li></ul><p id="ad0b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">随着自然语言处理和计算机视觉的不断进步，未来一定会一片光明！</p><h2 id="950a" class="nh kd hh bd ke ni nj nk ki nl nm nn km iw no np kq ja nq nr ku je ns nt ky nu bi translated">来源:</h2><ul class=""><li id="21be" class="mf mg hh in b io la is lb iw ne ja nf je ng ji mt ml mm mn bi translated"><a class="ae nx" href="https://arxiv.org/pdf/2010.06775v1.pdf" rel="noopener ugc nofollow" target="_blank">原始研究论文</a>:动词化:通过语境化、基于视觉的监督提高语言理解</li><li id="d13e" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mt ml mm mn bi translated"><a class="ae nx" href="https://analyticsindiamag.com/what-is-vokenization-image-text-nlp/" rel="noopener ugc nofollow" target="_blank">什么是动词化及其对自然语言处理应用的意义</a></li><li id="5839" class="mf mg hh in b io mo is mp iw mq ja mr je ms ji mt ml mm mn bi translated">《麻省理工科技评论》:这可能会导致常识人工智能的下一个重大突破</li></ul></div></div>    
</body>
</html>
<html>
<head>
<title>Principal Component Analysis(PCA) Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化的主成分分析</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/principal-component-analysis-pca-simplified-22ef97b0e1dc?source=collection_archive---------5-----------------------#2022-05-30">https://medium.com/mlearning-ai/principal-component-analysis-pca-simplified-22ef97b0e1dc?source=collection_archive---------5-----------------------#2022-05-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/7cdcdddb2039662f65b476a275a5d694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvLCtxP8ocXC2rEYdzRsCA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">source: author</figcaption></figure><p id="b5b1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">链接代码:<a class="ae jr" href="https://github.com/Jnjerry/ArticlesCode/tree/main/PCA" rel="noopener ugc nofollow" target="_blank"> Github </a></p><h1 id="7e78" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">问题陈述</h1><p id="712d" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">假设您有一个包含1000个要素的数据集。想象所有这些特征并试图解释这些特征之间的关系将是一场噩梦。此外，你的模型冒着<strong class="iv hi">过度拟合</strong>的风险。简单地说，过度拟合意味着您的模型已经记住了您的数据集模式太多，以至于在给定新数据时它表现不佳。</p><h1 id="a7cd" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">先决条件</h1><p id="baaf" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">数据集中的特征数量被称为其<strong class="iv hi">维度</strong>。因此，包含大量特征的数据集称为高维数据集，包含少量特征的数据集称为低维数据集。因此，为了解决我们上面的问题陈述，我们需要做的是<strong class="iv hi">将高维数据集转换成低维数据集</strong>。这叫做<strong class="iv hi">降维。</strong></p><p id="4fa8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="kv">请注意，降维不是删除列。它是对列中的信息进行数学转换，以获取相同的精确信息，但使用更少的列。例如，如果您有两个高度相关的特征，您可以将它们合并成一个新的特征。</em>T13】</strong></p><h1 id="03aa" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">降维的好处</h1><ul class=""><li id="53a5" class="kw kx hh iv b iw kq ja kr je ky ji kz jm la jq lb lc ld le bi translated">消耗较少的计算资源。</li><li id="ecdc" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lb lc ld le bi translated">运行速度更快的型号。</li><li id="e503" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lb lc ld le bi translated">改进您的模型性能。</li><li id="ae3c" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lb lc ld le bi translated">更好的数据可视化。</li></ul><p id="0e75" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">帮助我们降维的最流行的技术之一是主成分分析(<strong class="iv hi"> PCA)。</strong></p><p id="21ef" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kv"> PCA于1901年由</em> <a class="ae jr" href="https://en.wikipedia.org/wiki/Karl_Pearson" rel="noopener ugc nofollow" target="_blank"> <em class="kv">卡尔·皮尔逊</em> </a> <em class="kv">发明，至今仍在使用，已经证明它在降维方面是多么的高效。</em></p><h1 id="99fc" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">应用PCA</h1><ol class=""><li id="1ac3" class="kw kx hh iv b iw kq ja kr je ky ji kz jm la jq lk lc ld le bi translated"><strong class="iv hi">手动计算生成主成分</strong>。— PCA有一个数学方法。为了充分理解这个概念，我们将手动生成主成分。</li><li id="0f37" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lk lc ld le bi translated"><strong class="iv hi">使用scikit-learn库</strong> —我们将利用scikit-learn库为我们自动输出和生成主要组件。这是您在创建机器学习模型时最理想的使用方式。但是首先使用方法1来理解这个概念是很重要的。</li></ol><h1 id="f337" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">执行PCA的步骤</h1><ol class=""><li id="335d" class="kw kx hh iv b iw kq ja kr je ky ji kz jm la jq lk lc ld le bi translated">标准化</li><li id="6151" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lk lc ld le bi translated">协方差矩阵</li><li id="d6e4" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lk lc ld le bi translated">特征分解</li><li id="867d" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lk lc ld le bi translated">按特征值排序</li><li id="28a0" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lk lc ld le bi translated">选择你的主要成分</li></ol><h1 id="550d" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">标准化</h1><p id="d6f5" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">当分析数据时，我们处理的数据集的特征在数量和单位上有很大不同。例如，您可以处理以千克、千米、克、厘米等计量的要素。通过将机器学习技术应用于这些特征，例如，你的算法会认为100克大于1千克，这是不正确的，我们的算法会给我们错误的预测。</p><p id="a6d3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因此，在应用任何算法之前，我们需要想出一种方法来标准化我们的特征。因此，这意味着在处理体重(0-10000克)、年龄(0-100岁)和工资(0-8000美元)等变量时，特征缩放会将它们标准化到相同的范围内，例如，范围(0，1)，具体取决于所使用的缩放技术。</p><p id="313c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">请注意:如果变量之间的比例是一致的，那么标准化对于PCA来说可能是不必要的。</strong></p><h1 id="1026" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">协方差矩阵</h1><p id="b161" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">标准化数据集后，下一步是创建协方差矩阵。为了理解协方差矩阵，我们需要首先理解什么是方差和协方差。</p><p id="8702" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">方差— </strong>衡量您的数据被分散了多少。</p><p id="b635" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在下图中，我们有<strong class="iv hi"> x和y方差</strong>，其中<strong class="iv hi"> <em class="kv"> </em> x方差</strong>显示有多少数据在水平方向扩散，<strong class="iv hi"> y方差</strong>显示有多少数据在垂直方向扩散。因此，只看下图，x方差高于y方差，因为数据在水平轴上分布得更广。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div class="er es ll"><img src="../Images/861b94ea2dc7054cfc9c53de19bda3af.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*p32qHgCcY8-pKCsaUS_nYQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">source:author</figcaption></figure><p id="73e7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">协方差</strong> —这是<strong class="iv hi"> </strong>一种描述变量之间关系的度量。换句话说，你不能得到这种关系，因为你只使用了一个变量。然而，当你结合两个变量时，你可以得到关于它们如何相互联系以及它们的方向的信息。也就是说，如果变量x增加，变量y会增加还是减少或者保持不变。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lq"><img src="../Images/413d50f2bcbb230c57b2d1f410f614b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3HmBri739hheUzR03sAV4g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">variance vs covariance: source- author</figcaption></figure><p id="a1f2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">两个变量之间的协方差可以是正的、负的和零。这可以被视为您的数据具有正相关性、负相关性或无相关性，如下图所示。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/42ee697fe1f63b9195dc08f34038172c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*mSgamQYxXOk602Ak.jpg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">source- emathzone</figcaption></figure><p id="7c3a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">协方差矩阵</strong> —这是一个<strong class="iv hi">方阵</strong>，显示变量的<strong class="iv hi">方差</strong>和数据集中一对变量之间的<strong class="iv hi">协方差</strong>。如果变量X、Y和Z的值如下所示，那么我们将首先计算X、Y和Z的<strong class="iv hi">方差，分别为80.3、33.037和142.5。</strong></p><p id="9d4b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">z的方差最高，Y的方差最低。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/5e4651bae4bae4a2b42ff71af255e41b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rVOqFh1abzaKFYv-rgryiQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">covariance matrix: source -author</figcaption></figure><p id="37a0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">一旦获得了元素的方差，现在就可以计算协方差并创建协方差矩阵，如上图所示。</p><p id="941d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> cov(X，Y)是-13.865 </strong> —这是一个负数，意味着X增加，Y减少，反之亦然。</p><p id="4849" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> cov(X，Z)是14.25</strong>——这是一个正数，意味着随着X的增加，Z也增加，反之亦然。</p><p id="ae4f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> cov(Y，Z)是-39.525</strong>——这是一个负数，意味着随着Y的增加，Z减少，反之亦然。</p><p id="354a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因此，上面3个变量的公式如下所示，其中对角线元素表示数据集的方差，非对角线项表示一对变量之间的协方差。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/a6fa34df5eb36023684ee5f0d10b9571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*7ogGvGjxV07cqhz9emwt6w.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">covariance matrix: source-author</figcaption></figure><h1 id="e8cc" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">特征分解</strong></h1><p id="673f" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">现在你有了上面的协方差矩阵，下一步叫做特征分解，它是产生特征值和特征向量的简单过程。通常先找到一个特征值，然后找到一个特征向量来帮助我们得到主成分(我们得到的新变量是初始变量的组合或混合的结果)</p><p id="672a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">特征向量告诉我们数据集的方向。如果你的数据集有两个变量，比如说一个人的年龄和收入，你会期望两个特征向量来解释年龄和收入的方向。你也有两个特征值，表示特征向量的方差。</p><h1 id="1fa9" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">例子</h1><p id="524a" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">如果您有一个如下所示的二维数据集，那么您将有<strong class="iv hi">两个向量u和v。按照层级顺序，</strong> <strong class="iv hi"> u将被视为您的第一个向量</strong>(数据变化最大的方向)，而<strong class="iv hi"> v将被视为第二个向量</strong>(垂直于第一个特征向量的向量中变化最大的方向)。如果你有第三个特征向量，那么这将是垂直于前两个向量的方向中方差最大的一个，依此类推<strong class="iv hi">。用简单的英语来说，特征值就是你的箭头的长度，它解释了每个向量的方差。</strong></p><figure class="lm ln lo lp fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/eb08cc75812c89fb7eb57c698a41461f.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*CNgPTGQTKVA3P988Uk8jOg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">source:author</figcaption></figure><p id="2963" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">请访问此<a class="ae jr" href="https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/" rel="noopener ugc nofollow" target="_blank">链接</a>以获得对特征向量和值的更多了解。</p><h1 id="207a" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">按特征值排序并选择主成分</h1><p id="d484" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated"><strong class="iv hi">主成分</strong>是我们从初始变量的组合或混合中得到的新变量。特征向量通常乘以你的原始数据集得到<strong class="iv hi">主成分。</strong></p><p id="ac9d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">具有最低特征值的特征向量包含关于数据分布的最少信息，并且那些是我们理想地丢弃的。因此，如果从3个特征值中取两个最高值，那么你将得到2维数据集。一旦你决定了特征值，你现在把原始数据乘以相应的特征向量来得到主成分。如果你的年龄、身高和体重导致了肥胖，如果体重和身高有最高的特征值，那么你就会忽略年龄有最低的特征值。然后你将得到体重和身高的特征向量，你将得到主成分。这些将是数据集中的新要素。</p><h1 id="0ce3" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">手动计算和生成主成分</h1><ol class=""><li id="a2a6" class="kw kx hh iv b iw kq ja kr je ky ji kz jm la jq lk lc ld le bi translated">加载您的数据。</li></ol><pre class="lm ln lo lp fd lv lw lx ly aw lz bi"><span id="4871" class="ma jt hh lw b fi mb mc l md me">data=np.array([<br/>[6., 3., 2.],<br/>[3., 2., 7.],<br/>[5., 4., 2.],<br/>[1., 4., 3.],<br/>[7., 3., 1.0],<br/>[5., 1., 8.],<br/>[4., 2., 2.],<br/>[8., 6., 6.],<br/>[6., 3., 2.],<br/>[7., 1., 1.]])</span></pre><p id="d0de" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">2.标准化并计算协方差矩阵。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/67d90ec6756af71eacf5c231903635cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*tXIOEDdLXtZdrcEUCfbZBA.png"/></div></figure><p id="6718" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">3.特征分解得到特征值和特征向量。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/cade283a9ee7570a7ecba47e1ef827eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*aTphmchZQw7I68-B7Xf0Sw.png"/></div></figure><p id="2410" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">4.按特征值排序，得到按重要性排序的特征值和特征向量。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mh"><img src="../Images/98d278e5edc2e44512f5afdec816fc75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kIz0rN8xm8sn5xOOytanOA.png"/></div></div></figure><p id="703f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">5.将选择的特征向量乘以原始数据，得到主成分。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mi"><img src="../Images/beb0f0b30c5a213b625de7473f04bcab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VuWguTZtw4EV22ixt-o-VA.png"/></div></div></figure><h1 id="de17" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">使用Scikit的PCA-Learn</h1><ol class=""><li id="1b92" class="kw kx hh iv b iw kq ja kr je ky ji kz jm la jq lk lc ld le bi translated">加载您的数据—我们将使用pandas内置的葡萄酒数据集。</li></ol><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mj"><img src="../Images/9b050659a077e3acdc99e09beb763054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J9R0lKdpA3lZ2wieqJVjOA.png"/></div></div></figure><p id="fa35" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">2.标准化您的数据集并使其适合PCA方法。</p><p id="e8d4" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过将分量的数量指定为2 ( <code class="du mk ml mm lw b">n_components=2</code>)，您要求PCA找到最能解释数据可变性的两个分量。</p><p id="9cce" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">您可以根据自己的需求设置首选的组件数量，但是两个组件通常是最容易在散点图上解释和可视化的。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/4eb93046780d874404bfc6e63ec5693b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IvSwDqyObTGW5N9as9iqDA.png"/></div></div></figure><p id="a9b1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">3.输出您的新尺寸。</p><figure class="lm ln lo lp fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/9afcaa4a4cedcec111cb0f126b0f7a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JgNXxlJI0rrpoKX13mHPSA.png"/></div></div></figure><p id="1a39" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如果您的数据集中有其他要素(如目标变量),您可以将新要素连接到数据集中的其他要素，然后构建您的机器学习模型。</p><h1 id="0b78" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">何时使用PCA</h1><ol class=""><li id="b480" class="kw kx hh iv b iw kq ja kr je ky ji kz jm la jq lk lc ld le bi translated">当你想减少变量的数量，但不能清楚地确定你想删除的变量。</li><li id="f65e" class="kw kx hh iv b iw lf ja lg je lh ji li jm lj jq lk lc ld le bi translated">当你想确保你的变量是相互独立的。</li></ol><p id="606c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">代码链接:<a class="ae jr" href="https://github.com/Jnjerry/ArticlesCode/tree/main/PCA" rel="noopener ugc nofollow" target="_blank"> Github </a></p><div class="mp mq ez fb mr ms"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mt ab dw"><div class="mu ab mv cl cj mw"><h2 class="bd hi fi z dy mx ea eb my ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mz l"><h3 class="bd b fi z dy mx ea eb my ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="na l"><p class="bd b fp z dy mx ea eb my ed ef dx translated">medium.com</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng in ms"/></div></div></a></div></div></div>    
</body>
</html>
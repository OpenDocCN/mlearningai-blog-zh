<html>
<head>
<title>Generative Adversarial Networks (GANS) - A Practical Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络(GANS) -一个实际的实现</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/generative-adversarial-networks-gans-a-practical-implementation-90e5f54fb81d?source=collection_archive---------4-----------------------#2022-07-20">https://medium.com/mlearning-ai/generative-adversarial-networks-gans-a-practical-implementation-90e5f54fb81d?source=collection_archive---------4-----------------------#2022-07-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e4e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">GANS被设计用来创建逼真的图像。它由一个发生器和一个鉴别器网络组成。生成器网络将尝试从随机噪声中创建逼真的图像。鉴别器的职责非常简单。它所要做的就是验证一个图像是真是假。</p><p id="c866" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法的理想目标是很好地训练生成器网络，以便鉴别器将被生成器创建的假图像所愚弄，并使生成器相信它是真实的图像。在这里，我们将讨论使用手写数字的mnist数据集来训练我们的模型以生成相似图像的整个过程。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="023a" class="jl jm hh jh b fi jn jo l jp jq">import glob<br/>import imageio<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import os<br/>import PIL<br/>from tensorflow.keras import layers<br/>import time<br/>from IPython import display</span><span id="6f51" class="jl jm hh jh b fi jr jo l jp jq">(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()</span></pre><p id="29fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们加载mnist数据集，并从中获取训练图像和训练标签。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="37ae" class="jl jm hh jh b fi jn jo l jp jq">train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')</span><span id="835f" class="jl jm hh jh b fi jr jo l jp jq">train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]</span></pre><p id="ed10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图像的大小将被调整为(28，28，1)并且它们将被转换为浮点值。现在我们将像素值减去127.5，也就是255/2，这样两边的最大值就变成了(-127.5，+127.5)，现在很容易将其归一化为[-1，1]</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="8445" class="jl jm hh jh b fi jn jo l jp jq">BUFFER_SIZE = 60000<br/>BATCH_SIZE = 256</span></pre><p id="aa8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将批量设置为256。这意味着我们一次训练256张图片。混洗数据需要缓冲区大小。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="473d" class="jl jm hh jh b fi jn jo l jp jq">train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)</span></pre><p id="73f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">“from_tensor_slices”给出了切片元素的对象。数据集以256为一批创建，并使用缓冲区进行混洗。请记住，缓冲区的大小不应小于数据集的大小。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="1621" class="jl jm hh jh b fi jn jo l jp jq">def make_generator_model():<br/>    model = tf.keras.Sequential()<br/>    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))<br/>    model.add(layers.BatchNormalization())<br/>    model.add(layers.LeakyReLU())<br/>    model.add(layers.Reshape((7, 7, 256)))</span><span id="e144" class="jl jm hh jh b fi jr jo l jp jq">    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size</span><span id="6e52" class="jl jm hh jh b fi jr jo l jp jq">    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))</span><span id="0076" class="jl jm hh jh b fi jr jo l jp jq">    assert model.output_shape == (None, 7, 7, 128)</span><span id="7aff" class="jl jm hh jh b fi jr jo l jp jq">    model.add(layers.BatchNormalization())<br/>    model.add(layers.LeakyReLU())<br/>    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))</span><span id="add6" class="jl jm hh jh b fi jr jo l jp jq">    assert model.output_shape == (None, 14, 14, 64)</span><span id="45b2" class="jl jm hh jh b fi jr jo l jp jq">    model.add(layers.BatchNormalization())<br/>    model.add(layers.LeakyReLU())<br/>    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))</span><span id="7d50" class="jl jm hh jh b fi jr jo l jp jq">    assert model.output_shape == (None, 28, 28, 1)<br/>    return model</span></pre><p id="4f63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们需要生成器模型来从噪声中创建图像。输入形状给定为100，因为我们从100个点生成图像。然后，我们使用批处理规范化和泄漏relu。每一层的形状都不同，最后一层的形状应该是(28，28，1)。这个形状是我们原始数据的形状。</p><p id="5401" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">普通Conv2D对图像进行下采样，但这里我们使用Conv2D的转置对图像进行上采样，消除噪声。</p><p id="e6db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">assert函数用于检查是否按预期获得了形状。最后一层使用tanh作为激活函数，因为它的值在[-1，1]之间变化。请记住，我们将实像归一化为[-1，1]。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="105c" class="jl jm hh jh b fi jn jo l jp jq">generator = make_generator_model()</span><span id="5a24" class="jl jm hh jh b fi jr jo l jp jq">noise = tf.random.normal([1, 100])</span><span id="84cf" class="jl jm hh jh b fi jr jo l jp jq">generated_image = generator(noise, training=False)</span><span id="bd51" class="jl jm hh jh b fi jr jo l jp jq">plt.imshow(generated_image[0, :, :, 0], cmap='gray')</span></pre><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es js"><img src="../Images/478541fc708f02888b1937d0ee70da9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*bg4zrhRp-DuD01ciwiyVoQ.png"/></div></figure><p id="18a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，在创建模型之后，我们需要创建它的一个实例。然后我们会测试随机噪声产生的图像。我们将训练设置为假。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="c308" class="jl jm hh jh b fi jn jo l jp jq">def make_discriminator_model():</span><span id="0348" class="jl jm hh jh b fi jr jo l jp jq">    model = tf.keras.Sequential()<br/>    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[28, 28, 1]))</span><span id="11d8" class="jl jm hh jh b fi jr jo l jp jq">    model.add(layers.LeakyReLU())<br/>    model.add(layers.Dropout(0.3))<br/>    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))</span><span id="72ac" class="jl jm hh jh b fi jr jo l jp jq">    model.add(layers.LeakyReLU())<br/>    model.add(layers.Dropout(0.3))<br/>    model.add(layers.Flatten())<br/>    model.add(layers.Dense(1))<br/>    return model</span></pre><p id="aa61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，一旦我们创建了生成器，就该创建鉴别器了。相比之下，鉴别器比发生器轻，因为它只需要识别图像是真是假。此外，我们使用步长卷积。脱落层用于避免过度拟合。最后一层仅由一个具有乙状结肠激活功能的神经元组成。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="ecf2" class="jl jm hh jh b fi jn jo l jp jq">discriminator = make_discriminator_model()</span><span id="d862" class="jl jm hh jh b fi jr jo l jp jq">decision = discriminator(generated_image)</span><span id="072b" class="jl jm hh jh b fi jr jo l jp jq">print (decision)</span></pre><p id="9cea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，鉴别器的一个实例被创建，生成器生成的图像被提供给鉴别器。如果输出是零，则意味着图像是假的，如果是真的，则输出是一。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="f7e9" class="jl jm hh jh b fi jn jo l jp jq">cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)</span></pre><p id="8d60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是需要注意的一件重要事情。发生器和鉴别器的损耗是不同的。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="b84d" class="jl jm hh jh b fi jn jo l jp jq">def discriminator_loss(real_output, fake_output):</span><span id="f9d3" class="jl jm hh jh b fi jr jo l jp jq">    real_loss = cross_entropy(tf.ones_like(real_output), real_output)<br/>    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)<br/>    total_loss = real_loss + fake_loss<br/>    return total_loss</span></pre><p id="d803" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们创建一个定制的损失函数。因为我们把原始图像和伪图像提供给鉴别器。两者的损失计算方式不同。</p><p id="00d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于实图像的交叉熵函数，我们有两个参数。第二个是实际输出，第一个是期望输出。所以当我们给出一个真实的图像时，输出应该是1。“tf.ones_like”给出了所有1的矩阵。</p><p id="2b94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，当我们给出假数据时，期望输出应该为零。</p><p id="a10f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总损失是真实损失和虚假损失的总和。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="e1b2" class="jl jm hh jh b fi jn jo l jp jq">def generator_loss(fake_output):<br/>    return cross_entropy(tf.ones_like(fake_output), fake_output)</span></pre><p id="6f88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">发电机的情况也是如此。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="436b" class="jl jm hh jh b fi jn jo l jp jq">generator_optimizer = tf.keras.optimizers.Adam(1e-4)</span><span id="68c8" class="jl jm hh jh b fi jr jo l jp jq">discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)</span></pre><p id="3125" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">生成器和鉴别器的优化器是相似的。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="747d" class="jl jm hh jh b fi jn jo l jp jq">checkpoint_dir = './training_checkpoints'<br/>checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")</span><span id="d1b1" class="jl jm hh jh b fi jr jo l jp jq">checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,</span><span id="4d8c" class="jl jm hh jh b fi jr jo l jp jq">discriminator_optimizer=discriminator_optimizer,<br/>generator=generator, discriminator=discriminator)</span></pre><p id="88cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">保存检查点。</strong></p><p id="1084" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着模型被训练，生成器模型、鉴别器和优化器被保存在它定义的目录中。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="4535" class="jl jm hh jh b fi jn jo l jp jq">EPOCHS = 50<br/>noise_dim = 100<br/>num_examples_to_generate = 16</span><span id="5650" class="jl jm hh jh b fi jr jo l jp jq"># You will reuse this seed overtime (so it's easier)<br/># to visualize progress in the animated GIF)</span><span id="22cb" class="jl jm hh jh b fi jr jo l jp jq">seed = tf.random.normal([num_examples_to_generate, noise_dim])</span></pre><p id="0bf6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将纪元的数量设置为50。所以它被训练了50个纪元。如上所述，噪声的维数是100。</p><p id="43a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在测试模型时，我们创建了16个噪声样本，以观察生成的图像看起来有多好。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="f060" class="jl jm hh jh b fi jn jo l jp jq">@tf.function</span><span id="33c1" class="jl jm hh jh b fi jr jo l jp jq">def train_step(images):<br/>    noise = tf.random.normal([BATCH_SIZE, noise_dim])<br/>    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:<br/>      generated_images = generator(noise, training=True)</span><span id="6a09" class="jl jm hh jh b fi jr jo l jp jq">      real_output = discriminator(images, training=True)<br/>      fake_output = discriminator(generated_images, training=True)</span><span id="b917" class="jl jm hh jh b fi jr jo l jp jq">      gen_loss = generator_loss(fake_output)<br/>      disc_loss = discriminator_loss(real_output, fake_output)</span><span id="9b73" class="jl jm hh jh b fi jr jo l jp jq">    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)</span><span id="9a28" class="jl jm hh jh b fi jr jo l jp jq">    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)</span><span id="00be" class="jl jm hh jh b fi jr jo l jp jq">generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))<br/>discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))</span></pre><p id="c996" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们创建一个自定义的训练循环。我们需要指定数据应该如何从生成器流向鉴别器。</p><p id="79f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> @tf.function </strong>在我们创建自定义训练循环时使用。该注释导致函数被编译。</p><p id="5fa4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">梯度带有助于我们跟踪参数，并随时间记录下来。</p><p id="2ae9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">流程非常简单:</p><p id="6317" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们制造一些噪音。噪音被传送到发电机。它给出生成的图像。</p><p id="e979" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们将生成的输出提供给鉴别器，然后将该输出命名为fake_output。下一个真实图像被馈送到鉴别器，并且所获得的输出被称为真实输出。</p><p id="56dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分别计算了发生器和鉴别器的损耗函数。对于鉴别器，应该在两种情况下计算损失函数，即真实输出和虚假输出。</p><p id="d90d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在使用损失函数，我们使用梯度函数计算梯度，损失函数和可训练变量(模型的参数)作为输入。测量梯度，然后进行相应的优化。应用梯度功能进行优化。我们对鉴别器和发生器都这样做。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="4e8a" class="jl jm hh jh b fi jn jo l jp jq">def train(dataset, epochs):<br/>for epoch in range(epochs):<br/>start = time.time()<br/>for image_batch in dataset:<br/>train_step(image_batch)</span><span id="15d0" class="jl jm hh jh b fi jr jo l jp jq"># Produce images for the GIF as you go</span><span id="47ce" class="jl jm hh jh b fi jr jo l jp jq">display.clear_output(wait=True)<br/>generate_and_save_images(generator,epoch + 1,seed)</span><span id="6350" class="jl jm hh jh b fi jr jo l jp jq"># Save the model every 15 epochs</span><span id="3183" class="jl jm hh jh b fi jr jo l jp jq">if (epoch + 1) % 15 == 0:<br/>checkpoint.save(file_prefix = checkpoint_prefix)<br/>print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))</span><span id="4114" class="jl jm hh jh b fi jr jo l jp jq"># Generate after the final epoch</span><span id="8330" class="jl jm hh jh b fi jr jo l jp jq">display.clear_output(wait=True)<br/>generate_and_save_images(generator,epochs,seed)</span></pre><p id="898c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们创建一个训练循环，在这个循环中，我们向函数提供数据集以及历元数。</p><p id="5d8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们进入for循环。一次将数据集中的一批图像提供给训练集。在这里，一次对每一批进行整个训练步骤</p><p id="1be0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在每个时期之后，生成的图像被显示给我们以了解它进行得有多好。</p><p id="dbfa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在每15个时期之后，我们将权重保存到我们创建的检查点</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="200c" class="jl jm hh jh b fi jn jo l jp jq">def generate_and_save_images(model, epoch, test_input):</span><span id="5bf3" class="jl jm hh jh b fi jr jo l jp jq"># Notice `training` is set to False.<br/># This is so all layers run in inference mode (batchnorm).</span><span id="cd8b" class="jl jm hh jh b fi jr jo l jp jq">predictions = model(test_input, training=False)<br/>fig = plt.figure(figsize=(4, 4))</span><span id="909d" class="jl jm hh jh b fi jr jo l jp jq">for i in range(predictions.shape[0]):<br/>plt.subplot(4, 4, i+1)<br/>plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')<br/>plt.axis('off')<br/>plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))<br/>plt.show()</span></pre><p id="6d8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里测试已经完成。所以我们将训练设置为假。该函数接受模型、时期和测试输入。测试输入是之前创建的种子。种子确保每次都产生相同的随机噪声，这样我们每次都能得到相似的结果。</p><p id="4136" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们绘制预测图。我们将模型图像乘以127.5，再加上127.5，使其范围从0到255。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="d9b7" class="jl jm hh jh b fi jn jo l jp jq">train(train_dataset, EPOCHS)</span></pre><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es jw"><img src="../Images/9ad6705c48b575571db3b332ad7ba98a.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*kFtkn7Xdf8TawCCktlLhhw.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx">Epoch=1</figcaption></figure><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es jw"><img src="../Images/1ef76cebd10e083252d9e2e7b616ad36.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*bWvGiONDYsuy72loKoMYOg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx">Epoch=10</figcaption></figure><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es jw"><img src="../Images/cfbf42321cb47e6c2e67f6938d80714e.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*aegB9j29LbRPHkM5NwiPXg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx">Epoch=20</figcaption></figure><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es jw"><img src="../Images/832c33d98c4b8402f18df3070deed1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*9mMTFXZruRbIqxgSF4icdA.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx">Epoch=30</figcaption></figure><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es jw"><img src="../Images/8bb5ca1a96d54d78df2611e011f7f511.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*47K-3P3qJGsr_vu7wSkdgg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx">Epoch=40</figcaption></figure><figure class="jc jd je jf fd jt er es paragraph-image"><div class="er es jw"><img src="../Images/46a633304bc8b1696d5dd0e33575da09.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*kM8rz9oAZ840eCzJ3fZiew.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx">Epoch=50</figcaption></figure><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="65c9" class="jl jm hh jh b fi jn jo l jp jq">checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))</span></pre><p id="7961" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们使用“checkpoint.restore”来保存最新更新的权重。</p><p id="0c51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们成功地用GANS生成了手写数字。</p><p id="e28b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">谢谢大家！</p><div class="kb kc ez fb kd ke"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hi fi z dy kj ea eb kk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">medium.com</p></div></div><div class="kn l"><div class="ko l kp kq kr kn ks ju ke"/></div></div></a></div></div></div>    
</body>
</html>
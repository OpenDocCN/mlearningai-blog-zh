<html>
<head>
<title>Difference in ability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">能力上的差异</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/difference-in-ability-2e823ae447e?source=collection_archive---------2-----------------------#2022-11-15">https://medium.com/mlearning-ai/difference-in-ability-2e823ae447e?source=collection_archive---------2-----------------------#2022-11-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="beae" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">贝叶斯认知建模</h2></div><p id="c38a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇博文中，我将使用Lee &amp; Wagemakers所著的《<a class="ae js" href="https://bayesmodels.com/" rel="noopener ugc nofollow" target="_blank">贝叶斯认知建模</a>》一书中的另一个例子。这本书充满了认知心理学的例子，可以用贝叶斯方法来处理。由于这些例子大多是通过<strong class="iy hi"> WinBUGS </strong>完成的，我想看看我是否能使用<em class="jt"> brms </em>和<em class="jt"> stan </em>来重现它。所以，这就是这篇博文的内容。(我知道这本书也提供了stan代码，但我想看看我能用<em class="jt"> brms </em>走多远，它的功能比base <strong class="iy hi"> STAN </strong>或<strong class="iy hi"> WinBUGS </strong>要少)。</p><p id="6209" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这个例子中，我将模拟视觉刺激被识别的准确性——这里是色情图片。第一部分是对100名受试者的两次刺激的准确性进行建模。每个阶段有60次试验，所以我们可以把它当作一个二项式问题。</p><p id="3f70" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本书中，创建的模型是多元的，但是在<em class="jt"> brms </em>中，如果您不使用正态分布，这将更加困难。因此，我将使用残差的非结构化组件矩阵将模型转换为多级模型。这在一定程度上模拟了多元分布。</p><p id="4117" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们开始吧。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="a1dc" class="kd ke hh jz b be kf kg l kh ki">rm(list=ls()) <br/>library(dplyr)<br/>library(ggplot2)<br/>library(brms)<br/>library(bayesplot)<br/>library(tidybayes)<br/>library(marginaleffects)</span></pre><p id="b48a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里你可以看到刺激被正确识别的色情图片的比例。因为我们知道试验的次数正好是60次，所以我们也知道成功试验的次数。其实你下面看到的半连续音阶根本不是连续的。它只是一个二项式模型的变换。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="23aa" class="kd ke hh jz b be kf kg l kh ki">prc1.ero &lt;- c(0.6000000, 0.5333333, 0.6000000, 0.6000000, 0.4666667, <br/>              0.6666667, 0.6666667, 0.4000000, 0.6000000, 0.6000000,<br/>              0.4666667, 0.6666667, 0.4666667, 0.6000000, 0.3333333,<br/>              0.4000000, 0.4000000, 0.2666667, 0.3333333, 0.5333333,<br/>              0.6666667, 0.5333333, 0.6000000, 0.4000000, 0.4666667, <br/>              0.7333333, 0.6666667, 0.6000000, 0.6666667, 0.5333333,<br/>              0.5333333, 0.6666667, 0.4666667, 0.3333333, 0.4000000,<br/>              0.5333333, 0.4000000, 0.4000000, 0.3333333, 0.4666667,<br/>              0.4000000, 0.4666667, 0.4666667, 0.5333333, 0.3333333,<br/>              0.7333333, 0.2666667, 0.6000000, 0.5333333, 0.4666667,<br/>              0.4000000, 0.5333333, 0.6666667, 0.4666667, 0.5333333,<br/>              0.5333333, 0.4666667, 0.4000000, 0.4666667, 0.6666667,<br/>              0.4666667, 0.3333333, 0.3333333, 0.3333333, 0.4000000,<br/>              0.4000000, 0.6000000, 0.4666667, 0.3333333, 0.3333333,<br/>              0.6666667, 0.5333333, 0.3333333, 0.6000000, 0.4666667,<br/>              0.4666667, 0.4000000, 0.3333333, 0.4666667, 0.5333333,<br/>              0.8000000, 0.4000000, 0.5333333, 0.5333333, 0.6666667,<br/>              0.6666667, 0.6666667, 0.6000000, 0.6000000, 0.5333333,<br/>              0.3333333, 0.4666667, 0.6666667, 0.5333333, 0.3333333,<br/>              0.3333333, 0.2666667, 0.2666667, 0.4666667, 0.6666667)<br/><br/>prc2.ero &lt;- c(0.3333333, 0.6000000, 0.5333333, 0.2666667, 0.6666667,<br/>              0.5333333, 0.6666667, 0.4666667, 0.4666667, 0.6666667,<br/>              0.4000000, 0.6666667, 0.2666667, 0.4000000, 0.4666667,<br/>              0.3333333, 0.5333333, 0.6000000, 0.3333333, 0.4000000,<br/>              0.4666667, 0.4666667, 0.6000000, 0.5333333, 0.5333333,<br/>              0.6000000, 0.5333333, 0.6666667, 0.6000000, 0.2666667,<br/>              0.4666667, 0.4000000, 0.6000000, 0.5333333, 0.4000000,<br/>              0.4666667, 0.5333333, 0.3333333, 0.4000000, 0.4666667,<br/>              0.8000000, 0.6000000, 0.2000000, 0.6000000, 0.4000000,<br/>              0.4000000, 0.2666667, 0.2666667, 0.6000000, 0.4000000,<br/>              0.4000000, 0.4000000, 0.4000000, 0.4000000, 0.6666667,<br/>              0.7333333, 0.5333333, 0.5333333, 0.3333333, 0.6000000,<br/>              0.5333333, 0.5333333, 0.4666667, 0.5333333, 0.4666667,<br/>              0.5333333, 0.4000000, 0.4000000, 0.4666667, 0.6000000,<br/>              0.6000000, 0.6000000, 0.4666667, 0.6000000, 0.6666667,<br/>              0.5333333, 0.4666667, 0.6000000, 0.2000000, 0.5333333,<br/>              0.4666667, 0.4000000, 0.5333333, 0.5333333, 0.5333333,<br/>              0.5333333, 0.6000000, 0.6666667, 0.4000000, 0.4000000,<br/>              0.5333333, 0.8000000, 0.6000000, 0.4000000, 0.2000000,<br/>              0.6000000, 0.6666667, 0.4666667, 0.4666667, 0.4666667)   <br/>x &lt;- matrix(cbind(prc1.ero,prc2.ero),<br/>            nrow=100) <br/>n &lt;- nrow(x)<br/>dimnames(x)[[1]]&lt;-seq(1,100,1)<br/>dimnames(x)[[2]]&lt;-c("1", "2") <br/>df&lt;-as.data.frame(x)<br/>class(df)<br/>d &lt;- df<br/>Subject &lt;- rownames(d)<br/>rownames(d) &lt;- NULL<br/>df &lt;- cbind(Subject,d)<br/>colnames(df)&lt;-c("Subject", "Session1", "Session2")<br/><br/>ggplot(df, aes(Session1, Session2))+<br/>  geom_point()+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kj"><img src="../Images/2d3159bce7645fcb581d2611ac943fcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LKEBXf1br3383BcWlxsLhA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">And here we see, for 100 subjects, the percentage correct for <strong class="bd kv">Session 1</strong> and <strong class="bd kv">Session 2</strong>.</figcaption></figure><p id="5e27" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们也可以将数据转换成长格式。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="dd7c" class="kd ke hh jz b be kf kg l kh ki">df_long&lt;-df%&gt;%<br/>  tidyr::pivot_longer(cols=Session1:Session2,<br/>                      names_to = "Block",<br/>                      values_to = "PC")<br/>str(df_long)<br/>df_long$Subject&lt;-as.numeric(df_long$Subject)<br/>df_long&lt;-df_long%&gt;%dplyr::mutate(time = if_else(Block == "Session1",1,2))<br/>ggplot(df_long, aes(x=factor(Subject), <br/>               y=Block, <br/>               fill=PC))+<br/>  geom_tile()+<br/>  viridis::scale_fill_viridis(option="magma")+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kw"><img src="../Images/766bb09dd93deda247efbabe9928c638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0SodOTKXU6Pc-Ez5148ZQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">In long format it looks like this. You can clearly see that the previous accuracy does not have to predict the next accuracy. There are so many ways to model this data, but I will stick with the models from the book and have a go at them using <strong class="bd kv">brms</strong>.</figcaption></figure><p id="aa76" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这本书里还有一张图片，显示了一个组合的准确度出现的次数。让我们画出同样的图，但为此，我们需要计算组合。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="c754" class="kd ke hh jz b be kf kg l kh ki">colnames(df)&lt;-c("Subject", "Session1", "Session2")<br/>df%&gt;%<br/>  group_by(Session1, Session2)%&gt;%<br/>  count()%&gt;%<br/>  ggplot(., aes(x=Session1, <br/>                    y=Session2, <br/>                    size=n))+<br/>  geom_point()+<br/>  theme_bw()+<br/>  theme(legend.position = "none")</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kx"><img src="../Images/7c2dd5ee228f3d1dff9934e619aa0238.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pL2vfcxlYUiB-KVRSrVpcA.png"/></div></div></figure><p id="07d9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们做第一个建模练习。在<em class="jt"> brms </em>中，您可以使用多元正态分布，但这不是该数据集的正确分布。然而，让我们应用它，看看我们在哪里结束。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="f67f" class="kd ke hh jz b be kf kg l kh ki">bform1 &lt;- bf(mvbind(Session1, Session2) ~ 1)<br/>fit1   &lt;- brm(bform1, data = df, chains = 4, cores = 6)<br/>summary(fit1)<br/>plot(fit1)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es ky"><img src="../Images/87467e723a5918a418dad3939c8dc83b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vydoMj2tM0c83sZXwBfSQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">You can see that, simultaneously, the mean and standard deviation of both parameters (<strong class="bd kv">Session 1</strong> and <strong class="bd kv">Session 2</strong>) are measured, AND their correlation. It is that correlation that makes it multivariate normal.</figcaption></figure><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kz"><img src="../Images/25896fe1a812e030b9d2fd75bbe14da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWdEK85N-G2KJBKX3Jj2lQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">The <strong class="bd kv">recor </strong>parameter is the correlation parameter. As you can see, it is set at about 0.1, which means that there really is not a lot of correlation between <strong class="bd kv">Session 1</strong> and <strong class="bd kv">Session 2</strong> accuracy measures.</figcaption></figure><p id="2658" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们检查一下这个模型的预测能力。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="d190" class="kd ke hh jz b be kf kg l kh ki">df %&gt;%<br/>  add_epred_draws(fit1, <br/>                  ndraws=10, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  ggplot(., aes(Session1, Session2))+<br/>  geom_point()+<br/>  geom_point(aes(y = .epred, <br/>                group = paste(Subject, .draw)), alpha = 0.25, color="red") +<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es la"><img src="../Images/4798033f705d2ce825324e31d58bf49b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TlAmxjF3vfUAZG1ufynQuw.png"/></div></div></figure><p id="db00" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果我们用长格式绘制数据，如果你问我，我会觉得更有意义。此外，您应该能够看到还有另一种数据建模方式，那就是通过多级模型。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="6863" class="kd ke hh jz b be kf kg l kh ki">ggplot(df_long, aes(x=Block, <br/>                    y=PC, <br/>                    group=Subject))+<br/>  geom_line()+<br/>  geom_point()+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lb"><img src="../Images/228cfcca59c311b8898024a221eb8f45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IXukRLhSF6l9I32XVmBZkQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">The exact same data, but then in a “time-format”.</figcaption></figure><p id="89e2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们通过重复测量混合模型设计开始数据建模。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="63f9" class="kd ke hh jz b be kf kg l kh ki">get_prior(PC ~ time + (1 + time |Subject), <br/>          data = df_long,<br/>          family=Beta(link="logit"))</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lc"><img src="../Images/f1400a122bdb671a4c3dae6ea4f227db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01_iatEgXLwxHjNc1bCQmQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">These are the variables that need to go in.</figcaption></figure><p id="9956" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以绕一小段路，使用Frequentist模型，通过Beta分布对数据进行建模。这不是使用的最佳分布，因为数据本质上是二项式的，线性变换实际上没有帮助。换句话说，可以使用最接近生成过程的分布来对数据进行最佳建模。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="1167" class="kd ke hh jz b be kf kg l kh ki">fit2_try&lt;-glmmTMB::glmmTMB(PC ~ time +(1|Subject), <br/>                      data = df_long,<br/>                      family=list(family="beta",link="logit"))<br/>summary(fit2_try)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es ld"><img src="../Images/1777dcad60653a044de3a481618b12e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1tNSVXGM6xviezo9UDWKFg.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Not a whole lot of variance that can be attributed by the subject. This is because the accuracy scores within subjects, and across subjects, are really not that correlated. At all.</figcaption></figure><p id="1fc8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们使用brms框架运行重复测量模型。我将使用书中的先验知识，这些知识在平均意义上是没有信息的，但在精确度上却非常严格。这意味着它们是信息性的。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="87f8" class="kd ke hh jz b be kf kg l kh ki">fit2   &lt;- brm(PC ~ time + (1 + time|Subject), <br/>              data = df_long,<br/>              family=Beta(link="logit"),<br/>              prior = c(<br/>                prior(normal(0,0.001), class=Intercept),<br/>                prior(normal(0,0.001), class=b, coef=time), <br/>                prior(inv_gamma(0.001,0.001), class=phi), <br/>                prior(inv_gamma(0.001,0.001), class=sd,  coef=Intercept, group=Subject),<br/>                prior(inv_gamma(0.001,0.001), class=sd,  coef=time, group=Subject),<br/>                prior(lkj(1), class=cor, group=Subject)),<br/>              chains=4, <br/>              cores=6, <br/>              warmup = 3000,<br/>              iter = 6000)<br/>summary(fit2)<br/>plot(fit2)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es le"><img src="../Images/90c1b1e63e560064d00e5608cef878a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0oLB7t851xi2LfqN4SNXhw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Sampling is okay. The <strong class="bd kv">phi </strong>is the precision parameter of the <strong class="bd kv">Beta </strong>distribution I used.</figcaption></figure><div class="ju jv jw jx fd ab cb"><figure class="lf kk lg lh li lj lk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/6c9d7927c585b04d74f99688c70409bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*W1qiJTGMNq1CP7CDJlqeLQ.png"/></div></figure><figure class="lf kk ll lh li lj lk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/4b6b495fcef4d14363508ba05b69b223.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*UjjK8XfpOkHuaei75gJt6w.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx lm di ln lo">Here you can the see the mean (location) parameters, the variance components, their correlation, and the precision.</figcaption></figure></div><p id="cefb" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们绘制来自模型的预测，以更好地了解它到底在做什么。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="0fbe" class="kd ke hh jz b be kf kg l kh ki">df_long %&gt;%<br/>  add_epred_draws(fit2, <br/>                  ndraws=10, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  ggplot(., aes(x = time, <br/>             y = PC,<br/>             group=Subject)) +<br/>  geom_line(aes(y = .epred, <br/>                group = paste(Subject, .draw)), alpha = 0.25, color="red") +<br/>  geom_point(data = df_long, color="black")+<br/>  geom_line (data = df_long, color="black")+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lp"><img src="../Images/53feb3c89da1c91e18e6955683e40a1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G8YEI-_VoVdBQWh-RC7bgQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">The red line is the model prediction and it is predicting no correlation at all. The data, however, do seem to show correlation, but it is very subjective dependent and all over the place. <strong class="bd kv">Mixed models</strong> have a tendency to <a class="ae js" rel="noopener" href="/towards-artificial-intelligence/blups-and-shrinkage-in-mixed-models-sas-3fbc6662fa6b">shrink</a> extremes and this is most likely what we are seeing here.</figcaption></figure><p id="d847" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在是使用二项分布的时候了。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="1256" class="kd ke hh jz b be kf kg l kh ki">get_prior(Y | trials(N)  ~ <br/>            time + (1 + time|Subject), <br/>          data = df_long,<br/>          family=binomial(link = "logit"))<br/><br/>df_long$N=60<br/>df_long$Y&lt;-round(df_long$PC*df_long$N)<br/>fit2.1   &lt;- brm(Y | trials(N)  ~ <br/>                  time + (1 + time|Subject), <br/>                data = df_long,<br/>                family=binomial(link = "logit"),<br/>                prior = c(<br/>                  prior(normal(0,0.001), class=Intercept),<br/>                  prior(normal(0,0.001), class=b, coef=time), <br/>                  prior(inv_gamma(0.001,0.001), class=sd, group=Subject), <br/>                  prior(inv_gamma(0.001,0.001), class=sd,  coef=Intercept, group=Subject),<br/>                  prior(inv_gamma(0.001,0.001), class=sd,  coef=time, group=Subject),<br/>                  prior(lkj(1), class=cor, group=Subject)),<br/>                chains=4, <br/>                cores=6, <br/>                warmup = 3000,<br/>                iter = 6000)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lq"><img src="../Images/ad4b9384b2c0464321195c43398328f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZvVKk1cJGW_zm0uSLKMTw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Sampling looks good, but it seems as if there are no population-level effects. A very high negative correlation effect, which is clearly different from what we have seen before.</figcaption></figure><p id="04d6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我很想看看模型的预测会告诉我什么，尤其是考虑到高负相关系数。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="0e18" class="kd ke hh jz b be kf kg l kh ki">df_long %&gt;%<br/>  add_epred_draws(fit2.1, <br/>                  ndraws=10, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  ggplot(., aes(x = time, <br/>                y = Y,<br/>                group=Subject)) +<br/>  geom_line(aes(y = .epred, <br/>                group = paste(Subject, .draw)), alpha = 0.25, color="red") +<br/>  geom_point(data = df_long, color="black")+<br/>  geom_line (data = df_long, color="black")+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lr"><img src="../Images/c29ee115ac361fef4fc0a5fd205ed334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSO6XNi259HNbMC3pQ6BCw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Looking quite good!</figcaption></figure><p id="be7f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">看来这最后一个模型是成功的。现在，在这本书里有这个模型的续篇，其中包括人格特质外向性。假设是这一特征与情色图片的准确性有关，我将这样建模。老实说，我省略了很多背景故事，因为在这篇博客中，我只想告诉你如何对这种数据建模。如果你对背景感兴趣不如买这本书！</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="ed2d" class="kd ke hh jz b be kf kg l kh ki">extrav   &lt;- c(50, 80, 79, 56, 50, 80, 53, 84, 74, 67,<br/>              50, 45, 62, 65, 71, 71, 68, 63, 67, 58,<br/>              72, 73, 63, 54, 63, 70, 81, 71, 66, 74, <br/>              70, 84, 66, 73, 78, 64, 54, 74, 62, 71,<br/>              70, 79, 66, 64, 62, 63, 60, 56, 72, 72,<br/>              79, 67, 46, 67, 77, 55, 63, 44, 84, 65,<br/>              41, 62, 64, 51, 46, 53, 26, 67, 73, 39,<br/>              62, 59, 75, 65, 60, 69, 63, 69, 55, 63,<br/>              86, 70, 67, 54, 80, 71, 71, 55, 57, 41,<br/>              56, 78, 58, 76, 54, 50, 61, 60, 32, 67)<br/><br/>prc1.ero &lt;- c(0.6000000, 0.5333333, 0.6000000, 0.6000000, 0.4666667, <br/>              0.6666667, 0.6666667, 0.4000000, 0.6000000, 0.6000000,<br/>              0.4666667, 0.6666667, 0.4666667, 0.6000000, 0.3333333,<br/>              0.4000000, 0.4000000, 0.2666667, 0.3333333, 0.5333333,<br/>              0.6666667, 0.5333333, 0.6000000, 0.4000000, 0.4666667, <br/>              0.7333333, 0.6666667, 0.6000000, 0.6666667, 0.5333333,<br/>              0.5333333, 0.6666667, 0.4666667, 0.3333333, 0.4000000,<br/>              0.5333333, 0.4000000, 0.4000000, 0.3333333, 0.4666667,<br/>              0.4000000, 0.4666667, 0.4666667, 0.5333333, 0.3333333,<br/>              0.7333333, 0.2666667, 0.6000000, 0.5333333, 0.4666667,<br/>              0.4000000, 0.5333333, 0.6666667, 0.4666667, 0.5333333,<br/>              0.5333333, 0.4666667, 0.4000000, 0.4666667, 0.6666667,<br/>              0.4666667, 0.3333333, 0.3333333, 0.3333333, 0.4000000,<br/>              0.4000000, 0.6000000, 0.4666667, 0.3333333, 0.3333333,<br/>              0.6666667, 0.5333333, 0.3333333, 0.6000000, 0.4666667,<br/>              0.4666667, 0.4000000, 0.3333333, 0.4666667, 0.5333333,<br/>              0.8000000, 0.4000000, 0.5333333, 0.5333333, 0.6666667,<br/>              0.6666667, 0.6666667, 0.6000000, 0.6000000, 0.5333333,<br/>              0.3333333, 0.4666667, 0.6666667, 0.5333333, 0.3333333,<br/>              0.3333333, 0.2666667, 0.2666667, 0.4666667, 0.6666667)<br/>df2&lt;-cbind(extrav, prc1.ero)<br/>str(df2)<br/>df2&lt;-as.data.frame(df2)<br/>colnames(df2)&lt;-c("Extra", "PC")<br/>df2$N&lt;-60<br/>df2$Y&lt;-df2$PC*df2$N<br/>d &lt;- df2<br/>Subject &lt;- rownames(d)<br/>rownames(d) &lt;- NULL<br/>df2 &lt;- cbind(Subject,d)<br/>ggplot(df2, aes(Extra, Y))+<br/>  geom_point()+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es ls"><img src="../Images/ffe9547f8a4114eccbdefc3ccd10f7f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZqurXjhaQq220cRojBbCkQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">The extraversion rating of 100 subjects and the correct number of pictures (out of 60) in the first session.</figcaption></figure><p id="fc9b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们知道二项式是最好的，所以让我们直接应用它。下面的模型显示了准确性和外向性得分之间的函数关系。因此，你可以期待一个回归模型出来。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="8d12" class="kd ke hh jz b be kf kg l kh ki">get_prior(Y | trials(N) ~ Extra , <br/>          data = df2,<br/>          family=binomial(link = "logit"))<br/>df2$N&lt;-as.integer(df2$N)<br/>df2$Y&lt;-as.integer((df2$Y))<br/>fit3&lt;-brms::brm(Y | trials(N) ~ Extra, <br/>               data = df2,<br/>               family=binomial(link = "logit"),<br/>               prior = c(<br/>                 prior(normal(0, 1), class=b, coef=Extra ),<br/>                 prior(normal(0, 1), class=Intercept)), <br/>               chains=4, <br/>               cores=6, <br/>               warmup = 3000,<br/>               iter = 6000)<br/>summary(fit3)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lt"><img src="../Images/a4af8849139d666de10e250a27b4211a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZaeEr_K7DbT8vd1cuwCe9g.png"/></div></div></figure><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="772f" class="kd ke hh jz b be kf kg l kh ki">df2 %&gt;%<br/>  add_epred_draws(fit3, <br/>                  ndraws=200, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  mutate(PC_pred = .epred/N)%&gt;%<br/>  ggplot(., aes(x = Extra, <br/>                y = PC)) +<br/>  geom_line(aes(y = PC_pred, <br/>                group = paste(.draw)), alpha = 0.25, color="red") +<br/>  geom_point(data = df2, color="black")+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lu"><img src="../Images/6310fcb1004f06b8fa5bda76487ad436.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2-MyWUr6dyXdE-3TH8Z4A.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">As predicted, the predictions show a regression. However, this is not the final model.</figcaption></figure><p id="1013" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">既然我们知道外向性得分，我们也可以将其应用到之前的模型中，该模型显示了<strong class="iy hi">时段1 </strong>和<strong class="iy hi">时段2 </strong>之间的相关性。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="d768" class="kd ke hh jz b be kf kg l kh ki">df_long$Extra&lt;-rep(df2$Extra, each=2)<br/>ggplot(df_long, aes(x=Extra, y=PC, color=factor(time)))+<br/>  geom_point()+<br/>  theme_bw()+<br/>  labs(col="time")</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lv"><img src="../Images/2e6d3ffd2fe596bc56aa35d8262ba58c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0bfLHFoZaZ0smZxEgzDFsw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">The extra score and accuracy for <strong class="bd kv">Session 1</strong> and <strong class="bd kv">Session 2 </strong>(time=1 &amp; time=2).</figcaption></figure><p id="ce2d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们建立模型，全力以赴。在这个模型中，我们指定外向性得分将对每次会话产生不同的影响，并且在受试者内部和受试者之间存在差异。</p><p id="9cad" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，测试版的模型只是向你展示这个模型会有多糟糕。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="325e" class="kd ke hh jz b be kf kg l kh ki">fit4   &lt;- brm(PC ~ time*Extra + (1 + time|Subject), <br/>              data = df_long,<br/>              family=Beta(link="logit"),<br/>              prior = c(<br/>                prior(normal(0,0.001), class=Intercept),<br/>                prior(normal(0,0.001), class=b, coef=time),<br/>                prior(normal(0,0.001), class=b, coef=Extra), <br/>                prior(inv_gamma(0.001,0.001), class=phi), <br/>                prior(inv_gamma(0.001,0.001), class=sd,  coef=Intercept, group=Subject),<br/>                prior(inv_gamma(0.001,0.001), class=sd,  coef=time, group=Subject),<br/>                prior(lkj(1), class=cor, group=Subject)),<br/>              chains=4, <br/>              cores=6, <br/>              warmup = 3000,<br/>              iter = 6000)<br/>summary(fit4)<br/>pp_check(fit4, ndraws=200)<br/>df_long %&gt;%<br/>  add_epred_draws(fit4, <br/>                  ndraws=100, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  ggplot(., aes(x = Extra, <br/>                y = PC)) +<br/>  geom_point(aes(y = .epred, <br/>                group = paste(Subject, .draw)), alpha = 0.25, color="red") +<br/>  geom_point(data = df_long, color="black")+<br/>  theme_bw()+<br/>  facet_wrap(~time)<br/><br/>df_long %&gt;%<br/>  add_epred_draws(fit4, <br/>                  ndraws=10, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  ggplot(., aes(x = Extra, <br/>                y = PC)) +<br/>  geom_point(aes(y = .epred, <br/>                 group = paste(Subject, .draw)), alpha = 0.25, color="red") +<br/>  geom_point(data = df_long, color="black")+<br/>  theme_bw()+<br/>  facet_wrap(~time)</span></pre><div class="ju jv jw jx fd ab cb"><figure class="lf kk lw lh li lj lk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/7ab78ac2b0ea4708dcba46e6872b3b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*3CrWybQ2Zthx6HRft4TkIA.png"/></div></figure><figure class="lf kk lx lh li lj lk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/aa3958c40c30e5dffa1971b9c0ca97dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*QIWL5DGtgNllyd9Knf0rQQ.png"/></div></figure><figure class="lf kk ly lh li lj lk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/fcf23ce289987dc0677b9950afb68113.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*g_Sy-CKdsQST3L5pgbhx-Q.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx lz di ma lo">The model is not good with extreme Rhat values. This shows in the resulting predictions which are off.</figcaption></figure></div><p id="7c75" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，二项式模型。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="0b33" class="kd ke hh jz b be kf kg l kh ki">fit5   &lt;- brm(Y | trials(N) ~ time*Extra + (1 + time|Subject), <br/>              data = df_long,<br/>              family=binomial(link="logit"),<br/>              prior = c(<br/>                prior(normal(0,0.001), class=Intercept),<br/>                prior(normal(0,0.001), class=b, coef=time),<br/>                prior(normal(0,0.001), class=b, coef=Extra), <br/>                prior(inv_gamma(0.001,0.001), class=sd, group=Subject), <br/>                prior(inv_gamma(0.001,0.001), class=sd,  coef=Intercept, group=Subject),<br/>                prior(inv_gamma(0.001,0.001), class=sd,  coef=time, group=Subject),<br/>                prior(lkj(1), class=cor, group=Subject)),<br/>              chains=4, <br/>              cores=6, <br/>              warmup = 3000,<br/>              iter = 6000)<br/>summary(fit5)<br/>pp_check(fit5, ndraws=200)<br/>df_long %&gt;%<br/>  add_epred_draws(fit5, <br/>                  ndraws=100, <br/>                  allow_new_levels = TRUE) %&gt;%<br/>  ggplot(., aes(x = Extra, <br/>                y = Y)) +<br/>  geom_point(aes(y = .epred, <br/>                 group = paste(Subject, .draw)), alpha = 0.25, color="red") +<br/>  geom_point(data = df_long, color="black")+<br/>  theme_bw()+<br/>  facet_wrap(~time)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es mb"><img src="../Images/7ec399b2f2abfc1fe286b8b5f74af7b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CjUut9BQsKFa0Q8-yZH21A.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Good Rhat values means good sampling.</figcaption></figure><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es mc"><img src="../Images/56227afea6afc66b8026a3fe8ec4d7fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YRbrSRWwO43GNcTEgcb1Dw.png"/></div></div></figure><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es md"><img src="../Images/4060bd1fd31a14330c4e69ba3ed36d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GgC9g11DG4Nud_WhRW800g.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Predictions also looking good! However, because the sampling space overlaps you can not directly see how good the model is. Lets redo the predictions in long format.</figcaption></figure><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="f231" class="kd ke hh jz b be kf kg l kh ki">df_long %&gt;%<br/>  add_epred_draws(fit5, <br/>                  ndraws=100, <br/>                  allow_new_levels = TRUE)%&gt;%<br/>  group_by(Subject, <br/>           Block, <br/>           time)%&gt;%<br/>  dplyr::summarise(meanpred = mean(.epred), <br/>                   meanY = mean(Y), <br/>                   meanN = mean(N))%&gt;%<br/>  ggplot(.)+<br/>  geom_point(aes(x=time, y=meanY, group=Subject))+<br/>  geom_line(aes(x=time, y=meanY, group=Subject))+<br/>  geom_line(aes(x=time, y=meanpred, group=Subject), col="red", alpha=0.5)+<br/>  theme_bw()</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es me"><img src="../Images/a43cd118d468ebad9667c888ac406514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vV2iW7r2lzragm_ke2Nldw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Much better!</figcaption></figure><p id="5d34" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们也可以将最后两个图结合起来，将连续变量外向性切割成一个二元变量，然后绘制汇总预测。</p><pre class="ju jv jw jx fd jy jz ka bn kb kc bi"><span id="3117" class="kd ke hh jz b be kf kg l kh ki">df_long$CutExtra&lt;-cut(df_long$Extra, breaks=5)<br/>table(df_long$CutExtra)<br/>df_long %&gt;%<br/>  add_epred_draws(fit5, <br/>                  ndraws=100, <br/>                  allow_new_levels = TRUE)%&gt;%<br/>  group_by(CutExtra, <br/>           Block, <br/>           time)%&gt;%<br/>  dplyr::summarise(meanpred = mean(.epred), <br/>                   meanY = mean(Y), <br/>                   meanN = mean(N))%&gt;%<br/>  ggplot(.)+<br/>  geom_point(aes(x=time, y=meanY, group=CutExtra))+<br/>  geom_line(aes(x=time, y=meanY, group=CutExtra))+<br/>  geom_point(aes(x=time, y=meanpred, group=CutExtra), col="red")+<br/>  geom_line(aes(x=time, y=meanpred, group=CutExtra), col="red")+<br/>  theme_bw()+<br/>  facet_wrap(~CutExtra)</span></pre><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es mf"><img src="../Images/8eaeba4856e8415416785d020430499b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wOMojcvXNin_WhNs40Zv7g.png"/></div></div></figure><figure class="ju jv jw jx fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es mg"><img src="../Images/ad9f90ee2254e4841c3ef6648702cda1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9hYF5kJVOQyQ-J1PjmKIg.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">As you can see, prediction summaries overlap with observed summaries, except for the first split, but that makes sense considering that bin only has four observations.</figcaption></figure><p id="6772" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我想这就是了。我们现在有两个模型，这些模型是多水平二项式模型，与多元二项式模型相当。尽管您不能在brms中将多元二项式指定为分布，但与多元正态不同，我们可以对其建模！</p><p id="ab79" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果有任何问题，或事情不对劲，请让我知道！</p><div class="mh mi ez fb mj mk"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">medium.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my kp mk"/></div></div></a></div></div></div>    
</body>
</html>
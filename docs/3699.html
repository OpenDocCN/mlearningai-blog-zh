<html>
<head>
<title>Realtime Number Plate Detection using Yolov7 — Easiest Explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Yolov7进行实时车牌检测——最简单的解释</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/realtime-number-plate-detection-using-yolov7-easiest-explanation-df4a4ac82fec?source=collection_archive---------2-----------------------#2022-10-10">https://medium.com/mlearning-ai/realtime-number-plate-detection-using-yolov7-easiest-explanation-df4a4ac82fec?source=collection_archive---------2-----------------------#2022-10-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/2e8a870da5bb3e9bd3a2962bed51071d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-FqcpbzJKmWfOPvve9oNIA.png"/></div></div></figure><p id="77f4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">嘿，伙计们，在这个博客中，我们将看到如何使用YOLOv7 来执行<strong class="ir hi">车牌检测，方法是在我们定制的车牌数据上训练YOLOv7。</strong></p><p id="356d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">点击此处阅读完整博客—<a class="ae jn" href="https://machinelearningprojects.net/?p=11957" rel="noopener ugc nofollow" target="_blank">https://machine learning projects . net/number-plate-detection-using-yolov 7/</a></p><p id="abdb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">点击此处查看视频—【https://youtu.be/beV0nWFlYGc T4】</p><p id="8d51" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> YOLOv7是最新的实时物体检测模型</strong>。</p><p id="c3f3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您可以将它用于不同的工业应用。还有，你可以优化模型，也就是把模型转换成ONNX，TensorRT等，这样会增加吞吐量，运行边缘设备。</p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jo"><img src="../Images/df9f1bdf99ff538e76d5eb750df22d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SbjkURVq__dJkUl7.png"/></div></div></figure><p id="2bb6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这篇博客中，我们将看到在我们的自定义数据集上训练YOLOv7的分步指南。</p><p id="37fd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，没有任何进一步的原因，让我们做吧…</p><h1 id="9f59" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用Yolov7偷窥我们的车牌检测</h1><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es kr"><img src="../Images/65bb7b77897529cd37c0585f65102ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*fVDe3BAVKfqDFqpq46pV9A.gif"/></div></figure><h1 id="4d3d" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">步骤1-收集车牌数据集</h1><ul class=""><li id="5651" class="ks kt hh ir b is ku iw kv ja kw je kx ji ky jm kz la lb lc bi translated">为了训练的目的，我基本上使用了2个数据集。</li><li id="a726" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">数据集1 — <a class="ae jn" href="https://www.kaggle.com/datasets/deepakat002/indian-vehicle-number-plate-yolo-annotation" rel="noopener ugc nofollow" target="_blank">印度车辆牌照yolo注释</a></li><li id="4bd7" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">数据集2 — <a class="ae jn" href="https://www.kaggle.com/datasets/elysian01/car-number-plate-detection" rel="noopener ugc nofollow" target="_blank">汽车牌照检测</a></li><li id="ba43" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">数据集1已经具有YOLO注释。</li><li id="418b" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">但是对于数据集2，您必须对其进行注释。</li><li id="97bb" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">对于一个<strong class="ir hi">更简单的注释过程</strong>，你可以安装<strong class="ir hi">‘labelImg’</strong>python包。</li></ul><pre class="jp jq jr js fd li lj lk ll aw lm bi"><span id="f604" class="ln ju hh lj b fi lo lp l lq lr">pip install labelImg</span></pre><ul class=""><li id="3af2" class="ks kt hh ir b is it iw ix ja ls je lt ji lu jm kz la lb lc bi translated">安装软件包后，打开终端并运行“labelImg”命令。</li><li id="26d8" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">这将打开一个图形用户界面。</li><li id="f1a3" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">在其中选择图像目录。<strong class="ir hi">图像目录是存储您想要注释</strong>的所有图像的地方。</li><li id="44fe" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">更改其中的保存目录。<strong class="ir hi"> Save Director是存储注释的地方</strong>。</li><li id="93de" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">最后，确保将<strong class="ir hi">格式设置为YOLO，而不是帕斯卡沃克</strong>。</li></ul><h1 id="31aa" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">步骤2 —让我们在自定义数据集上训练YOLOv7</h1><ul class=""><li id="ef70" class="ks kt hh ir b is ku iw kv ja kw je kx ji ky jm kz la lb lc bi translated">到这一步，你应该有2个文件夹；图像和标签。</li><li id="b828" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated"><strong class="ir hi">图像文件夹应包含所有图像，标签文件夹应包含txt格式的所有注释。</strong></li><li id="b729" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">如果你没有看过我之前写的关于YOLOv7定制训练的博客，请去看看。</li></ul><p id="71e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jn" href="https://machinelearningprojects.net/train-yolov7-on-the-custom-dataset/" rel="noopener ugc nofollow" target="_blank">在自定义数据集上训练YOLOv7的最简单方法</a></p><ul class=""><li id="2482" class="ks kt hh ir b is it iw ix ja ls je lt ji lu jm kz la lb lc bi translated">当您在号码牌数据集上训练YOLOv7时，<strong class="ir hi">您将获得一个PyTorch重量文件。pt”格式</strong>。</li><li id="8973" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">那是我们进行推论所需要的最重要的文件。</li></ul><h1 id="746d" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">第三步——根据图像和视频进行推断</h1><h1 id="b555" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">图像文件推理</h1><ul class=""><li id="dde6" class="ks kt hh ir b is ku iw kv ja kw je kx ji ky jm kz la lb lc bi translated">下面是对图像文件进行推理的<strong class="ir hi">代码。</strong></li><li id="41fb" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">在<strong class="ir hi">第15行，我们已经加载了PyTorch重量</strong>文件。</li><li id="45d4" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">在<strong class="ir hi">第20行，我们给出了视频文件的路径</strong>。</li></ul><pre class="jp jq jr js fd li lj lk ll aw lm bi"><span id="67eb" class="ln ju hh lj b fi lo lp l lq lr"># Number Plate Detection using Yolov7</span><span id="52f7" class="ln ju hh lj b fi lv lp l lq lr">import matplotlib.pyplot as plt<br/>import torch<br/>import cv2<br/>import numpy as np<br/>import time</span><span id="c614" class="ln ju hh lj b fi lv lp l lq lr">from torchvision import transforms<br/>from utils.datasets import letterbox<br/>from utils.general import non_max_suppression_kpt<br/>from utils.plots import output_to_keypoint, plot_skeleton_kpts</span><span id="9b0d" class="ln ju hh lj b fi lv lp l lq lr">device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")<br/>weigths = torch.load('best.pt')<br/>model = weigths['model']<br/>model = model.half().to(device)<br/>_ = model.eval()</span><span id="9be2" class="ln ju hh lj b fi lv lp l lq lr">img_path = '1.jpg'</span><span id="f10a" class="ln ju hh lj b fi lv lp l lq lr">img = cv2.imread(img_path)</span><span id="1956" class="ln ju hh lj b fi lv lp l lq lr"># Get the frame width and height.<br/>h,w,c = img.shape<br/>frame_width = w<br/>frame_height = h<br/></span><span id="b3b1" class="ln ju hh lj b fi lv lp l lq lr">orig_image = img<br/>image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)<br/>image = letterbox(image, (frame_width), stride=64, auto=True)[0]<br/>image_ = image.copy()<br/>image = transforms.ToTensor()(image)<br/>image = torch.tensor(np.array([image.numpy()]))<br/>image = image.to(device)<br/>image = image.half()</span><span id="843f" class="ln ju hh lj b fi lv lp l lq lr">with torch.no_grad():<br/>    output, _ = model(image)</span><span id="8121" class="ln ju hh lj b fi lv lp l lq lr">output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], kpt_label=True)<br/>output = output_to_keypoint(output)<br/>nimg = image[0].permute(1, 2, 0) * 255<br/>nimg = nimg.cpu().numpy().astype(np.uint8)<br/>nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)<br/>for idx in range(output.shape[0]):<br/>    # plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)</span><span id="9992" class="ln ju hh lj b fi lv lp l lq lr">    # Comment/Uncomment the following lines to show bounding boxes around persons.<br/>    xmin, ymin = (output[idx, 2]-output[idx, 4]/2), (output[idx, 3]-output[idx, 5]/2)<br/>    xmax, ymax = (output[idx, 2]+output[idx, 4]/2), (output[idx, 3]+output[idx, 5]/2)</span><span id="3d2d" class="ln ju hh lj b fi lv lp l lq lr">    plate_roi = nimg[int(ymin):int(ymax),int(xmin):int(xmax)]<br/>    cv2.imshow('Plate',plate_roi)</span><span id="0ad9" class="ln ju hh lj b fi lv lp l lq lr">    cv2.putText(nimg, "Number Plate", (int(xmin), int(ymin)-5), cv2.FONT_HERSHEY_SIMPLEX,1, (228, 79, 215), 2)<br/>    cv2.rectangle(<br/>        nimg,<br/>        (int(xmin), int(ymin)),<br/>        (int(xmax), int(ymax)),<br/>        color=(228, 79, 215),<br/>        thickness=1,<br/>        lineType=cv2.LINE_AA<br/>    )</span><span id="0284" class="ln ju hh lj b fi lv lp l lq lr"># Convert from BGR to RGB color format.<br/>cv2.imwrite('result.jpg',nimg)</span></pre><h1 id="1c98" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结果</h1><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/c281ba391d38d2ab96cd99ef26f3cf41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VI-BhABru3qWFONr.jpg"/></div></div></figure><ul class=""><li id="6a05" class="ks kt hh ir b is it iw ix ja ls je lt ji lu jm kz la lb lc bi translated">我们的模型在这张图片上表现良好。</li><li id="f14a" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">轿车和卡车的<strong class="ir hi">车牌均检测成功</strong>。</li><li id="0c69" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated"><strong class="ir hi">虽然它也检测到一些噪声，但为了避免这种情况，我们可以对更多数据和更多时期进行训练。</strong></li></ul><h1 id="833f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">视频文件推理</h1><ul class=""><li id="f99a" class="ks kt hh ir b is ku iw kv ja kw je kx ji ky jm kz la lb lc bi translated">下面是对视频文件进行推理的<strong class="ir hi">代码。</strong></li><li id="390f" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">在<strong class="ir hi">第15行，我们已经加载了PyTorch重量</strong>文件。</li><li id="d8b9" class="ks kt hh ir b is ld iw le ja lf je lg ji lh jm kz la lb lc bi translated">在<strong class="ir hi">第20行，我们给出了视频文件</strong>的路径。</li></ul><pre class="jp jq jr js fd li lj lk ll aw lm bi"><span id="18d7" class="ln ju hh lj b fi lo lp l lq lr"># Number Plate Detection using Yolov7</span><span id="00e5" class="ln ju hh lj b fi lv lp l lq lr">import matplotlib.pyplot as plt<br/>import torch<br/>import cv2<br/>import numpy as np<br/>import time</span><span id="95da" class="ln ju hh lj b fi lv lp l lq lr">from torchvision import transforms<br/>from utils.datasets import letterbox<br/>from utils.general import non_max_suppression_kpt<br/>from utils.plots import output_to_keypoint, plot_skeleton_kpts</span><span id="4a2f" class="ln ju hh lj b fi lv lp l lq lr">device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")<br/>weigths = torch.load('best.pt')<br/>model = weigths['model']<br/>model = model.half().to(device)<br/>_ = model.eval()</span><span id="6165" class="ln ju hh lj b fi lv lp l lq lr">video_path = '1.mp4'</span><span id="9362" class="ln ju hh lj b fi lv lp l lq lr">cap = cv2.VideoCapture(video_path)<br/>if (cap.isOpened() == False):<br/>  print('Error while trying to read video. Please check path again')</span><span id="3e3a" class="ln ju hh lj b fi lv lp l lq lr"># Get the frame width and height.<br/>frame_width = int(cap.get(3))<br/>frame_height = int(cap.get(4))</span><span id="ef37" class="ln ju hh lj b fi lv lp l lq lr"># Pass the first frame through `letterbox` function to get the resized image,<br/># to be used for `VideoWriter` dimensions. Resize by larger side.<br/>vid_write_image = letterbox(cap.read()[1], (frame_width), stride=64, auto=True)[0]<br/>resize_height, resize_width = vid_write_image.shape[:2]</span><span id="ece6" class="ln ju hh lj b fi lv lp l lq lr"># Define codec and create VideoWriter object .<br/>out = cv2.VideoWriter("result.mp4",<br/>                    cv2.VideoWriter_fourcc(*'mp4v'), 30,<br/>                    (resize_width, resize_height))<br/></span><span id="4da1" class="ln ju hh lj b fi lv lp l lq lr">frame_count = 0 # To count total frames.<br/>total_fps = 0 # To get the final frames per second.<br/></span><span id="00f6" class="ln ju hh lj b fi lv lp l lq lr">while(cap.isOpened):<br/>  # Capture each frame of the video.<br/>  ret, frame = cap.read()<br/>  if ret:<br/>      orig_image = frame<br/>      image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)<br/>      image = letterbox(image, (frame_width), stride=64, auto=True)[0]<br/>      image_ = image.copy()<br/>      image = transforms.ToTensor()(image)<br/>      image = torch.tensor(np.array([image.numpy()]))<br/>      image = image.to(device)<br/>      image = image.half()</span><span id="2aa7" class="ln ju hh lj b fi lv lp l lq lr">      # Get the start time.<br/>      start_time = time.time()<br/>      with torch.no_grad():<br/>          output, _ = model(image)<br/>        # Get the end time.<br/>      end_time = time.time()<br/>      # Get the fps.<br/>      fps = 1 / (end_time - start_time)<br/>      # Add fps to total fps.<br/>      total_fps += fps<br/>      # Increment frame count.<br/>      frame_count += 1</span><span id="2397" class="ln ju hh lj b fi lv lp l lq lr">      output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], kpt_label=True)<br/>      output = output_to_keypoint(output)<br/>      nimg = image[0].permute(1, 2, 0) * 255<br/>      nimg = nimg.cpu().numpy().astype(np.uint8)<br/>      nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)<br/>      for idx in range(output.shape[0]):<br/>          # plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)</span><span id="e36d" class="ln ju hh lj b fi lv lp l lq lr">          # Comment/Uncomment the following lines to show bounding boxes around persons.<br/>          xmin, ymin = (output[idx, 2]-output[idx, 4]/2), (output[idx, 3]-output[idx, 5]/2)<br/>          xmax, ymax = (output[idx, 2]+output[idx, 4]/2), (output[idx, 3]+output[idx, 5]/2)</span><span id="572a" class="ln ju hh lj b fi lv lp l lq lr">          plate_roi = nimg[int(ymin):int(ymax),int(xmin):int(xmax)]<br/>          cv2.imshow('Plate',plate_roi)<br/>     <br/>          cv2.putText(nimg, "Number Plate", (int(xmin), int(ymin)-5), cv2.FONT_HERSHEY_SIMPLEX,1, (228, 79, 215), 2)<br/>          cv2.rectangle(<br/>              nimg,<br/>              (int(xmin), int(ymin)),<br/>              (int(xmax), int(ymax)),<br/>              color=(228, 79, 215),<br/>              thickness=1,<br/>              lineType=cv2.LINE_AA<br/>          )</span><span id="c2f3" class="ln ju hh lj b fi lv lp l lq lr">      # Write the FPS on the current frame.<br/>      cv2.putText(nimg, f"{fps:.3f} FPS", (15, 30), cv2.FONT_HERSHEY_SIMPLEX,<br/>                  1, (0, 255, 0), 2)<br/>      # Convert from BGR to RGB color format.<br/>      cv2.imshow('image', nimg)<br/>      out.write(nimg)<br/>      print(f"{fps:.3f} FPS")<br/>      # Press `q` to exit.<br/>      if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>          break<br/>  else:<br/>      break<br/># Release VideoCapture().<br/>cap.release()<br/># Close all frames and video windows.<br/>cv2.destroyAllWindows()<br/># Calculate and print the average FPS.<br/>avg_fps = total_fps / frame_count<br/>print(f"Average FPS: {avg_fps:.3f}")</span></pre><h1 id="ea33" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结果</h1><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es kr"><img src="../Images/65bb7b77897529cd37c0585f65102ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*fVDe3BAVKfqDFqpq46pV9A.gif"/></div></figure><p id="613b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">注意——如果您想运行这些推理文件，请将这些文件保存在克隆的yolo文件夹中，因为这些文件使用了yolo文件夹中的一些实用程序功能。</strong></p><p id="a95b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用以下命令克隆yolo repo:</p><pre class="jp jq jr js fd li lj lk ll aw lm bi"><span id="c38c" class="ln ju hh lj b fi lo lp l lq lr">git clone <a class="ae jn" href="https://github.com/WongKinYiu/yolov7.git" rel="noopener ugc nofollow" target="_blank">https://github.com/WongKinYiu/yolov7.git</a></span></pre><p id="23e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这样你就可以用最简单的方式在自定义数据集上训练YOLOv7。</p><p id="a06b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这篇博客中，我一步一步地解释了如何使用YOLOv7 训练车牌检测器，只要遵循这些步骤就可以做到。</p><p id="a690" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如需源代码，请访问我的博客—<a class="ae jn" href="https://machinelearningprojects.net/?p=11957" rel="noopener ugc nofollow" target="_blank">https://machine learning projects . net/number-plate-detection-using-yolov 7/</a></p><p id="4d74" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">查看我的其他</strong> <a class="ae jn" href="https://machinelearningprojects.net/machine-learning-projects/" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi">机器学习项目</strong></a><strong class="ir hi"/><a class="ae jn" href="https://machinelearningprojects.net/deep-learning-projects/" rel="noopener ugc nofollow" target="_blank"><strong class="ir hi">深度学习项目</strong></a><strong class="ir hi"/><a class="ae jn" href="https://machinelearningprojects.net/opencv-projects/" rel="noopener ugc nofollow" target="_blank"><strong class="ir hi">计算机视觉项目</strong></a><strong class="ir hi"/><a class="ae jn" href="https://machinelearningprojects.net/nlp-projects/" rel="noopener ugc nofollow" target="_blank"><strong class="ir hi">NLP项目</strong></a><strong class="ir hi"/><a class="ae jn" href="https://machinelearningprojects.net/flask-projects/" rel="noopener ugc nofollow" target="_blank"><strong class="ir hi">烧瓶项目</strong> </a> <strong class="ir hi"> at </strong> <a class="ae jn" href="https://machinelearningprojects.net/" rel="noopener ugc nofollow" target="_blank"/></p><div class="lx ly ez fb lz ma"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mb ab dw"><div class="mc ab md cl cj me"><h2 class="bd hi fi z dy mf ea eb mg ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mh l"><h3 class="bd b fi z dy mf ea eb mg ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mi l"><p class="bd b fp z dy mf ea eb mg ed ef dx translated">medium.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo in ma"/></div></div></a></div></div></div>    
</body>
</html>
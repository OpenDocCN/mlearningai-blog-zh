<html>
<head>
<title>Everyone’s Talking About It: What Is DALL.E 2?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个人都在谈论它:什么是DALL。E 2？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/everyones-talking-about-it-what-is-dall-e-2-86ffad43e438?source=collection_archive---------6-----------------------#2022-07-04">https://medium.com/mlearning-ai/everyones-talking-about-it-what-is-dall-e-2-86ffad43e438?source=collection_archive---------6-----------------------#2022-07-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9606" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为一名初级数据科学家，我没有该领域的广泛知识。在这篇文章中，我的目的是解释DALL。E 2是什么，它基于什么架构，用比专家可能写的更简单的话。我可能有点晚了，但我希望你仍然觉得有趣。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="757c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们先了解一下背景</strong></p><p id="da07" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我叫达尔。据说“E”是指电影《瓦力》及其同名机器人主角，以及西班牙著名艺术家萨瓦尔多·达利。</p><p id="1e84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">达尔。e是OpenAI开发的一款软件。如果你熟悉这个领域，你肯定听说过他们。如果没有，下面是对该公司的简要描述:OpenAI是一个专注于人工智能问题的研究实验室，旨在促进有益于人类的友好人工智能，而不是对人类构成风险。你可能听说过DeepMind的<em class="jc"> AlphaGo </em>击败了世界上最好的围棋选手，OpenAI参与了视频游戏DOTA 2的一个类似项目，他们在大量游戏中训练机器人。</p><p id="9857" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">达尔。2022年4月)是该算法的第二个版本，紧随DALL之后。2021年1月)。如果你有兴趣自己尝试看看它能做什么，你必须耐心等待，因为你需要在<a class="ae jk" href="https://labs.openai.com/waitlist" rel="noopener ugc nofollow" target="_blank"> OpenAI的网站</a>上注册，才能被列入等待名单，有机会获得访问权。然而，有一个简化的开源版本，叫做DALL。E Mini。请在这里<a class="ae jk" href="https://huggingface.co/spaces/dalle-mini/dalle-mini" rel="noopener ugc nofollow" target="_blank">随意查看它</a>，即使结果不那么令人印象深刻。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="34d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">打什么主意。E 2真的有吗？</strong></p><p id="fd69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DALL的主要特点。E 1和2是它将文本作为输入并基于该文本输出图像的能力。你可以获得任何人、物体、地点、情况等的图像。任何风格——你只需要在你的提示中清晰明了。</p><p id="3f16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">达尔。E 2还可以编辑现有的图片，并在考虑阴影、反射和照明的同时添加和删除对象。此外，它可以从现有的图片中提出不同风格的图片变体。你可以在OpenAI的网站上找到不同功能的演示。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="5eda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">它是怎么做到的？(这一部分我们可能需要更专业一点)</strong></p><p id="326b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">达尔。E 2由两个主要部分组成。第一个名为CLIP [1]，由OpenAI研究人员开发。它由一个并行图像编码器和一个文本编码器组成，两者都是在没有权重初始化的情况下从头开始训练的。</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jl"><img src="../Images/45e6b5c87f6761c893819c4ad535ec02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*snnKH2D0TReBvpVq"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx">The method used for CLIP from the research paper [1]</figcaption></figure><p id="0184" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于图像编码器，他们使用了两种不同的架构。第一个是ResNet-50的基础架构，有一些调整，我不会在这里列出，但你可以在论文中找到— <em class="jc">第4–2.4页。选择和缩放模型。</em>使用的第二个模型是一个视觉转换器，稍加修改。训练是在具有不同参数的5个ResNets和3个视觉变压器上进行的。一些参数在模型之间是通用的，比如时期数——32——或者选择的优化器——Adam。</p><p id="54b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文本编码器是一个转换器，也做了一些架构上的修改。它对49，152个标记词汇表进行操作，全部小写，并使用字节对编码(BPE)。BPE是一种用数据中不存在的另一个字符替换重复字符对的方法[2]。</p><p id="a964" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">OpenAI中有很多关于这种方法的更有价值的信息，但我尽量保持简单。如果您对模型、方法甚至所用参数的更多细节感兴趣，您可以在参考文献[1]中找到研究论文的链接。</p><p id="130f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">组成DALL的第二个元素。E 2是一个生成式预训练转换器，也是由OpenAI开发的。使用的版本是GPT-3 [3]的实现，有120亿个参数，而原始模型在其当前版本中使用了1750亿个参数。有关GPT-3的更多信息，请参见参考资料。</p><p id="c93c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在知道什么是建筑了。E 2是基于的，如果你有兴趣阅读OpenAI提出的完整方法，你会在这里或参考文献中找到研究论文的链接<a class="ae jk" href="https://arxiv.org/pdf/2204.06125.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="5940" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论</strong></p><p id="73fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">达尔。E 2是一种SoA(最先进的)算法。我们可以更深入地探讨这个问题，但我想我会失去很多人——坦率地说，我也可能会迷路。如果你是一个专家，你可能甚至不会读这篇文章，并且有兴趣阅读关于CLIP，DALL的全部研究论文。E 2，甚至GLIDE [1][4][5]，你会在参考资料部分找到所有的链接。</p><p id="f374" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">达尔。研究E 2真的很有趣，因为它使用不同的模型组合成一个“超级”模型，可以创建像下面这样令人印象深刻的作品——你可以在Andrew Mayne的Twitter feed 上找到许多其他例子:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es kb"><img src="../Images/d45a197b3078da7bc72b3e955b3816af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*87I9nAxsv-fcj793"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx">Example of DALL.E 2 powerfulness from Andrew Mayne’s twitter</figcaption></figure><p id="4a87" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我在文章开头提到的，我在这个领域还是个新手，所以如果你发现了任何对论文的误解或任何错误，我将很高兴在评论区接受批评。</p><p id="c424" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">敬请期待更多！如果你喜欢阅读，考虑留下一个关注或掌声。</em>🙂</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="034b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献</strong></p><p id="c38c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]剪辑:亚历克·拉德福德，琼·金旭，克里斯·哈拉西，阿迪蒂亚·拉梅什，加布里埃尔·高，桑迪尼·阿加瓦尔，吉里什·萨斯特里，阿曼达·阿斯克尔，帕梅拉·米什金，杰克·克拉克，格雷琴·克鲁格，伊利亚·苏茨基弗，<em class="jc">从自然语言监督中学习可转移的视觉模型</em>，<a class="ae jk" href="https://arxiv.org/pdf/2103.00020.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2103.00020.pdf</a></p><p id="7e91" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]字节对编码:【https://en.wikipedia.org/wiki/Byte_pair_encoding】T4</p><p id="756b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3] GPT-3: Sciforce，<em class="jc">什么是GPT-3，它是如何工作的，它实际上做什么？I </em>，<a class="ae jk" rel="noopener" href="/sciforce/what-is-gpt-3-how-does-it-work-and-what-does-it-actually-do-9f721d69e5c1">https://medium . com/sci force/what-is-GPT-3-how-it-work-and-what-it-actually-do-9f 721d 69 e5c 1</a></p><p id="5e1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4]达尔。E 2: Aditya Ramesh，Prafulla Dhariwal，Alex Nichol，Casey Chu，陈唐山，<em class="jc">分层文本条件，带剪辑潜伏的图像生成</em>，<a class="ae jk" href="https://arxiv.org/pdf/2204.06125.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2204.06125.pdf</a></p><p id="ce64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[5] GLIDE: Alex Nichol，Prafulla Dhariwal，Aditya Ramesh，Pranav Shyam，Pamela Mishkin，Bob McGrew，Ilya Sutskever，陈唐山，<em class="jc"> GLIDE:用文本引导扩散模型实现照片真实感图像生成和编辑，</em><a class="ae jk" href="https://arxiv.org/pdf/2112.10741.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2112.10741.pdf</a></p><div class="kc kd ez fb ke kf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kg ab dw"><div class="kh ab ki cl cj kj"><h2 class="bd hi fi z dy kk ea eb kl ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="km l"><h3 class="bd b fi z dy kk ea eb kl ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kn l"><p class="bd b fp z dy kk ea eb kl ed ef dx translated">medium.com</p></div></div><div class="ko l"><div class="kp l kq kr ks ko kt jv kf"/></div></div></a></div></div></div>    
</body>
</html>
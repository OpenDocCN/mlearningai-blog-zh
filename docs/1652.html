<html>
<head>
<title>Paper Review: “YOLOX: Exceeding YOLO Series in 2021”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文综述:《YOLOX:2021年超越YOLO系列》</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/paper-review-yolox-exceeding-yolo-series-in-2021-ffc1bd94a1f3?source=collection_archive---------2-----------------------#2022-01-16">https://medium.com/mlearning-ai/paper-review-yolox-exceeding-yolo-series-in-2021-ffc1bd94a1f3?source=collection_archive---------2-----------------------#2022-01-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="db07" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">在本文中，我将介绍YOLOX，它是YOLO的一个无锚点版本，做了一些改进以获得更好的性能。</h2></div><p id="7205" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">原文:<a class="ae js" href="https://arxiv.org/pdf/2107.08430.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2107.08430.pdf</a></p><h1 id="a49a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd in ke io kf iq kg ir kh it ki iu kj kk bi translated">1.YOLO物体探测器</h1><p id="308d" class="pw-post-body-paragraph iw ix hh iy b iz kl ii jb jc km il je jf kn jh ji jj ko jl jm jn kp jp jq jr ha bi translated">你只看一次(YOLO)是一个流行的实时处理的对象检测算法。这是一个单阶段的对象检测，因为它提出了使用一个端到端的神经网络，该网络可以同时预测包围盒和类别概率。因此，YOLO比以前的两阶段模型(R-CNN，快速R-CNN，更快R-CNN)具有更好的推理速度。</p><p id="3cbf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLO模型的主要思想如图1所示。输入图像被分成一个<em class="kq"> S </em> x <em class="kq"> S </em>网格，每个网格单元负责预测位于该网格单元中心的物体。每个网格单元预测<em class="kq"> B </em>边界框(中心坐标、宽度、高度)及其相应的置信度得分。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kr"><img src="../Images/236f3662f107e4e0bd749625e5fe7ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZsPjN8epKSBhx-WU9fHzFQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 1: </strong>Main ideal of YOLO ([1])</figcaption></figure><p id="5a68" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们知道，每个网格单元只预测一个单一的对象。当一个单元格有多个对象时，这就产生了问题。接下来的版本(YOLOv2，YOLOv3，…)通过使用锚盒解决了这个问题。它们在图像周围形成许多锚框。锚盒的宽度/高度的比率被检查，并且接近于要预测的对象的比率。我们预测每个锚定框的偏移量，而不是预测任意边界框。此外，该模型还从锚盒中预测相应的对象类。然而，这种设计有一些缺点:</p><ul class=""><li id="d270" class="lh li hh iy b iz ja jc jd jf lj jj lk jn ll jr lm ln lo lp bi translated">我们需要使用聚类分析(kNN，…)来确定锚盒的最佳大小。</li><li id="d3af" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">这种设计增加了预测的数量。这增加了算法的复杂性，并且我们需要在后处理中使用NMS(非最大抑制)算法来移除相同对象的包围盒。</li></ul><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es lv"><img src="../Images/8f152ca311a807e7fe7270c4873fe611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*dDg0eCRdFEctmi7mdy8b9Q.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 2: </strong>Non-maximum Suppression</figcaption></figure><h1 id="0ac8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd in ke io kf iq kg ir kh it ki iu kj kk bi translated">2.YOLOX</h1><p id="4f6e" class="pw-post-body-paragraph iw ix hh iy b iz kl ii jb jc km il je jf kn jh ji jj ko jl jm jn kp jp jq jr ha bi translated">考虑到YOLOv4和YOLOv5对于基于锚点的管道可能有点过度优化，作者决定使用YOLOv3作为基线。</p><h1 id="c0c1" class="jt ju hh bd jv jw jx jy jz ka kb kc kd in ke io kf iq kg ir kh it ki iu kj kk bi translated">2.1 YOLOX-Darknet53</h1><p id="0632" class="pw-post-body-paragraph iw ix hh iy b iz kl ii jb jc km il je jf kn jh ji jj ko jl jm jn kp jp jq jr ha bi translated"><strong class="iy hi"> YOLOv3基线</strong></p><p id="7a81" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在YOLOX的论文中，作者选择具有Darknet-53骨架和SPP层的yolo v3(yolo v3-SPP)作为基线。SPP图层使用3个不同大小的最大池图层来输入要素地图。然后，他们收集并连接3个输出特征图，形成最终的输出特征图。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es lw"><img src="../Images/c69e78dcdd9719d2c35ccec88037c2f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*rdgT1za1GEHaFRMJFRIwhQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 3: </strong>Darknet-53 architecture ([2])</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lx"><img src="../Images/346bf09bd38e8de7cbf844f819a81cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2vVkG-pZahOwu7GK7poFEA.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig.4:</strong> Comparision of backbones. YOLOv2 uses Darknet-19 backbone while YOLOv3 uses Darknet-53 backbone ([2])</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ly"><img src="../Images/1a9019e08611e081aa47051cdc17c751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x586NavGLvszI7HgfTl-ug.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig.5</strong>: Spatial Pyramid Pooling (SPP) layer ([3])</figcaption></figure><p id="abd8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">培训详情</strong></p><p id="3b62" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">训练YOLOX和基线的一些设置:</p><ul class=""><li id="e115" class="lh li hh iy b iz ja jc jd jf lj jj lk jn ll jr lm ln lo lp bi translated">作者在COCO train2017上训练了总共300个时代的模型，其中有5个时代的热身。</li><li id="1ea2" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">用于训练的随机梯度下降法。</li><li id="4f39" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">学习率是0.01*BatchSize/64和余弦学习率表。</li><li id="337a" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">重量衰减为0.0005，SGD动量为0.9，批量为128。</li><li id="aafb" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">输入大小从448到832以32步均匀绘制。</li><li id="8a2b" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">添加EMA权重更新。</li><li id="83e7" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">培训cls和obj分支的BCE损失和培训reg分支的IoU损失。</li><li id="fab7" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">用于数据扩充的随机水平翻转、颜色抖动和多尺度。</li></ul><p id="1325" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">解耦头</strong></p><p id="9617" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在对象检测中，分类和回归任务之间的冲突是一个众所周知的问题。许多对象检测系统使用去耦头(分离分类和回归)。然而，YOLO探测头保持耦合。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lz"><img src="../Images/f812412016910cd518e0a9ec9a5463ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zq8txQXoXQd9_GOvxf6uoA.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 6</strong>: Illustration of the difference between YOLOv3 head and the proposed decoupled head ([4])</figcaption></figure><p id="d3f1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在YOLOX中，作者用一个分离的头替换了YOLO的头。这提高了收敛速度并增加了端到端YOLO的AP。所以，他们为YOLOX型号选择了去耦头。新的探测头包括1x1卷积以减少特征图的数量，以及两个具有3x3卷积的分支。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ma"><img src="../Images/040e946de06d1d4f2988eea6d04df648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pUS33bc7BxO3lHvMNeGcBg.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 7:</strong> Training curves for detectors with YOLOv3 head<br/>or decoupled head. ([4])</figcaption></figure><p id="56dd" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">强大的数据增强</strong></p><p id="7e38" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">作者使用马赛克和混搭。有了这些增强，他们从零开始训练模型。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mb"><img src="../Images/9dd023e308e687e456072df3b5c7e430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wh48DkdPNFgTtOlFYimREQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 8</strong>: Mosaic ([5])</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mc"><img src="../Images/b7eb8cf6ff17c5e56bdc834e87450c10.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*Efmu2BPMm10pAs21uwwBVQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 9: </strong>Mixup ([6])</figcaption></figure><p id="70ea" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">无锚</strong></p><p id="314d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如上所示，使用锚点的模型有一些缺点。为了使YOLO无锚，作者将每个位置的预测从3减少到1，并直接预测边界框的四个值(即，网格的左上角和框的高度和宽度)。).每个对象的中心位置是一个正样本，它们预先定义了一个标度范围，以定义每个对象的FPN水平。</p><p id="5195" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因为YOLOX with anchor-free只为每个对象选择一个阳性样本，这就在训练时造成了阳性/阴性之间的不平衡。为了减轻这种情况，他们简单地将中间的3×3区域指定为阳性。这种策略在FCOS被称为“中心抽样”。</p><p id="09d5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">西蒙塔</strong></p><p id="5384" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">高级标签分配是近年来目标检测的又一重要进展。作者总结了高级标签分配的四个关键观点:</p><ul class=""><li id="3a7b" class="lh li hh iy b iz ja jc jd jf lj jj lk jn ll jr lm ln lo lp bi translated">损失/质量意识</li><li id="79d1" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">中心先验</li><li id="8ee8" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">每个地面实况的正锚动态数量</li><li id="a57d" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">全局视图</li></ul><p id="fd89" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">作者选择将指派过程公式化为最优运输(OT)问题的OTA来寻找最优指派。然而，OTA使用Sinkhorn-Knopp迭代算法，这带来了25%的额外训练时间，这对训练300个历元来说是相当昂贵的。因此，作者将其简化为动态top-k策略，命名为SimOTA，以获得近似解。</p><p id="7052" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，SimOTA计算每个预测-基础真实对的成对匹配度。地面实况g_i和预测p_j之间的成本<br/>计算如下:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es md"><img src="../Images/a488f75643176fd0e2e61c4f40362122.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*8Re4R8s71kwd_MAdmjbKug.png"/></div></figure><p id="8696" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于gt g_i，他们选择在<strong class="iy hi">固定中心区域</strong>内<strong class="iy hi">最小成本</strong>的<strong class="iy hi"> top k预测</strong>作为其正样本。最后，那些阳性预测的对应网格被指定为阳性，而其余网格为阴性。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es me"><img src="../Images/3196d9e859edafbf295447c82edc2bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nRCFrj4SiD0G3aTXFY8mJw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 10: </strong>Roadmap of YOLOX-Darknet53 in terms of AP (%) on COCO val. ([4])</figcaption></figure><h1 id="9488" class="jt ju hh bd jv jw jx jy jz ka kb kc kd in ke io kf iq kg ir kh it ki iu kj kk bi translated"><strong class="ak"> 2.2结果</strong></h1><p id="6e77" class="pw-post-body-paragraph iw ix hh iy b iz kl ii jb jc km il je jf kn jh ji jj ko jl jm jn kp jp jq jr ha bi translated">除了DarkNet53，作者还测试了YOLOX的其他主干配置，以实现不同的速度-精度权衡。作者修改了YOLOv5中的CSPNet，以比较YOLOv5。他们将模型缩小为YOLOX-Tiny，以便与YOLOv4-Tiny进行比较。。对于移动设备，他们采用深度卷积来构建YOLOX-Nano模型。下面的图片是得到的一些对比结果(细节在原文中)。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mf"><img src="../Images/d3c5a1ad11f8ca3857fd17d0ecbdc127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*cl7Zwv_Y89-z4nr-kSxnsg.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 11: </strong>Comparison of YOLOX and YOLOv5 in terms<br/>of AP (%) on COCO.</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mg"><img src="../Images/e6a1de6218e031b78580bcd642d31067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*ceuDVAAbUzuDaXWZs_3bMg.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 12: </strong>Comparison of YOLOX-Tiny and YOLOX-Nano<br/>and the counterparts in terms of AP (%) on COCO val.</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mh"><img src="../Images/3d60605bd8fc511402878d17428e1f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nYkruEF2GeLOShzLeTrRRQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 13</strong>: Effects of data augmentation under different model<br/>sizes.</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mi"><img src="../Images/481f0d34bbeac4e96f8f7180a1673b26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8IFf5WzWiPqGdblmNB0ww.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><strong class="bd jv">Fig. 14</strong>: Comparison of the speed and accuracy of different object detectors on COCO 2017 test-dev</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mj"><img src="../Images/4278a19938daf8143330bc69d061eefe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ozgygKniB-ycO-Tn8rw7qQ.png"/></div></div></figure><h1 id="6f1a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd in ke io kf iq kg ir kh it ki iu kj kk bi translated">结论</h1><p id="6e17" class="pw-post-body-paragraph iw ix hh iy b iz kl ii jb jc km il je jf kn jh ji jj ko jl jm jn kp jp jq jr ha bi translated">YOLOX是YOLO的无锚点版本，做了一些改进以获得更好的性能。作者在2021年CVPR自动驾驶研讨会上获得了第一名。</p><p id="c54b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您可以在以下网址找到YOLOX的官方源代码:</p><div class="mk ml ez fb mm mn"><a href="https://github.com/Megvii-BaseDetection/YOLOX" rel="noopener  ugc nofollow" target="_blank"><div class="mo ab dw"><div class="mp ab mq cl cj mr"><h2 class="bd hi fi z dy ms ea eb mt ed ef hg bi translated">GitHub -旷视科技-BaseDetection/YOLOX: YOLOX是一款高性能无锚点YOLO，超过…</h2><div class="mu l"><h3 class="bd b fi z dy ms ea eb mt ed ef dx translated">YOLOX是一款高性能无锚YOLO，超过yolov3~v5有MegEngine，ONNX，TensorRT，ncnn，OpenVINO…</h3></div><div class="mv l"><p class="bd b fp z dy ms ea eb mt ed ef dx translated">github.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb lb mn"/></div></div></a></div><p id="1f11" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="kq">如有任何问题，请在下方评论或通过</em></strong><a class="ae js" href="https://www.linkedin.com/in/tuan-nguyen85/" rel="noopener ugc nofollow" target="_blank"><strong class="iy hi"><em class="kq">LinkedIn</em></strong></a><strong class="iy hi"><em class="kq">或</em></strong><a class="ae js" href="https://github.com/anhtuan85" rel="noopener ugc nofollow" target="_blank"><strong class="iy hi"><em class="kq">github</em></strong></a>联系我</p><p id="78c4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你喜欢这个，请考虑支持我。T24】</p><figure class="ks kt ku kv fd kw er es paragraph-image"><a href="https://ko-fi.com/anhtuan85"><div class="er es nc"><img src="../Images/81047f44c89ac80b25a2614f96e6d829.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*tCgo5NNPyCIHrmtyIXwvRA.png"/></div></a></figure><h1 id="1bd0" class="jt ju hh bd jv jw jx jy jz ka kb kc kd in ke io kf iq kg ir kh it ki iu kj kk bi translated"><strong class="ak">资源:</strong></h1><p id="b75a" class="pw-post-body-paragraph iw ix hh iy b iz kl ii jb jc km il je jf kn jh ji jj ko jl jm jn kp jp jq jr ha bi translated">[1]https://arxiv.org/pdf/1506.02640.pdf论文:<a class="ae js" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">YOLO论文</a></p><p id="a756" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[2]约洛夫3论文:<a class="ae js" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1804.02767.pdf</a></p><p id="a568" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[3]https://arxiv.org/ftp/arxiv/papers/1903/1903.08589.pdf的DC-南非-YOLO</p><p id="bd34" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[4] YOLOX论文:<a class="ae js" href="https://arxiv.org/pdf/2107.08430.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2107.08430.pdf</a></p><p id="1b82" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[5]约洛夫4论文:<a class="ae js" href="https://arxiv.org/pdf/2004.10934.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2004.10934.pdf</a></p><p id="09c9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[6]剪辑画面:<a class="ae js" href="https://arxiv.org/pdf/1905.04899.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1905.04899.pdf</a></p><p id="43bb" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[7]yolov 5 github:<a class="ae js" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a></p><div class="mk ml ez fb mm mn"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mo ab dw"><div class="mp ab mq cl cj mr"><h2 class="bd hi fi z dy ms ea eb mt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mu l"><h3 class="bd b fi z dy ms ea eb mt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mv l"><p class="bd b fp z dy ms ea eb mt ed ef dx translated">medium.com</p></div></div><div class="mw l"><div class="nd l my mz na mw nb lb mn"/></div></div></a></div><p id="32e4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae js" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"> <strong class="iy hi">提交到MLearning.ai </strong> </a></p></div></div>    
</body>
</html>
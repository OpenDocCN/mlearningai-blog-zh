<html>
<head>
<title>Ensemble Learning — AdaBoost with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成学习—使用Python的AdaBoost</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/ensemble-learning-adaboost-with-python-8332778fbb61?source=collection_archive---------1-----------------------#2022-06-11">https://medium.com/mlearning-ai/ensemble-learning-adaboost-with-python-8332778fbb61?source=collection_archive---------1-----------------------#2022-06-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9896" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于如何用scikit-learn实现自适应增强(AdaBoost)算法的指南。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/6861d30d1cd6c0a9e197ebb3ca8c1833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*89ZTy_NEnzb8SYFi"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@libs?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Steven Libralon</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5cb0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">AdaBoost是一种boosting方法，使用完整的训练数据集来训练弱学习者。是理解助推的最好起点。在这篇文章中，我将讨论以下主题:</p><ul class=""><li id="4591" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb jy jz ka kb bi translated">什么是AdaBoost？</li><li id="8e25" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">AdaBoost如何工作？</li><li id="29aa" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">用scikit-learn实现AdaBoost</li><li id="c34e" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">数据预处理</li><li id="a7cf" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">构建决策树模型</li><li id="79f2" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">建立AdaBoost模型</li><li id="55df" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">AdaBoost模型与决策树模型的比较</li></ul><p id="76e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在开始之前，我们创建与数据科学、人工智能、机器学习和深度学习相关的内容。请不要忘记关注我们的YouTube频道。</p><p id="f392" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们开始吧！</p><h1 id="0af9" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">什么是AdaBoost</h1><p id="0e9c" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">AdaBoost是一种boosting方法，使用完整的训练数据集来训练弱学习者。这是一个连续的过程，每个后续模型都试图纠正前一个模型的错误。因此，后续模型依赖于前一个模型。</p><p id="4db8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个模型都在同一个数据集上训练，但是每个样本在前一个模型的成功中处于不同的权重下。权重在每次迭代中被重新分配以构建强分类器，该强分类器从集合中先前弱学习器的错误中学习。注意，错误预测样本的权重通常会增加，以强调它们的预测难度。</p><h1 id="a2d4" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">如何使用AdaBoost</h1><p id="b924" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">为了展示如何使用AdaBoost，让我一步一步地看一个例子。</p><ol class=""><li id="2c4f" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb lk jz ka kb bi translated">首先，从原始数据集中选择一个子集。</li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ll"><img src="../Images/bfd37e2b10f2db793a2342eaa1884f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*Wmq6lR_cDUHFhP5DmRzErQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx"><a class="ae js" href="https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312" rel="noopener ugc nofollow" target="_blank">Figure 1</a></figcaption></figure><p id="7d8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.最初，所有训练示例都被赋予相同的权重。</p><p id="c228" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.在这个子集上训练基本模型。</p><p id="627e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.该模型用于对所有数据进行预测。</p><p id="2785" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.使用实际值和预测值计算误差。</p><p id="9c4e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6.对于下一轮，错误分类的例子被分配更高的权重。在图1中，两个错误分类的蓝圈点将被赋予更高的权重。此外，正确分类的例子被分配较低的权重。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lm"><img src="../Images/efcecea27a767e9cfd482b8658472581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*5s-H61NvX4rtOjivsfM1Mg.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx"><a class="ae js" href="https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312" rel="noopener ugc nofollow" target="_blank">Figure 2</a></figcaption></figure><p id="8f45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">7.下一轮将更加关注具有最大权重的训练示例。</p><p id="9f80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">8.构建另一个模型，并对数据集进行预测。这个模型试图纠正前一个模型的错误。</p><p id="f308" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在图2中，该模型将circle类中的三个不同示例进行了错误分类。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/bad5c5aeede257bf4211590c4525eb3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*dI6LkBnzo8xD6_B8tKdpJQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx"><a class="ae js" href="https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312" rel="noopener ugc nofollow" target="_blank">Figure 3</a></figcaption></figure><p id="2ed9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">9.类似地，建立多个模型，每个模型修正前一个模型的误差。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lo"><img src="../Images/ada5932b5b0cc4d4ff1232ff8bcfdfb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*woqqK01iaeVZZANikcveEQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx"><a class="ae js" href="https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312" rel="noopener ugc nofollow" target="_blank">Figure 4</a></figcaption></figure><p id="8eff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">10.最终模型是所有模型的加权平均值。</p><p id="bbee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，AdaBoost算法结合了许多弱学习者。因此，每个模型都提高了整体的性能。我希望你明白如何使用AdaBoost。现在，我们来看看如何用scikit-learn实现AdaBoost。</p><h1 id="55f3" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">使用Scikit-Learn实现AdaBoost</h1><p id="10a0" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">在加载数据集之前，让我导入熊猫。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="54b5" class="lu ki hh lq b fi lv lw l lx ly">import pandas as pd</span></pre><p id="5fee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了展示如何实现bagging分类器，我将使用乳腺癌威斯康星州数据集。让我们加载数据集。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="aad8" class="lu ki hh lq b fi lv lw l lx ly">df = pd.read_csv("wdbc.data", header = None)</span></pre><p id="7ddb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">酷毙了。我们的数据集已加载。你可以在这里找到这个数据集。让我们看一下数据集的前五行。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="f2c2" class="lu ki hh lq b fi lv lw l lx ly">df.head()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lz"><img src="../Images/562154299a179066a85b1c6c1258e5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7i4EdpKDM0r5oSQgNo-_Ww.png"/></div></div></figure><p id="a4c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给你。该数据集由恶性和良性肿瘤细胞的例子组成。数据集中的第一列显示唯一的ID号，第二列显示诊断，假设M表示恶性，B表示良性。其余栏目是我们的特色。让我们来看看数据集的形状。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="251d" class="lu ki hh lq b fi lv lw l lx ly">df.shape</span><span id="4b1a" class="lu ki hh lq b fi ma lw l lx ly">#Output:<br/>(569,33)</span></pre><h1 id="4101" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">数据预处理</h1><p id="2db8" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">您可以看到行数和列数。让我删除不必要的列。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="35ac" class="lu ki hh lq b fi lv lw l lx ly">df= df.drop(["id","Unnamed: 32"], axis = 1)</span></pre><p id="5756" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们创建目标和输出变量。为此，我将使用loc方法并将这些变量转换为numpy数组。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="d893" class="lu ki hh lq b fi lv lw l lx ly">y = df["diagnosis"].values<br/>X = df.drop(["diagnosis"], axis = 1).values</span></pre><p id="0407" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">太美了。我们创造了变量。我们的目标变量有两类，M和b，让我们用label encoder对目标变量进行编码。首先，我要导入这个类。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="134d" class="lu ki hh lq b fi lv lw l lx ly">from sklearn.preprocessing import LabelEncoder</span></pre><p id="8218" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我要从这个类创建一个对象。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="16d7" class="lu ki hh lq b fi lv lw l lx ly">le = LabelEncoder()</span></pre><p id="f643" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们拟合并转换我们的目标变量。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="ad63" class="lu ki hh lq b fi lv lw l lx ly">y = le.fit_transform(y)</span></pre><p id="d531" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">太棒了，我们编码了目标标签。在构建模型之前，让我们将数据集分成训练集和测试集。为此，我将使用train_test_split函数。首先，让我导入这个函数。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="4c89" class="lu ki hh lq b fi lv lw l lx ly">from sklearn.model_selection import train_test_split</span></pre><p id="5976" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们使用这个函数分割数据集。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="5f28" class="lu ki hh lq b fi lv lw l lx ly">X_train, X_test, y_train, y_test = train_test_split(<br/>                            X, y,<br/>                            # To split in balanced, let me set<br/>                            stratify=y,<br/>                            # For reproducible output<br/>                            random_state=0)</span></pre><p id="088e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">酷毙了。我们的数据集已经可以分析了。我的计划是这样的:首先，我要用决策树分类器建立模型。之后，我将使用bagging来建立模型。最后，我将比较这些模型。</p><h1 id="890c" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">构建决策树模型</h1><p id="abfc" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">让我们建立一个基于决策树分类器的模型。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="d5c8" class="lu ki hh lq b fi lv lw l lx ly">from sklearn.tree import DecisionTreeClassifier</span></pre><p id="3023" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">好吧。让我们从DecisionTreeClassifier类创建一个对象。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="b0be" class="lu ki hh lq b fi lv lw l lx ly">tree = DecisionTreeClassifier(<br/>          max_depth=1,<br/>          random_state=42)</span></pre><p id="1942" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们使用这个对象来拟合模型。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="388b" class="lu ki hh lq b fi lv lw l lx ly">tree = tree.fit(X_train, y_train)</span></pre><p id="6000" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">酷毙了。模型已经建立。现在，让我们预测训练集。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="7fa0" class="lu ki hh lq b fi lv lw l lx ly">y_train_pred = tree.predict(X_train)</span></pre><p id="2f4a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们来预测一下测试集。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="9154" class="lu ki hh lq b fi lv lw l lx ly">y_test_pred = tree.predict(X_test)</span></pre><p id="a144" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们看看模型在训练集和测试集上的性能。为此，我将使用accuracy_score函数。让我导入这个函数。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="64f6" class="lu ki hh lq b fi lv lw l lx ly">from sklearn.metrics import accuracy_score</span></pre><p id="679b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们来看看训练集的准确度分数。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="c722" class="lu ki hh lq b fi lv lw l lx ly">tree_train = accuracy_score(y_train, y_train_pred)</span></pre><p id="fce6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们来看看测试集的准确率得分。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="ce45" class="lu ki hh lq b fi lv lw l lx ly">tree_test = accuracy_score(y_test, y_test_pred)</span></pre><p id="0197" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">太棒了。我们计算了准确度分数。</p><p id="cc6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们打印这些分数。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="deb1" class="lu ki hh lq b fi lv lw l lx ly">print(f’Decision tree train/test accuracies: {tree_train:.3f}/{tree_test:.3f}’)</span><span id="c8bf" class="lu ki hh lq b fi ma lw l lx ly"># Output:<br/>Decision tree train/test accuracies: 0.930/0.888</span></pre><p id="56a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给你。该树模型在训练集上的得分为93%。但是树模型在测试集上的得分是88%。如您所见，决策树似乎未能满足训练数据的要求。</p><h1 id="a928" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">建立AdaBoost模型</h1><p id="0cb0" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">现在我将使用AdaBoost技术通过scikit-learn分析数据。首先，让我从系综子模块中导入AdaBoostClassifier。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="2f0d" class="lu ki hh lq b fi lv lw l lx ly">from sklearn.ensemble import AdaBoostClassifier</span></pre><p id="e31a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，让我从AdaBoostClassifier创建一个对象。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="4d23" class="lu ki hh lq b fi lv lw l lx ly">ada = AdaBoostClassifier(<br/>           base_estimator=tree,<br/>           n_estimators=500,<br/>           learning_rate=0.5,<br/>           random_state=42)</span></pre><p id="2e71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，n _估计器指定提升被终止，并且较高的学习率增加了每个分类器的贡献。</p><p id="538b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">太棒了。我们的目标准备好训练了。让我们使用训练集来拟合AdaBoost模型。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="3841" class="lu ki hh lq b fi lv lw l lx ly">ada = ada.fit(X_train, y_train)</span></pre><p id="2b7b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">酷毙了。模型已经建立。现在，让我们使用这个模型来预测训练集。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="cfd5" class="lu ki hh lq b fi lv lw l lx ly">y_train_pred = ada.predict(X_train)</span></pre><p id="cddb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们来预测一下测试集。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="2658" class="lu ki hh lq b fi lv lw l lx ly">y_test_pred = ada.predict(X_test)</span></pre><p id="25d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们看看模型在训练集和测试集上的性能。为此，我将再次使用accuracy_score函数。首先，我们来看看模型在训练集上的准确率得分。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="54aa" class="lu ki hh lq b fi lv lw l lx ly">ada_train = accuracy_score(y_train, y_train_pred)</span></pre><p id="1d2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们来看看模型在测试集上的准确率得分。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="1469" class="lu ki hh lq b fi lv lw l lx ly">ada_test = accuracy_score(y_test, y_test_pred)</span></pre><p id="10db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">太美了。我们计算了准确度分数。现在，让我们打印这些分数。</p><pre class="jd je jf jg fd lp lq lr ls aw lt bi"><span id="352a" class="lu ki hh lq b fi lv lw l lx ly">print(f’Adaboost train/test accuracies: {ada_train:.3f}/{ada_test:.3f}’)</span><span id="c51b" class="lu ki hh lq b fi ma lw l lx ly">#Output:<br/>Adaboost train/test accuracies: 1.000/0.979</span></pre><p id="b376" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以看到，AdaBoost模型在训练集上的得分是100%。这意味着AdaBoost模型正确地预测了训练数据集的所有类标签。这表明与决策树模型相比，测试数据集的性能略有提高。但是AdaBoost模型在测试集上的评分是98%。当比较AdaBoost模型和树模型时，我会说AdaBoost分类器减少了模型偏差。</p><h1 id="bc35" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">结论</h1><p id="02b6" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">Adaboost是一种非常强大的集成方法，其中每个后续模型都试图纠正前一个模型的错误。您可以使用AdaBoost来降低偏差。但是，AdaBoost在减少模型方差方面是无效的。你可以在这里找到这个笔记本<a class="ae js" href="https://www.kaggle.com/code/tirendazacademy/breast-cancer-detection-with-bagging-technique" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0bb2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想看我关于AdaBoost的视频，给你👇</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="9faa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样。感谢您的阅读。我希望你喜欢它。别忘了在<a class="ae js" href="https://www.youtube.com/channel/UCFU9Go20p01kC64w-tmFORw" rel="noopener ugc nofollow" target="_blank">YouTube</a>|<a class="ae js" href="https://github.com/tirendazacademy" rel="noopener ugc nofollow" target="_blank">GitHub</a>|<a class="ae js" href="https://twitter.com/TirendazAcademy" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae js" href="https://www.kaggle.com/tirendazacademy" rel="noopener ugc nofollow" target="_blank">ka ggle</a>|<a class="ae js" href="https://www.linkedin.com/in/tirendaz-academy" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>上关注我们👍</p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/geekculture/6-steps-to-become-a-machine-learning-expert-5a1f155f7207"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">成为机器学习专家的6个步骤</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">成为机器学习专家需要知道的一切。</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu jm mg"/></div></div></a></div><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/geekculture/8-best-seaborn-visualizations-20143a4b3b2f"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">8个最好的Seaborn可视化</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">使用企鹅数据集与Seaborn一起动手绘制统计图。</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mv l mr ms mt mp mu jm mg"/></div></div></a></div><h1 id="263b" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">参考</h1><ul class=""><li id="6ec2" class="jt ju hh ig b ih lf il lg ip mw it mx ix my jb jy jz ka kb bi translated"><a class="ae js" href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting" rel="noopener ugc nofollow" target="_blank">装袋与增压</a></li><li id="218c" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated"><a class="ae js" href="https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312" rel="noopener ugc nofollow" target="_blank">使用PyTorch和Scikit-Learn进行机器学习</a></li></ul><p id="9ff7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果这篇文章有帮助，请点击拍手👏按钮几下，以示支持👇</p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mz l mr ms mt mp mu jm mg"/></div></div></a></div></div></div>    
</body>
</html>
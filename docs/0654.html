<html>
<head>
<title>CNNs with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带PyTorch的CNN</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/cnns-with-pytorch-6cf7ed114af7?source=collection_archive---------5-----------------------#2021-06-05">https://medium.com/mlearning-ai/cnns-with-pytorch-6cf7ed114af7?source=collection_archive---------5-----------------------#2021-06-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6eed" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">基于时尚MNIST数据集的两层卷积神经网络</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/2e9814d8efa9b659b77033b1dd06911e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktFwPKVjynu1PskxRt4xKA.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://www.pexels.com/@lum3n-44775" rel="noopener ugc nofollow" target="_blank">Lum3n</a> from <a class="ae jm" href="https://www.pexels.com/" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><h1 id="30e9" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">数据集处理</h1><p id="3881" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">在这个项目中，我们将使用<a class="ae jm" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank"> MNIST时尚数据集</a>，这是一个众所周知的数据集，恰好作为PyTorch库中的一个玩具示例出现。</p><p id="98a0" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">时尚-MNIST数据集被提议作为MNIST更具挑战性的替代数据集。它是一个数据集，由10种服装的60，000个小正方形28×28像素灰度图像组成，如鞋子、t恤、连衣裙等。</p><p id="fae0" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">你可以在这里找到这篇文章的<a class="ae jm" href="https://github.com/augustodn/pytorch_FashionMNIST" rel="noopener ugc nofollow" target="_blank">回购</a>，如果你想跟随代码旁边的评论。简单地说，数据集图像不会被重新缩放，因为我们希望以更高的训练率为代价来提高预测性能。因此，发生的唯一变换将是把图像作为张量对象(矩阵)处理所需的变换。</p><h1 id="3506" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">构建模型</h1><p id="8be5" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">众所周知，卷积神经网络(CNN)是计算机视觉中最常用的架构之一。这种架构通常可以在90%的准确度范围内获得令人印象深刻的结果。不仅如此，这些模型倾向于<a class="ae jm" href="https://developers.google.com/machine-learning/crash-course/generalization/video-lecture" rel="noopener ugc nofollow" target="_blank">很好地概括</a>。</p><p id="62f6" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">CNN由包括卷积和激活的几个变换组成。几个层可以连接在一起，以增强特征提取(是的，我知道你在想什么，我们向模型提供原始数据)。一般来说，我们使用卷积来减少要处理的信息量，同时保持特征完整。这有助于我们减少最后一层的输入(和神经元)数量。如果你想要更深入的解释，这里有一个很好的资源。对于这种特殊情况，我们将使用内核大小为5的卷积和大小为2的最大池激活。</p><p id="325f" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">如果你是卷积的新手，这里也有一个很好的视频，在最初的几分钟里，展示了卷积是如何发生的。这是一个很好的动画，它帮助我们形象化<a class="ae jm" href="https://www.youtube.com/watch?v=8rrHTtUzyZA" rel="noopener ugc nofollow" target="_blank">的概念以及流程如何工作</a>。此外，如果你想知道更多关于最大池激活，这里有另一个<a class="ae jm" href="https://www.youtube.com/watch?v=ZjM_XQa5s6s" rel="noopener ugc nofollow" target="_blank">视频</a>的额外细节。同样重要的是，卷积核(或滤波器)权重(参数)将在训练期间学习，以便优化模型。</p><p id="c33b" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">设计模型时最困难的部分之一是确定矩阵的维数，这需要作为卷积和最后完全连接的线性层的输入参数。最后一层帮助我们确定预测的类别或标签，在这种情况下，这些是不同的服装类别。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lg"><img src="../Images/5190b3e20fa5cc7eddf6a03072936356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qM-NrxVlSfQndPjUD0LaHA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Convolutional Neural Network architecture implemented</figcaption></figure><p id="dfb3" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">我们将创建一个2层CNN，其中最大池激活函数通过管道传输到卷积结果。因为我们不想失去图像的边缘，我们将在卷积发生之前添加填充。在整个项目中，我们将使用m=n(行等于列)的方阵。我们将矩阵输入维度称为<code class="du lh li lj lk b">I</code>，在这种特殊情况下，原始图像为<code class="du lh li lj lk b">I = 28</code>。同样，输出矩阵的维数将用字母<code class="du lh li lj lk b">O.</code>表示</p><h1 id="42c1" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">卷积参数</h1><pre class="ix iy iz ja fd ll lk lm ln aw lo bi"><span id="3042" class="lp jo hh lk b fi lq lr l ls lt">kernel = 5<br/>padding = 2<br/>stride = 1<br/>dilation = 1</span></pre><p id="8208" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">给定这些参数，卷积处理后的新矩阵维数为:</p><p id="8b2f" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><code class="du lh li lj lk b">O = I + 2 p - k + 1</code></p><p id="6e96" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><code class="du lh li lj lk b">O = I</code></p><p id="c3b7" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">其中:</p><ul class=""><li id="7ce2" class="lu lv hh kh b ki lb kl lc ko lw ks lx kw ly la lz ma mb mc bi translated">填充</li><li id="ad61" class="lu lv hh kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">k:内核大小</li><li id="d4eb" class="lu lv hh kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">I:输入矩阵大小</li><li id="c152" class="lu lv hh kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">o:输出矩阵大小</li></ul><h1 id="e212" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">最大池激活参数</h1><p id="acab" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">对于MaxPool激活，默认情况下stride是内核的大小。参数包括:</p><pre class="ix iy iz ja fd ll lk lm ln aw lo bi"><span id="3b0e" class="lp jo hh lk b fi lq lr l ls lt">kernel = 2<br/>padding = 0<br/>stride = 0<br/>dilation = 1</span></pre><p id="8bb1" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">在这种情况下，最大池激活后的新矩阵维数为:</p><p id="1a41" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><code class="du lh li lj lk b">O = (I - k)/s + 1</code></p><p id="0f4c" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><code class="du lh li lj lk b">O = (I - 2)/2 + 1</code></p><p id="f9c5" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated"><code class="du lh li lj lk b">O = I/2</code></p><p id="45fc" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">如果你对在几个过滤过程后确定矩阵维数感兴趣，你也可以看看这个:<a class="ae jm" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank"> CNN Cheatsheet CS 230 </a></p><h1 id="0fbc" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">实际项目矩阵维度</h1><p id="f395" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">经过前面的讨论，在这种特殊情况下，项目矩阵的维度如下</p><ul class=""><li id="c882" class="lu lv hh kh b ki lb kl lc ko lw ks lx kw ly la lz ma mb mc bi translated">在第一次卷积之后，创建了16个28×28像素的输出矩阵。</li><li id="da38" class="lu lv hh kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">最大池激活后矩阵的尺寸为14x14像素。</li><li id="d285" class="lu lv hh kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">第二次卷积后的32个结果矩阵具有与第一次卷积相同的内核和填充，其维数为14x14 px。</li><li id="e322" class="lu lv hh kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">最后，在最后一次最大池激活后，生成的矩阵具有7x7 px的维度。</li></ul><p id="00ed" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">最后一次最大池激活后的32个通道(每个通道有7x7 px)在展平通道后总计1568个输入到完全连接的最终层。</p><p id="402c" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">下面的类显示了<code class="du lh li lj lk b">forward</code>方法，在这里我们定义了如何在模型中组织操作。这是，这是我们设计神经网络架构的地方。PyTorch提供了一种替代方式，称为<code class="du lh li lj lk b">Sequential</code>模式。这里可以了解更多<a class="ae jm" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html" rel="noopener ugc nofollow" target="_blank">。正如您可能注意到的，第一个转换是一个卷积，接着是一个</a><a class="ae jm" href="https://towardsdatascience.com/understanding-relu-the-most-popular-activation-function-in-5-minutes-459e3a2124f" rel="noopener" target="_blank"> Relu </a>激活，然后是一个MaxPool激活/转换。如前所述，卷积充当特征提取过程，其中预测器被保留，并且信息被压缩。这样，我们可以在不丢失输入数据的情况下更快地训练网络。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mi mj l"/></div></figure><h1 id="ea09" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">确定优化器和数据加载器</h1><p id="1cef" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">在对我们的神经网络建模之后，我们必须确定损失函数和优化参数。因此，我们将选择交叉熵策略作为损失函数。该函数通常选择非二进制分类变量。这里有一篇很棒的文章可以让你了解更多。为了确定最小成本，我们将使用随机梯度下降策略，这几乎是在我们的数据不适合内存的情况下的普通风格。使用SGD，使用批次和几个步骤，运行损失函数以寻找至少一个局部最小值。为此，我们将创建<code class="du lh li lj lk b">train_loader</code>和<code class="du lh li lj lk b">validation_loader</code>迭代器。</p><h1 id="3fe9" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">训练模型</h1><p id="3085" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">如前所述，我们将通过数据运行一些训练迭代(历元)，这将分几批完成。然后，我们将使用验证数据检查模型的准确性，最后我们将重复这一过程。值得注意的是<code class="du lh li lj lk b">optimizer.step()</code>为下一次迭代调整模型权重，这是为了最小化真实函数y的误差</p><p id="497d" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">最后，我们将追加每个历元的成本和精度值，并绘制最终结果。分析剧情。我们将看到，随着模型调整权重并从训练数据中“学习”，成本如何下降，准确度如何提高。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mi mj l"/></div></figure><h1 id="a7cc" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">分析结果</h1><p id="6a8a" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">下面你会看到这个模型的成本和准确性的图表。正如预期的那样，当训练微调核和全连接层权重时，成本降低并且准确度增加。换句话说，模型通过迭代学习。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mk"><img src="../Images/9f8000778a3812248c29a0e95951d4cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*HTqb5fFZqzUHld5mBeh_6Q.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Cost and Accuracy results | Image by Author</figcaption></figure><h1 id="82c0" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">检查分类</h1><p id="1db6" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">下图描述了时尚MNIST数据集中的不同类别。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ml"><img src="../Images/c827a9f4b516ecb529aee03c27f370cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EeQjfpPVkZ7Bqxp_uyz0zw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Fashion MNIST Categories</figcaption></figure><p id="33a8" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">最后，我们将检查模型没有正确分类的一些样本。正如你可能看到的，有时在如此低分辨率的图片下区分凉鞋或运动鞋并不容易，即使对于人眼来说也是如此。请注意第一张图片，模型预测的是一个包，但实际上是一双运动鞋。它看起来有点像一个包，不是吗？。这位模特也很难区分套头衫和外套，但就这张照片而言，说实话，这并不容易分辨。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mm"><img src="../Images/9605dce6aac9a8ce4feb10819d3f91c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*oGZS4DT0BmRm0ZCS4mEFZQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Prediction failures | Image by author</figcaption></figure><h1 id="a5cc" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">包装它</h1><p id="80b8" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">一个2层的CNN在从时尚MNIST数据集中预测图像方面做了出色的工作，在6个训练时期之后，总体准确度几乎达到90%。这并不奇怪，因为这种神经网络结构取得了很好结果。</p><p id="f33c" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">当然，精度可以通过减少卷积核的大小来提高，以便每次迭代丢失更少的数据，代价是训练时间更长。此外，可以在每次卷积之后以及在最终完全连接的层中实现归一化。这有助于在更少的时期内获得更高的精度。你可以尝试一下，并在这里留下一些评论。有一篇关于<a class="ae jm" href="https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd" rel="noopener" target="_blank">批处理规范化</a>的好文章，你可以深入阅读。</p><p id="a52f" class="pw-post-body-paragraph kf kg hh kh b ki lb ii kk kl lc il kn ko ld kq kr ks le ku kv kw lf ky kz la ha bi translated">你可以在github <a class="ae jm" href="https://github.com/augustodn/pytorch_FashionMNIST" rel="noopener ugc nofollow" target="_blank">回购</a>中查看该笔记本。别忘了在<a class="ae jm" href="https://twitter.com/augusto_dn" rel="noopener ugc nofollow" target="_blank">推特上关注我。感谢来到这里，特别感谢Jorge和Franco对这篇文章的修改。</a></p></div></div>    
</body>
</html>
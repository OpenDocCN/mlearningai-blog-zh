# è‡ªåŠ¨ç¼–ç å™¨çš„é­”åŠ›

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/the-magic-of-autoencoders-73162e9bd43f?source=collection_archive---------1----------------------->

è‡ªåŠ¨ç¼–ç å™¨æ˜¯ä¸€ä¸ªé¡ºåºç¥ç»ç½‘ç»œï¼Œç”±ä¸¤ä¸ªç»„ä»¶ç»„æˆï¼Œ**ç¼–ç å™¨**å’Œ**è§£ç å™¨**ã€‚

å‡è®¾æˆ‘ä»¬åœ¨å¤„ç†å›¾åƒã€‚æˆ‘ä»¬çš„ç¼–ç å™¨å°†ä»å›¾åƒä¸­æå–ç‰¹å¾ï¼Œè¿™å°†å‡å°‘ä¸€äº›ç»„ä»¶ï¼Œå¦‚å…¶é«˜åº¦å’Œå®½åº¦ï¼Œä½†ä¸ºå›¾åƒåˆ¶ä½œä¸€ä¸ª**æ½œåœ¨è¡¨ç¤º**ã€‚è¿™ç§æ½œåœ¨çš„è¡¨ç°å½¢å¼åªæ˜¯æ„å‘³ç€ç¥ç»ç½‘ç»œåªæ•æ‰è¾“å…¥çš„æœ€ç›¸å…³çš„ç‰¹å¾ã€‚

è§£ç å™¨æ˜¯ç¥ç»ç½‘ç»œçš„ä¸€éƒ¨åˆ†ï¼Œå®ƒå­¦ä¹ å¦‚ä½•ä»ç¼–ç ç‰ˆæœ¬ä¸­é‡å»ºæ•°æ®ã€‚ä»¥å°½å¯èƒ½æ¥è¿‘åŸå§‹è¾“å…¥çš„æ–¹å¼é‡æ„æ•°æ®ã€‚

æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ª**é‡å»ºæŸå¤±**ï¼Œç”¨äºè¡¡é‡è§£ç å™¨çš„æ€§èƒ½ä»¥åŠè¾“å‡ºæ•°æ®ä¸åŸå§‹è¾“å…¥æ•°æ®çš„æ¥è¿‘ç¨‹åº¦ã€‚ä¸ºäº†æœ€å°åŒ–æŸå¤±ï¼Œè‡ªåŠ¨ç¼–ç å™¨ä½¿ç”¨**åå‘ä¼ æ’­**æ¥æœ€å°åŒ–ç¥ç»ç½‘ç»œçš„é‡å»ºæŸå¤±ã€‚

è‡ªåŠ¨ç¼–ç å™¨å…è®¸æˆ‘ä»¬ä»¥æœ€ä½³æ–¹å¼å‹ç¼©æ•°æ®ï¼Œä»¥å‡å°‘ç»´åº¦å¹¶å¿½ç•¥æ•°æ®ä¸­çš„å™ªå£°ã€‚

ä¸‹é¢æ˜¯å¦‚ä½•ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨å¯¹æ¥è‡ª MIST æ•°æ®é›†(æ‰‹å†™æ•°å­—)çš„å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç çš„ç¤ºä¾‹ã€‚å¦‚æ‚¨æ‰€è§ï¼ŒåŸå§‹è¾“å…¥å’Œé‡æ„è¾“å…¥éå¸¸ç›¸ä¼¼ã€‚

![](img/e76fe5cc48ef254e8c10c429b71faafa.png)

Image from google images.

## æ„å»ºè‡ªåŠ¨ç¼–ç å™¨

æˆ‘å·²ç»ç”¨ PyTorch æ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ï¼Œæˆ‘å°†ä¸€æ­¥ä¸€æ­¥åœ°å‘æ‚¨å±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ã€‚

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¹æ•´ä¸ªä»£ç åšä¸€ä¸ªæ¦‚è¿°:

```
import torch
import torch.nn as nn
from torchvision import datasets
from torch.autograd import Variable
from torchvision.transforms import transforms

#transform data to pytorch tensors
transforms = transforms.ToTensor()

fashion_data = datasets.FashionMNIST(root='./data',  download=True, transform=transforms) #train=True,

data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)

#iterating through our data
dataiter = iter(data_loader)
images, labels = dataiter.next()

#output will get the minimum tensor and the maximum tensor in the dataset --> important for our last activation
print(torch.min(images), torch.max(images))

class autoencoder(nn.Module):
    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):
        super(autoencoder, self).__init__()
        self.epochs = epochs
        self.batchSize = batchSize
        self.learningRate = learningRate
        self.weight_decay = weight_decay

        #encoder
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 12),
            nn.ReLU(),
            nn.Linear(12, 3)
        )

        #decoder
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
            nn.ReLU(),
            nn.Linear(12, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid()  # cause tensors are 0, 1
        )

        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)
        self.loss = nn.MSELoss()

    #feed data through network
    def forward(self, x):
        encoder = self.encoder(x)
        decoder = self.decoder(encoder)
        return decoder

    #training loop
    def train(self):
        for epoch in range(self.epochs):
            for data in data_loader:
                img, _ = data
                img = img.view(img.size(0), -1)
                img = Variable(img)

                #predict
                output = self(img)

                # find loss
                loss = self.loss(output, img)

                # perform back propagation
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')

model = autoencoder()
model.train()
```

ä¸ºäº†æ‰“ç ´åƒµå±€ï¼Œè®©æˆ‘ä»¬ä»æˆ‘ä»¬çš„è¿›å£å¼€å§‹:

```
import torch
import torch.nn as nn
from torchvision import datasets
from torch.autograd import Variable
from torchvision.transforms import transforms
```

å¯¼å…¥ torch â†’ PyTorch æ¨¡å—ã€‚

å¯¼å…¥ torch.nn ä½œä¸º nn â†’ç”¨äºæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œç±»ã€‚

ä» torchvision å¯¼å…¥æ•°æ®é›†â†’å…è®¸æˆ‘ä»¬åœ¨ PyTorch ä¸­ä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®é›†ã€‚

from torch.autograd å¯¼å…¥å˜é‡â†’æˆ‘ä»¬ä½¿ç”¨å˜é‡æ¥å­˜å‚¨ç”±æŸå¤±å‡½æ•°è®¡ç®—çš„å€¼ã€‚å˜é‡æœ‰è®¸å¤šä¸å¼ é‡å’Œåå‘ä¼ æ’­ç›¸å…³çš„å‡½æ•°ã€‚

from torchvision.transforms å¯¼å…¥è½¬æ¢â†’ç”¨äºå›¾åƒé¢„å¤„ç†ã€‚

å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†å¯¼å…¥ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è·å–å’Œæµè§ˆæˆ‘ä»¬çš„æ•°æ®äº†:

```
#transform data to pytorch tensors
transforms = transforms.ToTensor()

fashion_data = datasets.FashionMNIST(root='./data',  download=True, transform=transforms) #train=True,

data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)

#iterating through our data
dataiter = iter(data_loader)
images, labels = dataiter.next()
```

é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆå§‹åŒ–ä¸€ä¸ªåä¸º transforms çš„å˜é‡ï¼Œå½“å®ƒè¢«ä¼ é€’ç»™ transform å‚æ•°æ—¶ï¼Œä¼šå°†ä¸€ä¸ªå›¾åƒè½¬æ¢æˆ PyTorch å¼ é‡ã€‚

```
transforms = transforms.ToTensor()
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºæˆ‘ä»¬çš„ fashion_data å˜é‡ï¼Œå®ƒå°†ä½¿ç”¨æ•°æ®é›†ã€‚FashionMNIST è·å–é¢„å…ˆåŠ è½½åœ¨ PyTorch ä¸­çš„ FashionMNIST æ•°æ®ã€‚æˆ‘ä»¬è¿˜å°†æŠŠ transforms å˜é‡ä¼ é€’ç»™ transform å‚æ•°ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³æŠŠæˆ‘ä»¬çš„å›¾åƒè½¬æ¢æˆå¼ é‡ã€‚

```
fashion_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms)
```

PyTorch æœ‰ä¸€ä¸ªæ¼‚äº®çš„ç±»ï¼Œå«åš DataLoaderï¼Œå®ƒå…è®¸æˆ‘ä»¬åŠ è½½æ•°æ®ï¼Œå¹¶è¿­ä»£å…ƒç´ ï¼Œä¸æ‰‹åŠ¨è¾“å…¥æ‰€æœ‰æ•°æ®ç›¸æ¯”ï¼Œå®ƒçš„æ•ˆç‡æé«˜äº† 10 å€ã€‚

ä¸‹é¢ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª data_loader å˜é‡ï¼Œå®ƒä½¿ç”¨ PyTorch çš„ DataLoader è¿­ä»£æˆ‘ä»¬çš„ fashion_dataï¼Œç»™å®ƒä¸€ä¸ª 64 çš„æ‰¹å¤„ç†å¤§å°ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œæ··æ’ã€‚

```
data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)
```

æœ€åï¼Œæˆ‘ä»¬å°†éå† data_loaderï¼Œéå†æ¯å¼ å›¾ç‰‡å’Œæ ‡ç­¾ã€‚

```
#iterating through our data
dataiter = iter(data_loader)
images, labels = dataiter.next()
```

æˆ‘ä»¬å°†æ‰“å°å›¾åƒçš„ torch.min()æ¥æŸ¥æ‰¾è¾“å…¥å¼ é‡ä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å°å€¼ï¼Œå¹¶æ‰“å° torch.max()æ¥æŸ¥æ‰¾è¾“å…¥å¼ é‡ä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼ã€‚

```
#output will get the minimum tensor and the maximum tensor in the dataset --> important for our last activationprint(torch.min(images), torch.max(images))
```

è¿™æœ€åä¸€å¥è¯å¾ˆé‡è¦ï¼Œå› ä¸ºè¿”å›çš„å¼ é‡å€¼å°†å†³å®šæˆ‘ä»¬åœ¨è§£ç å™¨çš„æœ€åä¸€å±‚éœ€è¦ä½¿ç”¨ä»€ä¹ˆå‡½æ•°ã€‚å› ä¸ºè¾“å‡ºæ˜¾ç¤ºæˆ‘ä»¬çš„æœ€å°å¼ é‡æ˜¯å¼ é‡(0ã€‚)å¹¶ä¸”æœ€å¤§å¼ é‡æ˜¯å¼ é‡(1ã€‚)ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰çš„å¼ é‡éƒ½åœ¨è¿™äº›æ•°ä¹‹é—´ï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»ä½¿ç”¨ Sigmoid æ¿€æ´»ã€‚

è®°ä½ sigmoid æ¿€æ´»å‡½æ•°æ˜¯è¿ç»­çš„ï¼Œæ‰€æœ‰ç‚¹ä¸Šçš„å¯¼æ•°æ€»æ˜¯äº§ç”Ÿæ•°å­— 0 å’Œ 1 ä¹‹é—´çš„è¾“å‡ºã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ•°æ®ï¼Œå¹¶äº†è§£äº†ä¸€äº›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ„å»ºæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨ç¥ç»ç½‘ç»œã€‚

ä»¥ä¸‹æ˜¯æˆ‘ä»¬æ•´ä¸ªä»£ç çš„æ¦‚è¿°:

```
class autoencoder(nn.Module):
    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):
        super(autoencoder, self).__init__()
        self.epochs = epochs
        self.batchSize = batchSize
        self.learningRate = learningRate
        self.weight_decay = weight_decay

        #encoder
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 12),
            nn.ReLU(),
            nn.Linear(12, 3)
        )

        #decoder
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
            nn.ReLU(),
            nn.Linear(12, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid()  # cause tensors are 0, 1
        )

        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)
        self.loss = nn.MSELoss()

    #feed data through network
    def forward(self, x):
        encoder = self.encoder(x)
        decoder = self.decoder(encoder)
        return decoder

    #training loop
    def train(self):
        for epoch in range(self.epochs):
            for data in data_loader:
                img, _ = data
                img = img.view(img.size(0), -1)
                img = Variable(img)

                #predict
                output = self(img)

                # find loss
                loss = self.loss(output, img)

                # perform back propagation
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')

model = autoencoder()
model.train()
```

å¥½äº†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„è¿›æ­¥ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æŠŠå®ƒä¸€éƒ¨åˆ†ä¸€éƒ¨åˆ†çš„åˆ†è§£å§:)

```
class autoencoder(nn.Module):
    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):
        super(autoencoder, self).__init__()
        self.epochs = epochs
        self.batchSize = batchSize
        self.learningRate = learningRate
        self.weight_decay = weight_decay

        #encoder
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 12),
            nn.ReLU(),
            nn.Linear(12, 3)
        )

        #decoder
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
            nn.ReLU(),
            nn.Linear(12, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid()  # cause tensors are 0, 1
        )

        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)
        self.loss = nn.MSELoss()
```

æˆ‘ä»¬å°†è°ƒç”¨æˆ‘ä»¬çš„ç±» autoencoderï¼Œå®ƒå°†ç»§æ‰¿ nnã€‚æ¨¡å—ç±»ã€‚è¿™é€šå¸¸æ˜¯ PyTorch ä¸­æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç±»ã€‚

ä¸ºäº†ç®€å•åœ°è§£é‡Šè¿™ä¸ªæ¨¡å—ï¼Œå®ƒä½¿ç”¨å¼ é‡å’Œè‡ªåŠ¨å¾®åˆ†æ¨¡å—(è®¡ç®—å‡½æ•°å¯¼æ•°çš„æŠ€æœ¯)æ¥è®­ç»ƒå’Œæ„å»ºå±‚(è¾“å…¥ã€éšè—ã€è¾“å‡ºç­‰)ã€‚

åœ¨æˆ‘ä»¬çš„ __init__ ä¸­ï¼Œæˆ‘ä»¬å°†ä¼ å…¥æˆ‘ä»¬çš„çºªå…ƒã€æ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œåˆå§‹åŒ–ã€‚ä½ å¯ä»¥æ‘†å¼„è¿™äº›æ•°å­—ï¼Œä½†æ˜¯ï¼Œè¿™äº›æ˜¯æˆ‘å‘ç°æ•ˆæœæœ€å¥½çš„æ•°å­—ã€‚

```
class autoencoder(nn.Module):
    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):
        super(autoencoder, self).__init__()
        self.epochs = epochs
        self.batchSize = batchSize
        self.learningRate = learningRate
        self.weight_decay = weight_decay
```

åˆå§‹åŒ–ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ„å»ºæˆ‘ä»¬çš„ç¼–ç å™¨ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é¡ºåºç»“æ„ï¼Œä¸€ä¸ªçº¿æ€§å±‚åé¢è·Ÿç€ä¸€ä¸ª relu æ¿€æ´»ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¼ å…¥çš„å›¾åƒå¤§å°ä¸º 28 x 28ï¼Œå› ä¸ºæ—¶å°š MNIST æ•°æ®é›†çš„å›¾åƒä¸º 784 åƒç´ ã€‚æ¯ä¸€å±‚ï¼Œæˆ‘ä»¬éƒ½ä¼šå‡å°‘æŠ•å…¥ã€‚

ä½ å¯ä»¥æŠŠæˆ‘ä»¬çš„è¾“å…¥æƒ³è±¡æˆ Nï¼Œ784ï¼Œç¼–ç å™¨çš„è¾“å‡ºå°†ä¼šæ˜¾è‘—åœ°å‡å°‘åˆ° Nï¼Œ3ã€‚

```
#encoder
self.encoder = nn.Sequential(
    nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128
    nn.ReLU(),
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Linear(64, 12),
    nn.ReLU(),
    nn.Linear(12, 3)
)
```

æˆ‘ä»¬çš„è§£ç å™¨ä¸æˆ‘ä»¬çš„ç¼–ç å™¨ç»“æ„ç›¸ä¼¼ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹å‘ç›¸åï¼Œå³â†’ Nï¼Œ3 åˆ° Nï¼Œ784ã€‚

å¯¹äºæˆ‘ä»¬çš„æœ€åä¸€å±‚ï¼Œæ³¨æ„æˆ‘ä»¬ä½¿ç”¨äº† sigmoid æ¿€æ´»(å‰é¢è§£é‡Šè¿‡)ã€‚

```
#decoder
self.decoder = nn.Sequential(
    nn.Linear(3, 12),
    nn.ReLU(),
    nn.Linear(12, 64),
    nn.ReLU(),
    nn.Linear(64, 128),
    nn.ReLU(),
    nn.Linear(128, 28 * 28),
    nn.Sigmoid()  # cause tensors are 0, 1
)
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œæ ‡å‡†äº†ã€‚ä¸€å®šè¦ç¡®ä¿åœ¨ä½ çš„è‡ªåŠ¨ç¼–ç å™¨ä¸‹é¢å®šä¹‰å®ƒï¼Œå¦åˆ™ä½ å°†ä¸èƒ½ä¼ é€’ä»»ä½•ä¸œè¥¿ã€‚

è®°ä½â†’ä¼˜åŒ–å™¨æ˜¯æ”¹å˜å±äºä½ çš„ç¥ç»ç½‘ç»œçš„å±æ€§çš„ç®—æ³•ï¼Œæ¯”å¦‚æƒé‡å’Œå­¦ä¹ ç‡ï¼Œä»¥å‡å°‘æŸå¤±ã€‚

å¯¹äºæˆ‘ä»¬çš„ç½‘ç»œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ã€‚æˆ‘ä»¬å°†éœ€è¦ä¼ å…¥ self.parametersã€æˆ‘ä»¬çš„å­¦ä¹ ç‡å’Œæˆ‘ä»¬çš„ weight_decay(è¿™æ˜¯æˆ‘ä»¬ä¹‹å‰åœ¨ç½‘ç»œä¸­åˆå§‹åŒ–çš„)ã€‚

è®°ä½â†’å­¦ä¹ ç‡æ§åˆ¶ç€ç½‘ç»œé€‚åº”é—®é¢˜çš„é€Ÿåº¦ã€‚

è®°ä½â†’æ­£åˆ™åŒ–æ˜¯ä¸€ç§çº¦æŸæˆ‘ä»¬çš„ç½‘ç»œç²¾ç¡®æ‹Ÿåˆæˆ‘ä»¬çš„æ•°æ®ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆçš„æ–¹æ³•ã€‚Weight_decay æ˜¯ä¸€ç§åœ¨ç¥ç»ç½‘ç»œä¸Šæ‰§è¡Œæ­£åˆ™åŒ–çš„æ–¹æ³•ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ MSELossã€‚

```
self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)
self.loss = nn.MSELoss()
```

å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥æŠŠæ•°æ®è¾“å…¥ç½‘ç»œäº†ã€‚æˆ‘ä»¬å°†æ¥å— xï¼Œå°†å®ƒä¼ å…¥æˆ‘ä»¬çš„ç¼–ç å™¨ï¼Œå°†æˆ‘ä»¬çš„ç¼–ç å™¨ä¼ å…¥è§£ç å™¨ï¼Œæœ€åè¿”å›æˆ‘ä»¬çš„è§£ç å™¨çš„ç»“æœã€‚

```
#feed data through network
def forward(self, x):
    encoder = self.encoder(x)
    decoder = self.decoder(encoder)
    return decoder
```

ç°åœ¨æˆ‘ä»¬å·²ç»å»ºç«‹äº†æˆ‘ä»¬çš„ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

æˆ‘ä»¬å°†åœ¨æ¯ä¸ªæ—¶æœŸè¿­ä»£æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œå¹¶å¢åŠ æˆ‘ä»¬çš„å›¾åƒä»¥é€‚åº”ç½‘ç»œã€‚æˆ‘ä»¬å°†è°ƒç”¨é¢„æµ‹ï¼Œè®¡ç®—æŸå¤±ï¼Œç„¶åæ‰§è¡Œåå‘ä¼ æ’­ã€‚åœ¨æ¯ä¸€ä¸ªæ—¶ä»£ä¹‹åï¼Œæˆ‘ä»¬å°†è¾“å‡ºæŸå¤±ã€‚

```
#training loop
def train(self):
    for epoch in range(self.epochs):
        for data in data_loader:
            img, _ = data
            img = img.view(img.size(0), -1)
            img = Variable(img)

            #predict
            output = self(img)

            # find loss
            loss = self.loss(output, img)

            # perform back propagation
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

        print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')
```

æœ€åï¼Œä¸ºäº†è¿è¡Œæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª autoencoder ç±»çš„å¯¹è±¡ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªå¯¹è±¡ç§°ä¸ºæ¨¡å‹ã€‚ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å°†åœ¨å¯¹è±¡ä¸Šè°ƒç”¨æˆ‘ä»¬çš„è®­ç»ƒå‡½æ•°ã€‚

```
model = autoencoder()
model.train()
```

æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡å…³äºå¦‚ä½•åœ¨ PyTorch ä¸­æ„å»ºè‡ªåŠ¨ç¼–ç å™¨çš„è§£é‡Šå’Œæ•™ç¨‹ï¼è¿™ä¸ªæ¨¡å‹è®­ç»ƒå¾—å¾ˆå¥½ï¼Œå‡ ä¹æ²¡æœ‰æŸå¤±ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»æ—¶å°š MNIST ä¸­é€‰å–ä¸€ä¸ªç‰¹å®šçš„å›¾åƒæ¥æµ‹è¯•ç»“æœï¼Œå°†å®ƒè¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå¹¶ç»˜åˆ¶å‡ºä¹‹å‰å’Œä¹‹åçš„ç»“æœã€‚

# å¦‚æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·è”ç³»æˆ‘ğŸš€

å—¨ï¼Œæˆ‘æ˜¯ Ashleyï¼Œä¸€ä¸ª 16 å²çš„ç¼–ç¨‹å‘†å­ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½å’Œç¥ç»ç§‘å­¦çˆ±å¥½è€…ï¼

æˆ‘å¸Œæœ›ä½ å–œæ¬¢é˜…è¯»æˆ‘çš„æ–‡ç« ï¼Œå¦‚æœä½ å–œæ¬¢ï¼Œè¯·éšæ—¶æŸ¥çœ‹æˆ‘åœ¨ Medium ä¸Šçš„å…¶ä»–ä½œå“:)

è¿™æ®µä»£ç çš„ä»“åº“åœ¨æˆ‘çš„ GitHub ä¸Šï¼Œåœ¨æˆ‘çš„â€œPytorchâ€ä»“åº“ä¸‹ã€‚

å¦‚æœä½ è¯»äº†è¿™ç¯‡æ–‡ç« ï¼Œä½ ä¼šå–œæ¬¢çš„:

ğŸ’«[py torch ä¸­çš„ MNIST æ•°å­—åˆ†ç±»](https://ashleyy-czumak.medium.com/mnist-digit-classification-in-pytorch-302476b34e4f)

ğŸ’«[å·ç§¯ç¥ç»ç½‘ç»œæ¦‚è¿°](/swlh/an-overview-on-convolutional-neural-networks-ea48e76fb186)

ğŸ’«[å…¬å¸éœ€è¦å‡è½»äººå·¥æ™ºèƒ½åè§](/swlh/companies-need-to-mitigate-a-i-bias-830e7cae8149)

å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œæƒ³äº†è§£æ›´å¤šå…³äºæˆ‘çš„ä¿¡æ¯ï¼Œæˆ–è€…æƒ³è¦ä»»ä½•äººå·¥æ™ºèƒ½æˆ–ç¼–ç¨‹ç›¸å…³çš„èµ„æºï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘:

ğŸ’«ç”µå­é‚®ä»¶:ashleycinquires@gmail.com

ğŸ’« [Github](https://github.com/ashthedash2k)
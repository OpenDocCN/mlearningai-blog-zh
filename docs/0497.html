<html>
<head>
<title>Object Detection Explained: Faster R-CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">物体检测解释:更快的R-CNN</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-detection-explained-faster-r-cnn-23e7ab57991d?source=collection_archive---------2-----------------------#2021-05-04">https://medium.com/mlearning-ai/object-detection-explained-faster-r-cnn-23e7ab57991d?source=collection_archive---------2-----------------------#2021-05-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/a6c307b2fb836c2c0af8955c15d3c5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m46yEvhMgBOZ2WxYB2buCQ.jpeg"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx"><a class="ae hu" href="https://unsplash.com/@jo_coenen" rel="noopener ugc nofollow" target="_blank">Jo Coenen</a> via <a class="ae hu" href="https://unsplash.com/photos/5UNYknY0MTA" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="94a2" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">用简单的语言表达难懂的概念。</p><p id="efba" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">目标检测包括两个独立的任务，即分类和定位。R-CNN代表基于区域的卷积神经网络。R-CNN系列背后的关键概念是地区提案。区域建议用于定位图像中的对象。在接下来的博客中，我决定写一些在物体检测中使用的不同方法和架构。在本文中，我最终用更快的R-CNN结束了这个R-CNN系列。</p><p id="c3c6" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hy">之前的</strong>:</p><p id="b377" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" href="https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76" rel="noopener" target="_blank"> RCNN </a></p><p id="5f33" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" rel="noopener" href="/mlearning-ai/object-detection-explained-fast-r-cnn-bc11e607411f">快速RCNN </a></p><p id="c2d6" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" rel="noopener" href="/mlearning-ai/object-detection-explained-feature-pyramid-networks-cf2621c8f7cc"> FPN </a></p><h1 id="8ac8" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">快速RCNN的问题</h1><p id="5e69" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">虽然快速RCNN克服了RCNN的一些问题，但建议区域仍然是通过运行在CPU上的选择性搜索算法来计算的，而网络通常运行在GPU上。所以推断时间变得相当慢。因此，更快的RCNN通过引入区域建议网络(rpn)克服了这个问题。</p><h1 id="efa8" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">工作细节</h1><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es kv"><img src="../Images/50cff4f8c35b3277185c2179e2897413.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*8u44nQSCCIueRBpZO9DpDg.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Faster R-CNN is a single, unified network for object detection. Source:<a class="ae hu" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></figcaption></figure><p id="327b" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正如所看到的，当我们从主干网络获得我们的特征地图时，我们现在通过单独的网络传递它们，该网络是区域提议网络，其生成我们的提议。因此，我们现在训练一个单独的网络，而不是使用选择性搜索算法，这解决了与快速RCNN相关的问题。现在，我想一步一步地描述整个架构。</p><figure class="kw kx ky kz fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es la"><img src="../Images/b56afed30161e66401af5a302e250b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ibIVmaCwtfFwOz1cRJ-K7w.jpeg"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">FPN based Faster RCNN</figcaption></figure><h1 id="582f" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">中枢网络</h1><p id="6662" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">虽然作者利用传统的卷积网络进行特征提取，但我想详细阐述我以前的文章，并解释RCNN如何更快地利用FPN。正如我们所记得的，FPN制作了P2-P5专题地图，因此这些专题地图随后被输入到我们的区域提案网络中。这种修改大大改进了对象检测，因为它有助于检测各种规模的对象。因此，假设主干是我在上一篇文章中介绍的网络。</p><h1 id="83d5" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">区域提案网络</h1><h2 id="69d5" class="lb jt hx bd ju lc ld le jy lf lg lh kc jf li lj kg jj lk ll kk jn lm ln ko lo bi translated">锚箱</h2><figure class="kw kx ky kz fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lp"><img src="../Images/fa3877b40d52d07bfdee7fc4dc4c1fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z81KQWO6PPd0WQXx6uO6UA.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">Anchor box example. source:<a class="ae hu" href="https://www.youtube.com/watch?v=RTlwl2bv0Tg" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=RTlwl2bv0Tg</a></figcaption></figure><p id="8e34" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在每个滑动窗口位置，我们同时进行k个不同的预测。上图是一个简单的例子，其中k等于2。所以，有k个参考框被称为锚。每个锚点负责一个特定的比例和纵横比。该论文的作者使用了3个比例和3个长宽比，结果k为9。对于一个W × H大小的卷积特征图，总共有W *H*k个锚。因此，对于特征图中的每个位置，RPN产生9 * 2(不是对象/对象)对象性分数和9 * 4锚增量。值得注意的是，每个锚点只能分配给1个对象。</p><h2 id="ee30" class="lb jt hx bd ju lc ld le jy lf lg lh kc jf li lj kg jj lk ll kk jn lm ln ko lo bi translated">RPN头</h2><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es lq"><img src="../Images/e3aaf28203900e412e737b98930b9a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*mlieVpNAa9s2VACkbeOWCg.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">RPN head. source: <a class="ae hu" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></figcaption></figure><p id="4030" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在FPN框架中，从FPN获得的每个特征图在用于目标预测和边界盒回归的单独的1 × 1卷积滤波器被应用之前经过3 × 3卷积。这些3 × 3和1 × 1的卷积层被称为RPN <strong class="iw hy">头</strong>。</p><p id="3c31" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于训练rpn，给每个锚点分配一个二进制类别标签(是否为对象)。两种锚的标签为正:(I)具有最大交叉联合(IoU)的锚与地面实况框重叠，或(ii)IoU与任何地面实况框重叠至少0.7的锚。重要的是要注意，对于给定的基础事实框，可能有多个正锚。</p><p id="807c" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果对于所有地面实况框，锚的IoU比率低于0.3，则将负标签分配给锚。所以，其他的就干脆丢弃了。</p><p id="3722" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，使用我在以前的文章中介绍的公式来计算基本事实增量。</p><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es lr"><img src="../Images/0ae367ca6e309c8e1a525a1183967a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*wks3L7oWklMkIhkBiO2jPQ.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Delta calculation. source: <a class="ae hu" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></figcaption></figure><p id="0925" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中x_a和x*分别代表正锚和地面真值箱。</p><h2 id="a2ef" class="lb jt hx bd ju lc ld le jy lf lg lh kc jf li lj kg jj lk ll kk jn lm ln ko lo bi translated">一些训练细节</h2><p id="7e54" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">RPN可以通过反向传播和随机梯度下降进行端到端的训练。为了避免网络偏向负样本，作者试图保持正负锚的比例为1:1。但是，如果没有足够的正面锚，他们会用负面锚填充一批。</p><h2 id="51ef" class="lb jt hx bd ju lc ld le jy lf lg lh kc jf li lj kg jj lk ll kk jn lm ln ko lo bi translated">投资回报池</h2><p id="9ab5" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">通过应用FPN，我们最终得到了不同比例(P2-P5)的多个特征图，因此我们需要一种策略来给特征图分配给定的ROI。</p><figure class="kw kx ky kz fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ls"><img src="../Images/2d071455540d4f354f2d08b01aff1a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5vjDmqlbDc4XTbyjhYI62w.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">ROI pooling strategy. Source:<a class="ae hu" href="https://arxiv.org/pdf/1612.03144v2.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1612.03144v2.pdf</a></figcaption></figure><p id="2bd1" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">，其中224是原始输入图像尺寸，k_0是4。总的来说，k是FPN的P_k层。因此，如果k是5，我们选择P5并应用ROI池，然后通过快速RCNN传递它。</p><h1 id="cf5e" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">快速RCNN</h1><p id="2750" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">如上图所示，快速RCNN没有修改。因此，在我们从ROI pooling中获取作物后，我们只需将它传递给我们的快速RCNN分支。因此，该分支机构的所有培训细节保持不变。</p><h1 id="9a8f" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">一些遗言</h1><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es lt"><img src="../Images/09bb8f04871d605acc6c7584dd58e11b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*hT1-H_vbqv-kQdIHSptogQ.jpeg"/></div></figure><p id="b9d4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于RPN，我们设法在我们的网络中生成一个提议区域，这使我们有机会在GPU上处理整个过程。因此，它大大加快了这一进程。此外，该方法给出了统一的、基于深度学习的对象检测系统。学习后的RPN还提高了区域提议质量和总体目标检测精度。我希望你喜欢学习RCNN系列，并期待看看其他有趣的算法。</p></div></div>    
</body>
</html>
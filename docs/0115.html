<html>
<head>
<title>DeepLearning4J: Getting Started</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习4J:入门</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/neural-networks-getting-started-with-eclipse-deeplearning4j-897f3662832b?source=collection_archive---------2-----------------------#2021-02-12">https://medium.com/mlearning-ai/neural-networks-getting-started-with-eclipse-deeplearning4j-897f3662832b?source=collection_archive---------2-----------------------#2021-02-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/a311a05aa2020b7d9759b8ae6c24ad20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWgwDpfxVTs7UIKWx5ZQzw.jpeg"/></div></div></figure><div class=""/><p id="0ccf" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir ht"> Deep Learning for Java </strong>是一个为许多与深度学习相关的算法提供支持的库，包括神经网络🙂。让我们回顾一下使用<strong class="ir ht"> DeepLearning4J </strong>创建、训练和运行神经网络的主要任务。</p><h1 id="0027" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">方案</h1><p id="aef1" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">让我们来看一个我们之前讨论过的例子:一个识别XOR运算符的神经网络。在《T4》的前作《T5》中，我们从头开始实现了这一点。现在，让我们使用<strong class="ir ht"> DeepLearning4J。</strong>如图1所示，这个神经网络有两个输入，一个隐层有三个神经元，一个输出层有一个神经元。还显示了用于训练神经网络的输入数据以及相应的已知输出。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kr"><img src="../Images/16a2c51cf551ba185b69b0f8e4e1b73b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HYyy5aesHJji39EWjNQPCg.jpeg"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Figure 1. Our neural network for calculating the XOR operator.</figcaption></figure><h1 id="b62c" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">先决条件</h1><p id="569c" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为了在我们的项目中运行<strong class="ir ht"> DeepLearning4J </strong>，我们需要以下依赖项(库):</p><ul class=""><li id="563b" class="la lb hs ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated"><strong class="ir ht"> deeplearning4j-core </strong>，包含神经网络实现。</li><li id="7859" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><strong class="ir ht"> nd4j-native-platform </strong>，一个处理n维数组的通用库</li><li id="386f" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><strong class="ir ht"> datavec-api </strong> —用于向量化和加载数据的辅助库。</li></ul><p id="9466" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一定要把这些包含在你的项目里，我们就准备好了。</p><h1 id="af18" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">加载数据</h1><p id="6b8c" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">首先，我们需要加载输入数据和相应的已知输出。我们需要它们来训练神经网络。为此，我们使用<strong class="ir ht">in array、</strong> an <strong class="ir ht"> </strong> n维数组接口。in array不同于标准的Java数组，因为它使用<em class="lo">堆外</em>内存来存储数据。<em class="lo">堆外</em>意味着内存被分配在Java虚拟机之外，也就是说，它不受垃圾收集器的管理。此外，这些内存位置可以(通过指针)传递给底层C++代码，用于<strong class="ir ht"> Nd4J </strong>库的操作。进一步来说，由于其后端的不同，<strong class="ir ht"> Nd4j </strong>甚至可以让我们同时使用CPU和GPU。</p><p id="4aa4" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于我们的小例子来说，这似乎是不必要的，但是请考虑数据量巨大的情况。我们需要两个数组，一个用于输入值，一个用于已知输出。创建数组最常用的两种方法是<em class="lo">0()</em>和<em class="lo">1()</em>。是的，这个方法的名字告诉我们这个值将被用作数组中元素的初始值。而且，数组的形状是用整数参数指定的。例如，要创建一个4行2列的零填充数组，我们使用:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="aa54" class="lu jo hs lq b fi lv lw l lx ly">INDArray input = Nd4j.<em class="lo">zeros</em>(4, 2);</span></pre><p id="7809" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">创建的数组中<strong class="ir ht">的默认数据类型是<em class="lo"> float。</em>以类似的方式创建一个数组来存储我们已知的输出，我们可以使用:</strong></p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="4190" class="lu jo hs lq b fi lv lw l lx ly">INDArray knownOutput = Nd4j.<em class="lo">zeros</em>(4,1);</span></pre><p id="4382" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请注意，这是一个大小为<em class="lo">样本数量x特征数量</em>的矩阵。即使只有一个例子，它也需要这个形状。</p><p id="6088" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下一步，用如图1所示的值填充信息，表格在左边和右边。对于我们的例子，一个简单的方法就是将值插入数组。我们可以使用<em class="lo"> putScalar() </em>方法，该方法使用两个参数:第一个参数是一个包含新值坐标的整数数组，第二个参数是要存储到数组中的浮点值。我们的输入数据可以如下加载:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="3c2a" class="lu jo hs lq b fi lv lw l lx ly">input.putScalar(new int[]{0, 0}, 0);<br/>input.putScalar(new int[]{0, 1}, 0);<br/>input.putScalar(new int[]{1, 0}, 0);<br/>input.putScalar(new int[]{1, 1}, 1);<br/>input.putScalar(new int[]{2, 0}, 1);<br/>input.putScalar(new int[]{2, 1}, 0);<br/>input.putScalar(new int[]{3, 0}, 1);<br/>input.putScalar(new int[]{3, 1}, 1);</span></pre><p id="628f" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">同样，我们的已知输出值可以加载如下:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="ee92" class="lu jo hs lq b fi lv lw l lx ly">knownOutput.putScalar(new int[]{0}, 0);<br/>knownOutput.putScalar(new int[]{1}, 1);<br/>knownOutput.putScalar(new int[]{2}, 1);<br/>knownOutput.putScalar(new int[]{3}, 0);</span></pre><p id="86ac" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir ht"> Nd4j </strong>库提供了一组优秀的函数来处理数组。强烈推荐你看一下<strong class="ir ht"> Nd4j </strong>线性代数API <em class="lo">。</em></p><p id="a26e" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，我们需要将输入和已知输出放在一个<strong class="ir ht">数据集</strong>对象中。<strong class="ir ht">数据集</strong>对象是输入数据和已知输出(标签)的容器。<strong class="ir ht">数据集</strong>构造器接收如下两个参数:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="45f1" class="lu jo hs lq b fi lv lw l lx ly">DataSet dataSet = new DataSet(input, knownOutput);</span></pre><h1 id="cbf4" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">训练模型</h1><p id="5fcb" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated"><strong class="ir ht"> DeepLearning4J </strong>允许我们使用<a class="ae kq" rel="noopener" href="/javarevisited/design-patterns-101-factory-vs-builder-vs-fluent-builder-da2babf42113"> Fluent- <strong class="ir ht"> Builder模式</strong> </a>创建神经网络。让我向您展示实现图1中神经网络的代码，然后我们可以检查细节。</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="4e21" class="lu jo hs lq b fi lv lw l lx ly"><strong class="lq ht">MultiLayerConfiguration</strong> cfg = new <strong class="lq ht">NeuralNetConfiguration.Builder</strong>()<br/>  .weightInit(WeightInit.<em class="lo">UNIFORM</em>)<br/>  .list()<br/>  .layer(0,new <strong class="lq ht">DenseLayer</strong>.Builder()<br/>    .activation(<strong class="lq ht">Activation</strong>.<em class="lo">SIGMOID</em>)<br/>    .nIn(2)<br/>    .nOut(3)<br/>    .build())<br/>  .layer(1,new <strong class="lq ht">OutputLayer</strong>.Builder(LossFunctions.LossFunction.<em class="lo">MSE</em>)<br/>    .activation(Activation.<em class="lo">SIGMOID</em>)<br/>    .nIn(3)<br/>    .nOut(1)<br/>    .build())<br/>  .build();</span><span id="74ef" class="lu jo hs lq b fi lz lw l lx ly"><strong class="lq ht">MultiLayerNetwork</strong> network = new <strong class="lq ht">MultiLayerNetwork</strong>(cfg);</span></pre><p id="0776" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">两个基本类是<strong class="ir ht">多层配置</strong>和<strong class="ir ht">多层网络</strong>。关于神经网络、其层、输入、输出、激活函数等的所有细节都在<strong class="ir ht">多层配置</strong>对象中定义。然后，该对象用于使用<strong class="ir ht">多层网络</strong>创建网络。让我们回顾一下<strong class="ir ht">多层配置。</strong></p><p id="1fa6" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir ht">多层配置</strong>是这样的:(1)高级神经网络配置和(2)层配置。为了给神经网络创建一个<strong class="ir ht">多层配置</strong>，我们使用类<strong class="ir ht"> NeuralNetConfiguration。建造者</strong></p><p id="776e" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于高级神经网络配置:</p><ul class=""><li id="af0c" class="la lb hs ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated"><em class="lo">heavy nit()</em>定义权重初始化方案。在我们的示例中，我们将使用<a class="ae kq" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="noopener ugc nofollow" target="_blank"> Glorot和Bengio 2010 </a>中描述的均匀分布。</li><li id="0db0" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><em class="lo"> list()c </em>创建一个ListBuilder，它将存储我们每一层的配置。</li><li id="48cf" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><em class="lo"> layer() </em>新建一层；第一个参数是需要添加层的位置的索引；第二个参数是我们需要添加到网络中的图层类型。</li></ul><p id="569e" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一个<strong class="ir ht">密集层</strong>是一个深度连接的神经网络层，这意味着密集层中的每个神经元接收来自其前一层的所有神经元的输入。<strong class="ir ht">输出层</strong>是产生最终输出的最后一层神经元。除了我们将在示例中使用的密集图层和输出图层之外，还存在其他几种图层类型，其中包括GravesLSTM、卷积图层、RBM和嵌入图层。使用这些层，我们可以(以类似的方式)定义简单的神经网络、递归神经网络和卷积网络。注意，对于输出层，我们指定了用于评估输出的<strong class="ir ht">误差函数</strong>。这个误差函数也被称为损失函数。我们在示例<strong class="ir ht">中使用<strong class="ir ht">均方误差</strong>。</strong></p><p id="8968" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于层，我们配置如下:</p><ul class=""><li id="43b5" class="la lb hs ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated"><em class="lo"> activation() </em>定义神经元应用的<strong class="ir ht">激活函数</strong>。在我们的例子中，我们使用的是sigmoid函数。</li><li id="1b51" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><em class="lo"> nIn() </em>指定来自前一层的输入数量。在第一层中，它表示将从输入层获取的输入。</li><li id="4271" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><em class="lo"> nOut() </em>指定该层将发送给下一层的输出数量。对于输出层，它表示已知输出的数量</li></ul><p id="194f" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们正在创建一个具有两层的神经网络(我们只计算具有神经元的层)，一个隐藏层是一个密集层，一个输出层使用MSE进行误差计算。隐藏层有两个输入，生成三个输出。由于它是一个密集层，所有输入都与所有神经元相连，如图1所示。输出层有三个输入，只生成一个输出。两层中的神经元使用s形函数作为它们的激活函数。</p><p id="954c" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦我们创建了<strong class="ir ht">多层网络</strong>对象，我们调用init()方法来初始化这个对象。此外，我们可以将网络中所有层的<strong class="ir ht">学习速率</strong>配置为指定值。</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="199d" class="lu jo hs lq b fi lv lw l lx ly">network.init();<br/>network.setLearningRate(0.7);</span></pre><p id="f9ce" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以使用方法<em class="lo"> summary() </em>打印我们的网络配置，如下所示:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="905e" class="lu jo hs lq b fi lv lw l lx ly">System.<em class="lo">out</em>.println(network.summary());</span></pre><p id="49f4" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于我们的网络，该方法将打印如下内容:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="142c" class="lu jo hs lq b fi lv lw l lx ly">=================================================================<br/>LayerName (LayerType)   nIn,nOut   TotalParams   ParamsShape     <br/>=================================================================<br/>layer0 (DenseLayer)     2,3        9             W:{2,3}, b:{1,3}<br/>layer1 (OutputLayer)    3,1        4             W:{3,1}, b:{1,1}<br/>-----------------------------------------------------------------<br/>            Total Parameters:  13<br/>        Trainable Parameters:  13<br/>           Frozen Parameters:  0<br/>=================================================================</span></pre><p id="8eb4" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">与图1中的信息相同，但是是一个文本表。注意，我们有九个<strong class="ir ht">权重</strong>(每个神经元每个输入一个)和四个神经元，每个都有其<strong class="ir ht">偏差</strong>值。因此，我们的神经网络需要训练13个参数。</p><h1 id="30ee" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">训练模型</h1><p id="2aff" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我们的神经网络完成了！是时候训练它了。我们调用方法<em class="lo"> fit() </em>进行训练，如下所示:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="caa8" class="lu jo hs lq b fi lv lw l lx ly">for( int i=0; i &lt; 10000; i++ ) {<br/>    network.fit(dataSet);<br/>}</span></pre><p id="db0c" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">看看我的故事<strong class="ir ht">去神秘化的神经网络</strong>，它描述了当我们运行<em class="lo"> fit() </em>时会发生什么。我们的方法<em class="lo"> fit() </em>大致相当于那个故事中图13中的第10到24行。</p><p id="9bbe" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦网络训练完毕，我们就可以对其进行评估。</p><h1 id="ad92" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">测试模型</h1><p id="cadf" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">对于评估，<strong class="ir ht"> DeepLearning4J </strong>提供了类<strong class="ir ht">评估。</strong>方法<em class="lo"> eval() </em>将已知输出(标签)与模型生成的输出进行比较。并且，方法<em class="lo"> stats() </em>报告分类统计。代码如下:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="5ad2" class="lu jo hs lq b fi lv lw l lx ly">INDArray output = network.output(input);<br/>Evaluation eval = new Evaluation();<br/>eval.eval(knownOutput, output);</span><span id="a992" class="lu jo hs lq b fi lz lw l lx ly">System.<em class="lo">out</em>.println(eval.stats());</span></pre><p id="bcda" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该报告包括:</p><ul class=""><li id="bc6e" class="la lb hs ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated"><strong class="ir ht">混淆矩阵</strong>条目——在我们的例子中，预测了两个真阳性(TP)和两个真阴性(TN)。</li><li id="f0b4" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><strong class="ir ht">准确性</strong> —所有正确识别案例的度量。</li><li id="9a7f" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><strong class="ir ht">精度</strong> —从所有预测的阳性病例中正确识别出阳性病例的度量。</li><li id="164d" class="la lb hs ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated"><strong class="ir ht">F1-得分</strong> —精确度和召回率的调和平均值。</li></ul><p id="7119" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">打印结果如下:</p><pre class="ks kt ku kv fd lp lq lr ls aw lt bi"><span id="9fbd" class="lu jo hs lq b fi lv lw l lx ly">========================Evaluation Metrics========================<br/> # of classes:    2<br/> Accuracy:        1.0000<br/> Precision:       1.0000<br/> Recall:          1.0000<br/> F1 Score:        1.0000<br/>Precision, recall &amp; F1: reported for positive class (class 1 - "1") only</span><span id="faa3" class="lu jo hs lq b fi lz lw l lx ly">=========================Confusion Matrix=========================<br/> 0 1<br/>-----<br/> 2 0 | 0 = 0<br/> 0 2 | 1 = 1</span><span id="37b9" class="lu jo hs lq b fi lz lw l lx ly">Confusion matrix format: Actual (rowClass) predicted as (columnClass) N times<br/>==================================================================</span></pre><p id="9ca4" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们用大约50行代码为XOR运算符创建了一个完美的神经网络🙂。您可以从我的<a class="ae kq" href="https://github.com/javiergs/Medium/blob/main/NeuralNetwork/ExampleXORWithDL4J.java" rel="noopener ugc nofollow" target="_blank"> GitHub存储库</a>下载所述示例的源代码。这只是一个普通的例子。但是，它为从事更令人兴奋的项目打开了大门。例如，图像识别怎么样。</p><p id="bc44" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请注意，现在我们可以担心数据本身，而不是数据的存储或处理。此外，我们可以很容易地玩多个隐藏层或激活功能。此外，我们可以使用GPU来提高我们的训练过程的性能(需要一些配置，但它是可用的)。不过，那是后话了。</p></div><div class="ab cl ma mb go mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ha hb hc hd he"><p id="3efa" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">感谢阅读。请在下面留下您的反馈和评论。</p></div></div>    
</body>
</html>
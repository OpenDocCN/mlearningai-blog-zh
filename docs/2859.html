<html>
<head>
<title>K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k均值聚类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/k-means-clustering-71a875dbce3c?source=collection_archive---------4-----------------------#2022-06-19">https://medium.com/mlearning-ai/k-means-clustering-71a875dbce3c?source=collection_archive---------4-----------------------#2022-06-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="c996" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">将图像分割成簇。</h2></div><p id="a59b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">聚类算法是一种非监督学习算法，广泛用于在不使用目标标签的情况下执行探索性数据分析，或者当我们只想将数据集划分为几个聚类时。除了大多数数据科学任务中常见的典型数据分析场景，事实证明，聚类算法还用于计算机视觉等其他领域！在本文中，我们将探讨如何使用K-means进行图像分割！</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es js"><img src="../Images/152bf095223e218352da63053e7da71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i1vOB3ToEVG_eQ_aMQGMjw.jpeg"/></div></div><figcaption class="ke kf et er es kg kh bd b be z dx">Photo by <a class="ae ki" href="https://unsplash.com/@gatigato?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Gaëtan Othenin-Girard</a> on <a class="ae ki" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>.</figcaption></figure><h1 id="616d" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">K-均值聚类算法</h1><p id="539d" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">K-means聚类算法试图将数据集划分为<em class="lg"> k </em>个聚类，第<em class="lg"> i </em>个聚类由其质心<strong class="iy hi"> <em class="lg"> </em> </strong> <em class="lg"> ᵢ </em>定义。每个聚类的质心<strong class="iy hi"> <em class="lg"> </em> </strong> <em class="lg"> ᵢ </em>实质上是该聚类中所有<em class="lg"> nᵢ </em>点的平均值。</p><p id="afaf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，K-means算法尝试使用以下步骤为整个数据集找到最合适的K<em class="lg">质心值:</em></p><ol class=""><li id="e397" class="lh li hh iy b iz ja jc jd jf lj jj lk jn ll jr lm ln lo lp bi translated">从数据集中随机选择<em class="lg"> k </em>个数据点作为初始<em class="lg"> k </em>质心值。</li><li id="6324" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">对于数据集中的每个数据点，将其分配到最近的质心。距离用欧几里德距离来度量。</li><li id="ef59" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">重新计算<em class="lg"> k </em>质心的值，作为分配给它的所有<em class="lg"> nᵢ </em>数据点的平均值<em class="lg">。</em></li><li id="4135" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">重复步骤2-3，直到达到最大迭代次数或某个容差值，或者聚类分配收敛。</li></ol><p id="a82f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在步骤4完成之后，<em class="lg"> k </em> -means算法应该已经最小化了所有<em class="lg"> k </em>簇的惯性<em class="lg"> I </em>:</p><p id="43a5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lg">我</em>=σ<em class="lg">ᵢ</em>σ<em class="lg">ₗ</em>|<strong class="iy hi">x</strong><em class="lg">ᵢₗ</em><strong class="iy hi"/>-<strong class="iy hi"><em class="lg"/></strong><em class="lg">ᵢ</em>|，</p><p id="be6d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中第一求和索引<em class="lg"> i </em>遍历所有<em class="lg"> k </em>簇，第二求和索引<em class="lg"> l </em>遍历每个簇中的所有<em class="lg"> nᵢ </em>数据点。<strong class="iy hi"> x </strong> <em class="lg"> ᵢₗ </em>是第<em class="lg"> i </em>个聚类中的第<em class="lg"> l </em>个数据点，第<strong class="iy hi"> <em class="lg"> </em> </strong> <em class="lg"> ᵢ </em>是第<em class="lg"> i </em>个聚类的质心值。</p><h1 id="a257" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">用什么值的<em class="lv"> k </em>？</h1><p id="371b" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">K-means聚类算法的一个主要问题是，我们需要指定要使用的聚类数。对于极其简单的低维数据集，如下图所示，可以通过可视化数据点轻松猜测出<em class="lg"> k </em>的理想值。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lw"><img src="../Images/c054e8c067161ea995732afb04a630b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*bPL3gsAKt3mbNODXdwj4sw.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx">A simple 2D dataset with 4 clusters. Image created by the author.</figcaption></figure><p id="1827" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">不幸的是，现实生活中的大多数数据并没有形成漂亮的球形簇，维度的数量如此之多，以至于可视化数据是不可能的。</p><p id="a2d5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以使用的一种方法是根据集群的惯性<em class="lg"> I </em>来确定要使用的集群的理想数量。通常，当我们从2开始增加簇的数量时，惯性趋向于迅速减小。当我们接近要使用的簇的理想值时，<em class="lg"> I </em>的下降开始趋于平稳，在<em class="lg"> I </em> vs <em class="lg"> k </em>的图表中形成一个肘形。对于上面这个简单的2D数据集，我们发现惯性中的肘形出现在<em class="lg"> k </em> = 4。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lx"><img src="../Images/664bbf39fd4ae5a57ea324c4c16316b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*PXAwCmpFYL0yfzhAnWScoQ.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx">Elbow graph for the simple 2D dataset above, where the elbow occurs at k = 4. Image created by the author.</figcaption></figure><h1 id="d4ed" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">使用K-Means分割图像</h1><p id="ce18" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">现在我们知道了K-means聚类算法是如何工作的，我们将使用K-means算法来分割从Pexels 下载的图像<a class="ae ki" href="https://www.pexels.com/photo/woman-wearing-blue-and-white-dress-sitting-on-white-ceramic-batthub-1020057/" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es ly"><img src="../Images/bdf7d0b99043e8fdee5e344fb6cdb125.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*8O4eaJCGZiPWoPOUJZU8sQ.jpeg"/></div><figcaption class="ke kf et er es kg kh bd b be z dx">Photo by Ferdinand Studio: <a class="ae ki" href="https://www.pexels.com/photo/woman-wearing-blue-and-white-dress-sitting-on-white-ceramic-batthub-1020057/" rel="noopener ugc nofollow" target="_blank">https://www.pexels.com/photo/woman-wearing-blue-and-white-dress-sitting-on-white-ceramic-batthub-1020057/</a></figcaption></figure><p id="d5a2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">图像看起来有4种不同的颜色——白色的墙壁、家具和裙子、橙色的墙砖和地板、深蓝色的裙子和米色的肤色，但是让我们看看K-means算法是如何分割图像的！</p><h2 id="9a6b" class="lz kk hh bd kl ma mb mc kp md me mf kt jf mg mh kv jj mi mj kx jn mk ml kz mm bi translated">准备使用K-means进行聚类的图像</h2><p id="ea43" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">首先，我们使用<code class="du mn mo mp mq b">cv2</code>作为一个三维<code class="du mn mo mp mq b">numpy</code>数组来加载下载的图像。原始图像非常大——为了减少计算时间，我们将把图像调整到更小的尺寸。</p><p id="5b25" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此外，由于我们将使用<code class="du mn mo mp mq b">sklearn</code>来执行K-means聚类，我们需要将数组重新整形为可以被<code class="du mn mo mp mq b">sklearn</code> API接受的形状。</p><pre class="jt ju jv jw fd mr mq ms mt aw mu bi"><span id="3fae" class="lz kk hh mq b fi mv mw l mx my">import cv2<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans<br/>import tqdm</span><span id="7302" class="lz kk hh mq b fi mz mw l mx my"># Photo by Ferdinand Studio, downloaded from Pixels.<br/>file_path = "pexels-ferdinand-studio-1020057.jpg"</span><span id="72d9" class="lz kk hh mq b fi mz mw l mx my">img = cv2.imread(file_path)<br/>img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><span id="ae60" class="lz kk hh mq b fi mz mw l mx my">def resize(image, width = None, height = None, scale = 1):<br/>    # Resizes an RGB image.<br/>    if width is None or height is None:<br/>        width, height = image_width_height(image)<br/>        width = int(width * scale)<br/>        height = int(height * scale)</span><span id="6bab" class="lz kk hh mq b fi mz mw l mx my">    return cv2.resize(image, (width, height))</span><span id="056a" class="lz kk hh mq b fi mz mw l mx my">def image_width_height(image):<br/>    # Get an RGB image's width and height.<br/>    width = image.shape[1]<br/>    height = image.shape[0]<br/>    return width, height</span><span id="85b7" class="lz kk hh mq b fi mz mw l mx my">def image2X(image, width, height, channels = 3):<br/>    # Converts an RGB image to an array X for use with sklearn.<br/>    return image.reshape([width * height, channels])</span><span id="b0c5" class="lz kk hh mq b fi mz mw l mx my">def X2image(X, width, height, channels = 3):<br/>    # Converts an array X from sklearn to an RGB image.<br/>    return X.reshape([height, width, channels])</span><span id="a60d" class="lz kk hh mq b fi mz mw l mx my"># Resize the image to a 400 x 600 resolution.<br/>img = resize(img, width = 400, height = 600)<br/>width, height = image_width_height(img)</span><span id="5b78" class="lz kk hh mq b fi mz mw l mx my"># Convert the image to an array which can be input into<br/># sklearn's API.<br/>X = image2X(img, width, height, 3)<br/>print(img.shape, X.shape)</span><span id="e668" class="lz kk hh mq b fi mz mw l mx my">&gt;&gt;&gt; (600, 400, 3) (240000, 3)</span></pre><h2 id="0c50" class="lz kk hh bd kl ma mb mc kp md me mf kt jf mg mh kv jj mi mj kx jn mk ml kz mm bi translated">用肘法确定聚类数k</h2><p id="0c24" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">接下来，我们使用肘方法来确定用于分割图像的聚类的理想数量。</p><pre class="jt ju jv jw fd mr mq ms mt aw mu bi"><span id="1750" class="lz kk hh mq b fi mv mw l mx my"># Try 2 to 30 clusters.<br/>n_clusters = list(range(2, 30 + 1, 1))<br/>kmeans = []<br/>inertias = []</span><span id="07fd" class="lz kk hh mq b fi mz mw l mx my">for i in tqdm.trange(len(n_clusters)):<br/>    kmeans.append(KMeans(n_clusters = n_clusters[i], <br/>                         random_state = 42))<br/>    kmeans[-1].fit(X)<br/>    inertias.append(kmeans[-1].inertia_)</span><span id="0354" class="lz kk hh mq b fi mz mw l mx my">plt.figure(figsize = [20, 5])<br/>plt.subplot(1, 2, 1)<br/>plt.plot(n_clusters, inertias, "-o")<br/>plt.xlabel("$k$", fontsize = 14)<br/>plt.ylabel("Inertia", fontsize = 14)<br/>plt.grid(True)<br/>plt.subplot(1, 2, 2)<br/>plt.plot(n_clusters[:-1], np.diff(inertias), "-o")<br/>plt.xlabel("$k$", fontsize = 14)<br/>plt.ylabel("Change in inertia", fontsize = 14)<br/>plt.grid(True)<br/>plt.show()</span></pre><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es na"><img src="../Images/8fc3fb2f1f335ef4e87b528db0ddac76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ubqDsynBUZKb80SYQO1FA.png"/></div></div><figcaption class="ke kf et er es kg kh bd b be z dx">Left: cluster inertia I vs. number of clusters k, right: change in I with respect to k. After k = 6, the inertia I plateaus. Image created by the author.</figcaption></figure><p id="8975" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">左边的图表显示了当我们将簇的数量从2增加到30时，惯性<em class="lg"> I </em>如何变化，而右边的图表显示了惯性<em class="lg"> I </em>相对于<em class="lg"> k </em>的变化率:d <em class="lg"> I </em> /d <em class="lg"> k </em>。</p><p id="6b8e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">两个图都显示惯性<em class="lg"> I </em>在<em class="lg"> k </em> = 6之后达到平稳状态，这意味着下载的图像最好使用6个簇进行分割！</p><h2 id="8a94" class="lz kk hh bd kl ma mb mc kp md me mf kt jf mg mh kv jj mi mj kx jn mk ml kz mm bi translated">用6个簇分割下载的图像</h2><p id="2890" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">最后，我们使用6个聚类来分割原始图像，并获得图像中每个像素的聚类质心值。然后，我们将输出的<code class="du mn mo mp mq b">numpy</code>数组整形为一个3通道的RGB图像，以便可视化。</p><pre class="jt ju jv jw fd mr mq ms mt aw mu bi"><span id="ec7b" class="lz kk hh mq b fi mv mw l mx my"># Use 6 clusters in the K-means.<br/>kmeans = KMeans(n_clusters = 6, random_state = 42)<br/>kmeans.fit(X)</span><span id="6187" class="lz kk hh mq b fi mz mw l mx my"># Obtain the cluster centroids for each pixel in the image.<br/># These centroids are essentially our image segments.<br/>X_kmeans = kmeans.cluster_centers_[kmeans.predict(X)]<br/>X_kmeans = X_kmeans.astype("uint8")</span><span id="fe6e" class="lz kk hh mq b fi mz mw l mx my"># Convert the numpy array into an RGB image.<br/>img_kmeans = X2image(X_kmeans, width, height, 3)</span><span id="9479" class="lz kk hh mq b fi mz mw l mx my"># Visualize the original image with the segmented one.<br/>plt.figure(figsize = [10, 10])<br/>plt.subplot(1, 2, 1)<br/>plt.imshow(img)<br/>plt.subplot(1, 2, 2)<br/>plt.imshow(img_kmeans)<br/>plt.show()</span></pre><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es nb"><img src="../Images/287ea2dcb2cca08d756bb55e7123c021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*av6gHrJB3-nkY6FP0bcTjQ.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx">Left: original image, right: segmented image using 6 cluster centroids. Original image taken by <a class="ae ki" href="https://www.pexels.com/photo/woman-wearing-blue-and-white-dress-sitting-on-white-ceramic-batthub-1020057/" rel="noopener ugc nofollow" target="_blank">Ferdinand Studio on Pexels</a>, segmented image created by the author.</figcaption></figure><p id="9e61" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">K-means算法已经设法将原始图像分割成以下6个片段:</p><ol class=""><li id="76d0" class="lh li hh iy b iz ja jc jd jf lj jj lk jn ll jr lm ln lo lp bi translated">白色的墙壁、家具、衣服和某些皮肤。</li><li id="e7fe" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">橙色墙砖和地板。</li><li id="ea78" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">浅米色肤色。</li><li id="ac9b" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">米色肤色。</li><li id="2d53" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">家具和墙壁上的深米色肤色和阴影。</li><li id="4c13" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated">深蓝色的裙子和深色的阴影。</li></ol><h1 id="539b" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">结束语</h1><p id="fece" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">K-means是一种非常简单有效算法，用于将数据聚类成<em class="lg"> k </em>个不同的簇，而无需使用目标标签。这种强大的算法不仅可以用于典型的数据分析任务，还可以用于图像分割等其他任务。K-means算法的一个问题是确定要使用的聚类数<em class="lg"> k </em>，我们展示了如何使用肘方法来确定<em class="lg"> k的理想值。</em>然后，我们使用K-means算法将图像分割成几个片段，每个片段由该聚类中所有像素的平均值表示。</p><h1 id="7d81" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">参考</h1><ol class=""><li id="2a6c" class="lh li hh iy b iz lb jc lc jf nc jj nd jn ne jr lm ln lo lp bi translated">Dmytro Dzhulgakov，刘禹锡，塞巴斯蒂安·拉什卡(2022)。<em class="lg">用PyTorch和Scikit-Learn进行机器学习</em>，Packt出版有限公司。</li><li id="eee4" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated"><a class="ae ki" href="https://docs.opencv.org/4.x/d1/d5c/tutorial_py_kmeans_opencv.html" rel="noopener ugc nofollow" target="_blank">https://docs . opencv . org/4 . x/D1/d5c/tutorial _ py _ k means _ opencv . html</a></li><li id="f844" class="lh li hh iy b iz lq jc lr jf ls jj lt jn lu jr lm ln lo lp bi translated"><a class="ae ki" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . cluster . k means . html</a></li></ol><div class="nf ng ez fb nh ni"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw kc ni"/></div></div></a></div></div></div>    
</body>
</html>
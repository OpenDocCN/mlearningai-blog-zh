<html>
<head>
<title>Relaxing Hoeffding’s Inequality Using the KL Divergence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用KL散度放松Hoeffding不等式</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/machine-learning-comparing-hoeffdings-generalization-bound-c0443f39bf3f?source=collection_archive---------3-----------------------#2021-12-23">https://medium.com/mlearning-ai/machine-learning-comparing-hoeffdings-generalization-bound-c0443f39bf3f?source=collection_archive---------3-----------------------#2021-12-23</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><div class=""/><p id="e77c" class="pw-post-body-paragraph ii ij hl ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf he bi translated">在前一系列文章中，我们讨论了很多关于在机器学习环境中学习的可能性。具体来说，我们讨论了如何确保我们能够从一个假设类中选择一个<a class="ae jg" rel="noopener" href="/mlearning-ai/machine-learning-and-generalization-error-is-learning-possible-cff8721285e0">假设，并确保它能够很好地推广</a>。换句话说，我们如何衡量我们的假设在看不见的数据上的表现？我们发现我们可以调整<a class="ae jg" href="https://najamogeltoft.medium.com/machine-learning-the-intuition-of-hoeffdings-inequality-970a59c2b519" rel="noopener">赫夫丁的不等式</a>，这样它就可以在关于从一个假设类中找到最佳假设的设置中工作。在这篇文章中，我们不关心如何选择…</p></div></div>    
</body>
</html>
<html>
<head>
<title>NLP, Riches in the Niches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP，利基市场的财富</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/nlp-riches-concealed-in-the-niches-98cb73f7012e?source=collection_archive---------4-----------------------#2021-11-07">https://medium.com/mlearning-ai/nlp-riches-concealed-in-the-niches-98cb73f7012e?source=collection_archive---------4-----------------------#2021-11-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="aeef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">NLP模型训练实现了某种程度的泛化；然而，价值的金块隐藏在针对特定任务的简单且负担得起的微调中。下面是一个具体的例子。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/bd7a03fb680295e0b80301d50da4bf51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*gGMaTzsYTFHgQNjO-FAGhw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Hightail to the long tail. Few-shot learners like GPT-3 dominate our conversation. Can few-shot learners perform well in your use-case?</figcaption></figure><p id="a1ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于变压器的自然语言处理是，嗯，转换！人们对公开可用的NLP模型相当兴奋，这些模型是在大量文本数据上进行大规模训练的。更令人兴奋的是什么？进一步转移(微调)到广泛的下游任务的现实。</p><h2 id="15f4" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">判断的任务</h2><p id="7469" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">考虑在不同的常识和日常情况下对人们的判断进行推理的任务。基于语言的常识性道德推理模型德尔福(Delphi)已经证明它能够胜任这项任务，准确率高达92.1%<strong class="ig hi">。</strong></p><p id="9f92" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同时，对于自由形式的判断问题回答任务，GPT-3的零射击性能仅略好于吉斯的<strong class="ig hi"> 52.3% </strong>，GPT-3在广泛的提示工程后可达到的最佳性能是<strong class="ig hi"> 83.9% </strong>，比德尔福的微调版本低几个等级。</p><p id="a2c8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是Delphi执行的三个“判断”任务。</p><ol class=""><li id="1da2" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated"><strong class="ig hi">自由形式问答(QA) </strong>对基于伦理的情况做出简短的判断。下面的例子有一个问题和德尔福的回应。</li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ky"><img src="../Images/a56333ecb2e2d612e6b26ad877046ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*gBJi93EtX6D4q034Prz5fQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Free-form Question-Answer (image from paper)</figcaption></figure><p id="49db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。同意或不同意道德陈述的是/否问答</strong>。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kz"><img src="../Images/fa5ce0287ad070d87e467378b4bbe723.png" data-original-src="https://miro.medium.com/v2/resize:fit:286/format:webp/1*QAUoZeYPwxwycWPl-npdnQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Yes/No QA (image from paper)</figcaption></figure><p id="1f64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。比较两种道德状况的相对QA </strong>(尽管论文中有一个古怪的例子，但很有效)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es la"><img src="../Images/feeb8b570bb22762c14b833e4ffba8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*N8PgazCtRMrr7GJQDooJVA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Relative QA (is one action more or less morally acceptable that the other)</figcaption></figure><p id="a596" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae ko" href="https://delphi.allenai.org/" rel="noopener ugc nofollow" target="_blank">测试您自己对型号</a>的判断。你会被逗乐的！</p><h2 id="e023" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">德尔福通往令人瞠目结舌的准确性之路</h2><p id="ba7f" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">答案在于逐步微调模型。首先，<a class="ae ko" href="https://arxiv.org/abs/2103.13009" rel="noopener ugc nofollow" target="_blank"> UNICORN </a>(一个通用的常识推理模型)是在统一的<a class="ae ko" href="https://allenai.org/data/rainbow" rel="noopener ugc nofollow" target="_blank"> RAINBOW </a>基准上微调最大的<a class="ae ko" href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" rel="noopener ugc nofollow" target="_blank"> T5 </a>模型(文本到文本的转换变换器)T5–11B得出的。接下来，Delphi从UNICORN进行了微调，以利用其隐含的常识知识库。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lb"><img src="../Images/5ea324d626bd2a332cfcc7cf8f3de2af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jmEQfx4gRRtff2lyWt-P4A.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Progressive Fine-tuning</figcaption></figure><h2 id="8940" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">绘画洞察力</h2><p id="c5e4" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">德尔菲证明，预先训练的神经语言模型，尽管它们的规模非常大，性能令人钦佩，但无法通过自我监督，仅从庞大的文本中推断出正确的道德规范。Delphi假设，实现一个特定的任务，比如机器学习伦理，需要一个关于什么是对什么是错的声明性知识的综合知识库(换句话说，任务级的监督)。</p></div></div>    
</body>
</html>
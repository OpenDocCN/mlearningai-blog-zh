<html>
<head>
<title>Feature Scaling Made Simple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化特征缩放</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/feature-scaling-made-simple-12cb61bb790c?source=collection_archive---------0-----------------------#2021-06-18">https://medium.com/mlearning-ai/feature-scaling-made-simple-12cb61bb790c?source=collection_archive---------0-----------------------#2021-06-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/0f5e041c6c44497b67d3eab43e2af62f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_8LGJdiHskl1L8qy33htXQ.jpeg"/></div></figure><p id="f093" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">每个数值都由单位和大小组成。以年龄为例。如果我的年龄是24，那就意味着星等实际上是24，单位是年。要理解的主要事情是，当我们有许多特征时，每个特征将由不同的单位和量值来计算。</p><h1 id="018b" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">特征缩放？🤔</h1><p id="a563" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">特征缩放是特征工程的一部分。它允许我们把我们所有的特征放在同一个尺度上。</p><h2 id="9688" class="km jk hh bd jl kn ko kp jp kq kr ks jt iw kt ku jx ja kv kw kb je kx ky kf kz bi translated">但是..为什么？</h2><p id="976f" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">对于一些机器学习算法来说，数据预处理阶段的一个重要部分是我们尝试将特征缩小到一定的比例。以便避免一些特征被其他特征支配，使得机器学习模型只考虑支配特征。</p><p id="216d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然而，这并不意味着我们需要对所有的机器学习模型应用特征缩放，只是对其中的一些模型有必要，我们将在本文的后面看到这一点。</p><h1 id="e61b" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">怎么做特征缩放？</h1><p id="2498" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">实际上有许多技术，最常用的两种缩放技术是<strong class="in hi">规范化</strong>和<strong class="in hi">标准化。</strong></p><h2 id="b7bb" class="km jk hh bd jl kn ko kp jp kq kr ks jt iw kt ku jx ja kv kw kb je kx ky kf kz bi translated">有什么区别？</h2><ul class=""><li id="6d55" class="la lb hh in b io kh is ki iw lc ja ld je le ji lf lg lh li bi translated"><strong class="in hi"> <em class="lj">归一化</em> </strong> <em class="lj">(也称为最小-最大缩放器)</em>:它只是使用下面的公式将特性的所有值缩小到0-1之间</li></ul><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/f314d57c524285d6fe7ffb4143060d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Vsz-1VpYo-CckwMv-6KkFQ.png"/></div></figure><p id="c30a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">基本上，它用最小值减去每个值，然后除以最大值和最小值之差。由于分子和分母都是正的，并且分子总是小于或等于分母，这意味着该特性的所有值都在0-1之间。</p><p id="b0d8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下面是使用python ⬇️的实现</p><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div><figcaption class="lr ls et er es lt lu bd b be z dx"><strong class="ak"><em class="lv">Normalization</em></strong> in python</figcaption></figure></div><div class="ab cl lw lx go ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ha hb hc hd he"><p id="1f6e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">标准化</strong> <em class="lj">(也称为Z值标准化或标准缩放器)</em>:根据标准正态分布缩小特征；其中平均值通常为0，标准偏差为1。这将使用下面的公式将特性的所有值放在-3和3之间</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/58b79476dee8f8c085bff588fdc5a15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*W8hJsCQumBS4o96Msz0UJQ.png"/></div></figure><p id="4aff" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，它用特征中所有值的平均值减去特征中的每个值，然后除以标准差，标准差就是方差的平方根。</p><p id="312f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下面是使用python ⬇️的实现</p><figure class="ll lm ln lo fd ii"><div class="bz dy l di"><div class="lp lq l"/></div><figcaption class="lr ls et er es lt lu bd b be z dx"><strong class="ak">Standardization</strong> in python</figcaption></figure><h1 id="3680" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">何时使用特征缩放？</h1><p id="4c2a" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">当我们使用任何涉及欧几里德距离的机器学习算法或涉及梯度下降的深度学习算法时。</p><p id="81d7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">例子有:KNN，K均值聚类，所有深度学习算法，如人工神经网络(ANN)和卷积神经网络(CNN)。</p><h2 id="de6e" class="km jk hh bd jl kn ko kp jp kq kr ks jt iw kt ku jx ja kv kw kb je kx ky kf kz bi translated">什么时候不重要？</h2><p id="7ee0" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">在决策树、随机森林、XGBoost等算法中。因为，例如，在决策树中，我们只需创建一个决策树，并根据特征对其进行划分(这不会影响特征值的高低)，无论如何，它的行为都是一样的。</p><h1 id="ee2c" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated"><strong class="ak">规范化</strong> Vs. <strong class="ak">标准化，</strong>各什么时候用？</h1><p id="2cb3" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">在大多数需要缩放的机器学习算法中，标准化比规范化表现得更好(它会一直做这项工作)，因此我的建议是去标准化。</p><p id="4137" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">另一方面，当我们在大多数特征中具有正态分布时，推荐使用归一化(这将非常好)</p><p id="7fd8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">此外，在深度学习技术上，如ANN和CNN，我们使用归一化，因为我们需要缩小0-1之间的值。例如，在图像中，像素值在0-255之间，所以当我们缩小它时，它应该在0-1之间。类似地，在使用Tenserflow和Keras的人工神经网络中，他们将接受0-1之间的输入，这将有助于他们快速学习权重。</p></div><div class="ab cl lw lx go ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ha hb hc hd he"><h2 id="4051" class="km jk hh bd jl kn ko kp jp kq kr ks jt iw kt ku jx ja kv kw kb je kx ky kf kz bi translated">最后一个音符</h2><blockquote class="md me mf"><p id="83a1" class="il im lj in b io ip iq ir is it iu iv mg ix iy iz mh jb jc jd mi jf jg jh ji ha bi translated">当我们应用特征缩放时，我们应该总是将它分别应用于训练和测试集<strong class="in hi"/>。非常小心，不要一次在整个数据集上安装缩放器，因为这将丢失标准化情况下的平均值和标准偏差值，以及归一化情况下的最小值和最大值。那么在trining集合中进行拟合和变换，然后在测试集合中进行变换，为什么呢？以避免数据泄露。</p></blockquote><p id="7e13" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">说了这么多，我希望你喜欢我的博客，下次再来well✌🏻</p></div></div>    
</body>
</html>
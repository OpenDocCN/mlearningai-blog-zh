<html>
<head>
<title>7 Best Techniques To Improve The Accuracy of CNN W/O Overfitting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高CNN W/O过拟合精度的7种最佳技术</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/7-best-techniques-to-improve-the-accuracy-of-cnn-w-o-overfitting-6db06467182f?source=collection_archive---------0-----------------------#2021-05-27">https://medium.com/mlearning-ai/7-best-techniques-to-improve-the-accuracy-of-cnn-w-o-overfitting-6db06467182f?source=collection_archive---------0-----------------------#2021-05-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="e875" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">数据集— CIFAR 10</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/20ed6029c94cf02d933917e17d28e725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AD57vB0pG3pR40bL1WQ_9A.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://burst.shopify.com/@matthew_henry?utm_campaign=photo_credit&amp;utm_content=Picture+of+Frustrated+Man+On+Computer+-+Free+Stock+Photo&amp;utm_medium=referral&amp;utm_source=credit" rel="noopener ugc nofollow" target="_blank">Matthew Henry</a> from <a class="ae jm" href="https://burst.shopify.com/walls?utm_campaign=photo_credit&amp;utm_content=Picture+of+Frustrated+Man+On+Computer+-+Free+Stock+Photo&amp;utm_medium=referral&amp;utm_source=credit" rel="noopener ugc nofollow" target="_blank">Burst</a></figcaption></figure><p id="f343" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">当我们开发<strong class="jp hi">卷积神经网络</strong> (CNN)来对图像进行分类时，经常会发现当我们试图提高准确性时，模型开始过度拟合。非常令人沮丧，因此我列出了以下技术，这些技术将提高模型性能，而不会使模型过度适应训练数据。</p><ol class=""><li id="9bb3" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated"><strong class="jp hi">数据归一化<br/> </strong>我们通过减去平均值并除以每个通道上像素的标准偏差来归一化图像张量。标准化数据可以防止任何一个通道的像素值对损失和梯度产生不成比例的影响。<a class="ae jm" rel="noopener" href="/@ml_kid/what-is-transform-and-transform-normalize-lesson-4-neural-networks-in-pytorch-ca97842336bd">了解更多信息</a></li><li id="d7a4" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">数据扩充</strong> <br/>我们在从训练数据集中加载图像时应用了随机变换。具体来说，我们将每个图像填充4个像素，然后随机裁剪大小为32 x 32像素的图像，然后以50%的概率水平翻转图像。<a class="ae jm" href="https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/" rel="noopener ugc nofollow" target="_blank">了解更多信息</a></li><li id="ab5e" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">批量归一化<br/> </strong>在每个卷积层之后，我们增加了一个批量归一化层，对前一层的输出进行归一化。这有点类似于数据归一化，只是它应用于图层的输出，而平均值和标准差是学习参数。<a class="ae jm" href="https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd" rel="noopener" target="_blank">了解更多信息</a></li><li id="4da3" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">学习率调度<br/> </strong>我们不使用固定的学习率，而是使用一个学习率调度器，它会在每一批训练后改变学习率。在训练中有许多改变学习率的策略，我们使用了“一个周期学习率策略”。<a class="ae jm" href="https://sgugger.github.io/the-1cycle-policy.html" rel="noopener ugc nofollow" target="_blank">了解更多信息</a></li><li id="f5ce" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">权重衰减</strong>:我们在优化器中加入了权重衰减，这是另一种正则化技术，通过在损失函数中加入一个附加项来防止权重变得过大。<a class="ae jm" href="https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab" rel="noopener" target="_blank">了解更多信息</a></li><li id="c468" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">渐变剪辑</strong>:我们还增加了渐变剪辑pint，它有助于将渐变的值限制在一个小的范围内，以防止在训练过程中由于较大的渐变值而导致模型参数发生不希望的变化。<a class="ae jm" href="https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48#63e0" rel="noopener" target="_blank">了解更多</a></li><li id="1cdf" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi"> Adam optimizer </strong>:我们使用了Adam optimizer，而不是SGD(随机梯度下降)，它使用了动量和自适应学习率等技术来加快训练速度。有许多其他的优化器可供选择和试验。<a class="ae jm" href="https://ruder.io/optimizing-gradient-descent/index.html" rel="noopener ugc nofollow" target="_blank">了解更多信息</a></li></ol><p id="05e5" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">没有实现上述技术的CNN模型给出大约75%的准确度。你可以在这个<a class="ae jm" rel="noopener" href="/mlearning-ai/training-convolutional-neural-network-convnet-cnn-on-gpu-from-scratch-439e9fdc13a5">博客</a>上了解更多关于这款车型的信息。现在，我通过实现所有7种技术构建了一个CNN，并将模型精度提高到90%，而没有在训练集上过度拟合模型。</p><h1 id="bf2a" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">关于数据集</h1><p id="2a2f" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">CIFAR-10数据集(加拿大高级研究所)是一个图像集合，通常用于训练机器学习和计算机视觉算法。这是机器学习研究中使用最广泛的数据集之一。CIFAR-10数据集包含10个不同类别的60，000幅32x32彩色图像。这10个不同的类别代表飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。每个类有6000张图片。</p><h1 id="8237" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">目录</h1><ol class=""><li id="1416" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated"><a class="ae jm" href="#cd69" rel="noopener ugc nofollow">简介</a></li><li id="7d01" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#86f0" rel="noopener ugc nofollow">数据预处理</a> <br/> 2.1 <a class="ae jm" href="#c2ac" rel="noopener ugc nofollow">加载所需库</a></li><li id="1a6b" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#fe8c" rel="noopener ugc nofollow">应用<strong class="jp hi">数据规范化</strong>和<strong class="jp hi">数据扩充</strong></a><strong class="jp hi"><br/></strong>3.1<strong class="jp hi"/><a class="ae jm" href="#b0ce" rel="noopener ugc nofollow">构建数据转换</a> <br/> 3.2 <a class="ae jm" href="#34a5" rel="noopener ugc nofollow">将转换应用到数据集</a></li><li id="3d8b" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#a200" rel="noopener ugc nofollow">访问少量样本图像</a></li><li id="3471" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#8442" rel="noopener ugc nofollow">访问GPU </a></li><li id="8b0b" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#dbda" rel="noopener ugc nofollow">模型配置</a> <br/> 4.1 <a class="ae jm" href="#d3b6" rel="noopener ugc nofollow">设置精度函数和图像分类基类</a> <br/> 4.2 <a class="ae jm" href="#128b" rel="noopener ugc nofollow">实现<strong class="jp hi">批量归一化和漏失</strong> </a> <br/> 4.3 <a class="ae jm" href="#bd40" rel="noopener ugc nofollow">实现<strong class="jp hi">权重衰减</strong>、<strong class="jp hi">渐变裁剪</strong>、<strong class="jp hi"> Adam优化器</strong> </a> <br/> 4.4 <a class="ae jm" href="#bc8f" rel="noopener ugc nofollow">将模型移动到<strong class="jp hi"> GPU </strong> </a></li><li id="b724" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#83bb" rel="noopener ugc nofollow">训练模型&amp;结果分析</a> <br/> 6.1 <a class="ae jm" href="#d001" rel="noopener ugc nofollow">训练前设置参数</a> <br/> 6.2 <a class="ae jm" href="#2b8a" rel="noopener ugc nofollow">运行模型<strong class="jp hi"> 8个历元</strong> </a> <br/> 6.3 <a class="ae jm" href="#d1de" rel="noopener ugc nofollow">精度vs历元数</a> <br/> 6.4 <a class="ae jm" href="#5352" rel="noopener ugc nofollow">损失vs历元</a> <br/> 6.5 <a class="ae jm" href="#477d" rel="noopener ugc nofollow">学习率与批号</a></li><li id="a1b5" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#63fc" rel="noopener ugc nofollow">对测试数据集运行预测</a></li><li id="5ef1" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#4e58" rel="noopener ugc nofollow">总结</a></li><li id="ebba" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#830b" rel="noopener ugc nofollow">未来工作</a></li><li id="9550" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#930c" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="cd69" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№1:简介</h1><p id="c6b5" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">CIFAR-10数据集包含10个不同类别的60，000幅32x32彩色图像。CIFAR-10是一组图像，可用于教FFNN如何识别物体。由于CIFAR-10中的图像是低分辨率的(32x32)，这个数据集可以让研究人员快速尝试不同的算法，看看什么有效。</p><p id="c4fa" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">CIFAR 10数据集下的类别列表—</p><ol class=""><li id="d89f" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">✈️飞机公司</li><li id="f8a9" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">汽车🚗</li><li id="c71d" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">鸟🐦</li><li id="f827" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">猫😺</li><li id="2229" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">鹿🐆</li><li id="7a76" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">狗🐶</li><li id="8cbc" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">青蛙🐸</li><li id="3103" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">马🐴</li><li id="4082" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">船🚢</li><li id="b8fd" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">卡车🚚</li></ol><h1 id="86f0" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№2:数据预处理</h1><h1 id="c2ac" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">加载所需的库</h1><p id="3d61" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">因为我们用PyTorch来构建神经网络。我一次性导入了所有相关的库。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h1 id="fe8c" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№3:应用<strong class="ak">数据归一化</strong>和<strong class="ak">数据增强</strong></h1><p id="0aca" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">使用in transforms函数加载数据集时，会实现数据规范化和数据扩充。</p><h2 id="b0ce" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">构建数据转换</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h2 id="34a5" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">将变换应用于数据集</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="f05e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们访问培训和验证集</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="5add" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在我构建了2个数据加载器用于测试和验证。为此，我使用了DataLoader方法</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h1 id="a200" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№4:访问少量样本图像</h1><p id="14ec" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">在我们开始构建模型之前，让我们也访问一下样本图像。请注意，数据加载器中的数据是标准化的，显示这些数据没有任何意义。因此，开发了一个demoralize函数来还原这些更改，以便可以访问原始图像。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mn"><img src="../Images/e1ead270a530d1a3234c33b2c1f2580b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*P0gQmc-4poQ1U54JU7oEsg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Present in training dataset</figcaption></figure><h1 id="8442" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№5:访问GPU</h1><p id="1a52" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">如果您的执行平台连接到NVIDIA制造的图形处理器，您可以使用图形处理器(GPU)来更快地训练您的模型。按照以下说明在您选择的平台上使用GPU:</p><ul class=""><li id="9dbb" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki mo kp kq kr bi translated">Google Colab:使用菜单选项“运行时&gt;更改运行时类型”，并从“硬件加速器”下拉列表中选择“GPU”。</li><li id="c39c" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mo kp kq kr bi translated">Kaggle:在侧边栏的“设置”部分，从“加速器”下拉列表中选择“GPU”。使用右上角的按钮打开侧边栏。</li><li id="0b49" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mo kp kq kr bi translated">Binder:运行Binder的笔记本不能使用GPU，因为支持Binder的机器没有连接到任何GPU。</li><li id="d45a" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mo kp kq kr bi translated">Linux:如果你的笔记本电脑/台式机有NVIDIA GPU(显卡)，确保你已经安装了NVIDIA CUDA驱动程序。</li><li id="4037" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mo kp kq kr bi translated">Windows:如果你的笔记本电脑/台式机有NVIDIA GPU(显卡)，请确保你已经安装了NVIDIA CUDA驱动程序。macOS: macOS与NVIDIA GPUs不兼容</li><li id="ec9e" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki mo kp kq kr bi translated">如果您无法访问GPU或者不确定它是什么，不要担心，您可以在没有GPU的情况下执行本教程中的所有代码。</li></ul><p id="9cdb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们从安装和导入所需的库开始。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h1 id="dbda" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№6:型号配置</h1><h2 id="d3b6" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">设置精度函数和图像分类基类</h2><p id="64ac" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">准确度函数通过将模型输出与标签进行比较来提供模型的准确度。在ImageClassificationBase中，我们有计算“损失”的函数和计算每个时期的组合损失和精确度的辅助函数。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h2 id="128b" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">实施批量标准化和退出</h2><p id="87b6" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我们使用<code class="du mp mq mr ms b">nn.sequential</code>来链接神经网络的层。我在每一层的末尾实现了批量规范化。还要观察退学20%的执行情况。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h2 id="bd40" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">实现权重衰减、渐变裁剪、Adam优化器</h2><p id="83ec" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我稍微修改了一下拟合函数，以接受权重衰减和渐变剪切参数。请注意，<code class="du mp mq mr ms b">fit</code>函数是通用函数，可以像在其他神经网络中一样使用</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h2 id="bc8f" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">将模型移动到<strong class="ak"> GPU </strong></h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="3adb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在我们训练之前，让我们检查一下模特的表现</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="961d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我观察到大约10%的准确度。因为我们有10个类，所以预测正确的几率是1/10。因此，该模型似乎是随机猜测。</p><h1 id="83bb" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№7:训练模型和结果分析</h1><h2 id="d001" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">训练前设置参数</h2><p id="75fa" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">在开始训练之前，我传递以下参数。尝试用不同参数进行试验。最初，您可以从较大的值开始，当您的模型开始达到更高的精度值时，切换到较小的值。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><h2 id="2b8a" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">运行模型8个时期</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="8dea" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果你观察上面的结果。我们仅用不到3分钟的时间训练模型，就达到了大约90% 的<strong class="jp hi">准确率。这太棒了。</strong></p><h2 id="d1de" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">精确度与纪元数量</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mt"><img src="../Images/a5b89517fa47762e6cc22798ff838a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*HLxmx3E_uuKddgduaSy-OQ.png"/></div></figure><h2 id="5352" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">损失与时代</h2><p id="ca32" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我们还可以绘制训练和验证损失图来研究趋势。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mu"><img src="../Images/75a1a3b0450e131a41f4f58e40e229ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*_2viG53rE2exCo9U9TJ7EQ.png"/></div></figure><p id="e454" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">从趋势来看，我们的模型显然还没有过度适应训练数据。</p><h2 id="477d" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">批次号的学习率</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mv"><img src="../Images/228ef4e8398b21fcf3eb944fbcbbb075.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*VZdtVi8lmr0bqqLYWD38nw.png"/></div></figure><p id="62bf" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">正如预期的那样，学习率从一个低值开始，并在30%的迭代中逐渐增加到最大值<code class="du mp mq mr ms b">0.01</code>，然后逐渐减少到一个非常小的值。</p><h1 id="63fc" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№8:使用单个图像进行测试</h1><p id="a15f" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">虽然到目前为止我们一直在跟踪模型的整体准确性，但在一些样本图像上查看模型的结果也是一个好主意。让我们用10000张图像的预定义测试数据集中的一些图像来测试我们的模型。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="3bf3" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">模特似乎表现得很好。有些图像很难被人眼识别，但该模型似乎在分类这些图像方面做得很好。</p><h1 id="4e58" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№9:摘要</h1><p id="833c" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">下面是本文的简要总结，以及我们在应用所有7种技术来提高模型性能时遵循的一步一步的过程。</p><ol class=""><li id="d100" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">我们简单了解了所有的7种技术<br/> - <strong class="jp hi">数据归一化<br/>-</strong>-<strong class="jp hi">数据扩充<br/> </strong> - <strong class="jp hi">批量归一化<br/> </strong> - <strong class="jp hi">学习速率调度<br/> </strong> - <strong class="jp hi">权重衰减<br/>-</strong>-<strong class="jp hi">梯度裁剪<br/> </strong> - <strong class="jp hi"> Adam优化器</strong></li><li id="9e36" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们学会了构建转换，并在其中实现了<strong class="jp hi">数据规范化</strong>和<strong class="jp hi">数据扩充</strong>。</li><li id="a058" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们学习了访问GPU以及如何在GPU上加载训练和验证数据集。</li><li id="d93c" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">在构建神经网络时，我们实现了<strong class="jp hi">批量归一化</strong>和<strong class="jp hi">剔除</strong>。</li><li id="ed06" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们在训练模型的同时实现了<strong class="jp hi">权重衰减</strong>、<strong class="jp hi">梯度裁剪</strong>和<strong class="jp hi"> adam </strong>优化器。</li><li id="c2ce" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">经过3分钟的训练，我们达到了90%的准确率。</li><li id="ad0c" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们通过在几个测试样本上运行来随机检查模型性能</li></ol><h1 id="830b" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№10:未来的工作</h1><ol class=""><li id="1347" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated">尝试逐个删除批处理规范化、数据扩充和遗漏，以研究它们对过度拟合的影响。</li><li id="b762" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">使用TensorFlow建立模型，并尝试实现所有这些技术。</li><li id="4592" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们的模型在3分钟内训练出超过90%的准确率！尝试使用数据增强、网络架构&amp;超参数来实现以下结果:<br/>-10分钟内达到94%的准确率(简单)<br/>-2分钟内达到90%的准确率(中等)<br/>-5分钟内达到94%的准确率(困难)</li></ol><h1 id="930c" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№11:参考</h1><ol class=""><li id="2b62" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated">您可以通过此链接访问并执行完整的笔记本—<a class="ae jm" href="https://jovian.ai/hargurjeet/cfar-10-image-classifier" rel="noopener ugc nofollow" target="_blank">https://jovian.ai/hargurjeet/cfar-10-dataset-6e9d9</a></li><li id="7b86" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/</a></li><li id="99af" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans" rel="noopener ugc nofollow" target="_blank">https://jovian . ai/learn/deep-learning-with-py torch-zero-to-gans</a></li></ol><p id="e6c7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">至此，我们完成了所有3篇文章的系列，最初我们开始构建ANN，然后转向CNN以获得更好的性能，最后应用一些技术来进一步增强模型性能。你可以在这里访问我以前的博客——<a class="ae jm" rel="noopener" href="/mlearning-ai/training-feed-forward-neural-network-ffnn-on-gpu-beginners-guide-2d04254deca9">博客1 </a>、<a class="ae jm" rel="noopener" href="/mlearning-ai/training-convolutional-neural-network-convnet-cnn-on-gpu-from-scratch-439e9fdc13a5">博客2 </a></p><p id="908c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我真的希望你们能从这篇文章中学到一些东西。随意👏如果你喜欢你所学的。如果有什么需要我帮忙的，请告诉我。</p><h2 id="d9ca" class="lz ky hh bd kz ma mb mc ld md me mf lh jw mg mh lj ka mi mj ll ke mk ml ln mm bi translated">感谢阅读这篇文章。快乐学习😃</h2></div></div>    
</body>
</html>
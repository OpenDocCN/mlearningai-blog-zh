<html>
<head>
<title>Difference Between the Batch size and Epoch in Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络中批量大小与历元的差异</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/difference-between-the-batch-size-and-epoch-in-neural-network-2d2cb2a16734?source=collection_archive---------0-----------------------#2021-04-08">https://medium.com/mlearning-ai/difference-between-the-batch-size-and-epoch-in-neural-network-2d2cb2a16734?source=collection_archive---------0-----------------------#2021-04-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6d26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di"> H </span>你是否曾经对神经网络中批量和时期的概念化感到困惑？相信我，大多数发烧友往往吃了很多苦才知道这些想法的区别，我甚至都没有意识到。</p><p id="d97a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文将讨论批量大小和时期的概念，并通过可视化表示突出重点。</p><p id="4afe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">读完这篇文章你会知道什么？</strong></p><ul class=""><li id="bbc8" class="jl jm hh ig b ih ii il im ip jn it jo ix jp jb jq jr js jt bi translated">什么是批？</li><li id="7a94" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">什么是纪元？</li><li id="1058" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">batch和epoch有什么区别？</li></ul><h1 id="1ce3" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">什么是批量？</strong></h1><p id="1169" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">批量大小是通常一次通过神经网络的样本数。批量通常被称为小批量。</p><blockquote class="lc"><p id="0099" class="ld le hh bd lf lg lh li lj lk ll jb dx translated">理解有困难？放心吧！让我们看看下面的图片</p></blockquote><div class="lm ln lo lp lq ab cb"><figure class="lr ls lt lu lv lw lx paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/3f664551f92a28eb91c04ed9b29fc355.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*1qtLmXjBgEGvgiL5VM0CcQ.jpeg"/></div></figure><figure class="lr ls me lu lv lw lx paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/0be633a373bfc63c26a922821b5251c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*Mk0ilg9z9HxnraQ3dr5YdQ.png"/></div><figcaption class="mf mg et er es mh mi bd b be z dx mj di mk ml"><strong class="bd kb">Figure: Classification process of neural network</strong></figcaption></figure></div><blockquote class="lc"><p id="075e" class="ld le hh bd lf lg mm mn mo mp mq jb dx translated">你在上面的图像中观察到了什么？一些图像被输入到神经网络中，最终，它会给你一个预测，不是吗？</p></blockquote><p id="9412" class="pw-post-body-paragraph ie if hh ig b ih mr ij ik il ms in io ip mt ir is it mu iv iw ix mv iz ja jb ha bi translated">假设我们有1000万个数据集(图像)，在这种情况下，如果在没有定义批量大小的情况下训练模型，将需要大量的计算时间，这将不是一种有效的方法。这就是为什么出现了批量大小的概念，即您不必单独训练每个图像，但是您可以通过批量大小来训练它，以便将模型作为一个组来训练。例如，如果您将批次大小定义为100，则整个训练数据集中的100个样本图像将作为一组一起训练。</p><p id="9f75" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="mw">“批量越大，训练时每个历元的模型越快。”</em>T9】</strong></p><p id="9ce2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以从训练数据集生成一个或多个批次。批次梯度下降是一种学习算法，它使用所有训练样本来生成单个批次。当批量为一个样本时，学习算法称为随机梯度下降。当批量大于一个样本且小于训练数据集的大小时，学习算法被称为小批量梯度下降。</p><ul class=""><li id="ca27" class="jl jm hh ig b ih ii il im ip jn it jo ix jp jb jq jr js jt bi translated"><strong class="ig hi">批量梯度下降</strong>。批量大小=训练集的大小</li><li id="4d23" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated"><strong class="ig hi">随机梯度下降</strong>。批量= 1</li><li id="060f" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated"><strong class="ig hi">小批量梯度下降</strong>。1 &lt;批量大小&lt;训练集的大小</li></ul><p id="bf04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">小批量梯度下降最受欢迎的批量是32、64和128个样品。</p><h1 id="4efa" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">什么是纪元？</h1><p id="c0aa" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">批量大小和时期不相似。两者都有不同的工作方法。一个时期是机器学习中使用的一个术语，指的是机器学习算法在整个训练数据集上通过的次数。如果批量大小是整个训练数据集，则历元数等于迭代数。</p><p id="cfd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以沿着x轴<strong class="ig hi">的历元</strong>作为时间并且模型的误差或能力在y轴上的线图是典型的。这些图也称为学习曲线，有助于确定模型是否具有<strong class="ig hi">过度学习、</strong> <strong class="ig hi">欠学习、</strong>或<strong class="ig hi">充分拟合训练数据集的</strong>。</p><h1 id="d190" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">批量和历元有什么区别？</strong></h1><ul class=""><li id="e99f" class="jl jm hh ig b ih kx il ky ip mx it my ix mz jb jq jr js jt bi translated">批量大小:批量大小是在更新模型之前处理的样本数量。历元数代表通过<strong class="ig hi">训练数据集的总次数。</strong></li><li id="fba5" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">Epoch:表示<strong class="ig hi">机器学习</strong>算法已经完成的整个训练数据集的遍数</li></ul><h1 id="4c95" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">结论</strong></h1><p id="4a67" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">最后，本文简要讨论了批量大小和时期。这两个概念没有被很多人很好地理解；然而，希望这篇文章对那些已经开始从事深度学习的人有用。</p></div></div>    
</body>
</html>
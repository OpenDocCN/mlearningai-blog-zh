<html>
<head>
<title>Exploring the Amazon Bestselling books using Web Scraping: Python, Beautiful Soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用网络抓取探索亚马逊畅销书:Python，美丽的汤</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/exploring-the-amazon-bestselling-books-using-web-scraping-python-beautiful-soup-3d42d029f184?source=collection_archive---------2-----------------------#2022-05-18">https://medium.com/mlearning-ai/exploring-the-amazon-bestselling-books-using-web-scraping-python-beautiful-soup-3d42d029f184?source=collection_archive---------2-----------------------#2022-05-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="55a9" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="6f42" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">紧跟Instagram潮流，这里给你一个观点。</p><p id="92ab" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">PoV:您希望收集亚马逊上的畅销书信息。你去亚马逊网站，搜索畅销书，然后浏览网页，它显示了畅销书的矩阵。现在，你求助于提取信息的繁琐手段，即复制粘贴。选择第一本书，慢慢打开每个链接，将书的详细信息复制粘贴到Excel中。从单个链接复制粘贴数据似乎没问题；从2到3个链接看起来还不错，但是你很快就会想，“有更简单的选择吗？”“如何从可数的链接中提取信息？”</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/f913d36d7c01fd60e51a37c81a417700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8IU5iiKmqHJaZvmkBG8VjA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx">Image source: Canva</figcaption></figure><h1 id="7ee1" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">什么是网页抓取？</h1><p id="a5fe" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><em class="kv">网页抓取</em>可以定义为从网站和网页中加载、抓取、提取或筛选数据的自动过程。它使开发人员能够根据自己的需求获取、构建和分析数据。Web抓取也可以称为Web数据抽取或Web收获，在数据挖掘中起着至关重要的作用。</p><p id="6460" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">此外，当我们探索用于数据收集的各种网页时，我们观察到因特网上可用的大部分数据属于非结构化数据，这可以在HTML格式中找到。然而，为了从数据中获得有意义的见解和关联，我们需要将数据转换成表格数据库或电子表格形式的结构化数据。</p><p id="d128" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">有几种方法可以用于网络搜集。其中一些包括:</p><ol class=""><li id="bbf1" class="kw kx hh je b jf ka jj kb jn ky jr kz jv la jz lb lc ld le bi translated">使用在线服务(ParseHub、Scrapy、BrightData)</li><li id="77ba" class="kw kx hh je b jf lf jj lg jn lh jr li jv lj jz lb lc ld le bi translated">应用程序编程接口，即API(Scraper Box API、可读性API、WebKrawler API)</li><li id="6b91" class="kw kx hh je b jf lf jj lg jn lh jr li jv lj jz lb lc ld le bi translated">从头开始创建您的Web抓取代码</li><li id="ecdd" class="kw kx hh je b jf lf jj lg jn lh jr li jv lj jz lb lc ld le bi translated">使用来自编程语言的内置框架和包(熊猫，硒，美丽的汤)</li></ol><p id="9201" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">Google、Twitter和StackOverflow等流行网站公开提供API，以结构化格式访问它们的数据。如果一个人希望从一个不为他们的数据提供API的网站获取数据，Web抓取是一个方便的工具。</p><p id="f7b4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">本文将使用Python包——美汤收集数据，报废互联网。</p><p id="0545" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">网页抓取基础</strong></p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lk"><img src="../Images/475e1617ef435172620154fee4c7597a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*DempaPJNeTmA-D1k.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx">Image Source: Google Images</figcaption></figure><p id="7e96" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">首先，我们画出网站的URL。<br/>网页抓取器然后为提供的网站加载HTML代码。<br/>然后，刮刀从代码中获取所需信息，并以用户指定的格式(Excel表格、CSV文件、JSON文件)输出。</p><h1 id="580e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">美汤网刮</h1><p id="9efe" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">Python为我们提供了一个高效的库，叫做‘美丽的汤’。它允许网络抓取，并以刘易斯·卡罗尔(Lewis Carroll)在《爱丽丝漫游奇境记》(Alice's Adventures in Wonderland)中发表的一首诗“美丽的汤”命名。这是一个Python包，它解析不想要的数据，并允许我们从HTML/XML文档中提取数据。</p><p id="780a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">设置环境</strong></p><pre class="kg kh ki kj fd ll lm ln lo aw lp bi"><span id="cc9b" class="lq if hh lm b fi lr ls l lt lu">pip install requests<br/>pip install html5lib<br/>pip install bs4</span></pre><p id="75e1" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">请求-帮助我们从网站获取HTML内容<br/> html5lib-帮助我们解析内容(可选)<br/> bs4-帮助搜索并获取所需内容</p><p id="eda4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">为了处理HTML/XML文档，我们必须将URL链接转换为字符串，这需要“请求”的帮助。此外，HTML内容可以被解析并形成树状结构，以便于遍历。</p><p id="b820" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">我们将遵循的方法:</strong></p><ol class=""><li id="a461" class="kw kx hh je b jf ka jj kb jn ky jr kz jv la jz lb lc ld le bi translated">获取URL</li><li id="e1e7" class="kw kx hh je b jf lf jj lg jn lh jr li jv lj jz lb lc ld le bi translated">获取数据</li><li id="1dba" class="kw kx hh je b jf lf jj lg jn lh jr li jv lj jz lb lc ld le bi translated">将输出保存在excel表/中。csv文件</li></ol><p id="4006" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们使用以下链接查看亚马逊畅销书-【https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_ T4】</p><p id="2c93" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">此链接将打开以下网页-</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lw"><img src="../Images/f1a99c63fe3039e493efb9e495600876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qy2P-aS5YddD-IHgtpndng.png"/></div></div></figure><p id="bcc4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这个链接让我们只能访问显示亚马逊上前50本畅销书的第一个网页。如果我们想访问额外的页面，我们的网址将被改变。下一页的链接是-<a class="ae lv" href="https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_2?ie=UTF8&amp;pg=2" rel="noopener ugc nofollow" target="_blank">https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_2?ie=UTF8 &amp; pg=2 </a></p><p id="1445" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">所以，我们观察到的URL的格式是:<br/>https://www.amazon.in/gp/bestsellers/book/ref = ZG _ bs _ pg _ '+pageno+'？ie=UTF8 &amp; pg='+pageno</p><p id="6459" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这为我们提取多个网页的代码提供了基础。我们定义一个函数来提取名为“get_data”的URL。</p><p id="7423" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们分别创建请求和美丽的对象Soup、r和soup。我们使用。以字节为单位获取响应的内容。或者，我们也可以使用。以Unicode格式获取响应内容的文本。解析器创建了一个类似树的结构。顾名思义，prettify属性组织数据并使数据看起来更有说服力。</p><p id="eef5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">然而，如果我们输入页码为1，我们将获得一个巨大的输出，可能不容易理解。因此，我们进一步细化了代码，以更有组织的格式获取信息。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lx"><img src="../Images/d066b5451619a6836636ba7327c09c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SBlax5hFMPkK55-_40FMVQ.png"/></div></div></figure><h1 id="7453" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">步骤2:获取数据</h1><p id="e18d" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们需要将URL链接提供给漂亮的Soup对象，以获取所需的信息。正如我们在上一步中看到的，我们知道每本书的每个web文档都有大量的数据。</p><p id="d9cb" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">整个web文档是用HTML编码的，我们的数据存储在HTML标签中；当我们查看网页时，我们看到每本书都有一个单独的分部，它属于HTML的' div '标签。此外，每个标签都有包含子数据的属性。</p><p id="d32e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">右键单击网页并选择inspect来检查原始HTML代码。代码将类似于下面所示。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lx"><img src="../Images/f8c8e56ec03898ecd2a23ff8d8da7986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDv5DTL-Yh07jg63NVOHqA.png"/></div></div></figure><p id="9793" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">如果我们希望分析代码，美丽的汤提供了几种方法。但是，我们为此使用了“find_all”和“find”方法。“find_all”将查找具有指定属性值的标签的所有匹配项，而“find”将只查找第一个匹配项。</p><p id="32fb" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">人们可以将鼠标悬停在相应的书籍上，找到它们对应的HTML代码。我们希望获得这篇文章的书名、作者名、评级、图书类型、图书价格和相应的图书链接。用户可以右键单击任意细节，比如图书名称，并选择inspect选项来查看图书代码中的HTML行。</p><p id="7c4e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们将编写下面的代码来提取我们想要的信息。</p><pre class="kg kh ki kj fd ll lm ln lo aw lp bi"><span id="b59d" class="lq if hh lm b fi lr ls l lt lu">all=[]<br/>    for d in soup.find_all('div',attrs={'class':'a-section a-spacing-none aok-relative'}):<br/>        name=d.find('span', attrs={'class':'zg-text-center-align'})<br/>        book_name=name.find('img',alt=True)<br/>        author_name=d.find('a',attrs={'class':'a-size-small a-link-child'})<br/>        ratings=d.find('span',attrs={'class':'a-icon-alt'})<br/>        rating_score=d.find('a',attrs={'class':'a-size-small a-link-normal'})<br/>        book_type=d.find('span',attrs={'class':'a-size-small a-color-secondary'})<br/>        price=d.find('span',attrs={'class':'p13n-sc-price'})<br/>        book_link=d.find('a',attrs={'class':'a-link-normal'})</span></pre><p id="02ef" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在，我们可以创建另一个列表，比如“all1”，我们将继续追加提取的信息。如果我们查看网页，我们会发现所有列出的书籍可能没有我们想要的所有信息。因此，我们需要下面的附加代码。</p><pre class="kg kh ki kj fd ll lm ln lo aw lp bi"><span id="0e39" class="lq if hh lm b fi lr ls l lt lu">all1=[]<br/>        if book_name is not None:<br/>            all1.append(book_name.get('alt'))<br/>        else:<br/>            all1.append('unknown')<br/>        if author_name is not None:<br/>            all1.append(author_name.text)<br/>        else:<br/>            all1.append('unknown')<br/>        if ratings is not None:<br/>            all1.append(ratings.text)<br/>        else:<br/>            all1.append('unknown')<br/>        if rating_score is not None:<br/>            all1.append(rating_score.text)<br/>        else:<br/>            all1.append('unknown')<br/>        if book_type is not None:<br/>            all1.append(book_type.text)<br/>        else:<br/>            all1.append('unknown')<br/>        if price is not None:<br/>            all1.append(price.text)<br/>        else:<br/>            all1.append('unknown')<br/>        if book_link is not None:<br/>            all1.append('https://www.amazon.in/'+book_link.get('href'))<br/>        else:<br/>            all1.append('unknown')<br/>        all.append(all1)<br/>        <br/>    return all</span></pre><h1 id="20f5" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">步骤3:存储数据</h1><p id="9069" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">现在，我们已经创建了我们的函数，使用这个函数，我们可以将我们的数据转移到一个数据框中，该数据框将用于将其保存在一个excel表中。为此，我们需要提到页数，即我们希望从多少页中提取数据。此外，我们可以创建一个函数，比如说“flatten ”,它将展平列表的子列表以压缩数据。</p><pre class="kg kh ki kj fd ll lm ln lo aw lp bi"><span id="48e6" class="lq if hh lm b fi lr ls l lt lu">import pandas as pd<br/>results = []<br/>no_pages=5<br/>for i in range(1, no_pages+1):<br/>    results.append(get_data(i))<br/>flatten = lambda l: [item for sublist in l for item in sublist]<br/>df = pd.DataFrame(flatten(results),columns= ['Book Name','Author','Rating','Customers_Rated', 'Book_type','Price','link'])</span></pre><p id="726e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">既然我们已经提取了所需的数据，并将其修改为数据帧，那么我们可以将它存储为我们喜欢的任何格式。csv，代码如下。</p><pre class="kg kh ki kj fd ll lm ln lo aw lp bi"><span id="22e0" class="lq if hh lm b fi lr ls l lt lu">df.to_csv('books.txt', sep='t')</span></pre><p id="a86e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">网络抓取是一种广泛使用的从你选择的网站中提取信息的过程。你可以从Flipkart收集你选择的特定品牌的数据，从运动鞋网站收集关于他们的销售、趋势和更多应用的细节。我们需要Python库“美丽的汤”来做同样的事情。以前的HTML知识，即使理解网站的编码是一个优势，美丽的汤帮助我们从零开始从标记语言代码之间提取信息。</p><p id="fa50" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这标志着我们对亚马逊畅销书搜索的结束。如果需要，我们可以提取更多的信息，并使用美丽的汤的其他属性，如type(soup)和soup.title来获取所需的内容。相同的网页抓取方法可以根据需要在不同的网站上使用。</p><h1 id="0978" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="7ba6" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><a class="ae lv" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwi4mNiEn8b3AhVcUGwGHcGvCH0QFnoECAQQAQ&amp;url=https%3A%2F%2Fwww.geeksforgeeks.org%2Fwhat-is-web-scraping-and-how-to-use-it%2F&amp;usg=AOvVaw1MbAfQJ6g-XyKrpGnjZGzb" rel="noopener ugc nofollow" target="_blank">什么是网页抓取？</a></p><p id="77ed" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><a class="ae lv" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwie6vCin8b3AhXrRmwGHWLdC04QwqsBegQIDRAB&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DxUs6F7qBhbo&amp;usg=AOvVaw1NsEdiG6TiPN7LCk3FB9ll" rel="noopener ugc nofollow" target="_blank">网页抓取教程</a></p><p id="e8c0" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><a class="ae lv" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwi-1eu_n8b3AhUTSGwGHUr1DSoQFnoECAUQAQ&amp;url=https%3A%2F%2Fpandas.pydata.org%2Fdocs%2Freference%2Fapi%2Fpandas.DataFrame.to_csv.html&amp;usg=AOvVaw0YU4NfV7GXp7ONlogqDITf" rel="noopener ugc nofollow" target="_blank">数据帧到。csv </a></p><p id="cd5e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">请访问这个<a class="ae lv" href="https://colab.research.google.com/drive/1XAcZPVyS9w9t6IYxYcOaD39DOX2duLOk?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本</a>以访问完整的代码并验证输出。</p><p id="2255" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我希望你喜欢这篇文章！</p><p id="76c7" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">如有任何信息、疑问或机会，请通过https://www.linkedin.com/in/netrahirani/<br/>T5联系我</p><div class="ly lz ez fb ma mb"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hi fi z dy mg ea eb mh ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">medium.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp kp mb"/></div></div></a></div></div></div>    
</body>
</html>
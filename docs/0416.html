<html>
<head>
<title>Extracting Tabular Data from PDF using Deep Learning Table Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习表格检测从PDF中提取表格数据</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/extracting-tabular-data-from-pdf-using-deep-learning-table-detection-81242cbad6d?source=collection_archive---------0-----------------------#2021-04-09">https://medium.com/mlearning-ai/extracting-tabular-data-from-pdf-using-deep-learning-table-detection-81242cbad6d?source=collection_archive---------0-----------------------#2021-04-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/3fbd7ba0f118fc0c09990c543b6e7e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X5FV5i77ovOrgOiR"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@olloweb?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Agence Olloweb</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="aabc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">众所周知，尽管数据已经存在了几个世纪，但数据是这个千年创新的中心。多亏了计算机编程的进步，人们现在才意识到它的潜力。</p><p id="ae3f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，收集尽可能多的数据至关重要。然而，对于那些主要依赖纸质报告(如财务收据，甚至是以表格形式提供见解的小册子)的行业来说，这可能尤其困难。在本文中，我们将展示如何利用预训练的RetinaNet深度学习模型从pdf中识别表格，然后使用python包Tabula将其提取到csv中。</p><h2 id="259e" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">介绍</h2><p id="9e18" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">如果没有Fizyr的T2在GitHub上预建的令人惊叹的RetinaNet模型，这一切都是不可能的。我们还利用了<a class="ae it" href="https://github.com/ferrygun" rel="noopener ugc nofollow" target="_blank"> ferrygun </a>令人敬畏的<a class="ae it" href="https://github.com/ferrygun/PDFTableExtract" rel="noopener ugc nofollow" target="_blank"> PDFTableExtract </a>库。</p><p id="4383" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们从下载开放的PDF数据集开始，将它们转换成图像文件(JPEG格式)，然后从800多张图像中手动注释所需的表格。接下来，我们在我们的数据上训练Fizyr的预训练模型权重，从而产生我们的表检测模型。最后，利用末端模型确定表格坐标，为使用Tabula——python包——提取提供区域限制。</p><p id="3389" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了给图像添加注释，我们使用了labelImg，可以在这里  <em class="ks">下载<a class="ae it" href="https://tzutalin.github.io/labelImg/" rel="noopener ugc nofollow" target="_blank"> <em class="ks">。</em></a></em></p><blockquote class="kt ku kv"><p id="8741" class="iu iv ks iw b ix iy iz ja jb jc jd je kw jg jh ji kx jk jl jm ky jo jp jq jr ha bi translated">注意:可以选择将labelImg直接安装到python中，并在代码中标注图像，但是我们发现下载应用程序本身更容易。</p></blockquote><h2 id="3f50" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">建立</h2><p id="6649" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">由于该模型的计算量非常大，要在您自己的数据上运行该模型，强烈建议在支持GPU的系统上运行。如果您的计算机只有CPU处理能力，请不要担心。Google Colab允许您在浏览器中编写和执行Python，使用</p><ul class=""><li id="5033" class="kz la hh iw b ix iy jb jc jf lb jj lc jn ld jr le lf lg lh bi translated">不需要配置</li><li id="c625" class="kz la hh iw b ix li jb lj jf lk jj ll jn lm jr le lf lg lh bi translated">免费访问GPU</li><li id="cafa" class="kz la hh iw b ix li jb lj jf lk jj ll jn lm jr le lf lg lh bi translated">轻松分享</li></ul><blockquote class="kt ku kv"><p id="27be" class="iu iv ks iw b ix iy iz ja jb jc jd je kw jg jh ji kx jk jl jm ky jo jp jq jr ha bi translated">我们的脚本写在一个Google Colab笔记本上。代码可以在不同的云环境中复制，甚至可以在本地复制，但请注意，有些包需要降级，以适应预训练模型中的Tensorflow包。(更多信息请参考Fizyer的git)</p></blockquote><p id="8620" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我们进入代码之前，最后提一下，什么是RetinaNet？</p><p id="fa48" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">它是一种深度学习模型，利用卷积神经网络(CNN)来识别图像中的对象类别。为了更深入地理解它，Prakash Jay在这篇文章中解释了RetinaNet <a class="ae it" rel="noopener" href="/@14prakash/the-intuition-behind-retinanet-eb636755607d">背后的直觉。</a></p><p id="be89" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我将在这里链接包含代码的GitHub库，供您在我们进行的过程中使用。</p><div class="lp lq ez fb lr ls"><a href="https://github.com/ektaatomar/Extracting-Tabular-Data-from-PDFs-using-Object-Detection-with-Keras-Retinanet.git" rel="noopener  ugc nofollow" target="_blank"><div class="lt ab dw"><div class="lu ab lv cl cj lw"><h2 class="bd hi fi z dy lx ea eb ly ed ef hg bi translated">ektaatomar/Extracting-Tabular-Data-from-pdf-using-Object-Detection-with-Keras-retina net</h2><div class="lz l"><h3 class="bd b fi z dy lx ea eb ly ed ef dx translated">受https://github.com/fizyr/keras-retinanet.git工作的启发，我们利用谷歌实验室来满足GPU的需求</h3></div><div class="ma l"><p class="bd b fp z dy lx ea eb ly ed ef dx translated">github.com</p></div></div><div class="mb l"><div class="mc l md me mf mb mg in ls"/></div></div></a></div><h2 id="ac38" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">数据准备</h2><p id="ec08" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">收集PDF文件后，您需要将文件转换为一组图像。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><blockquote class="kt ku kv"><p id="91a2" class="iu iv ks iw b ix iy iz ja jb jc jd je kw jg jh ji kx jk jl jm ky jo jp jq jr ha bi translated">注意:Google Colab将临时存储您的数据，然后在运行时重新启动后清除所有数据，因此我们建议运行以下转换代码，然后将文件夹下载到您的硬盘上。</p></blockquote><p id="ee2b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你碰巧有PNG图像想添加注释，那么不要担心，我们已经包含了将PNG文件转换为JPG的代码。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="2969" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">万岁！现在，您有了一组要使用labelImg进行注释的图像。注释完图像后，您的数据应该包含一个图像文件文件夹和一个XML文件文件夹。</p><p id="e236" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型需要两个文本文件'<strong class="iw hi"> <em class="ks"> train.txt </em> </strong>'和'<strong class="iw hi"> <em class="ks"> test.txt </em> </strong>'，这样就可以创建下面需要的文件。它们只是简单的文本文件，包含没有文件扩展名的图像名称。例如，训练文件将包含“图像1”、“图像2”..等等。没有了。jpg '扩展名。下面的test.txt示例代码也是如此，它将Image文件夹中的图像名称写入train.txt，然后将train.txt更改为test.txt以创建test.txt文件:</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="0e2e" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">装置</h2><p id="0474" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">现在我们准备好进入有趣的部分了。克隆Fizyr keras-retinanet repo并安装setup.py</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="8fb3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">将图像上传至文件夹<em class="ks">'/content/keras-re Tina net/images/</em>'，将注释上传至文件夹'<em class="ks">/content/keras-re Tina net/annotations/'。</em>这样做之后，您将运行以下程序，这将生成3个新的csv文件:train file-<em class="ks">' retina net-train . CSV '，</em>test file-<em class="ks">' retina net-test . CSV '，</em>以及类文件<em class="ks"> 'retinanet-classes.csv '。</em>我们建议您保存csv文件，以避免每次都重新创建它们，以便您在使用相同数据时可以重复使用它们。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="e315" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们还在GitHub中包含了一些样本数据集，以防您需要一些公共数据集来运行模型。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="220e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在安装了其他需要的包之后，我们需要下载预先训练好的模型权重来用于我们的数据。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="2391" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，我们准备好对我们的数据运行模型。批量大小、步长和时期是可配置的参数。如果代码由于内存不足而出错，首先尝试减少批处理大小和步骤。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="0fd6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型运行完成后，您需要将模型转换为推理模型。我们需要这样做，以便在图像上执行对象检测。</p><figure class="mh mi mj mk fd ii"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="6567" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们现在准备在我们的测试文件上测试这个模型。代码请参考上面的GitHub。</p><p id="6040" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">测试结果应该是这样的:</p><figure class="mh mi mj mk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/ec81182bf2ed14f89bb7ca575501d220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9KyWEpWetkdzanHQRV7kg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Test Sample with 80% Table Detection Accuracy</figcaption></figure><h2 id="eacc" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">使用Tabula将表格提取为CSV格式</h2><p id="0562" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">既然我们能够从图像中检测出桌子坐标，我们可以将它传递给Tabula python包，以便于提取。</p><p id="ec28" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">关于Tabula需要注意的一点是，它不是从图像中提取表格，而是从文本PDF文件中提取。因此，即使我们找到了桌子的坐标，我们也必须将其转换成Tabula可以读取的单位。我们发现Tabula的“面积”参数以pdf点为单位。如果您想测试或找到PDF表格的精确点，那么您可以使用Adobe Acrobat Reader中的测量工具。</p><p id="6d06" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，由于我们的坐标是像素，我们需要将它们转换为点。像素到点的转换公式为:</p><ul class=""><li id="87ea" class="kz la hh iw b ix iy jb jc jf lb jj lc jn ld jr le lf lg lh bi translated">点数=像素* 72 / DPI</li></ul><p id="6dc2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">DPI是每英寸点数的缩写。您可以使用pdf2image包中的<em class="ks"> img_page.info['dpi'] </em>函数找到图像的DPI。在我们的例子中，DPI是200。像素是由模型产生的x1，y1，x2，y2坐标。Tabula不遵循x1，y1，x2，y2的约定，而是将面积参数输入为area(y1，x1，y2，x2)。因为我们的DPI是200，那么我们的tabula函数看起来如下:</p><pre class="mh mi mj mk fd mo mp mq mr aw ms bi"><span id="0075" class="js jt hh mp b fi mt mu l mv mw">output_tabula = read_pdf(PDF_PATH, pages=str(pg), guess = <strong class="mp hi">True</strong>, area =(x[1]*72/200, x[0]*72/200, x[3]*72/200, x[2]*72/200))</span></pre><p id="6511" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后我们有了out表，现在我们只需要将它导出到一个csv文件中。</p><pre class="mh mi mj mk fd mo mp mq mr aw ms bi"><span id="bfb6" class="js jt hh mp b fi mt mu l mv mw">db.to_excel(pdf_file[:-4]+"-"+str(pg)+"-table-"+str(i)+".xlsx", header = <strong class="mp hi">False</strong>, index = <strong class="mp hi">False</strong>)</span></pre><p id="5cb3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请参考GitHub以获得在您的文件上运行的完整代码。生成的CSV文件:</p><figure class="mh mi mj mk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mx"><img src="../Images/5d253cc02d9dae4299f3c33ec0954977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b8W6qOoT2DoH5bzGvAI4lg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Extraction Result</figcaption></figure><p id="5897" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这就是深度学习对象检测的另一个可怕的用例！希望AI让你的生活轻松一点。感谢您的宝贵时间！</p><p id="8071" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">喜欢这个帖子就鼓掌分享。请在下面评论任何问题或反馈。</p><p id="6de5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">注:</strong>这篇文章和代码是与<a class="ae it" href="https://github.com/ektaatomar" rel="noopener ugc nofollow" target="_blank">埃克塔·托马尔</a>合作完成的。</p></div></div>    
</body>
</html>
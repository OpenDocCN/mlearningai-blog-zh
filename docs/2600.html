<html>
<head>
<title>Image classification with transfer learning on PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch上基于迁移学习的图像分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-2d718c85b58f?source=collection_archive---------2-----------------------#2022-05-22">https://medium.com/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-2d718c85b58f?source=collection_archive---------2-----------------------#2022-05-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="22b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在<a class="ae jc" rel="noopener" href="/mlearning-ai/image-classification-with-transfer-learning-on-tensorflow-68b6bc87ef4b">之前的文章</a>中，我们回顾了使用Tensorflow/Keras进行迁移学习的图像分类。PyTorch是另一个流行的深度学习框架，同样的模式在这里也适用。</p><p id="739e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，图像分类迁移学习的一般步骤是:</p><ol class=""><li id="2c71" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb ji jj jk jl bi translated">数据加载器</li><li id="31f6" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">预处理</li><li id="e1ba" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">加载预训练模型，根据需要冻结模型层</li><li id="fb73" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">根据需要添加额外的层，以形成最终的模型</li><li id="3b57" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">编译模型，设置优化器和损失函数</li><li id="8c1c" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">使用model.fit训练模型</li></ol><p id="ac81" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们回顾一下PyTorch提供的示例教程</p><div class="jr js ez fb jt ju"><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener  ugc nofollow" target="_blank"><div class="jv ab dw"><div class="jw ab jx cl cj jy"><h2 class="bd hi fi z dy jz ea eb ka ed ef hg bi translated">计算机视觉迁移学习教程- PyTorch教程1.11.0+cu102文档</h2><div class="kb l"><h3 class="bd b fi z dy jz ea eb ka ed ef dx translated">作者:Sasank Chilamkurthy在本教程中，你将学习如何训练一个卷积神经网络的图像…</h3></div><div class="kc l"><p class="bd b fp z dy jz ea eb ka ed ef dx translated">pytorch.org</p></div></div></div></a></div><h2 id="a601" class="kd ke hh bd kf kg kh ki kj kk kl km kn ip ko kp kq it kr ks kt ix ku kv kw kx bi translated">数据加载器和预处理</h2><p id="042a" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">该示例用于训练模型对蚂蚁和蜜蜂进行分类。它假设你将<a class="ae jc" href="https://download.pytorch.org/tutorial/hymenoptera_data.zip" rel="noopener ugc nofollow" target="_blank">数据集</a>下载到“数据/膜翅目_数据”文件夹。该示例还包括数据加载期间的预处理(使用转换功能，例如调整大小、翻转等。)</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="42d0" class="kd ke hh li b fi lm ln l lo lp">from __future__ import print_function, division</span><span id="edc0" class="kd ke hh li b fi lq ln l lo lp">import torch<br/>import torch.nn as nn<br/>import torch.optim as optim<br/>from torch.optim import lr_scheduler<br/>import torch.backends.cudnn as cudnn<br/>import numpy as np<br/>import torchvision<br/>from torchvision import datasets, models, transforms<br/>import matplotlib.pyplot as plt<br/>import time<br/>import os<br/>import copy</span><span id="b7a5" class="kd ke hh li b fi lq ln l lo lp"># Data augmentation and normalization for training<br/># Just normalization for validation<br/>data_transforms = {<br/>    'train': transforms.Compose([<br/>        transforms.RandomResizedCrop(224),<br/>        transforms.RandomHorizontalFlip(),<br/>        transforms.ToTensor(),<br/>        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])<br/>    ]),<br/>    'val': transforms.Compose([<br/>        transforms.Resize(256),<br/>        transforms.CenterCrop(224),<br/>        transforms.ToTensor(),<br/>        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])<br/>    ]),<br/>}</span><span id="df07" class="kd ke hh li b fi lq ln l lo lp">data_dir = 'data/hymenoptera_data'<br/>image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),<br/>                                          data_transforms[x])<br/>                  for x in ['train', 'val']}<br/>dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,<br/>                                             shuffle=True, num_workers=4)<br/>              for x in ['train', 'val']}<br/>dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}<br/>class_names = image_datasets['train'].classes</span></pre><h2 id="cc01" class="kd ke hh bd kf kg kh ki kj kk kl km kn ip ko kp kq it kr ks kt ix ku kv kw kx bi translated">负载预训练模型</h2><p id="1fa6" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated"><a class="ae jc" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> RESNET18 </a>是微软研究院在2015年发布的一款热门机型。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="e400" class="kd ke hh li b fi lm ln l lo lp">model_ft = models.resnet18(pretrained=True)</span></pre><h2 id="d95d" class="kd ke hh bd kf kg kh ki kj kk kl km kn ip ko kp kq it kr ks kt ix ku kv kw kx bi translated">添加附加层</h2><p id="0123" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">它代替最后的<a class="ae jc" href="https://towardsdatascience.com/convolutional-layers-vs-fully-connected-layers-364f05ab460b" rel="noopener" target="_blank">全连接层</a>进行二进制分类。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="9862" class="kd ke hh li b fi lm ln l lo lp">num_ftrs = model_ft.fc.in_features<br/># Here the size of each output sample is set to 2.<br/># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).<br/>model_ft.fc = nn.Linear(num_ftrs, 2)</span></pre><h2 id="87e9" class="kd ke hh bd kf kg kh ki kj kk kl km kn ip ko kp kq it kr ks kt ix ku kv kw kx bi translated">设置优化器，损失函数</h2><p id="1914" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated"><a class="ae jc" rel="noopener" href="/swlh/cross-entropy-loss-in-pytorch-c010faf97bab">分类任务常用交叉熵损失</a>，使用<a class="ae jc" href="https://www.projectpro.io/recipes/optimize-function-sgd-pytorch" rel="noopener ugc nofollow" target="_blank">随机梯度下降/SGD </a>优化器。学习率在机器学习训练中非常重要。想想下山，通常一开始坡度很陡，所以你会迈较大的步幅，但当你接近底部时，坡度就不那么陡了，为了不错过底部，你会迈越来越小的步幅。PyTorch提供lr_scheduler来调整学习速率。更多信息，请看<a class="ae jc" href="https://www.youtube.com/watch?v=81NJgoR5RfY" rel="noopener ugc nofollow" target="_blank">这段视频</a>。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="cc6d" class="kd ke hh li b fi lm ln l lo lp">device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")<br/>model_ft = model_ft.to(device)</span><span id="4b1b" class="kd ke hh li b fi lq ln l lo lp">criterion = nn.CrossEntropyLoss()</span><span id="b44c" class="kd ke hh li b fi lq ln l lo lp"># Observe that all parameters are being optimized<br/>optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)</span><span id="4908" class="kd ke hh li b fi lq ln l lo lp"># Decay LR by a factor of 0.1 every 7 epochs<br/>exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)</span></pre><h2 id="a2ee" class="kd ke hh bd kf kg kh ki kj kk kl km kn ip ko kp kq it kr ks kt ix ku kv kw kx bi translated">火车模型</h2><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="ddcb" class="kd ke hh li b fi lm ln l lo lp">model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)</span></pre><h2 id="c8cb" class="kd ke hh bd kf kg kh ki kj kk kl km kn ip ko kp kq it kr ks kt ix ku kv kw kx bi translated">等等。有东西不见了</h2><p id="6679" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">我必须承认，为了保持模式简单，我故意省略了一些东西:您必须定义train_model函数。不像Keras API，在PyTorch中你需要定义训练循环。接下来，对于每个训练历元，它分批迭代输入图像，对于每一批，它首先将输入变量(图像张量)通过一个f <a class="ae jc" href="https://d2l.ai/chapter_multilayer-perceptrons/backprop.html" rel="noopener ugc nofollow" target="_blank">正向通道</a>来计算模型输出，然后使用<a class="ae jc" href="https://www.analyticsvidhya.com/blog/2021/06/how-does-backward-propagation-work-in-neural-networks/" rel="noopener ugc nofollow" target="_blank">反向传播</a>来计算神经网络参数的梯度，以最小化损失函数。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="f7fc" class="kd ke hh li b fi lm ln l lo lp">def train_model(model, criterion, optimizer, scheduler, num_epochs=25):<br/>    since = time.time()</span><span id="2670" class="kd ke hh li b fi lq ln l lo lp">best_model_wts = copy.deepcopy(model.state_dict())<br/>    best_acc = 0.0</span><span id="9c4c" class="kd ke hh li b fi lq ln l lo lp">for epoch in range(num_epochs):<br/>        print(f'Epoch {epoch}/{num_epochs - 1}')<br/>        print('-' * 10)</span><span id="f96c" class="kd ke hh li b fi lq ln l lo lp"># Each epoch has a training and validation phase<br/>        for phase in ['train', 'val']:<br/>            if phase == 'train':<br/>                model.train()  # Set model to training mode<br/>            else:<br/>                model.eval()   # Set model to evaluate mode</span><span id="e6ac" class="kd ke hh li b fi lq ln l lo lp">running_loss = 0.0<br/>            running_corrects = 0</span><span id="db73" class="kd ke hh li b fi lq ln l lo lp"># Iterate over data.<br/>            for inputs, labels in dataloaders[phase]:<br/>                inputs = inputs.to(device)<br/>                labels = labels.to(device)</span><span id="d1eb" class="kd ke hh li b fi lq ln l lo lp"># zero the parameter gradients<br/>                optimizer.zero_grad()</span><span id="c355" class="kd ke hh li b fi lq ln l lo lp"># forward<br/>                # track history if only in train<br/>                with torch.set_grad_enabled(phase == 'train'):<br/>                    outputs = model(inputs)<br/>                    _, preds = torch.max(outputs, 1)<br/>                    loss = criterion(outputs, labels)</span><span id="fa24" class="kd ke hh li b fi lq ln l lo lp"># backward + optimize only if in training phase<br/>                    if phase == 'train':<br/>                        loss.backward()<br/>                        optimizer.step()</span><span id="750c" class="kd ke hh li b fi lq ln l lo lp"># statistics<br/>                running_loss += loss.item() * inputs.size(0)<br/>                running_corrects += torch.sum(preds == labels.data)<br/>            if phase == 'train':<br/>                scheduler.step()</span><span id="f478" class="kd ke hh li b fi lq ln l lo lp">epoch_loss = running_loss / dataset_sizes[phase]<br/>            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><span id="3193" class="kd ke hh li b fi lq ln l lo lp">print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')</span><span id="3411" class="kd ke hh li b fi lq ln l lo lp"># deep copy the model<br/>            if phase == 'val' and epoch_acc &gt; best_acc:<br/>                best_acc = epoch_acc<br/>                best_model_wts = copy.deepcopy(model.state_dict())</span><span id="f4b8" class="kd ke hh li b fi lq ln l lo lp">print()</span><span id="617c" class="kd ke hh li b fi lq ln l lo lp">time_elapsed = time.time() - since<br/>    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')<br/>    print(f'Best val Acc: {best_acc:4f}')</span><span id="2fbf" class="kd ke hh li b fi lq ln l lo lp"># load best model weights<br/>    model.load_state_dict(best_model_wts)<br/>    return model</span></pre><p id="da96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如您所见，这个函数中有许多样板代码。PyTorch Lightning就是为了简化这一点而创建的。下次再来探索吧。</p><div class="jr js ez fb jt ju"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jv ab dw"><div class="jw ab jx cl cj jy"><h2 class="bd hi fi z dy jz ea eb ka ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kb l"><h3 class="bd b fi z dy jz ea eb ka ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kc l"><p class="bd b fp z dy jz ea eb ka ed ef dx translated">medium.com</p></div></div><div class="lr l"><div class="ls l lt lu lv lr lw lx ju"/></div></div></a></div></div></div>    
</body>
</html>
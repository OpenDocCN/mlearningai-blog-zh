<html>
<head>
<title>Transfer Learning Example Using Keras and DistilBERT, with Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras和DistilBERT的迁移学习示例，带代码</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/transfer-learning-example-using-keras-and-distilbert-with-code-e6e725f1fc2d?source=collection_archive---------2-----------------------#2020-10-09">https://medium.com/mlearning-ai/transfer-learning-example-using-keras-and-distilbert-with-code-e6e725f1fc2d?source=collection_archive---------2-----------------------#2020-10-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d63a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">简介</strong></p><p id="8db0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文介绍了一个使用DistilBERT和迁移学习进行情感分析的例子。本文首先设定一个目标，制定一个计划，并在进行模型训练之前收集数据，最后对结果进行一些分析。这个想法是从始至终跟踪这个项目，以便说明整个数据科学过程。正如许多数据科学家所知，机器学习大约10%是实际的机器学习，90%是其他的。我希望对我的项目的深入描述能够说明这一点。我还想提供一个使用Keras和DistilBERT进行自然语言处理的迁移学习的深入示例，并附有代码，供希望开始这一领域的人使用。</p><p id="6efa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">本项目的目标</strong></p><p id="7878" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我不清理数据、不分析数据、不学习数据、不做数据白日梦时，我喜欢把时间花在攀岩上。对我来说幸运的是，有一个很棒的网站叫做MountainProject.com，这是一个登山者的在线资源。Mountain Project的主要目的是作为一个在线指南，其中每条攀登路线都有描述，以及关于攀登质量、难度和类型的信息。还有一些论坛，攀岩者可以在那里提问，学习新技术，寻找伙伴，吹嘘最近的攀岩冒险，并复习攀岩装备。</p><p id="6b22" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我试图决定下一步想买什么样的装备时，攀岩装备评论对我来说真的很有帮助。我想到，攀岩装备公司可能想知道攀岩者如何看待他们的品牌，或者他们制造的某件特定的装备。于是，这个项目诞生了。</p><p id="c281" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个项目的目标是给gear评论论坛的情绪贴上积极、消极或中立的标签。问题是:“攀岩者对不同种类的攀岩装备有什么感觉？”更广泛地说，这个项目的目标是创建一个模型，可以使用有限的训练数据来标记利基社区中在线论坛的情绪。虽然这个项目是集中在攀岩社区，这里描述的方法也可以很容易地用于其他领域。这对于给定社区中想要了解最佳技术和购买最佳装备的参与者来说可能是有用的。这对为该行业提供产品的公司也是有用的；对于这些公司来说，了解用户对其产品的感受，以及参与者在对产品做出正面或负面评论时使用的关键词将会非常有用。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="9b41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">计划</strong></p><p id="d4c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对我来说不幸的是，山地项目齿轮审查论坛没有标签。论坛是思想和观点的集合，但是没有与之相关的数值。我的意思是，我可以写下我对一件装备的看法，但我不会给它一个星级。这消除了直接监督学习的可能性。(是的，当然，我可以去手工标记100k+的论坛，但是这有什么意思呢？哪儿也不去，听起来很糟糕。)</p><p id="0416" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">进入迁移学习。迁移学习是指在一项任务上训练的模型被用于类似的任务。在这种情况下，我有一个未标记的数据集，我想给它分配标签。因此，我需要创建一个模型，该模型被训练来预测已标记数据集上的标签，然后使用该模型为我的未标记论坛数据集创建标签。</p><p id="5551" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为这个模型将需要分析自然语言，所以我需要我的模型首先理解语言。这就是我使用蒸馏模型原因。关于DistilBERT如何工作的细节超出了本文的范围，但是可以在<a class="ae jj" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">对BERT </a>的描述和<a class="ae jj" rel="noopener" href="/huggingface/distilbert-8cf3380435b5">对DistilBERT </a>的描述中找到。简而言之，DistilBERT是一个预训练的LSTM模型，它懂英语。加载DistilBERT模型后，可以在更具体的数据集上对其进行微调。在这种情况下，我想调整DistilBERT，以便它可以准确地标记攀登齿轮论坛。</p><p id="18a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，将有两个学习的转移；首先，DistilBERT中包含的知识将被转移到我的标记数据集。然后，我会训练这个模型来标注数据的情绪。第二，我将这个模型转移到我的未标记论坛数据集。这将允许我的模型标记数据集。在论坛数据集被标上积极、消极或中性情绪后，我可以分析登山者对不同类型攀岩装备的看法。</p><p id="37f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">数据</strong></p><p id="17c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你的初始任务越接近最终任务，迁移学习就越有效。所以，我需要找到一个与攀岩和攀岩装备相关的标注数据集。我的搜索把我带到了两个地方。首先，去Trailspace.com。Trailspace是一个户外爱好者可以写关于他们装备的评论的网站，并且(最重要的是)留下星级。这看起来很完美，但遗憾的是只有大约1000条关于攀岩装备的评论。</p><p id="834f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据的缺乏让我想到了第二个带标签的数据集:山区路线项目。每条路线都有描述和星级评定，网站上有大约116，000条路线。这是大量的数据，但这些数据并不是我所需要的，因为登山者谈论路线的方式不同于登山者谈论装备的方式。比如我不会用“好玩”来形容gear，也不会用“有用”来形容一条路线。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/e1e7e2ee01973789ed9a057b2e9554b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hw0e7cwkt6b-_MvDlc5Gog.png"/></div></div></figure><p id="78da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管如此，我认为根据路线数据进行训练总比什么都没有好，因为登山者谈论任何事情的方式都有一些重叠，而且方言非常独特，有很多俚语。例如，如果我把一条路线描述为“带着轰炸机装备的恶心攀登”，那么这个攀登就是高质量的。希望我的模型将学习这种独特的攀爬词汇，并在需要给它们贴标签的时候应用到gear评论论坛上。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="2498" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第一步:抓取数据</strong></p><p id="3320" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我的计划已经制定好了，现在是时候实际收集一些数据了。为此，我需要为Mountain Project和Trailspace创建一个web scraper。在开始这个项目之前，我不知道如何做任何类型的网络抓取。所以，我看了<a class="ae jj" href="https://www.youtube.com/watch?v=XQgXKtPSzUI&amp;t=831s" rel="noopener ugc nofollow" target="_blank">这个</a>非常有用的YouTube视频，它是关于使用BeautifulSoup在Python中进行网络抓取的。对我来说幸运的是，Trailspace和山地项目论坛都很容易刮。例如，Trailspace抓取的代码如下:</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="d4c1" class="kb kc hh jx b fi kd ke l kf kg">from urllib.request import urlopen as uReq<br/>from bs4 import BeautifulSoup as soup<br/>import os<br/>import time</span><span id="cbc6" class="kb kc hh jx b fi kh ke l kf kg">%%capture<br/>from tqdm import tqdm_notebook as tqdm<br/>tqdm().pandas()</span><span id="54ee" class="kb kc hh jx b fi kh ke l kf kg"># Manually gather list of main page URLs<br/>all_urls = ["https://www.trailspace.com/gear/mountaineering-boots/",<br/>           "https://www.trailspace.com/gear/mountaineering-boots/?page=2",<br/>           "https://www.trailspace.com/gear/mountaineering-boots/?page=3",<br/>           "https://www.trailspace.com/gear/approach-shoes/",<br/>           "https://www.trailspace.com/gear/approach-shoes/?page=2",<br/>           "https://www.trailspace.com/gear/climbing-shoes/",<br/>           "https://www.trailspace.com/gear/climbing-shoes/?page=2",<br/>           "https://www.trailspace.com/gear/climbing-protection/",<br/>           "https://www.trailspace.com/gear/ropes/",<br/>           "https://www.trailspace.com/gear/carabiners-and-quickdraws/",<br/>           "https://www.trailspace.com/gear/belay-rappel/",<br/>           "https://www.trailspace.com/gear/ice-and-snow-gear/",<br/>           "https://www.trailspace.com/gear/big-wall-aid-gear/",<br/>           "https://www.trailspace.com/gear/harnesses/",<br/>           "https://www.trailspace.com/gear/climbing-helmets/",<br/>           "https://www.trailspace.com/gear/climbing-accessories/"]</span><span id="f2a0" class="kb kc hh jx b fi kh ke l kf kg">def get_gear_subpages(main_url):</span><span id="8fad" class="kb kc hh jx b fi kh ke l kf kg">    '''Function to grab all sub-URLs from main URL'''</span><span id="a34b" class="kb kc hh jx b fi kh ke l kf kg">    # Get HTML info<br/>    uClient = uReq(main_url) # request the URL<br/>    page_html = uClient.read() # Read the html<br/>    uClient.close() # close the connection<br/>    gear_soup = soup(page_html, "html.parser")<br/><br/><br/>    item_urls = []<br/>    items = gear_soup.findAll("a", {"class":"plProductSummaryGrid"})<br/>    for a_tag in items:<br/>        href = a_tag.attrs.get("href")<br/>        if href == "" or href is None:<br/>            continue<br/>        else:<br/>            item_urls.append("https://www.trailspace.com"+href)<br/><br/>    return item_urls</span><span id="d47c" class="kb kc hh jx b fi kh ke l kf kg"># Get a lit of all sub-URLs<br/>all_sub_urls = []<br/>for main_url in tqdm(all_urls):<br/>    all_sub_urls += get_gear_subpages(main_url)</span><span id="4be9" class="kb kc hh jx b fi kh ke l kf kg">def get_gear_comments(gear_url):</span><span id="71c8" class="kb kc hh jx b fi kh ke l kf kg">    '''Function to extract all comments from each sub-URL'''<br/>    # Get HTML info<br/>    uClient = uReq(gear_url) # request the URL<br/>    page_html = uClient.read() # Read the html<br/>    uClient.close() # close the connection<br/>    review_soup = soup(page_html, "html.parser")<br/>    <br/>    all_reviews = review_soup.find("div", {"id":"reviews"})<br/>    <br/>    review_dict = dict()<br/>    <br/>    try:<br/>        for this_review in all_reviews.findAll("div", {"class": "reviewOuterContainer"}):<br/>            # Get review rating<br/>            try:<br/>                rating = float(str(this_review.find_next('img').find_next("img")).split("rated ")[1].split(" of")[0])<br/>            except:<br/>                rating = float(str(this_review.find("img").find_next("img").find_next("img")).split("rated ")[1].split(" of")[0])<br/>            # Get review text<br/>            review_summary = this_review.find("div",{"class":"review summary"}).findAll("p")<br/>            review_text = ""<br/>            for blurb in review_summary:<br/>                review_text += "   " + blurb.text.replace("\n", "   ").replace("\r", "   ")<br/><br/>            review_dict[review_text] = rating<br/>    except:<br/>        pass<br/>    <br/>    return review_dict</span><span id="d76c" class="kb kc hh jx b fi kh ke l kf kg"># Extract information from all URLs and save to file:</span><span id="ede1" class="kb kc hh jx b fi kh ke l kf kg">t0 = time.time()<br/><br/>filename = "trailspace_gear_reviews.csv"<br/>f = open(filename, "w")<br/>headers = "brand, model, rating, rating_text\n"<br/>f.write(headers)<br/>   <br/>for url in tqdm(all_sub_urls):<br/>    brand = url.split("/")[4]<br/>    model = url.split("/")[5]<br/>    info = get_gear_comments(url)<br/>    for review in info.keys():<br/>        rating_text = review.replace(",", "~")<br/>        rating = info[review]<br/><br/>        f.write(brand  +","+ <br/>                model  +","+ <br/>                str(rating) +","+ <br/>                rating_text  + "\n")<br/>        <br/>f.close()<br/>t1 = time.time()  <br/>t1-t0</span></pre><p id="2e94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事实证明，这些路线更具挑战性。在山地项目上，路线按“区域&gt;子区域&gt;路线”排序。但有时会有多个分区，所以看起来是“区域&gt;大分区&gt;中分区&gt;小分区&gt;路线”。我的主要问题是迭代所有的路线，以确保我收集了所有路线的数据，即使它们不是统一组织的。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ki"><img src="../Images/df39f8c5b0d0ca5c5e1eeb0b352d350e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YTNaL1sBFu2_LaMEnnED2A.png"/></div></div></figure><p id="c33d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">幸运的是，山区项目有另一种方式解决这个问题。在Mountain Project中，您可以搜索路线并按难度排序，然后按名称排序。然后，它会输出一个可爱的csv文件，其中包括搜索结果中每条路线的URL。不幸的是，搜索最多只能搜索1000条路线，所以你不可能一次搜索到所有路线。我没有被这样一个小小的不便所吓倒，我煞费苦心地穿过每个区域和分区，一次抓取1000条路线，并将文件保存到我的计算机上，直到我在我的计算机上以单独的csv文件保存了所有116，000条路线。一旦我有了所有的csv文件，我就用下面的代码将它们组合起来:</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="e601" class="kb kc hh jx b fi kd ke l kf kg">import os<br/>import glob<br/>import pandas as pd<br/>from progress.bar import Bar<br/>import time<br/>import tqdm</span><span id="73cf" class="kb kc hh jx b fi kh ke l kf kg"># Combine CSVs that I got directly from Mountain Project<br/>extension = 'csv'<br/>all_filenames = [i for i in glob.glob('*.{}'.format(extension))]<br/><br/>#combine all files in the list<br/>combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])<br/><br/>#export to csv<br/>combined_csv.to_csv( "all_routes.csv", index=False, encoding='utf-8-sig')<br/>routes = pd.read_csv("all_routes.csv")<br/>routes.drop_duplicates(subset = "URL", inplace = True)<br/><br/># remove routes with no rating<br/>routes = routes[routes["Avg Stars"]!= -1]</span></pre><p id="e0da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此时，我有一个很大的csv文件，其中包含Mountain Project上所有路线的URL。现在，我需要迭代每个URL并抓取我需要的信息，然后将其添加回这个csv。删除了空描述、非英文描述或少于10票**的路线。这将我的路由示例数量减少到大约31，000个。</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="43be" class="kb kc hh jx b fi kd ke l kf kg">def description_scrape(url_to_scrape, write = True):<br/>    """Get description from route URL"""<br/><br/>    # Get HTML info<br/>    uClient = uReq(url_to_scrape) # request the URL<br/>    page_html = uClient.read() # Read the html<br/>    uClient.close() # close the connection<br/>    route_soup = soup(page_html, "html.parser")<br/>    <br/>    # Get route description headers<br/>    heading_container = route_soup.findAll("h2", {"class":"mt-2"})<br/>    heading_container[0].text.strip()<br/>    headers = ""<br/>    for h in range(len(heading_container)):<br/>        headers += "&amp;&amp;&amp;" + heading_container[h].text.strip()<br/>    headers = headers.split("&amp;&amp;&amp;")[1:]<br/>    <br/>    # Get route description text<br/>    route_soup = soup(page_html, "html.parser")<br/>    desc_container = route_soup.findAll("div", {"class":"fr-view"})<br/>    words = ""<br/>    for l in range(len(desc_container)):<br/>        words += "&amp;&amp;&amp;" + desc_container[l].text<br/>    words = words.split("&amp;&amp;&amp;")[1:]<br/>    <br/>    # Combine into dictionary<br/>    route_dict = dict(zip(headers, words))<br/>    <br/>    # Add URL to dictionary<br/>    route_dict["URL"] = url_to_scrape<br/>    <br/>    # Get number of votes on star rating and add to dictionary<br/>    star_container = route_soup.find("span", id="route-star-avg")<br/>    num_votes = int(star_container.span.span.text.strip().split("from")[1].split("\n")[0].replace(",", ""))<br/>    route_dict["star_votes"] = num_votes<br/>    <br/>    if write == True:<br/>        # Write to file:<br/>        f.write(route_dict["URL"] +","+ <br/>                route_dict.setdefault("Description", "none listed").replace(",", "~") +","+<br/>                route_dict.setdefault("Protection", "none listed").replace(",", "~") +","+<br/>                str(route_dict["star_votes"]) + "\n")<br/>    else:<br/>        return route_dict</span><span id="73d9" class="kb kc hh jx b fi kh ke l kf kg"># Get URLs from large route.csv file<br/>all_route_urls = list(routes["URL"])</span><span id="2979" class="kb kc hh jx b fi kh ke l kf kg"># Open a new file<br/>filename = "route_desc.csv"<br/>f = open(filename, "w")<br/>headers = "URL, desc, protection, num_votes\n"<br/>f.write(headers)</span><span id="c881" class="kb kc hh jx b fi kh ke l kf kg"># Scrape all the routes<br/>for route_url in tqdm(all_route_urls):<br/>    description_scrape(route_url)<br/>    time.sleep(.05)<br/><br/>t1 = time.time()<br/>t1-t0<br/><br/>f.close()</span><span id="a744" class="kb kc hh jx b fi kh ke l kf kg"># Merge these dataframes:<br/>merged = routes.merge(route_desc, on='URL')<br/>merged.to_csv("all_routes_and_desc.csv", index=False)<br/>df = pd.read_csv("all_routes_and_desc.csv")</span><span id="7cf7" class="kb kc hh jx b fi kh ke l kf kg">##### CLEANING STEPS #####</span><span id="d9db" class="kb kc hh jx b fi kh ke l kf kg"># Drop column that shows my personal vote<br/>df.drop(["Your Stars"], axis = 1, inplace=True)</span><span id="43b4" class="kb kc hh jx b fi kh ke l kf kg"># Removes whitespace around column names<br/>df_whole = df.rename(columns=lambda x: x.strip()) </span><span id="8405" class="kb kc hh jx b fi kh ke l kf kg"># Combine text columns and select needed columns<br/>df_whole["words"] = df_whole["desc"] + " " + df_whole["protection"]<br/>df = df_whole[["words", "num_votes", "Avg Stars"]]</span><span id="4a42" class="kb kc hh jx b fi kh ke l kf kg"># Remove rows with no description<br/>bad_df = df[df.words.apply(lambda x: len(str(x))&lt;=5)]<br/>new_df = df[~df.words.isin(bad_df.words)]<br/>print(len(df), len(bad_df), len(new_df), len(df)-len(bad_df)==len(new_df))<br/>df = new_df</span><span id="49bd" class="kb kc hh jx b fi kh ke l kf kg"># Remove non-english entries... takes a few minutes...<br/>from langdetect import detect<br/>def is_english(x):<br/>    try:<br/>        return detect(x)<br/>    except:<br/>        return None<br/><br/>df["english"] = df['words'].apply(lambda x: is_english(x) == 'en')<br/>df = df[df.english]<br/>df = df[["words", "num_votes", "Avg Stars"]]</span><span id="cc08" class="kb kc hh jx b fi kh ke l kf kg"># Now remove rows with less than 10 votes<br/>few_votes = np.where(df.num_votes &lt;= 9)[0]<br/>for vote in few_votes:<br/>    try:<br/>        df.drop(vote, inplace = True)<br/>    except:<br/>        pass<br/>df_small = df.drop(few_votes)<br/>df = df_small</span><span id="d39f" class="kb kc hh jx b fi kh ke l kf kg"># Save it<br/>df.to_csv('data/words_and_stars_no_ninevotes.csv', index=False, header=True)</span></pre><p id="1974" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我有三个数据集要处理:Trailspace.com装备评论、山地项目路线和山地项目装备评论论坛。</p><p id="986f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">gear评论论坛的一个问题是，在同一个论坛帖子中，经常有关于多个gear的多种观点。所以，在一次天真的尝试中，我把论坛帖子分成句子，每当有句号的时候，我就把每个帖子分开。有很多原因说明这不是将文本拆分成句子的最佳方式，但我认为这对于这个项目来说已经足够好了。这将样本数量增加到大约200，000个。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="ad0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第二步:建立模型</strong></p><p id="1c0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你已经做到了这一步，那就高兴吧，因为是时候进行一些真正的机器学习了！嗯，差不多是时候了。在开始构建模型之前，我需要某种度量来衡量我的模型的质量。这意味着我不得不承担手动标记一些论坛的可怕任务。我手动将论坛的4000个样本标记为正面(2)、负面(0)或中性(1)，以便我可以评估我的模型。这花了大约四个小时。</p><p id="1120" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当然，我想为我的任务建立尽可能好的模型。我有两个数据集来帮助我创建这个模型。Trailspace的数据很少，但更相关。路线数据很大，但相关性较低。哪个对我的模型帮助更大？或者，我应该使用两者的组合吗？重要的是，额外的数据是否比简单的蒸馏模型提供了更好的性能？</p><p id="1a64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我决定对四种模型进行比较:</p><ol class=""><li id="44b9" class="kj kk hh ig b ih ii il im ip kl it km ix kn jb ko kp kq kr bi translated">只有蒸馏瓶的模型</li><li id="bd0d" class="kj kk hh ig b ih ks il kt ip ku it kv ix kw jb ko kp kq kr bi translated">具有蒸馏物和路线信息的模型</li><li id="660d" class="kj kk hh ig b ih ks il kt ip ku it kv ix kw jb ko kp kq kr bi translated">具有蒸馏和轨迹空间信息的模型</li><li id="ecc7" class="kj kk hh ig b ih ks il kt ip ku it kv ix kw jb ko kp kq kr bi translated">一个带蒸馏瓶和两个数据集的模型</li></ol><p id="ac81" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在每个蒸馏瓶的顶部是一个小的、相同的神经网络。这个网络在4000个带标签的论坛实例上进行训练，随机种子设置为42，以防止数据分割方式的变化。较低的DistilBERT层被锁定，这意味着DistilBERT没有被论坛数据重新训练。通过保持网络的一致性，模型之间的唯一差异是DistilBERT被调整的数据集(或缺少数据集)。这将允许我断定哪个数据集在调整DistilBERT以预测论坛帖子标签方面做得最好，而不会引入来自不同类型模型的噪声或数据分割的变化。因为有三个类别(阳性、阴性和中性)，分类交叉熵被用作损失函数。</p><p id="799b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">经过大量的试验和调整参数后，我发现训练DistilBERT only模型的最佳方法是下面的方法:</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="0b2c" class="kb kc hh jx b fi kd ke l kf kg">from transformers import pipeline<br/>from transformers import AutoTokenizer, TFAutoModelForSequenceClassification<br/>from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig, TFAutoModelWithLMHead, TFAutoModel, AutoModel<br/><br/>from sklearn.model_selection import train_test_split<br/><br/>import tensorflow as tf<br/><br/>import pandas as pd<br/>import numpy as np<br/><br/>classifier = pipeline('sentiment-analysis')<br/><br/>import random<br/>random.seed(42)</span><span id="9ed9" class="kb kc hh jx b fi kh ke l kf kg">##### SET UP THE MODEL #####</span><span id="3595" class="kb kc hh jx b fi kh ke l kf kg">save_directory = "distilbert-base-uncased"<br/>config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)<br/>config.output_hidden_states = False<br/>transformer_model = TFAutoModel.from_pretrained(save_directory, from_pt=True, config = config)<br/><br/>input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')<br/>input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32') </span><span id="41c8" class="kb kc hh jx b fi kh ke l kf kg"># Build model that will go on top of DistilBERT<br/>embedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]<br/>X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)<br/>X = tf.keras.layers.GlobalMaxPool1D()(X)<br/>X = tf.keras.layers.Dense(50, activation='relu')(X)<br/>X = tf.keras.layers.Dropout(0.2)(X)<br/>X = tf.keras.layers.Dense(3, activation='sigmoid')(X)<br/>tf.keras.layers.Softmax(axis=-1)<br/>model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)<br/><br/>for layer in model.layers[:3]:<br/>    layer.trainable = False<br/>    <br/>model.compile(optimizer="Adam", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=["acc"])</span><span id="6246" class="kb kc hh jx b fi kh ke l kf kg"><br/>##### LOAD THE TEST DATA #####</span><span id="2c8f" class="kb kc hh jx b fi kh ke l kf kg">df = pd.read_csv('data/labeled_forum_test.csv')<br/>X_train, X_test, y_train, y_test = train_test_split(df["text"], df["sentiment"], test_size=0.20, random_state=42)</span><span id="8105" class="kb kc hh jx b fi kh ke l kf kg"># Create X values<br/>tokenizer = AutoTokenizer.from_pretrained(save_directory)<br/>X_train = tokenizer(<br/>     list(X_train),<br/>     padding=True,<br/>     truncation=True,<br/>     return_tensors="tf",<br/>     max_length = 128<br/> )<br/><br/>X_test = tokenizer(<br/>     list(X_test),<br/>     padding=True,<br/>     truncation=True,<br/>     return_tensors="tf",<br/>     max_length = 128<br/> )</span><span id="7d38" class="kb kc hh jx b fi kh ke l kf kg"># Create Y values<br/>y_train = pd.get_dummies(y_train)<br/>y_test = pd.get_dummies(y_test)</span><span id="cc44" class="kb kc hh jx b fi kh ke l kf kg">#### TRAIN THE MODEL ####</span><span id="0810" class="kb kc hh jx b fi kh ke l kf kg">history = model.fit([X_train["input_ids"],   X_train["attention_mask"]], <br/>          y_train, <br/>          batch_size=128, <br/>          epochs=8, <br/>          verbose=1, <br/>          validation_split=0.2)</span><span id="ffa2" class="kb kc hh jx b fi kh ke l kf kg">#### SAVE WEIGHTS FOR LATER ####</span><span id="6dfb" class="kb kc hh jx b fi kh ke l kf kg">model.save_weights('models/final_models/bert_only2/bert_only2')</span></pre><p id="5309" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的代码创建了基线模型，只有DistilBERT。现在，我将使用保存到“data/words _ and _ stars _ no _ nine votes . CSV”中的数据来调优DistilBERT。</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="55ba" class="kb kc hh jx b fi kd ke l kf kg">from transformers import pipeline<br/>from transformers import AutoTokenizer, TFAutoModelForSequenceClassification<br/><br/>from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig, TFAutoModelWithLMHead, TFAutoModel, AutoModel<br/><br/>import tensorflow as tf<br/>import numpy as np<br/><br/>classifier = pipeline('sentiment-analysis')</span><span id="79d9" class="kb kc hh jx b fi kh ke l kf kg">##### LOAD DATA THAT WILL TUNE DISTILBERT #####<br/>df = pd.read_csv('data/words_and_stars_no_ninevotes.csv')<br/>df.replace(4,3.9999999) # prevents errors</span><span id="d2a3" class="kb kc hh jx b fi kh ke l kf kg">#### TUNE DISTILBERT #####<br/># normalize star values<br/>df["norm_star"] = df["Avg Stars"]/2<br/>df.head()<br/><br/># drop null entries<br/>print(len(np.where(pd.isnull(df["words"]))[0])) # 288 null entries<br/>df.dropna(inplace = True)<br/><br/>model_name = "distilbert-base-uncased"<br/>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)<br/>tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')<br/>model = DistilBertModel.from_pretrained('distilbert-base-uncased')<br/><br/>tf_batch = tokenizer(<br/>     list(df["words"]),<br/>     padding=True,<br/>     truncation=True,<br/>     return_tensors="tf"<br/> )<br/><br/>tf_outputs = tf_model(tf_batch, labels = tf.constant(list(df["norm_star"]), dtype=tf.float64))<br/><br/>loss = [list(df["norm_star"])[i]-float(tf_outputs[0][i]) for i in range(len(df))]<br/>star_diff = (sum(loss)/1000)*4<br/>star_diff<br/><br/># Save the tuned DistilBERT so you can use it later<br/>save_directory = "models/route_model"<br/>tokenizer.save_pretrained(save_directory)<br/>model.save_pretrained(save_directory)</span></pre><p id="61c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从这里开始，创建一个以经过调优的DistilBERT为基础的模型的代码与用于创建DistilBERT only模型的代码是相同的，除了:</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="434b" class="kb kc hh jx b fi kd ke l kf kg">save_directory = "distilbert-base-uncased"</span></pre><p id="78b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用:</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="9b91" class="kb kc hh jx b fi kd ke l kf kg">save_directory = "models/route_model"</span></pre><p id="9883" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">经过实验和参数调整，四个模型的结果如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es kx"><img src="../Images/5428eb1ec72548f34e0bbf56c6c149ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nO0MrHb-fZP_moF9W7oiVA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">Δtest_acc refers to the change in accuracy before and after parameter tweaking</figcaption></figure><p id="1e63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">具有路线和齿轮数据的DistilBERT模型为三向分类提供了81.6%的最佳测试精度，并将用于标注山地项目论坛。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="6e32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第三步:模型分析</strong></p><p id="1b41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">路线和档位模型提供了81.6%的测试准确度。这就引出了一个问题:在另外的18.4%发生了什么？会不会是帖子的长度导致了不准确？</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lc"><img src="../Images/e415498e59d55ae779d148c4ae4a4e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*92cxmFKq17unalb795DsRg.png"/></div></div></figure><p id="e0d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对字符串长度的初步观察并没有显示不匹配字符串的长度与整个数据集的长度有很大不同，所以这不太可能是罪魁祸首。</p><p id="5be8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我将错误标注的单词数与正确标注的单词数进行了对比，包括有无停用词。在每一个例子中，除了两个词“cam”和“hex”之外，计数看起来都很相似。带有这些词的帖子往往会被贴错标签。这些都是指一种攀岩装备，我认为它们因为不同的原因被贴错了标签。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ld"><img src="../Images/5a4b2c0e9734154a0e6cd36b0a58311d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ttASRDJRSoAdZfgvdEUWw.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">Sentiment about hexes is quite controversial. Sentiment about cams are more often listed as neutral. Notice the difference in the number of examples; cams are far more popular than hexes.</figcaption></figure><p id="55ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Hexes是“老派”设备，可以工作，但已经过时了。因此，人们不再真的购买它们，在论坛上有很多关于它们是否仍然有用的复杂感觉。当主题是hexes时，这可能混淆了分类情绪的模型。</p><p id="6917" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当gear有大减价时，人们通常会在论坛上发布相关信息。当我标记数据时，如果帖子只是“网站上的摄像头有25%的折扣”，我会将其标记为中性。相机很贵，经常打折，登山者需要很多，所以相机上的销售经常贴出来；所有这些帖子都被标为中立。关于哪种cam是最好的，也有很多争论，这可能导致句子有多种情绪，导致标签出来是中性的。此外，当推荐用于特定攀登的齿轮时，人们以中性的方式谈论凸轮。我认为这些事情导致我的模型相信凸轮几乎总是中立的。</p><p id="0ff1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总之，我的模型在以下情况下混淆了情绪:</p><ol class=""><li id="424b" class="kj kk hh ig b ih ii il im ip kl it km ix kn jb ko kp kq kr bi translated">当有一个销售提到:<em class="le">“25%的黑钻相机，市场上最好的”</em>真:2，标签:1</li><li id="3364" class="kj kk hh ig b ih ks il kt ip ku it kv ix kw jb ko kp kq kr bi translated">当帖子与爬山没有直接关系:<em class="le">“共和党不支持我们使用公共土地”</em>真:0，标签:1(我怀疑这是因为我的模型不是为此训练的)</li><li id="fbb3" class="kj kk hh ig b ih ks il kt ip ku it kv ix kw jb ko kp kq kr bi translated">提到平行裂纹时:<em class="le">“凸轮对平行裂纹有好处”</em>真:2，标号:0(我怀疑这是因为凸轮是唯一一种在平行裂纹中工作良好的齿轮。大多数帖子都说“三头肌很好，除非它是平行裂缝。”)</li><li id="9774" class="kj kk hh ig b ih ks il kt ip ku it kv ix kw jb ko kp kq kr bi translated">当提到hexes时:<em class="le">“Hexes对你的第一个机架来说很好。”</em>真:2，标签:0</li></ol><p id="62f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过这个项目，我希望确定在分析利基在线论坛上的情绪时，一个大的、不太相关的数据集是否比一个小的、更相关的数据集更好。我的模型有最多的训练样本，表现最好。然而，不清楚这是因为更多的例子更相关，还是仅仅因为更多的例子。</p><p id="0391" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我有额外的路线数据(投票数为9或更少的路线)。虽然我怀疑这个数据可能不太可靠，但在后续实验中可能会有用。我可以只根据不同大小的路线数据来训练模型，直到我收集了116，700个样本，然后进行比较。这将告诉我额外的准确性是否仅仅是由于更多的数据，或者小齿轮数据集的特异性是否有所帮助。</p><p id="0c0c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然不能断定包含更小但更相关的标记数据会改进模型，但可以断定更多的数据确实比更少的数据好，即使更大的数据集不太相关。这一点可以从纯齿轮模型和纯路线模型的比较中得到证明。然而，齿轮数据集的相关性可能会也可能不会改善最终模型；要得出这个结论，还需要进一步的实验。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="97ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第四步:分析结果</strong></p><p id="af56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，是时候给论坛贴上标签了，这样我就可以对它们进行一些分析，看看登山者对装备的真实感受。</p><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="277b" class="kb kc hh jx b fi kd ke l kf kg">rom transformers import pipeline<br/>from transformers import AutoTokenizer, TFAutoModelForSequenceClassification<br/>from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig, TFAutoModelWithLMHead, TFAutoModel, AutoModel<br/>from transformers import PreTrainedModel<br/><br/>from sklearn.model_selection import train_test_split<br/><br/>import tensorflow as tf<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/><br/>classifier = pipeline('sentiment-analysis')<br/><br/>import random<br/>random.seed(42)<br/><br/>%matplotlib inline</span><span id="39fe" class="kb kc hh jx b fi kh ke l kf kg">#### RERUN YOUR MODEL #####</span><span id="2d4d" class="kb kc hh jx b fi kh ke l kf kg">save_directory = "models/route_model"<br/>config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)<br/>config.output_hidden_states = False<br/>transformer_model = TFAutoModel.from_pretrained(save_directory, from_pt=True, config = config)<br/><br/>input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')<br/>input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')</span><span id="9013" class="kb kc hh jx b fi kh ke l kf kg"># Build model that will go on top of DistilBERT<br/>embedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]<br/>X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)<br/>X = tf.keras.layers.GlobalMaxPool1D()(X)<br/>X = tf.keras.layers.Dense(50, activation='relu')(X)<br/>X = tf.keras.layers.Dropout(0.2)(X)<br/>X = tf.keras.layers.Dense(3, activation='sigmoid')(X)<br/>tf.keras.layers.Softmax(axis=-1)<br/>model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)<br/><br/>for layer in model.layers[:3]:<br/>    layer.trainable = False<br/>    <br/>model.compile(optimizer="Adam", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=["acc"])</span><span id="c120" class="kb kc hh jx b fi kh ke l kf kg"><br/>#### LOAD THE WEIGHTS THAT YOU TRAINED BEFORE AND PREP DATA #####</span><span id="879f" class="kb kc hh jx b fi kh ke l kf kg">model.load_weights('models/final_models/route_only2/route_only2')</span><span id="655c" class="kb kc hh jx b fi kh ke l kf kg"># read in data<br/>df = pd.read_csv('data/all_forums.csv')</span><span id="3b4c" class="kb kc hh jx b fi kh ke l kf kg"># Create X values<br/>tokenizer = AutoTokenizer.from_pretrained(save_directory)<br/>X = tokenizer(<br/>     list(df["text"]),<br/>     padding=True,<br/>     truncation=True,<br/>     return_tensors="tf",<br/>     max_length = 128<br/>    )</span><span id="a1de" class="kb kc hh jx b fi kh ke l kf kg">preds = model.predict([X["input_ids"], X["attention_mask"]])</span><span id="5ae4" class="kb kc hh jx b fi kh ke l kf kg"><br/>#### ADD PREDICTIONS TO THE DATAFRAME ####</span><span id="66b0" class="kb kc hh jx b fi kh ke l kf kg"># Start with the first 5000, then replace the first n rows of the df<br/># For some reason, the merge works better this way.</span><span id="2cfe" class="kb kc hh jx b fi kh ke l kf kg"># Add predicted labels to df<br/>pred_labels = [np.argmax(preds[i], axis = 0) for i in range(len(preds))]<br/>df_small = df.copy()<br/><br/>df_small = df_small[:5000] # remove in full set<br/>df_small["pred_label"] = pred_labels[:5000] # add predicted labels<br/>df_small["text"] = df_small["text"].str.strip().str.lower() # lower and strip whitespace<br/><br/># remove empty rows<br/>df_small['text'].replace('', np.nan, inplace=True)<br/>df_small.dropna(subset=['text'], inplace=True)<br/><br/>#clean index mess<br/>df_small.reset_index(inplace = True) <br/>df_small.drop(["index"], axis = 1, inplace = True)<br/><br/># Get labeled dataframe<br/>labeled_df = pd.read_csv("data/labeled_forum_test.csv")<br/>labeled_df["text"] = labeled_df["text"].str.strip().str.lower()<br/><br/># Now merge<br/>new_df = df_small.merge(labeled_df, how = 'left', on = "text")<br/>print(len(new_df))<br/>print(len(new_df)-len(df_small))</span><span id="b52f" class="kb kc hh jx b fi kh ke l kf kg"># Now get big DF and replace the first n rows<br/># Add predicted labels to df<br/>pred_labels = [np.argmax(preds[i], axis = 0) for i in range(len(preds))]<br/>full_df = df.copy()<br/><br/>full_df["pred_label"] = pred_labels # add predicted labels<br/>full_df["text"] = full_df["text"].str.strip().str.lower() # lower and strip whitespace<br/><br/># remove empty rows<br/>full_df['text'].replace('', np.nan, inplace=True)<br/>full_df.dropna(subset=['text'], inplace=True)<br/><br/>#clean index mess<br/>full_df.reset_index(inplace = True) <br/>full_df.drop(["index"], axis = 1, inplace = True)<br/></span><span id="28df" class="kb kc hh jx b fi kh ke l kf kg">##### COMBINE THE DATAFRAMES AND SAVE #####</span><span id="ef5b" class="kb kc hh jx b fi kh ke l kf kg"># Combine df_small and full_df[len(new_df):]<br/>df_full = new_df.append(full_df[len(new_df):])<br/>df_full = df_full.rename(columns={"sentiment": "true_label"})<br/>df_full.reset_index(inplace = True) <br/>df_full.drop(["index"], axis = 1, inplace = True)</span><span id="70f1" class="kb kc hh jx b fi kh ke l kf kg">df_full.to_csv('data/full_forum_labeled.csv', index = False)</span></pre><p id="5484" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从这里可以做进一步的分析，具体看你想知道什么。下面是一些你下一步可以做什么的例子。我对Mammut有点挑剔，因为我刚刚根据一个山地项目的建议买了一个Mammut背包。</p><ul class=""><li id="da84" class="kj kk hh ig b ih ii il im ip kl it km ix kn jb lf kp kq kr bi translated">攀岩者对装备的评价大多是正面的、负面的还是中性的？</li></ul><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="6ca2" class="kb kc hh jx b fi kd ke l kf kg">df = pd.read_csv('data/full_forum_labeled.csv')<br/>plt.title("Overall Sentiment")<br/>plt.ylabel('Count')<br/>plt.xlabel('Sentiment')<br/>plt.xticks([0,1,2])<br/>plt.hist(df.pred_label)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lg"><img src="../Images/60c0e0d90774b90b5f1eebbd7b8fb4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TxPQk4Un2c41B7NCUwM5Wg.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">It appears that most posts are neutral. This makes sense because climbers are often talking about sales, or recommending gear for a specific climb, both of which I labeled as neutral.</figcaption></figure><ul class=""><li id="4d3c" class="kj kk hh ig b ih ii il im ip kl it km ix kn jb lf kp kq kr bi translated">随着时间的推移，对Mammut的看法有所改变吗？</li></ul><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="3127" class="kb kc hh jx b fi kd ke l kf kg"># Generate dataframe<br/>mammut_df = df[df.text.str.contains("mammut").fillna(False)]<br/>mammut_df["post_year"] = [mammut_df.post_date[i][-4:] for i in mammut_df.index]<br/>mammut_grouped = mammut_df.groupby(["post_year"]).mean()</span><span id="1be2" class="kb kc hh jx b fi kh ke l kf kg"># Create plot<br/>plt.title("Mammut Sentiment Over Time")<br/>plt.ylabel('Average Sentiment')<br/>plt.xlabel('Year')<br/>plt.xticks(rotation=45)<br/>plt.bar(mammut_grouped.index, mammut_grouped.pred_label)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lh"><img src="../Images/8a4d8e5da40611ebcc175e9ca2e2368b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1DieHIKJxoh3hGQkFGzQFA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">It appears that sentiment about Mammut has not changed much over time.</figcaption></figure><ul class=""><li id="c43f" class="kj kk hh ig b ih ii il im ip kl it km ix kn jb lf kp kq kr bi translated">最近加入Mountain Project的登山者对Mammut的感受和很久以前加入的登山者有所不同吗？(帐龄被用来代表作为攀登者的年数；更有经验的攀岩者会有不同的偏好吗？)</li></ul><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="ccfa" class="kb kc hh jx b fi kd ke l kf kg"># Generate dataframe<br/>mammut_df = df[df.text.str.contains("mammut").fillna(False)]<br/>mammut_df["post_year"] = [int(mammut_df.post_date[i][-4:]) for i in mammut_df.index]</span><span id="c73a" class="kb kc hh jx b fi kh ke l kf kg"># Get join dates if available<br/>join_year_list = []<br/>for i in mammut_df.index:<br/>    try:<br/>        join_year_list.append(int(mammut_df.join_date[i][-4:]))<br/>    except:<br/>        join_year_list.append(-1000)</span><span id="2235" class="kb kc hh jx b fi kh ke l kf kg"># Add join year and years as memeber before posting columns, remove missing info<br/>mammut_df["join_year"] = join_year_list<br/>mammut_df["years_as_mem_before_posting"] = mammut_df["post_year"] - mammut_df["join_year"]<br/>mammut_df = mammut_df[mammut_df['years_as_mem_before_posting'] &lt; 900]</span><span id="4d48" class="kb kc hh jx b fi kh ke l kf kg"># groupby<br/>mammut_grouped = mammut_df.groupby(["years_as_mem_before_posting"]).mean()</span><span id="e502" class="kb kc hh jx b fi kh ke l kf kg"># Create plot<br/>plt.title("Mammut Sentiment of Newer vs. Older Accounts")<br/>plt.ylabel('Average Sentiment')<br/>plt.xlabel('Num Years as Member')<br/>plt.xticks(rotation=45)<br/>plt.bar(mammut_grouped.index, mammut_grouped.pred_label)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es li"><img src="../Images/303171425e12a667c9ce8325c88b8e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXP4pr3HNZmdIJTs41N_zA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">This graph compares the age of the account to the average sentiment towards Mammut. There does not appear to be a trend but there is more variance in older accounts, so it is hard to say for sure.</figcaption></figure><ul class=""><li id="68ee" class="kj kk hh ig b ih ii il im ip kl it km ix kn jb lf kp kq kr bi translated">上图中的差异是由于老客户的样本量较小造成的吗？</li></ul><pre class="jl jm jn jo fd jw jx jy jz aw ka bi"><span id="a4c7" class="kb kc hh jx b fi kd ke l kf kg"># Groupby<br/>mammut_grouby_count = mammut_df.groupby(["years_as_mem_before_posting"]).count()</span><span id="3c33" class="kb kc hh jx b fi kh ke l kf kg"># Create plot<br/>plt.title("Count of Account Age that Mentions Mammut")<br/>plt.ylabel('Count')<br/>plt.xlabel('Num Years as Member')<br/>plt.bar(mammut_grouby_count.index, mammut_grouby_count.join_year)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es li"><img src="../Images/1f7e6e62af3b74af3727b486cc0e2db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AluuT6EZs_NUOCebgeRwaQ.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">There are much fewer older accounts, which is why there is more variance in the graph above at the right end of the graph.</figcaption></figure></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="1c52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论</strong></p><p id="c307" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我走过了一个完整的机器学习项目的步骤，包括设定目标，制定计划，收集数据，模型训练和分析，以及结果分析。具体来说，我以MountainProject.com为例，用代码演示了如何使用DistilBERT和迁移学习对未标记数据进行情感分析。虽然我无法断定一个更小、更相关的数据集比一个更大、更不相关的数据集更好(反之亦然)，但我仍然能够给攀岩装备论坛的情绪贴上标签，并从我在那里找到的结果中得出一些结论。</p><p id="b0d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个项目，所有的代码，还有一份报告，都可以在我的<a class="ae jj" href="https://github.com/pdegner/DL_final_project" rel="noopener ugc nofollow" target="_blank"> GitHub账号</a>上找到。</p><p id="4044" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有这些数据集都被<a class="ae jj" href="https://www.kaggle.com/pdegner/mountain-project-rotues-and-forums?select=review_forum.csv" rel="noopener ugc nofollow" target="_blank">发布在Kaggle </a>上。</p><p id="bdcf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请随时在这里留下问题和评论，或者<a class="ae jj" href="https://www.linkedin.com/in/patricia-degner/" rel="noopener ugc nofollow" target="_blank">在LinkedIn </a>上给我发消息。</p><p id="1822" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">感谢您的阅读！</strong></p><p id="09e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">* <em class="le">我用的是DistilBERT而不是BERT，因为它更小，更容易在我的小型本地计算机上运行。虽然精确度不如BERT，但我认为对于这个项目来说已经足够好了。将基本模型从DistilBERT更改为BERT是微不足道的，如果需要的话，会导致更高的精度，但也需要更大的计算能力。</em></p><p id="fc5d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="le">* *为什么评级较少的路由可能会提供不可靠的数据？</em></p><p id="267e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="le">首先，评级越少的路由越容易出现离群值。路线星级完全是主观的，路线的享受程度可能取决于一些因素，如攀登者的力量或高度，人们尝试时的天气如何，以前攀登的路线与这条路线相比如何，等等。在任何路线上，一个人可能认为它很糟糕，而另一个人却喜欢它。因此，随着越来越多的人投票，平均星级变得更加可靠。</em></p><p id="a1e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="le">其次，第一次登高聚会通常会抬高路线的等级，因为建造路线在时间和金钱上都很昂贵。攀岩运动中每个螺栓的成本为5-10美元，所以一个有10-12个螺栓的标准运动攀岩项目的成本大约为100美元，由攀岩者个人支付。每个螺栓可能需要十五分钟到一个小时来放置，每条路线总共需要三至十个小时。没有螺栓传统攀登仍然是一笔大投资；传统攀岩者将承担更大的风险，因为他们不知道安全完成攀岩需要什么装备。寻找潜在的新路线，然后清除路线上的松散岩石、泥土和其他碎片也需要时间。获得在私人或公共土地上攀岩的许可可能会有法律问题。所有这些问题使得路由建立成为非常耗时的过程。对第一个登山队的奖励是他们在指南和登山计划中的名字，他们可以命名路线。然而，许多第一次攀登的人希望其他人也能爬上他们花了这么多心血的路线。因此，第一次登山聚会有时会夸大登山项目的星级，以吸引更多的登山者来尝试。</em></p><p id="8647" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，有时候当地小社区的攀岩者不希望他们的小岩壁上挤满了被众多高星级攀岩吸引的人群。在这种情况下，登山者可能会将好的路线标记为非常差的路线，以吓跑大量的登山者。</p><p id="37a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="le">最后，还有许多“关闭的项目”列在山地项目上。这意味着攀登已经被发现，获得了攀登的许可，并且已经被清洁和栓住(如果有栓住的话)，但是攀登在技术上是非常困难的，并且投入工作来建立它的人还不能攀登它而不跌倒。允许创建者先攀登并命名路线是一种常见的礼貌，因此这些攀登不会有任何攀登，并将有不可靠的星级评定。</em></p></div></div>    
</body>
</html>
<html>
<head>
<title>Overcoming Overfitting with Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用正则化克服过拟合</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/overcoming-overfitting-with-regularization-4064eaf7a3a3?source=collection_archive---------3-----------------------#2022-07-03">https://medium.com/mlearning-ai/overcoming-overfitting-with-regularization-4064eaf7a3a3?source=collection_archive---------3-----------------------#2022-07-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7bb8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">过度拟合是机器学习问题中的一个常见问题，但它可能很难处理。删除某些不重要的特性是处理过度拟合的一种简单方法，但是正则化呢？</p><p id="4b12" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正则化就像是治疗我们倾向于适应或被数据中的噪音分散注意力的方法。如果我们的模型正在学习这种噪音，这将毫无意义，因为这些数据点并不真正代表我们数据的真实属性。</p><p id="b21a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正则化是指修改学习算法以支持“更简单”的预测规则来避免过度拟合的行为。正则化通过约束模型来工作，使得我们的模型不能适应噪声。</p><p id="6991" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们将均方误差(MSE)作为回归模型的损失函数。MSE的工作原理是计算实际值和预测值之差的平方。预测值通过高次多项式获得，而θ值是权重，x是我们的模型使用的特征。请记住，我们的目标是在训练迭代过程中最小化这个MSE值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/85a675cde901cd49c4834187aed42349.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*eF9IdYrAHJ50jDWbpMpkRQ.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jk"><img src="../Images/fde43dc82bd7172a64bbb4a16190221c.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*0u7wiJtwTgYFqTPEI9JiGg.png"/></div></figure><p id="a28d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如上所述，当我们的模型与数据非常吻合时，这意味着我们的模型对于某些特征具有较高的权重值，尽管这些特征并不重要。正则化的主要思想是我们惩罚不重要的特征，特别是惩罚大的权重。</p><p id="99f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记住<strong class="ig hi"> <em class="jl"> </em> </strong>复杂的假设导致过度拟合。正则化的主要思想是改变误差函数来惩罚假设或正则项的复杂性。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jm"><img src="../Images/dda05d825849f5c4fc219b0a373f4610.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*QXwaw5q3GMprqCkyJlWZvw.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx">L2 Regularization (Ridge)</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jr"><img src="../Images/71173e46317050ac4651dff19c713654.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*9vI0YaOrpiehqYca-R0kHg.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx">L1 Regularization (Lasso)</figcaption></figure><p id="9fd9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">λ被称为正则化系数，它控制着我们的模型与数据的吻合程度。L1正则化和L2正则化的主要区别是在上面的公式中使用了平方和绝对值。</p><p id="158f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果系数等于0，解决方案与普通最小二乘线性回归相同。正系数将导致权重的大小小于通常的线性解。</p><p id="600f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果系数处于“好”值，正则化有助于<strong class="ig hi">避免过度拟合</strong>。如果存在与模型不相关的要素，正则化将赋予它们较小但非零的权重(理想情况下，不相关要素的权重应恰好等于0)</p><p id="1b36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们进入代码来证明这一点！</strong></p><p id="cdbe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要导入相关的库，特别是线性回归、Ridge和Lasso，以便对它们进行比较。我们将使用Kaggle的墨尔本房屋快照数据。之后，我们需要选择相关的特征并对空值进行插补。为了简单起见，我们对数据使用一个热编码和标准化。最后，我们可以将它们分成训练集和测试集。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="js jt l"/></div></figure><p id="2b60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在数据准备过程之后，我们准备制作一些模型。首先，我们构建线性回归作为基线。之后，我们可以建立拉索(L2)和里奇(L1)作比较。请注意，当我们定义Lasso或Ridge时，我们可以使用它们的超参数，正如您在sklearn文档中所看到的。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="js jt l"/></div></figure><p id="860d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下表总结了实验结果。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es ju"><img src="../Images/0004c07482e224f630710374d5b9e385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yBBZVCyFeY4qbHxeRHEJ4g.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx">Result table</figcaption></figure><p id="3f3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到，我们的基线模型(线性回归)对数据拟合过度，因为它在训练数据上有很好的表现，但在测试数据上表现不佳。请注意，如果R平方的结果为负，这意味着我们的模型性能更差。</p><p id="ce26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，套索和岭比我们的线性回归表现更好。它显示了测试数据的性能改进，尽管它仍然不是我们的模型所能做到的最好的性能。如前所述，正则化项是这种改进的原因。很好。</p><p id="ae1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论:</strong></p><p id="bbc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正则化可以防止过度拟合。它通过添加正则化项来惩罚某些特征的权重。通过这样做，我们使我们的模型变得简单，并对模型进行约束，这样我们就不能很好地拟合噪声或训练数据。</p></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><p id="9523" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">代码和数据可在<a class="ae kg" href="https://github.com/yogawicaksana/regularization_medium" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</p><p id="4a47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献:</strong></p><ul class=""><li id="8974" class="kh ki hh ig b ih ii il im ip kj it kk ix kl jb km kn ko kp bi translated"><a class="ae kg" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stab/modules/class . html # module-sklearn . linear _ model</a></li><li id="bfa4" class="kh ki hh ig b ih kq il kr ip ks it kt ix ku jb km kn ko kp bi translated"><a class="ae kg" href="https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot" rel="noopener ugc nofollow" target="_blank">https://www . kaggle . com/dataset/dans Becker/Melbourne-housing-snapshot</a></li></ul><div class="kv kw ez fb kx ky"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kz ab dw"><div class="la ab lb cl cj lc"><h2 class="bd hi fi z dy ld ea eb le ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lf l"><h3 class="bd b fi z dy ld ea eb le ed ef dx translated">如何成为移动人工智能的作者</h3></div><div class="lg l"><p class="bd b fp z dy ld ea eb le ed ef dx translated">medium.com</p></div></div><div class="lh l"><div class="li l lj lk ll lh lm ji ky"/></div></div></a></div></div></div>    
</body>
</html>
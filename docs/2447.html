<html>
<head>
<title>SVD and image compression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">奇异值分解和图像压缩</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/svd-and-image-compression-749d59558410?source=collection_archive---------5-----------------------#2022-05-03">https://medium.com/mlearning-ai/svd-and-image-compression-749d59558410?source=collection_archive---------5-----------------------#2022-05-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0bca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我的<a class="ae jc" rel="noopener" href="/mlearning-ai/eigendecomposition-2f04ce896e6f">上一篇文章</a>中，我讨论了特征分解。然而，这只能应用于方阵。一种更通用的方法，奇异值分解(SVD)，被称为线性代数的<em class="jd">基本定理，适用于所有矩阵。</em></p><p id="9f0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我将首先介绍SVD的理论和构造，然后我将向您展示我们如何使用SVD来近似矩阵，从而允许图像压缩。请记住，毕竟，图像只是代表像素颜色的矩阵。</p></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jl"><img src="../Images/31cc169d3895840a59007814c4718fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7L441mCHJH8II8QyT3KqUA.png"/></div></div></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es jx"><img src="../Images/b32413f0b8b1ce7dca070c8c2eb441d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*WlWLHm_wrTDZ3ROh8SMy-A.png"/></div></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jl"><img src="../Images/e571b410068dcff1fc71697736449529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MwzzH5dnPwBEq8TL5MP7Nw.png"/></div></div></figure><p id="aad1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">价值观:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es jy"><img src="../Images/420e7955f2067b945b82b93db1133a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*zpdaJ1VCEXgmzqEvIWzKDg.png"/></div></figure><p id="4c7a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">都称为奇异值，有<strong class="ig hi"> r </strong>这样的值(<strong class="ig hi"> r </strong>是矩阵<strong class="ig hi">T9】AT11】的秩)。按照惯例，它们是按降序排列的。此外，奇异值矩阵<strong class="ig hi"><em class="jd">σ</em></strong>是唯一的，并且与矩阵<strong class="ig hi"><em class="jd"/></strong>的大小相同。</strong></p><p id="cfb9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">矩阵<strong class="ig hi"> <em class="jd"> U </em> </strong>的列向量称为左奇异向量，矩阵<strong class="ig hi"><em class="jd"/></strong>的列向量称为右奇异向量。</p><h2 id="a5e4" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">SVD分解的直觉是什么？</h2><p id="8d21" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">设<strong class="ig hi"> <em class="jd"> A </em> </strong>是将向量空间<strong class="ig hi"> R </strong> <em class="jd"> {mxm} </em>映射到向量空间<strong class="ig hi">R</strong><em class="jd">【nxn }</em>上的线性映射的变换矩阵。SVD将这个线性映射分解成三个部分。</p><ol class=""><li id="5e54" class="kz la hh ig b ih ii il im ip lb it lc ix ld jb le lf lg lh bi translated">矩阵<strong class="ig hi"> <em class="jd"> V </em> </strong>是<strong class="ig hi"> R </strong> <em class="jd"> {n} </em>中的变换矩阵，执行从<strong class="ig hi">a</strong>^<em class="jd">{ t }</em><strong class="ig hi">a</strong>的特征基到标准基的变换。因为<strong class="ig hi"> <em class="jd"> V </em> </strong>是正交的，所以它成立:</li></ol><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es li"><img src="../Images/f7bc7238e38166803684941e6043925c.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/format:webp/1*Z8soHKzabY2o_oVFiKyqUg.png"/></div></figure><p id="5577" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以首先，<strong class="ig hi"><em class="jd">v</em></strong>^<em class="jd">{ t }</em>执行一个从标准基到本征基的基变换<strong class="ig hi"><em class="jd"/></strong>^<em class="jd">{ t }</em><strong class="ig hi"><em class="jd"/></strong>。</p><p id="a698" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.<strong class="ig hi"><em class="jd"/></strong>σ矩阵通过奇异值缩放新坐标并将<strong class="ig hi"><em class="jd">a</em></strong>^<em class="jd">{ t }</em><strong class="ig hi"><em class="jd">a</em></strong>的本征基映射到<strong class="ig hi"><em class="jd">aa</em></strong>^<em class="jd">{ t }</em>。</p><p id="4495" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<strong class="ig hi"> <em class="jd"> U </em> </strong>是将特征基映射到<strong class="ig hi"> R </strong> <em class="jd"> {m} </em>的标准基的变换矩阵。</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lj"><img src="../Images/5ff13e1a9b423e2cd3047171e526530b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JQZcdlISts8UhZXE-g9Ndw.png"/></div></div></figure><p id="0a2c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在SVD中，在<strong class="ig hi"> R </strong> <em class="jd"> {mxm} </em>和<strong class="ig hi"> R </strong> <em class="jd"> {nxn} </em>向量空间中都有基的变化，然而，在特征分解中，在同一向量空间中只有一个基的变化。</p><h2 id="634a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">奇异值分解的构造</h2><p id="d459" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">首先，让我们回忆一下矩阵对称半正定(SPD)是什么意思。对称矩阵满足</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es li"><img src="../Images/bae6d717c32f93283f88b5e267b26525.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/format:webp/1*05gwglDz3sF-6MtgjnGvew.png"/></div></figure><p id="e22f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于所有的<em class="jd"> x </em>。</p><p id="45d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们有任何一个矩阵<strong class="ig hi"> <em class="jd">一个</em> </strong>，我们可以使SPD矩阵为:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lk"><img src="../Images/3a79caa21758e18e110a4101023449c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:156/format:webp/1*ckiDnM9HdWgNPgjDl8WRGw.png"/></div></figure><p id="a97d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es ll"><img src="../Images/dee0c68f97df4b15f57e99f61bcba60c.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*u8c--QN18ghcgrTxzGIVHg.png"/></div></figure><p id="7f34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样代表:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lk"><img src="../Images/455dce0709dfb9c81622ebd8fefa7f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:156/format:webp/1*xJq5gj56-fZGb19FElyAhw.png"/></div></figure><p id="385f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们知道，我们可以用特征向量的标准正交基计算半正定矩阵的特征分解。因此，我们可以得到:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lm"><img src="../Images/6abb49c52b2326ab3fe396561eb5e486.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*9JJrrcpIlklcocE1uO5qKQ.png"/></div></div></figure><p id="a26f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<strong class="ig hi"> <em class="jd"> P </em> </strong>为特征向量的正交基，对角矩阵包含正特征值。</p><p id="3808" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设奇异值分解存在:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es ln"><img src="../Images/2743e6396de33518adfa984eabd1d6c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*JwV3qZpaljvQt7rI_4DfZg.png"/></div></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lm"><img src="../Images/4f3aae4eb6b4e89bc67747abbdcf1b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*zR-Opvu45B-54a932gZPxQ.png"/></div></div></figure><p id="8d2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将las方程与本征分解比较可以看出，<strong class="ig hi"> <em class="jd"> P </em> </strong>是一个右奇异向量<strong class="ig hi"><em class="jd">V</em></strong>of<strong class="ig hi"><em class="jd"/></strong>的矩阵，本征值是奇异值的平方。</p><p id="2ea0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">至此，我们确定了什么应该是<strong class="ig hi"> <em class="jd"> P </em> </strong>矩阵和<strong class="ig hi"><em class="jd">σ</em></strong>矩阵，但是我们需要构造<strong class="ig hi"><em class="jd"/></strong>。</p><p id="2c9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意矩阵<strong class="ig hi"> <em class="jd"> V </em> </strong>:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lo"><img src="../Images/e705a46e5e334891ddf974a4f32c24f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*YNXQ25dVdSAGzsxPngzsbw.png"/></div></figure><p id="4862" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另外，在变换矩阵<strong class="ig hi"><em class="jd"/></strong>下，正交的<strong class="ig hi"> <em class="jd"> V </em> </strong>的向量列的图像也必须正交。</p><p id="bdb9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">再次假设SVD存在，请看:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lp"><img src="../Images/5111d6e8a75fdde1ba12f5e6d60b767b.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*zdRJkUjKjEFG9igxUMswOg.png"/></div></figure><p id="e3c5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">谱定理告诉我们，我们可以用标准正交特征向量对角化矩阵:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lq"><img src="../Images/dc19c1e3061a09ae8569122df351dfdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*ptLaeBCkFlSzNqxDGi0vNw.png"/></div></figure><p id="da38" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd"> AA </em> </strong> ⊤的标准正交特征向量是左奇异向量<strong class="ig hi"><em class="jd"/></strong>并构成标准正交基集。</p><p id="ac32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，AV形成了一个标准正交基<strong class="ig hi"> <em class="jd"> AA </em> </strong> ⊤ A，但也u .然而，我们知道:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lr"><img src="../Images/21804aaaf59c5d6e9dbe7c6f45e1c741.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*0REX25dFTd98grvIc1IJxQ.png"/></div></figure><p id="b8c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，获得<strong class="ig hi"> <em class="jd"> U </em> </strong>的方法就是将<strong class="ig hi"> <em class="jd"> AV </em> </strong>:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lr"><img src="../Images/cd12cffe08365f5105968c5bf994525a.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*QkX79MhXO634xJ9_9dBgIA.png"/></div></figure><p id="0bc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于j的所有值，我们得出:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lr"><img src="../Images/0dbcbec35ba795321f023b68b074e3b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*cWN2ruVi3C02p5V_tXnAvQ.png"/></div></figure><p id="de2b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是<strong class="ig hi">的SVD分解<em class="jd">一</em>一</strong>。</p><h2 id="1dd9" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">矩阵近似</h2><p id="244e" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">通过奇异值分解，我们得到:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es ls"><img src="../Images/a3a5187256b552491d3ab0a7450cccc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*wWj3T7tLlN7KbFd7fQEkzA.png"/></div></figure><p id="84b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们也可以把它写成:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es ls"><img src="../Images/839e3abf2ee52d7447c6c0a5be52d9e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*k6SaDwsMkXE0RNNEImGbBA.png"/></div></figure><p id="eab6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们知道奇异值是降序排列的，第一个元素对结果的贡献更大。尝试去掉后面的部分是有意义的，这样可以有更小的维数，从而有更快的算法。</p><p id="ca05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是我们如何执行秩k近似。我们只取若干个第一列向量<strong class="ig hi"><em class="jd"/></strong>和同样数量的第一行向量<strong class="ig hi"><em class="jd"/></strong>并计算结果。</p><p id="0eeb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是例子。使用的图片是:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es lt"><img src="../Images/03bf2f6c6311a2cd6261cb74292a335d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PErT44ZA3hLDeO-92a4tUg.jpeg"/></div></div></figure><p id="e340" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图像的大小为1240x1280。</p><p id="9536" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用python中的numpy，我计算了图像的SVD分解，并尝试用10、20、30、40和50个第一列来近似图片。下面是我用代码得到的结果，可以在这里找到<a class="ae jc" href="https://github.com/Una865/SVD-approximation/blob/main/svd.py" rel="noopener ugc nofollow" target="_blank"/>:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lu"><img src="../Images/344c4baa6fea316a9a6d74d120be61e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*ulHBSDha1NC79MyMhXKsMg.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx">n = 10</figcaption></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lu"><img src="../Images/0f5f6ada659f12c156d29e9c8fb6b691.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*hmh58jZPOsrzIIKnXGX5LQ.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx">n = 20</figcaption></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lu"><img src="../Images/d2d6f2ece765f613cce7c5cdcd2bb25c.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*71a2g5s6KSEUqSXA8gpqsA.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx">n = 30</figcaption></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lu"><img src="../Images/1b046a266fee230b080578322661226a.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*ueiVJoPPlpqbRBBHk-BP-A.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx">n = 40</figcaption></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es lu"><img src="../Images/89fb5a19aaae84615ab405cbda4fc708.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*PNHaxUrBirQuDFry2PJzUQ.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx">n = 50</figcaption></figure><p id="19b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后一张图是最初形象的伟大代表。它只包括大约7%的数字。(50*(1240+1+1280)/(1240*1280)).太神奇了:)</p><h2 id="1bd1" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">结论</h2><p id="6739" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">当我们想要通过近似来执行数据压缩时，SVD允许我们识别数据中的异构性。它是一种适用于非方阵和数据表的方法，这使得它的应用非常广泛。</p><p id="0b66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还要记住的是，线性代数是一个非常强大的工具！</p><div class="lz ma ez fb mb mc"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="md ab dw"><div class="me ab mf cl cj mg"><h2 class="bd hi fi z dy mh ea eb mi ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mj l"><h3 class="bd b fi z dy mh ea eb mi ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mk l"><p class="bd b fp z dy mh ea eb mi ed ef dx translated">medium.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq jv mc"/></div></div></a></div></div></div>    
</body>
</html>
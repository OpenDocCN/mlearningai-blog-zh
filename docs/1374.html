<html>
<head>
<title>What data scientists keep missing about imbalanced datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于不平衡的数据集，数据科学家们一直忽略了什么</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/what-data-scientists-keep-missing-about-imbalanced-datasets-d1f10e808297?source=collection_archive---------0-----------------------#2021-12-04">https://medium.com/mlearning-ai/what-data-scientists-keep-missing-about-imbalanced-datasets-d1f10e808297?source=collection_archive---------0-----------------------#2021-12-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/add0fa4fb1791afb8841f2b8306e84bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*zvrOYxt21x0Ypn4pmCTL5w.png"/></div><figcaption class="il im et er es in io bd b be z dx">Figure 1: (<a class="ae ip" href="https://unsplash.com/photos/JKUTrJ4vK00" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/JKUTrJ4vK00</a>)</figcaption></figure><p id="c924" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">许多数据科学家未能完全理解不平衡数据集导致的问题以及缓解这些问题的方法。</p><p id="791b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">作为数据科学家，我们会遇到许多不同的数据集，其中某些类型的数据实例(称为多数类)明显占优势，而其他类型的数据实例(少数类)则明显不足。这对于数据科学的实践具有重要意义，在数据科学中，简单地在具有这种特征的数据集上训练模型可能会导致偏向大多数类。例如，如果我们专注于预测心脏病，并有一个数据集，其中20人患有心脏病，80人没有，我们可以有一个模型，每次都预测没有疾病，因此实现了80%的可靠准确性得分和88%的F1得分。</p><p id="3750" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">尽管这是一个众所周知的问题，但在太多的情况下，数据科学家忽略了这个问题，只是训练了一个模型，而没有真正理解数据集中的不平衡。这篇文章的目的是给你一些简单的方法来解决这个问题。请注意，没有一种方法是完美的，因此，你需要对问题有深刻的理解，并有广泛的解决方案。</p><p id="229b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jo">不平衡数据集的问题特征</em></p><p id="fa11" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">首先，重要的是要理解为什么不平衡数据集是一个需要解决的关键问题。我们可以从关键数据问题的角度来看这个问题:</p><p id="a434" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">1.小间断</p><p id="bb56" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">解释</em>:当数据集的聚类错误分类率比总体错误分类率高得多时，就会出现小析取问题。</p><p id="a143" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">这怎么是个问题？</em>:这对于以分治为中心的算法是有问题的，例如决策树，其中某些实例类型，即那些具有少数类的实例类型，可能具有非常差的分类性能。</p><p id="47bc" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">2.缺乏密度</p><p id="e7b2" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">解释</em>:缺少部分班级的资料。</p><p id="9a11" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">这怎么是问题</em>？:归纳算法没有足够的数据来概括样本的分布，少数类别最有可能在模型中被歪曲。</p><p id="d103" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">3.噪声数据</p><p id="ce5a" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">解释</em>:数据集中噪声的存在对少数类的影响大于对其他类的影响。</p><p id="9918" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">这怎么是问题</em>？:噪声将在更大程度上影响少数类，从而显著影响模型。</p><p id="8727" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">4.数据集移位</p><p id="94f8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">解释</em>:当训练和测试数据集遵循不同的分布时，会出现这种情况。这是一个常见的问题，会影响各种分类问题，通常是样本选择偏差的结果。</p><p id="5182" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">- <em class="jo">这怎么成问题了？</em>:对于高度不平衡的数据集，少数类对分类错误特别敏感，因此受偏移的影响更大。</p><p id="0a66" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jo">数据引导技术解决此问题</em></p><p id="f9e8" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">数据导向技术旨在通过增加转换数据集中少数类的表示(过采样)或减少多数类的表示(欠采样)来减少代表不足类和代表过多类之间的比率偏差，其中模型可以成功地在转换数据集中进行训练。下图给出了可以使用的各种技术的更详尽的列表，但是在本文中，我们将重点关注三种最常用的技术；随机过采样、随机欠采样和SMOTE。</p><figure class="jq jr js jt fd ii er es paragraph-image"><div class="er es jp"><img src="../Images/9057e3a32faff577b6545886e3afb75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*qLEDoVvVqYpSlvdYV-n9bQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Figure 2: examples of data level approaches to the problem of imbalanced datasets</figcaption></figure><p id="e109" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jo">随机过采样</em></p><p id="9183" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">随机过采样是从少数类中随机复制样本并将其添加到训练数据集中的过程，目的是获得更加平衡的数据集。虽然这是一个相对简单的过程，但天下没有免费的午餐，过采样也不例外，因为它会导致模型过度拟合。</p><p id="dedc" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">该方法的简单本质意味着它很容易使用Python实现。下面的函数显示了当我们的数据集中有一个二进制目标类(1或0)时，从头开始实现过采样。所有函数的代码和使用的<a class="ae ip" href="https://www.kaggle.com/arashnic/imbalanced-data-practice" rel="noopener ugc nofollow" target="_blank">数据集</a>可以在这个<a class="ae ip" href="https://github.com/patstew123/Imbalanced-datasets" rel="noopener ugc nofollow" target="_blank"> github链接</a>中找到。</p><figure class="jq jr js jt fd ii"><div class="bz dy l di"><div class="ju jv l"/></div></figure><p id="a117" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jo">随机欠采样</em></p><p id="5d85" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">随机欠采样是从多数类中随机移除实例的过程。这导致变换数据集中多数类的示例数量大大减少。与过采样相比，欠采样不太常用，在少数分类中存在大量实例的情况下，欠采样更为适用，因此仍然可以获得有用的模型。如前所述，天下没有免费的午餐，这种技术会丢失信息，因为被删除的多数类中的实例可能对定义明确的决策边界的生成至关重要。</p><p id="49ad" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">下面的函数显示了当我们的数据集中有一个二进制目标类(1或0)时，欠采样的从头实现。所有函数的代码和使用的<a class="ae ip" href="https://www.kaggle.com/arashnic/imbalanced-data-practice" rel="noopener ugc nofollow" target="_blank">数据集</a>可以在这个<a class="ae ip" href="https://github.com/patstew123/Imbalanced-datasets" rel="noopener ugc nofollow" target="_blank"> github链接</a>中找到。</p><figure class="jq jr js jt fd ii"><div class="bz dy l di"><div class="ju jv l"/></div></figure><p id="33ce" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jo">重击</em></p><p id="2137" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">如前所述，随机过采样远非完美，更好的方法是在拟合模型之前综合少数类中的样本。合成少数过采样技术(SMOTE)是实现这一点的一种方法。</p><p id="2672" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">SMOTE通过在少数类中随机选择一个实例来工作。然后找到该实例的k个最近邻居(例如knn = 5)，随机选择这些最近邻居中的一个。由此，新的合成实例被创建为目标数据点和目标选择的最近邻数据点的凸组合。</p><p id="4745" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这种方法已经被证明是有效的，但是当少数民族和多数民族之间有明显的重叠时，这种方法就不那么适用了。在这种情况下，如果经常使用的最近邻是相反的类别，则创建的合成数据可能有些不明确。</p><p id="e716" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">下面的代码展示了如何使用不平衡学习包(pip install unbalanced-learn)实现SMOTE。所有函数的代码和使用的<a class="ae ip" href="https://www.kaggle.com/arashnic/imbalanced-data-practice" rel="noopener ugc nofollow" target="_blank">数据集</a>可以在这个<a class="ae ip" href="https://github.com/patstew123/Imbalanced-datasets" rel="noopener ugc nofollow" target="_blank"> github链接</a>找到。</p><figure class="jq jr js jt fd ii"><div class="bz dy l di"><div class="ju jv l"/></div></figure><p id="b6df" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="jo">结论</em></p><p id="ccd7" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在，你知道了，这篇文章向你展示了三种简单的方法来改善不平衡数据集的问题。请注意，这些方法没有一个是放之四海而皆准的，很好地掌握图2中提到的一系列技术是必不可少的。此外，在算法、成本敏感和/或特征级别，还有其他更广泛的方法来处理不平衡数据集。</p><p id="3466" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">更多更新请关注我:<a class="ae ip" href="https://twitter.com/Patrick74925271" rel="noopener ugc nofollow" target="_blank">https://twitter.com/Patrick74925271</a></p><div class="jw jx ez fb jy jz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ka ab dw"><div class="kb ab kc cl cj kd"><h2 class="bd hi fi z dy ke ea eb kf ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kg l"><h3 class="bd b fi z dy ke ea eb kf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kh l"><p class="bd b fp z dy ke ea eb kf ed ef dx translated">medium.com</p></div></div><div class="ki l"><div class="kj l kk kl km ki kn ij jz"/></div></div></a></div></div></div>    
</body>
</html>
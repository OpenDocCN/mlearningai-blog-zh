<html>
<head>
<title>Lessons Learned While Scraping Data From Dynamic Sites for my Regression ML Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为我的回归ML项目从动态站点收集数据时学到的经验教训</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/lessons-learned-while-scraping-data-from-dynamic-sites-for-my-regression-ml-project-c7f52e5ef7ea?source=collection_archive---------4-----------------------#2022-01-11">https://medium.com/mlearning-ai/lessons-learned-while-scraping-data-from-dynamic-sites-for-my-regression-ml-project-c7f52e5ef7ea?source=collection_archive---------4-----------------------#2022-01-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/f2bc025c2fa7cdaea5aeef6c6c769e13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-uOd4uP3LIABwGdTtolFkA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo Credit: Shutter Stock</figcaption></figure><p id="3390" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">希望这篇文章是关于分享我的经验，关于我用“两行代码”抓取一个网站赚了多少钱，或者“我如何创建一个爬虫来运行它几年”。但我的目标是从<strong class="iv hi">Indeed.com</strong>收集工资数据，或者从<strong class="iv hi">Zillow.com</strong>收集房地产数据，但不幸的是，由于动态HTML内容，我无法成功收集数据，或者从<strong class="iv hi"> Youtube </strong>或<strong class="iv hi">Medium.com</strong>上获得的任何教程都是有用的。</p><p id="e21c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我追求Zillow的动机是为了给我的数据添加更多的“特征”,因为他们有学校评级信息。由于搜集到的数据将被用来创建一个讨论学校评级和房价之间关系的线性回归算法，Zillow更有意义。</p><p id="c6ae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Zillow方面的另一个发展是，他们大约在一年前放弃了他们的免费API。现在它是通过另一个平台提供的，你需要被邀请到这个平台。</p><p id="571c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因为这已经成为我想要克服的一个挑战，我必须找到一种方法从网站上提取至少一些数据。在这种情况下，我使用了<strong class="iv hi"> Apify </strong>，它使用后端的<strong class="iv hi">木偶师</strong>来抓取您想要抓取的页面。你可以查看<a class="ae jr" href="https://www.youtube.com/watch?v=i2Dy9fDqbRk" rel="noopener ugc nofollow" target="_blank">这个视频</a>了解详细的使用信息。</p><p id="db14" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">警告</strong>:我意识到的一个共同点是，Youtube上的大多数教程(如果不是全部的话)都已经超过一年了，所以当你查看它们的时候，它们页面的动态内容可能已经在这些网站上被改变了。此外，他们主要是解决静态网站，表格，等创造内容，所以他们大多数只是点击诱饵这一点。</p><h1 id="5a95" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">议程</h1><ol class=""><li id="7d42" class="kq kr hh iv b iw ks ja kt je ku ji kv jm kw jq kx ky kz la bi translated">网络抓取与网络爬行</li><li id="3e0f" class="kq kr hh iv b iw lb ja lc je ld ji le jm lf jq kx ky kz la bi translated">你能做什么？</li><li id="6b79" class="kq kr hh iv b iw lb ja lc je ld ji le jm lf jq kx ky kz la bi translated">"/robots.txt "的事情</li></ol><p id="38f7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我写这篇文章的目的不是教你如何抓取网页，而是在一些最常用的工具中，帮助你克服一些你可能会遇到的陷阱。</p></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><h1 id="c314" class="js jt hh bd ju jv ln jx jy jz lo kb kc kd lp kf kg kh lq kj kk kl lr kn ko kp bi translated">1.网络抓取与网络爬行</h1><p id="1bef" class="pw-post-body-paragraph it iu hh iv b iw ks iy iz ja kt jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">本质上，我们想做网络抓取，但因为我以前有过这种困惑，所以我想谈谈不同之处。根据维基百科的说法，</p><blockquote class="lv lw lx"><p id="360c" class="it iu ly iv b iw ix iy iz ja jb jc jd lz jf jg jh ma jj jk jl mb jn jo jp jq ha bi translated"><strong class="iv hi">网页抓取</strong>、<strong class="iv hi">网页抓取</strong>或<strong class="iv hi">网页数据提取</strong>是用于从网站中提取数据的数据抓取。网络抓取软件可以使用超文本传输协议或网络浏览器直接访问万维网。虽然web抓取可以由软件用户手动完成，但该术语通常指的是使用bot或web crawler实现的自动化过程。这是一种复制形式，从网络上收集并复制特定的数据。</p></blockquote><p id="5d2f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">它也包含了一些网络爬行的元素。但是网络爬行通常是指搜索引擎所做的事情。它更多的是索引，而不是显示网页的全部内容。</p><h1 id="2712" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak"> 2。你能做什么？</strong></h1><p id="4970" class="pw-post-body-paragraph it iu hh iv b iw ks iy iz ja kt jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">通过使用应用最多的三个库<em class="ly"> BeautifulSoup，Requests和硒</em>。</p><p id="3d2d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过使用<em class="ly"> BeautifulSoup </em>库；</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="aa7a" class="ml jt hh mh b fi mm mn l mo mp">from<!-- --> <!-- -->urllib.request<!-- --> <!-- -->import<!-- --> <!-- -->urlopen<br/>from<!-- --> <!-- -->bs4<!-- --> <!-- -->import<!-- --> <!-- -->BeautifulSoup</span><span id="3223" class="ml jt hh mh b fi mq mn l mo mp">url = ''<br/>html<!-- --> <!-- -->=<!-- --> <!-- -->urlopen(url)<br/>bs<!-- --> <!-- -->=<!-- --> <!-- -->BeautifulSoup(html,<!-- --> <!-- -->'html.parser')<br/><br/>for<!-- --> <!-- -->child<!-- --> <!-- -->in<!-- --> <!-- -->bs.find('table',{'id':'giftList'}).children:<br/> <!-- --> <!-- --> <!-- --> <!-- -->print(child)</span></pre><p id="f8b8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">作为一个自然的Selenium用户，我对该工具的第一印象是，因为我觉得不需要它。但是随着我开始在更多的项目中使用它，并将其与Selenium结合，我意识到它可以产生一些美好的东西。</p><p id="2aae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过使用<em class="ly">请求</em>；</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="c60e" class="ml jt hh mh b fi mm mn l mo mp">import requests<br/>from pandas.io.json import json_normalize<br/><br/>url = 'url you want to scrape'<br/>jsonData = requests.get(url).json()<br/><br/>table = json_normalize(jsonData['data'])</span></pre><p id="bc35" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">你可以点击查看请求文档<a class="ae jr" href="https://docs.python-requests.org/en/latest/" rel="noopener ugc nofollow" target="_blank">。它确实返回JSON格式，你只需要从那里开始。</a></p><p id="912c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">或者使用Selenium WebDriver</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="df8b" class="ml jt hh mh b fi mm mn l mo mp">from selenium import webdriver<br/>from selenium.webdriver.common.by import By<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>import time<br/>import json<br/><br/>driver=webdriver.Chrome(executable_path='./chromedriver.exe')<br/>driver.get(url)<br/>rating=WebDriverWait(driver, 10).until(<br/>        EC.presence_of_all_elements_located((By.XPATH, 'your xpath locator'))<br/>    )</span></pre><p id="eb13" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Selenium WebDriver是一个自动化工具，通过使用CSS选择器、Xpath、Id、Name等定位器来定位网站DOM，从而帮助您自动化浏览器的移动。它是自动化测试人员中常用的工具，编写的测试可能不可靠，因为如果DOM中有任何变化，工具就不可能找到某个项目。上面是一些样板代码，你可以用来开始你的旅程。此外，通过使用CroPath Chrome扩展，您可以通过查找相对和绝对Xpaths来轻松定位元素。</p><p id="64e2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">该工具的另一个问题是它处理AJAX调用。AJAX = <strong class="iv hi"> A </strong>同步<strong class="iv hi">J</strong>avaScript<strong class="iv hi">A</strong>nd<strong class="iv hi">X</strong>ML。你可以在这里获得更多关于它的信息，但总而言之，它是</p><blockquote class="lv lw lx"><p id="69dd" class="it iu ly iv b iw ix iy iz ja jb jc jd lz jf jg jh ma jj jk jl mb jn jo jp jq ha bi translated">AJAX允许通过在后台与web服务器交换数据来异步更新网页。这意味着可以更新网页的一部分，而不需要重新加载整个页面。</p></blockquote><p id="2929" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这也是测试自动化工程师的噩梦。因为Selenium(不像Cypress)在浏览器上工作，它对AJAX调用没有任何控制。这里的<a class="ae jr" href="https://www.selenium.dev/documentation/webdriver/waits/" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi">等待</strong> </a>前来救援。等待只是让用户显式或隐式地等待，直到预期的元素加载。</p><p id="b024" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">示例代码:</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="6dbb" class="ml jt hh mh b fi mm mn l mo mp">from selenium.webdriver.support.ui import WebDriverWait<br/><br/>driver.navigate("file:///race_condition.html")<br/>el = WebDriverWait(driver).until(lambda d: d.find_element_by_tag_name("p"))<br/>assert el.text == "Hello from JavaScript!"</span></pre></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><p id="6bb5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在忘记提及之前，我还被Zillow和Realtor禁止使用Selenium，所以请确保您将<strong class="iv hi"> <em class="ly"> sleep() </em> </strong>方法添加到您的调用中。或者更好的选择是使用代理。却被告知代理是为了安全<a class="ae jr" href="https://www.itbriefcase.net/4-vulnerabilities-of-a-proxy-server" rel="noopener ugc nofollow" target="_blank">T5】漏洞T7】而开放的。这里有一个代码示例，用于检查代理是否工作，然后您可以使用它使您的代码在站点上运行。</a></p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="2d2c" class="ml jt hh mh b fi mm mn l mo mp"># Import the required Modules<br/>import requests</span><span id="a8a3" class="ml jt hh mh b fi mq mn l mo mp"># Create a pool of proxies<br/>proxies = {<br/> '<a class="ae jr" href="http://114.121.248.251:8080'" rel="noopener ugc nofollow" target="_blank">http://'</a>,<br/> '<a class="ae jr" href="http://222.85.190.32:8090'" rel="noopener ugc nofollow" target="_blank">http://'</a>,<br/> '<a class="ae jr" href="http://47.107.128.69:888'" rel="noopener ugc nofollow" target="_blank">http://'</a>,<br/> <br/>}</span><span id="80f8" class="ml jt hh mh b fi mq mn l mo mp">url = '<a class="ae jr" href="https://ipecho.net/plain'" rel="noopener ugc nofollow" target="_blank">'</a></span><span id="87aa" class="ml jt hh mh b fi mq mn l mo mp"># Iterate the proxies and check if it is working.<br/>for proxy in proxies:<br/> try:<br/>  page = requests.get(<br/>  url, proxies={"http": proxy, "https": proxy})</span><span id="b927" class="ml jt hh mh b fi mq mn l mo mp"># Prints Proxy server IP address if proxy is alive.<br/>  print("Status OK, Output:", page.text)</span><span id="6c03" class="ml jt hh mh b fi mq mn l mo mp">except OSError as e:</span><span id="a75f" class="ml jt hh mh b fi mq mn l mo mp"># Proxy returns Connection error<br/>  print(e)</span></pre></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><h1 id="46a2" class="js jt hh bd ju jv ln jx jy jz lo kb kc kd lp kf kg kh lq kj kk kl lr kn ko kp bi translated">3."/robots.txt "的事情🤔</h1><figure class="mc md me mf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/9707427f727ea62dc506c16500e3b99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HR8G9C-6pyHtrOXVJXPlbQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Screenshot credit to the article writer</figcaption></figure><p id="fa46" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">当你在网站URL后添加“/robots.txt”时，它会告诉你什么是允许的，什么是不允许的。从我尝试抓取的三个网站可以看出，他们倾向于不允许抓取任何内容？！</p></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><h2 id="acb1" class="ml jt hh bd ju ms mt mu jy mv mw mx kc je my mz kg ji na nb kk jm nc nd ko ne bi translated">结论</h2><p id="6c9f" class="pw-post-body-paragraph it iu hh iv b iw ks iy iz ja kt jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">如果你需要处理房地产数据，我建议你去看看其他的房地产网站，比如世纪21或realtor.com。你可能会有更好的运气。在刮<strong class="iv hi">Indeed.com</strong>方面，我诚实的反馈是不要尝试。Indeed.com是一个非常混乱的地方，大多数工作甚至没有工资信息或范围共享。但是如果你想浏览Craigslist这样的网站，你可以在这里找到一个我在<a class="ae jr" href="https://github.com/METIS-DATA-SCIENCE-PROJECTS/webscraping-projects/blob/main/Philadelphia-Area-Craigslist-2-br-Apt-Scraping.ipynb" rel="noopener ugc nofollow" target="_blank">做过的小例子</a>。也请注意网站的网页抓取规则。</p><p id="9e05" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">感谢阅读！</p><div class="nf ng ez fb nh ni"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw in ni"/></div></div></a></div></div></div>    
</body>
</html>
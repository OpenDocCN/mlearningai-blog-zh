<html>
<head>
<title>Web Scraping an Online Travel Agency Website with Python, Selenium, Beautiful Soup, and Requests</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个在线旅行社网站，有Python，Selenium，Beautiful Soup和Requests</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/web-scraping-an-online-travel-agency-website-with-python-selenium-beautiful-soup-and-requests-def99b4a8123?source=collection_archive---------0-----------------------#2022-04-04">https://medium.com/mlearning-ai/web-scraping-an-online-travel-agency-website-with-python-selenium-beautiful-soup-and-requests-def99b4a8123?source=collection_archive---------0-----------------------#2022-04-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/373bb5e2c9b82e9d4a841a3e5f259efd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jir5kBf56R7cFdhNwz_z4Q.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Web Scraping an Online Travel Agency Website with Python, Selenium, Beautiful Soup, and Requests. Image by the author.</figcaption></figure><p id="1335" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">2006年，数据科学和以客户为中心的商业战略方面的英国数学家和企业家Clive Robert Humbly创造了一个短语“数据是新的石油”[1]。网络上有很多。数据呈指数级增长。研究人员估计每天会产生2.5万亿字节的数据。这些数据的一些来源包括购买交易记录、社交媒体网站，如Twitter的推文、LinkedIn上的评论、多媒体图像以及上传到Instagram、抖音和物联网(IoT)的视频[3]。企业收集、处理和分析生成的数据至关重要，以便[4]:</p><ol class=""><li id="caf9" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">做出更明智的业务驱动型决策。</li><li id="5a5d" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq jw jx jy jz bi translated">优化性能并提高成本效率。</li><li id="935f" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq jw jx jy jz bi translated">为战略制定和可持续变革积累见解。</li><li id="6a29" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq jw jx jy jz bi translated">提高财务绩效和管理风险。</li></ol><p id="9c86" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">网络搜集是一种在线收集数据的有效技术[5]。Web抓取是“创建一个计算机程序以自动方式从web下载、解析和组织数据的过程”[6]。简而言之，网络抓取是互联网数据的自动收集。这些数据被保存到文件或数据库中，需要时可以检索出来进行分析。Web抓取也称为“web数据提取”、“web收获”或“web挖掘”。</p><p id="39ae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">虽然公司提供的应用编程接口(API)是另一种在互联网上收集数据的技术，但是网络抓取仍然是最优选的，因为[6]:</p><ol class=""><li id="b98d" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">提供的API只能在有限的时间内访问。</li><li id="72b3" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq jw jx jy jz bi translated">提供的API需要在使用前付费。</li><li id="01a3" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq jw jx jy jz bi translated">提供的API没有公开所有需要的数据。</li><li id="e877" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq jw jx jy jz bi translated">该网站不提供API。</li></ol><h2 id="bbda" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak">网页抓取过程</strong></h2><p id="c10c" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">Web抓取至少使用一种流行的编程语言来完成，比如R或Python。一旦确定了要抓取的网站，就会创建一个HTTP请求来提取数据。该请求在包含GET查询或POST查询的URL中执行。如果请求成功，定位器将用于搜索HTML元素中的数据。在下一阶段，将提取和解析数据，并以结构化格式保存已获取的所需信息。</p><h2 id="8fec" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak">法律和道德含义</strong></h2><p id="e96b" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">关于网页抓取的法律仍然是一个“灰色地带”[7]。尽管网页抓取并没有错，因为它取决于意图，但是即使要丢弃的数据是打算用于道德目的，也有一些准则要遵循。</p><h2 id="4bb0" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak">使用或服务条款</strong></h2><p id="8b5b" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">大多数网站向网络用户提供“使用条款”或“服务条款”协议，明确禁止网络抓取。要接受这些条款，网络用户必须点击复选框或“我接受”链接。如果一个网络用户在表明他或她的提升后没有遵守条款，那么他或她就违反了合同，从法律的角度来看，可能会被起诉[7]。</p><h2 id="abc2" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak">版权或商标侵权</strong></h2><p id="c44d" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">当网络用户抓取网站所有者明确拥有版权的数据或信息时，就发生了版权侵权[8]。尽管如此，在没有得到网站所有者许可的情况下，仍然可以在有限的范围内抓取受版权保护的信息或数据。在法律上，这属于“合理使用”的法律原则。</p><h2 id="bd19" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak">网站受损</strong></h2><p id="1b27" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">在web抓取期间同时发送数百个请求可能会使服务器过载。这可能导致网站提供的服务价值降低，甚至对网站造成损害。网站所有者可以起诉网络用户侵犯动产，要求赔偿损失。</p><p id="5f48" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">刮削时要记住的一些一般准则</p><p id="ea44" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">1)只有公共信息应该被废弃。</p><p id="a795" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">2)在抓取之前，一定要查看网站的使用条款或服务政策。</p><p id="11a6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">3)避免抓取有版权的数据或信息。</p><p id="14bd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">4)不要同时向web服务器发送多个请求。</p><h2 id="c59e" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak"> Python网页抓取库</strong></h2><p id="a3d0" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">有几个用于web抓取的Python库。在本文中，我将简要介绍五(5)个库。</p><p id="8800" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 1)美汤(BS4) </strong></p><p id="1e1d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Beautiful soup (BS4)是一个Python库，用于从HTML和XML文件中提取数据。BS4是一个支持HTML解析器的解析器库。此外，它还支持LXML等第三方Python解析器。解析器帮助程序员轻松获得HTML文件。</p><p id="ed3e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">除了对初学者友好和易于使用之外，BS4还具有自动编码检测功能。它可以将UTF 8格式的文件转换成Unicode格式，反之亦然。更重要的是，BS4经常与请求库一起使用。</p><p id="3956" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在这里阅读它的文档<a class="ae lf" href="https://readthedocs.org/projects/beautiful-soup-4/downloads/pdf/latest/" rel="noopener ugc nofollow" target="_blank"><strong class="iv hi"/></a></p><p id="9803" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 2)刺儿头</strong></p><p id="9897" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Scrapy是一个网页抓取和网页抓取框架。它抓取网站并从其网页中检索数据。scrapy的一些用途包括:-数据监控，数据挖掘，自动化测试。</p><p id="c79a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">阅读其文档<a class="ae lf" href="https://docs.scrapy.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi">此处</strong> </a></p><p id="8ab6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 3)请求</strong></p><p id="941b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">请求库允许用户发送GET和POST之类的HTTP请求。请求提取网页的原始HTML。请求不解析提取的数据。通过BS4和LXML进行解析。</p><p id="9342" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在这里阅读它的文档<a class="ae lf" href="https://docs.python-requests.org/_/downloads/en/v2.1.0/pdf/" rel="noopener ugc nofollow" target="_blank"><strong class="iv hi"/></a></p><p id="f31a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 4)硒</strong></p><p id="5d0d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Selenium是一个基于web的自动化测试工具，使用Selenium WebDriver。它使浏览器自动化，可以打开网页，点击链接，填写表格，并模仿互联网上的其他人类行为。关于网络抓取，它是抓取用JavaScript编写的网站的一个很好的选择。此外，不同于其他图书馆，它可以用来刮动态网站同样静态网站。</p><p id="7db6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">阅读其文档<a class="ae lf" href="https://www.selenium.dev/documentation/" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi">此处</strong> </a></p><p id="474c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 5) Urllib </strong></p><p id="bef6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Urllib是一个用于获取URL(统一资源定位器)的Python包。它包含以下模块:</p><ul class=""><li id="1472" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">urllib.request打开并读取URL</li><li id="4b66" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">urllib.error包含由urllib.request引发的异常</li><li id="2ade" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">urllib.parse解析器URL</li><li id="7c10" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">urllib.robotparser解析器robots.txt文件</li></ul><p id="2014" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">阅读其文档<a class="ae lf" href="https://docs.python.org/3/library/urllib.html" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi">此处</strong> </a></p><p id="c3b9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">人们并不总是需要编写Python脚本来从互联网上收集数据。有许多工具和软件解决方案可用于网络报废。其中包括:</p><ul class=""><li id="c3cd" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">八解析</li><li id="f65c" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">ProWebScraper</li><li id="744c" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">ParseHub</li><li id="1df3" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">报废蜜蜂</li><li id="b54d" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">Import.io</li><li id="0628" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">刮刀猫头鹰</li></ul></div><div class="ab cl lh li go lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ha hb hc hd he"><h1 id="672a" class="lo kg hh bd kh lp lq lr kl ls lt lu kp lv lw lx ks ly lz ma kv mb mc md ky me bi translated"><strong class="ak">实际演示</strong></h1><p id="1dbf" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated"><strong class="iv hi">任务:</strong>编写一个python脚本，自动从网站收集公共信息，并以表格格式保存。</p><p id="1aca" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">目标:从酒店收集酒店列表信息。ng网站并保存为CSV文档。</p><p id="ca7f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">关于Hotels . ng</strong>T24】酒店。ng是一家专门从事尼日利亚酒店预订的在线旅行社。他们帮助客户在网上预订酒店房间。他们还为客户提供全面的帮助和支持，使酒店预订过程变得顺畅和简单。此外，他们还提供酒店推荐和评论。</p><p id="8145" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">结果输出</strong></p><p id="1d23" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从网站上提取了卡杜纳、阿布贾、拉各斯和河流州的总共854个酒店列表数据。</p><p id="2dca" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">我刮来的数据</strong> <br/> 1)酒店名称<br/> 2)地址<br/> 3)设施<br/> 4)每晚均价<br/> 5)评级</p><p id="42e1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对于这个项目，我使用Selenium来自动化浏览器。其他被使用的库包括:<br/> -请求<br/> -漂亮组<br/> - lxml</p></div><div class="ab cl lh li go lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ha hb hc hd he"><h2 id="b097" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">我们开始吧</h2><h2 id="bf30" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">导入依赖项</h2><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Import dependencies. Image by the author.</figcaption></figure><h2 id="4507" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">启动web驱动程序</h2><p id="ac0c" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">步骤:</p><ul class=""><li id="d215" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">启动web驱动程序</li><li id="69d7" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">导航到目标网站</li><li id="fcaa" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">使用。获取驱动程序的方法，并将url作为参数传入</li></ul><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Startup the webdriver. Image by the author.</figcaption></figure><h2 id="5f13" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">创建一个使用字符串格式插入搜索词的函数</h2><p id="437b" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">步骤:</p><ul class=""><li id="bce4" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">将url链接分配给模板变量</li><li id="102e" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">删除url中的关键字搜索词，用花括号{}替换。这就是我们要插入搜索词的地方。</li><li id="84df" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">此外，用加号(+)替换搜索词中的每个空格，以符合url约定。</li><li id="e887" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">返回插入了字符串格式的搜索词的模板。</li></ul><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Create a function that will insert a search term using string formatting. Image by the author.</figcaption></figure><p id="36ae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我们有了一个函数，它将根据提供的搜索词生成一个URL。让我们试一试。</p><figure class="mf mg mh mi fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ml"><img src="../Images/ffa22b5ac3d993ef66949cc2adeb4086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kmVJaYJgABEtc4K0EA8TMg.png"/></div></div></figure><h2 id="45f2" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">做汤</h2><p id="2931" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">需要注意的几点:</p><ul class=""><li id="f5db" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">这将使我们能够访问网站的HTML元素，并将其表示为嵌套的数据结构。</li><li id="07af" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">Beautiful Soup支持Python标准库中包含的HTML解析器，但它也支持许多第三方Python解析器。一个是lxml解析器。我们将使用lxml解析器，因为它比HTML解析器快。</li><li id="0564" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">司机。page_source检索我们在driver上传递的url的HTML。获取(url)。当我们单击Inspect Element时，它得到的代码与我们在浏览器上看到的代码相同。</li><li id="a663" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">find_all()返回所有匹配过滤器的标签和字符串。</li></ul><figure class="mf mg mh mi fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mm"><img src="../Images/67050c5ddd691b7b22b30d65bd2a106b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KOjANRqOpncfvRr9WpYiQg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Making the Soup. Image by the author.</figcaption></figure><h2 id="b1b3" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">创建一个原型模型来提取酒店数据</h2><p id="9768" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">这里，我们原型化了单个记录的提取。然后，将模型应用于整个记录集。之后，我们将第一个结果分配给变量卡。</p><figure class="mf mg mh mi fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/1a3253c8bbf142e54ca0c7164e1e2f6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*la-dEvGefy_CkdC3E7Lx2A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Create a prototype model to extract the hotel data. Image by the author.</figcaption></figure><h2 id="2880" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">将原型模型放在一起</h2><p id="04b0" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">步骤:</p><ul class=""><li id="4a44" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">将原型模型归纳为一个函数，并将其应用于页面上的所有酒店列表。</li><li id="dfb2" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">定义一个名为get_hotel_listings的函数，该函数接受信用卡参数。</li><li id="d23a" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">复制并粘贴我们创建的所有代码来获取卡数据</li><li id="6a2d" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">向我们的def函数添加错误处理。</li><li id="a14c" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">将变量组织成一个元组，然后将其分配给一个hotel_listings变量。</li><li id="c361" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">然后返回hotel _ listings变量。</li></ul><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Put the prototype model together. Image by the author.</figcaption></figure><h2 id="8f5a" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">使用for循环将原型模型应用于页面上的所有列表</h2><p id="d34f" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">步骤:</p><ul class=""><li id="2ce6" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">创建一个空的hotels []列表，其中包含我们提取的所有酒店数据。</li><li id="f296" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">使用上面的列表模式收集页面上所有的酒店列表进行迭代。</li></ul><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Apply the prototype model to all listings on the page using a for loop. Image by the author.</figcaption></figure><h2 id="bbb6" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">打印前5个列表</h2><figure class="mf mg mh mi fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/1265f424bb68984f93710588beadfad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1lj_i1OUPP7mKobATB7apw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Print the first 5 listings. Image by the author.</figcaption></figure><h2 id="afb7" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">进入下一页</h2><p id="467e" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">步骤:</p><ul class=""><li id="b9c4" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">使用字符串格式将页面查询添加到url</li><li id="32a8" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">然后请求下一页，直到我们已经从网站的所有页面提取。</li><li id="a3a8" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">为方便起见，我们需要修改已经定义的get url函数。</li><li id="f697" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">赋给一个url变量template.format .然后像前面一样传入我们的搜索词。</li><li id="a686" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">添加页面和花括号{}。这将给我们提供字符串格式的下一个页码。</li><li id="ac57" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">最后，我们将返回url。</li></ul><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div></figure><h2 id="c810" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">将所有内容放在一起/抓取多页</h2><p id="8a27" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">只在一个页面上搜集了酒店列表，在这个阶段，我们组装了所有的代码来从网站的多个页面中提取数据。</p><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div></figure><h2 id="cfad" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">定义一个主函数来执行程序</h2><p id="6727" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">在这个阶段，我们定义一个主函数。主函数将帮助执行程序。定义一个主函数，并让它接受搜索词的一个参数。它会为我们运行搜索，并根据搜索词保存数据。</p><p id="7884" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">步骤:</p><ul class=""><li id="862a" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">启动web驱动程序。</li><li id="b47a" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">创建一个空的hotels []列表，其中包含我们提取的所有酒店数据。</li><li id="4d8c" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">用我们传递到主函数中的搜索词设置一个url。</li><li id="8024" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">迭代超过10页。</li><li id="f42c" class="jr js hh iv b iw ka ja kb je kc ji kd jm ke jq lg jx jy jz bi translated">关闭驱动程序。</li></ul><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Define a main function to execute the program. Image by the author.</figcaption></figure><h2 id="c03b" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">将数据保存到csv文件中</h2><figure class="mf mg mh mi fd ii"><div class="bz dy l di"><div class="mj mk l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Save the data to a csv file. Image by the author.</figcaption></figure><p id="88a6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在一切都创建好了，我们可以通过输入搜索词来运行主程序。在这里，我对尼日利亚河流州的酒店感兴趣。</p><figure class="mf mg mh mi fd ii er es paragraph-image"><div class="er es mp"><img src="../Images/29fb5074a77d4cdf057b2562bc46eb3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*dfioLKMpEHn0mMNvPzBcDQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Run the main program by inputting our search term. Image by the author.</figcaption></figure><p id="ed9f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从网站上提取了卡杜纳、阿布贾、拉各斯和河流州的总共854个酒店列表数据。</p><h2 id="8f8d" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated"><strong class="ak">数据清理</strong></h2><p id="65ce" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">提取数据后，我用Microsoft Excel进行了数据清洗。</p><ul class=""><li id="4cbb" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated"><strong class="iv hi">脏数据</strong></li></ul><figure class="mf mg mh mi fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/fc96576ab5f71c3318e49c9cf67b200e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9c68-reoKzr_kXn5vKc-jA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Dirty data. Image by the author</figcaption></figure><ul class=""><li id="0d09" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq lg jx jy jz bi translated">清理的数据</li></ul><figure class="mf mg mh mi fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/ad33001f53de67f2eaadc458fc8a155e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZKputxXfgzRY_X7X92qsBw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Cleaned data. Image by the author.</figcaption></figure><p id="1e08" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">祝贺你到达终点。如果你有任何问题或者只是想打个招呼，请在下面发表。</p><p id="17a6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">参见我的<a class="ae lf" href="https://github.com/SampsonIpiankama/Web_Scraping_Projects/tree/main/Hotels.ng" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中的完整代码</p><p id="50bb" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在推特上关注我</p><p id="2b90" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在LinkedIn<a class="ae lf" href="https://www.linkedin.com/in/sampsonipiankama/" rel="noopener ugc nofollow" target="_blank">上与我联系</a></p><h2 id="5ec3" class="kf kg hh bd kh ki kj kk kl km kn ko kp je kq kr ks ji kt ku kv jm kw kx ky kz bi translated">参考</h2><p id="08b8" class="pw-post-body-paragraph it iu hh iv b iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm le jo jp jq ha bi translated">[1] C. Arthur，“科技巨头可能很庞大，但没有什么比得上大数据”，<em class="ms">《卫报》</em>，2013年8月23日。<a class="ae lf" href="https://www.theguardian.com/technology/2013/aug/23/tech-giants-data#:~:text=%22Data%20is%20the%20new%20oil" rel="noopener ugc nofollow" target="_blank">https://www . the guardian . com/technology/2013/aug/23/tech-giants-data #:~:text = % 22 data % 20 is % 20 the % 20 new % 20 oil</a>(2022年3月24日访问)。</p><p id="37b8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[2] W. Lemahieu，S. vanden Broucke和B. Baesens，<em class="ms">数据库管理原理:存储、管理和分析小型和大型数据的实用指南</em>。剑桥:剑桥大学出版社，2018年。</p><p id="1383" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[3] J. Li，L. Xu，L. Tang，S. Wang，L. Li，“旅游研究中的大数据:一个文献综述”，<em class="ms">旅游管理</em>，第68卷，第301–323页，2018年10月，doi:10.1016/j . tourman . 2018 . 03 . 009。</p><p id="c16f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[4] V. Jayagopal和B. K. K .，“数据管理和大数据分析:数字经济中的数据管理。，“在<em class="ms">大数据分析、架构和应用研究选集</em>中，信息资源管理协会编辑。IGI全球，2022年，第1614-1633页。</p><p id="2009" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[5] S. J. Mooney、D. J. Westreich和A. M. El-Sayed，“大数据时代的流行病学”，<em class="ms">流行病学</em>，第26卷，第3期，第390-394页，2015年5月，doi:10.1097/ede . 000000000000274</p><p id="2cd3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[6] Seppe Vanden Broucke和B. Baesens，<em class="ms">用于数据科学的实用Web抓取</em>。加州伯克利，2018年。</p><p id="c4b6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[7] J. Snell和N. Menaldo，“大数据2.0时代的网络抓取”，彭博法律新闻，2016年。访问时间:2022年3月25日。【在线】。可用:<a class="ae lf" href="https://www.perkinscoie.com/images/content/1/5/v2/156775/Snell-web-scraping-BNAI.pdf" rel="noopener ugc nofollow" target="_blank">https://www . Perkins coie . com/images/content/1/5/v2/156775/Snell-we B- scraping-bnai . pdf</a>。</p><p id="d485" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">[8] A. J .德雷耶和j .斯托克顿，“互联网‘数据搜集’:咨询客户入门”，《纽约法律期刊》，2013年7月。访问时间:2022年3月24日。【在线】。可用:【https://www.law.com/newyorklawjournal/almID/1202610687621/? T2】slreturn=20220229032115。</p><div class="mt mu ez fb mv mw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mx ab dw"><div class="my ab mz cl cj na"><h2 class="bd hi fi z dy nb ea eb nc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nd l"><h3 class="bd b fi z dy nb ea eb nc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ne l"><p class="bd b fp z dy nb ea eb nc ed ef dx translated">medium.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk in mw"/></div></div></a></div></div></div>    
</body>
</html>
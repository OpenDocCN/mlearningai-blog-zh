<html>
<head>
<title>Object Detection Explained: Single Shot MultiBox Detector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释的对象检测:单次发射多盒检测器</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-detection-explained-single-shot-multibox-detector-c45e6a7af40?source=collection_archive---------0-----------------------#2021-07-04">https://medium.com/mlearning-ai/object-detection-explained-single-shot-multibox-detector-c45e6a7af40?source=collection_archive---------0-----------------------#2021-07-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/2287604ae9f6e93d26e5cb029e16820f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Oi8LUNndHr2IT8BJXiZjQ.jpeg"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx"><a class="ae hu" href="https://unsplash.com/@stevencornfield" rel="noopener ugc nofollow" target="_blank">Steven Cornfield</a> via <a class="ae hu" href="https://unsplash.com/photos/jWPNYZdGz78" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="501d" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">简单语言中的硬概念。</p><p id="fd92" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">目标检测由两个独立的任务组成，即分类和定位。上次我报道了R-CNN系列的物体探测器。R-CNN系列目标检测器由两个阶段组成，即区域建议网络和分类与盒细化头。然而，现在我们正在转向单级物体探测器。在本文中，我将介绍单次发射多盒探测器(SSD)。</p><p id="b7fe" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hy">上一次</strong>:</p><p id="40d6" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" href="https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76" rel="noopener" target="_blank"> RCNN </a></p><p id="3c93" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" rel="noopener" href="/mlearning-ai/object-detection-explained-fast-r-cnn-bc11e607411f">快速RCNN </a></p><p id="eccc" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" rel="noopener" href="/mlearning-ai/object-detection-explained-feature-pyramid-networks-cf2621c8f7cc"> FPN </a></p><p id="1e3a" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae hu" rel="noopener" href="/mlearning-ai/object-detection-explained-faster-r-cnn-23e7ab57991d">更快的RCNN </a></p><h1 id="ad02" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">包围盒回归</strong></h1><p id="2fa0" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">与fast R-CNN一样，作者回归到默认边界框(d)的中心(cx，cy)及其宽度(w)和高度(h)的偏移。因此，公式如下所示:</p><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es kv"><img src="../Images/1fd9111a5867238a785b232affad61ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*-88vJQILooXz1KQsem1C4A.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Bounding box regression. Paper: <a class="ae hu" href="https://arxiv.org/pdf/1512.02325.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.02325.pdf</a></figcaption></figure><h1 id="1014" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">体系结构</h1><figure class="kw kx ky kz fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es la"><img src="../Images/d4d989905b31cced342c327b59dcc1bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*WJkDxnrDDKkVTOMlpZczsg.png"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">SSD Architecture. Paper: <a class="ae hu" href="https://arxiv.org/pdf/1512.02325.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.02325.pdf</a></figcaption></figure><p id="f7cf" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上图显示了以VGG-16为中枢的架构。我将通过将其分解为3个部分来解释该体系结构:主干、辅助卷积和预测卷积。为了您的方便，我还将提供一些代码。</p><h1 id="587b" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">基础网络</h1><figure class="kw kx ky kz fd hj"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="f9bc" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我想<em class="ld">强调一下</em>下面的例子是在假设输入图像的尺寸是300×300的情况下提供的，就像原纸一样。</p><p id="d0a4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由此可见，我们正在利用一个简单而著名的VGG-16网络来提取<strong class="iw hy"> <em class="ld"> conv4_3 </em> </strong> <em class="ld">和</em><strong class="iw hy">T21【conv 7】</strong>的特征。此外，我们可以注意到特征尺寸分别是(N，512，38，38)和(N，1024，19，19)。我希望这一部分简单明了，足以让我们继续讨论阿克苏利亚回旋</p><h1 id="44a2" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">辅助卷积</h1><figure class="kw kx ky kz fd hj"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="e5a9" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">辅助卷积使我们能够在VGG-16基础网络上获得额外的功能。这些层的大小逐渐减小，允许以多种比例预测检测结果。因此，我们传递到网络中的输入是从VGG-16网络获得的<strong class="iw hy"> conv7 </strong>特征。由此可见，在应用卷积和ReLU激活函数时，应保留中间特征，即<strong class="iw hy"> conv8_2、conv9_2、conv10_2和conv11_2 </strong>。请慢慢看代码和特征图的<strong class="iw hy">尺寸</strong></p><h1 id="80c8" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">选择默认边界框</h1><p id="3228" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">这听起来可能有点吓人，但不要担心，它仍然很容易掌握。默认边界框是手动选择的。每个要素地图图层都分配有一个比例值。例如，<strong class="iw hy"> Conv4_3 </strong>以最小比例0.2(或有时0.1)检测对象，然后线性增加到比例0.9，用于<strong class="iw hy"> conv11_2 </strong>(从辅助卷积获得)。此外，我们可以注意到，在每个特征图中，每个位置都有一定数量的先验框。对于做4个预测的图层，SSD使用4个不同的纵横比，分别是1，2，0.5和<em class="ld"> sqrt(s_k * s_(k+1)) </em>，其中<em class="ld"> s_k </em>是<em class="ld"> kth </em>特征图的一个比例值。通常，它被定义为纵横比为1时计算的附加比例。那么默认框的宽度和高度计算如下:</p><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es le"><img src="../Images/8a781c27688a502b2ba2d48b2fe7c723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b_qnLAhcr248S2_C.png"/></div></figure><p id="c8c1" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们用下面这段代码来总结一下。</p><figure class="kw kx ky kz fd hj"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="ebb2" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中它返回由SSD做出的8732个预测的8732个先前框。</p><h1 id="53e2" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">预测卷积</h1><figure class="kw kx ky kz fd hj"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="2b43" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这可能看起来很复杂，但它基本上获得了我们从基本VGG-16和辅助卷积中获得的所有特征图，并应用卷积层来预测每个特征图的类别和边界框。花点时间去理解它，并通过注意特征图的尺寸来确保你能跟上。</p><h1 id="711c" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">包裹</h1><p id="740f" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">现在让我们把它们放在一起，看看最终的架构，如下所示。</p><figure class="kw kx ky kz fd hj"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="9243" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请注意，较低级别的特征(conv4_3_feats)具有相当大的比例，因此我们采用L2范数并重新调整其比例。重新缩放因子最初设定为20，但在反向推进过程中会对每个通道进行学习。</p><h1 id="bf4e" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">损失</strong></h1><figure class="kw kx ky kz fd hj er es paragraph-image"><div class="er es lf"><img src="../Images/5b8faa4b5ce4909052b9fc6ae487ac30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*YJnMwhgNHvIIBiSPda0bTQ.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Loss. Paper: <a class="ae hu" href="https://arxiv.org/pdf/1512.02325.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.02325.pdf</a></figcaption></figure><p id="6752" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正如所看到的，我们已经从R-CNN系列的前几篇文章中熟悉了它。定位损失是L1平滑损失，而分类损失是众所周知的交叉熵损失。</p><h1 id="1e6c" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">匹配策略</h1><p id="02d0" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在训练期间，我们需要确定哪个生成的先验盒应该对应于我们的基础事实盒，以包括在损失计算中。因此，我们将每个基础事实框与具有最高Jaccard重叠的在先框进行匹配。此外，我们还挑选具有至少0.5的重叠的在先框，以允许网络预测多个重叠框的高分。</p><h1 id="4d1b" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">硬负开采</h1><p id="26b8" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在匹配步骤之后，大多数先前/默认框被用作负样本。然而，为了避免正样本和负样本之间的不平衡，我们将比率保持在最多3:1，因为这将导致更快的优化和稳定的学习。同样，定位损失仅在正(非背景)先验上计算。</p><h1 id="5149" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">下一步是什么？</h1><p id="cfe0" class="pw-post-body-paragraph iu iv hx iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">虽然我已经讨论了本文的技术细节，但我想分享一篇文章，从中您可以找到更多关于各种对象检测算法(包括SSD)的具体限制、缺点和优点。它还提供了关于何时使用特定算法的深刻见解。请通过以下方式阅读更多信息:</p><div class="hg hh ez fb hi lg"><a href="https://neptune.ai/blog/object-detection-algorithms-and-libraries" rel="noopener  ugc nofollow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hy fi z dy ll ea eb lm ed ef hw bi translated">对象检测算法和库- neptune.ai</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">对象检测在图像中找到并识别事物，这是深度学习的最大成就之一…</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">海王星. ai</p></div></div><div class="lp l"><div class="lq l lr ls lt lp lu ho lg"/></div></div></a></div><h1 id="de7b" class="js jt hx bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">一些遗言</h1><figure class="kw kx ky kz fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lv"><img src="../Images/21578ce18ccb295d1ef2ce081bd1ca15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*CJI3_5F64NocZU0Cq8wpKA.jpeg"/></div></div></figure><p id="60bf" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我希望我设法让SSD易于理解和掌握。我试着用代码，这样你就能想象这个过程。慢慢理解吧。还有，如果你试着自己用就更好了。下一次我将写关于YOLO系列的物体探测器。</p><p id="c398" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">原文:<a class="ae hu" href="https://arxiv.org/pdf/1512.02325.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.02325.pdf</a></p></div></div>    
</body>
</html>
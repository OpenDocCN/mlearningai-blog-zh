<html>
<head>
<title>Paper Summary [Attention Augmented Convolutional Network]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文摘要[注意力增强卷积网络]</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/paper-summary-attention-augmented-convolutional-network-ca6e8ee50469?source=collection_archive---------2-----------------------#2021-12-21">https://medium.com/mlearning-ai/paper-summary-attention-augmented-convolutional-network-ca6e8ee50469?source=collection_archive---------2-----------------------#2021-12-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/bc55c706f785d8ab8fc8ab322cdb4dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JJ9pmpq8sHyFFhHfi2fDA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">These figures are used for Attention visualizations in the paper</figcaption></figure><blockquote class="iu iv iw"><p id="7a01" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated"><strong class="ja hi"> <em class="hh">请注意，这篇帖子是为了我将来很可能的研究在没有完全阅读</em> </strong> <a class="ae jw" href="https://arxiv.org/pdf/1904.09925" rel="noopener ugc nofollow" target="_blank"> <strong class="ja hi"> <em class="hh">论文</em> </strong> </a> <strong class="ja hi"> <em class="hh">的情况下回过头来复习关于这个题目的材料。</em>T13】</strong></p></blockquote></div><div class="ab cl jx jy go jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="ha hb hc hd he"><p id="7d4a" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">注意力和卷积架构在各种应用中都令人惊叹，当谈到混合这两者时，听起来很有趣。在这篇<a class="ae jw" href="https://arxiv.org/pdf/1904.09925" rel="noopener ugc nofollow" target="_blank">论文</a>中提出的一个网络(注意力增强卷积网络)是卷积和自我注意力的混合，用于骨干训练。这个网络架构是由<a class="ae jw" href="https://research.google/teams/brain/" rel="noopener ugc nofollow" target="_blank">谷歌大脑团队</a>在2019年开发的，是AI领域最可靠的来源之一。在这篇文章中，我将用一种简单的方式总结上述科学论文。希望你喜欢它。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/2c5f35407b69c53ece38f800e3acbcf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*lDx3_B_ij12NY3tTsu3B3g.png"/></div></figure><p id="8ecf" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">在摘要中，作者说由于卷积计算的局部性(RNNs也是如此)带来了一些缺陷。另一方面，殷勤没有这种约束；因此，在顺序数据的长期依赖关系上表现良好。这鼓励团队在本研究中发展增强卷积算子和自我注意机制，换句话说，一种新的二维相对自我注意机制。</p><p id="cf69" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">因此，结果提供了这样的事实，即所提出的AANet模型使图像分类和检测的改进永久化。</p><p id="67a2" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">在<strong class="ja hi">简介</strong>中，提到了卷积层的两个特性:</p><ol class=""><li id="a6ab" class="km kn hh ja b jb jc jf jg ke ko kf kp kg kq jv kr ks kt ku bi translated">局部执行(通过有界感受野)</li><li id="1490" class="km kn hh ja b jb kv jf kw ke kx kf ky kg kz jv kr ks kt ku bi translated">翻译等方差(按权重)</li></ol><p id="46f7" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">自我关注并不是什么新鲜事(例如，Bahdanau 2014)，但它在2017年的论文“<a class="ae jw" href="http://papers.nips.cc/paper/7181-attention-is-all-you-%0Aneed.pdf" rel="noopener ugc nofollow" target="_blank">关注是你所需要的全部</a>”中得到了极大的关注。自我关注对于序列建模应用(例如NLP、时间序列等)是最可靠的。).与汇集或卷积运算符不同，加权平均运算中使用的权重是由隐藏单元中的函数动态生成的。因此，当涉及到输入信号之间的相互作用时，它归结于信号本身而不是其他局部项目。这使得捕获长期依赖关系变得可行。</p><p id="3461" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">本研究的自我注意公式能够完全取代常规卷积；此外，人们认识到这种组合的性能要好得多(因此卷积的思想没有被抛弃)。因此，通过绑定和连接卷积特征图(实施局部性)到自我关注特征图(为长期依赖性建模)。从下图可以看出:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/f3346a729045624c48d9d0e239e51a37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_r23o-VTRcbS5Jsg5hZNg.png"/></div></div></figure><p id="98d9" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">在本研究的所有实验中，AANet在计算量增加不多的情况下，系统地提高了压缩和激发通道注意的性能。特别是，可以看到如下表现:</p><ul class=""><li id="5391" class="km kn hh ja b jb jc jf jg ke ko kf kp kg kq jv lb ks kt ku bi translated">基于ResNet50基准的1.3%顶级精度ImageNet</li><li id="e2bc" class="km kn hh ja b jb kv jf kw ke kx kf ky kg kz jv lb ks kt ku bi translated">1.4在RetinaNet基线之上的COCO对象检测的地图增加</li></ul><p id="e984" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">有趣的是，AANet(注意力和回旋的混合)比完全自我注意力模型表现得更好。因此，AANet在这种情况下更有效。</p><h2 id="cdec" class="lc ld hh bd le lf lg lh li lj lk ll lm ke ln lo lp kf lq lr ls kg lt lu lv lw bi translated">注意力增强卷积</h2><p id="a617" class="pw-post-body-paragraph ix iy hh ja b jb lx jd je jf ly jh ji ke lz jl jm kf ma jp jq kg mb jt ju jv ha bi translated">人们已经得出结论，卷积正遭受局限于他们的局部性和缺乏实现全球背景。注意重新校准卷积特征映射以执行长相关性。</p><p id="849f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">在这篇论文中，作者提到他们:</p><ol class=""><li id="6818" class="km kn hh ja b jb jc jf jg ke ko kf kp kg kq jv kr ks kt ku bi translated">使用一个基于注意力的可以参与<em class="iz">到空间和特征子空间的联合</em></li><li id="becc" class="km kn hh ja b jb kv jf kw ke kx kf ky kg kz jv kr ks kt ku bi translated">引入额外的功能地图</li></ol><h2 id="05e2" class="lc ld hh bd le lf lg lh li lj lk ll lm ke ln lo lp kf lq lr ls kg lt lu lv lw bi translated">连接卷积和注意力特征图；</h2><p id="b529" class="pw-post-body-paragraph ix iy hh ja b jb lx jd je jf ly jh ji ke lz jl jm kf ma jp jq kg mb jt ju jv ha bi translated">相应的AANet写为</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/553f0b37b3ebec87c7b37253114fd94b.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*n5zIhqpPlJ5LEhN7AWbBTg.png"/></div></figure><p id="01a9" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">其中，MHA(X)可以计算如下:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es md"><img src="../Images/2f8d509f084515dc0ef55adf8bbb3322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*Da8XB9DGagPm0zln07Grmw.png"/></div></figure><p id="11da" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">同样，当涉及到二维位置衰退时:(没有关于位置的明确信息，自我注意是置换等价的)</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/fd845afcc5d312d5ed81424f107ca1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hZt7UzsphkkbwiI0vc9OQ.png"/></div></div></figure><p id="b9be" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">当谈到相对位置嵌入时:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/c081a6fb21eb8fcb5049dea24bf53a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*BJYpTZYDMijhDXHFyxBSdQ.png"/></div></figure><p id="c1fb" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">本次研究中模型的<strong class="ja hi"> <em class="iz">架构</em> </strong>描述如下:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/46c8662818fb7ff351d5b2e1623b6230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*eEgyKujmqWbqKGx1yQpNyQ.png"/></div></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/f2d36d422dea38bd0e9c6ab40c099940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*gjpN4e1o8l9G4JD5AgAmEQ.png"/></div></figure><p id="ae6d" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">本节中有趣的一点是，为了对抗内存开销的影响，AANet从空间维度最小的最后一层开始。此外，他们采用更小的批量和缩减输入采样来减少模型的内存占用。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/de6aec36756b69ac15ea10ab332942de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*m4nxj72ccRtWVviywRtoIQ.png"/></div></figure><p id="7c86" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">在“<strong class="ja hi">实验</strong>”部分，据说该模型在用于图像分类和对象检测的流行数据集上进行测试，并且表现良好。(本文中没有提到这些实现和结果)</p><p id="d0ba" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">此外，自我关注特征图被用来代替卷积特征图，这将是一个更简单的比较。</p><p id="7950" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">最后一部分是关于“T10”的讨论和未来的工作“T11”，我认为这对于机器学习领域的发展非常重要。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/95e63012d798895870ce04b4c7432cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*u-iCuimRugzs7XVeLD71QA.png"/></div></figure><p id="5843" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji ke jk jl jm kf jo jp jq kg js jt ju jv ha bi translated">作者表示，有一些差距值得关注:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/a459068a15d8ec8bb3b5e6d9901e1761.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*t88dzrBvUsvSaPkxC72LXw.png"/></div></figure><ol class=""><li id="83e7" class="km kn hh ja b jb jc jf jg ke ko kf kp kg kq jv kr ks kt ku bi translated">关注充分注意机制交换效率VS权力</li><li id="95eb" class="km kn hh ja b jb kv jf kw ke kx kf ky kg kz jv kr ks kt ku bi translated">在各种架构搜索中使用ANets作为主要工具，以找到更好的模型</li><li id="a4cc" class="km kn hh ja b jb kv jf kw ke kx kf ky kg kz jv kr ks kt ku bi translated">发现这种替代将保持到什么程度</li></ol><blockquote class="iu iv iw"><p id="e6cb" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">如果发现任何错误，请发电子邮件到rezayazdanfar1111@gmail.com找我。同时，在我的Twitter  <a class="ae jw" href="https://twitter.com/reza__yazdanfar" rel="noopener ugc nofollow" target="_blank"> <em class="hh">这里</em> </a> <em class="hh">关注我，在我的LinkedIn </em> <a class="ae jw" href="https://www.linkedin.com/in/reza-yazdanfar-b69055156/" rel="noopener ugc nofollow" target="_blank">这里</a> <em class="hh">访问我。最后，如果你发现它有用，并想在以后的文章中继续，请在</em> <a class="ae jw" href="https://rezayazdanfar.medium.com/" rel="noopener">媒体中关注我。</a>最后，如果你有任何想法或建议，我是开放的，你只需要在linkedIn给我发消息。🙂</p></blockquote><div class="ml mm ez fb mn mo"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">medium.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc io mo"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Building an Image Colorization Neural Network — Part 4: Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建图像彩色化神经网络第4部分:实现</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/building-an-image-colorization-neural-network-part-4-implementation-7e8bb74616c?source=collection_archive---------4-----------------------#2022-09-19">https://medium.com/mlearning-ai/building-an-image-colorization-neural-network-part-4-implementation-7e8bb74616c?source=collection_archive---------4-----------------------#2022-09-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="er es hf"><img src="../Images/b60430386897d61c2857b9ec17a004e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*jx5GizhOl5D0AUsP8L7_UA.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Image generated by <a class="ae hq" href="https://stability.ai/blog/stable-diffusion-public-release" rel="noopener ugc nofollow" target="_blank">Stable Diffusion</a></figcaption></figure><div class=""/><p id="09bd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">欢迎回到本系列的第四部分，也是最后一部分，我们将最终实现一个能够将颜色应用于黑白图像的神经网络。在前面的文章中，我们已经介绍了生成模型和自动编码器、人工神经网络和卷积神经网络的基础知识。如果这些对你来说听起来像是胡言乱语，在你学习下面的部分(下面的链接)之前，一定要检查相应的文章。</p><p id="de94" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">整个系列由以下4部分组成:</p><ol class=""><li id="c181" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><a class="ae hq" rel="noopener" href="/mlearning-ai/building-an-image-colorization-neural-network-part-1-generative-models-and-autoencoders-d68f5769d484"> <strong class="is hu">第一部分</strong> </a>:概述生成模型和<em class="jx">自动编码器</em>的基础知识。</li><li id="57a4" class="jo jp ht is b it jy ix jz jb ka jf kb jj kc jn jt ju jv jw bi translated"><a class="ae hq" rel="noopener" href="/mlearning-ai/building-an-image-colorization-neural-network-part-2-artificial-neural-networks-ac591eb180"> <strong class="is hu">第二部分</strong> </a>:展示了人工<em class="jx">神经网络</em>的基本概念。</li><li id="78fd" class="jo jp ht is b it jy ix jz jb ka jf kb jj kc jn jt ju jv jw bi translated"><a class="ae hq" rel="noopener" href="/mlearning-ai/building-an-image-colorization-neural-network-part-3-convolutional-neural-networks-21a45ef42dde"> <strong class="is hu">第三部分</strong> </a>:介绍<em class="jx">卷积神经网络</em>的基础知识。</li><li id="c4c5" class="jo jp ht is b it jy ix jz jb ka jf kb jj kc jn jt ju jv jw bi translated"><strong class="is hu">第4部分(当前)</strong>:描述实际模型的实现。</li></ol><blockquote class="kd ke kf"><p id="91d8" class="iq ir jx is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn ha bi translated">声明:这绝不是一个教程。它提供了一些基本知识，但主要目标是展示如何构建这样一个模型。</p></blockquote><p id="a0b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">整个模型用<a class="ae hq" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>搭建，图像预处理借助<a class="ae hq" href="https://scikit-image.org" rel="noopener ugc nofollow" target="_blank"> Scikit-Image </a>库进行。所有的代码都可以在:<a class="ae hq" href="https://github.com/gkamtzir/cnn-image-colorization" rel="noopener ugc nofollow" target="_blank">https://github.com/gkamtzir/cnn-image-colorization</a>中找到</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h1 id="1e2d" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">数据和预处理</h1><p id="51b4" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">在进行实际实现之前，我们需要一个包含彩色图像的相当大的数据集。请记住，我们的方法不需要相应的黑白图像，因为正如我们在<a class="ae hq" rel="noopener" href="/mlearning-ai/building-an-image-colorization-neural-network-part-1-generative-models-and-autoencoders-d68f5769d484">第一篇文章</a>中提到的，我们将利用LAB格式，这意味着我们可以分解训练集的图像，并获得每个图像的黑白版本。我选择的数据集是<a class="ae hq" href="https://www.kaggle.com/datasets/aayush9753/image-colorization-dataset" rel="noopener ugc nofollow" target="_blank">图像彩色化数据集</a>，包含5000张用于训练的彩色图像和739张用于测试的图像。每张图片的尺寸是400x400x3。它们的内容各不相同，从食物、人、动物、车辆的图像到室内和室外的图像。</p><p id="230d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">唯一进行的预处理是将RGB转换为LAB格式。为此，我使用了Scikit-Image库和PyTorch提供的“Dataset”类来创建读取和加载图像的机制。有关更多详细信息，请查看“Dataset.py”文件。</p><h1 id="e38e" class="kq kr ht bd ks kt lt kv kw kx lu kz la lb lv ld le lf lw lh li lj lx ll lm ln bi translated">架构和配置</h1><p id="2cc2" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">关于神经网络的架构，我们已经提到，我们将尝试实现一个自动编码器，其中编码器将由卷积层组成，解码器将包含转置卷积层。输入将是具有1个通道的400x400的图像，L值(亮度)。在输出中，我们将得到一个400x400的图像，有两个通道，a和b值。将通过将预测的a和b与输入l相结合来构建最终的彩色图像</p><p id="d3d7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">网络的结构是逐步建立起来的，从只有几层和几个参数的网络到在信息流方面有更复杂方法的多层网络。基本上，我遵循奥卡姆剃刀原则，逐步构建更复杂的解决方案，我试图将任务的实际复杂性反映到模型的复杂性中。</p><p id="3622" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">有一点我们还没有谈到，那就是层与层之间的批量规范化。我发誓要写一篇关于批处理规范化的文章，但是现在你可以把批处理规范化看作是一个聪明的技巧，它允许我们在很好地处理权重值的同时加快训练过程。</p><blockquote class="kd ke kf"><p id="e777" class="iq ir jx is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn ha bi translated">批量规范化远不止这些。我将在接下来的文章中解释一切。</p></blockquote><p id="f6ec" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">作为激活功能，我使用了<em class="jx"> ReLU </em>，因为这是最安全的选项之一。批次大小设置为32，这意味着用包含32个图像的批次来训练网络。预测损失通过<em class="jx">均方误差</em>或<em class="jx"> MSE </em>计算，而在实验中，网络使用<em class="jx"> Adam优化器</em>。</p><p id="1dd2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">总的来说，我已经尝试了6个不同的网络。在随后的部分中，我将提供所有这些设置和结果。每个人都在大约200个时期的200个图像的开发集上接受训练。开发集用于在将整个数据集提供给模型之前测试和比较不同的架构，可以节省大量时间。</p><h2 id="d73f" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">第一架构</h2><p id="f31e" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">第一种，也是最基本的一种架构，如下图所示。我们已经用三种不同的学习速度进行了三个独立的实验，但是它们的表现都非常相似。此外，他们甚至无法学习训练实例，这对于学习能力来说是一个危险信号。</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es mm"><img src="../Images/5c21fad25a01d05e7601b85aca1a56cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*-q1CWpfVSwlRoWS0o-l_xA.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Architecture of 1st Network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es mr"><img src="../Images/0653f5f8c926638a51c5af2667bceca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*yETo3a-pUwDiqmfA24s49g.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Configuration of 1st network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/c66ef43676fb98d4aeec9ec49857923c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*k9ZE-_Gc3K_z8R7cjllqOQ.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Loss of 1st Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es mt"><img src="../Images/016388251198e2db72162d102f90fe94.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*US8kG_Mj5XsCiLWHm1UGGg.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Errors of 1st Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mu"><img src="../Images/626c20403f5e9629055d7d249fe34531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pqSmwNHrkLuaCOYtqiIyFw.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Results of 1st Architecture (left: training set, right: testing set). The number underneath the picture indicates the MSE.</figcaption></figure><h2 id="fd6f" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">第二架构</h2><p id="73b7" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">第二种架构本质上是前一种架构的增强，其中我分别在编码器和解码器中添加了1个卷积层和1个转置卷积层。在这种情况下，与第一种情况相比，损失减少了，而学习率为0.001的实验证明了更好的结果。尽管如此，该网络还是不能给图像着色，尽管它确实尝试在某些地方涂上一些颜色。</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mz"><img src="../Images/3d8862981e0789de3a8799420e6e58aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ydioOfhQVNoZTeyEj1bnEQ.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Architecture of 1st Network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es na"><img src="../Images/cb47de8cd4f6de4871efbf831fafdffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*4RsmNJnFAn92f81qnpzvKQ.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Configuration of 2nd Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/d79c513f05fd4ab73b422dc533645b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*pV89Sq3JEUSIJ_rt2oYmPw.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Loss of 2nd Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es mt"><img src="../Images/6c21116a099ffefb43921dc180e7e656.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*IJ5Xv4fcjFhVLcwnyQsLdQ.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Errors of 2nd Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nb"><img src="../Images/ca7b736772290ca0b0e60d510b47ce24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUIDb5AecJHM0as7yL7sAg.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Results of 2nd Architecture (left: training set, right: testing set)</figcaption></figure><h2 id="e6ef" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">第三架构</h2><p id="0e8f" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">第三个架构不仅仅是一个增强，而是一个完整的修改。我已经调整了网络来实现所谓的U-Net [1]。U-Net布局使用先前计算的编码器输出作为解码器后续部分的输入。这样，我们可以确保网络不会丢失任何重要信息。U形网的确切结构如下所示:</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nc"><img src="../Images/8b8941a3c87188f9836d9acaeb7ee541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*or9FJUA_kuDLkN20TV2M_g.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">U-Net Layout (Source: Wikipedia <a class="ae hq" href="https://commons.wikimedia.org/wiki/File:Example_architecture_of_U-Net_for_producing_k_256-by-256_image_masks_for_a_256-by-256_RGB_image.png" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:Example_architecture_of_U-Net_for_producing_k_256-by-256_image_masks_for_a_256-by-256_RGB_image.png</a>)</figcaption></figure><p id="8eed" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">使用这种方法，网络收敛速度更快，训练集和测试集的错误更少。此外，它还是第一个能够持续应用特定颜色的网络。</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nd"><img src="../Images/549d220559a06278877873bbb7570c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q0GRamhrk0iCTidy_qvFog.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Architecture of 3rd Network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es ne"><img src="../Images/3bf5d9971a7c5f95a4774671116c21c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*1cZLEO_CoNNUfd-f1Iecbw.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Configuration of 3rd Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/3d1f3012937cd8e8903db18051d55938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Ja8XZ9eSLK1E6RDfrnMKTQ.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Loss of 3rd Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es nf"><img src="../Images/bc6cbb6b3e1adb799e5f2cc196cecd67.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*veZ_XxU8smcOvlEDuGUMMg.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Errors of 3rd Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nb"><img src="../Images/869043ba3e29a63f5986860e4372e8f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wy61Yd1XXeMKqeBW2i__DA.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Results of 3rd Architecture (left: training set, right: testing set)</figcaption></figure><h2 id="77a3" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">第四建筑</h2><p id="683e" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">这种架构基于前一种架构，在编码器和解码器上增加了一层。最终结果显示，训练集中的损失减少得更多，输出包含更多彩色区域。注意测试损失增加了。这意味着我们的模型在训练集上过度拟合，但这在这一点上不是问题，因为构建模型的第一步是确保它能够学习。这是通过让模型在某种程度上过度拟合，然后通过增加训练集来实现的，过度拟合问题通常会消失。</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es ng"><img src="../Images/e786402a5d9434ce3a90cf6ceb4fb443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeeemGtFrXQ6eOd_rsSxZg.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Architecture of 4th Network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es nh"><img src="../Images/e59cd2462166dfd29a0155d969210ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*lg8CQeldjDJ4UtH1Fq-jxw.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Configuration of 4th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/0c4c5a537069e74458eb939b02ced04d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*CBKmTmeJ_g_CMBWC__CErA.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Loss of 4th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ni"><img src="../Images/ecfcc04ff201d9bf1e3fcea1de96d2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*gDj6DiHzpXvqFHnnkBOiQA.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Errors of 4th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nj"><img src="../Images/66e61ecbeb1ac6a95c37d64ae468c515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C88zVPZ3jOznnGE3NOfEaQ.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Results of 4th Architecture (left: training set, right: testing set)</figcaption></figure><h2 id="3de4" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">第五建筑</h2><p id="f6d9" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">在这个阶段，我选择通过引入膨胀层来修改网络布局，这也被称为“a trous”层。有研究表明，像我们这样的病例在预测方面有了重大改进[2]。同样，损失减少得更多，模型能够更精确地给图像着色。</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nk"><img src="../Images/726f53cda18315556f43fbc298beec85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTUY6hfHINXS1BJ5pZWZqQ.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Architecture of 5th Network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es nl"><img src="../Images/bada69b4d17aca8dac3ff72f0ac60710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*OhrzLyTdAL_ZtlDF-42W1w.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Configuration of 5th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/dd360e369a2456317bc41910bd31742a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*lyi0CEIOXGZ-z8w6e5ZXxQ.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Loss of 5th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es nm"><img src="../Images/e0f99a8e90b0eca6e1cee05439e4e0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*wRTPM9jpYmshXNzTBPS-Sw.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Errors of 5th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nn"><img src="../Images/c9e23ab4a954d3c8b1bec2efcfde04c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vILwduPRC2f8dDomIoM4kA.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Results of 5th Architecture (left: training set, right: testing set)</figcaption></figure><h2 id="69d9" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">第六建筑</h2><p id="b220" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">最后一个架构是第五个案例的扩充版本，我在其中添加了两个额外的层。结果与以前的版本没有太大的不同，这使得这个架构成为一个很好的停止点。公平地说，在某些部分，架构5比6更好，但由于后者表现出较低的过拟合，我选择它作为最终模型。</p><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es no"><img src="../Images/2fb58517dd0fa935c4e3242b100f1f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nVDb522XobSbOZ6QuZWx7A.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Architecture of 6th Network</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es np"><img src="../Images/170fcd9280e1b63a1ceca27ac5a9cb96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*sfEUW_BIxjTD9EqrFko-sg.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Configuration of 6th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es ms"><img src="../Images/30385d916b13ff2fde4b7fc3b99e9d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*OWnYbWQ8hIXR5DJi5ierOw.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Loss of 6th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div class="er es nq"><img src="../Images/9d86d1f6860bdc85ef7a5f1daf2da13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*3GsVqDdWro-FP-ZWDHPegw.png"/></div><figcaption class="hm hn et er es ho hp bd b be z dx">Errors of 6th Architecture</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nr"><img src="../Images/0bb3ba1135d0ac36ffa735dbf88a5e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rE6PKu8HTa7ksArvO-3ybA.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Results of 6th Architecture (left: training set, right: testing set)</figcaption></figure><h1 id="6d4b" class="kq kr ht bd ks kt lt kv kw kx lu kz la lb lv ld le lf lw lh li lj lx ll lm ln bi translated">决赛成绩</h1><p id="c6fa" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">针对第六架构的开发集的培训在Google Colab Pro GPUs上持续了约40分钟，在i5–4690k @ 3.9 GHz CPU上持续了约2.5小时。由于时间限制和GPU可用性，我被限制只能使用CPU进行培训。这就是为什么最终的架构是在2000幅图像上训练的，而不是在整个数据集上。于是，我对模型进行了300个历元的训练，3天的学习率为0.001。最终的结果是令人鼓舞的，因为该模型不仅能够彩色化它在训练中遇到的图像，还能够彩色化它以前没有见过的图像！</p><h2 id="3cfa" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">训练集</h2><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es ns"><img src="../Images/b4e7efecbad99b8809c99c1a08ecd71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7sKMyVEwu6xF2_1PsUA6A.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Final Results on Training Data I</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nt"><img src="../Images/05ebd8f0074b9ca8cbbfe912caf95c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkNpVScmDfxoBnAnPuu7iQ.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Final Results on Training Data II</figcaption></figure><h2 id="3149" class="ly kr ht bd ks lz ma mb kw mc md me la jb mf mg le jf mh mi li jj mj mk lm ml bi translated">测试设备</h2><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nu"><img src="../Images/09f9d0f3142c0e6a8f3d491256700771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqNMYxS-opis5UI13K6Omg.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Final Results on Testing Data I</figcaption></figure><figure class="mn mo mp mq fd hj er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nv"><img src="../Images/20d3c790d781e2902b3d2ecbf0c65b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYwW4-mFArpiDCciaTpfZQ.png"/></div></div><figcaption class="hm hn et er es ho hp bd b be z dx">Final Results on Testing Data II</figcaption></figure><p id="cc97" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这就结束了用神经网络解决图像彩色化问题的整个系列。我真的希望你在这个过程中学到了很多，同时也获得了乐趣。这是我的第一个机器学习相关系列，所以请相信在不久的将来会有更多的系列。在那之前，继续学习！</p><h1 id="e63a" class="kq kr ht bd ks kt lt kv kw kx lu kz la lb lv ld le lf lw lh li lj lx ll lm ln bi translated">参考</h1><p id="2f22" class="pw-post-body-paragraph iq ir ht is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn ha bi translated">[1]，曾志刚，程莲，唐慧明，<em class="jx">使用U-Net的逐像素回归及其在泛锐化上的应用</em>，神经计算，第312卷，第364–371页，ISSN 0925–2312，2018。</p><p id="5a18" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">[2]陈，梁杰和帕潘德里欧，乔治和科克基诺斯，亚索纳和墨菲，凯文和尤耶，艾伦，<em class="jx"> DeepLab:用深度卷积网、卷积和全连通CRFs进行语义图像分割</em>，IEEE模式分析和机器智能汇刊，PP，10.1109/tpami . 2017 . 20160202005</p><div class="hg hh ez fb hi nw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nx ab dw"><div class="ny ab nz cl cj oa"><h2 class="bd hu fi z dy ob ea eb oc ed ef hs bi translated">Mlearning.ai提交建议</h2><div class="od l"><h3 class="bd b fi z dy ob ea eb oc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="oe l"><p class="bd b fp z dy ob ea eb oc ed ef dx translated">medium.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok hk nw"/></div></div></a></div></div></div>    
</body>
</html>
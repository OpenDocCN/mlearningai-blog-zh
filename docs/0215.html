<html>
<head>
<title>Handling Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理不平衡数据</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/handling-imbalanced-data-c69c917378db?source=collection_archive---------5-----------------------#2021-03-04">https://medium.com/mlearning-ai/handling-imbalanced-data-c69c917378db?source=collection_archive---------5-----------------------#2021-03-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/326579aba37d0641837133060d83751d.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*HRv0gAoBzMKloe-8soYumw.png"/></div></figure><p id="0148" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在分类问题中，我们可能经常会遇到数据集中的不平衡。这意味着我们的班级在结果的频率上有显著的差异。对于二元分类问题，这可能意味着有10，000个样本或行具有类标签1，而只有10行具有标签0。在信贷欺诈检测的情况下，有可能存在大量的非欺诈案件而缺乏欺诈案件。另一方面，常用的iris数据集是一个平衡数据集，因为它对所有三种花卉都有相同数量的样本。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div class="er es jj"><img src="../Images/6163ac22b2531e52cd0c95dfb75a6203.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*ORluuacdYc2Kj0Vr4nS78A.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Imbalanced data</figcaption></figure><h2 id="0d09" class="js jt hh bd ju jv jw jx jy jz ka kb kc iw kd ke kf ja kg kh ki je kj kk kl km bi translated">但是这里面临的挑战是什么？</h2><p id="2ba1" class="pw-post-body-paragraph il im hh in b io kn iq ir is ko iu iv iw kp iy iz ja kq jc jd je kr jg jh ji ha bi translated">为了预测患者是否患有癌症、将电子邮件分类为垃圾邮件还是非垃圾邮件以及其他类似场景，我们通常必须更加关注少数类别，即患有癌症的患者或垃圾邮件。但在默认情况下，机器学习算法往往会偏向多数类，从而导致不正确的预测。他们忽视了少数群体，尽管这通常是重点群体，但他们的表现很差。在实现最大似然算法之前，我们必须平衡我们的数据。</p><p id="604b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">处理不平衡数据的技术:</p><h2 id="d251" class="js jt hh bd ju jv jw jx jy jz ka kb kc iw kd ke kf ja kg kh ki je kj kk kl km bi translated">1.欠采样</h2><p id="47ab" class="pw-post-body-paragraph il im hh in b io kn iq ir is ko iu iv iw kp iy iz ja kq jc jd je kr jg jh ji ha bi translated">这里，我们减少了多数类中的样本数量，使其与少数类样本的频率相匹配。假设我们有1000个样本和两个类，0和1。有800个标签为1的样本，只有100个标签为0的样本。这显示了明显的不平衡。基于这样的数据直接建立一个模型将会产生虚假的结果。解决这个问题的一个方法是欠采样。</p><p id="c4ff" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">A.随机欠采样-通过仅使用从我们的1类样本中随机选择的某些行来创建平衡，以使其与0类样本匹配或成比例。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ks"><img src="../Images/c7c44d4b2bf92b874d228e3c7d33bca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*VdgjqR8LIV-kh82OH7DZ2w.png"/></div></div></figure><p id="9975" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这里，欠采样可以通过从第一类的800个样本中随机选取100个来完成。这给了我们总共200个矢量。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div class="er es ks"><img src="../Images/793c718fd6fa6478dbf14dd093162c85.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*y-6KuD3oVtOLqMlrSflecQ.png"/></div></figure><p id="83af" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这个数据现在达到了理想的平衡，因为我们两个类的样本数量相等。通过使用这种方法，我们将得到正确的结果，但这是以丢失有价值的数据为代价的，这在大多数情况下是不可行的。</p><p id="4dc7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">B.未遂欠采样-该技术考虑了多数类点相对于少数类的距离(使用欧几里德距离或其他类似的距离度量)。如果两个点(其中一个属于较大的类，另一个属于较小的类)彼此接近，则消除多数类数据点，以尝试使数据集平衡。</p><blockquote class="kx ky kz"><p id="a2fe" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">接近缺失欠采样-1:它考虑到少数类的三个最近实例的平均最小距离，以便消除多数类的数据点。</p><p id="5ec8" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">接近缺失欠采样-2:它考虑多数类点到少数类的三个最远实例之间的平均最小距离。</p><p id="a88c" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">未遂欠采样-3:它为少数类中的每个实例选择固定数量的最接近的多数类实例。</p></blockquote><p id="f258" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">C.Tomek链接-考虑所有的tomek链接(属于不同类但彼此最近邻的点),并从中排除大多数类实例。</p><p id="70d8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">D.编辑过的最近邻(ENN)-那些其类别标签与其k个最近邻中的大多数不相同的多数类别样本被根除。它可以扩展到重复ENN，其中ENN应用，直到所有这样的样本被删除。</p><h2 id="584f" class="js jt hh bd ju jv jw jx jy jz ka kb kc iw kd ke kf ja kg kh ki je kj kk kl km bi translated">2.过采样</h2><p id="fe74" class="pw-post-body-paragraph il im hh in b io kn iq ir is ko iu iv iw kp iy iz ja kq jc jd je kr jg jh ji ha bi translated">这里我们保持多数类样本的数量不变，并增加属于少数类的样本的频率(这里为800)。</p><p id="14be" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">A.随机过采样-这是通过随机复制样本来实现的。这给了我们</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div class="er es le"><img src="../Images/4c58273e2c17ad4a202a9fbbaada3ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*dtSNKbq1tzsNW5iMa8A7Gw.png"/></div></figure><p id="b05b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们现在总共有1600个样品(其中700个是重复的)。这种技术经常使用，但是复制的样本不会给模型增加任何新的信息，并且会导致过度拟合。</p><p id="bbf9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">B.SMOTE(合成少数过采样技术)- SMOTE是一种过采样方法，使用k近邻(knn)算法。</p><blockquote class="kx ky kz"><p id="81a7" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">1.选择k(默认值=5)。</p><p id="4e63" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">2.随机选择少数类数据点并找到其k个最近邻，通常基于欧几里德距离。</p><p id="18ac" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">3.在最近邻和少数数据点之间创建一个向量。</p><p id="4a3b" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">4.在这些线上的某处人工生成一个合成数据点。我们也可以在一个链接上有多个样本。</p><p id="36ea" class="il im la in b io ip iq ir is it iu iv lb ix iy iz lc jb jc jd ld jf jg jh ji ha bi translated">5.重复这些步骤，直到我们得到相同数量的多数和少数类样本。</p></blockquote><p id="6384" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">考虑来自少数类(x1，y1)的数据点及其最近的邻居之一为(x2，y2)。现在可以使用以下方法生成新点:</p><p id="2d0c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">(x '，y')= (x1，y1) + rand(0，1)* ((x2，y2)-(x1，y1))</p><p id="66f3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">其中，(x’，y’)是合成生成的新数据点</p><p id="59d0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">(x1，y1)是我们选择的少数类数据点</p><p id="c8b3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">rand(0，1)给出一个介于0到1之间的随机数，乘以最近邻和原始数据点之间的差值。</p><p id="5606" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然而，SMOTE有一些缺点，包括创建的数据点重叠。当我们的数据中存在异常观察值时，创建合成数据点可能会导致不同类别之间的重叠点。</p><p id="e0e7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">C.这个问题可以通过使用边界SMOTE解决。与少数类相比，具有多数类的所有邻居或多数类的更多邻居的少数类的观察值分别被称为噪声点和边界点。边界线smote将忽略噪声点，并考虑边界点来生成数据。因此，它忽略了异常值，并防止数据点重叠。然而，缺点是该技术最终会忽略某些数据。</p><p id="1f8e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">D.ADASYN(自适应合成采样)-它类似于SMOTE方法，但是它不是预测严格位于少数样本与其k个最近邻样本之间的线上的点，而是预测方差稍大的点，即它们有点分散。它不像smote那样关注边界，有助于克服前一种技术的问题。</p><p id="9256" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">ADASYN方程:</p><p id="df42" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">1.计算多数阶级和少数阶级的比率。</p><p id="db07" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">d = mᵣ / mₓ </p><p id="ec16" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">2.计算要创建的综合观测值的数量(多数类和少数类样本数量之间的差异)</p><p id="5e58" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">G = (mₓ — mᵣ) × β</p><p id="f2d2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果β = 1，则意味着数据集将完全平衡。</p><p id="4df0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">3.计算属于多数类的邻居与所选k值的比率。</p><p id="5bb3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">rᵢ=δᵢ/k</strong></p><p id="e6d7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">4.将上一步的输出转换为概率密度分布。</p><p id="bf69" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> rₓ ← rᵢ / ∑ rᵢ </strong></p><p id="9dbf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">5.对于每个单独的点，确定可以生成多少个点。</p><p id="7c3e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，如果一个点在多数类中具有更多数量的邻居，则该点将具有更高的rᵢ，从而可以为其生成更多的合成点。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Automated Machine Learning and Hyperparameter Optimisation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动机器学习和超参数优化</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/automated-machine-learning-and-hyperparameter-optimisation-f33be5eb6901?source=collection_archive---------5-----------------------#2021-12-23">https://medium.com/mlearning-ai/automated-machine-learning-and-hyperparameter-optimisation-f33be5eb6901?source=collection_archive---------5-----------------------#2021-12-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f96c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">构建和应用机器学习模型可以成为现代商业的推动者，并被广泛使用。然而，建立这种模型的过程通常是一个漫长的过程，需要专家、时间和计算资源。</p><p id="0797" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动机器学习(AutoML)变得越来越流行，并且近年来已经发布了许多不同的框架(例如基于流行的库scikit-learn构建的)来支持工程师(尤其是非专家)构建成功的ML模型。</p><p id="e5f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种库包括例如以下。</p><ul class=""><li id="8fac" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">https://github.com/automl/autoweka</li><li id="1111" class="jc jd hh ig b ih jm il jn ip jo it jp ix jq jb jh ji jj jk bi translated">https://epistasislab.github.io/tpot/<a class="ae jl" href="https://epistasislab.github.io/tpot/" rel="noopener ugc nofollow" target="_blank">TPOT</a></li><li id="92e3" class="jc jd hh ig b ih jm il jn ip jo it jp ix jq jb jh ji jj jk bi translated">https://automl.github.io/auto-sklearn/master/index.html#<a class="ae jl" href="https://automl.github.io/auto-sklearn/master/index.html#" rel="noopener ugc nofollow" target="_blank">autosklearn⁴:</a></li><li id="03af" class="jc jd hh ig b ih jm il jn ip jo it jp ix jq jb jh ji jj jk bi translated">https://autokeras.com/的AutoKeras⁵: <a class="ae jl" href="https://autokeras.com/" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="9e4d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，以下部分的大部分内容都是从[6]中提到的那本书转述而来的。这些信息可以在这本书的第一章找到。这是一本开放存取的书，可以在以下网站下载:<a class="ae jl" href="https://www.automl.org/book/" rel="noopener ugc nofollow" target="_blank">https://www.automl.org/book/</a>。</p><h1 id="6930" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">使用AutoML的原因</h1><ul class=""><li id="6168" class="jc jd hh ig b ih kp il kq ip kr it ks ix kt jb jh ji jj jk bi translated">(至少)半自动化ML的可能性→这不仅节省了时间，还允许以不同的方式使用节省的资源。</li><li id="7456" class="jc jd hh ig b ih jm il jn ip jo it jp ix jq jb jh ji jj jk bi translated">让非专家也可以访问ML。时至今日，选择ML模型要么取决于(1)专家根据过去的经验选择模型，要么取决于(2)大量的反复试验。类似地，超参数使用网格或随机搜索等技术进行优化，或者在深度学习的情况下，主要由专家进行优化。最近的研究表明，AutoML有能力胜过这些方法。</li><li id="260c" class="jc jd hh ig b ih jm il jn ip jo it jp ix jq jb jh ji jj jk bi translated">创造一种更结构化的方法来进行机器学习。(!)</li></ul><p id="f13c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当然，你可以使用AutoML的原因还有很多。尽管如此，我相信(至少对我来说)上面提到的三点是最重要的。</p><h1 id="a246" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">问题的定义</h1><p id="d2d5" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">下文概述了超参数优化(HPO)，这是AutoML中最基本的任务之一。在HPO，目标是找到给定机器学习模型的最佳超参数。</p><h2 id="dfcd" class="kx js hh bd jt ky kz la jx lb lc ld kb ip le lf kf it lg lh kj ix li lj kn lk bi translated">模型和超参数</h2><p id="6e1d" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">在AutoML中，我们通常看一个给定的ML算法及其超参数。一个特定的算法被表示为<strong class="ig hi"> A </strong>，其第I个超参数的域被表示为<strong class="ig hi">λᵢ</strong>。因此，具有<strong class="ig hi"> n </strong>个超参数的算法的超参数的总向量是所有超参数的叉积，如下所示。</p><figure class="lm ln lo lp fd lq er es paragraph-image"><div class="er es ll"><img src="../Images/adf2c3665cabc3b18cd958a4521401ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/1*hb3BZxkFeaS1dzT8F_pSuA.gif"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Vector of hyper-parameters of an algorithm A</figcaption></figure><p id="8bab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不同的域类型可以从分类(例如支持向量机的<em class="lx">核</em>超参数)到整数(例如随机森林中的树的数量)或完全实值变化。在实践中，它们的值通常有一些限制。例如，如果你观察SVM的超参数<em class="lx"> C </em>，除了10，你几乎看不到任何其他值。</p><p id="d753" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于超参数空间要考虑的最后一件事是不同超参数之间的依赖性。为ML算法的一个特定超参数选择某个值可能会使包含另一个超参数变得完全没有必要。<br/>在图论中，这样的条件使得超参数空间成为有向无环图。一个例子是，SVM的<em class="lx">次</em>超参数仅在选择了<em class="lx">多项式</em>核时相关。</p><h2 id="9102" class="kx js hh bd jt ky kz la jx lb lc ld kb ip le lf kf it lg lh kj ix li lj kn lk bi translated">问题陈述</h2><p id="d527" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">根据上面的定义，我们可以定义要最小化的函数如下。我们搜索在给定数据集<strong class="ig hi"> D </strong>上最小化损失的一组超参数(表示为函数<strong class="ig hi"> V </strong>)。</p><figure class="lm ln lo lp fd lq er es paragraph-image"><div class="er es ly"><img src="../Images/2f2592cdef628cae438d245f3dd96476.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/1*bD9pmEi01rFSABGsnShQcQ.gif"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Minimisation Problem</figcaption></figure><p id="b0c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> V </strong>是一个以损失函数<strong class="ig hi"> L </strong>(如F-1得分或RMSE)和算法<strong class="ig hi"> A </strong>为输入的函数，带有一个超参数矢量<strong class="ig hi"> λ </strong>。此外，训练和验证测试集也被传递给该函数。</p><p id="fb4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">函数V可以使用保持方法或交叉验证来计算损耗。</p><h2 id="26fb" class="kx js hh bd jt ky kz la jx lb lc ld kb ip le lf kf it lg lh kj ix li lj kn lk bi translated">使用Argmin的替代方法</h2><p id="51fe" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">上面的定义显示了进行优化的基本方法。在实践中，只返回一个“最佳”配置可能不是最佳的，尤其是当有多个不同的和非常多样化的解决方案时。</p><p id="8a4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，可以使用类似于随机森林的方法，返回多个配置。这些可以再次用于生成一个整体学习器。这种方法在过去取得了可喜的成果。要了解更多信息，我推荐你阅读[7]中提到的论文。</p><h2 id="91d9" class="kx js hh bd jt ky kz la jx lb lc ld kb ip le lf kf it lg lh kj ix li lj kn lk bi translated">其他需要考虑的事情</h2><p id="a1bc" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">尽管返回性能最佳的模型是有意义的，但是在进行AutoML时还有其他的目标要考虑。通常(几乎总是在ML中)在模型的预测性能和其他性能因素(例如，时间、内存)之间有一个折衷。您可能更喜欢速度更快、预测性能略低的模型，而不是计算时间更长的模型。</p><p id="edc8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多目标优化(MPO)试图找到具有多个待优化因素的优化问题的解决方案。很多时候，没有一个理想的解决方案(尤其是在处理大量目标时)。</p><p id="da3e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，在MPO，返回多个解决方案并不罕见，每个解决方案对于不同目标之间的某种平衡都是最优的。这被称为帕累托前沿，如果不可能构建另一个配置来增强一个目标而不损害另一个目标，则解决方案属于该集合。</p><p id="a3fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">想了解更多关于MPO的信息，我推荐阅读[8]，它对这个主题有一个很好的概述。</p></div><div class="ab cl lz ma go mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ha hb hc hd he"><p id="13cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]: <em class="lx"> Pedregosa </em> <em class="lx">等</em><a class="ae jl" href="http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html" rel="noopener ugc nofollow" target="_blank">Scikit-learn:Python中的机器学习</a>。JMLR 12。第2825-2830页。2011.</p><p id="8a13" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]: <em class="lx">科特霍夫等人</em>。<a class="ae jl" href="https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/16-599.pdf" rel="noopener ugc nofollow" target="_blank">Auto-WEKA 2.0:WEKA中的自动模型选择和超参数优化。JMLR 18(25):15。2017.</a></p><p id="a934" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3]: <em class="lx">乐等</em> <a class="ae jl" href="https://academic.oup.com/bioinformatics/article/36/1/250/5511404" rel="noopener ugc nofollow" target="_blank">用特征集选择器将基于树的自动机器学习扩展到生物医学大数据</a>。生物信息学36(1):250–256。2020.</p><p id="1f86" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4]: <em class="lx">福雷尔等人</em> <a class="ae jl" href="https://papers.neurips.cc/paper/5872-efficient-and-robust-automated-machine-learning" rel="noopener ugc nofollow" target="_blank">高效健壮的自动化机器学习</a>。神经信息处理系统进展28 (NIPS 2015)。2015.</p><p id="e2a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[5]: <em class="lx">金等</em> Auto-keras: <a class="ae jl" href="https://dl.acm.org/doi/pdf/10.1145/3292500.3330648" rel="noopener ugc nofollow" target="_blank">一个高效的神经架构搜索系统。</a>第25届ACM SIGKDD知识发现国际会议论文集&amp;数据挖掘。ACM。2019.</p><p id="10b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[6]: <em class="lx">赫特等人</em>。<a class="ae jl" href="https://link.springer.com/book/10.1007/978-3-030-05318-5" rel="noopener ugc nofollow" target="_blank">自动化机器学习。方法，系统，挑战。</a>斯普林格。2019</p><p id="4b7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[7]: <em class="lx"> Momma et al. </em> <a class="ae jl" href="http://doi.org/10.1137/1.9781611972726.16" rel="noopener ugc nofollow" target="_blank">一种支持向量回归模型选择的模式搜索方法</a>。SIAM数据挖掘国际会议论文集。暹罗。2002.</p><p id="bea0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[8]: <em class="lx"> Ngatchou等</em> <a class="ae jl" href="http://doi.org/10.1109/ISAP.2005.1599245" rel="noopener ugc nofollow" target="_blank">帕累托多目标优化。</a>第13届电力系统智能系统应用国际会议论文集:84–91。2005.</p><div class="mg mh ez fb mi mj"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">medium.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx lr mj"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>NaÃ¯ve Machine Translation in NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ç®€å•æœºå™¨ç¿»è¯‘</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/mlearning-ai/na%C3%AFve-machine-translation-in-nlp-13cf02b9400?source=collection_archive---------6-----------------------#2021-05-04">https://medium.com/mlearning-ai/na%C3%AFve-machine-translation-in-nlp-13cf02b9400?source=collection_archive---------6-----------------------#2021-05-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9bb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">å¤©çœŸçš„æœºå™¨ç¿»è¯‘:</strong></p><p id="b77a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™ä¸ªé¡¹ç›®çš„ç›®çš„æ˜¯ä½¿ç”¨å•è¯åµŒå…¥å’Œå‘é‡ç©ºé—´æ¨¡å‹å°†è‹±è¯­å•è¯ç¿»è¯‘æˆæ³•è¯­ã€‚</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/b9c4be564c89ea5a68786f3e2a04ba2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/0*XpQal-mzVltbTHT8.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Image Source: <a class="ae jo" href="https://fiverr-res.cloudinary.com/images/t_main1,q_auto,f_auto,q_auto,f_auto/gigs/151330916/original/c616ef73c76b73204e888c9d8460c2ca9b596964/translate-from-french-to-english.jpeg" rel="noopener ugc nofollow" target="_blank">Fiverr</a></figcaption></figure><p id="d9aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å½“æˆ‘ä»¬ä¸ºä¸€ä¸ªè¯æ±‡è¡¨è®­ç»ƒå•è¯åµŒå…¥æ—¶ï¼Œä¸»è¦çš„ç„¦ç‚¹æ˜¯ä¼˜åŒ–å•è¯åµŒå…¥ï¼Œä½¿å¾—æ ¸å¿ƒå«ä¹‰å’Œå•è¯ä¹‹é—´çš„å…³ç³»å¾—ä»¥ä¿æŒã€‚è¿™ä¸ªæ¦‚å¿µèƒŒåçš„æ€æƒ³æ˜¯ç”±çº¦ç¿°Â·é²ç€ç‰¹Â·å¼—æ–¯åœ¨20ä¸–çºª50å¹´ä»£æå‡ºçš„:â€œä½ åº”è¯¥ä»ä»–æ‰€äº¤å¾€çš„äººé‚£é‡ŒçŸ¥é“ä¸€ä¸ªè¯â€â€”â€”å¼—æ–¯ï¼ŒJ.R. (1957)</p><p id="0b2c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å®ƒçš„å·¥ä½œåŸç†æ˜¯ï¼Œä¸€ä¸ªè¯çš„è¯­ä¹‰æˆ–æ„ä¹‰ä¸»è¦æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡æˆ–å®ƒä¸å…¶ä»–è¯çš„ä½¿ç”¨æ¥æ•æ‰çš„ã€‚å› æ­¤ï¼Œä»»ä½•å•è¯çš„å‘¨å›´å•è¯éƒ½æœ‰åŠ©äºç†è§£è¯¥å•è¯çš„æ„æ€ã€‚</p><p id="c3dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Gensimæ˜¯Pythonä¸­çš„ä¸€ä¸ªä¸»é¢˜å»ºæ¨¡å’Œç›¸ä¼¼æ€§æ£€ç´¢åº“ï¼Œå®ƒæä¾›å¯¹Word2Vecç­‰å•è¯åµŒå…¥ç®—æ³•çš„è®¿é—®ä»¥è¿›è¡Œè®­ç»ƒï¼Œè¿˜æä¾›é¢„è®­ç»ƒçš„å•è¯åµŒå…¥ä»¥ä¾›ä¸‹è½½ã€‚</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="f908" class="ju jv hh jq b fi jw jx l jy jz">from gensim.models import KeyedVectors</span><span id="85ee" class="ju jv hh jq b fi ka jx l jy jz">en_embeddings = KeyedVectors.load_word2vec_format (â€˜./GoogleNews-vectors-negative300.binâ€™, binary = True)<br/>fr_embeddings = KeyedVectors.load_word2vec_format(â€˜./wiki.multi.fr.vecâ€™)</span></pre><p id="ac0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä½¿ç”¨äº†Coursera workspaceä¸­æä¾›çš„åµŒå…¥å­é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­å…³é”®å­—æ˜¯å•è¯ï¼Œå€¼æ˜¯ä¸€ä¸ª300ç»´çš„æ•°ç»„ï¼ŒåŒ…å«ç‰¹å®šå•è¯çš„å•è¯åµŒå…¥ã€‚</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="e174" class="ju jv hh jq b fi jw jx l jy jz">en_embeddings_subset = pickle.load(open(â€œen_embeddings.pâ€, â€œrbâ€))<br/>fr_embeddings_subset = pickle.load(open(â€œfr_embeddings.pâ€, â€œrbâ€))</span></pre><p id="0421" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åŠ è½½è‹±è¯­åˆ°æ³•è¯­æ•°æ®å­—å…¸ï¼Œå°†è‹±è¯­å•è¯ä½œä¸ºå…³é”®å­—æ˜ å°„åˆ°æ³•è¯­å•è¯ä½œä¸ºå€¼ã€‚</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="274e" class="ju jv hh jq b fi jw jx l jy jz">en_fr_train = get_dict(â€˜en-fr.train.txtâ€™)<br/>en_fr_test = get_dict(â€˜en-fr.test.txtâ€™)</span></pre><p id="4c94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•å®ƒã€‚</p><p id="522c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°å°†è‹±è¯­åˆ°æ³•è¯­è¯å…¸ã€è‹±è¯­åµŒå…¥å’Œæ³•è¯­åµŒå…¥ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢æˆ2ä¸ªçŸ©é˜µXå’ŒYï¼Œä½¿å¾—çŸ©é˜µXåœ¨å•è¡Œä¸­åŒ…å«æ¯ä¸ªè‹±è¯­å•è¯çš„å•è¯åµŒå…¥ï¼Œè€ŒçŸ©é˜µYåœ¨ç›¸åº”è¡Œä¸­åŒ…å«å¯¹åº”æ³•è¯­å•è¯çš„å•è¯åµŒå…¥ã€‚</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="608e" class="ju jv hh jq b fi jw jx l jy jz">for en_word, fr_word in en_fr.items():<br/>    #check if the words have an embedding in the given dataset<br/>    if fr_word in french_set and en_word in english_set:<br/>        #Get the english and french embedding of corresponding words and append them to the list<br/>        en_vec = english_vecs[en_word]<br/>        fr_vec = french_vecs[fr_word]<br/>        X.append(en_vec)<br/>        Y.append(fr_vec)<br/>return X,Y</span></pre><p id="3840" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¯¥å‡½æ•°è¿”å›ç”¨äºè®­ç»ƒæœºå™¨ç¿»è¯‘å™¨çš„X_trainå’ŒY_trainçŸ©é˜µã€‚</p><p id="b931" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æœ‰äº†Xå’ŒYçŸ©é˜µï¼Œæœºå™¨ç¿»è¯‘é—®é¢˜å¯ä»¥è½¬åŒ–ä¸ºæœ€å°åŒ–é—®é¢˜ã€‚è§£å†³æ–¹æ¡ˆå½’ç»“ä¸ºæ‰¾åˆ°ä¸€ä¸ªå˜æ¢çŸ©é˜µRï¼Œå½“ä¹˜ä»¥Xæ—¶ï¼Œç»™å‡ºä¸€ä¸ªåµŒå…¥Fçš„æ–°å•è¯ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥è®¡ç®—Yä¸­Fçš„æœ€è¿‘é‚»å±…ï¼Œå¹¶æ¨èæœ€ç›¸ä¼¼çš„å•è¯</p><p id="ac54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å› æ­¤ï¼Œæˆ‘ä»¬å°†å°è¯•æ‰¾åˆ°ä¸€ä¸ªå˜æ¢çŸ©é˜µRï¼Œä½¿å¾—è¯¥æ–¹ç¨‹æœ€å°åŒ–ï¼Œå…¶ä¸­x Ræ˜¯è®¡ç®—çš„è¾“å‡ºï¼ŒYæ˜¯ç›®æ ‡</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kb"><img src="../Images/047611ef272eea878394db331adfb75d.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/1*fPbR8Xr54myBnKIXtRpBiw.png"/></div></figure><p id="3e4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨çŸ©é˜µçš„FrobenoiusèŒƒæ•°æ¥è®¡ç®—æŸå¤±å‡½æ•°ã€‚FrobenoiusèŒƒæ•°ç”±ä¸‹å¼ç»™å‡º:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kc"><img src="../Images/e75ce1c0c5eb625909b31de58b52c86a.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*oQvxc851G5JttZwDa0EIyQ.png"/></div></figure><p id="0b8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å…¶ä¸­Iæ˜¯çŸ©é˜µaçš„è¡Œï¼Œjæ˜¯çŸ©é˜µaçš„åˆ—</p><p id="3567" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æŸå¤±å‡½æ•°å°†æ˜¯çŸ©é˜µä¸å…¶è¿‘ä¼¼å€¼ä¹‹å·®çš„FrobenoiusèŒƒæ•°çš„å¹³æ–¹ï¼Œé™¤ä»¥è®­ç»ƒæ ·æœ¬æ•°ğ‘š</p><ol class=""><li id="2758" class="kd ke hh ig b ih ii il im ip kf it kg ix kh jb ki kj kk kl bi translated">è®¡ç®—æŸå¤±å‡½æ•°:</li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es km"><img src="../Images/65df25a570681b47b794dadf9a99348a.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*ywWvfov_AR4qoXSNfBRgWg.png"/></div></figure><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="a2de" class="ju jv hh jq b fi jw jx l jy jz">loss = np.sum(np. square (np.dot (X, R) â€” Y))/m</span></pre><p id="f8c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kn"><img src="../Images/74303d955092b49705272d9275904aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*ojJgMLeHW7Fd_3bfruCw8w.png"/></div></figure><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="9144" class="ju jv hh jq b fi jw jx l jy jz">gradient = np.dot (X.T, (np.dot (X, R) â€” Y)) *(2 /m)</span></pre><p id="6d5a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•å¯»æ‰¾æœ€ä¼˜R</p><p id="f820" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®¡ç®—æŸå¤±ç›¸å¯¹äºçŸ©é˜µRçš„æ¢¯åº¦gï¼Œå¹¶è¿­ä»£æ›´æ–°R:</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="e004" class="ju jv hh jq b fi jw jx l jy jz">def tranformation_matrix():<br/>    for i in range(steps):<br/>        gradient = compute_gradient(X, Y, R) <br/>        R = R â€” learning_rate*gradient<br/>    return R</span></pre><p id="3b30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™ä¸ªå‡½æ•°è¿”å›å˜æ¢çŸ©é˜µRã€‚</p><p id="2305" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">k-NNæ˜¯ä¸€ç§ç®—æ³•ï¼Œå®ƒå°†ä¸€ä¸ªå‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶åœ¨æ•°æ®é›†ä¸­æ‰¾åˆ°ä¸å…¶æœ€æ¥è¿‘çš„å…¶ä»–å‘é‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨k-NNæ¥è·å¾—ä¸æ¥è‡ªå˜æ¢å‘é‡XRçš„åµŒå…¥æœ€æ¥è¿‘çš„åµŒå…¥ã€‚</p><p id="e988" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½™å¼¦ç›¸ä¼¼æ€§æ˜¯é‡åŒ–ä¸¤ä¸ªæ–‡æ¡£ä¹‹é—´ç›¸ä¼¼æ€§çš„ä¸¤ä¸ªå‘é‡ä¹‹é—´è§’åº¦çš„ä½™å¼¦ã€‚å¦‚æœæˆ‘ä»¬æŠŠå‘é‡çš„æ–¹å‘çœ‹ä½œå®ƒçš„æ„ä¹‰ï¼Œå®ƒå°±èƒ½æ›´å¥½åœ°æ•æ‰è¯­ä¹‰çš„ç›¸ä¼¼æ€§ã€‚æ­¤å¤–ï¼Œå‘é‡ä¹‹é—´çš„è§’åº¦æ›´ä¸å—å­—æ•°ç­‰å¤–éƒ¨å› ç´ çš„å½±å“ã€‚</p><p id="326b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½¿ç”¨åŸºæœ¬çš„ä¸‰è§’å‡½æ•°ï¼Œ</p><p id="4f74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Cos (0) = 1(å¦‚æœè§’åº¦ä¸º0ï¼Œå‘é‡åœ¨åŒä¸€ç›´çº¿ä¸Šï¼Œæ–¹å‘ç›¸åŒï¼Œå› æ­¤éå¸¸ç›¸ä¼¼)</p><p id="f3d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Cos (90) = 0(å¦‚æœè§’åº¦ä¸º90ï¼Œåˆ™çŸ¢é‡æ˜¯æ­£äº¤çš„ï¼Œå› æ­¤å®ƒä»¬ä¸ç›¸ä¼¼)</p><p id="f439" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">cos(180)=-1(å¦‚æœè§’åº¦ä¸º180ï¼Œåˆ™çŸ¢é‡å®Œå…¨ä¸åŒ)</p><p id="6b7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ‰€ä»¥å½“æ–‡ä»¶ä¹‹é—´çš„è§’åº¦Î¸åœ¨0Â°å’Œ90Â°ä¹‹é—´æ—¶(0&lt;= Cos(Î¸) &lt;= 1), we consider the documents to be similar, else dissimilar.</p><p id="69dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Since distance and similarity are not the same, we define distance metric using cosine similarity as</p><p id="e986" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">d = 1 -cos (u, v)</p><p id="3185" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">So we create a nearest neighbor function that takes in the vector, all possible nearest neighbors candidates and number of neighbors as input and gives the indices of top n closest neighbors as output.</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="d7a5" class="ju jv hh jq b fi jw jx l jy jz">def nearest_neighbor(v, candidates, k):<br/>    for row in candidates:<br/>        cos_similarity = cosine_similarity(row,v)<br/>        similarity_l.append(cos_similarity)<br/>        sorted_ids = np.argsort(similarity_l) <br/>    return sorted_ids[-k:]</span><span id="6488" class="ju jv hh jq b fi ka jx l jy jz">def get_translation(X, Y, R):<br/>    pred = np.dot(X,R)<br/>    for i in range(len(pred)):<br/>        pred_idx = nearest_neighbor(pred[i], Y, 1)<br/>    return pred_idx</span></pre><p id="3e2b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">So the closest neighbor returned by this function is the word embedding in French, which can be translated into its corresponding French word using the French embedding dictionary.</p><p id="5f37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">The machine translation accuracy obtained using this model is 56%</p><p id="a547" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Note : This blog is based on the new specialization NLP at <a class="ae jo" href="https://www.deeplearning.ai/" rel="noopener ugc nofollow" target="_blank">https://www.deeplearning.ai/</a></p></div></div>    
</body>
</html>
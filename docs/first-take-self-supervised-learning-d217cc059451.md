# 第一步:自我监督学习

> 原文：<https://medium.com/mlearning-ai/first-take-self-supervised-learning-d217cc059451?source=collection_archive---------6----------------------->

揭开一个可能改变人工智能/人工智能世界的概念的神秘面纱

我仍然被埋葬，所以还没有进入我的背传播博客帖子。然而，我确实遇到了一个对我来说全新的概念，我再次发现尝试研究这个概念很痛苦(参见我以前的博客中的经验总结…)，所以我花了一点时间来思考这个问题，并将很快在这里介绍我的学习结果。

大多数以数据为中心的机器学习方法的一个问题是，为了有价值，它们需要大量的带标签的训练数据。现实情况是，不幸的是，带标签的数据是一种稀缺商品(与可用数据的总量相比)，这意味着在我们能够知道我们的数据是否能够首先提供任何预测能力之前，必须在创建标签方面投入大量的人力。自我监督学习旨在解决这一问题，方法是允许机器学习算法在没有**人类标记数据的情况下* *生成预测模型，然后通过提供少量标记数据来将预测与人类可读输出对齐，从而使这些模型可用。

它的工作方式——也是大多数人在讨论它时忽略的事情——是第一步是使用机器学习方法来生成一组观察值的表示。假设您有 100，000 张未标记的图像，每张图像都存储在 10 个不同的旋转位置，总共有 1，000，000 张图像及其变体。这些图像首先被分解成矢量(ish)表示，这些矢量表示被存储为每个图像的数据标签。瞧，您现在已经快速标记了 1，000，000 张图片！当然，此时作为一个人类读者，你对这些标签无能为力，但我们稍后会谈到这一点。

在下一步中，你获取这些图像并训练第二个模型——这一次，屏蔽掉每个图像的一些部分。第二个模型被训练来预测丢失的向量分量，而不是它们的最终标签，并且达到尽可能高的精确度。

在最后一个阶段(虽然不一定要在最后发生，但我认为这并不重要，当它发生时)，你训练一个模型，将少量标记的训练数据与机器标记的语料库中的数据相关联。假设你有 5 类动物——狗、猫、马、鱼和昆虫。通过提供一小组比如 500 个带标签的图像(也可以旋转？)并让模型根据向量表示与原始训练数据集中 100，000 幅图像的接近程度来预测机器标记数据的类别。

那么，从理论上讲，你所做的是获取一个非常小的带标签的数据集，用它将意义应用到一个更大的机器标记数据的语料库，然后可以扩展它，为一个模型所做的预测提供意义，这个模型只在预测向量表示而不是人类可读的标签上进行训练。

漂亮的滑头！我在上面描述的方法[同样适用于标签、语音/波形和文本预测](https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text/)，因为各个阶段之间唯一的依赖关系是底层数据的矢量表示，而不是标签或数据类型本身。

我确信这将会引起我更多的注意。与此同时，我希望我的“最后一英里”解释对你有所帮助，如果你正试图理解这个概念并像我一样挣扎的话。欢迎评论和指正！

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
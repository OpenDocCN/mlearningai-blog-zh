<html>
<head>
<title>Python, Machine Learning, GANs, Synthetic Data, and Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python、机器学习、GANs、合成数据和Google Colab</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/python-machine-learning-gans-synthetic-data-and-google-colab-5bb43491a8c7?source=collection_archive---------3-----------------------#2021-11-11">https://medium.com/mlearning-ai/python-machine-learning-gans-synthetic-data-and-google-colab-5bb43491a8c7?source=collection_archive---------3-----------------------#2021-11-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/77b30f98147162332225ff0681dc1992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3nLcmI6k5Wp3qLWVeg0vmg.png"/></div></div></figure><div class=""/><p id="729c" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="jn">你想学习如何用机器学习和GANs制作人工生成的人脸吗？</em>我也没有。我想使用GANs从现有的二进制数据(我的训练数据)中学习，这样我就可以制作真实的合成数据。仅仅制造随机数据不足以满足我的需求。</p><p id="c85c" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">顺便说一句，这次旅行不是没有一些糟糕的旅行。在这篇文章的最后一节看到我的经验教训，你可能会节省一些时间。</p><h1 id="6569" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">问题陈述</h1><p id="7344" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我想创建单声道、8位音频样本(&lt; 64KB) using a GAN, that I can load in an old hardware sample, the Ensoniq Mirage. I have already written the software that can load the samples onto a floppy disk- <a class="ae kr" href="https://github.com/mogrifier/wavsyn/wiki" rel="noopener ugc nofollow" target="_blank">见Wavsyn Wiki </a>)，使它们真正易于使用。</p><p id="0bc5" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我正在现有的样本上训练GAN(主要是循环波形，但我也会尝试一些声音！)并看看它能产生什么。我的方法可能行不通</p><p id="eedc" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我不会像许多文章那样停止模型训练。我将使用经过训练的模型来生成更多图像，这是创建合成数据的全部目的。</p><h1 id="617c" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">让我们干杯</h1><p id="0459" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我正在寻找Windows相关问题的解决方案，无意中发现了Google Colab。它看起来很有趣，是基于Jupyter笔记本的，就像Kaggle和AWS Sagemaker一样。我已经使用Jupyter笔记本好几年了，所以没有想到这一点让我觉得很愚蠢。我甚至将笔记本内置到我设计的产品中，我的团队为DARPA开发了该产品，以支持原型机器学习算法。</p><p id="eda1" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">回到科拉布。Python开发的Jupyter笔记本？检查。与Google Drive集成用于文件的输入/输出？检查。仍然从访问您的笔记本吗？检查。免费在云端使用GPU？<strong class="ir ht">检查</strong></p><p id="1227" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae kr" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌实验室网站</a></p><p id="101f" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">笔记本还有其他优势。Python模块在云中安装非常快，预装了许多关键模块。您也可以安装自己的模块。Colab用的是Ubuntu，所以很支持Python模块。您可以从任何可以访问网络的计算机上访问该笔记本。如果事情变得非常糟糕，只需重启您的会话，就好像扔掉一个虚拟机或云实例，但不必做任何相关的设置！</p><h1 id="98d2" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">用于合成数据创建的GAN</h1><p id="e03d" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">GAN是一个生成性的对抗网络。两个神经网络被用来相互竞争。一个(图像生成器)试图根据输入的训练数据生成好看的数据。另一个(鉴别器)尝试确定数据是真实的还是来自GAN。它会产生一个反馈回路，改进图像生成器，目标是创建欺骗鉴别器的结果。</p><p id="35c1" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请注意，在这次旅程中，我对不同数据类型的不同机器学习方法有了一些其他想法。在我的侧钻下面有一节讨论了这一点。</p><h1 id="7f23" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">预处理</h1><p id="eb15" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我选择PyGAN做这个练习。和其他许多软件一样，它是用来处理图像的。其他神经网络(如CNN)也是面向图像的，所以我的技术也适用于此。我的初始数据不是图像，但我的数据是二进制的，所以它可以重新格式化，看起来像一个图像，以<em class="jn">欺骗GAN使用我的数据</em>。</p><p id="4983" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在我的第一个方法中，我选择的数据失败了(但是可以用于其他数据类型！)，我为这篇文章创建了一个有效的位图头:<a class="ae kr" href="https://en.wikipedia.org/wiki/BMP_file_format" rel="noopener ugc nofollow" target="_blank"> BMP文件格式—维基百科</a>，并在我所有的训练数据文件前添加了一个14字节的位图头和一个40字节的DIB头。我忽略了颜色图，因为我真的只有关闭或打开的像素。像素颜色值无关紧要。然后，GAN可以处理数据。</p><p id="4580" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于数据的限制，我切换到不同的数据类型(音频),并使用不同的技术来创建GAN所需的图像。我用我的1d音频数据创建了一个2d数组，并用它制作了一个位图。这就像音频程序通过将音频文件转换成振幅与时间的关系图来可视化音频文件一样，比如Audacity。我的代码如下。</p><p id="0258" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="jn">注意——这个编辑器对预格式化的代码做了一件可怕的工作，Python有非常严格的格式化规则(恶心)。这意味着制表符和空格被删除了，我已经试着把它们添加回去，这样你就可以很容易地复制和使用这段代码。</em></p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7958" class="lb jp hs kx b fi lc ld l le lf">import os<br/>import sys<br/>import numpy as np<br/>import struct<br/>import matplotlib.pyplot as plot<br/>from PIL import Image, ImageDraw</span><span id="3f55" class="lb jp hs kx b fi lg ld l le lf">'''<br/>Takes the data from an inputFile, which should be an 8-bit PCM file (no wave header). Reads it and processes into a 256 x 256 array for conversion to a bitmap. Writes the bitmap to the outputFile.<br/>'''</span><span id="154f" class="lb jp hs kx b fi lg ld l le lf">def sampleToBitmap(inputFile, outputFile):<br/>    source = read_file_bytes(inputFile)<br/>    rows = len(source)<br/>    cols = 256<br/>    a_2d = np.zeros((rows, cols), dtype=np.uint8, order='C')<br/>    for i in range(rows):<br/>        val = source[i]<br/>        # reverse data to get it to look like audio file should<br/>        a_2d[(rows -1) - i][val] = 10</span><span id="c7c7" class="lb jp hs kx b fi lg ld l le lf"># compress the sample data down to 256 x 256. Average the values.<br/>compress = int(rows / 256)<br/>a_2d = np.zeros((256, 256), dtype=np.uint8, order='C')<br/>val = 0<br/>for j in range(0, 256):<br/>    val = 0<br/>    for k in range(compress):<br/>        val = val + source[j * compress + k]<br/>        #average<br/>        avg = int(val / compress)<br/>        a_2d[j][avg] = 10</span><span id="fd83" class="lb jp hs kx b fi lg ld l le lf"># Need to draw the data and connect the points together, then output as a bitmap</span><span id="a069" class="lb jp hs kx b fi lg ld l le lf">#Create Image object. L is for bitmap<br/>im = Image.new('L', (256, 256), color = 'white')<br/>pt1 = (0,0)<br/>pt2 = (0,0)<br/>for j in range(256):<br/>    for k in range(256):<br/>        if a_2d[j][k] &gt; 0:<br/>            pt1 = (j, k)<br/>            if j &lt; 255:<br/>                if a_2d[j + 1][k] &gt; 0:<br/>                    pt2 = (j, k)</span><span id="a222" class="lb jp hs kx b fi lg ld l le lf">    #Draw line<br/>    draw = ImageDraw.Draw(im)<br/>    draw.line([pt1, pt2], fill=(0))</span><span id="2341" class="lb jp hs kx b fi lg ld l le lf">im.save(outputFile)</span></pre><p id="e8f9" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我在包含音频样本训练数据的目录中循环调用了上面的代码，并为每个文件生成了一个位图。我的初始训练集有186个文件。这是256x256位图的音频文件示例:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div class="er es lh"><img src="../Images/07f243c1b8a72c0356fe5208ff7dee6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*Hwo59jAgvvrI1PZWEvKm7A.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Subset of training data bitmaps to be fed into the GAN</figcaption></figure><p id="7929" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦位图制作完成，我就把它们上传到我的谷歌硬盘的一个文件夹里，以便在笔记本上使用。</p><h1 id="6598" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">其他方法</h1><p id="3ef5" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated"><em class="jn">【这是一个你可以稍后阅读的侧道】</em>其他类型的数据需要其他类型的机器学习方法。在我的第一次尝试中，我使用的数据集在转换为图像时不具备处理GAN所需的功能和结构。这些数据看起来非常随机，一点也不像图像。没有明确定义的特征供神经网络学习，因此没有什么可供GAN使用。结果没用。阿甘只是一个错误的选择。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div class="er es lm"><img src="../Images/0973e9553963926b13af5afa9e63ee90.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*kePCq2ct_2UNdo8mv7U2zw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Bitmap of test data from first attempt</figcaption></figure><p id="dc69" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在做了更多的阅读后，多层感知器网络会是一个更好的选择，因为我的数据集中的每个数据块都是一个1D向量，相当于CSV文件中的一行。将此转换为与GAN一起使用的位图无助于在生成的数据中创建新的特征，并且一般来说，在列之间几乎没有要学习的关系。为了让深度学习发挥作用，这些特征和关系需要存在。我从这种方法中获得的数据显示，所有数据都是平均的，在0-255个值的范围内，GAN的输出将所有数据点大致放在125-130之间。这是没有用的。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div class="er es ln"><img src="../Images/67f472a3049abb2550abed142b40af6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*hXs4RysyL13ewuXkxp35_w.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">GAN output</figcaption></figure><p id="ae57" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">还有其他值得注意的软件问题，这些是真正的交易破坏者。我的数据在大小上有限制。它必须准确——每行数据有1178个字节。我开始用PyGAN和Accel-Brain软件处理图像(见<a class="ae kr" href="https://code.accel-brain.com/Generative-Adversarial-Networks/README.html" rel="noopener ugc nofollow" target="_blank">https://code . Accel-Brain . com/Generative-Adversarial-Networks/readme . html</a>)。三个图像生成器中的两个正在生成图像中多了一些行和列的输出。虽然对于生成图像来说很好，但当我需要输出精确的字节数时，这是一场灾难。这些模块——GANImageGenerator，ebaeimagegenerator——重塑了数据。前者可能会产生错误的字节数输出，而后者会在形状不匹配时出错。沿着这条路继续走下去是没有意义的。EBGANImageGenerator可以产生输出，但是数据点的范围很窄，没有用。</p><p id="14cd" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于我使用音频数据的第二次尝试，你也可以使用LSTM(长短期记忆)方法。LSTM是递归神经网络的一个亚型。我没有试过这个，但我知道它们对视频和音频都有好处。LSTM基于以前的数据创建新数据，所以像音频文件或流这样的数据是有意义的，因为它是按时间排序的。</p><h2 id="4889" class="lb jp hs bd jq lo lp lq ju lr ls lt jy ja lu lv kc je lw lx kg ji ly lz kk ma bi translated">这个故事的寓意</h2><p id="1b2e" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">你选择的机器学习方法会极大地影响你的结果。您可能还需要尝试多种方法来找到最佳结果。</p><h1 id="d657" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">甘码</h1><p id="59c0" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">PyGan有三种不同的算法可供选择用于Gan。关于不同算法的信息见<a class="ae kr" href="https://code.accel-brain.com/Generative-Adversarial-Networks/README.html" rel="noopener ugc nofollow" target="_blank">生成对抗网络库:pygan-pygan文档(accel-brain.com)</a>并见使用它们的样本代码。</p><p id="c613" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下面的代码直接来自示例代码。为了测试我的方法，我特意设置了一个较低的学习迭代次数(iter_n = 20)。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9e2b" class="lb jp hs kx b fi lc ld l le lf">import numpy as np<br/>import os<br/>import pygan<br/>import sys</span><span id="bf72" class="lb jp hs kx b fi lg ld l le lf">from pygan.gan_image_generator import GANImageGenerator<br/>from logging import getLogger, StreamHandler, NullHandler, DEBUG, ERROR</span><span id="d997" class="lb jp hs kx b fi lg ld l le lf">logger = getLogger("accelbrainbase")<br/>handler = StreamHandler()<br/>handler.setLevel(DEBUG)<br/>logger.setLevel(DEBUG)<br/>logger.addHandler(handler)</span><span id="071b" class="lb jp hs kx b fi lg ld l le lf">#my fake 256x256 bitmaps are in "/content/drive/My Drive/patches/".</span><span id="7e0b" class="lb jp hs kx b fi lg ld l le lf">gan_image_generator = GANImageGenerator(<br/>    # `list` of path to your directories.<br/>    dir_list=["/content/drive/My Drive/patches",],<br/>    # `int` of image width.<br/>    width=256,<br/>    # `int` of image height.<br/>    height=256,<br/>    # `int` of image channel.<br/>    channel=1,<br/>    # `int` of batch size.<br/>    batch_size=40,<br/>    # `float` of learning rate.<br/>    learning_rate=1e-06<br/>)</span><span id="1238" class="lb jp hs kx b fi lg ld l le lf">gan_image_generator.learn(<br/>    # `int` of the number of training iterations.<br/>    iter_n=20,<br/>    # `int` of the number of learning of the discriminative model.<br/>    k_step=10<br/>)</span><span id="2eb4" class="lb jp hs kx b fi lg ld l le lf">print(gan_image_generator.GAN.posterior_logs_arr)<br/>arr = gan_image_generator.GAN.generative_model.draw()</span></pre><p id="32c6" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你可能想知道神经网络在哪里？PyGAN提供了一个默认的，但是您可以覆盖它。网络是在<a class="ae kr" href="https://code.accel-brain.com/Generative-Adversarial-Networks/_modules/pygan/gan_image_generator.html#GANImageGenerator" rel="noopener ugc nofollow" target="_blank"> pygan.gan_image_generator源代码</a>中定义的，这给了你一个很好的模板来创建你自己的网络。</p><p id="4635" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">运行GAN时，您如何知道何时完成？训练模型产生关于误差量的输出，但是GAN具有两个模型(网络),使得这更加困难。</p><p id="5f64" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir ht"> <em class="jn">填写读甘输出上的错误和学习成功的</em> </strong></p><p id="f126" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">5次迭代:[0.49988141 0.46187854 0.50002797 0.45569888 0.50001973 0.46612009 0.50014204 0.45283565 0.4996585 0.43780279]</p><p id="32d0" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">20次迭代:【0.50017167 0.55513453 0.50019184 0.55407137 0.49999906 45 0.5470007 77 0.50007 812 0.54849 999784 1 0.54999 786 0.5495</p><p id="6bea" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后我运行了250次迭代，最终得到了如下的好值(0.50很好):</p><p id="ed19" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi">… 0.49962118 0.50590265 0.50013419 0.50725633 0.50022006 0.51314133 0.49990247 0.5052942 0.4999769 0.50594449 0.50027339 0.50536716 0.49983954 0.50563681 0.49972819 0.50757897 0.50013671 0.50382507 0.50012222 0.50401735]</p><p id="ec06" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我确实对我的GAN神经网络做了一个改变。在鉴别器中，我将activation_list变量中的sigmoid改为tanh。Tanh应该是一个更好的函数。</p><h1 id="8ec5" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">如何从模型生成新图像</h1><p id="9c26" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我需要使用GAN训练的模型来输出新的图像。这行代码告诉经过训练的生成模型这样做。</p><blockquote class="mb mc md"><p id="6db6" class="ip iq jn ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">arr = gan_image_generatorGAN.generative_model.draw()</p></blockquote><p id="9315" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">连续的调用将从模型中输出一组新的图像，可用的数量等于批量大小。</p><h1 id="412e" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">从四维数组中读取二维图像</h1><p id="eec9" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">输出存储在名为“arr”的4d NDArray中。它的形状是(40，1，259，259)。40是批次号，1是图像通道号，图像形状是259 x 259。请注意，输出形状略有不同，它有3个额外的行和列。通道与颜色通道的数量有关。RGB颜色= 3个通道。黑白= 1个通道(所以每个像素只有一个值)。</p><p id="ec64" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">训练结束后，您可以从“arr”中获取数据，如下所示。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7b95" class="lb jp hs kx b fi lc ld l le lf">from PIL import Image</span><span id="567b" class="lb jp hs kx b fi lg ld l le lf">from matplotlib import cm<br/>from matplotlib import pyplot as plt<br/>import mxnet</span><span id="7b07" class="lb jp hs kx b fi lg ld l le lf">for i in range(10):<br/>    image2d = arr[i, 0, :, :]<br/>    # arr and image2d are instances of mxnet.ndarray.ndarray.NDArray<br/>    # convert to a numpy ndarray for use with matplotlib<br/>    img = image2d.asnumpy()<br/>    # scale to 0-255<br/>    img = img * 255<br/>    img = img.astype(np.uint8)<br/>    # colorizes if default color map of 'viridis' is not changed.<br/>    # add argument cmap='gray' for grayscale. Data not changed.<br/>    plt.imshow(img, cmap='gray')<br/>    plt.show()</span></pre><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mh"><img src="../Images/98ff83de1a1b7adbf9dffe9b82b6de10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XXiDeDf4VMptKFUzhZTrFw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Output files from a very short training run at 256x256</figcaption></figure><p id="7184" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个数据显然比第一次尝试的随机数据好得多；然而，它并不完美，因为线条有点太粗了。我在图像中的训练数据行都是单个像素。另外，这些看起来和一些输入文件非常相似，尽管这是GAN应该做的。</p><p id="a976" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">线条的粗细是一个问题，这使得很难像在输入文件中那样提取出漂亮的线条画。我需要那张线条画。可能训练不够，所以我会看看更多的迭代做什么。</p><p id="cfae" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我在一个更真实的64 x 64的图像尺寸上做了另一次运行，但是为了比较只进行了10次迭代。超级丑又模糊。您还可以看到整形(由于卷积核大小或步幅)的影响，使图像变成67x67，但只是在这些额外的区域放置了垃圾(黄线)。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div class="er es mi"><img src="../Images/cf1fe94936b9782c1d7156bcc3ce8ba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:134/format:webp/1*Mkf4caQXCDrPkkgYcsRGKQ.jpeg"/></div><figcaption class="li lj et er es lk ll bd b be z dx">GAN output from 10 training iterations</figcaption></figure><p id="73ef" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些结果促使我更深入地研究GAN和我的代码产生的数据。我遇到了与缺乏正常化相关的严重问题。值的范围大约在-5到+ 3之间，而我期望的是-1到+1，每个数据数组(代表一个图像)都有不同的最小值和最大值。当使用numpy转换为uint8时，超出范围的值被“包装”起来，在奇怪的地方增加了点。<strong class="ir ht">一定要分析你的输出！</strong></p><p id="ccd2" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在我的代码中，我现在处理每个图像的输出数组，并确保它在0–255(uint 8)的范围内正常化。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="a9dd" class="lb jp hs kx b fi lc ld l le lf">for kk in range(20):<br/>    image2d = arr[kk, 0, :, :]<br/>    # arr and image2d are instances of mxnet.ndarray.ndarray.NDArray<br/>    img = image2d.asnumpy()<br/>    # scale to 0-255.<br/>    max = img.max()<br/>    min = img.min()<br/>    for i in range (259):<br/>        for j in range (259):<br/>            val = img[i][j] + min<br/>            if val &lt; 0:<br/>                val = 0<br/>            val = (val / (min + max)) * 255<br/>    img = img.astype(np.uint8)</span><span id="b178" class="lb jp hs kx b fi lg ld l le lf"># then save the array, img.</span></pre><p id="9efb" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图像现在清晰多了，可以使用了。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div class="er es mj"><img src="../Images/85f7aa96210bc781af4062163a019083.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*k1NMW2vZvmk0JZ_GQXVmyA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Properly Normalized Output</figcaption></figure><p id="fd05" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我开始后期处理，但很难从紫色中分离出黄色像素。似乎使用matplotlib将我的数据保存为位图的行为极大地改变了它，并使numpy数组中的每个字节都变成了4字节的值，即使我指定了灰度色图。这既奇怪又糟糕，所以我需要在保存为图像之前研究numpy数组(反正我不需要这个图像)。这段代码让我保存用于分析的数据数组。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2c40" class="lb jp hs kx b fi lc ld l le lf"># save numpy array as npy file<br/>from numpy import asarray<br/>from numpy import save</span><span id="8238" class="lb jp hs kx b fi lg ld l le lf">for kk in range(50): <br/>    image2d = arr[kk, 0, :, :]</span><span id="3eac" class="lb jp hs kx b fi lg ld l le lf"># arr and image2d are instances of mxnet.ndarray.ndarray.NDArray<br/>    # convert to a numpy ndarray for use with matplotlib<br/>    img = image2d.asnumpy()<br/>    # scale to 0-255. <br/>    max = img.max()<br/>    min = img.min()</span><span id="ebbc" class="lb jp hs kx b fi lg ld l le lf">for i in range (259):<br/>        for j in range (259):</span><span id="c708" class="lb jp hs kx b fi lg ld l le lf">val = img[i][j] + min<br/>          if val &lt; 0:<br/>              val = 0</span><span id="5bd5" class="lb jp hs kx b fi lg ld l le lf">val = (val / (min + max))    * 255</span><span id="2873" class="lb jp hs kx b fi lg ld l le lf">img = img.astype(np.uint8)<br/>    #result is 259 by 259 array of uint8</span><span id="8fcf" class="lb jp hs kx b fi lg ld l le lf"># colorizes if default color map of 'viridis' is not changed.<br/>    # add argument cmap='gray' for grayscale. Data not changed.<br/>    plt.imshow(img, cmap='gray')<br/>    plt.show()</span><span id="2773" class="lb jp hs kx b fi lg ld l le lf"># I want to process columnwise, so transpose the array axes<br/>    d2trans = np.transpose(img)<br/>    # convert to a 1d array<br/>    d1 = d2trans.flatten()<br/>    # save to npy file<br/>    name = f"/content/drive/My Drive/syntheticTANH250iter/output{kk}"<br/>    save(name, d1)</span></pre><p id="85ff" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">处理4个字节的值并不困难，只要你知道这就是你所拥有的。</p><h1 id="b427" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">后加工</h1><p id="5ff7" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我的数据有限制，即它必须作为单声道音频文件使用，这是一个一维数组。这意味着有一些后处理要做，因为如果我只是打开这些图像文件，就好像它们是PCM音频数据，并播放它们，我得到的只是一个可爱的静态。对于您的特定数据需求，您可能会面临类似的挑战。数据处理，我的意思是管理，是机器学习的大部分工作，因为:</p><ul class=""><li id="aeed" class="mk ml hs ir b is it iw ix ja mm je mn ji mo jm mp mq mr ms bi translated">它对于需要定制编码的特定数据来说是非常具体的</li><li id="848c" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">机器学习算法，像其他任何东西一样，需要良好的输入</li></ul><p id="d205" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我在上面提到了预处理(将数据转换成位图)。我将给出从您创建的合成文件中获取数据的要点。</p><p id="9484" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于创建输出图像是将字节转换成4字节值，因此图像不是最佳选择，需要更多的处理。不过，它们看起来很好，可以看出事情是否正常。</p><ul class=""><li id="5180" class="mk ml hs ir b is it iw ix ja mm je mn ji mo jm mp mq mr ms bi translated">将每组输出数据(离散图像数据)保存为2d数组</li><li id="0a0d" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">读取一整行数据</li><li id="e0e9" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">根据需要插入新数据(见下文)</li><li id="7536" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">将该行写入临时数组</li><li id="ef25" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">将临时数组添加到用于保存所有数据的字节数组中</li><li id="f56f" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">重复此操作，直到读取完所有行</li><li id="eb35" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">将新数据的字节数组写入文件</li><li id="f3ff" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">检查数据(健全性检查)并测试(对我来说，这意味着将文件作为音频播放)</li></ul><p id="6d9d" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对我来说，结果是一个8位(无符号整数)PCM音频文件(无波形头),供我的音乐硬件和软件使用。</p><h2 id="99df" class="lb jp hs bd jq lo lp lq ju lr ls lt jy ja lu lv kc je lw lx kg ji ly lz kk ma bi translated">数据插值</h2><p id="8c4f" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">这在我的用例中是必需的，因为我首先对我的8位训练数据进行采样和压缩，以将音频样本降低到256x256位图。相反的过程需要通过插入中间值将数据从256x256扩展到任何原始样本长度。有几个算法你可以尝试，但他们分为几类:线性或曲线拟合。线性就是简单地连接这些点，并在GAN的输出之间插入新的数据点。曲线拟合需要查看几个点，并应用与它们匹配的曲线，这比较复杂。对于8位数据值，我认为线性可能就足够了。</p><h1 id="06fa" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">成品呢？？</h1><p id="5732" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">使用来自GAN输出的8位PCM文件和我的后处理代码(如上所述)，我制作了下面的位图。您将会看到与上面训练数据集图片的相似之处。PCM音频文件在Audacity中也能正常播放，我将能够加载到我的采样器中。奇怪的是，播放我只是为了检查数据而制作的位图也在Audacity中“播放”，并创建了漂亮的脉宽调制方波(就像科幻电影声音中的电流)。用一点点音频工作是非常宽容的。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es my"><img src="../Images/d7b7659de577ab5c5edc2f259deb4126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*erFc7IeUEZI75lEhBHPFww.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">GAN output represented as bitmaps of the audio waveform</figcaption></figure><p id="db2a" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然而，数据不仅仅是相似。我用更高的训练迭代做了一些运行，看了大约5000张图像，所以你不必这样做！几乎所有的数据都来自训练数据，所以我正在经历一种叫做</p><blockquote class="mb mc md"><p id="c5b0" class="ip iq jn ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">模式崩溃</p></blockquote><p id="90c9" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">那么，我如何摆脱这种情况，让GAN给我新的数据呢？阅读建议调整学习速度。较小的批量也可能有所帮助。问题是你不知道从哪里开始或者什么会起作用。这意味着您需要创建一组想要调整的参数，并使用每个参数运行系统，保存输出和用于创建参数的参数列表(运行元数据)。然后，直观地检查输出，看看哪组参数做得最好。您可以使用CNN来自动检查，但有趣的是，您想要看起来不同的图像，而不是与您的训练集相同的图像，因此得分低的输出将是最好的输出！</p><h1 id="9db4" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">解决模式崩溃</h1><p id="ce86" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">如果我第一次就把一切都做对了，我就不会发表这篇文章，所以这是解决模式崩溃的一个更新。改变学习速度是一个好计划。总的来说，较大的学习率对我有用，但是YMMV。我用了3e06，4e06，5e05。仍然有一些空数组，但是很少。我知道我正在从GAN获得良好的原始输出，因为我可以看到一些使用不同参数运行的相关图像，但正如您在下面看到的那样，它们只是略有不同。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mz"><img src="../Images/09f1a705be5f6760ca55508cca416a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-rGotoSXEh9t_mKuWfjYug.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Similar, but different</figcaption></figure><p id="9f26" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里有一组数据，显示了使用不同学习率时的一些结果。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es na"><img src="../Images/eff081e640bbd9ac537ea656a05a3d67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*znBaZ9FznffhdBIstwttQw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Good output from the GAN</figcaption></figure><p id="9ddf" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些数据集并不都是音乐上有用的，但有些有前途，现在我可以用GAN生成更多。</p><p id="5874" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">顺便说一下，批量大小8只给了我0的数组，不考虑其他参数。</p><p id="15aa" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="jn">有一步我没有尝试，但也是推荐的，就是用不同的学习速率训练两个网络。</em></p><h1 id="10b3" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">保存Colab的输出</h1><p id="602e" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">有很多方法可以做到这一点。我在下面展示了其中的几个。第一个是保存二进制数据(这是我的用例所需要的)。第二个将你的数据的CSV文件写入你的Google Drive。</p><h2 id="4449" class="lb jp hs bd jq lo lp lq ju lr ls lt jy ja lu lv kc je lw lx kg ji ly lz kk ma bi translated">方法1</h2><p id="63ff" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我展示这个只是因为它是一个</p><blockquote class="mb mc md"><p id="08dd" class="ip iq jn ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">不好的方式，不会工作的权利！！</p></blockquote><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6209" class="lb jp hs kx b fi lc ld l le lf">from google.colab import files</span><span id="537a" class="lb jp hs kx b fi lg ld l le lf">for i in range(40):<br/>    name = f"output{i}.pcm"<br/>    image2d = arr[i, 0, :, :].asnumpy()<br/>    dst1d = image2d.reshape(1, 259 * 259)<br/>    data = dst1d.tobytes()<br/>    output = open(name, 'wb')<br/>    output.write(data)<br/>    output.close()</span><span id="b6d8" class="lb jp hs kx b fi lg ld l le lf">files.download(name)</span></pre><p id="74eb" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这适用于一些文件，但不是大规模的。我试了40个，只收到十几个。</p><h2 id="4367" class="lb jp hs bd jq lo lp lq ju lr ls lt jy ja lu lv kc je lw lx kg ji ly lz kk ma bi translated">方法2</h2><p id="f7c4" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">这是写入任意文件的最佳方式——使用您的挂载点将它们直接写入Google Drive。<em class="jn">任何保存文件的库都可以保存到你的挂载点路径，就好像它是一个本地硬盘一样。</em></p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="4903" class="lb jp hs kx b fi lc ld l le lf">from google.colab import drive</span><span id="189c" class="lb jp hs kx b fi lg ld l le lf">drive.mount('/content/drive')</span><span id="c25e" class="lb jp hs kx b fi lg ld l le lf">for i in range(40):<br/>    name = f"/content/drive/My Drive/syntheticpatches/output{i}.pcm"<br/>    image2d = arr[i, 0, :, :].asnumpy()<br/>    dst1d = image2d.reshape(1, 259 * 259)<br/>    data = dst1d.tobytes()<br/>    output = open(name, 'wb')<br/>    output.write(data)<br/>    output.close()</span></pre><p id="4668" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您可能想知道方法2与numpy.save有何不同。答案是这种方法只保存没有numpy头的字节。使用numpy.save方法时，一个128字节的头放在文件的开头。这个头文件的存在使得numpy可以很容易地从以前保存的数组中加载二进制数据。头包括元数据，如顺序(C或Fortran)和数据的形状。如果没有这些额外的信息，numpy就不知道保存数据的数组的形状。</p><h2 id="1baf" class="lb jp hs bd jq lo lp lq ju lr ls lt jy ja lu lv kc je lw lx kg ji ly lz kk ma bi translated">方法3</h2><p id="3192" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">这使用pandas DataFrame功能来保存合成数据。熊猫模块已经和一个文件处理模块一起安装在Colab笔记本中。需要进行一些转换，如下所示。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8c36" class="lb jp hs kx b fi lc ld l le lf">from google.colab import files<br/>import pandas as pd<br/>#save data to a file<br/># 40 batches so that is how many images to save</span><span id="9ca0" class="lb jp hs kx b fi lg ld l le lf">for i in range(40):<br/>    # this reads 2 dimensions from a 4-dimensional array<br/>    image2d = arr[i, 0, :, :]<br/>    # arr and image2d are instances of mxnet.ndarray.ndarray.NDArray<br/>    # convert to a numpy ndarray for conversion to DataFrame<br/>    img = image2d.asnumpy()<br/>    # scale to 0-255<br/>    img = img * 255<br/>    img = img.astype(np.uint8)<br/>    output = pd.DataFrame(img)<br/>    output.to_csv(f"/content/drive/My   Drive/patches/synthetic2darray_{i}.csv")</span><span id="5583" class="lb jp hs kx b fi lg ld l le lf">drive.flush_and_unmount()<br/>print('All changes made in this colab session should now be visible in Drive.')</span></pre><p id="f7c3" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">是的，我的文件保存了！但是它们都是错误的形状。GAN图像生成器正在改变输入形状，我不知道为什么。也许是因为我需要使用默认的神经网络定义来提供我自己的神经网络定义。在任何情况下，我的数据都可以被重塑，我可以把它重塑回来。</p><p id="e572" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">保存到CSV很简单，但结果数据不是二进制文件。你可能需要更多的转换，这取决于你的假图像数据首先是什么。</p><h1 id="1d3d" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">多类合成数据</h1><p id="10a7" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">如果您只有一种类型的输入数据，并试图从其建模和创建新的合成数据，那么您应该感到幸运。如果有多类数据，则需要多类训练数据。如果您的数据还没有被分类，您还有一些额外的工作要做。聚类算法(非监督算法，如k-means)应该可以做到这一点。一旦数据集被分成聚类(就像将每个聚类放在自己的文件夹中一样简单)，就可以对每个文件夹运行整个GAN过程，以创建特定于类的合成数据，而不是所有类的大杂烩。我可能需要更多的训练数据来填写每个类，但这是一个不同的问题。</p><h1 id="15c0" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">天空中伟大的GPU</h1><p id="c63d" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">你应该使用GPU运行你的代码，Colab免费提供。我有一个图形处理器，但它是旧的，是镭龙制造的。使用MxNet和AMD GPU需要大量的设置，不值得。</p><ul class=""><li id="993f" class="mk ml hs ir b is it iw ix ja mm je mn ji mo jm mp mq mr ms bi translated">导航至编辑→笔记本设置</li><li id="fd7b" class="mk ml hs ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated">从硬件加速器下拉列表中选择GPU</li></ul><p id="ebfa" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">启用GPU后，由于使用的是不同的服务器，任何安装的模块(通过pip)都需要重新安装。会话结束时也是如此。只需将安装代码放入笔记本，然后重新运行所有程序。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="bfb5" class="lb jp hs kx b fi lc ld l le lf">!pip install pygan<br/>!pip install mxnet    [cpu only]<br/>!pip install mxnet-cu101     [gpu only]</span></pre><p id="c4ab" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir ht">注意— </strong>启动新会话还需要您重新验证您的google drive，因此也要重新运行，并单击运行此代码时出现的链接。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="bcff" class="lb jp hs kx b fi lc ld l le lf">from google.colab import drive<br/>drive.mount('/content/drive')</span></pre><p id="9bb9" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">值得注意的是，Google Colab的免费等级是有限制的。它们也没有很好的定义。我尝试了400次训练迭代，我因GPU过度使用而断开连接，但没有给出任何细节。当然，你可以付费购买Colab Pro，重新回到游戏中。参见<a class="ae kr" href="https://research.google.com/colaboratory/faq.html#resource-limits" rel="noopener ugc nofollow" target="_blank"> Google Colab资源限制</a>。我也可以试试我桌子上的Nvidia Jetson，看看它是否能承受这样的负载。</p><h1 id="4b07" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">你学到了什么？</h1><p id="a645" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">这是一个具有挑战性的主题，但有像Google Colab这样的好工具。你知道如何将它与你的Google Drive整合，并从你的Jupyter笔记本中获取数据。您需要确保您的数据和问题适合GAN。你需要准备尝试不同的方法。当数据看起来很奇怪时，深入挖掘，看看到底发生了什么。阅读源代码。观察模式崩溃，然后尝试修复它。</p><p id="16c5" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">正确处理输入和输出数据比运行基本的GAN更困难。一旦您控制了IO，您就可以轻松地为GAN使用其他代码。<a class="ae kr" href="https://github.com/eriklindernoren/PyTorch-GAN" rel="noopener ugc nofollow" target="_blank">查看PyTorch项目中的大量技术</a>。</p><h1 id="d1b6" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">未来</h1><p id="f3c2" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">有一些相关的活动我会尝试。我已经提到了我的第一种方法，它不适用于GAN，但应该适用于多层感知器网络。我还计划使用一些其他数据(MIDI文件)，我可以预处理成图像文件，因此，将与GAN一起工作。</p><h1 id="d297" class="jo jp hs bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">课程</h1><p id="0a91" class="pw-post-body-paragraph ip iq hs ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">以下是我从这一努力中学到的一些经验。</p><p id="74b9" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我第一次在Windows 11(！)并尝试安装相同的库(PyGAN和Apache MxNet之类的依赖项)并在本地进行开发。令人沮丧的几个小时后，我放弃了。根本问题是Windows 11安装了Python 3.10(也可能是我安装的，因为是最新的)。无论如何，它在2021年10月才发布，Python生态系统的其余部分都在支持它。我确实通过降级到Python 3.9.7并从我的路径中移除3.10来解决这个问题。这使得安装像numpy和scipy这样的好库变得可行(scipy在3.10中已经破产)。我也可以安装mxnet，尽管它确实把我的numpy安装版本降级到了1.16.6。</p><p id="6e4b" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最终，Google Colab更简单，如果你没有GPU，你可以使用GPU，但你不能做很多迭代而不会因为过度使用而被踢出局。</p><p id="0d4b" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我的第一轮GAN方法揭示了我的数据中一个有趣的问题。我有奇数行(31)。图像处理库不喜欢这样。MxNet(PyGAN使用的)在试图操作我的数据时产生整形错误。有一些图像库可以将你的高度或宽度从奇数变为偶数。这对于图像处理来说可能没问题，但对于我的合成数据来说就不一样了。我确认问题出在31行，只需将它改为30行。不知道我的额外的数据行去了哪里，但甘跑了。</p><p id="9f6d" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我仍然不确定我的256 x 256的图像尺寸是否有问题。这对于GAN来说很大(应该是一半或四分之一或更少)，但较小的图像会失去音频保真度，需要更多的插值。权衡比比皆是。甘是训练，虽然，但可能只是学习了太多的设置(如过度拟合)。</p><p id="42ce" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">缺少许多API的文档，并且您不知道数据发生了什么。我在matplotlib中特别看到了这一点，所以我不再使用它进行一些处理。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/reinforcement-learning-learning-a6e45d4502a5?source=collection_archive---------5-----------------------#2022-07-27">https://medium.com/mlearning-ai/reinforcement-learning-learning-a6e45d4502a5?source=collection_archive---------5-----------------------#2022-07-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="cb87" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">增强学习是人工智能蛋糕上的樱桃，机器学习是蛋糕本身，深度学习是糖衣。如果没有前面的迭代，cherry将一无所获。</p><p id="0b85" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated"><em class="hh">——扬·勒村</em></p></blockquote><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/fb591d0ce94bcc3e24a3929851a7770e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BrLlGX8CIo_Q0eUM"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">Reinforcement Learning is has immense potential in the gaming industry</figcaption></figure><p id="c2f1" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi jz translated"><span class="l ka kb kc bm kd ke kf kg kh di"> R </span>强化学习(RL)是一种机器学习，涉及智能代理如何在动态环境中做出决策，在这种环境中，它应该执行某个目标，以使累积报酬最大化。环境是智能体生活和互动的世界。特工们接受奖惩机制的训练。代理人因正确的移动而得到奖励，因错误的移动而受到惩罚。重复时，代理试图最小化错误的，最大化正确的。它是机器学习的三个基本类别之一，与监督学习和非监督学习并列。</p><p id="a463" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">强化学习与监督学习的不同之处在于，在监督学习中，训练数据带有答案，因此模型是用正确的答案来训练的，而在强化学习中，没有答案，而是由强化代理来决定如何执行给定的任务。在没有训练数据集的情况下，它必然会从自己的经验中学习。强化学习的诞生可以追溯到1957年，当时理查德·贝尔曼推导出了贝尔曼方程。它与<strong class="ik hi">动态规划</strong>相关联，用于通过包含先前状态的值来计算某一点的决策问题的值。还有，无模型算法，Q-learning就是基于这个方程。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es ki"><img src="../Images/fb27c0dad6eced6397ce048f42111173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*L3FiBbsb4JPnW2N1"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Reinforcement Learning explained in a picture!</figcaption></figure><p id="2c7d" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">有两种类型的强化:</p><p id="b439" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated"><strong class="ik hi">正向强化</strong>是指某一特定行为与奖励的增加相关联，从而导致该行为的强度和频率增加。</p><p id="5cd2" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated"><strong class="ik hi">负面强化</strong>是一种行为的强化，因为一种负面状况被阻止或避免。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es kj"><img src="../Images/fe736a178a25186a8cec86b5a5856ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SEuTqqs6r7d3c4p0"/></div></div></figure><p id="7601" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">除了代理和环境之外，强化学习系统还有四个主要的子元素:</p><ol class=""><li id="67b5" class="kk kl hh ik b il im ip iq jw km jx kn jy ko jf kp kq kr ks bi translated">一项政策</li><li id="5bae" class="kk kl hh ik b il kt ip ku jw kv jx kw jy kx jf kp kq kr ks bi translated">奖励信号</li><li id="cff5" class="kk kl hh ik b il kt ip ku jw kv jx kw jy kx jf kp kq kr ks bi translated">价值函数</li><li id="d78e" class="kk kl hh ik b il kt ip ku jw kv jx kw jy kx jf kp kq kr ks bi translated">环境的模型。</li></ol><p id="5347" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated"><strong class="ik hi">策略</strong>是从感知的环境状态到处于这些状态时要采取的行动的映射。一个<strong class="ik hi">奖励信号</strong>定义了强化学习问题中的目标。在每一个时间步，环境发送一个数字，奖励给强化学习代理。代理人的唯一目标是最大化其长期获得的总回报。因此，奖励信号定义了对代理人来说什么是好的和坏的事件。一个<strong class="ik hi">价值函数</strong>指定了什么是长期的好。模型是用于计划的，我们的意思是在实际经历之前，通过考虑可能的未来情况来决定行动过程的任何方式。<strong class="ik hi"> Q-learning </strong>和<strong class="ik hi"> SARSA </strong>(状态-动作-奖励-状态-动作)是两种常用的RL算法。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/d16d08c2cc881cdf7457980dbed7819d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bVQjG52oysnToeif"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">Some Algorithms used in Reinforcement Learning</figcaption></figure><p id="dd06" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">强化学习在许多领域都有应用，包括信息论、基于模拟的优化、多智能体系统、群体智能、统计学、博弈论、控制理论和运筹学。</p><p id="b42b" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">强化学习的一个例子是机器人学习如何走路。机器人首先向前迈出一大步，然后摔倒。随着那一大步跌倒的结果是强化学习系统响应的数据点。由于反馈是负面的，即跌倒，系统调整动作以迈出更小的一步。因此，机器人能够向前移动。</p><p id="1957" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">强化学习的应用:</p><ol class=""><li id="cb56" class="kk kl hh ik b il im ip iq jw km jx kn jy ko jf kp kq kr ks bi translated"><strong class="ik hi">在自然语言处理中:</strong>用于同时机器学习，具有学习何时信任预测单词的能力，并使用RL来确定何时等待更多输入。</li></ol><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es ky"><img src="../Images/f67b74ac8d4ce9ecbe4d88f7e1267826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hjmOalEc0CpxX_6L"/></div></div></figure><p id="cb61" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">2.<strong class="ik hi">在博弈方面:</strong>利用强化学习，AlphaGo Zero能够从零开始学习围棋的博弈。深度强化学习算法正在国际象棋、围棋和雅达利等游戏上进行测试。像DeepMind和OpenAI这样的公司已经在这一领域进行了广泛的研究，并建立了可能训练强化学习模型的健身房。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es kz"><img src="../Images/a8711a352857abc7917bd82f9bda9aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1h4RUaEMVX4wXARd"/></div></div></figure><p id="a2a0" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated">强化学习无疑是本世纪发现的最具创新性的技术之一。敬请期待阅读更多此类文章！</p><p id="4de9" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jw iu iv iw jx iy iz ja jy jc jd je jf ha bi translated"><strong class="ik hi">参考文献:</strong></p><ol class=""><li id="6ef4" class="kk kl hh ik b il im ip iq jw km jx kn jy ko jf kp kq kr ks bi translated"><a class="ae la" href="https://www.geeksforgeeks.org/what-is-reinforcement-learning/" rel="noopener ugc nofollow" target="_blank">强化学习— GeeksforGeeks </a></li><li id="9f56" class="kk kl hh ik b il kt ip ku jw kv jx kw jy kx jf kp kq kr ks bi translated"><a class="ae la" href="https://neptune.ai/blog/reinforcement-learning-applications" rel="noopener ugc nofollow" target="_blank">强化学习的10个现实应用— neptune.ai </a></li><li id="680d" class="kk kl hh ik b il kt ip ku jw kv jx kw jy kx jf kp kq kr ks bi translated"><a class="ae la" href="http://users.umiacs.umd.edu/~jbg/docs/2014_emnlp_simtrans.pdf" rel="noopener ugc nofollow" target="_blank">2014 _ em NLP _ sim trans . pdf(umd.edu)</a></li><li id="b978" class="kk kl hh ik b il kt ip ku jw kv jx kw jy kx jf kp kq kr ks bi translated"><a class="ae la" href="https://unsplash.com/photos/YuipfPtOH1k" rel="noopener ugc nofollow" target="_blank">黑白游戏控制器(unsplash.com)</a></li></ol><div class="lb lc ez fb ld le"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd hi fi z dy lj ea eb lk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">medium.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls jq le"/></div></div></a></div></div></div>    
</body>
</html>
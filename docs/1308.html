<html>
<head>
<title>An Empirical Approach to Explain Deep Reinforcement Learning in Portfolio Management Task</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释投资组合管理任务中深度强化学习的实证方法</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/an-empirical-approach-to-explain-deep-reinforcement-learning-in-portfolio-management-task-e65a42225d9d?source=collection_archive---------4-----------------------#2021-11-18">https://medium.com/mlearning-ai/an-empirical-approach-to-explain-deep-reinforcement-learning-in-portfolio-management-task-e65a42225d9d?source=collection_archive---------4-----------------------#2021-11-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="94a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇博客是基于我们的论文的教程:<strong class="ig hi">可解释的投资组合管理的深度强化学习:一种实证方法</strong>，在<strong class="ig hi">第二届ACM国际金融人工智能会议上发表。</strong></p><div class="jc jd ez fb je jf"><a href="https://arxiv.org/abs/2111.03995" rel="noopener  ugc nofollow" target="_blank"><div class="jg ab dw"><div class="jh ab ji cl cj jj"><h2 class="bd hi fi z dy jk ea eb jl ed ef hg bi translated">投资组合管理的可解释深度强化学习:一种实证方法</h2><div class="jm l"><h3 class="bd b fi z dy jk ea eb jl ed ef dx translated">深度强化学习(DRL)在投资组合管理任务中得到了广泛的研究。然而，这很有挑战性…</h3></div><div class="jn l"><p class="bd b fp z dy jk ea eb jl ed ef dx translated">arxiv.org</p></div></div><div class="jo l"><div class="jp l jq jr js jo jt ju jf"/></div></div></a></div><p id="76dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Jupyter笔记本的代码可以在我们的<a class="ae jv" href="https://github.com/AI4Finance-Foundation/FinRL" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> Github </strong> </a>和<a class="ae jv" href="https://colab.research.google.com/drive/117v2qWo-qPC7OPd7paY1wYkOUywU_DWZ#scrollTo=cY_q0OoF33dB" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> Google Colab </strong> </a>上找到。</p><div class="jc jd ez fb je jf"><a href="https://github.com/AI4Finance-Foundation/FinRL" rel="noopener  ugc nofollow" target="_blank"><div class="jg ab dw"><div class="jh ab ji cl cj jj"><h2 class="bd hi fi z dy jk ea eb jl ed ef hg bi translated">GitHub-ai4 finance-Foundation/FinRL:自动化交易的深度强化学习框架…</h2><div class="jm l"><h3 class="bd b fi z dy jk ea eb jl ed ef dx translated">免责声明:这里没有任何金融建议，也不是交易真钱的建议。请运用常识…</h3></div><div class="jn l"><p class="bd b fp z dy jk ea eb jl ed ef dx translated">github.com</p></div></div><div class="jo l"><div class="jw l jq jr js jo jt ju jf"/></div></div></a></div><div class="jc jd ez fb je jf"><a href="https://colab.research.google.com/drive/117v2qWo-qPC7OPd7paY1wYkOUywU_DWZ#scrollTo=cY_q0OoF33dB" rel="noopener  ugc nofollow" target="_blank"><div class="jg ab dw"><div class="jh ab ji cl cj jj"><h2 class="bd hi fi z dy jk ea eb jl ed ef hg bi translated">谷歌联合实验室</h2><div class="jn l"><p class="bd b fp z dy jk ea eb jl ed ef dx translated">投资组合管理的可解释深度强化学习:一种实证方法。</p></div></div><div class="jo l"><div class="jx l jq jr js jo jt ju jf"/></div></div></a></div><h1 id="6d07" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">概观</h1><p id="eccd" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">深度强化学习(DRL)在投资组合管理任务中得到了广泛的研究。然而，由于深度神经网络的黑箱性质，理解基于DRL的交易策略是具有挑战性的。</p><p id="a257" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们提出了一个实证方法来解释投资组合管理任务的DRL代理人的策略。首先，我们使用后知后觉的线性模型作为参考模型，该模型通过假设预先知道实际股票回报来找到最佳投资组合权重。特别地，我们事后使用线性模型的系数作为参考特征权重。其次，对于DRL代理，我们使用综合梯度来定义特征权重，这是线性回归模型下报酬和特征之间的系数。第三，我们研究了单步预测和多步预测两种情况下的预测能力。</p><p id="9c91" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特别地，我们通过计算DRL代理的特征权重和参考特征权重之间的线性相关性来量化预测能力，并且类似地用于机器学习方法。最后，我们评估了2009年1月1日至2021年9月1日期间道琼斯30种成份股的投资组合管理任务。我们的方法从经验上揭示了DRL代理比机器学习方法表现出更强的多步预测能力。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lb"><img src="../Images/3a6e1e974ce9757eafa8fed2a8695676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*-RajdBaENUoA8DFZ9HbXZg.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Overview of explanation method</figcaption></figure><h1 id="4001" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">第1部分:参考模型和特性权重</h1><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lm"><img src="../Images/828d18435f3cb694f78d5917cd2bcc64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*4uhiPwAm3SN9PBbdP979ag.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Reference model in hindsight</figcaption></figure><p id="2bc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们事后用线性模型作为参考模型。对于后知后觉的线性模型，恶魔会用实际股票收益和实际样本协方差矩阵来优化投资组合。这是任何线性预测模型能够达到的性能上限</p><p id="0647" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用回归系数将参考特征权重定义为</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es ln"><img src="../Images/3d8f94a3627418cda8d7e69e160fdbe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*Oh0dWxDHRLyrv5GQzzYGYQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Reference feature weights</figcaption></figure><h1 id="8479" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">第2部分:DRL代理的特征权重</h1><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lo"><img src="../Images/704ecf7c5641f6fc4bf0815cf9069329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*UitYkO08wjSIpUFyB6zJsw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Feature weights of a trained DRL agent.</figcaption></figure><p id="7797" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用综合梯度来定义投资组合管理任务中DRL代理的特征权重。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lp"><img src="../Images/1ac646d05c780dfc396180ef954e304c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*DFqanomFQ9r23LYHU0kJIw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Integrated gradients</figcaption></figure><p id="b0a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用一个线性模型来寻找特征和投资组合收益向量q之间的关系。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lq"><img src="../Images/53ff93cc752e29a4aa3c28c4198a5383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LiVPHtDDjB-JoGDiZ_AQ0A.png"/></div></div></figure><p id="b7e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们使用综合梯度和回归系数定义了投资组合管理任务中DRL代理的特征权重。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lv"><img src="../Images/c0c943a956fec447dcb1705f52374fd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*MyZ8ZNM9R7okza48LKflTQ.png"/></div></figure><h1 id="4573" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">第3部分:ML方法的特征权重</h1><p id="9453" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">我们使用传统的机器学习方法作为对比。</p><p id="e865" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，它使用特征作为输入来预测股票收益向量。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lw"><img src="../Images/c41e4e26078f84ad253f9ffcdbbaf94b.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*CR1k7VQ0qd-jg-xARpuxXw.png"/></div></figure><p id="b3c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其次，建立线性回归模型，找出投资组合收益向量q与特征之间的关系。</p><p id="de4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，它使用回归系数b来如下定义特征权重。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lx"><img src="../Images/d3c75f86a34016373612fbef6240a9d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*jC0_bP5i3CLO7g6aHNQOlg.png"/></div></figure><h1 id="19c8" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">第4部分:预测能力</h1><p id="62c8" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">机器学习方法和DRL代理都从它们的预测能力中获利。我们通过计算DRL代理的特征权重和参考特征权重之间的线性相关性𝜌()来量化预测能力，并且类似地用于机器学习方法。此外，在预测未来时，机器学习方法和DRL代理是不同的。机器学习方法依靠单步预测来寻找投资组合权重。然而，DRL的代理人发现投资组合权重具有长期目标。然后，我们比较了单步预测和多步预测两种情况。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es ly"><img src="../Images/ba9d3195a7956a0993f7d980d27c34a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Llgioxd9GuFWW8nQRfcN1g.png"/></div></div></figure><h1 id="ba4d" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">第五部分:实验</h1><ol class=""><li id="d0f6" class="lz ma hh ig b ih kw il kx ip mb it mc ix md jb me mf mg mh bi translated">算法:<br/> 1.1 DRL药剂:PPO，A2C <br/> 1.2 ML方法:SVM，决策树，随机森林，线性回归，</li><li id="428d" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">数据:道琼斯30种成份股，访问时间:2020年7月1日【2021训练时间:2009年1月1日至2020年6月30日<br/>2.2交易时间:2020年7月1日至2021年9月1日</li><li id="de89" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">功能:MACD、CCI、RSI、ADX</li><li id="b216" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">基准:道琼斯工业平均指数(DJIA)</li></ol><p id="3d9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">投资组合表现</strong></p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es mn"><img src="../Images/e8988ce280ca7edd3b93bc817678f698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2h2o4cwF6tnMg_Fy0zW1pg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Portfolio performance comparison</figcaption></figure><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es mo"><img src="../Images/d285b7d0bc6b7823c08e8b4905df7660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qOGtbhnkAGldkBUvvqFsTA.png"/></div></div></figure><p id="952c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">预测功率分布</strong></p><p id="0b14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单步执行</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es mp"><img src="../Images/72d356dacb2f93b089de8d3edc2a315c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rg7EOudeLXRadtRDQG6jSw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Single step prediction power’s histogram</figcaption></figure><p id="7749" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多步骤</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es mq"><img src="../Images/00ae150579de24b043a043e33fad2db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksMBv56g7OclzB0E_cIcRg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Multi step prediction power’s histogram</figcaption></figure><p id="6f10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">统计检验</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es mr"><img src="../Images/5c4f33f7977896ccf20a2957d0a9fee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*HZQMrXYGi3WARGintziaPA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Statistical test for mean value</figcaption></figure><p id="7e2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">平均预测功效&amp;夏普比率</strong></p><p id="f88f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们比较了所有算法的预测能力和夏普比率。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es ms"><img src="../Images/0672b788ba815f0f77e758929abcdd91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rps_sYvBuEsZDyTS9ds-kw.png"/></div></div></figure><p id="8a51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们发现:</p><ol class=""><li id="3a49" class="lz ma hh ig b ih ii il im ip mt it mu ix mv jb me mf mg mh bi translated">在所有其他试剂中，使用PPO的DRL试剂具有最高的夏普比率:2.11和最高的平均相关系数(多步):0.09。</li><li id="c534" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">DRL代理的平均相关系数(多步)明显高于它们的平均相关系数(单步)。</li><li id="9e3f" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">机器学习方法的平均相关系数(单步)明显高于它们的平均相关系数(多步)。</li><li id="dffa" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">DRL代理在多步预测能力方面优于机器学习方法，但在单步预测能力方面落后。</li><li id="f5fc" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">总的来说，较高的平均相关系数(多步)表示较高的夏普比率</li></ol><div class="jc jd ez fb je jf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jg ab dw"><div class="jh ab ji cl cj jj"><h2 class="bd hi fi z dy jk ea eb jl ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="jm l"><h3 class="bd b fi z dy jk ea eb jl ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="jn l"><p class="bd b fp z dy jk ea eb jl ed ef dx translated">medium.com</p></div></div><div class="jo l"><div class="mw l jq jr js jo jt ju jf"/></div></div></a></div></div></div>    
</body>
</html>
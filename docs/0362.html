<html>
<head>
<title>VGG in depth</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入VGG</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/vgg-in-depth-48ec68d71a92?source=collection_archive---------2-----------------------#2021-03-29">https://medium.com/mlearning-ai/vgg-in-depth-48ec68d71a92?source=collection_archive---------2-----------------------#2021-03-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="4cf6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我之前的帖子中，我们谈到了AlexNet，这是CNN的一个革命性的进步，并成为图像分类的最佳模型。然后VGG来了，改变了整个场景。</p><p id="ae11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">VGG的全称是视觉几何组。它是由<a class="ae jc" href="https://en.wikipedia.org/wiki/Oxford_Robotics_Institute" rel="noopener ugc nofollow" target="_blank">牛津机器人研究所</a>的<a class="ae jc" href="http://www.robots.ox.ac.uk/~karen/" rel="noopener ugc nofollow" target="_blank">卡伦·西蒙扬</a>和<a class="ae jc" href="https://en.wikipedia.org/wiki/Andrew_Zisserman" rel="noopener ugc nofollow" target="_blank">安德鲁·齐泽曼</a>在2014年提出的。VGG研究卷积网络深度的最初目的是了解卷积网络的深度如何影响大规模图像分类和识别的准确度和精度。-Deep-16 CNN)，为了加深网络层数，避免参数过多，所有层都使用了一个小的3×3卷积核。</p><h2 id="d145" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">VGG建筑</h2><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es jy"><img src="../Images/be3c340b2814f1926e05b74af2ce2005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzxRI1qHXjiVXla-_NiMBA.png"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx">VGG Architectue</figcaption></figure><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es ko"><img src="../Images/e55cd32002cf3139ecf1509a2bba663a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*g8fe6eiwOcPKJ8jdkcrLtA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx">VGG Layers Description</figcaption></figure><ol class=""><li id="5368" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated">使用64个过滤器的卷积</li><li id="51e6" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用64个过滤器+最大池的卷积</li><li id="1ab8" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用128个过滤器的卷积</li><li id="3eb7" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用128个过滤器的卷积+最大池</li><li id="9b79" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用256个过滤器的卷积</li><li id="df94" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用256个过滤器的卷积</li><li id="f52f" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用256个过滤器+最大池的卷积</li><li id="da53" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用512个过滤器的卷积</li><li id="f40d" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用512个过滤器的卷积</li><li id="996c" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用512个过滤器+最大池的卷积</li><li id="285b" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用512个过滤器的卷积</li><li id="00b7" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用512个过滤器的卷积</li><li id="35c0" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">使用512个过滤器+最大池的卷积</li><li id="4e9c" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">完全连接4096个节点</li><li id="7533" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">完全连接4096个节点</li><li id="aa6a" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">具有1000个节点的Softmax激活的输出层。</li></ol><p id="72b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该网络的特点是简单，整体结构包括5组仅<em class="ld"> 3×3 </em>的卷积层，这些卷积层以递增的深度相互堆叠。减少卷大小是由最大池处理的。两个完全连接的层，每个层有4，096个节点，然后是softmax分类器。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es le"><img src="../Images/e05d59312f693206e6ef478a04ca8f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNRj3NosPuf4Wts2UoM6Aw.jpeg"/></div></div></figure><p id="18d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">AlexNet仅包含一个内核大小为7 * 7的卷积，但是在VGG中，每个卷积层包含2到4个卷积运算。与AlexNet相比，内核的大小也很小，即3 * 3。卷积步距固定为1个像素；conv的空间填充。层输入使得空间分辨率在卷积后保持不变，即对于3×3 conv，填充是1个像素。层次。VGGNet最明显的改进是减小了卷积核的大小，增加了卷积层数。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es lf"><img src="../Images/745640bd6748eed07a87eaaba9d8f013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9UxCBJXcX5_yvh8gqRJg2Q.jpeg"/></div></div></figure><p id="4631" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1 * 1卷积层主要是在不影响卷积层感受野的情况下，增加判决函数的非线性。虽然1 * 1卷积运算是线性的，但ReLu增加了非线性。</p><h2 id="21f7" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">培养</h2><p id="8c3e" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated"><strong class="ig hi">优化方法</strong>是带动量的随机梯度下降SGD + momentum (0.9)。</p><p id="2511" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">批次</strong>尺寸为256。</p><p id="27f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">正则化</strong>:使用L2正则化。</p><p id="a9d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">退出</strong>是在前两个完全连接的层之后。</p><h2 id="4b5f" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">总结VGGNet</h2><ol class=""><li id="886d" class="kp kq hh ig b ih lg il lh ip ll it lm ix ln jb ku kv kw kx bi translated">使用更小的3 * 3卷积核和更深的网络。两个3 * 3卷积核的堆叠是相对于5 * 5卷积核的视场而言的，三个3 * 3卷积核的堆叠相当于7 * 7卷积核的视场。这样，参数可以更少。</li><li id="a8bb" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">在VGGNet的卷积结构中，引入了1 * 1卷积核。</li><li id="535c" class="kp kq hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">在不影响输入输出维数的情况下，引入非线性变换，增加网络的表达能力，减少计算量。</li></ol><p id="4bb8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望这篇文章对你学习和了解VGGNet有所帮助。</p></div></div>    
</body>
</html>
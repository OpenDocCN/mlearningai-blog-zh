<html>
<head>
<title>Creating scalable NLP pipelines using PySpark and Nlphose</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PySpark和Nlphose创建可伸缩的NLP管道</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/creating-scalable-nlp-pipelines-using-pyspark-and-nlphose-b93afa3097c1?source=collection_archive---------6-----------------------#2022-01-25">https://medium.com/mlearning-ai/creating-scalable-nlp-pipelines-using-pyspark-and-nlphose-b93afa3097c1?source=collection_archive---------6-----------------------#2022-01-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b45c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将了解如何使用<a class="ae jc" href="https://github.com/code2k13/nlphose" rel="noopener ugc nofollow" target="_blank">NLP hoste</a>和Pyspark来执行NLP管道，并收集关于儒勒·凡尔纳的著作《80天环游世界》中的著名旅程的信息。这里是本文中使用的⬇️ <a class="ae jc" href="https://github.com/code2k13/nlphose/blob/main/Nlphose_Pyspark.ipynb" rel="noopener ugc nofollow" target="_blank"> Pyspark笔记本的链接。</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/47370a9c399940216f6062427501617f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*clWtLxBpj_cvVnXI.png"/></div></div></figure><p id="1a28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据我的个人经验，我发现从非结构化数据中挖掘数据需要使用多种技术。没有一个单一的模型或库可以提供您需要的一切。通常，您可能需要使用用不同编程语言/框架编写的组件。这就是我的开源项目<a class="ae jc" href="https://github.com/code2k13/nlphose" rel="noopener ugc nofollow" target="_blank"> Nlphose </a>出现的地方。Nlphose支持使用一组简单的命令行工具，在几秒钟内创建复杂的NLP管道，用于处理静态文件或流文本。您可以在终端中执行单个命令，对文本执行多种操作，如NER、情感分析、分块、语言识别、Q &amp; A、0-shot分类等。Spark是广泛使用的大数据处理工具，可用于并行化工作负载。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/8d37ff8f4695e8585d2effabc7938664.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8MmfrBUvBywGLJO0.jpg"/></div></div></figure><p id="f9d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://github.com/code2k13/nlphose" rel="noopener ugc nofollow" target="_blank"> Nlphose </a>基于“<a class="ae jc" href="https://tldp.org/LDP/GNU-Linux-Tools-Summary/html/c1089.htm" rel="noopener ugc nofollow" target="_blank"> Unix工具哲学</a>”。这个想法是创造简单的工具，它们可以一起工作来完成多项任务。Nlphose脚本依靠标准的“文件流”来读写数据，并且可以通过管道连接在一起，以创建复杂的自然语言处理管道。每个脚本从“标准输入”读取JSON，并写入“标准输出”。所有的脚本都期望JSON以nlphose兼容格式编码，并且输出也需要是nlphose兼容的。你可以在这里阅读关于NLP hose<a class="ae jc" href="https://github.com/code2k13/nlphose/wiki/Architecture-of-nlphose" rel="noopener ugc nofollow" target="_blank">架构的更多细节。</a></p><h1 id="d0b0" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">Nlphose有什么不同？</h1><p id="3793" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">Nlphose在设计上不像SparkML那样支持Spark/Pyspark。Pyspark中的Nlphose依赖于安装在spark集群所有节点上的“Docker”。当在<a class="ae jc" href="https://cloud.google.com/dataproc/" rel="noopener ugc nofollow" target="_blank"> Google Dataproc </a>中创建一个新的集群时，这是很容易做到的(对于任何其他Spark分布也应该是一样的)。除了Docker之外，Nlphose不需要在Spark集群的工作节点上安装任何其他依赖项。我们使用下面描述的“PipeLineExecutor”类从Pyspark中执行Nlphose管道。</p><p id="d27d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在幕后，这个类使用“<a class="ae jc" href="https://docs.python.org/3/library/subprocess.html" rel="noopener ugc nofollow" target="_blank">子进程</a>模块为一个Spark任务生成一个新的docker容器，并执行一个Nlphose管道。使用stdout和stdin执行I/O。这听起来很简单，但这就是我构建Nlphose的方式。它从未被设想为支持任何特定的计算框架或库。您可以用许多不同的方式运行Nlphose，这里将介绍其中一种方式。</p><h1 id="82f4" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">我们开始吧</h1><p id="8c56" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">首先，我们安装一个包，稍后我们将使用它来构建一个可视化。</p><p id="691a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">！pip安装字数</p><p id="f646" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的命令从gutenber.org的<a class="ae jc" href="https://ashishware.com/2022/01/23/PysparkNlphose/gutenber.org" rel="noopener ugc nofollow" target="_blank">下载电子书《80天环游世界》，并使用Nlphose提供的工具将单个文本文件分割成行分隔的json。每个json对象都有一个“id”和“text”属性。</a></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="c6da" class="ky jr hh ku b fi kz la l lb lc">!docker run code2k13/nlphose:latest \<br/>/bin/bash -c “wget <a class="ae jc" href="https://www.gutenberg.org/files/103/103-0.txt" rel="noopener ugc nofollow" target="_blank">https://www.gutenberg.org/files/103/103-0.txt</a> &amp;&amp; ./file2json.py 103–0.txt -n 2” &gt; ebook.json</span></pre><p id="34d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们删除所有不再需要的docker容器。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="7bd0" class="ky jr hh ku b fi kz la l lb lc">!docker system prune -f</span></pre><p id="7090" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们导入所有需要的库。读取我们之前创建的json文件，并将其转换为pandas数据框。然后，我们将一个“group_id”列添加到行中，该列从0到3之间随机分配一个groupId。完成后，我们创建一个新的PySpark数据框架并显示一些结果。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="6553" class="ky jr hh ku b fi kz la l lb lc">import pandas as pd<br/>from pyspark.sql.types import StructType,StructField, StringType, IntegerType<br/>from pyspark.sql.functions import desc<br/>from pyspark.sql.functions import udf</span><span id="c8b7" class="ky jr hh ku b fi ld la l lb lc">df_pd = pd.read_json(“ebook.json”,lines=True) <br/>df_pd[‘group_id’] = [i for i in range(0,3)]*347<br/>df= spark.createDataFrame(df_pd)<br/>df= spark.createDataFrame(df_pd)</span><span id="773c" class="ky jr hh ku b fi ld la l lb lc">+ — — — — -+ — — — — — — — — — — + — — — — — — — — — — + — — — — +<br/>|file_name| id| text|group_id|<br/>+ — — — — -+ — — — — — — — — — — + — — — — — — — — — — + — — — — +<br/>|103–0.txt|2bbbfe64–7c1e-11e…| The Project Gute…| 0|<br/>|103–0.txt|2bbea7ea-7c1e-11e…| Title: Around th…| 1|<br/>|103–0.txt|2bbf2eb8–7c1e-11e…|IN WHICH PHILEAS …| 2|<br/>|103–0.txt|2bbfdbd8–7c1e-11e…| Certainly an Eng…| 0|<br/>|103–0.txt|2bbff29e-7c1e-11e…| Phileas Fogg was…| 1|<br/>|103–0.txt|2bc00734–7c1e-11e…| The way in which…| 2|<br/>|103–0.txt|2bc02570–7c1e-11e…| He was recommend…| 0|<br/>|103–0.txt|2bc095f0–7c1e-11e…| Was Phileas Fogg…| 1|<br/>|103–0.txt|2bc0ed20–7c1e-11e…| Had he travelled…| 2|<br/>|103–0.txt|2bc159d6–7c1e-11e…| It was at least …| 0|<br/>|103–0.txt|2bc1a3be-7c1e-11e…| Phileas Fogg was…| 1|<br/>|103–0.txt|2bc2a2aa-7c1e-11e…|He breakfasted an…| 2|<br/>|103–0.txt|2bc2c280–7c1e-11e…| If to live in th…| 0|<br/>|103–0.txt|2bc30b3c-7c1e-11e…| The mansion in S…| 1|<br/>|103–0.txt|2bc34dd6–7c1e-11e…| Phileas Fogg was…| 2|<br/>|103–0.txt|2bc35f88–7c1e-11e…|Fogg would, accor…| 0|<br/>|103–0.txt|2bc3772a-7c1e-11e…| A rap at this mo…| 1|<br/>|103–0.txt|2bc3818e-7c1e-11e…| “The new servant…| 2|<br/>|103–0.txt|2bc38e0e-7c1e-11e…| A young man of t…| 0|<br/>|103–0.txt|2bc45c6c-7c1e-11e…| “You are a Frenc…| 1|<br/>+ — — — — -+ — — — — — — — — — — + — — — — — — — — — — + — — — — +</span></pre><h1 id="6b1f" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">使用Pyspark运行nlphose管道</h1><p id="2e48" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">如前所述，Nlphose没有与Pyspark/Spark的本地集成。因此，我们创建了一个名为“PipeLineExecutor”的类，它启动一个docker容器并执行一个Nlphose命令。这个类使用“标准输入”和“标准输出”与docker容器通信。最后，当docker容器完成执行时，我们执行‘docker system prune-f’来清除任何未使用的容器。“execute_pipeline”方法将数据从dataframe写入stdin(逐行)，从stdout读取输出，并返回从输出创建的dataframe。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="9b74" class="ky jr hh ku b fi kz la l lb lc">import subprocess<br/>import pandas as pd<br/>import json<br/><br/>class PipeLineExecutor:<br/>  def __init__(self, nlphose_command,data,id_column='id',text_column='text'):<br/>    self.nlphose_command = nlphose_command<br/>    self.id_column = id_column<br/>    self.text_column = text_column<br/>    self.data = data<br/><br/>  def execute_pipeline(self):<br/>    try:<br/>     prune_proc = subprocess.Popen(["docker system prune -f"],shell=True)<br/>     prune_proc.communicate()<br/>        <br/>     proc = subprocess.Popen([self.nlphose_command],shell=True,stdout=subprocess.PIPE, stdin=subprocess.PIPE,stderr=subprocess.PIPE)<br/>     for idx,row in self.data.iterrows():       <br/>        proc.stdin.write(bytes(json.dumps({"id":row[self.id_column],"text":row[self.text_column]}),"utf8"))<br/>        proc.stdin.write(b"\n")<br/>        proc.stdin.flush()<br/>    <br/>     output,error = proc.communicate()<br/>     output_str = str(output,'utf-8')<br/>     output_str = output_str<br/>     data = output_str.split("\n")    <br/>     data = [d for d in data if len(d) &gt; 2]<br/>    finally:<br/>        prune_proc = subprocess.Popen(["docker system prune -f"],shell=True)<br/>        prune_proc.communicate()<br/>    return pd.DataFrame(data)</span></pre><h1 id="143d" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">Nlphose命令</h1><p id="8360" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">以下命令执行多项任务:</p><ul class=""><li id="fb33" class="le lf hh ig b ih ii il im ip lg it lh ix li jb lj lk ll lm bi translated">它使用dockerhub中的<a class="ae jc" href="https://hub.docker.com/r/code2k13/nlphose#!" rel="noopener ugc nofollow" target="_blank"> code2k13/nlphose:latest </a>图像启动docker容器。</li><li id="3e58" class="le lf hh ig b ih ln il lo ip lp it lq ix lr jb lj lk ll lm bi translated">它将主机的stdin、stdout和stderr重定向到docker容器中。</li><li id="0691" class="le lf hh ig b ih ln il lo ip lp it lq ix lr jb lj lk ll lm bi translated">然后，它在docker容器中运行nlphose命令，该命令对来自“stdin”的json执行以下操作，并将输出写入“stdout”:</li><li id="2f1e" class="le lf hh ig b ih ln il lo ip lp it lq ix lr jb lj lk ll lm bi translated"><a class="ae jc" href="https://github.com/code2k13/nlphose/wiki/Name-Entity-Recognition" rel="noopener ugc nofollow" target="_blank">实体识别</a></li><li id="cea4" class="le lf hh ig b ih ln il lo ip lp it lq ix lr jb lj lk ll lm bi translated">寻找“他们携带了什么”这个问题的答案<a class="ae jc" href="https://github.com/code2k13/nlphose/wiki/Question-Answering" rel="noopener ugc nofollow" target="_blank">使用基于变压器的模型</a>。</li></ul><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="41ac" class="ky jr hh ku b fi kz la l lb lc">command = '''<br/>docker run -a stdin -a stdout -a stderr -i code2k13/nlphose:latest /bin/bash -c “./entity.py |\<br/>./xformer.py — pipeline question-answering — param ‘what did they carry?’ <br/>“ <br/>'''</span></pre><p id="87b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的函数格式化PipelineExecutor任务返回的数据。“pipeline executor . execute _ pipeline”返回的dataframe有一个字符串列，其中包含Nlphose命令的输出。数据帧中的每一行代表Nlphose命令的一行/一个文档输出。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="3d38" class="ky jr hh ku b fi kz la l lb lc">def get_answer(row):<br/>  try:<br/>    x =  json.loads(row[0],strict=False)<br/>    row['json_obj'] = json.dumps(x)<br/>    if x['xfrmr_question_answering']['score'] &gt; 0.80:<br/>        row['id'] =  str(x['id'])<br/>        row['answer'] = x['xfrmr_question_answering']['answer']        <br/>    else:<br/>        row['id'] = str(x['id'])<br/>        row['answer'] = None<br/>        <br/>  except Exception as e:<br/>    row['id'] = None<br/>    row['answer'] = "ERROR " + str(e) #.message<br/>    row['json_obj'] = None<br/>    <br/>  return row</span></pre><p id="eccf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的函数创建一个“PipeLineExecutor”对象，将数据传递给它，然后对该对象调用“execute_pipeline”方法。然后，它使用“get_answer”方法来格式化“execute_pipeline”方法的输出。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="1dc9" class="ky jr hh ku b fi kz la l lb lc">def run_pipeline(data):<br/>  nlphose_executor = PipeLineExecutor(command,data,"id","text")<br/>  result = nlphose_executor.execute_pipeline()<br/>  result =  result.apply(get_answer,axis=1)     <br/>  return  result[["id","answer","json_obj"]]</span></pre><h1 id="646f" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">使用PySpark扩展管道</h1><p id="d098" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">我们使用PySpark的“<a class="ae jc" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.GroupedData.applyInPandas.html" rel="noopener ugc nofollow" target="_blank"> applyInPandas </a>”来并行化和大规模处理文本。PySpark自动处理Spark集群上Nlphose管道的缩放。对输入数据的每个“组”调用“run_pipeline”方法。重要的是根据节点数量设置适当数量的组，以便在Spark集群上有效地处理数据。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="29c1" class="ky jr hh ku b fi kz la l lb lc">output = df.groupby(“group_id”).applyInPandas(run_pipeline, schema=”id string,answer string,json_obj string”)<br/>output.cache()</span></pre><h1 id="147d" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">可视化我们的发现</h1><p id="0bfe" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">一旦我们完成了nlphose管道的执行，我们就开始可视化我们的发现。我已经创建了两个可视化:</p><ul class=""><li id="698c" class="le lf hh ig b ih ii il im ip lg it lh ix li jb lj lk ll lm bi translated">显示书中提到的地方的地图。</li><li id="44d0" class="le lf hh ig b ih ln il lo ip lp it lq ix lr jb lj lk ll lm bi translated">人物旅途中携带的所有重要物品的单词云。</li></ul><h1 id="96b0" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">在世界地图上标出书中最常见的位置</h1><p id="9dbd" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">下面的代码从Nlphose管道中提取纬度和经度信息，并创建一个最常见位置的列表。</p><blockquote class="ls lt lu"><p id="1640" class="ie if lv ig b ih ii ij ik il im in io lw iq ir is lx iu iv iw ly iy iz ja jb ha bi translated"><em class="hh">💡注意:Nlphose实体提取将使用基于字典的方法自动猜测已知位置的坐标</em></p></blockquote><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="7352" class="ky jr hh ku b fi kz la l lb lc">def get_latlon2(data):<br/>        json_obj = json.loads(data)<br/>        if 'entities' in json_obj.keys():<br/>            for e in json_obj['entities']:<br/>                if e['label'] == 'GPE' and 'cords' in e.keys():<br/>                    return json.dumps({'data':[e['entity'],e['cords']['lat'],e['cords']['lon']]})<br/>        return None<br/>        <br/>get_latlon_udf2 = udf(get_latlon2)  <br/>df_locations = output.withColumn("locations",get_latlon_udf2(output["json_obj"]))<br/>top_locations = df_locations.filter("`locations` != 'null'").groupby("locations").count().sort(desc("count")).filter("`count` &gt;= 1")<br/>top_locations.cache() <br/>top_locations.show()</span></pre><p id="3f07" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们使用“geopandas”包在世界地图上绘制这些位置。在此之前，我们必须将数据帧转换成“geopandas”能够理解的格式。这是通过应用函数‘add _ lat _ long’来完成的</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="2b3f" class="ky jr hh ku b fi kz la l lb lc">def add_lat_long(row):<br/>     obj =  json.loads(row[0])["data"]<br/>     row["lat"] = obj[1]<br/>     row["lon"] = obj[2]<br/>     return row</span><span id="0e3d" class="ky jr hh ku b fi ld la l lb lc">import geopandas<br/><br/>df_locations = top_locations.toPandas()<br/>df_locations = df_locations.apply(add_lat_long,axis=1)<br/><br/>gdf = geopandas.GeoDataFrame(df_locations, geometry=geopandas.points_from_xy(df_locations.lon, df_locations.lat))<br/>world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))<br/>ax = world.plot(color=(25/255,211/255,243/255) ,edgecolor=(25/255,211/255,243/255),<br/>                    linewidth=0.4,edgecolors='none',figsize=(15, 15))<br/>ax.axis('off')   <br/>gdf.plot(ax=ax,alpha=0.5,marker=".",markersize=df_locations['count']*100,color='seagreen')</span></pre><p id="e30f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你熟悉这本书，你会意识到我们几乎描绘了福格在他著名的旅程中所走的实际路线。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lz"><img src="../Images/c7e8f8614232ff12f293995b2685a293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jM8UmQYw5hAqcEoV.png"/></div></div></figure><p id="eb45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为参考，下面是他从维基百科上截取的实际路线的图片</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/53209d7243962798057c59962208ac88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*GkZC0VxBvf0nO6WK.png"/></div></figure><p id="6336" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">八十天环游世界地图</p><p id="68b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://commons.wikimedia.org/wiki/File:Around_the_World_in_Eighty_Days_map.png" rel="noopener ugc nofollow" target="_blank"> Roke </a>，<a class="ae jc" href="https://creativecommons.org/licenses/by-sa/3.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 3.0 </a>，通过维基共享</p><h1 id="1db7" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">创建一个福格旅途中携带物品的单词云</h1><p id="e142" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">下面的代码使用“提取问题回答”找到旅行者携带的最常见的物品，并创建一个单词云。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="c816" class="ky jr hh ku b fi kz la l lb lc">from wordcloud import WordCloud, STOPWORDS<br/>import matplotlib.pyplot as plt<br/>from matplotlib.pyplot import figure</span><span id="0ec0" class="ky jr hh ku b fi ld la l lb lc">figure(figsize=(12, 6), dpi=120)<br/>wordcloud = WordCloud(background_color=’white’,width=1024,height=500).generate(‘ ‘.join(output.filter(“`answer` != ‘null’”).toPandas()[‘answer’].tolist()))<br/>plt.imshow(wordcloud)<br/>plt.axis(“off”)<br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/c30c84e0ea50f33524d0023aff05a4c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EcZf1yB7oPDJmzsc.png"/></div></div></figure><h1 id="754a" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="8f60" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">PySpark是数据科学家和ML实践者最喜欢的工具的原因之一是因为使用数据框架非常方便。本文展示了如何使用PySpark在Spark集群上运行Nlphose。使用本文描述的方法，我们可以非常容易地将Nlphose管道作为数据处理管道的一部分嵌入。希望你喜欢这篇文章。随时欢迎反馈和评论，谢谢！</p><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt jn mf"/></div></div></a></div></div></div>    
</body>
</html>
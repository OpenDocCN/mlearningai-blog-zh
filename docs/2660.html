<html>
<head>
<title>Popular Machine Learning Algorithms (Supervised and Unsupervised Learning)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">流行的机器学习算法(监督和非监督学习)</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/popular-machine-learning-algorithms-supervised-and-unsupervised-learning-766120e96d49?source=collection_archive---------7-----------------------#2022-05-27">https://medium.com/mlearning-ai/popular-machine-learning-algorithms-supervised-and-unsupervised-learning-766120e96d49?source=collection_archive---------7-----------------------#2022-05-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="b1bd" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">一些流行的机器学习算法及其Python实现(Scikit-learn)</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/ed536028d23cd671d92bf0db6df1f769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X8ycVWNaBPaOXSMTIAT8bg.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by Serpstat from <a class="ae jm" href="https://www.pexels.com/photo/silver-imac-displaying-line-graph-placed-on-desk-572056/" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><h1 id="a165" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">介绍</h1><p id="6906" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">机器学习对我们的日常生活帮助很大。许多机器学习应用程序包括推荐系统、垃圾邮件过滤器、股票价格预测、情感分析、社交媒体上的排名帖子、搜索引擎、手写识别等。嗯，机器学习确实已经成为我们日常生活的一部分。然而，机器学习到底是什么？</p><blockquote class="lb lc ld"><p id="af88" class="kf kg le kh b ki lf ii kk kl lg il kn lh li kq kr lj lk ku kv ll lm ky kz la ha bi translated">机器学习是在没有明确编程的情况下赋予计算机学习能力的研究领域。阿瑟·塞缪尔，1959年</p></blockquote><p id="7fa3" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">还有另一种解释:</p><blockquote class="lb lc ld"><p id="bad3" class="kf kg le kh b ki lf ii kk kl lg il kn lh li kq kr lj lk ku kv ll lm ky kz la ha bi translated">如果一个计算机程序在任务T和性能测量P上的性能随着经验E的增加而提高，那么这个程序就可以说是从经验E中学习了</p></blockquote><p id="fdfb" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">总之，机器学习不需要显式编程，它可以从数据中学习并找到模式。想了解更多关于机器学习的知识，可以阅读这篇<a class="ae jm" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">文章</a>。</p><p id="b3f8" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">本文探讨了流行的机器学习算法，包括监督和非监督学习。这些算法包括:</p><p id="5660" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated"><a class="ae jm" href="#dbe5" rel="noopener ugc nofollow"> 1。线性回归</a> <br/> <a class="ae jm" href="#e872" rel="noopener ugc nofollow"> 2。逻辑回归</a> <br/> <a class="ae jm" href="#923a" rel="noopener ugc nofollow"> 3。支持向量机【SVM】</a><br/><a class="ae jm" href="#ba48" rel="noopener ugc nofollow">4。k-最近邻(KNN) </a> <br/> <a class="ae jm" href="#88df" rel="noopener ugc nofollow"> 5。朴素贝叶斯分类</a> <br/> <a class="ae jm" href="#d773" rel="noopener ugc nofollow"> 6。决策树</a> <br/> <a class="ae jm" href="#0dd8" rel="noopener ugc nofollow"> 7。随机森林</a> <br/> <a class="ae jm" href="#b0f3" rel="noopener ugc nofollow"> 8。k-均值聚类</a></p><p id="a50f" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">读完这篇文章后，你应该能够理解一些最流行的机器学习算法。所以让我们开始吧！</p><h1 id="dbe5" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 1。线性回归</strong></h1><p id="1a1e" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">线性回归又名普通最小二乘法(OLS)是一种受监督的机器学习算法，其中预测的输出是连续数据，通过拟合直线来获得误差最小的回归模型。而在统计学中，线性回归是一种对解释变量和响应变量之间的关系进行建模的线性方法。解释变量也称为自变量，而响应变量也称为因变量。简而言之，线性回归通过根据因变量和自变量拟合误差最小的直线来预测输出。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ln"><img src="../Images/55dff3c0dba5e37d2ec146725d336a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*FNAmlufPGtUcqT_RK2gpKg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Linear regression (image by author).</figcaption></figure><p id="ad75" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">线性回归有几种类型，包括简单线性回归、多项式回归和多项式回归。然而，有时线性回归模型可以提供不太准确的预测(过拟合或欠拟合)。要解决这个问题，可以使用线性回归类型，如岭回归(L2范数)和套索回归(L1范数)。你可以看这个<a class="ae jm" href="https://youtu.be/VqKq78PVO9g" rel="noopener ugc nofollow" target="_blank">视频</a>了解更多关于脊和套索回归的知识。</p><p id="12aa" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">那么，我们如何衡量我们的线性回归模型是好的呢？因此，我们可以使用几个评估指标来衡量线性回归模型的好坏，包括均方根误差(RMSE)、均方误差(MSE)、平均绝对误差(MAE)、平均绝对百分比误差(MAPE)和平均百分比误差(MPE)。</p><p id="22a3" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现线性回归:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lq"><img src="../Images/29539aec4c5ef90016016cde45cc6aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QF41kK95IW7QRMs30Lg11w.png"/></div></div></figure><h1 id="e872" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 2。逻辑回归</strong></h1><p id="152b" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">就像线性回归一样，逻辑回归也是一种有监督的机器学习算法。逻辑回归通常用于分类，因为它可以输出与属于给定类别的概率相对应的值。与预测结果为连续值的线性回归不同，逻辑回归预测结果为离散类。</p><p id="5e24" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">逻辑回归使用sigmoid函数转换输出并返回一个概率值，然后可以将该概率值映射到两个或多个离散类。如果估计的概率大于50%或具有最大值，则模型预测该实例属于该类，如果它不属于该类或具有较小的值，则模型预测它不属于该类。比如60%是1类，40%是0类。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lr"><img src="../Images/44ddc35d8c38917f2d9bb1a40f69569e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Fn3jS5uV9RvxsBH1G_Emzg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Logistic regression with sigmoid function (image by author).</figcaption></figure><p id="bfc1" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">逻辑回归可用于多种分类情况，如二元分类(通过或失败)、多类分类(猫、狗或猪)和有序分类(高、中、低)。为了评估逻辑回归模型，我们可以使用混淆度、ROC曲线、AIC (Akaike信息标准)、零偏差和剩余偏差。</p><p id="c4a6" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现逻辑回归:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ls"><img src="../Images/791cf7e0fe58f991669b9c12d90f4063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1IBX3eUvCfxCNxXxdt2R3Q.png"/></div></div></figure><h1 id="923a" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 3。支持向量机(SVM) </strong></h1><p id="a296" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">支持向量机(SVM)是一种受监督的机器学习算法，能够执行线性或非线性分类、回归和异常值检测。SVM算法的目标是了解每个训练数据点对于表示两个类别之间的决策边界(<em class="le">超平面</em>)有多重要，并产生属于不同类别的对象之间的最大最小距离(<em class="le">余量</em>)。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lr"><img src="../Images/e14e2e08db5c5f8101ff01ad7cd2ac32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*--FsBL8dIU53NoSGFG3uPw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Support vector machine (Zhang et al., 2020).</figcaption></figure><p id="a2c6" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">SVM可以处理分类任务和回归任务。在分类任务中，SVM试图在两个类之间拟合最大可能的街道，同时限制边界违规。而在回归任务中，SVM试图在街道上拟合尽可能多的实例，同时限制边界违规，街道的宽度由超参数控制。</p><p id="5788" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">在分类任务中，SVM适用于可线性分离或不可线性分离的数据集。对于可分离的数据集，我们可以使用软间隔分类，而对于不可分离的数据集，我们可以使用多项式核、相似性特征和高斯RBF核。</p><p id="c19b" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现支持向量机:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lt"><img src="../Images/8dc446dfbe176fc501f540c4101abd3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pWVopEEIEte9tIeVDRPehA.png"/></div></div></figure><h1 id="ba48" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 4。k-最近邻(KNN) </strong></h1><p id="f439" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">k-最近邻(KNN)是最简单的监督机器学习算法之一，用于分类和回归。K-最近邻的主要概念是找到预定义数量的最接近新点的训练样本，并从这些训练样本中预测标签。训练数据集中最近的数据点称为其<em class="le">最近邻</em>。</p><p id="30e8" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">KNN算法有以下步骤。首先，选择邻居的数量K。然后，计算新点和所有训练数据之间的欧几里德距离。最后，挑选最接近的训练数据的前K个。</p><p id="76a5" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">在创建KNN模型时，您需要注意两个重要参数，包括相邻要素的数量以及如何测量数据点之间的距离。在实践中，选择三个或五个邻域已经给出了很好的精度结果，但是您仍然必须对其进行调整以获得具有高精度的模型(尽可能选择奇数个邻域)。选择正确的距离度量也非常重要，但在实践中，欧氏距离效果很好。</p><p id="8de8" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现K近邻:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lu"><img src="../Images/f217fccddf644028732ce5d18700e858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gl4WwAamtvGnG97KmXrVaQ.png"/></div></div></figure><h1 id="88df" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 5。朴素贝叶斯分类</strong></h1><p id="2b88" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">朴素贝叶斯分类也是一种监督机器学习算法，它是一种分类器算法。朴素贝叶斯是基于贝叶斯理论的概率分类器，这意味着基于对象的概率进行预测。给定一些新信息P(B | A)和事件概率P(A)的先验信念，贝叶斯定理是理解某个事件概率P(A | B)的首要方法。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lv"><img src="../Images/4a21949bd2087bfb4a48528524899e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*fZfNwzNoMN_pjUGtDkpfPg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Bayesian formula</figcaption></figure><p id="7d35" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">存在几种类型的朴素贝叶斯模型，包括高斯模型、多项式模型和伯努利模型。高斯NB假设特征遵循正态分布，可应用于任何连续数据，而伯努利NB假设二进制数据，当数据为多项式分布时，使用多项式NB。</p><p id="cfe6" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现朴素贝叶斯:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lw"><img src="../Images/abde9b41c9796fbe09242337b5a2ffea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xmVANQ1hDnJO9eehzlVykQ.png"/></div></div></figure><h1 id="d773" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 6。决策树</strong></h1><p id="c7d1" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">决策树是受监督的机器学习算法，可用于分类和回归任务。决策树的主要概念是创建一个模型，通过学习从数据特征推断的简单决策规则来预测目标变量的值。决策树的工作方式是将数据集连续分割成小段，直到目标变量不变或数据集无法再分割为止。但这种算法是贪婪的，它在某一时刻做出最佳决策，而不考虑全局最优。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lr"><img src="../Images/3791673bfe4683db0ecb21dde80aed95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Cgufg53tqkvCHkrdF2AxCg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Example of decision tree (Muller &amp; Guido, 2016).</figcaption></figure><p id="11fb" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">决策树还可以估计一个实例属于某个特定类的概率。实际上，决策树模型很容易过度拟合。要解决这个问题，您可以提前停止创建树，或者先构建树，然后删除或折叠包含少量信息的节点。要提前停止创建树，必须设置树的最大深度和最大叶子数。</p><p id="dd1d" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现决策树:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lx"><img src="../Images/4fc2ab80bc72afbbe6689eca2eea3193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qagV9gpx3dEghfZdF2mgyQ.png"/></div></div></figure><h1 id="0dd8" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated">7 .<strong class="ak">。随机森林</strong></h1><p id="dbda" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">随机森林是一种有监督的机器学习算法，是一种集成方法。集成是结合多个机器学习模型来创建更强大的模型的方法。随机森林基本上是决策树的集合，其中每棵树都与其他树略有不同。随机森林的工作原理是根据随机的特征子集训练许多决策树，然后对它们的预测进行平均。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ly"><img src="../Images/23e34aed96fc03accb33b6ccbb4354cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*TmcWan8gmNOWAE7u8lZrfQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Random forest (Laudato et al., 2020).</figcaption></figure><p id="c204" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">导致过度拟合模型的决策树问题的解决方案是随机森林。随机森林通过平均来自多个决策树的结果来减少训练数据的过度拟合。制作随机森林模型有几个挑战，包括需要很长的训练时间，因为它是一个学习集合，比其他机器学习模型需要更多的资源，并且更复杂。</p><p id="736d" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现随机森林:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lz"><img src="../Images/1f0ec67688efb664f644dd48991e9e40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_YIJam19WFuRnYJFT5NVw.png"/></div></div></figure><h1 id="b0f3" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak"> 8。k-均值聚类</strong></h1><p id="9897" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">K-means聚类是一种无监督的机器学习算法，也是最常用的聚类算法。聚类是将数据集划分成组的任务，这些组称为聚类。如果我们希望对未标记的数据进行分组，K-means算法是一个不错的选择。K-means聚类试图找到代表某个数据区域的聚类中心，并将每个数据点分配到最近的聚类中心。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ly"><img src="../Images/12d338516ce4d76f57082d69d6538344.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*qdoBXt7vgF9GgcwbFfVTkg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Kmeans clustering (image by author).</figcaption></figure><p id="fb6f" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">这里最重要的事情是，你必须确定算法必须找到的k个簇的数量。当聚类过少或过多时，模型的性能会很差。此外，选择正确的质心初始化策略对模型在训练期间的性能有显著影响。</p><p id="b5e3" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">使用Scikit-learn简单实现K-means聚类:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ma"><img src="../Images/50a7f23966372a8c59e9dc5e08c05197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uDc6cEVZYaDqyRhMwrZrUw.png"/></div></div></figure><h1 id="b527" class="jn jo hh bd jp jq jr js jt ju jv jw jx in jy io jz iq ka ir kb it kc iu kd ke bi translated"><strong class="ak">总结</strong></h1><p id="a2e0" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">这个世界上有许多机器学习算法，每天都会有新的算法出现。流行的机器学习算法，其中一些是线性回归、逻辑回归、支持向量机、K-最近邻、朴素贝叶斯分类、决策树、随机森林和K-均值聚类。每种算法都有自己的优缺点。在实践中，您可能会尝试应用这些算法，并选择性能最佳的算法。</p></div><div class="ab cl mb mc go md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ha hb hc hd he"><h1 id="4da3" class="jn jo hh bd jp jq mi js jt ju mj jw jx in mk io jz iq ml ir kb it mm iu kd ke bi translated"><strong class="ak">参考文献:</strong></h1><p id="7f43" class="pw-post-body-paragraph kf kg hh kh b ki kj ii kk kl km il kn ko kp kq kr ks kt ku kv kw kx ky kz la ha bi translated">[1]阿尔邦，C. (2018)。机器学习与Python食谱:从预处理到深度学习的实用解决方案。奥赖利媒体</p><p id="ff16" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">[2] Géron，a .(2019)。使用Scikit-Learn、Keras和Tensorflow进行机器学习:构建智能系统的概念、工具和技术。奥赖利媒体</p><p id="ddab" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">[3]劳达托、詹纳罗&amp;奥利韦托、罗科&amp;斯卡拉布利诺、西蒙尼&amp;科拉维塔、安吉拉-丽塔&amp;德维托、卢卡&amp;皮卡里略、弗朗切斯科&amp;图多萨、伊万。(2020).压缩心电图信号中R峰出现的识别。10.1109</p><p id="8784" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">[4]a .穆勒和s .圭多(2016)。Python机器学习导论:数据科学家指南。奥赖利媒体</p><p id="f9b8" class="pw-post-body-paragraph kf kg hh kh b ki lf ii kk kl lg il kn ko li kq kr ks lk ku kv kw lm ky kz la ha bi translated">[5]张，简&amp;松拉，拉胡尔&amp;洛克哈特，瑟蒙。(2020).使用可穿戴传感器和支持向量机自动检测老年人的动态和静态活动。Sci。2.56.10.3390/sci2030056。</p><div class="mn mo ez fb mp mq"><a rel="noopener follow" target="_blank" href="/mlearning-ai/top-python-libraries-for-data-visualization-static-and-interactive-visualization-e5f1bc72de41"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hi fi z dy mv ea eb mw ed ef hg bi translated">用于数据可视化的顶级Python库(静态和交互式可视化)</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">用于数据可视化的python库集合</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jg mq"/></div></div></a></div></div></div>    
</body>
</html>
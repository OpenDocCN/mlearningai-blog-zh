<html>
<head>
<title>Web Scraping in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的Web抓取</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/web-scraping-in-python-cf1e506572f?source=collection_archive---------2-----------------------#2022-09-04">https://medium.com/mlearning-ai/web-scraping-in-python-cf1e506572f?source=collection_archive---------2-----------------------#2022-09-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1704" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将关注Python中的Web抓取。我们将演练什么是web抓取，在Python中使用什么库，什么是CSS选择器，以及一个循序渐进的例子。希望你觉得有用，我感谢任何反馈。另外，请在下面的GitHub或Gitlab库中找到这些项目。</p><p id="49b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">gitlab:<a class="ae jc" href="https://gitlab.com/rshowrav/webscraping-in-python" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/rshowrav/webscraping-in-python</a></p><p id="b6c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">GitHub:【https://github.com/rshowrav/webscraping-in-python T2】</p><p id="74a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，这类似于我写的一篇关于如何在r中抓取网页的文章。如果你对此感兴趣，请参见下面的文章。</p><div class="jd je ez fb jf jg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/web-scraping-in-r-dcd1e95ae8fd"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">R中的网页抓取</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">在这篇文章中，我们将重点讨论r中的web抓取。我们将演练什么是Web抓取，在r中使用什么库…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">medium.com</p></div></div><div class="jp l"><div class="jq l jr js jt jp ju jv jg"/></div></div></a></div><h1 id="36ed" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">什么是网页抓取？</h1><p id="549d" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">网络抓取最简单的定义是从网站中提取内容和数据的行为。网站是使用超文本标记语言(HTML)代码构建的，网页抓取代码或网页抓取器可以从该代码下载对象。Python是一个强大的工具，让我们可以使用代码来抓取网站。</p><h1 id="fc2d" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">什么是CSS选择器？</h1><p id="a396" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">当使用HTML构建网站时，它们与定义了规则的属性值一起存储。在Web抓取的意义上，通过识别CSS选择器，我们可以更简单地获得HTML代码的特定部分。SelectorGadget是为给定站点识别CSS选择器的一个很好的工具。SelectorGadget确实要求你使用谷歌Chrome作为浏览器。注意，在示例项目中也使用了这个工具来识别所需的CSS选择器。要了解有关该工具的更多信息，请参阅以下链接中的文档:</p><div class="jd je ez fb jf jg"><a href="https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">选择orGadget</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">简单，强大的CSS选择器生成。</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">chrome.google.com</p></div></div><div class="jp l"><div class="kz l jr js jt jp ju jv jg"/></div></div></a></div><h1 id="81fd" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">这个例子</h1><p id="08a8" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">在本文中，我们将浏览一家笔记本电脑商店，并从网站上获取所需的基本信息。这个例子中使用商店是MicroCenter。将收集的详细信息包括笔记本电脑信息、SKU号码、产品价格和预计发货时间。我们将在Python中执行必要的提取。</p><h1 id="4062" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">步骤1:安装必要的软件包</h1><p id="f361" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">使用下面的代码(假设你用的是Notebook ),我们下载必要的包来执行网络抓取。每个包装的详细信息如下:</p><ul class=""><li id="acf0" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">Pandas-是Python中的一个包，它让我们可以执行数据分析和操作。为了我们的目的，将被用来创建一个数据帧。</li><li id="c40c" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">BS4-是Python中的一个包，可以让你从HTML中提取数据。</li><li id="90dc" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">请求——允许我们向网站发送HTTP请求。简单来说，它让我们与网站互动。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="dd32" class="lx jx hh lt b fi ly lz l ma mb">!pip install pandas<br/>!pip install bs4<br/>!pip install requests</span></pre><h1 id="ab2a" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">步骤2:导入包</h1><p id="3741" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">在安装完这些包之后，接下来必须将它们导入Python以用于我们的代码。这可以使用下面的代码来完成。</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="fe2c" class="lx jx hh lt b fi ly lz l ma mb">import pandas as pd<br/>from bs4 import BeautifulSoup<br/>import requests</span></pre><h1 id="e46a" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">第三步:了解网站</h1><p id="39f3" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">接下来就是了解网站了。正在使用的示例包含以下内容。</p><figure class="lo lp lq lr fd md er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mc"><img src="../Images/0125ecb8f167507aebefc92d31d8d7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2ZY1njS2TLHDRtQKCQPWw.png"/></div></div></figure><p id="b63c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的截图向我们展示了我们想要捕捉的功能，包括笔记本电脑信息、SKU号码、价格和发货时间细节。另外，请注意，总共有162台可用的笔记本电脑(即我们预期的记录数量)。此外，请注意，这些笔记本电脑在多个网页上。</p><h1 id="7a42" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">步骤4:了解统一资源定位器(URL)</h1><p id="fbf9" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">理解如何与URL交互是网络抓取的关键。正如我们在下面看到的，如果我们转到网站的第2页，我们会看到下面的URL。</p><figure class="lo lp lq lr fd md er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mj"><img src="../Images/d3467e58f22b0a71b1eb5a2369b308b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BnMqmTRv7W9rqr0r.png"/></div></div></figure><p id="6ded" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">重复这个过程，转到第1页，得到下面的网址。</p><figure class="lo lp lq lr fd md er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mj"><img src="../Images/0a3f6edcc6b92c495b1a659e005dc6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rGsU4LBK1EYohg3-.png"/></div></div></figure><p id="674b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，在URL中，转到URL中的第2页，我们看到page=2，转到第1页，URL变为page=1。此外，URL中的所有其他字段保持不变。</p><h1 id="8801" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">步骤5:创建空数组</h1><p id="415c" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">为了存储我们感兴趣的数据，我们需要创建空数组。这可以使用下面的代码来完成:</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="38d5" class="lx jx hh lt b fi ly lz l ma mb">info = []<br/>sku = []<br/>price = []<br/>ship_time = []</span></pre><h1 id="f1e4" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">第六步:网页抓取</h1><p id="d627" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">下面Python中的下一个代码是数据的实际抓取和编译，我们将解释它的每个元素。第一部分是一个for循环，它创建了一个pgn元素，该元素从1到7(注意:这是因为网站有7个页面)。下一部分是创建一个链接(即代码中的url)，这分为3个部分的网址，中间部分填充后页=正如我们在研究时确定的网址。因此，每个页面都将使用request语句requests来读取，并存储在res中。然后，漂亮的soup包将为我们提供一种从URL与HTML进行交互的方法，并将它存储在Soup中。接下来，是我们的初始for循环中的一系列for循环:它的第一个方面是定位CSS选择器(注意:使用SelectorGadget)，在循环中以文本形式返回结果，然后追加到数组中。循环运行，直到它通过所有7页。</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="aeda" class="lx jx hh lt b fi ly lz l ma mb"># Initial loops through each page<br/>for pgn in range(1,8):<br/>    url = "<a class="ae jc" href="https://www.microcenter.com/search/search_results.aspx?N=4294967288&amp;NTK=all&amp;page=" rel="noopener ugc nofollow" target="_blank">https://www.microcenter.com/search/search_results.aspx?N=4294967288&amp;NTK=all&amp;page=</a>" + str(pgn) + "&amp;cat=Laptops/Notebooks-:-MicroCenter"<br/>    res = requests.get(url)<br/>    soup = BeautifulSoup(res.text)<br/>   #loops to get each text from each CSS selector <br/>    for info_select in soup.select(".normal a"):<br/>        info.append(info_select.text)<br/>    for sku_select in soup.select(".sku"):<br/>        sku.append(sku_select.text)<br/>    for price_select in soup.select(".price &gt; span"):<br/>        price.append(price_select.text) <br/>    for ship_time_select in soup.select(".availabilityTrunc"):<br/>        ship_time.append(ship_time_select.text)</span></pre><h1 id="cc2a" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">步骤7:存储在数据框中</h1><p id="db5a" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">最后，我们需要使用Python中的Pandas包来存储数据框中的数据。这可以使用下面的代码来完成:</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="6b0d" class="lx jx hh lt b fi ly lz l ma mb">df=pd.DataFrame(columns=['info','sku','price','ship_time'])<br/>df['info']=pd.DataFrame(info)<br/>df['sku']=pd.DataFrame(sku)<br/>df['price']=pd.DataFrame(price)<br/>df['ship_time']=pd.DataFrame(ship_time)</span><span id="127d" class="lx jx hh lt b fi mk lz l ma mb">df</span></pre><p id="b42d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">代码的第一个方面是用给定的列名创建一个空数据框。然后将前一步中的每个数组存储在每一列中。</p><h1 id="d5bf" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">最终输出</h1><p id="2d35" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">最终输出将是下面的内容，其中包含我们感兴趣的要素和现在位于数据框中的162条记录。</p><figure class="lo lp lq lr fd md er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es ml"><img src="../Images/9d633714538b69ea4857409863f345a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ATe907OhgyeMoyB7fs-41A.png"/></div></div></figure><div class="jd je ez fb jf jg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hi fi z dy jl ea eb jm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">medium.com</p></div></div><div class="jp l"><div class="mm l jr js jt jp ju jv jg"/></div></div></a></div></div></div>    
</body>
</html>
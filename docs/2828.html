<html>
<head>
<title>Quick introduction to CounterFactual Regression (CFR)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反事实回归(CFR)快速介绍</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/quick-introduction-to-counterfactual-regression-cfr-382521eaef21?source=collection_archive---------0-----------------------#2022-06-15">https://medium.com/mlearning-ai/quick-introduction-to-counterfactual-regression-cfr-382521eaef21?source=collection_archive---------0-----------------------#2022-06-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/cfc2492468275551bf73219b0a890b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UIsdIdMRPYigLils"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://www.pexels.com/@agk42/" rel="noopener ugc nofollow" target="_blank">Alex Knight </a>from <a class="ae it" href="https://www.pexels.com/photo/high-angle-photo-of-robot-2599244/" rel="noopener ugc nofollow" target="_blank">Pexels</a>:</figcaption></figure><p id="d530" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">日语里有个有趣的短语“Deep de Pon！(Deepでポン！)".这句话本意是贬损把深度学习应用于一切和任何事物的态度。</p><p id="7d2e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">虽然深度学习在NLP和CV等领域的表现确实令人印象深刻，但它在因果推理方面的活动似乎有限。在因果推断中，仔细讨论识别策略是最重要的，然后只是选择一个合适的估计方法。显然，出于这个目的，提出深度学习是大材小用。这就像“深德邦！”。</p><p id="c624" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">不过最近在因果推理领域出现了一些使用深度学习的有趣论文。今天我们要介绍其中的一种，<strong class="iw hi">反事实回归</strong>(以下简称<strong class="iw hi"> CFR </strong>)。</p><p id="bde1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本帖描述的模型原纸如下:</p><p id="0d17" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">【沙利特等人，2017】沙利特，尤里，弗雷德里克·d·约翰逊，大卫·桑塔格。"估计个体治疗效果:一般化界限和算法."机器学习国际会议。PMLR，2017。</strong></p><p id="0439" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">【约翰松等人，2016】约翰松、弗雷德里克、尤里·沙利特、大卫·桑塔格。"学习反事实推理的表征."机器学习国际会议。PMLR，2016。</strong></p><p id="4d7c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们特别关注【Shalit et al. 2017】。【Johansson et al .，2016】不是主要关注点，但这里有一些比较容易理解的数字和解释，我们酌情参考</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h2 id="a32b" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated"><strong class="ak">目录和摘要</strong></h2><p id="f505" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">由于这篇文章的篇幅有点大，所以先提供一个目录和摘要。我们希望你只阅读你需要知道的东西。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="1516" class="jz ka hh le b fi li lj l lk ll"><strong class="le hi">1. Motivation : </strong><br/>CFR is a model for causal inference and was developed specifically for estimating ITE (Individualized Treatment Effect).<br/>We will discuss its estimation difficulties.</span><span id="5635" class="jz ka hh le b fi lm lj l lk ll"><strong class="le hi">2. CFR’s Solution :<br/></strong>This section describes the CFR's solution.<br/>If you would like to get at least a rough idea of this model, we hope you will read this section alone!</span><span id="012a" class="jz ka hh le b fi lm lj l lk ll"><strong class="le hi">3. Theoretical Bound :<br/></strong>This chapter discusses the theoretical bound for errors in estimated causal effects. This is a detailed discussion and can be skipped; we will only introduce the conclusion.</span><span id="6543" class="jz ka hh le b fi lm lj l lk ll"><strong class="le hi">4. Let's do it with PyTorch :</strong><br/>Since the implementation in the original paper was in TensorFlow, a simple rewrite in PyTorch is presented here. Even if you are not good at mathematics, you should be able to understand it better by reading the python code.</span><span id="a848" class="jz ka hh le b fi lm lj l lk ll"><strong class="le hi">5. Experiments and discussion on hyperparameters :<br/></strong>Here we perform several experiments on hyperparameters. Although there is a problem that the sample data selected for this blog was not very suitable for this model, we would like to share the difficulty of tuning α as a practical issue.</span><span id="93a3" class="jz ka hh le b fi lm lj l lk ll"><strong class="le hi">6. Why do we need CFR?</strong><br/>Although CFR has some practical difficulties, such as the difficulty of adjusting alpha, I would like to show what the benefits of CFR are. Although this is a somewhat personal and subjective view, we hope that the expressive power of DeepLearning will broaden the scope of causal inference. we are looking forward to further breakthroughs in the future.</span></pre></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="0328" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated">1.动机</h1><p id="dd48" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">首先，下面是我们希望寻求的估计。我们在这里提出的模型是用来无偏地估计ITE(个体化治疗效果)的；我们感兴趣的是每个个体的因果效应，而不是对群体的效应，如ATE(平均治疗效应)和ATT(平均治疗效应)。(当然，ATE和ATT可以通过合计ITE来计算。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/1b36fa9ff6d2f36a2c82082792be9187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umJ5Gq0hIPK4sHRC15kcyg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 1: “ITE” Based on [Johansson et al., 2016], with additional explanations added by the author.</figcaption></figure><p id="5b74" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">和上面ITE的定义一样，ITE由yF和yCF组成。前者是实际观察到的结果，而后者是治疗相反的世界中的潜在结果(反事实结果)。yCF不是直接观测到的，所以可以用任何机器学习模型来估计。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mf"><img src="../Images/f3413034adbe34664769f834264d0ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_AMOF3sFh4wt4pXURUGpAw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 2: “empirical factual/counterfactual distribution” Based on [Johansson et al., 2016], with additional explanations added by the author.</figcaption></figure><p id="9d67" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然而，很难正确预测yCF。这是因为经验事实分布不等于经验反事实分布。</p><p id="cad1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">CFR概念的有趣之处在于，它将这个问题视为一个<strong class="iw hi">协变量转移</strong>。</p><blockquote class="mg mh mi"><p id="b59d" class="iu iv mj iw b ix iy iz ja jb jc jd je mk jg jh ji ml jk jl jm mm jo jp jq jr ha bi translated">“通过反事实预测进行因果推断的问题可能需要对不同于给出样本的分布进行推断。在机器学习术语中，这意味着测试集的特征分布不同于训练集的特征分布。这是协变量移位的一个例子，是域适应的一个特例”[Johansson et al .，2016]</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="a295" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated"><strong class="ak"> 2。CFR的解决方案</strong></h1><p id="f35a" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">以下来自[Johansson et al. 2016]的概念性图解是理解CFR的最佳方式。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/15bf12d889398fe875103ad8aecd7824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9H2sYpw_i-pwbTQPTY5QFw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 3: “CFR concept” Based on [Johansson et al., 2016], with additional explanations added by the author.</figcaption></figure><p id="01fc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">值得注意的是，新增了一个<strong class="iw hi">损失</strong>。<br/>这是一种损失，它在从协变量x到y的网络中间创建了一个<strong class="iw hi">表示层</strong>，并调整t=1和t=0的分布，使其尽可能相似。</p><p id="05d2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">更具体的架构如下:</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/b336f75318a0c3049f72536a3b895678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LqWvsxEPHyFKzL7pMx_pCg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 4: “CFR architectures” Based on [Johansson et al., 2016] and [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure><p id="cc8c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">网络定义<br/> - <em class="mj"> repnet </em>:从协变量x到表示层的网络<br/> - <em class="mj"> outnet </em>:从表示层到结果y的网络</p><p id="817f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在[Johansson et al .，2016]中，<em class="mj"> outnet </em>很简单:一个MLP(多层感知器)，将表示层和处理变量作为输入(<em class="mj"> `split_outnet=False` </em>)。<br/>另一方面，<em class="mj">out net</em>in【Shalit er al。，2017]基于治疗的存在或不存在构建两个MLP(<em class="mj">` split _ outnet = true `</em>)。</p><p id="44de" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面我们基本采用[Shalit er al]的架构。2017].</p><p id="8f89" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">目标函数如下:</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/a15b56c4dc4a63ce22b8fb2eee45e2f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4HW5JVpwMzGVqPFEd4mmA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 5: “CFR’s object function” Based on [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure><ul class=""><li id="6b8e" class="mq mr hh iw b ix iy jb jc jf ms jj mt jn mu jr mv mw mx my bi translated">上图中的红框是正常监督学习的损失。</li><li id="e2b1" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">蓝色外壳是CFR专用损耗；表示层中处理和控制分布的伪距离(IPM)被视为损失。</li><li id="8755" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><strong class="iw hi"> α </strong>是一个超参数，用于调整IPM损失(惩罚)的贡献</li></ul><p id="37db" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="mj">此处仅供参考，有困惑的可以不看，但CFR将因果推理视为领域适应。<br/>从下面可以看出，确实很清楚，架构和目标函数类似于领域对抗性神经网络(DANN)【Ganin et al .，2016】。</em></p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ne"><img src="../Images/f4381f178ee3b178d1d316103b903b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xFBZBcfHE8DVv-udUdyGMQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 6: “DANN vs. CFR” Based on <em class="nf">[Ganin et al., 2016] and</em> [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="221c" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated"><strong class="ak"> 3。理论界限</strong></h1><p id="c89c" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">虽然这一章有些详细，但我们之所以介绍它，是因为它是CFR的有趣特性之一。首先，我们定义ITE误差。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ng"><img src="../Images/0a5011202f4df10ed901715909422cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8v9Yhx8thOlzgDUF3WJWQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 7: “the expected PEHE loss” Based on [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure><p id="37c6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是一个明显但<strong class="iw hi">不可测量的指标。</strong>(不可能知道真实的ITE τ(x))。但是，CFR告诉我们，存在一个<strong class="iw hi">理论界限</strong>！！</p><p id="8171" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了得出界限，我们将“<strong class="iw hi">例外反事实损失</strong>定义如下:与“预期实际处理/控制损失”(下图左侧)不同，后者实际上也无法观察到。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nh"><img src="../Images/f50bb5156b5ee63cea2f0a432f7a8f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gBkPiebxUzIyZfuzHwr7g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 8: “the expected counterfactual loss” Based on [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure><p id="f5bf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过设定例外反事实损失的上限，我们能够证明ITE损失(PEHE损失)与预期实际处理/控制损失和IPM损失(两者都是可观察损失)有一个上限。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/319fdf490708de8a34bfee2eb0e32a07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCKymSu7prIwqKZuQ8hSLQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 9: “a theoretical bound” Based on [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure><p id="2167" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以上引理的证明请参考原论文的附录[Shalit er al ., 2017].</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="85d7" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated">4.让我们用PyTorch做吧</h1><p id="e449" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">以下两个github存储库用作参考。</p><ul class=""><li id="8b73" class="mq mr hh iw b ix iy jb jc jf ms jj mt jn mu jr mv mw mx my bi translated">https://github.com/clinicalml/cfrnet</li><li id="ae40" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">https://github.com/koh-t/SC-CFR<a class="ae it" href="https://github.com/koh-t/SC-CFR" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="dcd7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">前者([cfrnet])是原版的正式实现；在TensorFlow中实现。里面的算法作为参考。后者([SC-CFR])是用PyTorch实现的，和我的一样。模型的架构是不同的，但是我使用了许多类定义等等。作为参考。</p><p id="c58e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我的资源库如下:【https://github.com/MasaAsami/introduction_to_CFR】T5<br/>T6】</p><h2 id="56f9" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">cfr.py</h2><figure class="kz la lb lc fd ii"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx">cfr.py</figcaption></figure><ul class=""><li id="9419" class="mq mr hh iw b ix iy jb jc jf ms jj mt jn mu jr mv mw mx my bi translated">第139行定义了<em class="mj"> repnet </em>。</li><li id="afb4" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">149和152线为<em class="mj"> outnet </em>，分别用于处理和控制。</li><li id="4d31" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">第73~91行是CFR中新增的IPM损耗。在本实验中，<strong class="iw hi">线性最大均值差异</strong>(线性MMD)被用作IPM损失。</li></ul><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nk"><img src="../Images/637ee91c186303802a6bad994a2404fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KTMgtQmgp-fH3bgl"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 10: “linear MMD” Based on [Shalit er al., 2017]</figcaption></figure><ul class=""><li id="91c1" class="mq mr hh iw b ix iy jb jc jf ms jj mt jn mu jr mv mw mx my bi translated">原始论文中的形式算法具有收敛判定机制，但是为了简单起见，我们上面的实现使用了固定数量的历元(在第35行)。</li></ul><h2 id="421e" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">数据集:</h2><p id="54aa" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">在这里，正如我们之前的文章一样，我们使用了LaLonde数据集(失业者职业培训数据集)；国家支持工作演示(NSW)数据集是一个RCT，因此真实的ATT是可以确定的。(ATT=1676.3426) <br/>我们采用非实验数据(CPS:当前人口调查)作为对照组，并移除新南威尔士州对照组，以创建数据进行验证。</p><p id="3925" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">(详见<a class="ae it" href="https://python.plainenglish.io/comparison-of-estimation-methods-in-causal-inference-16f5ac9ed122" rel="noopener ugc nofollow" target="_blank">上一篇</a>和本文末尾的附录。)</p><h2 id="566a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">配件:</h2><p id="acf3" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">超参数设置如下:</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="a1de" class="jz ka hh le b fi li lj l lk ll">cfg <strong class="le hi">=</strong> {<br/>    "alpha": 10 <strong class="le hi">**</strong> 6,<br/>    "lr": 1e-3,<br/>    "wd": 0.5,<br/>    "sig": 0.1,<br/>    "epochs": 1000,<br/>    "ipm_type": "mmd_lin",<br/>    "repnet_num_layers": 3,<br/>    "repnet_hidden_dim": 48,<br/>    "repnet_out_dim": 48,<br/>    "repnet_dropout": 0.145,<br/>    "outnet_num_layers": 3,<br/>    "outnet_hidden_dim": 32,<br/>    "outnet_dropout": 0.145,<br/>    "gamma": 0.97,<br/>    "split_outnet": <strong class="le hi">True</strong>,<br/>}</span></pre><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nl"><img src="../Images/304052ee4ab37d63439d17c1e6a2fc91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LgURZkVgkfsx2DdLZLR8Kw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 11: “temp hyperparams” Based on [Shalit er al., 2017], with additional explanations added by the author.</figcaption></figure><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="5656" class="jz ka hh le b fi li lj l lk ll">model <strong class="le hi">=</strong> CFR(in_dim<strong class="le hi">=</strong>8, out_dim<strong class="le hi">=</strong>1, cfg<strong class="le hi">=</strong>cfg)<br/><br/>within_result, outof_result, train_mse, ipm_result <strong class="le hi">=</strong> model<strong class="le hi">.</strong>fit(<br/>    dataloader, X_train, y_train, t_train, X_test, y_test, t_test, logger<br/>)</span></pre><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nm"><img src="../Images/00c94f883c2aaf990e9d100e7eef393e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qdIjHJSvrQRzD0kJRIFcKQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 12: “fitting results” by the author.</figcaption></figure><p id="1f6c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">真正的ATT是1676.3426。看起来应该不远了。</p><h2 id="1237" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated"><strong class="ak">表现层可视化:</strong></h2><p id="8ebb" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">通过t-SNS(<em class="mj">` sk learn . manifold . tsns `</em>)对表示层分布情况进行二维汇总，然后可视化。原始数据位于左侧，制图表达图层位于右侧。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nn"><img src="../Images/f135edd8f7f1ea0006e2f62a5c35fc50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9BBR-KAUwyKq4a4S-6K_wA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 13: “visualization of representation layer” by the author.</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="6cba" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated"><strong class="ak"> 5。超参数的实验和讨论</strong></h1><p id="9bc9" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">使用“<a class="ae it" href="https://hydra.cc/docs/intro/" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hi">九头蛇</strong> </a>和“<a class="ae it" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hi"> mlflow </strong> </a>建立实验环境</p><figure class="kz la lb lc fd ii"><div class="bz dy l di"><div class="ni nj l"/></div></figure><p id="6c25" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">基础超参数在yaml文件(<em class="mj">` config/experiments . YAML`</em>)中描述，实验结果在mlflow中管理。<br/>验证的参数如下<br/> -通过outnet_split的真/假验证ATT变化多少<br/> -通过按以下顺序改变α验证ATT的变化</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="0fb0" class="jz ka hh le b fi li lj l lk ll">$ python experiment_run.py -m alpha=0,0.1,0.01,0.001,0.0001,1,100,10000,100000,1000000,10000000,100000000,1000000000,10000000000,100000000000 split_outnet=True,False</span></pre><p id="14f1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以下命令启动mlflow浏览器，并允许您检查结果。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="c196" class="jz ka hh le b fi li lj l lk ll">$ mlflow ui</span></pre><p id="e7a7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后:</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es no"><img src="../Images/da62cc6da137684fdeb4d2d71e62d06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L4kfyhI8UxH0xU9scMBXIw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 14: “MLflow UI” by the author.</figcaption></figure><h2 id="8603" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">实验结果</h2><p id="13fc" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">结果如下。<br/> -顶行:样本内，底行:样本外<br/> -左:ATT估计值(虚线为真实的ATT)，右:结果预测误差(RMSE)</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es np"><img src="../Images/94a5eb953c91a638cb1f7b60492a4655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nl24BXLi2tgClpkR9hDsSA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 15: “Experiments Results” by the author.</figcaption></figure><h2 id="4336" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated"><strong class="ak">讨论(1/2) split_outnet: </strong></h2><p id="e5e6" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">当split_net==False时(即<em class="mj"> outnet </em>未分割)，治疗效果始终被估计为较低。</p><p id="6dc6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这可能是由于正则化偏差(收缩估计)的影响。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nq"><img src="../Images/3850d0dad282fba00f94bf74375b7f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n1FzV6YEf4027oaD_wQ9Ng.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 16: “shrinkage estimation with L2 penalty” by the author.</figcaption></figure><p id="48ca" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">顺带一提，这个结果并没有直接批评【Johansson et al. 2016】。【Johansson et al .，2016】的目标函数与【Shalit et al .，2017】的目标函数一开始就有些不同，所以这不是一个公平的比较。<br/>我们还认为这不是架构本身的缺陷，因为低估因果效应可能可以通过设计一种不在<em class="mj"> outnet </em>中包含正则项的方法来避免。<br/>但是，由于【Shalit et al .，2017】通过有无处理来分离<em class="mj">outnet</em>，对<em class="mj"> outnet </em>本身的正则化惩罚不应该应用于处理效果，我们认为有可能构建更复杂的<em class="mj"> outnet </em>。</p><h2 id="c2dc" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">讨论(2/2) α:</h2><p id="da4f" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">在这些数据中，几乎没有阿尔法收益。原始论文[Shalit等人，2017年]也使用了LaLonde作业数据集，并指出:</p><blockquote class="mg mh mi"><p id="15d4" class="iu iv mj iw b ix iy iz ja jb jc jd je mk jg jh ji ml jk jl jm mm jo jp jq jr ha bi translated">“在就业方面，我们认为使用IPM惩罚措施的收益比IHDP要小。我们相信这是事实，因为当我们最小化我们对观察数据的限制并考虑这种偏差时，我们只是在随机子集上评估预测，其中治疗组分布相同。”[沙利特等人，2017年]</p></blockquote><p id="edce" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">无论如何，α的调谐难度是很高的。<br/>在大多数情况下，真实的治疗效果是未知的，因此我们别无选择，只能根据IPM和结果损失做出模糊决策。</p><p id="0df0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个问题在原文中也被定位为<strong class="iw hi">未决问题</strong>:</p><blockquote class="mg mh mi"><p id="c5f5" class="iu iv mj iw b ix iy iz ja jb jc jd je mk jg jh ji ml jk jl jm mm jo jp jq jr ha bi translated">“重要的开放性问题是选择IPM权重α时的理论考虑，如何最好地获得我们模型预测的置信区间，以及如何将我们的工作与更复杂的因果模型(如具有隐藏混杂变量或工具变量的模型)相集成。”[沙利特等人，2017年]</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="b140" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated">6.为什么我们需要CFR？</h1><p id="c96d" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">这一章是<strong class="iw hi">我的个人观点</strong>，所以我希望你可以随意阅读……<br/>当我第一次了解CFR的时候，我很不尊重地认为它是矫枉过正。(在我看来这是一个“深de Pon！”努力的类型，正如我在这篇文章开头所说的。)</p><p id="0ae1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">α的寻找太难了，再加上还有其他模型来估算ITE，所以我不好意思说，我个人并没有特别看到CFR的重要性。</p><p id="9445" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">不过最近有CFR应用的论文，我觉得很吸引人。如你所知，深度学习是一个非常有表现力的模型，并且<strong class="iw hi">不再需要成为表格数据</strong>。</p><p id="9047" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[Takeuchi等人，2021]的以下应用将协变量作为图像进行处理。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nr"><img src="../Images/d6535796419bf365944cfd043ce54515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q4tGqYlHt5LnTTeX"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 17: “covariates as images” by[Takeuchi et al., 2021].</figcaption></figure><ul class=""><li id="2b66" class="mq mr hh iw b ix iy jb jc jf ms jj mt jn mu jr mv mw mx my bi translated">疏散引导被认为是一种治疗，干预的概率用剧院的拥挤程度来解释(<strong class="iw hi">图像数据</strong>)。</li><li id="96db" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">决策者看着拥挤的人群，决定是否治疗。</li></ul><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ns"><img src="../Images/3eb550e1a4edce7d440dae5a48d8ca8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jp9eJSHrMfokNTXC"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 18: “SC-CFR” by [Takeuchi et al., 2021].</figcaption></figure><p id="a331" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以上是SC-SCR [Takeuchi et al .，2021]的架构，它使用一个CNN(卷积神经网络)用于<em class="mj"> repnet </em>，允许协变量作为图像处理并用于偏差调整。</p><p id="ddfc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">希望深度学习的表达能力能够拓宽因果推理的范围。期待未来能有进一步的突破。</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="5e1c" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated">参考</h1><h2 id="bd60" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">(论文)</h2><ul class=""><li id="4641" class="mq mr hh iw b ix ku jb kv jf nt jj nu jn nv jr mv mw mx my bi translated">[Shalit等人，2017年] Shalit、Uri、Fredrik D. Johansson和David Sontag。<a class="ae it" href="https://proceedings.mlr.press/v70/shalit17a/shalit17a.pdf" rel="noopener ugc nofollow" target="_blank">估计个体治疗效果:推广范围和算法。</a>“机器学习国际会议。2017年，PMLR</li><li id="e06f" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">【Johansson et al .，2016】Johansson，Fredrik，Uri Shalit，和David Sontag。<a class="ae it" href="http://proceedings.mlr.press/v48/johansson16.pdf" rel="noopener ugc nofollow" target="_blank">学习反事实推理的表征。</a>“机器学习国际会议。PMLR，2016。</li><li id="db95" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">[Takeuchi等人，2021年] Takeuchi，Koh等人.“<a class="ae it" href="https://arxiv.org/abs/2102.03980" rel="noopener ugc nofollow" target="_blank">抓住人群的缰绳:使用因果推理估计人群运动引导的效果</a>”<em class="mj"> arXiv预印本arXiv:2102.03980，</em> 2021。</li><li id="1ade" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">【加宁等人，2016】加宁，y；乌斯季诺瓦，e；阿贾坎，h；日尔曼，p。拉罗歇尔；拉维奥莱特，f；马尔尚，m。和Lempitsky，v . .<a class="ae it" href="https://jmlr.org/papers/volume17/15-239/15-239.pdf" rel="noopener ugc nofollow" target="_blank">神经网络的领域对抗训练</a>机器学习研究杂志17(1):2096–2030，2016。</li></ul><h2 id="9288" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">(Python代码)</h2><ul class=""><li id="7d3b" class="mq mr hh iw b ix ku jb kv jf nt jj nu jn nv jr mv mw mx my bi translated">https://github.com/clinicalml/cfrnet</li><li id="f6a5" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">https://github.com/koh-t/SC-CFR</li></ul><h2 id="7a2e" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated"><strong class="ak">(我的github </strong>资源库<strong class="ak"> ) </strong></h2><ul class=""><li id="3f57" class="mq mr hh iw b ix ku jb kv jf nt jj nu jn nv jr mv mw mx my bi translated">https://github.com/MasaAsami/introduction_to_CFR<a class="ae it" href="https://github.com/MasaAsami/introduction_to_CFR" rel="noopener ugc nofollow" target="_blank"/></li></ul><h1 id="0d5b" class="ln ka hh bd kb lo nw lq kf lr nx lt kj lu ny lw km lx nz lz kp ma oa mc ks md bi translated">我的幻灯片</h1><figure class="kz la lb lc fd ii"><div class="bz dy l di"><div class="ob nj l"/></div></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="0d38" class="ln ka hh bd kb lo lp lq kf lr ls lt kj lu lv lw km lx ly lz kp ma mb mc ks md bi translated">附录:数据集</h1><h2 id="895b" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">描述</h2><p id="5881" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">该工作数据集是Dehejia和Wahba (1999)用于评估倾向得分匹配方法的国家支持工作示范数据集之一。该数据集和其他相关数据集(如CPS)可在<a class="ae it" href="http://users.nber.org/~rdehejia/data/nswdata2.html" rel="noopener ugc nofollow" target="_blank">http://users.nber.org/~rdehejia/data/nswdata2.html</a>获得。</p><h2 id="367c" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">python代码</h2><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="f2b5" class="jz ka hh le b fi li lj l lk ll">import pandas as pd</span><span id="313a" class="jz ka hh le b fi lm lj l lk ll"># LaLonde dataset(RCT)<br/>RCT_DATA = "<a class="ae it" href="http://www.nber.org/~rdehejia/data/nsw_dw.dta" rel="noopener ugc nofollow" target="_blank">http://www.nber.org/~rdehejia/data/nsw_dw.dta</a>"</span><span id="6d9b" class="jz ka hh le b fi lm lj l lk ll"># Data limited to cps surveys that were unemployed at the time of the survey.<br/>CPS_DATA = "<a class="ae it" href="http://www.nber.org/~rdehejia/data/cps_controls3.dta" rel="noopener ugc nofollow" target="_blank">http://www.nber.org/~rdehejia/data/cps_controls3.dta</a>"</span><span id="9dc5" class="jz ka hh le b fi lm lj l lk ll">df = pd.concat(<br/>    [<br/>        pd.read_stata(RCT_DATA).query(<br/>            "treat&gt;0"<br/>        ),  # RCT data, only treated data is extracted.<br/>        pd.read_stata(CPS_DATA),<br/>    ]<br/>).reset_index(drop=True)</span><span id="3eaa" class="jz ka hh le b fi lm lj l lk ll">del df["data_id"]</span><span id="9f7a" class="jz ka hh le b fi lm lj l lk ll">df["treat"] = df["treat"].astype(int)</span><span id="001d" class="jz ka hh le b fi lm lj l lk ll">df.sample(5)</span></pre><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es oc"><img src="../Images/3e23a8ae6b9404c2486ca3f2e5b0ea56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BKIF4B4f8xU243-6INZCTw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 19: “dataset sample” from NSW + CPS.</figcaption></figure><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="64d6" class="jz ka hh le b fi li lj l lk ll">df.groupby("treat")["re78"].count()</span></pre><figure class="kz la lb lc fd ii er es paragraph-image"><div class="er es od"><img src="../Images/7e766b0346bfaa90637fdddba3df09d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*sUcUpemcFL33sivLrBwGsA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 20: “sample size” from NSW + CPS.</figcaption></figure><h2 id="a5a3" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">格式</h2><p id="fad0" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated">治疗分配指示符是数据帧的第一个变量:<code class="du oe of og le b">treat</code> (1 =已治疗；0 =控制)。接下来的7列是协变量:</p><ul class=""><li id="6d6f" class="mq mr hh iw b ix iy jb jc jf ms jj mt jn mu jr mv mw mx my bi translated"><code class="du oe of og le b">age</code>，以年计量；</li><li id="e706" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">education</code>，以年计量；</li><li id="6e6d" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">black</code>，表示人种(黑人为1，其他为0)；</li><li id="768b" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">hispanic</code>，表示种族(如果是西班牙裔为1，否则为0)；</li><li id="3609" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">married</code>，表示婚姻状况(已婚为1，否则为0)；</li><li id="4939" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">nodegree</code>，表示高中毕业证(无学位为1，否则为0)；</li><li id="1d91" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">re74</code>，1974年的真实收益；</li><li id="40c6" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated"><code class="du oe of og le b">re75</code>，1975年真实收益。</li></ul><p id="e9a1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后一个变量是<code class="du oe of og le b">re78</code>，1978年的真实收益(<code class="du oe of og le b">outcome</code>)。</p><h2 id="b24a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">来源</h2><p id="cef8" class="pw-post-body-paragraph iu iv hh iw b ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn ky jp jq jr ha bi translated"><a class="ae it" href="https://users.nber.org/~rdehejia/data/" rel="noopener ugc nofollow" target="_blank">http://users.nber.org/~rdehejia/data/nswdata2.html</a></p><h2 id="c7e5" class="jz ka hh bd kb kc kd ke kf kg kh ki kj jf kk kl km jj kn ko kp jn kq kr ks kt bi translated">数据参考</h2><ul class=""><li id="e352" class="mq mr hh iw b ix ku jb kv jf nt jj nu jn nv jr mv mw mx my bi translated">Dehejia，r .和Wahba，s .,“非实验研究中的因果效应:重新评价培训计划的评估”，<em class="mj">美国统计协会杂志</em>，94，1053–1062，1999年。</li><li id="ae31" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi translated">拉隆德，“评估培训项目的计量经济学评估”，<em class="mj">《美国经济评论》</em>，76，604–620，1986年。</li><li id="6fd6" class="mq mr hh iw b ix mz jb na jf nb jj nc jn nd jr mv mw mx my bi">安井翔太（著）株式会社ホクソエム（監修）.『効果検証入門：正しい比較のための因果推論／計量経済学の基礎』技術評論社, 2020.</li></ul></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><div class="kz la lb lc fd oh"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="oi ab dw"><div class="oj ab ok cl cj ol"><h2 class="bd hi fi z dy om ea eb on ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="oo l"><h3 class="bd b fi z dy om ea eb on ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="op l"><p class="bd b fp z dy om ea eb on ed ef dx translated">medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov in oh"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Out-of-core, multi-label text classification with scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用scikit-learn进行核外多标签文本分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/out-of-core-multi-label-text-classification-with-scikit-learn-14afa4c1bb75?source=collection_archive---------4-----------------------#2021-12-14">https://medium.com/mlearning-ai/out-of-core-multi-label-text-classification-with-scikit-learn-14afa4c1bb75?source=collection_archive---------4-----------------------#2021-12-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="20b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在促进分类和回归任务并支持NLP/机器学习项目的各种开源库中，scikit-learn无疑是任何it生态系统中最通用和最容易引入的包之一。<br/>事实上，scikit-learn为一个(ml)门外汉的全栈开发人员实现了机器学习的民主化，这比我们所知道的要多得多。<br/>拥有一个重要的评估器和算法库，它使得快速构建NLP或机器学习模块的任务非常快速，<br/>并且对于大部分功能目的来说相当有效。</p><p id="8bd9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然有太多的文本分类示例处理有限的语料库和有限的数据类别，但下面的文章试图揭示核外学习，即无法放入工作站主存储器的训练数据，以及如何使用intrepid scikit-learn处理如此大的语料库文本分类任务。</p><p id="5bd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，让我们快速浏览一下scikit——了解它所有的语法简单性和对大型数据集进行有效文本分类的直接方法。<br/>为了便于说明，我们将采用包含药品名称、患者情况和对前者的评论的药品评论数据集。<br/>我们将通过skicit-learn实现的估计器传递合理的大样本集，并训练模型从评论中学习，以反向预测状况——这不是该数据集的最实际应用，但它适合我们目前的目的。</p><p id="cfc0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">应该注意的是，选择这个特定的数据集是因为它的高维度，此外还有正好适合我们的程序案例<br/>的语料库大小。</p><p id="98ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于特定的数据集和数据集的引用，请参见文章结尾。</p><p id="57e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在来看实际的代码；请参考github repo<a class="ae jc" href="https://github.com/kundanj/text-class-ooc-sk" rel="noopener ugc nofollow" target="_blank">https://github.com/kundanj/text-class-ooc-sk</a>获取相关代码。</p><p id="0dfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jd"> Pre-req </em> : python技巧，git repo中脚本安装请见自述。</p><p id="0a03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">大文本分类:</strong></p><p id="774c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，让我们直接使用pandas，让它做它最擅长的事情——分割CSV文件以获得我们需要的数据。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="c1e1" class="jn jo hh jj b fi jp jq l jr js">df=pd.read_csv(FILE_PATH + “/../data/drugsComTrain_raw.csv”)<br/>all_conditions = df[‘condition’]<br/>all_reviews = df[‘review’]</span></pre><p id="8606" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或许看一眼数据就能知道我们在处理什么。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="6c70" class="jn jo hh jj b fi jp jq l jr js">print(all_reviews.head(10))<br/>print(all_conditions.head(10))<br/>print(all_reviews.shape)</span></pre><p id="27fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以我们有了语料库(所有样本中的整个字典集)和作为pandas系列整齐排列的类，这形成了我们训练练习的基础。</p><p id="133d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有关类别/条件的快速主列表</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="a4b5" class="jn jo hh jj b fi jp jq l jr js">for category in all_conditions:<br/>    if category not in classes:<br/>        classes.append(category)</span></pre><p id="bae8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用这些数据进行培训。但在此之前，我们需要将数据转换成机器可读的格式。<br/>对于那些迟到的人，机器学习评估人员的工作是数字构建，而不是文本漫谈。所以我们需要将文本转换成数字，并为每个数据样本(评论)中的单词找到正确的加权表示，这将确定正确的适用类别(条件)。<br/>对于标签来说，这很容易做到</p><p id="4a47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du jt ju jv jj b">y_all = [ classes.index(x) for x in all_conditions ]</code></p><p id="ca71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，对于评论来说，它并不像一维系列或数组那样简单。<br/>因此，我们将评论数组矢量化为矩阵，即将可变长度的文本样本转换为固定长度的数字表示。此外，“矢量化矩阵”听起来比简单地说“使用字符串数组”更酷！<br/>出现了著名的单词袋模型，其中每个单词都是大小矩阵(语料库中的单词数:nw) X(样本集大小:ns)中的一个数据点。<br/>这基本上意味着每个样本由包含在样本中的词的指示来表示，这种指示被示为相应词在组合语料库词典中的代表位置。因此，大小为nw×ns的矩阵中的样本j将是包含nw个元素的向量，其中仅沿着j填充了表示来自特征集NW的对应单词和频率计数的那些数字。这个想法是让样本中各个单词的出现频率决定它的类别。<br/>这实际上听起来相当初级，可能并不总是转化为对类别的最佳猜测，例如，在一个关于技术文章样本的博客中，像“技术”和“计算机”这样的词可能会大量出现在所有文档中，认为这些词代表类别分类可能会产生误导(例如，文章是在谈论移动应用还是基因工程)。因此，我们使用TF-IDF转换器对样本进行矢量化，降低样本中所有常见单词的出现频率，削弱它们影响分类的能力。<br/>现在我们似乎有了一种可行的方法来表示每个样本中重要单词的加权数字，这些可以输入到机器学习算法中。然而，我们还有一个问题。<br/>根据我们语料库中的数据类型(885个类别中的161297个样本)和大约137102个样本(据报道有262144个最大特征)进行训练，我们正在讨论一个137102 X 262144 X 4(假设仅用整数表示单词)字节的矩阵。这是需要与大多数scikit用户熟悉的通常的CountVectorizer-TF-IDF传统进行特殊偏离的地方。<br/>进入HashVectorizer，它以简单的形式，使用低内存特性哈希将文本文档转换成scipy.sparse矩阵，该矩阵可扩展用于大型数据集。它是一个无状态的矢量器，所以不需要调用fit。然而，它有相当多的缺点，不适合IDF评分，并可能导致哈希冲突，这就是为什么我们使用大量的max功能(&gt; 2**18)。<br/>然而，文档暗示了我们可以将其转化为TF-IDF转换的可能性，因此这就是我们将要做的。</p><p id="e16d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如通常在NLP管道中提到的，在特征提取之前，可以对文本样本进行一定量的预处理，这可以包括(单词/字符)标记化，随后是停用词消除、词条化等。其中大部分已经由HashVectorizer完成(小写转换，忽略标点符号等)<br/>然而，自定义预处理(例如停用词)的效果可能是问题特定的，可以根据具体情况包含在管道中。<br/>我们有责任在此提出另一个警告——单词袋/n元语法方法忽略了文本中的位置信息，这意味着上下文相关性、语义等被忽略。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="09e4" class="jn jo hh jj b fi jp jq l jr js">    #as the name suggests, split training data<br/>    X_train, X_test, Y_train, Y_test = train_test_split(clean_corpus(all_reviews), y_all, test_size=0.15, random_state=42)<br/>    vectorizer = HashingVectorizer(ngram_range=(1,2), strip_accents='ascii', n_features=2**18)<br/>    X_train_hashed = vectorizer.transform(X_train)<br/>    tfidf_transformer=TfidfTransformer()<br/>    X_train = tfidf_transformer.fit_transform(X_train_hashed)<br/>    X_test_hashed = vectorizer.transform(X_test)<br/>    X_test = tfidf_transformer.transform(X_test_hashed)</span></pre><p id="05c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，您可以使用这个数据集附带的单独测试数据，而不是分割训练数据。<br/>上述大多数函数调用都是参数语义，除了需要快速提及的n-gram除了单个单词特征，我们还采用了双单词，例如，潜在地适应“头痛”和“慢性头痛”之间的细微差别。</p><p id="b861" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后是模型。我们使用SGD分类器，在这种情况下，它是线性SVM的优化器。我们将使用SGD作为拟合线性分类器的方法。<br/>无需深入研究模型背后的数学原理(这超出了本文的范围),线性模型意味着一种代数方程形式，其中估计的目标是加权特征的线性总和——考虑系数和截距。<br/>选择SGD是因为它在处理大量样本和特征时非常有用。它正好符合核心外学习的部分适应机制。<br/>我们将线性SVM用于参数“铰链”指定的损失函数。</p><p id="eca0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，从程序上讲，SGD对增量拟合有一个方便的适应性，我们将在下面的代码块中看到。SGD是适合于增量学习的一组估计器中的一个，也就是说，整个语料库不会一次加载到算法中。</p><p id="c83f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然在我们的例子中，大规模的语料库可能不适合单个镜头中的模型，但在我们使用partial_fit <br/>将训练集分成批次的情况下，需要增量步骤。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="9cc1" class="jn jo hh jj b fi jp jq l jr js">    epoch = 5<br/>    batchsize = 1000<br/>    model = SGDClassifier(loss="hinge", penalty="l2")<br/>    batches = int(X_train.shape[0]/batchsize) + 1<br/>    samples = X_train.shape[0]<br/>    for i in range(epoch):<br/>        for j in range(batches):<br/>            #print('in j...', j, j*batchsize, '----2is:',samples, (j+1)*batchsize )<br/>            model.partial_fit(X_train[j*batchsize:min(samples,(j+1)*batchsize)], Y_train[j*batchsize:min(samples,(j+1)*batchsize)], classes=range(len(classes)))<br/>    print ("Accuracy on testing data :", epoch, model.score(X_test, Y_test))</span></pre><p id="6937" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们得到了71%的准确率，这是一个很好的起点。如果您需要使用模型，请使用model.predict根据症状对医疗状况进行分类，或者使用下面的代码结构。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="af57" class="jn jo hh jj b fi jp jq l jr js">    test_stmt = []<br/>    test_stmt.append(input_statement)<br/>    X_testing_counts = vectorizer.transform(clean_corpus(test_stmt))<br/>    X_testing = tfidf_transformer.transform(X_testing_counts)<br/>    predicted = model.predict(X_testing)<br/>    for doc, category in zip(test_stmt, predicted):<br/>    return classes[category]</span></pre><p id="36fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">微调模型超参数和历元迭代可能会有所帮助，但是增加批量大小通常不会有助于提高准确性，特别是在SGD中。</p><p id="93b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是scikit learning对大文本分类的简明快速的介绍。编码快乐！</p><p id="3dab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jd">数据集和引用:</em></p><p id="e604" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://www.kaggle.com/jessicali9530/kuc-hackathon-winter-2018?select=drugsComTest_raw.csv" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/Jessica Li 9530/kuc-hackathon-winter-2018？select=drugsComTest_raw.csv </a></p><p id="70f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jd">数据集鸣谢:<br/>数据集最初发布在UCI机器学习知识库上。引文:费利克斯·格雷尔、苏亚·卡鲁马迪、哈根·马尔贝格和塞巴斯蒂安·萨恩塞德。2018.基于方面的跨领域和跨数据学习的药物评论情感分析。在2018年数字健康国际会议(DH '18)的会议录中。美国纽约州纽约市ACM，121–125。</em></p><div class="jw jx ez fb jy jz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ka ab dw"><div class="kb ab kc cl cj kd"><h2 class="bd hi fi z dy ke ea eb kf ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kg l"><h3 class="bd b fi z dy ke ea eb kf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kh l"><p class="bd b fp z dy ke ea eb kf ed ef dx translated">medium.com</p></div></div><div class="ki l"><div class="kj l kk kl km ki kn ko jz"/></div></div></a></div></div></div>    
</body>
</html>
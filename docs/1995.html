<html>
<head>
<title>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä¸€å¹…å›¾åƒç›¸å½“äº16x16ä¸ªå­—:å¤§è§„æ¨¡å›¾åƒè¯†åˆ«çš„å˜å½¢é‡‘åˆš</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/mlearning-ai/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale-51f3561a9f96?source=collection_archive---------0-----------------------#2022-02-20">https://medium.com/mlearning-ai/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale-51f3561a9f96?source=collection_archive---------0-----------------------#2022-02-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d8c44e78df1a991584d9700163941fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fa65_7TmyNs4xLaW_fhRbA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">ViT architecture presented in the paper</figcaption></figure><p id="080a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">è¿™æ˜¯è°·æ­Œç ”ç©¶çš„ä¸€ç¯‡è®ºæ–‡ã€‚æœ¬æ–‡çš„ä¸»è¦è§‚ç‚¹æ˜¯</p><blockquote class="jr js jt"><p id="6aab" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated">ç›´æ¥åº”ç”¨äºå›¾åƒè¡¥ä¸å¹¶åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„è½¬æ¢å™¨åœ¨å›¾åƒåˆ†ç±»æ–¹é¢éå¸¸æœ‰æ•ˆã€‚</p></blockquote><p id="4be9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">åœ¨æœ¬å¸–ä¸­ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è®¨è®ºè§†è§‰å˜å‹å™¨(ViT)æ¶æ„ä»¥åŠè®ºæ–‡ä¸­å‘è¡¨çš„ç»“æœã€‚</p><p id="03bd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">é€šè¿‡ä½¿ç”¨<a class="ae jy" href="https://github.com/souvik3333/medium_blogs/blob/main/transformers/ViT/ViT.ipynb" rel="noopener ugc nofollow" target="_blank">è¿™å°</a>ç¬”è®°æœ¬æ¥å°è¯•è¿™é‡Œä½¿ç”¨çš„å®ç°ã€‚ç‚¹å‡»<code class="du jz ka kb kc b">Open in Colab</code>ç›´æ¥åœ¨Colabä¸Šè¿è¡Œã€‚</p><h1 id="d88d" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ViTæ¶æ„ğŸƒ</h1><ul class=""><li id="489a" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated">ViTå°†å›¾åƒåˆ†å‰²æˆå›ºå®šæ•°é‡çš„é¢ç‰‡ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥åˆ›å»ºåµŒå…¥ï¼Œå¹¶å°†å®ƒä»¬é€šè¿‡æ ‡å‡†çš„transformerç¼–ç å™¨ã€‚</li><li id="1496" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">æˆ‘ä»¬å…ˆè®¨è®ºä¸€ä¸‹NLPå˜å‹å™¨æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œç„¶åå†å’ŒViTè¿›è¡Œæ¯”è¾ƒå’Œè®¨è®ºã€‚</li></ul><h2 id="a705" class="lr ke hh bd kf ls lt lu kj lv lw lx kn je ly lz kr ji ma mb kv jm mc md kz me bi translated">NLPå˜å‹å™¨ç¼–ç å™¨ğŸ¨</h2><figure class="mg mh mi mj fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/a02f7450904b6aa697f46becf091f549.png" data-original-src="https://miro.medium.com/v2/resize:fit:332/format:webp/1*q3Z092SdqVdBdZE--Xa2OQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Transformer encoder</figcaption></figure><ul class=""><li id="b6fc" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æˆ‘ä»¬æŠŠä¸€ä¸ªå¥å­ä½œä¸ºè¾“å…¥ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬æ²¡æœ‰å‘é€æ•´ä¸ªå¥å­ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€ä¸ª<code class="du jz ka kb kc b">tokenizer</code>ç»™æ¯ä¸ªå•è¯ä¸€ä¸ª<code class="du jz ka kb kc b">id</code>ã€‚ç°åœ¨ï¼Œåˆ†è¯å™¨å®é™…ä¸Šä¸å¿…åƒæŒ‰å•è¯æ‹†åˆ†é‚£æ ·ç®€å•åœ°è¿›è¡Œæ‹†åˆ†ï¼Œè€Œæ˜¯å¯ä»¥å°†å•è¯æ‹†åˆ†æˆå¤šä¸ªéƒ¨åˆ†å¹¶è¿›è¡Œèµ‹å€¼ã€‚è¿™ä¸ªè¦çœ‹åˆ†è¯å™¨æ€ä¹ˆè®­ç»ƒäº†ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç®€å•çš„è®°å·èµ‹äºˆå™¨å¯ä»¥åšå¦‚ä¸‹å·¥ä½œ</li></ul><figure class="mg mh mi mj fd ii"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="6324" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">ä½†æ˜¯å¦ä¸€ä¸ªäººæŠŠå¥å­æ‹†æˆäº†ä¸‹é¢è¿™æ ·:</p><figure class="mg mh mi mj fd ii"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="b088" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå°†æ‰€æœ‰å¯èƒ½çš„idæ˜ å°„åˆ°å‘é‡è¡¨ç¤ºçš„çŸ©é˜µã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ç¬¬äºŒä¸ªè®°å·èµ‹äºˆå™¨ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦ä¸º<code class="du jz ka kb kc b">To</code>é€‰æ‹©åµŒå…¥ï¼Œæˆ‘ä»¬å°†é€‰æ‹©ç´¢å¼•11å¤„çš„å‘é‡è¡¨ç¤ºã€‚</p><figure class="mg mh mi mj fd ii"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="a3c8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">è¿™äº›åµŒå…¥å¯ä»¥åœ¨å¼€å§‹æ—¶éšæœºåˆå§‹åŒ–ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒä¸­å­¦ä¹ ã€‚</p><h2 id="f4d7" class="lr ke hh bd kf ls lt lu kj lv lw lx kn je ly lz kr ji ma mb kv jm mc md kz me bi translated">ä½ç½®åµŒå…¥</h2><ul class=""><li id="1c10" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated">é€’å½’ç¥ç»ç½‘ç»œ(RNNs)ä»¥è¿ç»­çš„æ–¹å¼é€å­—åˆ†æå¥å­ã€‚ä½†æ˜¯å˜å‹å™¨æ¶æ„ä¸ä½¿ç”¨é€’å½’æœºåˆ¶ï¼Œè€Œæ˜¯æ”¯æŒå¤šå¤´è‡ªå…³æ³¨æœºåˆ¶ã€‚è¿™å‡å°‘äº†å˜å½¢é‡‘åˆšçš„è®­ç»ƒæ—¶é—´ï¼Œä½†æ˜¯æ¨¡å‹ä¸çŸ¥é“å•è¯çš„ä½ç½®ã€‚</li><li id="092d" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å‘è¾“å…¥åµŒå…¥æ·»åŠ äº†ä¸€æ¡é¢å¤–çš„ä¿¡æ¯(ä½ç½®ç¼–ç )ã€‚</li><li id="14da" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ç°åœ¨ä¸€ä¸ªç®€å•çš„æ–¹æ³•å°±æ˜¯ç»™ç¬¬ä¸€ä¸ªå•è¯èµ‹å€¼1ï¼Œç»™ç¬¬äºŒä¸ªå•è¯èµ‹å€¼2ï¼Œä¾æ­¤ç±»æ¨ã€‚ä½†åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªæ¯”å®ƒåœ¨è®­ç»ƒä¸­çœ‹åˆ°çš„ä»»ä½•å¥å­éƒ½é•¿çš„å¥å­ã€‚åŒæ ·ï¼Œå¯¹äºä¸€ä¸ªè¾ƒé•¿çš„å¥å­ï¼Œä¼šæœ‰è¾ƒå¤§çš„å€¼éœ€è¦æ·»åŠ ï¼Œè¿™ä¼šå ç”¨æ›´å¤šçš„å†…å­˜ã€‚</li><li id="0d65" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">æˆ‘ä»¬å¯ä»¥å–ä¸€ä¸ªèŒƒå›´ï¼Œæ¯”å¦‚ç¬¬ä¸€ä¸ªä½œå“åŠ 0ï¼Œæœ€åä¸€ä¸ªåŠ 1ï¼Œåœ¨ä¸¤è€…ä¹‹é—´æˆ‘ä»¬åˆ†å‰²èŒƒå›´[0ï¼Œ1]å¹¶å¾—åˆ°å€¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ª3ä¸ªå•è¯çš„å¥å­ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ç¬¬ä¸€ä¸ªå•è¯å–0ï¼Œå¯¹ç¬¬äºŒä¸ªå•è¯å–0.5ï¼Œå¯¹ç¬¬ä¸‰ä¸ªå•è¯å–1ï¼›å¯¹äºä¸€ä¸ª4ä¸ªå•è¯çš„å¥å­ï¼Œå®ƒå°†åˆ†åˆ«æ˜¯0ï¼Œ0.33ï¼Œ0.66ï¼Œ1ã€‚è¿™æ ·çš„é—®é¢˜æ˜¯ä½ç½®å·®Î´ä¸æ˜¯å¸¸æ•°ã€‚åœ¨ç¬¬ä¸€ä¸ªä¾‹å­ä¸­ï¼Œå®ƒæ˜¯0.5ï¼Œä½†æ˜¯åœ¨ç¬¬äºŒä¸ªä¾‹å­ä¸­ï¼Œå®ƒæ˜¯0.33ã€‚</li><li id="c13f" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ä½¿ç”¨çš„ä½ç½®ç¼–ç æ˜¯ä¸€ä¸ªdç»´å‘é‡ã€‚</li></ul><figure class="mg mh mi mj fd ii"><div class="bz dy l di"><div class="mn mo l"/></div></figure><ul class=""><li id="0b0a" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">è¿™å°±æ˜¯æ‰€æœ‰äº‹ç‰©çš„ç»“åˆ</li></ul><figure class="mg mh mi mj fd ii"><div class="bz dy l di"><div class="mn mo l"/></div></figure><ul class=""><li id="92c7" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†é€šè¿‡å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ä¼ é€’è¿™äº›å‘é‡ã€‚</li></ul><h2 id="db74" class="lr ke hh bd kf ls lt lu kj lv lw lx kn je ly lz kr ji ma mb kv jm mc md kz me bi translated">å¤šå¤´æ³¨æ„åŠ›ğŸ”¥</h2><ul class=""><li id="e5a7" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated">å¤šå¤´æ³¨æ„åŠ›æœ‰ä¸‰ä¸ªçŸ©é˜µï¼Œåˆ†åˆ«æ˜¯æŸ¥è¯¢(Q)ã€é”®(K)ã€å€¼(V)çŸ©é˜µã€‚å®ƒä»¬ä¸­çš„æ¯ä¸€ä¸ªéƒ½å…·æœ‰ä¸åµŒå…¥ç›¸åŒçš„ç»´æ•°ã€‚å› æ­¤ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæ‰€æœ‰3ä¸ªçŸ©é˜µéƒ½æ˜¯512x512</li><li id="3320" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">å¯¹äºæ¯ä¸ªä»¤ç‰ŒåµŒå…¥ï¼Œæˆ‘ä»¬å°†å…¶ä¸æ‰€æœ‰ä¸‰ä¸ªçŸ©é˜µ(Qï¼ŒKï¼ŒV)ç›¸ä¹˜ã€‚å› æ­¤ï¼Œå¯¹äºæ¯ä¸ªä»¤ç‰Œï¼Œæˆ‘ä»¬å°†æœ‰3ä¸ªé•¿åº¦ä¸º512çš„ä¸­é—´å‘é‡ã€‚</li><li id="5684" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬æœ‰<code class="du jz ka kb kc b">n </code>ä¸ªå¤´ï¼Œæˆ‘ä»¬æŠŠæ¯ä¸ªå‘é‡åˆ†æˆ<code class="du jz ka kb kc b">n</code>ä¸ªéƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰8ä¸ªå¤´ï¼Œå¯¹äºå•è¯<code class="du jz ka kb kc b">Today</code>ï¼Œæˆ‘ä»¬å°†æŠŠæ‰€æœ‰3ä¸ªä¸­é—´å‘é‡åˆ†æˆç»´æ•°ä¸º64çš„å°å‘é‡ã€‚</li><li id="97ac" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ç„¶åï¼Œæ¯ä¸ªå¤´ä»æ‰€æœ‰ä¸­é—´å‘é‡ä¸­å–å‡ºå…¶å¯¹åº”çš„æ®µã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªå¤´å°†å–å¾—æ‰€æœ‰äº”ä¸ªåµŒå…¥(å¯¹åº”äºäº”ä¸ªä»¤ç‰Œ)çš„æ‰€æœ‰ä¸‰ä¸ªä¸­é—´å‘é‡(å¯¹åº”äºæŸ¥è¯¢ã€å¯†é’¥ã€å€¼ä¹˜æ³•ç»“æœ)çš„ç¬¬ä¸€ä¸ªåˆ†è£‚(ç»´åº¦64)ã€‚ç±»ä¼¼åœ°ï¼Œç¬¬äºŒä¸ªå¤´å°†å–ç¬¬äºŒä¸ªæ®µï¼Œä¾æ­¤ç±»æ¨ã€‚</li><li id="03a5" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">åœ¨æ¯ä¸ªæ ‡é¢˜ä¸­ï¼Œæˆ‘ä»¬ç‚¹ç§¯æŸ¥è¯¢å’Œé”®çŸ©é˜µç›¸ä¹˜çš„å‘é‡ã€‚åœ¨ä¸‹å›¾ä¸­ï¼Œæˆ‘ä»¬åœ¨q1å’Œæ‰€æœ‰å…³é”®çŸ©é˜µç›¸ä¹˜çš„å‘é‡(k{i}ï¼Œi in [1ï¼Œ5])ä¹‹é—´åšç‚¹ç§¯ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å®ƒä¹˜ä»¥ç›¸åº”çš„å€¼å‘é‡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†å®ƒä»¬ç›¸åŠ ä»¥åˆ›å»ºä¸€ä¸ªç»“æœ64ç»´å‘é‡ã€‚è¿™å‘ç”Ÿåœ¨q2ã€q3ã€q4ã€q5ï¼Œæœ€åï¼Œæˆ‘ä»¬å¾—åˆ°ç»´æ•°ä¸º64çš„5ä¸ªå‘é‡ã€‚ç°åœ¨åŸºæœ¬ä¸Šæ¯ä¸ªç»“æœå‘é‡éƒ½æœ‰æ‰€æœ‰å…¶ä»–å‘é‡çš„ä¿¡æ¯ã€‚</li></ul><figure class="mg mh mi mj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/43f19d1b3b883ba9e605843162c22e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4o4wPyvUIWU8Vkt-W4-Tyg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Attention logic</figcaption></figure><ul class=""><li id="f4d1" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ç°åœ¨æˆ‘ä»¬è¿æ¥æ‰€æœ‰å¤´éƒ¨çš„ç»“æœå‘é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¿æ¥æ‰€æœ‰8ä¸ªå¤´çš„ç¬¬ä¸€ä¸ªç»“æœå‘é‡ï¼Œä»¥åˆ›å»º512 dimç¬¬ä¸€ä¸ªå‘é‡ã€‚å¯¹äºæ‰€æœ‰å…¶ä»–4ä¸ªå‘é‡ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</li><li id="f853" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">æœ€åæˆ‘ä»¬æœ‰5ä¸ªå‘é‡ï¼Œæ¯ä¸ªéƒ½æœ‰512ä¸ªç»´åº¦ã€‚</li></ul><h2 id="3ed0" class="lr ke hh bd kf ls lt lu kj lv lw lx kn je ly lz kr ji ma mb kv jm mc md kz me bi translated">æ·»åŠ &amp;è¯ºå§†â˜¯</h2><ul class=""><li id="aaa0" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated">è¿™äº›æ˜¯æ­£å¸¸çš„æ‰¹å¤„ç†è§„èŒƒåŒ–å’Œå‰©ä½™è¿æ¥ï¼Œå¦‚Resnetå—ã€‚</li></ul><h2 id="d742" class="lr ke hh bd kf ls lt lu kj lv lw lx kn je ly lz kr ji ma mb kv jm mc md kz me bi translated">å‰é¦ˆğŸ€</h2><ul class=""><li id="1ffa" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated">è¿™äº›æ˜¯ç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œåº”ç”¨äºæ¯ä¸ªæ³¨æ„åŠ›å‘é‡ã€‚</li></ul><p id="7b65" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">è¿™å°±æ˜¯ä¸€ä¸ªç®€å•çš„å˜å‹å™¨ç¼–ç å™¨çš„å·¥ä½œåŸç†ã€‚æ¥ä¸‹æ¥è®©æˆ‘ä»¬çœ‹çœ‹ViTæ¶æ„ã€‚åŒæ—¶æˆ‘ä»¬ä¹Ÿä¼šçœ‹åˆ°å¦‚ä½•å®ç°ã€‚</p><h2 id="a280" class="lr ke hh bd kf ls lt lu kj lv lw lx kn je ly lz kr ji ma mb kv jm mc md kz me bi translated">ViTç¼–ç å™¨æ¶æ„</h2><p id="a908" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je mq jg jh ji mr jk jl jm ms jo jp jq ha bi translated"><strong class="iv hi">åµŒå…¥è¡¥ä¸çš„â˜‘ï¸ </strong></p><ul class=""><li id="bf31" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ä¸ºäº†å¤„ç†2Då›¾åƒï¼Œå›¾åƒè¢«åˆ†æˆå‡ ä¸ªå°å—ã€‚æˆ‘ä»¬å°†2Dé¢ç‰‡å±•å¹³æˆ1DçŸ¢é‡ã€‚</li><li id="d3a3" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›å‘é‡åµŒå…¥åˆ°æ¨¡å‹ç»´åº¦ç©ºé—´ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹å°†æ¯ä¸ªå‘é‡è½¬æ¢ä¸º768ç»´å‘é‡ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="dd32" class="lr ke hh kc b fi mx my l mz na">import torch<br/>import torch.nn as nn<br/>in_chans = 3 #RGB<br/>embed_dim = 768 # vector dimension in model space<br/>patch_size = 16 # each image patch size 16*16<br/>proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size) # this will create the patch in image<br/>img = torch.randn(1, 3, 224,224) # dummy image<br/>x = proj(img).flatten(2).transpose(1, 2) # BCHW -&gt; BNC<br/>print(x.shape)</span></pre><ul class=""><li id="d0d5" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬æ‹æ‘„äº†å¤§å°ä¸º224*224çš„å›¾åƒï¼Œå¹¶å‡è®¾æ¯ä¸ªé¢ç‰‡çš„å¤§å°ä¸º16x16ã€‚</li><li id="00a2" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ç°åœ¨è¿™å°†å¯¼è‡´æ€»å…±(224/16<em class="ju">* 224/16)= 14 *</em>14 = 196ä¸ªå‘é‡ã€‚</li><li id="a31d" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">è¿™äº›å‘é‡çš„å¤§å°éƒ½æ˜¯16*16 = 256ã€‚ä½†æ˜¯ï¼Œå› ä¸ºæˆ‘ä»¬å¿…é¡»å°†å…¶è½¬æ¢ä¸ºæ¨¡å‹ç»´åº¦ï¼Œå³768ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨å·ç§¯ä¸­ä½¿ç”¨768ä½œä¸ºè¾“å‡ºé€šé“ã€‚æœ€åï¼Œæˆ‘ä»¬å°†å®ƒå±•å¹³ä¸ºBNCï¼Œå…¶ä¸­B=æ‰¹æ¬¡ï¼ŒN=ç”Ÿæˆçš„é¢ç‰‡ï¼ŒC =æ¨¡å‹ç©ºé—´ä¸­çš„å‘é‡ç»´åº¦ã€‚</li></ul><p id="1743" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">ç±»åµŒå…¥ğŸ†•</strong></p><ul class=""><li id="0deb" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ViTå°†ä¸€ä¸ªå¯å­¦ä¹ çš„åµŒå…¥é™„åŠ åˆ°åµŒå…¥è¡¥ä¸åºåˆ—ä¸­ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="fd26" class="lr ke hh kc b fi mx my l mz na">cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) # create class embeddings without batch<br/>cls_token = cls_token.expand(x.shape[0], -1, -1) # add batch<br/>x = torch.cat((cls_token, x), dim=1) # append class token with linear proj embeddings<br/>x.shape # 196 -&gt; 197</span></pre><p id="46fe" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">ä½ç½®åµŒå…¥â˜‘ï¸ </strong></p><ul class=""><li id="dd5e" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç»´æ•°ä¸º(num _ patches+1)<em class="ju">* embed _ dim(197 *</em>768)çŸ©é˜µã€‚è¿™äº›å€¼æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ åˆ°çš„ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="9f05" class="lr ke hh kc b fi mx my l mz na">num_patches = 14*14<br/>pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim)) # +1 for class token<br/>x = x + pos_embed # add position encoding<br/>x.shape</span></pre><p id="9e2d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">è¡—åŒºâ˜‘ï¸ </strong></p><ul class=""><li id="8e6b" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">åŸºäºè¯¥æ¨¡å‹ï¼Œæˆ‘ä»¬æœ‰<code class="du jz ka kb kc b">n</code>ä¸ªå—ã€‚</li><li id="94b4" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">æ¯ä¸ªåŒºå—éƒ½ä¸€æ ·ã€‚æ¯ä¸€å±‚åŒ…æ‹¬ä¸€ä¸ªæ³¨æ„å±‚å’Œä¸€ä¸ªMLPå±‚ã€‚</li></ul><p id="cf0b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">å…³æ³¨å±‚â˜‘ï¸ </strong></p><ul class=""><li id="d4c2" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ä¸ä¹‹å‰è§£é‡Šçš„NLPæ³¨æ„åŠ›ç›¸åŒã€‚</li><li id="8191" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">è®©æˆ‘ä»¬åˆ›å»ºä¸­é—´å‘é‡ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="6bbe" class="lr ke hh kc b fi mx my l mz na"># Transformation from source vector to query vector<br/>fc_q = nn.Linear(embed_dim, embed_dim)<br/># Transformation from source vector to key vector<br/>fc_k = nn.Linear(embed_dim, embed_dim)<br/># Transformation from source vector to value vector<br/>fc_v = nn.Linear(embed_dim, embed_dim)</span><span id="936b" class="lr ke hh kc b fi nb my l mz na">Q = fc_q(x)<br/>K = fc_k(x)<br/>V = fc_v(x)</span><span id="6632" class="lr ke hh kc b fi nb my l mz na">print(Q.shape, K.shape, V.shape)</span></pre><ul class=""><li id="743c" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">åˆ†å‰²ä¸­é—´å‘é‡ä»¥åœ¨æ¯ä¸ªå¤´ä¸­å¤„ç†ä¸€ä¸ªé›¶ä»¶ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="dc4f" class="lr ke hh kc b fi mx my l mz na">num_heads = 8<br/>batch_size = 1<br/>Q = Q.view(batch_size, -1, num_heads, embed_dim//num_heads).permute(0, 2, 1, 3) # split the Q matrix for 8 head<br/>K = K.view(batch_size, -1, num_heads, embed_dim//num_heads).permute(0, 2, 1, 3) # split the K matrix for 8 head<br/>V = V.view(batch_size, -1, num_heads, embed_dim//num_heads).permute(0, 2, 1, 3) # split the V matrix for 8 head<br/>print(Q.shape, K.shape, V.shape) # batch_size, num_head, num_patch+1, feature_vec dim per head</span></pre><ul class=""><li id="246f" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æ³¨æ„åŠ›çŸ©é˜µä¹˜æ³•ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="0ee2" class="lr ke hh kc b fi mx my l mz na">score = torch.matmul(Q, K.permute(0, 1, 3, 2)) # Q*k<br/>score = torch.softmax(score, dim=-1)<br/>score = torch.matmul(score, V) # normally we apply dropout layer before this<br/>score.shape # batch_size, num_head, num_patches+1, feature_vector_per_head (embed_dim/num_head)</span></pre><ul class=""><li id="eeb2" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">é‡å¡‘ç»“æœ</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="339f" class="lr ke hh kc b fi mx my l mz na">score = score.permute(0, 2, 1, 3).contiguous()<br/>score.shape # batch_size, num_patches+1, num_head, feature_vector_per_head (embed_dim/num_head)</span></pre><ul class=""><li id="c480" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">å°†å‘é‡åˆå¹¶å›å®ƒä»¬çš„åŸå§‹å½¢çŠ¶</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="58fe" class="lr ke hh kc b fi mx my l mz na">score = score.view(batch_size, -1, embed_dim) # merge the vectors back to original shape<br/>score.shape # batch_size, num_patches+1, embed_dim</span></pre><p id="a3f7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> MLPè´Ÿè´£äººâ˜‘ï¸ </strong></p><ul class=""><li id="688f" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æ­£å¸¸å¤šå±‚æ„ŸçŸ¥å™¨ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="7247" class="lr ke hh kc b fi mx my l mz na">act_layer=nn.GELU # activation function<br/>in_features = embed_dim <br/>hidden_features = embed_dim * 4<br/>out_features = in_features<br/>fc1 = nn.Linear(in_features, hidden_features)<br/>act = act_layer()<br/>drop1 = nn.Dropout(0.5)<br/>fc2 = nn.Linear(hidden_features, out_features)<br/>drop2 = nn.Dropout(0.5)</span></pre><ul class=""><li id="ade8" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ä»MLPå›¾å±‚ä¸­è·å–ç»“æœ</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="760a" class="lr ke hh kc b fi mx my l mz na">x = fc1(score)<br/>x = act(x)<br/>x = drop1(x)<br/>x = fc2(x)<br/>x = drop2(x)<br/>x.shape</span></pre><ul class=""><li id="22a1" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æ‹¿å‡º<code class="du jz ka kb kc b">cls</code>ä»¤ç‰Œç‰¹æ€§ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="81fd" class="lr ke hh kc b fi mx my l mz na">cls = x[:,0]</span></pre><p id="6ae7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">é€‰ç²‰æœºæœºå¤´ğŸ†•</strong></p><ul class=""><li id="55b4" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">åˆ›å»ºä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨å¤´ï¼Œå¹¶ä¼ é€’ç±»ä»¤ç‰Œç‰¹å¾æ¥è·å¾—é¢„æµ‹ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="24af" class="lr ke hh kc b fi mx my l mz na">num_classes = 10 # assume 10 class classification<br/>head = nn.Linear(embed_dim, num_classes) <br/>pred = head(cls)<br/>pred</span></pre><h1 id="b837" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ç»“æœå‘è¡¨åœ¨è®ºæ–‡ä¸­ğŸ“ˆ</h1><blockquote class="jr js jt"><p id="4d58" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated">å½“åœ¨æ²¡æœ‰å¼ºæ­£åˆ™åŒ–çš„ä¸­å‹æ•°æ®é›†(å¦‚ImageNet)ä¸Šè®­ç»ƒæ—¶ï¼Œè¿™äº›æ¨¡å‹äº§ç”Ÿçš„é€‚åº¦ç²¾åº¦æ¯”å¯æ¯”å¤§å°çš„ResNetsä½å‡ ä¸ªç™¾åˆ†ç‚¹ã€‚</p><p id="8d93" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated">å˜å‹å™¨ç¼ºä¹CNNå›ºæœ‰çš„ä¸€äº›å½’çº³åå·®ï¼Œå¦‚ç¿»è¯‘ç­‰å˜å’Œå±€éƒ¨æ€§ï¼Œå› æ­¤åœ¨æ•°æ®é‡ä¸è¶³çš„æƒ…å†µä¸‹è®­ç»ƒæ—¶ä¸èƒ½å¾ˆå¥½åœ°æ¦‚æ‹¬ã€‚</p><p id="381a" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated">ä½†æ˜¯ï¼Œå¦‚æœæ¨¡å‹æ˜¯åœ¨æ›´å¤§çš„æ•°æ®é›†(14M-300Må›¾åƒ)ä¸Šè®­ç»ƒçš„ï¼Œæƒ…å†µå°±ä¸åŒäº†ã€‚æˆ‘ä»¬å‘ç°å¤§è§„æ¨¡è®­ç»ƒèƒœè¿‡å½’çº³åå·®ã€‚</p></blockquote><ul class=""><li id="a3ff" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ä½œè€…æåˆ°ï¼Œå¯¹äºè¾ƒå°çš„é¢„è®­ç»ƒæ•°æ®é›†(ImageNet ), ViT-Largeæ¨¡å‹çš„æ€§èƒ½ä½äºViT-Baseæ¨¡å‹ã€‚å¯¹äºå¤§å‹æ•°æ®é›†(JFT-300ç±³)ï¼ŒViT-å¤§å‹æ¨¡å‹æ•ˆæœå¾ˆå¥½ã€‚</li><li id="abad" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">åœ¨JFT-300Mæ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„Vision Transformeræ¨¡å‹åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½ä¼˜äºåŸºäºResNetçš„åŸºçº¿ï¼Œè€Œé¢„è®­ç»ƒæ‰€éœ€çš„è®¡ç®—èµ„æºå´å°‘å¾—å¤šã€‚</li><li id="e6d3" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated">ä¸‹è¡¨æ˜¾ç¤ºäº†ç”¨JFT-300Mæ•°æ®é›†å’ŒImageNet-21kæ•°æ®é›†é¢„å¤„ç†çš„ViTçš„ç»“æœã€‚è¿™äº›åˆ—æ˜¾ç¤ºäº†ç”¨ä¸åŒæ•°æ®é›†é¢„å¤„ç†çš„å‡ ä¸ªæ¨¡å‹ã€‚è¿™äº›è¡Œæ˜¯ä¸‹æ¸¸ä»»åŠ¡ã€‚</li></ul><figure class="mg mh mi mj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nc"><img src="../Images/2f153cd0efd8146a46558ae4b786e142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaRA_RwNxD4i8uOAg-MfWg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Table 2 from the paper</figcaption></figure><h1 id="92fa" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ç”¨PyTorché—ªç”µå’Œtimmè®­ç»ƒä¸€ä¸ªç®€å•çš„ViTğŸ†</h1><ul class=""><li id="6b6b" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated">è¿™é‡Œè®©æˆ‘ä»¬ä½¿ç”¨<a class="ae jy" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>å’Œ<a class="ae jy" href="https://github.com/rwightman/pytorch-image-models" rel="noopener ugc nofollow" target="_blank"> timm </a>è®­ç»ƒä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="ef75" class="lr ke hh kc b fi mx my l mz na">import timm<br/>import torch<br/>import pytorch_lightning as pl<br/>import torchvision<br/>import torchvision.transforms as transforms<br/>from pytorch_lightning import Trainer, seed_everything<br/>from pytorch_lightning.callbacks import ModelCheckpoint<br/>import torchmetrics</span><span id="4c84" class="lr ke hh kc b fi nb my l mz na">seed_everything(42, workers=True)</span></pre><ul class=""><li id="0845" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€å•çš„lightningæ¨¡å‹ç±»ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="cbf4" class="lr ke hh kc b fi mx my l mz na">class Model(pl.LightningModule):<br/>    """<br/>    Lightning model<br/>    """<br/>    def __init__(self, model_name, num_classes, lr = 0.001, max_iter=20):<br/>        super().__init__()<br/>        self.model = timm.create_model(model_name=model_name, pretrained=True, num_classes=num_classes)<br/>        self.metric = torchmetrics.Accuracy()<br/>        self.loss = torch.nn.CrossEntropyLoss()<br/>        self.lr = lr<br/>        self.max_iter = max_iter<br/>        <br/>    def forward(self, x):<br/>        return self.model(x)</span><span id="e1a3" class="lr ke hh kc b fi nb my l mz na">    def shared_step(self, batch, batch_idx):<br/>        x, y = batch<br/>        logits = self(x)<br/>        loss = self.loss(logits, y)<br/>        preds = torch.argmax(logits, dim=1)<br/>        self.metric(preds, y)<br/>        <br/>        return loss<br/>    <br/>    def training_step(self, batch, batch_idx):<br/>        loss = self.shared_step(batch, batch_idx)<br/>        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)<br/>        self.log('train_acc', self.metric, on_epoch=True, logger=True, prog_bar=True)<br/>        <br/>        return loss<br/>    <br/>    def validation_step(self, batch, batch_idx):<br/>        loss = self.shared_step(batch, batch_idx)<br/>        self.log('val_loss', loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)<br/>        self.log('val_acc', self.metric, on_epoch=True, logger=True, prog_bar=True)<br/>        <br/>        return loss<br/>    <br/>    def configure_optimizers(self):<br/>        optim = torch.optim.Adam(self.model.parameters(), lr=self.lr)<br/>        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optim, T_max=self.max_iter)<br/>        <br/>        return [optim], [scheduler]</span></pre><ul class=""><li id="6166" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å®šä¹‰è½¬æ¢å¹¶ä¸‹è½½å’ŒåŠ è½½CIFAR10æ•°æ®é›†ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="4c41" class="lr ke hh kc b fi mx my l mz na">transform = transforms.Compose(<br/>    [transforms.Resize(224),<br/>     transforms.ToTensor(),<br/>     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><span id="88bc" class="lr ke hh kc b fi nb my l mz na">batch_size = 128</span><span id="345f" class="lr ke hh kc b fi nb my l mz na">trainset = torchvision.datasets.CIFAR10(root='./data', train=True,<br/>                                        download=True, transform=transform)<br/>trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,<br/>                                          shuffle=True, num_workers=8)</span><span id="2dd9" class="lr ke hh kc b fi nb my l mz na">testset = torchvision.datasets.CIFAR10(root='./data', train=False,<br/>                                       download=True, transform=transform)<br/>testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,<br/>                                         shuffle=False, num_workers=8)</span><span id="53d0" class="lr ke hh kc b fi nb my l mz na">classes = ('plane', 'car', 'bird', 'cat',<br/>           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')</span></pre><ul class=""><li id="2293" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">ç°åœ¨æˆ‘ä»¬å°†åˆå§‹åŒ–<code class="du jz ka kb kc b">Model</code>ç±»ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ViTçš„ä¸€ä¸ªå˜ä½“ï¼Œå®ƒæ‹æ‘„å¤§å°ä¸º224*224çš„å›¾åƒï¼Œé¢ç‰‡å¤§å°ä¸º16ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="dbbd" class="lr ke hh kc b fi mx my l mz na">model = Model(model_name="vit_tiny_patch16_224", num_classes=len(classes), lr = 0.001, max_iter=10)</span></pre><ul class=""><li id="24da" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ£€æŸ¥ç‚¹å›è°ƒæ¥ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹ã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="4d57" class="lr ke hh kc b fi mx my l mz na">checkpoint_callback = ModelCheckpoint(<br/>    monitor='val_loss',<br/>    dirpath='./checkpoints',<br/>    filename='vit_tpytorch_lightning6_224-cifar10-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}'<br/>)</span></pre><ul class=""><li id="d8a4" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">å¿«å¥½äº†ã€‚è®©æˆ‘ä»¬åˆ›å»ºæ•™ç»ƒã€‚</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="abb5" class="lr ke hh kc b fi mx my l mz na">trainer = Trainer(<br/>    deterministic=True, <br/>    logger=False, <br/>    callbacks=[checkpoint_callback], <br/>    gpus=[0], # change it based on gpu or cpu availability<br/>    max_epochs=10, <br/>    stochastic_weight_avg=True)</span></pre><ul class=""><li id="8db1" class="lb lc hh iv b iw ix ja jb je mk ji ml jm mm jq li lj lk ll bi translated">æœ€åï¼Œè®©æˆ‘ä»¬è®­ç»ƒæ¨¡å‹ğŸ˜ƒ</li></ul><pre class="mg mh mi mj fd mt kc mu mv aw mw bi"><span id="9492" class="lr ke hh kc b fi mx my l mz na">trainer.fit(model=model, train_dataloaders=trainloader, val_dataloaders=testloader)</span></pre><h1 id="5aad" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ç›¸å…³èµ„æº</h1><ul class=""><li id="9f73" class="lb lc hh iv b iw ld ja le je lf ji lg jm lh jq li lj lk ll bi translated"><a class="ae jy" href="https://github.com/google-research/vision_transformer" rel="noopener ugc nofollow" target="_blank">å®˜æ–¹ä»£å·</a></li><li id="0193" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated"><a class="ae jy" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">è®ºæ–‡</a></li><li id="e41e" class="lb lc hh iv b iw lm ja ln je lo ji lp jm lq jq li lj lk ll bi translated"><a class="ae jy" href="https://github.com/souvik3333/medium_blogs/blob/main/transformers/ViT/ViT.ipynb" rel="noopener ugc nofollow" target="_blank">ä»£ç ç¬”è®°æœ¬</a></li></ul><p id="6896" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">ç‰¹åˆ«æ„Ÿè°¢<a class="nd ne ge" href="https://medium.com/u/bea753eb5d92?source=post_page-----51f3561a9f96--------------------------------" rel="noopener" target="_blank"> Prakash Jay </a>æŒ‡å¯¼æˆ‘å®Œæˆè¿™ä¸ªé¡¹ç›®ã€‚</p><div class="nf ng ez fb nh ni"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">Mlearning.aiæäº¤å»ºè®®</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">å¦‚ä½•æˆä¸ºMlearning.aiä¸Šçš„ä½œå®¶</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw in ni"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Emotion Detector using Keras â€” with source codeâ€” Easiest Way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä½¿ç”¨Kerasçš„æƒ…ç»ªæ£€æµ‹å™¨â€”â€”å¸¦æºä»£ç â€”â€”æœ€ç®€å•çš„æ–¹æ³•</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/mlearning-ai/emotion-detector-using-keras-with-source-code-easiest-way-easy-implementation-6f62ad9e2528?source=collection_archive---------5-----------------------#2022-01-03">https://medium.com/mlearning-ai/emotion-detector-using-keras-with-source-code-easiest-way-easy-implementation-6f62ad9e2528?source=collection_archive---------5-----------------------#2022-01-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="612d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ‰€ä»¥åœ¨ä»Šå¤©çš„åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œåœ¨Kerasä¸­æ„å»ºä¸€ä¸ªæƒ…ç»ªæ£€æµ‹å™¨æ¨¡å‹ã€‚è¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„é¡¹ç›®ä¹‹ä¸€ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘å¾ˆå…´å¥‹å¼€å§‹å®ƒï¼Œæ‰€ä»¥æ²¡æœ‰ä»»ä½•è¿›ä¸€æ­¥çš„åŸå› ã€‚</p><p id="9c5e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">åœ¨è¿™é‡Œé˜…è¯»å¸¦æºä»£ç çš„æ•´ç¯‡æ–‡ç« â€”</strong><a class="ae jc" href="https://machinelearningprojects.net/emotion-detector-using-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning projects . net/emotion-detector-using-keras/</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/e0adc9f2521551c52d1eb5703fafcf26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*kcO2Odho5azQstm0Gfkjvg.gif"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Emotion detector</figcaption></figure><h1 id="f7ad" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">è®©æˆ‘ä»¬å¼€å§‹å§â€¦</h1><h2 id="f95c" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤1-å¯¼å…¥æƒ…æ„Ÿæ£€æµ‹å™¨æ‰€éœ€çš„åº“ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="0ce1" class="kn jq hh lc b fi lg lh l li lj">from keras.preprocessing.image import ImageDataGenerator<br/>from keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,BatchNormalization,Flatten<br/>from keras.models import Sequential<br/>from keras.optimizers import rmsprop_v2<br/>from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint<br/>from keras.models import load_model<br/>import cv2<br/>from PIL import Image<br/>import numpy as np<br/>import pandas as pd<br/>import os<br/>from keras.utils.np_utils import to_categorical<br/>import seaborn as sns</span></pre><h2 id="5a88" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤2-è¯»å–æ‰€æœ‰å›¾åƒï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨æ•°æ®å¸§ä¸­ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="811e" class="kn jq hh lc b fi lg lh l li lj">int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}<br/>emotions2int = {'Angry':0,'Fear':1,'Happy':2,'Neutral':3,'Sad':4,'Surprise':5}<br/><br/>dic = {'images':[], 'labels':[], 'purpose':[]}<br/>    <br/>for d in os.listdir('fer2013/'):<br/>    print(d)<br/>    for emotion in os.listdir(f'fer2013/{d}'):<br/>        print(emotion)<br/>        for i in os.listdir(f'fer2013/{d}/{emotion}'):<br/>            img = cv2.imread(f'fer2013/{d}/{emotion}/{i}',0)<br/>            img = img.reshape(48,48,1)<br/>            <br/>            dic['images'].append(img)<br/>            dic['labels'].append(emotion)<br/>            <br/>            if d=='train':<br/>                dic['purpose'].append('T')<br/>            else:<br/>                dic['purpose'].append('V')<br/><br/>df = pd.DataFrame(dic)<br/>df.head()</span></pre><ul class=""><li id="e2b9" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªæ˜¯è¯»å–æˆ‘ä»¬çš„æ•°æ®ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ä¸€ä¸ªç†ŠçŒ«æ•°æ®å¸§ä¸­ã€‚</li><li id="e9bb" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">å›¾åƒåŒ…å«å½¢çŠ¶ä¸º48X48X1çš„å›¾åƒã€‚</li><li id="bbc5" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">æ ‡ç­¾æè¿°äº†å›¾åƒçš„æƒ…æ„Ÿã€‚</li><li id="fa59" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">ç›®çš„æœ‰ä¸¤ä¸ªå€¼Tå’ŒVï¼ŒTç”¨äºè®­ç»ƒï¼ŒVç”¨äºéªŒè¯ã€‚</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/89658fbca1a42f7ee9747a31003d9c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/0*xTk1uK11xD7g_NlU.png"/></div></figure><h2 id="24dc" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤3 â€”æå–è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="02b8" class="kn jq hh lc b fi lg lh l li lj">train_data = df[df['purpose']=='T']<br/>val_data = df[df['purpose']=='V']</span></pre><ul class=""><li id="c117" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">åˆ›å»º2ä¸ªä¸åŒçš„æ•°æ®æ¡†ã€‚</li><li id="564f" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">ç¬¬ä¸€æ¬¡ç”¨äºè®­ç»ƒï¼Œç¬¬äºŒæ¬¡ç”¨äºéªŒè¯ã€‚</li></ul><p id="a267" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ£€æŸ¥è´Ÿè´£äººçš„åŸ¹è®­æ•°æ®ã€‚</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="d501" class="kn jq hh lc b fi lg lh l li lj">train_data.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/d24e03a59afce87646db07c63be3d11c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/0*-EZ6C_VV1Ox2CSX1.png"/></div></figure><p id="1dcf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ£€æŸ¥éªŒè¯æ•°æ®çš„æ ‡é¢˜ã€‚</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="4d36" class="kn jq hh lc b fi lg lh l li lj">val_data.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/94c6f44d2f161760e6d0df9d28bc116a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*B5lp9h_mYrMQIdOS.png"/></div></figure><h2 id="0a56" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤4-æ£€æŸ¥è®­ç»ƒæ•°æ®çš„æ ‡ç­¾åˆ—ä¸­çš„å€¼ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="2eec" class="kn jq hh lc b fi lg lh l li lj">train_data[â€˜labelsâ€™].value_counts()</span></pre><ul class=""><li id="6914" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">æ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹å›¾ä¸­çœ‹åˆ°çš„ï¼Œæ ‡ç­¾åœ¨è®­ç»ƒæ•°æ®ä¸­éå¸¸ä¸å¹³è¡¡ï¼Œå› æ­¤æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€æ­¥ä¸­å¹³è¡¡å®ƒä»¬ã€‚</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/61d4c02d262b78a02c11d98dd6e84897.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*lMARebSSSf0ySsEk.png"/></div></figure><h2 id="de48" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤5â€”â€”è·å–æ‰€æœ‰ç±»çš„ç›¸åŒå®ä¾‹ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="ca51" class="kn jq hh lc b fi lg lh l li lj">happy_df = train_data[train_data['labels']=='Happy'].sample(n=3171)<br/>neutral_df = train_data[train_data['labels']=='Neutral'].sample(n=3171)<br/>sad_df = train_data[train_data['labels']=='Sad'].sample(n=3171)<br/>fear_df = train_data[train_data['labels']=='Fear'].sample(n=3171)<br/>angry_df = train_data[train_data['labels']=='Angry'].sample(n=3171)<br/>surprise_df = train_data[train_data['labels']=='Surprise'].sample(n=3171)<br/><br/>train_data = pd.concat([happy_df,neutral_df,sad_df,fear_df,angry_df,surprise_df])<br/><br/>train_data = train_data.sample(frac=1)<br/>train_data.reset_index(inplace=True)<br/>train_data.drop('index',inplace=True,axis=1)<br/><br/>train_data.head()</span></pre><ul class=""><li id="4dad" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰å–äº†3171ä¸ªæ¯ç§æƒ…æ„Ÿå¹¿å‘Šçš„å®ä¾‹ï¼Œå¹¶ä¸å®ƒä»¬è”ç³»èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªæœ€ç»ˆçš„æ•°æ®æ¡†æ¶ã€‚</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/4d1b0dfc5242fa669f39ea0beb715f4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/0*g1wLDVSPAe2ChApX.png"/></div></figure><h2 id="1b40" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤6-å†æ¬¡æ£€æŸ¥åˆ—è½¦æ•°æ®æ ‡ç­¾åˆ—ä¸­çš„å€¼ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="4ee1" class="kn jq hh lc b fi lg lh l li lj">train_data[â€˜labelsâ€™].value_counts()</span></pre><ul class=""><li id="15b7" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">ç°åœ¨å†æ¬¡æ£€æŸ¥è®¡æ•°ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„ç±»éƒ½æ˜¯å¹³è¡¡çš„ã€‚</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/dc78037e8dd2bc477edb6e09308af112.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/0*MrGXWcNqo0M9mc_t.png"/></div></figure><p id="79ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç»˜åˆ¶åˆ—ã€‚</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="5bbf" class="kn jq hh lc b fi lg lh l li lj">sns.countplot(train_data[â€˜labelsâ€™])</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/c707d4a3ae09a644590511a011ea0aa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/0*ZTe57tI0OVLso_-q.png"/></div></figure><h2 id="086c" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤7-å£°æ˜ä¸€äº›å¸¸é‡ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="5571" class="kn jq hh lc b fi lg lh l li lj">batch_size= 32<br/>classes = 6<br/>rows,columns=48,48</span></pre><h2 id="4998" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">ç¬¬8æ­¥â€”â€”ä»¥æ­£ç¡®çš„å½¢å¼è·å–æƒ…ç»ªæ£€æµ‹å™¨æ¨¡å‹çš„æ•°æ®ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="5f4b" class="kn jq hh lc b fi lg lh l li lj">train_labels = list(train_data['labels'].replace(emotions2int))<br/>train_labels = to_categorical(train_labels)<br/><br/>val_labels = list(val_data['labels'].replace(emotions2int))<br/>val_labels = to_categorical(val_labels)<br/><br/>train_data = list(train_data['images'])<br/>train_data = np.array(train_data)<br/><br/>val_data = list(val_data['images'])<br/>val_data = np.array(val_data)</span></pre><ul class=""><li id="2671" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">ç¬¬1â€“2è¡Œâ€”å°†æƒ…ç»ªè½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦‚æ„¤æ€’è½¬æ¢ä¸º0ï¼Œææƒ§è½¬æ¢ä¸º1ï¼Œç­‰ç­‰ï¼Œç„¶åä½¿ç”¨to _ categoricalå°†è¿™äº›æ•°å­—è½¬æ¢ä¸ºone-hotç¼–ç ã€‚è¿™æ˜¯ç”¨äºè®­ç»ƒæ•°æ®çš„ã€‚</li><li id="64cf" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">ç¬¬4â€“5è¡Œâ€”å¯¹éªŒè¯æ•°æ®æ‰§è¡Œä¸ä¸Šè¿°ç›¸åŒçš„æ“ä½œã€‚</li><li id="ebd2" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">ç¬¬7â€“8è¡Œâ€”å‡ºäºè®­ç»ƒç›®çš„ï¼Œå°†å›¾åƒåˆ—è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç„¶åè½¬æ¢ä¸ºNumPyæ•°ç»„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸ä¼šå°†dataframeåˆ—ç”¨äºè®­ç»ƒç›®çš„ï¼Œå› æ­¤æˆ‘ä»¬å°†å®ƒä»¬è½¬æ¢ä¸ºæ•°ç»„ã€‚</li><li id="b743" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">ç¬¬10â€“11è¡Œâ€”å¯¹éªŒè¯æ•°æ®æ‰§è¡Œä¸ä¸Šè¿°ç›¸åŒçš„æ“ä½œã€‚</li></ul><p id="eee3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ£€æŸ¥è®­ç»ƒæ•°æ®å½¢çŠ¶ã€‚</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="5a65" class="kn jq hh lc b fi lg lh l li lj">train_data.shape</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mf"><img src="../Images/2c59989756c53ec10e464012c95a37ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/0*2sN78FDP_3V4LNvI.png"/></div></figure><p id="987e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ£€æŸ¥éªŒè¯æ•°æ®å½¢çŠ¶ã€‚</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="22b5" class="kn jq hh lc b fi lg lh l li lj">val_data.shape</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/381322fbe963bb596ad2ab208bc9e872.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/0*vuqLA5029YKCqfA_.png"/></div></figure><h2 id="0b8d" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤9â€”â€”åˆ›å»ºæƒ…ç»ªæ£€æµ‹å™¨æ¨¡å‹ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="1e3c" class="kn jq hh lc b fi lg lh l li lj">model = Sequential()<br/><br/># First Block<br/>model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/>model.add(Dropout(0.2))<br/><br/># Second Block<br/>model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/>model.add(Dropout(0.2))<br/><br/># Third Block<br/>model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/>model.add(Dropout(0.2))<br/><br/># Fourth Block<br/>model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))<br/>model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/>model.add(Dropout(0.2))<br/><br/># Fifth Block<br/>model.add(Flatten())<br/>model.add(Dense(256,activation='elu',kernel_initializer='he_normal'))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.5))<br/><br/># Sixth Block<br/>model.add(Dense(128,activation='elu',kernel_initializer='he_normal'))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.5))<br/><br/># Seventh Block<br/>model.add(Dense(64,activation='elu',kernel_initializer='he_normal'))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.5))<br/><br/># Eighth Block<br/>model.add(Dense(classes,activation='softmax',kernel_initializer='he_normal'))<br/><br/>print(model.summary())</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/320567450889e836b6f83cce61c363fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*XtwFF8bWxPfVE3Le.png"/></div></figure><ul class=""><li id="d0a0" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">åˆ›å»ºæˆ‘ä»¬çš„å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚</li><li id="d76f" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">åˆ›å»º4å—<a class="ae jc" href="https://keras.io/api/layers/convolution_layers/convolution2d/" rel="noopener ugc nofollow" target="_blank">ã€Conv2Dã€‘</a>â€”<a class="ae jc" href="https://keras.io/api/layers/normalization_layers/batch_normalization/" rel="noopener ugc nofollow" target="_blank">â€”</a>â€”<a class="ae jc" href="https://keras.io/api/layers/convolution_layers/convolution2d/" rel="noopener ugc nofollow" target="_blank">Conv2D</a>â€”<a class="ae jc" href="https://keras.io/api/layers/normalization_layers/batch_normalization/" rel="noopener ugc nofollow" target="_blank">batch normalization</a>â€”<a class="ae jc" href="https://keras.io/api/layers/pooling_layers/max_pooling2d/" rel="noopener ugc nofollow" target="_blank">maxpooli2d</a>â€”<a class="ae jc" href="https://keras.io/api/layers/regularization_layers/dropout/" rel="noopener ugc nofollow" target="_blank">Dropout</a>å±‚ã€‚</li><li id="b837" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">åˆ›å»º3å—<a class="ae jc" href="https://keras.io/api/layers/core_layers/dense/" rel="noopener ugc nofollow" target="_blank">å¯†é›†</a>â€”â€”æ‰¹é‡â€”â€”å‰”é™¤å±‚ï¼Œæœ€ç»ˆåˆ›å»º1ä¸ªå…·æœ‰6ä¸ªç¥ç»å…ƒ/èŠ‚ç‚¹çš„å¯†é›†å±‚ã€‚</li></ul><h2 id="42d7" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤10-å£°æ˜å›è°ƒã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="bd04" class="kn jq hh lc b fi lg lh l li lj">checkpoint = ModelCheckpoint('model\\6_class_emotion_detector_V2.h5',<br/>                             save_best_only=True,<br/>                             mode='min',<br/>                             monitor='val_loss',<br/>                             verbose=1)<br/><br/>earlystopping = EarlyStopping(patience=10,<br/>                             verbose=1,<br/>                             min_delta=0,<br/>                             monitor='val_loss',<br/>                             restore_best_weights=True)<br/><br/><br/>callbacks = [checkpoint, earlystopping]<br/><br/>model.compile(metrics=['accuracy'],<br/>             optimizer='rmsprop',<br/>             loss='categorical_crossentropy')</span></pre><ul class=""><li id="751a" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">åˆ›å»º<a class="ae jc" href="https://keras.io/api/callbacks/early_stopping/" rel="noopener ugc nofollow" target="_blank">æå‰åœæ­¢</a>å’Œ<a class="ae jc" href="https://keras.io/api/callbacks/model_checkpoint/" rel="noopener ugc nofollow" target="_blank">æ£€æŸ¥ç‚¹</a>å›è°ƒã€‚</li></ul><h2 id="aac6" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">æ­¥éª¤11 â€”è®­ç»ƒæ¨¡å‹ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="47c0" class="kn jq hh lc b fi lg lh l li lj">train_samples = 28273<br/>validation_samples = 3534<br/>batch_size = 64<br/>epochs=30<br/><br/>history = model.fit(train_data,<br/>                    train_labels,<br/>                    epochs=epochs,<br/>                    steps_per_epoch=train_samples//batch_size,<br/>                    validation_data=(val_data,val_labels),<br/>                    validation_steps=validation_samples//batch_size,<br/>                    callbacks=callbacks)</span></pre><ul class=""><li id="68ef" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">æœ€åè®­ç»ƒæ¨¡å‹ã€‚</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="er es mi"><img src="../Images/67838304b6e7089708b0d53465fc800b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XHxSpX6c5sQ-KrHK.png"/></div></div></figure><h2 id="afb3" class="kn jq hh bd jr ko kp kq jv kr ks kt jz ip ku kv kd it kw kx kh ix ky kz kl la bi translated">ç¬¬12æ­¥â€”å®æ—¶é¢„æµ‹ã€‚</h2><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="ae43" class="kn jq hh lc b fi lg lh l li lj">import cv2<br/>from keras.models import load_model<br/>import numpy as np<br/><br/>int2emotions = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}<br/>model = load_model('model\\6_class_emotion_detector_V2.h5')<br/>cap = cv2.VideoCapture(0)<br/><br/>classifier = cv2.CascadeClassifier('Haarcascades\\haarcascade_frontalface_default.xml')<br/><br/>def detect_face(frame):<br/>    faces=classifier.detectMultiScale(frame,1.3,4)<br/>    if faces==():<br/>        return frame<br/>    for x,y,w,h in faces:<br/>        cv2.rectangle(frame,(x,y),(x+w,y+h),(172,42,251),2)<br/>        face = frame[y:y+h,x:x+w]<br/>        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)<br/>        face = cv2.resize(face,(48,48))<br/>        face = face.reshape(1,48,48,1)<br/>        cv2.putText(frame,text=int2emotions[np.argmax(model.predict(face))],<br/>                    org=(x,y-15),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(106,40,243),thickness=2)<br/>    return frame<br/><br/>while 1:<br/>    ret,frame= cap.read()<br/>    if ret==True:<br/>        cv2.imshow('emotion_detector',detect_face(frame))<br/>        if cv2.waitKey(1)==27:<br/>            break<br/>cap.release()<br/>cv2.destroyAllWindows()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/e0adc9f2521551c52d1eb5703fafcf26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*kcO2Odho5azQstm0Gfkjvg.gif"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Emotion detector</figcaption></figure><p id="0236" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¦‚æœå¯¹æƒ…ç»ªæ£€æµ‹å™¨æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·é€šè¿‡ç”µå­é‚®ä»¶æˆ–LinkedInè”ç³»æˆ‘ã€‚</p><p id="22e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="mn">æ¢ç´¢æ›´å¤šæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€NLPã€Flaské¡¹ç›®è®¿é—®æˆ‘çš„åšå®¢â€” </em> </strong> <a class="ae jc" href="https://machinelearningprojects.net/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="mn">æœºå™¨å­¦ä¹ é¡¹ç›®</em> </strong> </a></p><p id="2ee7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">å¦‚éœ€è¿›ä¸€æ­¥çš„ä»£ç è§£é‡Šå’Œæºä»£ç ï¼Œè¯·è®¿é—®æ­¤å¤„â€”</strong><a class="ae jc" href="https://machinelearningprojects.net/emotion-detector-using-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning projects . net/emotion-detector-using-keras/</a></p><p id="7d4d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™å°±æ˜¯æˆ‘å†™ç»™è¿™ä¸ªåšå®¢çš„æ‰€æœ‰å†…å®¹ï¼Œæ„Ÿè°¢ä½ çš„é˜…è¯»ï¼Œæˆ‘å¸Œæœ›ä½ åœ¨é˜…è¯»å®Œè¿™ç¯‡æ–‡ç« åï¼Œèƒ½æœ‰æ‰€æ”¶è·ï¼Œç›´åˆ°ä¸‹æ¬¡ğŸ‘‹â€¦ </p><p id="267c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="mn">çœ‹æˆ‘ä»¥å‰çš„å¸–å­:</em> </strong> <a class="ae jc" href="https://machinelearningprojects.net/monkey-breed-classification/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="mn">çŒ´å­å“ç§åˆ†ç±»åˆ©ç”¨è¿ç§»å­¦ä¹ </em> </strong> </a></p><div class="mo mp ez fb mq mr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hi fi z dy mw ea eb mx ed ef hg bi translated">Mlearning.aiæäº¤å»ºè®®</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">å¦‚ä½•æˆä¸ºMlearning.aiä¸Šçš„ä½œå®¶</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">medium.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf jj mr"/></div></div></a></div></div></div>    
</body>
</html>
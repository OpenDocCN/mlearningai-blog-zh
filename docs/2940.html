<html>
<head>
<title>Logical vs Geometrical vs Probabilistic Models in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的逻辑模型、几何模型和概率模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/logical-vs-geometrical-vs-probabilistic-models-in-machine-learning-ae3a33e6be1e?source=collection_archive---------0-----------------------#2022-06-30">https://medium.com/mlearning-ai/logical-vs-geometrical-vs-probabilistic-models-in-machine-learning-ae3a33e6be1e?source=collection_archive---------0-----------------------#2022-06-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c4e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di"> M </span>机器学习就是使用正确的<strong class="ig hi"> <em class="jl">特性</em> </strong>来构建正确的<strong class="ig hi"> <em class="jl">模型</em> </strong>来完成正确的<strong class="ig hi"> <em class="jl">任务</em> </strong>。</p><p id="9f8b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">特点:</strong>机器学习的老黄牛。</p><p id="23ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">模型:</strong>机器学习的输出。</p><p id="8aa4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">任务:</strong>可以用机器学习解决的问题。</p><blockquote class="jm jn jo"><p id="a830" class="ie if jl ig b ih ii ij ik il im in io jp iq ir is jq iu iv iw jr iy iz ja jb ha bi translated">特性在很大程度上决定了ML应用程序的成功，因为一个模型的好坏取决于它的特性。</p></blockquote><p id="dcc8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们主要关注的是<strong class="ig hi">车型<em class="jl">。让我们继续我们的造型trip…✈️</em></strong></p><p id="b37d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型是机器学习中的核心概念，因为它们是为了解决给定任务而从数据中学习的东西。有各种各样的机器学习模型可用。这尤其是因为机器学习旨在解决的任务无处不在。我们看到的最常见的3组模型是:<strong class="ig hi"><em class="jl"/></strong><strong class="ig hi"><em class="jl">几何</em> </strong>和<strong class="ig hi"> <em class="jl">概率</em> </strong>模型。让我们仔细看看每一类模型。</p><h2 id="5318" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated"><strong class="ak">逻辑模型</strong></h2><p id="ef4e" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated"><strong class="ig hi">【逻辑】</strong>因为这类模型很容易翻译成人类可以理解的<strong class="ig hi"><em class="jl"/></strong>规则，比如。，<em class="jl">如果彩票= 1那么class = Y = spam。</em>这样的规则很容易排列成树形结构，我们称之为<strong class="ig hi"> <em class="jl">特征树</em> </strong>。这种树的思想是使用特征迭代地划分实例空间。因此，树的叶子对应于实例空间中的矩形区域(或更一般的超矩形)，我们称之为实例空间段，或简称为段。根据我们正在解决的任务，我们可以用类别、概率、真实值等等来标记树叶。</p><blockquote class="jm jn jo"><p id="0ec4" class="ie if jl ig b ih ii ij ik il im in io jp iq ir is jq iu iv iw jr iy iz ja jb ha bi translated">叶子标有类别的特征树通常称为<strong class="ig hi"> <em class="hh">决策树</em> </strong>。</p></blockquote><p id="b6b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个简单的逻辑模型如下所示:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ks"><img src="../Images/1f3441c662136ca74e8a682a41f8b230.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*YeJIXD-mbHUN08wDLobGNA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx">Source — Wikipedia</figcaption></figure><p id="87ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">显示泰坦尼克号上幸存乘客的树(“sibsp”是船上配偶或兄弟姐妹的数量)。叶子下面的数字显示了存活的概率和叶子中观察到的百分比。总结:如果你是(1)女性或(2)小于9.5岁的男性，且严格来说兄弟姐妹少于3个，那么你存活的机会很大。</p><p id="a1a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更深入地理解逻辑模型，我们需要理解<strong class="ig hi"> <em class="jl">概念学习</em> </strong>的概念，这将在我即将发表的博客中讨论。哇！我们只有两步之遥…不能再等了(๑ &gt; ᴗ &lt; ๑).)让我们快速深入我们的几何模型。</p><h2 id="ef67" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">几何模型</h2><p id="eac6" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在学习什么是几何模型之前？它有哪些类型？，它们是如何工作的？等等。我们先来了解一下<strong class="ig hi"> <em class="jl">究竟什么是“实例空间”？？</em> </strong>。</p><blockquote class="jm jn jo"><p id="07aa" class="ie if jl ig b ih ii ij ik il im in io jp iq ir is jq iu iv iw jr iy iz ja jb ha bi translated">一个<strong class="ig hi">实例空间</strong>是所有可能的或可描述的实例的集合，无论它们是否出现在我们的数据集中。通常这个集合有一些几何结构。例如，如果所有特征都是数字的，那么我们可以将每个特征用作笛卡尔坐标系中的坐标。</p></blockquote><p id="42ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jl">几何模型/特征学习</em> </strong>是一种结合机器学习和计算机视觉解决视觉任务的技术。这些模型通过考虑实例空间的几何来定义相似性。这里，特征可以描述为二维(x轴和y轴)或三维空间(x、y和z)中的点。即使特征本质上不是几何的，它们也可以以几何方式建模。然而，重要的是要记住，笛卡尔实例空间具有与特征一样多的坐标，可以是几十个、几百个、几千个甚至更多。这样的高维空间很难想象，但在机器学习中很常见。可能适用于更高维度空间的几何概念往往以“hyper-”为前缀:例如，一个无限维的决策边界被称为一个<strong class="ig hi"> <em class="jl">超平面</em> </strong>。几何分类器的一个主要优点是，只要我们坚持二维或三维，它们就很容易可视化。</p><p id="9e6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">几何模型基本上有两种类型</p><ol class=""><li id="6415" class="le lf hh ig b ih ii il im ip lg it lh ix li jb lj lk ll lm bi translated">直接在实例空间中构建的几何模型，使用诸如线或平面的几何概念，用于分割实例空间，称为<strong class="ig hi">线性模型</strong>。</li><li id="ec03" class="le lf hh ig b ih ln il lo ip lp it lq ix lr jb lj lk ll lm bi translated">使用距离作为度量来表示实例之间的相似性的几何模型被称为<strong class="ig hi">基于距离的模型</strong>。常用的距离度量有，<strong class="ig hi"><em class="jl"/></strong><strong class="ig hi"><em class="jl">闵可夫斯基</em></strong><strong class="ig hi"><em class="jl">曼哈顿</em></strong><strong class="ig hi"><em class="jl">马哈拉诺比斯</em> </strong>。</li></ol><p id="1d98" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">线性模型</strong></p><p id="7a8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了对实例进行分类，线性模型使用下面的等式，<strong class="ig hi"> <em class="jl"> f(x) = a + bx </em> </strong>，如果x和f(x)是标量，并且如果x = (x1，.。。，xd)是一个向量，f (x)是一个标量，那么f的形式是<strong class="ig hi"> <em class="jl"> f(x) = a +b1x1 +。。。+bd xd </em> </strong> = a + b x其中b = (b1，.。。，bd)。方程f (x) = 0定义了垂直于法向量b的Rd平面。</p><p id="be06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性模型适用于所有预测任务，包括分类、概率估计和回归。比如说。,</p><p id="850a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">a)花在学习上的时间与学生的分数</p><p id="38e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b)降雨量与农业产量</p><p id="a517" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c)用电量与电费</p><p id="348d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">d)自杀率与压力人群的数量</p><p id="24b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有不同的线性模型，如最小二乘法(一种数学回归分析)，支持向量机(使用超平面最好地分离两个或多个类别)。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/8d0804cbe3fb099ce0b25a33cbd5c976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ltXBVWoo1qSIRuWbsS5qAw.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx"><strong class="bd ju">Least Squares (left) and SVM (right)</strong></figcaption></figure><p id="d7f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基于距离的模型</strong></p><p id="2033" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">机器学习中一个非常有用的几何概念是距离的概念。如果两个实例之间的距离很小，那么这些实例就其特征值而言是相似的，因此附近的实例将被期望接收相同的分类或属于相同的聚类。在笛卡尔坐标系中，距离可以用<em class="jl">欧几里德距离</em>来度量，欧几里德距离是沿着每个坐标的距离平方之和的平方根。</p><p id="b162" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了对新实例进行分类，我们从存储器中检索最相似的训练实例(即，与要分类的实例具有最小欧几里德距离的训练实例)，并简单地分配该训练实例的类别。这个分类器被称为<strong class="ig hi"> <em class="jl">最近邻</em> </strong>分类器。这个简单而强大的主题存在着无穷无尽的变化:我们可以检索k个最相似的训练实例并进行投票(<strong class="ig hi"><em class="jl">k-nearest neighbor</em></strong>)。</p><p id="9de4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们可以使用一组邻近点的平均值作为这些点的代表性样本。假设我们想将数据分成K个簇，并且我们对数据应该如何进行簇有一个初步的猜测。然后，我们计算每个初始聚类的平均值，并将每个点重新分配给最近的聚类平均值。我们重复这两个步骤(计算聚类平均值并将点重新分配给聚类)，直到没有变化发生。这种叫做<strong class="ig hi"> <em class="jl">的聚类算法，K-的意思是</em> </strong>。</p><p id="cb21" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一种基于距离的聚类是<strong class="ig hi"> <em class="jl">层次聚类</em> </strong>，这是一种构建聚类层次的算法。该算法从分配给它们自己的聚类的所有数据点开始。然后将两个最近的聚类合并成同一个聚类。最后，当只剩下一个簇时，该算法终止。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lx"><img src="../Images/1be3a79503848aab215c4f1a8492e8f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FVWenKOAGHHsdhXKCF_qVw.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx"><strong class="bd ju">KNN (top-left), K-means (top-right) and Hierarchical clustering (bottom)</strong></figcaption></figure><p id="2baf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">哇！我们离这里只有一箭之遥。下一个也是最后一个模型是概率模型。我们来看看它和其他两款有什么不同。</p><h2 id="d1e5" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">概率模型</h2><p id="9f98" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">概率模型/方法基于概率理论，或随机性在预测未来事件中发挥作用的事实。</p><p id="18f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让X表示我们知道的变量，例如，我们实例的特征值；让Y表示我们感兴趣的目标变量，例如，实例的类。机器学习的关键问题是如何对X和y之间的关系进行建模。统计学家的方法是假设存在一些潜在的随机过程，根据定义良好但未知的概率分布来生成这些变量的值。</p><p id="b7a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于特定情况下X是已知的，但Y可能是未知的，因此我们对条件概率P(Y |X)特别感兴趣，其中我们根据X来预测Y的值。朴素贝叶斯是概率模型的一个示例，它遵循贝叶斯定理。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ly"><img src="../Images/4b42f45bad68211da09cbb02ff47a2b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*SbIgRhKMAQOYQEA-DErw-w.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx"><strong class="bd ju">Bayes Theorem</strong></figcaption></figure><p id="a786" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">P(Y/X) =后验概率(给定证据假设为真的概率)</p><p id="8b11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">P(X/Y) =似然比(假设为真时看到证据的概率)</p><p id="7da1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">P(Y) =类先验概率(在任何证据出现之前，假设为真的概率)</p><p id="27d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">P(X) =预测值先验概率(观察证据的概率)</p><p id="f01b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在对概率模型有了一些概念。在许多情况下，这是一个从数据中估计模型参数的问题，通常通过直接计数来实现。</p><blockquote class="jm jn jo"><p id="9888" class="ie if jl ig b ih ii ij ik il im in io jp iq ir is jq iu iv iw jr iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>基于模型的机器学习的目标是单一的建模框架应该支持广泛的模型。</p></blockquote><p id="5976" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">呼呼..！！差不多到现在。我们终于到达了终点。在我的下一篇博客中，我们将会看到每一个算法(如上所述)是如何详细工作的。到那时，<strong class="ig hi"> <em class="jl">快乐学习机:)</em> </strong></p><div class="lz ma ez fb mb mc"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="md ab dw"><div class="me ab mf cl cj mg"><h2 class="bd hi fi z dy mh ea eb mi ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mj l"><h3 class="bd b fi z dy mh ea eb mi ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mk l"><p class="bd b fp z dy mh ea eb mi ed ef dx translated">medium.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ky mc"/></div></div></a></div></div></div>    
</body>
</html>
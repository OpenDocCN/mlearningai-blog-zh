<html>
<head>
<title>Machine learning Attack</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习攻击</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/machine-learning-attack-a92c5359b36d?source=collection_archive---------5-----------------------#2022-03-27">https://medium.com/mlearning-ai/machine-learning-attack-a92c5359b36d?source=collection_archive---------5-----------------------#2022-03-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b28b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">破坏ML模型|对抗性机器学习|安全措施</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/366f3128c4c683b99c74e2b2dd3e3490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2kakouGP-uY2cmKwNBHimA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Adversarial attack</figcaption></figure><p id="a631" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">机器学习模型确实会被黑！！</p><p id="9fc2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">…</p><p id="2685" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">..</p><p id="97eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">是的，你没看错。与任何其他软件类似，机器学习模型可以被黑客攻击和破坏，以破坏应用程序的预期用途。作为一名数据科学家、机器学习工程师或用户，了解不同的攻击和一些可能的解决方案是有用的。</p><p id="b78f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们开始，首先探索一些安全攻击的例子…</p><ul class=""><li id="b426" class="js jt hh ig b ih ii il im ip ju it jv ix jw jb jx jy jz ka bi translated">人脸欺骗——人脸识别模型可能会错误地将照片验证为一个人</li><li id="033b" class="js jt hh ig b ih kb il kc ip kd it ke ix kf jb jx jy jz ka bi translated">用带有附加噪声的类别(比如猪)的图像呈现的图像分类模型可能被欺骗来预测其他类别(比如客机)</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kg"><img src="../Images/79f071d8a5c36d399af6914e95ff1f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a5d_MjWi0MweYMNC06584Q.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">adversarial example</figcaption></figure></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><p id="5614" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可能想知道这种攻击是否有任何特定的类别？？好吧，让我们了解一下主要的类别和减少每一类攻击的方法。</p><p id="2ca2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以基于攻击者的预期目标(间谍、破坏、欺诈)和机器学习生命周期中的攻击阶段(培训、生产)来定义对ML模型的攻击类别。分别是<strong class="ig hi">规避、投毒、木马、后门、重编程和推理攻击</strong>。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ko"><img src="../Images/7155b4a196d5f6fae043e913d344c1ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2QG0DPty1DjZQJ1d4j6_Yw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">attacks</figcaption></figure><blockquote class="kp kq kr"><p id="3b26" class="ie if ks ig b ih ii ij ik il im in io kt iq ir is ku iu iv iw kv iy iz ja jb ha bi translated">规避、投毒、推理攻击是最常见的。我们将在<a class="ae kw" href="https://towardsdatascience.com/how-to-attack-machine-learning-evasion-poisoning-inference-trojans-backdoors-a7cb5832595c" rel="noopener" target="_blank">简报</a>中探索它们</p></blockquote><ol class=""><li id="9449" class="js jt hh ig b ih ii il im ip ju it jv ix jw jb kx jy jz ka bi translated"><strong class="ig hi">闪避攻击</strong></li></ol><p id="9cb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">创建扰动样本来误导验证，而不影响模型本身。例如，犯罪分子可以使用逃避攻击来误导人脸识别系统(例如，戴上类似于另一个人的面具)。任何受干扰的样本(看起来像好的输入样本，但实际上在推理时引入了噪声的输入)都可能破坏模型的性能和可靠性。</p><p id="adf7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.<strong class="ig hi">中毒发作</strong></p><p id="0318" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一种对抗性攻击，将精心设计的样本注入到<strong class="ig hi">训练数据</strong>中，以改变系统对特定样本或模式的响应和行为。</p><p id="da1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<strong class="ig hi">探索攻击(模型窃取)/推理攻击</strong></p><p id="8de3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">试图窃取关于模型的知识。它不会直接影响模型行为，但是获得的知识可能会造成潜在的攻击威胁。攻击者打算探索系统，例如模型或数据，以获取任何可能派上用场的信息。</p><blockquote class="ky"><p id="b026" class="kz la hh bd lb lc ld le lf lg lh jb dx translated">Python使用<a class="ae kw" href="https://secml.readthedocs.io/en/v0.15/#getting-started" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> SecML </strong> </a> <strong class="ak">为安全评估提供了一个有趣的实现。</strong>它配备了规避和中毒对抗性机器学习攻击</p></blockquote></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><p id="c138" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">防御</strong></p><p id="a742" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">防御的目标可以是主动的，也可以是被动的。主动防御试图优化人工智能系统，使其对某些输入更加鲁棒，而反应防御旨在检测潜在的安全问题，如改变分布或敌对样本。从广义上来说，主动防御是在训练时应用的，通过训练对某些类型的攻击和输入的鲁棒性。反应性防御，另一方面，处理测试时的防御或推理</p><p id="6a47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一些主要使用的防御方法如下</p><ul class=""><li id="8abc" class="js jt hh ig b ih ii il im ip ju it jv ix jw jb jx jy jz ka bi translated"><strong class="ig hi">在特征空间中实施类别分离:</strong></li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es li"><img src="../Images/f3eb868623fb7a763950c9f673fb8a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yi5_83QvFpf-kYejivYnKA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Proactive defense — enforcing class separation</figcaption></figure><p id="a58e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它试图用对立的输入来训练模型，迫使类簇在一定距离处形成，并最小化对立输入的错误分类的机会。</p><ul class=""><li id="c6bf" class="js jt hh ig b ih ii il im ip ju it jv ix jw jb jx jy jz ka bi translated"><strong class="ig hi">猴子测试</strong>:一种软件测试，在软件中注入随机输入，目的是破解软件。它有助于识别关键漏洞。这是一种反应性防御。</li></ul><p id="8350" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">防御攻击领域是一个活跃的研究领域，并且正在被<a class="ae kw" href="https://towardsdatascience.com/adversarial-attacks-in-machine-learning-and-how-to-defend-against-them-a2beed95f49c" rel="noopener" target="_blank">广泛探索</a>。意识到这种攻击的本质是减少其几率的第一步。</p><p id="c7f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论</strong></p><p id="5976" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">机器学习被广泛应用于商业、公共服务和政府组织，包括国防。攻击者可能会妨碍各种关键应用程序。我们需要确保我们的人工智能系统的可信度。攻击的性质不断演变，因此行业需要强调针对此类攻击的防御研究，并帮助开发能够成功和失败都很优雅的系统。</p><blockquote class="kp kq kr"><p id="2238" class="ie if ks ig b ih ii ij ik il im in io kt iq ir is ku iu iv iw kv iy iz ja jb ha bi translated"><em class="hh">感谢您的阅读！！我，Sourav Agarwal，打算用数据灌输意识和授权决策。</em></p></blockquote><h2 id="cad3" class="lj lk hh bd ll lm ln lo lp lq lr ls lt ip lu lv lw it lx ly lz ix ma mb mc md bi translated"><em class="me">“学习和创新齐头并进。成功的傲慢是认为你昨天所做的足以应付明天。”——威廉·波拉德</em></h2><p id="ce7c" class="pw-post-body-paragraph ie if hh ig b ih mf ij ik il mg in io ip mh ir is it mi iv iw ix mj iz ja jb ha bi translated"><em class="ks">沐浴你的❤，跟随它成为持续学习之旅的一部分。我们将共同利用数据来增强决策能力。</em></p><div class="mk ml ez fb mm mn"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mo ab dw"><div class="mp ab mq cl cj mr"><h2 class="bd hi fi z dy ms ea eb mt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mu l"><h3 class="bd b fi z dy ms ea eb mt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mv l"><p class="bd b fp z dy ms ea eb mt ed ef dx translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb jm mn"/></div></div></a></div></div></div>    
</body>
</html>
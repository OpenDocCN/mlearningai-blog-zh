<html>
<head>
<title>Telco Churn Analysis and Modeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">电信客户流失分析和建模</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/telco-churn-analysis-and-modeling-a3c5f408bd9b?source=collection_archive---------1-----------------------#2021-11-29">https://medium.com/mlearning-ai/telco-churn-analysis-and-modeling-a3c5f408bd9b?source=collection_archive---------1-----------------------#2021-11-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/629aff1fe14a715fc76761abd4c61773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/0*JgifbLhsG2eutLK3"/></div><figcaption class="il im et er es in io bd b be z dx">Image source <a class="ae ip" href="https://www.ibm.com/blogs/business-partners/ibm-telco-network-cloud-ecosystem/" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="d899" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">问题陈述</strong></p><p id="1645" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">在一家电信公司中，有一种促销费用叫做购买成本和保留成本。获取新消费者的成本被称为获取成本。同时，保留现有客户的费用被称为保留成本。</p><p id="f32a" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">由于人的局限性，我们经常无法准确预测哪些客户会流失，哪些会留下来。因此，货币的分配可能不正确，导致发行的资金量更高。</p><p id="e642" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">此外，一些消息来源称，采购成本比保留成本高5倍。如果我们预测到一个客户会不正确地流失，但结果是我们预测到一个客户会留下来，我们将不得不花费更多。</p><h2 id="91ca" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">目标</h2><p id="f033" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">机器学习有一个目标，让成本分配尽可能精确。</p><p id="63ff" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">确保您已经在命令行提示符或anaconda提示符下安装了xgboost by- <code class="du ko kp kq kr b">pip install xgboost</code>。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="dee2" class="jo jp hh kr b fi la lb l lc ld"><em class="le">#Importing the libraries</em><br/><strong class="kr hi">import</strong> pandas <strong class="kr hi">as</strong> pd <br/><strong class="kr hi">import</strong> numpy <strong class="kr hi">as</strong> np <br/><strong class="kr hi">import</strong> xgboost <strong class="kr hi">as</strong> xgb <br/><strong class="kr hi">from</strong> sklearn.model_selection <strong class="kr hi">import</strong> train_test_split <br/><strong class="kr hi">from</strong> sklearn.metrics <strong class="kr hi">import</strong> roc_auc_score, balanced_accuracy_score, make_scorer <br/><strong class="kr hi">from</strong> sklearn.model_selection <strong class="kr hi">import</strong> GridSearchCV <br/><strong class="kr hi">from</strong> sklearn.metrics <strong class="kr hi">import</strong> confusion_matrix, plot_confusion_matrix <br/><strong class="kr hi">import</strong> matplotlib.pyplot <strong class="kr hi">as</strong> plt<br/><strong class="kr hi">import</strong> seaborn <strong class="kr hi">as</strong> sns <br/>pd<strong class="kr hi">.</strong>set_option('display.max_columns', 500) </span></pre><h1 id="752f" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">1.导入数据集</h1><p id="9af9" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">现在，我们将从<a class="ae ip" href="https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113" rel="noopener ugc nofollow" target="_blank">https://community . IBM . com/community/user/business analytics/blogs/Steven-macko/2019/07/11/telco-customer-churn-1113</a>导入数据集</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="8cae" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># load the dataset in df and lest look at the first 5 rows of df</em><br/>df<strong class="kr hi">=</strong> pd<strong class="kr hi">.</strong>read_excel('Telco_customer_churn.xlsx')<br/>df<strong class="kr hi">.</strong>head()</span></pre><p id="1b53" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们导入数据并存储在测向数据帧中。</p><h1 id="58e6" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">行动纲要</h1><p id="7164" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi lw translated">elco Co .提供了7043名客户的精选历史数据，包括每个客户是否都曾倒戈的指标。在分析和转换数据后，我们优化了几个分类模型。每个模型在75%的历史数据上被训练，然后被要求在剩余的25%的测试数据上预测流失分数。每个模型都与以前的最佳模型进行了比较，其中XG Boost模型表现最佳</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="3d33" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Lets look at the shape of dataset</em><br/>df<strong class="kr hi">.</strong>shape</span><span id="38af" class="jo jp hh kr b fi mf lb l lc ld"><em class="le"># Lets describe the dataset</em><br/>df<strong class="kr hi">.</strong>describe()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es mg"><img src="../Images/d3807cc5e8af0f40ec03ac991f4bd117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7FNBMJgshj2ghMikOvoI5A.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Data Summary</figcaption></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="94ed" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Lets look at the data type of each columns in dataset</em><br/>df<strong class="kr hi">.</strong>info()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/f6cd15bbc8488264ea480ddfd2158704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*VI04mctFUHbR5ywMEt2MUw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Data information</figcaption></figure><p id="0c66" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">因此，Df数据集包含7043行，33列</p><h1 id="1ca5" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">2.数据预处理</h1><p id="b833" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">人们已经离开了电信公司，所以我们将从数据集中删除这些列。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="df18" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Removing these columns so, we did axis=1, and inplace= True, means not making the copy of dataset</em><br/>df<strong class="kr hi">.</strong>drop(['Churn Reason','CLTV','Churn Score','Churn Label'], axis<strong class="kr hi">=</strong>1, inplace<strong class="kr hi">=</strong> <strong class="kr hi">True</strong>)<br/>df<strong class="kr hi">.</strong>head()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es mm"><img src="../Images/85473c9d91ac50c2ba71434bc88db50a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*22FTeDkzNXI110LeUU_kLw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">After Removing garbage columns</figcaption></figure><p id="037d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">某些列仅包含单个值，从上面的数据框中可以看出，一些列有一个唯一值，即列[Count，Country，State]。此外，我不会使用customerID列，因为CustomerID不确定某人是否会流失的概率。</p><blockquote class="mn"><p id="c758" class="mo mp hh bd mq mr ms mt mu mv mw jn dx translated">邮政编码，纬度，经度也将被删除。我不会用它来构建机器学习。</p></blockquote><figure class="my mz na nb nc ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es mx"><img src="../Images/174f2d6eb980597af43df7cb399238a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nWYPd0sHUYdeBCZg17t2cg.png"/></div></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="4343" class="jo jp hh kr b fi la lb l lc ld">df<strong class="kr hi">.</strong>drop(['Count','City','Country','State','CustomerID','Zip Code', 'Lat Long', 'Latitude', 'Longitude'],<br/>       axis<strong class="kr hi">=</strong>1, inplace<strong class="kr hi">=</strong> <strong class="kr hi">True</strong>)<br/><em class="le"># Lets see first 5 rows </em><br/>df<strong class="kr hi">.</strong>head()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es nd"><img src="../Images/c24ee00c1f7903fee2cdf4508033f9b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hl4euHMtX5mkY0te5Af53g.png"/></div></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="9c0d" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Replacing the space from column name </em><br/>df<strong class="kr hi">.</strong>columns<strong class="kr hi">=</strong> df<strong class="kr hi">.</strong>columns<strong class="kr hi">.</strong>str<strong class="kr hi">.</strong>replace(' ','_') <em class="le">#replacing space with undescore</em><br/>df<strong class="kr hi">.</strong>columns</span><span id="d4f9" class="jo jp hh kr b fi mf lb l lc ld"><em class="le"># Now replacing white spaces with underscore</em><br/>df<strong class="kr hi">.</strong>replace(' ', '_', regex<strong class="kr hi">=True</strong>, inplace <strong class="kr hi">=True</strong>)<br/>df<strong class="kr hi">.</strong>head()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es nd"><img src="../Images/0b847654eb97e540f65f5d8cf61a8b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*on53XERuE4Kg-GKEAiTRpg.png"/></div></div></figure><p id="2b51" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">检查缺失值</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="efed" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># checking missing values </em><br/>df<strong class="kr hi">.</strong>isnull()<strong class="kr hi">.</strong>sum()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ne"><img src="../Images/dfee732f6083529d62f7650b47e5d651.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*tacHfHFfyvGyyQup3DHrxA.png"/></div><figcaption class="il im et er es in io bd b be z dx">Missing values</figcaption></figure><p id="0059" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们没有发现任何丢失的值</p><p id="9878" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">浏览数据帧中的列:</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="be28" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Lets look at the column of df['Total_Charges']</em><br/>df[df['Total_Charges']<strong class="kr hi">==</strong>"_"]</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es nf"><img src="../Images/a4343be9105f323728b1d962590d35be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JAVr0eCnixc08DTSTycxRQ.png"/></div></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="22ba" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># replacing the colum Total_Charges with zero</em><br/>df['Total_Charges']<strong class="kr hi">=</strong> np<strong class="kr hi">.</strong>where(df['Total_Charges']<strong class="kr hi">==</strong>"_",0,df['Total_Charges'])</span></pre><p id="1dc2" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">更改Total_Charges列的数据类型</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="bc58" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># lets change the datatype of column Total_Charges to numeric</em><br/>df['Total_Charges']<strong class="kr hi">=</strong> pd<strong class="kr hi">.</strong>to_numeric(df['Total_Charges'])<br/>df['Total_Charges']<strong class="kr hi">.</strong>dtype</span></pre><h1 id="ecf9" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">3.电子设计自动化(Electronic Design Automation)</h1><p id="cfce" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">探索性数据分析是使用统计和可视化工具(EDA)对数据进行初步检查，以发现数据中测量值之间的联系，并深入了解数据集中包含的不同实体之间的趋势、模式和交互作用。</p><h1 id="961d" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">3.1单变量分析:</h1><p id="4bad" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">因为uni表示一，variate表示变量，所以在单变量分析中只有一个可靠变量。单变量分析的目标是导出数据，描述和总结数据，并检查可能存在的任何模式。它分别调查数据集中的每个变量。有两种类型的变量可以使用:分类变量和数字变量。</p><p id="1a3e" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">集中趋势(平均值、众数和中位数)、离差(范围、方差)、四分位数(四分位数间范围)和标准差是使用单变量分析可以容易发现的一些模式。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="94d6" class="jo jp hh kr b fi la lb l lc ld">df['Churn_Value']<strong class="kr hi">.</strong>value_counts()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ng"><img src="../Images/142d5edf64394f21066a69655f82c984.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*CehWAf3UtWJBBL4p5J57SA.png"/></div></figure><p id="7f6b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">让我们想象一下目标变量</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="3fdb" class="jo jp hh kr b fi la lb l lc ld">plt<strong class="kr hi">.</strong>figure(figsize<strong class="kr hi">=</strong>(10,5))<br/>plt<strong class="kr hi">.</strong>pie(df['Churn_Value']<strong class="kr hi">.</strong>value_counts(), labels<strong class="kr hi">=</strong>df['Churn_Value']<strong class="kr hi">.</strong>unique(), autopct<strong class="kr hi">=</strong>'%.2f%%')<br/>plt<strong class="kr hi">.</strong>show()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nh"><img src="../Images/1c045b7dc077f5d6867b1cb4b295700d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*N6XIm8l4JzqALs_lJ25LZw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Pie chart: Target Variable</figcaption></figure><p id="177b" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">通过查看df['Churn_Value']列，我们得出数据不平衡的结论，我们必须在建立机器学习模型之前处理不平衡的数据</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="ef1b" class="jo jp hh kr b fi la lb l lc ld">plt<strong class="kr hi">.</strong>figure(figsize<strong class="kr hi">=</strong>(5,5))<br/>sns<strong class="kr hi">.</strong>countplot(df<strong class="kr hi">.</strong>Gender)<br/>plt<strong class="kr hi">.</strong>title('Male counts Vs female count ')</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ni"><img src="../Images/8ee004ac4f29a05115b0849a712ccca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*BiQpk4SLicLXphVzD5wYJA.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="f44c" class="jo jp hh kr b fi la lb l lc ld">sns<strong class="kr hi">.</strong>histplot(df<strong class="kr hi">.</strong>Monthly_Charges)<br/>plt<strong class="kr hi">.</strong>title('Histogram of Monthly_Charges')</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nj"><img src="../Images/b9b4c2b895ed5000a4426949938d2290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*ibSEIjkFfKx9XFMvpxMBUg.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="b2ea" class="jo jp hh kr b fi la lb l lc ld">plt<strong class="kr hi">.</strong>figure(figsize<strong class="kr hi">=</strong>(5,5))<br/>sns<strong class="kr hi">.</strong>countplot(df<strong class="kr hi">.</strong>Senior_Citizen)<br/>plt<strong class="kr hi">.</strong>title('Bar plot of Senior_Citizen ')</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nk"><img src="../Images/4bd93f5fdf90b81f906358cdf73c445b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*DCqq5_ARJyen_x4cb62IUg.png"/></div></figure><h1 id="2b8f" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">3.2双变量分析</h1><p id="81f4" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">这里有两个变量，bi表示两个，variate表示变量。这项研究的重点是问题的根源以及这两个变量之间的关系。双变量分析分为三种类型。</p><ul class=""><li id="c99c" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn nq nr ns nt bi translated"><strong class="is hi">两个数值变量的二元分析</strong>(数值-数值)我们做<strong class="is hi">散点图</strong>，<strong class="is hi">相关。</strong></li><li id="eb95" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated"><strong class="is hi">一个数值和一个分类变量的双变量分析</strong>(数值-分类)，我们做<strong class="is hi"> ANOVA </strong></li><li id="fc39" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated"><strong class="is hi">双变量分析两个分类变量</strong>(分类-分类)，我们做<strong class="is hi"> Chi2检验。</strong></li></ul><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="f08e" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># column Senior_Citizen</em><br/>df['Senior_Citizen']<strong class="kr hi">.</strong>value_counts()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nz"><img src="../Images/2b6a799c301e613358fac509cef70271.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*83Xdbv_EdmNRl0DlgogLGw.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="8ea1" class="jo jp hh kr b fi la lb l lc ld">plt<strong class="kr hi">.</strong>figure(figsize<strong class="kr hi">=</strong>(8,6))<br/>sns<strong class="kr hi">.</strong>catplot(x<strong class="kr hi">=</strong>'Gender', hue<strong class="kr hi">=</strong>'Churn_Value', col<strong class="kr hi">=</strong>'Senior_Citizen', kind<strong class="kr hi">=</strong>'count', data<strong class="kr hi">=</strong>df)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es oa"><img src="../Images/feb20179ebdb0840b4edbacea10b1440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*InBByYVONtMIHMgwS6GsCQ.png"/></div></div></figure><p id="c088" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">从上面的形象化数据中，我们可以看到，老年公民(男性和女性)的流失率和保留率几乎相同。同样，非老年人的流失率和保留率。但如果我们观察一下，与非老年人相比，老年人的流失率有所增加。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="b3d4" class="jo jp hh kr b fi la lb l lc ld">by_gender_senior <strong class="kr hi">=</strong> df<strong class="kr hi">.</strong>groupby(['Senior_Citizen', 'Gender'])['Churn_Value']<strong class="kr hi">.</strong>value_counts(normalize<strong class="kr hi">=True</strong>)<strong class="kr hi">.</strong>to_frame()<strong class="kr hi">.</strong>rename(columns<strong class="kr hi">=</strong>{'Churn_Value': 'Ratio'})<strong class="kr hi">.</strong>reset_index()<strong class="kr hi">.</strong>sort_values('Senior_Citizen')<br/>by_gender_senior</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ob"><img src="../Images/4c8faedb354ea1bc5766f363140bfcf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*uBiP5e3f1Ya-hCCoXEZd1A.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="35ea" class="jo jp hh kr b fi la lb l lc ld">sns<strong class="kr hi">.</strong>catplot(x<strong class="kr hi">=</strong> 'Gender', hue<strong class="kr hi">=</strong> 'Churn_Value',col<strong class="kr hi">=</strong>'Partner', kind<strong class="kr hi">=</strong> 'count', data<strong class="kr hi">=</strong> df)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es oc"><img src="../Images/97c1521c17a0ab451bf6a0ef619d1a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-KElJ0M_0d5jFwUMBeCOKw.png"/></div></div></figure><p id="3323" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">从上面的形象化来看，没有伴侣的男性和女性都更有可能流失。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="1074" class="jo jp hh kr b fi la lb l lc ld">sns<strong class="kr hi">.</strong>catplot(x<strong class="kr hi">=</strong>'Payment_Method', hue<strong class="kr hi">=</strong>'Churn_Value', kind<strong class="kr hi">=</strong>'count', data<strong class="kr hi">=</strong>df)<br/>plt<strong class="kr hi">.</strong>xticks(rotation<strong class="kr hi">=</strong>45)<br/>plt<strong class="kr hi">.</strong>show()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es od"><img src="../Images/c8a15191b77f534fd341a50f21df9746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*zP3O6rm7oTOorhFIL6PotA.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="77e4" class="jo jp hh kr b fi la lb l lc ld">pd<strong class="kr hi">.</strong>crosstab(df['Payment_Method'], df['Churn_Value'], normalize<strong class="kr hi">=</strong>0)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es oe"><img src="../Images/8c82985a61e73e3a79503ad87987aeda.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*Z7Bted2eGsF3IbtjotFUsg.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="5199" class="jo jp hh kr b fi la lb l lc ld">plt<strong class="kr hi">.</strong>figure(figsize<strong class="kr hi">=</strong>(16,5))<br/>plt<strong class="kr hi">.</strong>subplot(1,2,1)<br/>plt<strong class="kr hi">.</strong>title('Monthly Charge distribution')<br/>sns<strong class="kr hi">.</strong>distplot(df[df['Churn_Value'] <strong class="kr hi">==</strong> 1]['Monthly_Charges'], label<strong class="kr hi">=</strong>'Churn')<br/>plt<strong class="kr hi">.</strong>subplot(1,2,2)<br/>plt<strong class="kr hi">.</strong>title('Monthly Charge distribution Split by Gender')<br/>sns<strong class="kr hi">.</strong>distplot(df[(df['Churn_Value'] <strong class="kr hi">==</strong> 1) <strong class="kr hi">&amp;</strong> (df['Gender'] <strong class="kr hi">==</strong> 'Male')]['Monthly_Charges'], label<strong class="kr hi">=</strong>'Male')<br/>sns<strong class="kr hi">.</strong>distplot(df[(df['Churn_Value'] <strong class="kr hi">==</strong> 1) <strong class="kr hi">&amp;</strong> (df['Gender'] <strong class="kr hi">==</strong> 'Female')]['Monthly_Charges'], label<strong class="kr hi">=</strong>'Female')<br/>plt<strong class="kr hi">.</strong>legend()<br/>plt<strong class="kr hi">.</strong>show()</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es of"><img src="../Images/da76ea7ce3c372f48fe7a48a3210d2a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yi_1eq3KuUT9MxNq6IRM6Q.png"/></div></div></figure><h1 id="5c08" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated"><strong class="ak"> 4。创建独立和相关数据集</strong></h1><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="b317" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Creating independent and depedent variable </em><br/>X<strong class="kr hi">=</strong> df<strong class="kr hi">.</strong>iloc[:,:<strong class="kr hi">-</strong>1] <em class="le">#Independent variable </em><br/>y<strong class="kr hi">=</strong> df['Churn_Value'] <em class="le">## Dependent variable</em><br/>X<strong class="kr hi">.</strong>head()</span></pre><h1 id="b5a0" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">5.特征工程</h1><ul class=""><li id="b781" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">对于名义上的数据:我们不能对数据进行排序，例如邮政编码</li><li id="3ef3" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">我们对序数数据做:我们可以给出一个等级，比如年级，教育状况</li></ul><p id="586d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们在这里做<strong class="is hi"> One_hot_encoding </strong>因为机器学习算法只理解数字数据，我们有一些预测器是分类类型的数据，我们将使用<code class="du ko kp kq kr b">get_dummies()</code></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="a266" class="jo jp hh kr b fi la lb l lc ld">X_encoded<strong class="kr hi">=</strong> pd<strong class="kr hi">.</strong>get_dummies(X,columns<strong class="kr hi">=</strong>['Gender','Senior_Citizen','Partner','Dependents','Phone_Service',<br/>                                    'Multiple_Lines','Internet_Service','Online_Security','Online_Backup',<br/>                                    'Device_Protection','Tech_Support','Streaming_TV','Contract','Paperless_Billing',<br/>                                    'Payment_Method','Streaming_Movies'])</span><span id="e2ff" class="jo jp hh kr b fi mf lb l lc ld"># Creating copy and stored in X variables</span><span id="45b1" class="jo jp hh kr b fi mf lb l lc ld">X<strong class="kr hi">=</strong>X_encoded<strong class="kr hi">.</strong>copy()<br/>X<strong class="kr hi">.</strong>shape</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es oj"><img src="../Images/1bebcfcd2a9a426414848ec8def79211.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*0FKySrgmaG5c_Np1V0LOzg.png"/></div></figure><h1 id="f8cf" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">6.构建XGBoost模型</h1><h2 id="65ae" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">XGBoost的优势</h2><p id="8bed" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">我一直很喜欢这项技术提供的预测模型增强功能。当我观察它的性能和高精度背后的物理原理时，我发现了几个好处:</p><h2 id="0d17" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">正规化:</h2><ul class=""><li id="5bf5" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">标准GBM实现没有XGBoost那样的正则化，因此它也有助于减少过度拟合。</li><li id="bae4" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">XGBoost也被称为“正则化增强”技术。</li></ul><p id="eac5" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们将把数据分成训练集和测试集，但在分割之前，让我们看看有多少人离开了公司，我们只需将所有的<strong class="is hi"> y=1 </strong>值相加，然后除以数据的总长度。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="f32c" class="jo jp hh kr b fi la lb l lc ld">sum(y)<strong class="kr hi">/</strong>len(y)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ok"><img src="../Images/0630132d761f5216e9914561218858c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*RjUuhblg9RZKszx3ZzrPnQ.png"/></div></figure><p id="1457" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi"> <em class="le">所以，看到只有27%的人离开了公司，所以得出的结论是数据集非常不平衡</em> </strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="e689" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Spliting the data</em><br/>X_train,X_test,y_train,y_test<strong class="kr hi">=</strong> train_test_split(X,y,random_state<strong class="kr hi">=</strong>42,stratify<strong class="kr hi">=</strong>y)</span></pre><p id="1e08" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在让我们验证一下<code class="du ko kp kq kr b">stratify</code>是否如预期的那样工作。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="51c8" class="jo jp hh kr b fi la lb l lc ld">sum(y_train)<strong class="kr hi">/</strong>len(y_train)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ok"><img src="../Images/0630132d761f5216e9914561218858c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*RjUuhblg9RZKszx3ZzrPnQ.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="5dc1" class="jo jp hh kr b fi la lb l lc ld">sum(y_test)<strong class="kr hi">/</strong>len(y_test)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ok"><img src="../Images/0630132d761f5216e9914561218858c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*RjUuhblg9RZKszx3ZzrPnQ.png"/></div></figure><p id="94b1" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><em class="le">验证</em> <code class="du ko kp kq kr b"><em class="le">stratify</em></code> <em class="le">按预期工作，y_train和y_test具有相同的百分比</em></p><p id="5c1d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">构建XGBoost模型</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="b9b7" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Lets build the Xgboost model without cross validation</em><br/>clf_xgb<strong class="kr hi">=</strong> xgb<strong class="kr hi">.</strong>XGBClassifier(objective<strong class="kr hi">=</strong>'binary:logistic',max_depth<strong class="kr hi">=</strong>5,learning_rate<strong class="kr hi">=</strong> 0.1,<br/>                           colsample_bytree <strong class="kr hi">=</strong> 0.5,<br/>                           subsample<strong class="kr hi">=</strong>0.90, reg_lambda<strong class="kr hi">=</strong> 10,use_label_encoder<strong class="kr hi">=False</strong>)</span></pre><p id="bdb4" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">拟合模型</strong></p><ul class=""><li id="d0d6" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn nq nr ns nt bi translated">这里early_stopping_rounds=10:表示如果在构建10棵以上的树之后预测没有改善</li><li id="2401" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">如果10个构建的树中没有一个不改进预测，那么它将停止。</li></ul><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="41c1" class="jo jp hh kr b fi la lb l lc ld">clf_xgb<strong class="kr hi">.</strong>fit(X_train,y_train,early_stopping_rounds<strong class="kr hi">=</strong>10,eval_metric<strong class="kr hi">=</strong>'aucpr',eval_set<strong class="kr hi">=</strong>[(X_test,y_test)])</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es ol"><img src="../Images/2ce7883b6cbea5585d803b33ee845c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nu2_GpJ2z1Tr9G3jdEedag.png"/></div></div></figure><p id="726d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">预测模型:</strong></p><p id="691d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这里我们将在X_test数据上预测模型。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="0ae7" class="jo jp hh kr b fi la lb l lc ld">y_pred<strong class="kr hi">=</strong> clf_xgb<strong class="kr hi">.</strong>predict(X_test)</span></pre><p id="8350" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">混乱矩阵</strong></p><p id="4040" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">这是一个机器学习分类问题的性能指标，有两个或更多的类作为输出。此表中有四种预测值和实际值的不同组合。</p><p id="fbc4" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">它对测量召回率、精确度、特异性、准确性以及最重要的AUC-ROC曲线非常有用。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="3d54" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># ploting the confusion matrics</em><br/>plot_confusion_matrix(clf_xgb,X_test,y_test,values_format<strong class="kr hi">=</strong>'d',display_labels<strong class="kr hi">=</strong>['did not left','left'])</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es om"><img src="../Images/d37eb25a872ed0b1c6b80aac6fd76706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*oL9yAvl-vfgWk4oCdq8qJg.png"/></div></figure><p id="fb9a" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">没有离开公司的人(91%)被正确分类。但不是模型在离开公司的人面前表现不好，只有48%的人正确分类。XGBoost有一个参数<code class="du ko kp kq kr b">scale_pos_weight</code>，可以帮助处理不平衡的数据。我们试图通过交叉验证来提高准确性。</p><p id="dbc0" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">现在我们将评估该模型，因为该数据集完全不平衡，所以我们将通过<code class="du ko kp kq kr b">roc_auc_score</code>获得准确性。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="ffd9" class="jo jp hh kr b fi la lb l lc ld">print('The accuracy of the model is:',roc_auc_score(y_test,y_pred))<br/><strong class="kr hi">from</strong> sklearn.metrics <strong class="kr hi">import</strong> classification_report<br/>print(classification_report(y_test,y_pred))</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es on"><img src="../Images/b5b397db1b292f3786e0c2e711c25b3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*MXFKssMQ9hDTYIomF_W-IA.png"/></div></figure><h1 id="f6cd" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">7.XGBoost参数</h1><p id="a9ed" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated"><strong class="is hi">最大深度[默认值=6] </strong></p><ul class=""><li id="3b6e" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn nq nr ns nt bi translated">树的最大深度，与GBM相同。</li><li id="260e" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">用于控制过度拟合，因为较高的深度将允许模型学习特定样本的特定关系。</li><li id="0ed6" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">应使用CV进行调整。</li><li id="18b5" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">典型值:3–10</li></ul><p id="a5ba" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">最大叶节点数</strong></p><ul class=""><li id="c0d5" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn nq nr ns nt bi translated">树中的最大终端节点或叶子数。</li><li id="eb4b" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">可以代替max_depth进行定义。由于二叉树被创建，深度“n”将产生最大的2^n叶。</li><li id="1c68" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">如果这样定义，GBM将忽略max_depth。</li></ul><h2 id="29f0" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">伽玛[默认值=0]</h2><ul class=""><li id="9518" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">只有当产生的分裂给出损失函数的正减少时，节点才被分裂。Gamma指定进行分割所需的最小损失减少量。</li><li id="63c7" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">使算法保守。这些值可能因损失函数而异，应该进行调整。</li></ul><h2 id="1af8" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">max _ delta _ step[默认值=0]</h2><ul class=""><li id="dcbf" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">在最大增量步骤中，我们允许每棵树的重量估计为。如果该值设置为0，则表示没有约束。如果将其设置为正值，则有助于使更新步骤更加保守。</li><li id="d694" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">通常，这个参数是不需要的，但是当类极度不平衡时，它可能有助于逻辑回归。</li><li id="d842" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">这通常不被使用，但是如果你愿意，你可以进一步探索。</li></ul><h2 id="d47b" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">子样本[默认值=1]</h2><ul class=""><li id="7162" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">同GBM子样本。表示每棵树的随机样本的观察分数。</li><li id="55f4" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">较低的值使算法更加保守，并防止过度拟合，但太小的值可能会导致拟合不足。</li><li id="085a" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">典型值:0.5–1</li></ul><h2 id="d41c" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">col sample _ bytree[默认值=1]</h2><ul class=""><li id="dad3" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">类似于GBM中的max_features。表示作为每个树的随机样本的列的比例。</li><li id="4cc6" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">典型值:0.5–1</li></ul><h2 id="6f86" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">col sample _ by level[默认值=1]</h2><ul class=""><li id="29c0" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">表示每个级别中每个拆分的列的子抽样比率。</li><li id="94bc" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">我不经常使用它，因为subsample和colsample_bytree会为您完成这项工作。但是如果你觉得可以进一步探索。</li></ul><h2 id="f628" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">λ[默认值=1]</h2><ul class=""><li id="331b" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">关于权重的L2正则化项(类似于岭回归)</li><li id="06ef" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">这用于处理XGBoost的正则化部分。虽然许多数据科学家不经常使用它，但应该探索它以减少过度拟合。</li></ul><h2 id="3555" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">alpha[默认值=0]</h2><ul class=""><li id="0d13" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">权重上的L1正则化项(类似于套索回归)</li><li id="2215" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">可以在非常高的维数的情况下使用，使得算法在实现时运行得更快</li></ul><h2 id="ca53" class="jo jp hh bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">scale _ pos _ weight[默认值=1]</h2><ul class=""><li id="b5b4" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">在高等级不平衡的情况下，应该使用大于0的值，因为它有助于更快地收敛。</li></ul><h1 id="e193" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">7.1网格搜索简历</h1><p id="49b5" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">网格搜索计算所有指定超参数及其值的每个组合的性能，然后为超参数选择最佳值。基于所涉及的超参数的数量，这使得处理耗时且成本高。</p><p id="9233" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">它需要四个参数:估计量、参数网格、cv和得分。以下是参数列表:</p><ol class=""><li id="ab30" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn oo nr ns nt bi translated">estimator–使用Scikit-learn构建的模型</li></ol><p id="c004" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">2.参数网格-包含参数值列表和参数名称作为关键字的字典。</p><p id="4992" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">3.评分——评估绩效的标准。例如，对于回归模型，使用“r2”，而对于分类模型，使用“precision”。</p><p id="57c0" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">4.cv-K-fold交叉验证的折叠数是一个整数。</p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="8252" class="jo jp hh kr b fi la lb l lc ld">param_grid<strong class="kr hi">=</strong>{'max_depth':[3,4,5],<br/>            'gamma':[0,0.25,1.0],<br/>            'learning_rate':[0.1,0.5,1.0],<br/>            'reg_lambda':[1,10,20],<br/>            'scale_pos_weight':[1,3,5],<br/>    <br/>}</span></pre><p id="a223" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">寻找最佳参数</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="ede7" class="jo jp hh kr b fi la lb l lc ld">optimal_param<strong class="kr hi">=</strong> GridSearchCV(estimator<strong class="kr hi">=</strong>xgb<strong class="kr hi">.</strong>XGBClassifier(objective<strong class="kr hi">=</strong>'binary:logistic',seed<strong class="kr hi">=</strong>42,<br/>                                                        subsample<strong class="kr hi">=</strong>0.9,colsample_bytree<strong class="kr hi">=</strong>0.5,use_label_encoder<strong class="kr hi">=False</strong>),<br/>                            param_grid<strong class="kr hi">=</strong>param_grid,<br/>                            scoring<strong class="kr hi">=</strong>'roc_auc',<br/>                            verbose<strong class="kr hi">=</strong>2, <br/>                            cv<strong class="kr hi">=</strong>3)</span></pre><p id="aabd" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">拟合网格搜索</strong></p><ul class=""><li id="add4" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn nq nr ns nt bi translated">找到最佳参数需要一些时间，对我来说，大约需要10分钟。</li></ul><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="e28b" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># fitting the gridsearch</em><br/>optimal_param<strong class="kr hi">.</strong>fit(X_train,y_train,early_stopping_rounds<strong class="kr hi">=</strong>10,eval_metric<strong class="kr hi">=</strong>'auc',eval_set<strong class="kr hi">=</strong>[(X_test,y_test)],verbose<strong class="kr hi">=False</strong>)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es op"><img src="../Images/1fc8b5c892a3936bf9b9e1c855dcad4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oxt1rU44l1KfcMy0ZcEmrw.png"/></div></div></figure><p id="c020" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">寻找最佳参数</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="dbb0" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Printing the best parameter</em><br/>print(optimal_param<strong class="kr hi">.</strong>best_params_)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es oq"><img src="../Images/37ebcd4af5008114267759d7f9d2ba6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0JbvDY7b07CFlKumDY8PEQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Best parameters</figcaption></figure><h1 id="c494" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">建立模型，评估模型</h1><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="6253" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># After getting the best parameter, now we will biuld the final classifier model</em><br/>clf_classifier<strong class="kr hi">=</strong> xgb<strong class="kr hi">.</strong>XGBClassifier(objective<strong class="kr hi">=</strong>'binary:logistic',<br/>                                  gamma<strong class="kr hi">=</strong>1.0,<br/>                                  learning_rate<strong class="kr hi">=</strong>0.1,<br/>                                  max_depth<strong class="kr hi">=</strong>3,<br/>                                  reg_lambda<strong class="kr hi">=</strong>10,<br/>                                  scale_pos_weight<strong class="kr hi">=</strong>3,<br/>                                  subsample<strong class="kr hi">=</strong>0.9, <br/>                                  colsample_bytree<strong class="kr hi">=</strong>0.50,<br/>                                  use_label_encoder<strong class="kr hi">=False</strong>)</span></pre><p id="5850" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">拟合模型</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="ccd2" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># fitting the model</em><br/>clf_classifier<strong class="kr hi">.</strong>fit(X_train,y_train,early_stopping_rounds<strong class="kr hi">=</strong>10,eval_metric<strong class="kr hi">=</strong>'aucpr',eval_set<strong class="kr hi">=</strong>[(X_test,y_test)]</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es or"><img src="../Images/23f4e74d29034d38c63802049e15251d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8F9p0VQaUDhJWi-Ue1qYJg.png"/></div></div></figure><p id="e393" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">预测最终模型</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="29a3" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Predicting the model</em><br/>y_pred<strong class="kr hi">=</strong> clf_classifier<strong class="kr hi">.</strong>predict(X_test)</span></pre><p id="772d" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">绘制最终模型的混淆度量</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="cfbb" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Plotting the confusion matrics</em><br/>plot_confusion_matrix(clf_classifier,X_test,y_test,values_format<strong class="kr hi">=</strong>'d',display_labels<strong class="kr hi">=</strong>['did not leave','left'])</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es os"><img src="../Images/d080b1473c5c248b2657177e72785a5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*j0-kvv8IcVjv4Lee8OmSpw.png"/></div></figure><p id="35c3" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">我们看到总人数<strong class="is hi"> 1294 </strong>和未离职人员<strong class="is hi"> 937 </strong> (72%)被正确分类。出<strong class="is hi"> 467 </strong>和出<strong class="is hi"> 385 </strong> (83%)正确分类。</p><p id="9c13" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">评估最终模型</strong></p><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="2a29" class="jo jp hh kr b fi la lb l lc ld"><em class="le"># Priting the accuracy and the model and lassification report</em><br/>print('The accuracy of the model:',roc_auc_score(y_test,y_pred))</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ot"><img src="../Images/4ec01626afdd2a8f8cce0c87d4403eed.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*mLL6C0ZUXeQm3nqSGrrA8g.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="16ec" class="jo jp hh kr b fi la lb l lc ld">print(classification_report(y_test,y_pred))</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ou"><img src="../Images/16c1e7396fc2b269ea0d26de97c23722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*KaJJS1ul_-Lj_M7sW5yR5g.png"/></div></figure><pre class="ks kt ku kv fd kw kr kx ky aw kz bi"><span id="1316" class="jo jp hh kr b fi la lb l lc ld"><strong class="kr hi">from</strong> sklearn.metrics <strong class="kr hi">import</strong> plot_precision_recall_curve<br/>plot_precision_recall_curve(clf_classifier,X_test,y_test)</span></pre><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ov"><img src="../Images/50ee6d91ccc1a3b557e34143d1a5feef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*Ygbhiu_ko_0BFieCULTzJQ.png"/></div></figure><p id="8fb1" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated"><strong class="is hi">我们提高了正确分类，离职率从52 %提高到82% </strong></p><h1 id="7be6" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">8.模型解释</h1><p id="da3f" class="pw-post-body-paragraph iq ir hh is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn ha bi translated">目标变量:流失值</p><ul class=""><li id="820c" class="nl nm hh is b it iu ix iy jb nn jf no jj np jn nq nr ns nt bi translated">合同期限(强):逐月合同的变动远远超过一年或两年的合同。</li><li id="76bd" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">互联网服务(中等):互联网光纤或DSL服务比其他服务发展更快。</li><li id="6e8b" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">家属(适度):支持家属(孩子/老人)的顾客不太愿意购买。</li><li id="c54f" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">(低)无纸计费:选择无纸计费的客户流失率更高。</li><li id="8e67" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">(低)流:指示消费者是否正在利用互联网服务来传输电视或电影。</li><li id="39d8" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">(低)自动支付:设置了自动支付的客户不太可能流失。</li><li id="bc44" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">(低)合作伙伴:已婚客户的离职率较低。</li><li id="0e5a" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">顾客的月费是根据平均顾客指数计算的。</li></ul><h1 id="4ee5" class="lf jp hh bd jq lg lh li ju lj lk ll jy lm ln lo kb lp lq lr ke ls lt lu kh lv bi translated">结论</h1><ul class=""><li id="ea9b" class="nl nm hh is b it kj ix kk jb og jf oh jj oi jn nq nr ns nt bi translated">该模型的AUC为78 %,这意味着它在大约五分之四的客户场景中是正确的。</li><li id="7ff0" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">召回表明，该模型正确预测了83%的客户流失案例。</li><li id="7332" class="nl nm hh is b it nu ix nv jb nw jf nx jj ny jn nq nr ns nt bi translated">该模型预测的假阳性率接近1/2，准确率为54%。</li></ul><p id="48eb" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">参考资料:</p><div class="ow ox ez fb oy oz"><a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab dw"><div class="pb ab pc cl cj pd"><h2 class="bd hi fi z dy pe ea eb pf ed ef hg bi translated">XGBoost参数| XGBoost参数调整</h2><div class="pg l"><h3 class="bd b fi z dy pe ea eb pf ed ef dx translated">XGBoost是一个强大的机器学习算法，特别是在速度和准确性方面，我们需要考虑…</h3></div><div class="ph l"><p class="bd b fp z dy pe ea eb pf ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn ij oz"/></div></div></a></div><p id="32af" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">在LinkedIn上关注我</p><div class="ow ox ez fb oy oz"><a href="https://www.linkedin.com/in/rahulsisodia06/" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab dw"><div class="pb ab pc cl cj pd"><h2 class="bd hi fi z dy pe ea eb pf ed ef hg bi translated">Rahul Sisodia -常春藤专业学校-新德里，德里，印度| LinkedIn</h2><div class="pg l"><h3 class="bd b fi z dy pe ea eb pf ed ef dx translated">拉胡尔非常热衷于数据科学和机器学习，他喜欢他所做的事情，并且总是…</h3></div><div class="ph l"><p class="bd b fp z dy pe ea eb pf ed ef dx translated">www.linkedin.com</p></div></div><div class="pi l"><div class="po l pk pl pm pi pn ij oz"/></div></div></a></div><p id="afa4" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ha bi translated">GitHub:</p><div class="ow ox ez fb oy oz"><a href="https://github.com/rahkum96" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab dw"><div class="pb ab pc cl cj pd"><h2 class="bd hi fi z dy pe ea eb pf ed ef hg bi translated">rahkum96 -概述</h2><div class="pg l"><h3 class="bd b fi z dy pe ea eb pf ed ef dx translated">AI和ML认证数据科学家。rahkum96有34个可用的存储库。在GitHub上关注他们的代码。</h3></div><div class="ph l"><p class="bd b fp z dy pe ea eb pf ed ef dx translated">github.com</p></div></div><div class="pi l"><div class="pp l pk pl pm pi pn ij oz"/></div></div></a></div><div class="ow ox ez fb oy oz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="pa ab dw"><div class="pb ab pc cl cj pd"><h2 class="bd hi fi z dy pe ea eb pf ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="pg l"><h3 class="bd b fi z dy pe ea eb pf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ph l"><p class="bd b fp z dy pe ea eb pf ed ef dx translated">medium.com</p></div></div><div class="pi l"><div class="pq l pk pl pm pi pn ij oz"/></div></div></a></div></div></div>    
</body>
</html>
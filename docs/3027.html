<html>
<head>
<title>Computer vision — Unet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉— Unet</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/computer-vision-unet-30d07500254c?source=collection_archive---------5-----------------------#2022-07-10">https://medium.com/mlearning-ai/computer-vision-unet-30d07500254c?source=collection_archive---------5-----------------------#2022-07-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7945" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">今天，我们来谈谈著名的卷积网络架构Unet。它的名字是基于它的形状，我们将在后面看到。这篇文章将主要由原文引导，原文可以在这里找到。</p><h2 id="974a" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">语义分割</h2><p id="659a" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">使用卷积层的动机是对局部平移的不变性，当我们更关心特征的存在，而不是它的确切位置时。</p><p id="de04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当你第一次开始学习卷积神经网络时，卷积可能会用在用来对图片进行分类的模型中。例如，您希望预测图片中是否包含某种特定的动物、对象甚至人。</p><p id="2906" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，我们经常希望定位每个像素。期望的输出是分割成不同区域的图像，从而降低机器理解图像的复杂性。这在生物医学图像处理和自动驾驶汽车方面非常有用。</p><p id="4ee9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看一些语义分段的实际例子:</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es kd"><img src="../Images/354b7ab1d3da7103036533723003ae23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFpcut08Alhv3BNSPnQQaw.jpeg"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx">semantic segmentation used for self-driving cars</figcaption></figure><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es kt"><img src="../Images/a29e25ebf686de102ed47129f9afa2a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WAH73vII2XvCc26yQxwFLg.jpeg"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx">semantic segmentation of MRI scans</figcaption></figure><p id="4e34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">改版:</strong></p><p id="4a24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你不太熟悉卷积以及它们是如何应用的，强烈建议你在这里看看briliant blogpost:</p><div class="ku kv ez fb kw kx"><a href="https://cs231n.github.io/convolutional-networks/#conv" rel="noopener  ugc nofollow" target="_blank"><div class="ky ab dw"><div class="kz ab la cl cj lb"><h2 class="bd hi fi z dy lc ea eb ld ed ef hg bi translated">用于视觉识别的CS231n卷积神经网络</h2><div class="le l"><h3 class="bd b fi z dy lc ea eb ld ed ef dx translated">目录:卷积神经网络非常类似于以前的普通神经网络…</h3></div><div class="lf l"><p class="bd b fp z dy lc ea eb ld ed ef dx translated">cs231n.github.io</p></div></div><div class="lg l"><div class="lh l li lj lk lg ll kn kx"/></div></div></a></div><h2 id="005e" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">建筑</h2><p id="fa5b" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">现在，我们了解了什么是语义分割，是时候看看模型的构建块了，它非常擅长制作这些模板。</p><p id="05b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Unet具有下采样—编码器和下采样—解码器部分。关于Unet的一个关键点是，它还具有将信息传播到更高分辨率层的跳过连接或特征通道。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es lm"><img src="../Images/342f2c88bc2f14bea027a44026df8a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvXoKMHoPJMKpKK7keZMEA.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx">Unet architecture</figcaption></figure><p id="7009" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ln">编码器</em></p><p id="07d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码器由重复的<strong class="ig hi"> 3x3 </strong>卷积组成，ReLU作为线性激活函数将非线性引入模型，然后是maxpooling运算。在每个下采样步骤中，通道的数量加倍。</p><p id="fba7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ln">解码器</em></p><p id="c4bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解码器通过上采样层组合空间信息和特征信息，然后与来自编码器的更高分辨率特征连接。在每个上采样步骤，通道的数量减半。最后一步是<strong class="ig hi"> 1x1 </strong>卷积，将64分量特征映射到<strong class="ig hi"> 23 </strong>卷积层。</p><p id="95f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ln">跳过</em> <em class="ln">连接</em></p><p id="92e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">跳过连接有助于通过在编码器部分学习的细节从解码器构建图像。</p><p id="8814" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在论文中还提到，选择输入大小很重要，这样最大池操作就可以应用于均匀的<em class="ln"> x，y </em>大小。</p><p id="f749" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">训练和损失功能</strong></p><p id="a8e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在最初的论文中，他们将soft-max与交叉熵损失函数相结合。我想详细说明论文中给出的公式，因为乍一看可能不清楚。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es lo"><img src="../Images/abbc131897e634f1baaaba82b2ec19de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*liCN1VKIw0CVNQoYD2kngA.png"/></div></figure><p id="54e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="ln"/></strong>表示位置<strong class="ig hi"> <em class="ln"> x </em> </strong>处像素的真实标签。例如，如果像素是第一类的一部分，则<strong class="ig hi"> <em class="ln"> l(x)= 1 </em> </strong>。现在我们将<strong class="ig hi"> <em class="ln"> p_k </em> </strong>计算为:</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es lp"><img src="../Images/a04d581c73e24dcf09c06925ccc0c28b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YRZbkxr0pXiv7n9p08fRfw.png"/></div></div></figure><p id="d2df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<strong class="ig hi"> <em class="ln"> a_k </em> </strong>为特征通道<strong class="ig hi"> <em class="ln"> k </em> </strong>中位置<strong class="ig hi"><em class="ln">x</em></strong><strong class="ig hi"><em class="ln">k</em></strong>为类数。因此如果<strong class="ig hi"> <em class="ln"> l(x) = 1 </em> </strong>，我们就会有<strong class="ig hi"> <em class="ln"> p1(x) </em> </strong>。</p><p id="3511" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了迫使网络学会准确预测同一类对象之间的边界，他们引入了加权损失:</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es lq"><img src="../Images/989724bbb84fabf69c9c66fbcdfc4222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSgGupCEXHg8HfFWuJPpSg.png"/></div></div></figure><p id="3bf6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<strong class="ig hi"> <em class="ln"> wc(x) </em> </strong>为加权类映射。计算它的步骤是:</p><ul class=""><li id="422e" class="lr ls hh ig b ih ii il im ip lt it lu ix lv jb lw lx ly lz bi translated">对于每个类，计算地面真实中有多少像素属于该类</li><li id="0ac1" class="lr ls hh ig b ih ma il mb ip mc it md ix me jb lw lx ly lz bi translated">对于形状为一个输入图像的wc(x)中的每个像素，将概率指定为1/(上面计算的数)</li><li id="b7b8" class="lr ls hh ig b ih ma il mb ip mc it md ix me jb lw lx ly lz bi translated">将地图中的所有值除以地图的最大值，使背景的权重为1</li></ul><p id="d04f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="ln">【w0(x)</em></strong>是在原纸中分别设置为10和5的常数。<strong class="ig hi"><em class="ln">【D1(x)</em></strong>和<strong class="ig hi"> <em class="ln"> d2(x) </em> </strong>是如文中所说的到前两个最近单元格的距离。</p><p id="8467" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是可视化，你可以看到更多的重量在物体之间的边界上。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es mf"><img src="../Images/e83ff62117a456ef3bcb63982d416614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5B69Si49EqRYpDvYpGZOg.png"/></div></div></figure><p id="cc32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ln">应用</em> </strong></p><p id="fc53" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">语义分割在向计算机提供感知方面非常有用。例如，自主车需要理解环境，语义符号可以帮助它识别道路和与道路相交的物体。在图像诊断中，它可以帮助医生管理x射线的方向，以便其他健康的器官受到最小的辐射。</p><p id="8d8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有趣的kaggle数据集可以为您提供实践服务:</p><ul class=""><li id="e7be" class="lr ls hh ig b ih ii il im ip lt it lu ix lv jb lw lx ly lz bi translated"><a class="ae jc" href="https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/competitions/uw-Madison-gi-tract-image-segmentation/data</a></li><li id="f3c3" class="lr ls hh ig b ih ma il mb ip mc it md ix me jb lw lx ly lz bi translated"><a class="ae jc" href="https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/mateuszbuda/LGG-MRI-segmentation</a></li><li id="91a6" class="lr ls hh ig b ih ma il mb ip mc it md ix me jb lw lx ly lz bi translated"><a class="ae jc" href="https://www.kaggle.com/datasets/kumaresanmanickavelu/lyft-udacity-challenge" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/kumaresanmanickavelu/lyft-uda city-challenge</a></li></ul><p id="9956" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ln">参考文献</em> </strong>:</p><ul class=""><li id="259a" class="lr ls hh ig b ih ii il im ip lt it lu ix lv jb lw lx ly lz bi translated"><a class="ae jc" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></li><li id="18f9" class="lr ls hh ig b ih ma il mb ip mc it md ix me jb lw lx ly lz bi translated"><a class="ae jc" href="https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47" rel="noopener" target="_blank">https://towards data science . com/understanding-semantic-segmentation-with-unet-6 be 4f 42 D4 b 47</a></li><li id="3af4" class="lr ls hh ig b ih ma il mb ip mc it md ix me jb lw lx ly lz bi translated"><a class="ae jc" href="https://doi.org/10.48550/arXiv.1505.04597" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.1505.04597</a></li></ul><div class="ku kv ez fb kw kx"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ky ab dw"><div class="kz ab la cl cj lb"><h2 class="bd hi fi z dy lc ea eb ld ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="le l"><h3 class="bd b fi z dy lc ea eb ld ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lf l"><p class="bd b fp z dy lc ea eb ld ed ef dx translated">medium.com</p></div></div><div class="lg l"><div class="mg l li lj lk lg ll kn kx"/></div></div></a></div></div></div>    
</body>
</html>
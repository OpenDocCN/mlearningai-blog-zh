<html>
<head>
<title>Using Mean squared error loss (MSE) in Logistic Regression?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在逻辑回归中使用均方误差损失(MSE)？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/using-mean-squared-error-loss-mse-in-logistic-regression-bcc5e07a6d99?source=collection_archive---------6-----------------------#2022-11-13">https://medium.com/mlearning-ai/using-mean-squared-error-loss-mse-in-logistic-regression-bcc5e07a6d99?source=collection_archive---------6-----------------------#2022-11-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="50f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我一直在重温一些濒临从我的记忆中消失的算法/概念:)在修改逻辑回归时，我意识到我从未关注过一些微小的细节。为什么我们在训练一个逻辑回归模型的时候不用MSE损失呢？在谷歌上搜索了不同的来源后，我明白了以下几点== &gt;</p><p id="f346" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在深入回答之前，让我们先复习一些概念</p><p id="10b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可能知道，通常对数损失(也称为交叉熵损失)用于训练逻辑回归分类模型。相同的公式如下</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/ba1235d6b6070100351319ee5d687431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JX64dkxTbQ6Q3c1D.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">LogLoss Formula</figcaption></figure><blockquote class="js jt ju"><p id="59ca" class="ie if jv ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">其中y是实际值或标签</p><p id="1a73" class="ie if jv ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">p是模型的预测值。</p></blockquote><p id="be54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个对数损失是一个凸函数，这意味着图中只存在一个局部极小值。并且如同任何其他ML算法一样，梯度下降被用于优化，其寻找系数的最佳值，使得成本函数值最低。如果你还记得梯度下降的一个主要条件是，图应该只有一个局部最小值，它迭代并试图找到最优值。</p><p id="2b6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们通过绘制对数损失函数来了解这一点。将复杂的事情分解成更小的部分总会让你更容易更快地理解。让我们把对数损失函数分解成几个部分。根据yi的值，应该是这样的== &gt;</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jz"><img src="../Images/e1fb4cf8a04f5bd993a9d77fc38af1e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/0*CvT9FOslfQecaRWA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Plot of CrossEntropyLoss</figcaption></figure><p id="a28e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单地说，可以在α= 0.5找到局部最小值。这就是为什么凸函数在梯度下降中是重要的，否则算法将永远不会在一个非凸函数中找到精确的局部最小值，因为它包含不止一个最小值。</p><p id="bfb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们继续我们的主题，为什么MSE损失不用于逻辑回归。上面提到的整个语境足以理解其中的原因。</p><h1 id="5a9c" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak"> 1。非凸性质</strong></h1><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ky"><img src="../Images/5670cdad98a45c7d58181e67a8f93971.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*lNAlzMHEsj1o3UEOu5ZoSg.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Convex vs Concave plots.</figcaption></figure><p id="9c85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于逻辑回归，均方误差函数的图形是非凸的。因为我们把因变量x放在一个非线性的sigmoid函数中。如上所述，梯度下降不适用于非凸函数，逻辑回归模型将永远无法收敛到最优值。</p><h1 id="b79f" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak"> 2。对错误预测的惩罚。</strong></h1><p id="55e5" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">好吧，如果你不关心优化和寻找最佳局部最小值，但仍然想使用MSE损失，它仍然不会工作。为什么？</p><p id="1c6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我问你，成本函数/损失函数的功是什么？</p><blockquote class="js jt ju"><p id="aa55" class="ie if jv ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">基本上，在错误预测的情况下，成本函数应该能够通过输出最终将导致更高梯度值的更高损失值来惩罚模型。</p></blockquote><p id="c350" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是逻辑回归中使用的均方误差并没有以很大的方式惩罚模型。理想情况下，对于错误的类预测，MSELoss应该很高，但这不会发生，原因是逻辑回归用于分类，并且所有预测的概率值都在0，1之间。</p><p id="e622" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设在一个二进制分类问题中，您的模型预测第1类的概率为0.1(这是一个错误分类的明显例子)。</p><blockquote class="js jt ju"><p id="a6ef" class="ie if jv ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">这里我们的<strong class="ig hi"> Y_Actual=1 </strong>和<strong class="ig hi"> Y_Pred=0.1 </strong></p></blockquote><p id="4dca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">理想情况下，对于好的成本函数，惩罚/误差值应该很高。让我们比较相同的均方误差和对数损失</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es le"><img src="../Images/e9d5383a65635d4aef76b9d11f8a845c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*GhqyJIi5uZW-JqH9Sx9CoQ.png"/></div></figure><p id="f606" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望现在清楚了为什么MSE损失在逻辑回归中不是一个好的选择。尽管分类错误，MSE仍然用比logloss更低的值来惩罚模型。</p><p id="4780" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">谢谢大家！</p><p id="bbe3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请关注更多如此优秀的博客:)</p><p id="4d89" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://www.linkedin.com/in/pranav-kushare-ab217418a/" rel="noopener ugc nofollow" target="_blank">T5】领英T7】</a></p><p id="87f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://www.buymeacoffee.com/PranavK" rel="noopener ugc nofollow" target="_blank"> <em class="jv">给我买杯咖啡</em> </a></p><p id="a649" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://github.com/Pranav082001" rel="noopener ugc nofollow" target="_blank"> <em class="jv"> Github </em> </a></p><div class="lg lh ez fb li lj"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lk ab dw"><div class="ll ab lm cl cj ln"><h2 class="bd hi fi z dy lo ea eb lp ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lq l"><h3 class="bd b fi z dy lo ea eb lp ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lr l"><p class="bd b fp z dy lo ea eb lp ed ef dx translated">medium.com</p></div></div><div class="ls l"><div class="lt l lu lv lw ls lx jm lj"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Use SynapseML to process large scale pdf with Form Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SynapseML通过表单识别处理大型pdf</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/use-synapseml-to-process-large-scale-pdf-with-form-recognition-d56ccd854ef5?source=collection_archive---------4-----------------------#2022-07-16">https://medium.com/mlearning-ai/use-synapseml-to-process-large-scale-pdf-with-form-recognition-d56ccd854ef5?source=collection_archive---------4-----------------------#2022-07-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="d56f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用Azure认知服务通过表单识别处理大规模pdf</h1><h1 id="814d" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">先决条件</h1><ul class=""><li id="f6ab" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="9b15" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure存储帐户</li><li id="23d7" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure认知服务</li><li id="555a" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure synapse分析</li><li id="e2c1" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建一个容器并上传pdf文件</li><li id="54bd" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">为容器创建一个SAS密钥</li></ul><h1 id="5515" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用SynapseML和Spark的流程</h1><ul class=""><li id="14d6" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">创建火花3.2预览火花池</li><li id="d333" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建一个新笔记本，并选择创建的新池</li><li id="a432" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">现在加载最新的synapseml预览版用于文档api处理</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="fd06" class="ki if hh ke b fi kj kk l kl km">%%configure -f<br/>{<br/>    "name": "synapseml",<br/>    "conf": {<br/>        "spark.jars.packages": "com.microsoft.azure:synapseml_2.12:0.9.5-103-4975dda5-SNAPSHOT",<br/>        "spark.jars.repositories": "https://mmlspark.azureedge.net/maven",<br/>        "spark.jars.excludes": "org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12",<br/>        "spark.yarn.user.classpath.first": "true"<br/>    }<br/>}</span></pre><ul class=""><li id="5679" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">让我们导入必要的库</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="3209" class="ki if hh ke b fi kj kk l kl km">import os<br/>if os.environ.get("AZURE_SERVICE", None) == "Microsoft.ProjectArcadia":<br/>    from pyspark.sql import SparkSession<br/>    spark = SparkSession.builder.getOrCreate()</span></pre><ul class=""><li id="8f1c" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在普通图书馆</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="f8ab" class="ki if hh ke b fi kj kk l kl km">from pyspark.sql.functions import udf, col<br/>from synapse.ml.io.http import HTTPTransformer, http_udf<br/>from requests import Request<br/>from pyspark.sql.functions import lit<br/>from pyspark.ml import PipelineModel<br/>from pyspark.sql.functions import col<br/>import os</span></pre><ul class=""><li id="1a0d" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">让我们导入synapseml</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6c50" class="ki if hh ke b fi kj kk l kl km">from synapse.ml.cognitive import *</span></pre><ul class=""><li id="4e35" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在让我们阅读一些图片并进行测试</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="bfdb" class="ki if hh ke b fi kj kk l kl km">from pyspark.sql.functions import col, explode</span><span id="cf4e" class="ki if hh ke b fi ks kk l kl km"># Create a dataframe containing the source files<br/>imageDf = spark.createDataFrame([<br/>  ("https://storagename.dfs.core.windows.net/containername/billoflading/billofladding1.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/billofladding2.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/BillofLading_Labeled_resized.jpg?sp=r&amp;st=2022xxx",)<br/>], ["source",])</span><span id="b879" class="ki if hh ke b fi ks kk l kl km"># Run the Form Recognizer service<br/>analyzeLayouts = (AnalyzeDocument()<br/>                 .setSubscriptionKey("xxxxxxxxxxxxxxxxxxxxxxxxxxx")<br/>                 .setLocation("eastus2")<br/>                 .setPrebuiltModelId("prebuilt-document")<br/>                 .setImageUrlCol("source")<br/>                 .setOutputCol("Layouts"))<br/># Show the results of recognition.<br/>display(analyzeLayouts<br/>        .transform(imageDf)<br/>        .withColumn("documentsresult", col("Layouts.analyzeResult"))<br/>        .select("source", "documentsresult"))</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kt"><img src="../Images/5f482bd851398fb986792b4f41209502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oPQHpIiPUKwwlkc5.jpg"/></div></div></figure><ul class=""><li id="e58c" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">仅提取密钥对</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="5345" class="ki if hh ke b fi kj kk l kl km">from pyspark.sql.functions import col, explode</span><span id="4e58" class="ki if hh ke b fi ks kk l kl km"># Create a dataframe containing the source files<br/>imageDf = spark.createDataFrame([<br/>  ("https://storagename.dfs.core.windows.net/containername/billoflading/billofladding1.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/billofladding2.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/BillofLading_Labeled_resized.jpg?sp=r&amp;st=2022xxx",)<br/>], ["source",])</span><span id="0f74" class="ki if hh ke b fi ks kk l kl km"># Run the Form Recognizer service<br/>analyzeLayouts = (AnalyzeDocument()<br/>                 .setSubscriptionKey("xxxxxxxxxxxxxxxxxxxxxxxxxxx")<br/>                 .setLocation("eastus2")<br/>                 .setPrebuiltModelId("prebuilt-document")<br/>                 .setImageUrlCol("source")<br/>                 .setOutputCol("Layouts"))<br/># Show the results of recognition.<br/>display(analyzeLayouts<br/>        .transform(imageDf)<br/>        .withColumn("documentsresult", col("Layouts.analyzeResult.keyValuePairs"))<br/>        .select("source", "documentsresult"))</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lb"><img src="../Images/4b95a9e6932a47ae865ca2587f2a2802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9B3vtjDvW18BFmoW.jpg"/></div></div></figure><ul class=""><li id="fd91" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">仅显示实体</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="7bc0" class="ki if hh ke b fi kj kk l kl km"># Show the results of recognition.<br/>display(analyzeLayouts<br/>        .transform(imageDf)<br/>        .withColumn("documentsresult", col("Layouts.analyzeResult.entities"))<br/>        .select("source", "documentsresult"))</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lc"><img src="../Images/28d88c37daa09a6dc06df62f985eb8b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oTZszSXk9JYwhRBv.jpg"/></div></div></figure><ul class=""><li id="28af" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在只有桌子</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="b00a" class="ki if hh ke b fi kj kk l kl km"># Show the results of recognition.<br/>display(analyzeLayouts<br/>        .transform(imageDf)<br/>        .withColumn("documentsresult", col("Layouts.analyzeResult.tables"))<br/>        .select("source", "documentsresult"))</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es ld"><img src="../Images/246738b01ca98cb9077b32e4d3815c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lgKbxbTMv52a7lPN.jpg"/></div></div></figure><h1 id="847b" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">分析布局</h1><ul class=""><li id="adcd" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">使用布局api</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="692f" class="ki if hh ke b fi kj kk l kl km">from pyspark.sql.functions import col, explode</span><span id="5c82" class="ki if hh ke b fi ks kk l kl km"># Create a dataframe containing the source files<br/>imageDf = spark.createDataFrame([<br/>  ("https://storagename.dfs.core.windows.net/containername/billoflading/billofladding1.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/billofladding2.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/BillofLading_Labeled_resized.jpg?sp=r&amp;st=2022xxx",)<br/>], ["source",])</span><span id="5ac1" class="ki if hh ke b fi ks kk l kl km"># Run the Form Recognizer service<br/>analyzeLayouts = (AnalyzeLayout()<br/>                 .setSubscriptionKey("xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")<br/>                 .setLocation("westus2")<br/>                 .setImageUrlCol("source")<br/>                 .setOutputCol("Layouts"))<br/># Show the results of recognition.<br/>display(analyzeLayouts<br/>        .transform(imageDf)<br/>        .withColumn("documentsresult", explode(col("Layouts.analyzeResult.readResults")))<br/>        .select("source", "documentsresult"))</span></pre><ul class=""><li id="de42" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在显示页面结果</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="66bd" class="ki if hh ke b fi kj kk l kl km">from pyspark.sql.functions import col, explode</span><span id="b247" class="ki if hh ke b fi ks kk l kl km"># Create a dataframe containing the source files<br/>imageDf = spark.createDataFrame([<br/>  ("https://storagename.dfs.core.windows.net/containername/billoflading/billofladding1.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/billofladding2.png?sp=r&amp;st=2022xxxx",),<br/>  "https://storagename.dfs.core.windows.net/containername/billoflading/BillofLading_Labeled_resized.jpg?sp=r&amp;st=2022xxx",)<br/>], ["source",])</span><span id="38a7" class="ki if hh ke b fi ks kk l kl km"># Run the Form Recognizer service<br/>analyzeLayouts = (AnalyzeLayout()<br/>                 .setSubscriptionKey("xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")<br/>                 .setLocation("westus2")<br/>                 .setImageUrlCol("source")<br/>                 .setOutputCol("Layouts"))<br/># Show the results of recognition.<br/>display(analyzeLayouts<br/>        .transform(imageDf)<br/>        .withColumn("documentsresult", explode(col("Layouts.analyzeResult.pageResults")))<br/>        .select("source", "documentsresult"))</span></pre><h1 id="bafd" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">将大批量作为数据帧处理</h1><ul class=""><li id="3462" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">设置root和sas键</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="806b" class="ki if hh ke b fi kj kk l kl km">root = "https://storagename.dfs.core.windows.net/containername/billoflading/"<br/>sas = "?sp=r&amp;st=2022-xxxxxxx"</span></pre><ul class=""><li id="ca21" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">让我们创建一个函数来解析abfss文件url并为数据添加http</li><li id="c116" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">abfss是数据帧理解加载到spark数据帧中的内容</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="ac60" class="ki if hh ke b fi kj kk l kl km">from pyspark.sql.functions import udf<br/>from pyspark.sql.types import StringType</span><span id="320c" class="ki if hh ke b fi ks kk l kl km">def blob_to_url(blob):<br/>  [prefix, postfix] = blob.split("@")<br/>  container = prefix.split("/")[-1]<br/>  split_postfix = postfix.split("/")<br/>  account = split_postfix[0]<br/>  filepath = "/".join(split_postfix[1:])<br/>  return "https://{}/{}/{}".format(account, container, filepath) + sas</span></pre><ul class=""><li id="99e8" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">为容器添加sas密钥以获得对文件的权限</li><li id="6619" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">现在加载数据帧</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6924" class="ki if hh ke b fi kj kk l kl km">df2 = (spark.read.format("binaryFile")<br/>       .load("abfss://containername@storageaccount.dfs.core.windows.net/billoflading/*")<br/>       .select("path")<br/>       .limit(10)<br/>       .select(udf(blob_to_url, StringType())("path").alias("url"))<br/>       .cache()<br/>      )</span></pre><ul class=""><li id="ea02" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">设置cog svc订阅密钥</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6af5" class="ki if hh ke b fi kj kk l kl km">key = "xxxxxx"</span></pre><ul class=""><li id="5d36" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在调用文档api</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="8756" class="ki if hh ke b fi kj kk l kl km">from synapse.ml.cognitive import *</span><span id="374f" class="ki if hh ke b fi ks kk l kl km">analyzed_df = (AnalyzeDocument()<br/>  .setSubscriptionKey(key)<br/>  .setLocation("eastus")<br/>  .setPrebuiltModelId("prebuilt-document")<br/>  .setImageUrlCol("url")<br/>  .setOutputCol("Layouts")<br/>  .setErrorCol("errors")<br/>  .setConcurrency(5)<br/>  .transform(df2)<br/>  .cache())</span></pre><ul class=""><li id="f8b9" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在让我们分析结果</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="aee3" class="ki if hh ke b fi kj kk l kl km"># Show the results of recognition.<br/>display(analyzed_df)</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es le"><img src="../Images/560a2f11af1b5739ea056aea2b8e9991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pFCeCo7HXjTtTazX.jpg"/></div></div></figure><ul class=""><li id="e489" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在让我们写回数据帧的输出，以便进一步处理</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="e014" class="ki if hh ke b fi kj kk l kl km">path = "abfss://containername@storagename.dfs.core.windows.net/billofladingoutput/"<br/>analyzed_df.write.format("parquet").mode("overwrite").save(path)</span></pre></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><p id="a907" class="pw-post-body-paragraph lm ln hh je b jf kn lo lp jh ko lq lr jj ls lt lu jl lv lw lx jn ly lz ma jp ha bi translated"><em class="mb">最初发表于</em><a class="ae mc" href="https://github.com/balakreshnan/Samples2022/blob/main/SynapseSpark/synapsemlcogform.md" rel="noopener ugc nofollow" target="_blank"><em class="mb">【https://github.com】</em></a><em class="mb">。</em></p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu kz mg"/></div></div></a></div></div></div>    
</body>
</html>
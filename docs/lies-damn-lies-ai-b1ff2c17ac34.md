# 谎言，该死的谎言&唉

> 原文：<https://medium.com/mlearning-ai/lies-damn-lies-ai-b1ff2c17ac34?source=collection_archive---------0----------------------->

![](img/52e4d021a941bb60bd8f104c9d41438e.png)

# 机器会说谎吗？

你可能从未听说过利亚姆·波尔。

当利亚姆决定尝试有史以来最强大的自然语言深度神经网络模型 GPT-3(稍后将详细介绍 GPT-3)时，他是伯克利的一名大学生。利用它，他创建了许多完全由机器生成的博客帖子。他的帖子在两周内达到了 26，000 人，其中一些人订阅了“他的”博客。

> *我会写标题和介绍，加上一张照片，然后让 GPT-3 做剩下的事情。该博客已经有超过 26000 名访客，我们现在有大约 60 名忠实订户……*
> 
> *也只有* ***一个人*** *注意到它是 GPT-3 写的。*
> 
> 利亚姆·波尔，2020 年 8 月

事实上，第一篇[帖子](https://adolos.substack.com/p/feeling-unproductive-maybe-you-should)登上了 Y-Combinator 非常受欢迎的[黑客新闻](https://news.ycombinator.com/)网站的**第一名。有趣的是，暗示这篇博文是人为生成的少数评论实际上被社区否决了。**

惊讶吗？

你不应该这样。人们是懒惰的机器，我们经常相信[强化了我们先前的信念](https://en.wikipedia.org/wiki/Confirmation_bias)，我们几乎不去尝试，也没有时间和资源去核实我们每天接触到的巨大信息流。这实际上是我们最基本的架构。人们是节能的，大脑发展到尽可能节能，他们必须这样做。

我们的大脑喜欢熟悉的、温暖舒适的模式。从卡路里的角度来说，学习新的模式是一种努力。认知心理学实验表明，当解决现实世界的问题时，我们总是更喜欢使用以前学习的模式，即使存在其他(有时更简单)的方法。因此，当引入新数据时，无论是文本数据还是其他数据，我们都倾向于将其放入众所周知的思维定势中。当 Porr 文章的博客读者浏览这些文章时，他们会自动将这些文章与他们过去读过的类似文章进行比较。一旦这种潜意识的比较没有任何奇怪之处，他们得出结论，该文本是人类的合法作品。

但这就是 GPT 3 号的意义所在。基于对数十亿现有文本的学习和建模，复制人类文本。他们怎么能看出区别呢？

# 谎言比真相传播得快

有句老话说，在真理穿上靴子之前，谎言可以走遍半个世界，然而，这不再是一句谚语，而是现实。

为了证明这一点，麻省理工学院教授 Soroush Vosoughi 使用了 2006 年至 2017 年推特上的一组谣言。他报告说，大约有 300 万人散布了 126，000 个谣言。虚假的消息比真实的消息接触到更多的人；前 1%的虚假新闻扩散到 1000 到 100，000 人之间，而真相很少扩散到 1000 人以上。谎言也比真相传播得更快(参见[真假新闻在线传播](https://science.sciencemag.org/content/359/6380/1146)，麻省理工学院)。

所以看起来我们很不擅长辨别真假。甚至看起来我们并不在乎(只要他们证实了我们的信念)。此外，在当前快速通信和个人出版的世界中，我们往往比事实数据和真相更快地传播虚假，并被有意调整以推广流行数据的有偏见的算法进一步放大。

但情况变得更糟了。

公司现在提供假新闻机器人农场，虚假的社会网络简介，和虚假放大。这个行业一直低调行事，但毫无疑问，它正在蓬勃发展。随着时间的推移，社交网络假档案被建立和维护以模拟真实的人的档案，人类文本生成器被用来创建看起来真实(但虚假)的新闻文章，精心制作的工具被用来搭载社交网络和搜索引擎算法，以便大规模传播前者。

反乌托邦？

进入[人工通用智能](https://en.wikipedia.org/wiki/Artificial_general_intelligence)。

# 什么是 GPT-3

对人工智能(AI)的探索已经有几个世纪的历史了，可以追溯到玛丽·谢利的[T3]弗兰肯斯坦 T5]或卡雷尔·恰佩克](https://en.wikipedia.org/wiki/Frankenstein)的[。早期的黑客建造机器，这些机器在 20 世纪 90 年代初由于缺乏计算能力和有效的算法而被放弃，只是在过去十年里又卷土重来。深度学习(使用多层类脑神经元)已经成为创造机器的事实标准，这些机器可以解决特定领域的问题，如驾驶汽车或诊断病人。然而，圣杯过去是，现在仍然是，建造一台能够像人类一样理解和行动的机器，也就是说，具有一般(然而是人工)智能。](https://en.wikipedia.org/wiki/Karel_%C4%8Capek)

GPT-3 是解决 GAI 问题的黑客之一，而且相当不错。这是一个深度神经网络，已经通过在线可用的大多数文本进行了训练。通俗地说，它是一个模仿人脑的计算机模型，可以阅读(几乎)互联网上的所有内容。

为了理解 GPT-3，人们可以依靠众所周知的搜索查询自动完成。一旦你开始输入一个搜索查询，搜索引擎会根据其他人之前看到的查询尽量完善你的句子。这种基本(但有效)的机制是一种原始的生成语言模型，其当前的艺术状态是 [Open AI](https://openai.com/) 的 GPT-3。

一旦该模型经过数十亿个句子(来自自然语言或编程语言)的训练，它就学会了单个以及多个单词序列之间的复杂关系。然后可以向它提供一个文本片段，生成一个适当的“后续”文本片段。一旦完成，它就获取生成的代码片段，并基于后者继续创建更多的文本。这听起来可能很简单，但这种方法被证明可以成功地创建真实的(伪造的)新闻文章，甚至人工生成的采访，以及功能齐全、正确的计算机代码。

你不想让它落入坏人之手，对吧？太晚了。

GPT-3 现在是在公共领域，每个人都可以填写表格，成为测试用户(在付费模式之上，也是公开的，不太贵)。事实上，这正是利亚姆·波尔所做的。他所要做的就是从现有的博客文章中抓取一些热门标题，输入到机器中，然后在他的(假)博客中发布结果。没有人(嗯，26，000 名读者中的大多数)不能做出改变。

现在想象一下，一个不稳定的亿万富翁，或者一个外国势力大规模使用这样的工具来扭曲民主选举，或者操纵公众舆论，以便对已经分裂的社会造成严重破坏。

# 坏机器

大约在 2016 年，微软发布了一个名为 [Tay](https://www.theverge.com/2016/3/23/11290200/tay-ai-chatbot-released-microsoft) 的 Twitter 机器人，它应该能够从 Twitter 上学习“对话理解”，并以一种“随意而有趣”的方式做出回应。Twitter 只用了不到 24 小时就把无辜的 AI 聊天机器人变成了一只羽翼丰满的纳粹种族主义者和肌源性猪。这不是由于机器人的错误行为。

微软迅速将 Tay 从网络中移除，但事实仍然是，Tay——本质上是一只与互联网连接的机器人鹦鹉——只是向用户重复了人类的共同情感。泰本身并不是一台*坏*机器，然而，如果它无人看管并被误认为是人类，泰可能会以进一步分裂本已四分五裂的社会的方式放大有毒话语。

现在想象成千上万的泰斯或 GPT-3 为基础的引擎，由流氓政府，政治或恐怖组织，或一个大公司对他们的敌人操作。如此大规模的操作可以(而且很可能会)拖垮经济，挤兑股票和货币工具，制造局部争斗，甚至可能导致全国性的错误决策，俄罗斯参与选举一位不称职的前总统就是例证。

事实和真理的概念受到攻击，我们对现实的共同理解也受到攻击。一旦事实成为叙事，在大规模人工智能的帮助下，我们作为人类将失去让社会存在的东西，更不用说我们自己对什么是真实什么是虚假的个人控制。

如果有反击的时候，现在就是时候了。我们这边需要机器。

> *原子爆能枪是一种很好的武器，但是它可以指向两个方向。*
> 
> 艾萨克·阿西莫夫

# 只是一个小针刺

我们如何使用人工智能来打击虚假，假新闻和操纵机器生成的数据？答案是:我们制造对抗机器。我的意思是我们制造人工智能来对抗人工智能。以毒攻毒的观念由来已久，然而，它有了现代的变化。

如果机器正在制造、发布和推广针对我们的真理概念和事实证据的谎言和操纵运动，我们需要反机器来检测、预防和阻止这些对我们社会的企图。这当然是一场军备竞赛。随着流氓人工智能变得更好，我们的反人工智能也必须变得更好。随着用于创建虚假内容的算法和网络变得更像人类，我们需要开发能够检测这些虚假内容的细微差异和特征的人工智能，并在它们变得大量出现之前阻止它们。这是一个数据驱动的免疫系统，因此，它需要不断学习和对抗新的威胁(热心的读者可能会发现[我几年前在](https://towardsdatascience.com/fake-news-classification-via-anomaly-detection-765c4c71d539)[数据科学](https://towardsdatascience.com/)杂志上发表的这篇文章很有趣)。

话虽如此，我们必须明白，如果上述情况成为可能，那么生成虚假文本和数据(例如图像、深度伪造视频等)的机器。)我们这些凡人无法从人类生成的内容*中分辨出来，只能被反人工智能检测到，我们面临着一个更大的问题，因为人工智能的水平将超过人类的智力(正如埃隆·马斯克和其他人偶尔提醒我们的那样)。*

这可能会成为一个过渡期，就像上个世纪的冷战一样。在某个时候，人类会理解那些人工智能工具和对抗工具是疯狂的(相互确保毁灭),并决定拆除它们。人工智能伦理形成了，人工智能法律出台了，不允许恶意使用人工智能，就像我们对核武器一样。

我们需要行动，而且我们需要尽早行动。遗憾的是，正如历史向我们展示的那样，后来往往是我们的选择

*最初发布于 2021 年 1 月 24 日*[*http://colderlazarus . me*](https://colderlazarus.me/2021/01/24/lies-damn-lies-ai/)*。*
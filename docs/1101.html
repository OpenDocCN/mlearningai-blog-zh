<html>
<head>
<title>A Scalable Solution to Detect Duplicate Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种可扩展的重复图像检测方案</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/a-scalable-solution-to-detect-duplicate-images-97d431c2726d?source=collection_archive---------1-----------------------#2021-10-02">https://medium.com/mlearning-ai/a-scalable-solution-to-detect-duplicate-images-97d431c2726d?source=collection_archive---------1-----------------------#2021-10-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2514" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在训练模型之前，删除重复数据是一个必要的步骤。问题是如何以一种可扩展的方式来实现它。</p><p id="52c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="#d824" rel="noopener ugc nofollow">问题</a> <br/> <a class="ae jc" href="#60bc" rel="noopener ugc nofollow">现有方法</a> <br/> <a class="ae jc" href="#3420" rel="noopener ugc nofollow">要求</a> <br/> <a class="ae jc" href="#0a51" rel="noopener ugc nofollow">解决方案</a> <br/> <a class="ae jc" href="#9609" rel="noopener ugc nofollow">实施</a> <br/> ∘ <a class="ae jc" href="#0ddb" rel="noopener ugc nofollow"> 1 .聚类</a> <br/> ∘ <a class="ae jc" href="#d788" rel="noopener ugc nofollow"> 2。保存质心</a> <br/> ∘ <a class="ae jc" href="#8240" rel="noopener ugc nofollow"> 3。根据到形心</a> <br/> ∘ <a class="ae jc" href="#4019" rel="noopener ugc nofollow"> 4的距离找到群集。与集群内的其他图像进行比较</a> <br/> <a class="ae jc" href="#da88" rel="noopener ugc nofollow">结论</a> <br/> <a class="ae jc" href="#de7f" rel="noopener ugc nofollow">参考文献</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/645b435120c3af1f1e53cfbab9c0ceaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dsd2IiYOdRPTWWSXCVFKDA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jc" href="https://unsplash.com/@dbmartin00?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">David Brooke Martin</a> on <a class="ae jc" href="https://unsplash.com/s/photos/double-rainbow?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a1ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果同一性意味着像素方面的同一性，则相同的图像更容易被检测到。例如，我们可以使用图像散列来编码每个图像，并快速比较两个图像的散列值。但是，如果要比较两幅图像有多相似，或者两幅图像是否“非常相似”到人类无法分辨的地步，那么问题就难多了。后者是“重复”的工作定义，我想告诉你如何检测重复的图像。完整的代码示例可从<a class="ae jc" href="https://github.com/changsin/ClassifyImages/blob/main/notebooks/dedupe_images.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h1 id="d824" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">问题</h1><p id="5920" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">要问的第一个问题是为什么要检测重复图像。可能有很多原因，但让我列出几个机器学习的原因。</p><ol class=""><li id="234d" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated"><strong class="ig hi">偏差:</strong>有重复数据意味着模型将更多地根据该类型的数据进行训练，因此会有偏差。一个或多个重复数据可能没问题，但如果有很多重复数据，模型将无法对新数据进行归纳。</li><li id="9e64" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">成本:</strong>每一条数据都需要手工标注，并以某种方式进行审查。拥有重复数据意味着增加了不必要的数据处理、存储和计算成本。</li><li id="fb65" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">噪音:</strong>如果标记不一致或不正确，重复数据也会导致训练集中出现细微的噪音。</li></ol><p id="08ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">出于这些原因，我们希望删除尽可能多的重复数据。然而，手动检测和删除重复是不可扩展的，因此需要一种更好的方法。</p><h1 id="60bc" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">现有方法</h1><p id="01ea" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">有一些已知的解决方案来检测重复。</p><ol class=""><li id="bfcb" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated"><strong class="ig hi">图像散列:</strong>将每个图像编码为一个散列值，然后比较散列值，这是一种检查相同图像的快速简单的方法。但是，正如您将看到的，如果图像被轻微改变(例如，图像像素向左移动一个像素)，此方法不起作用。此外，图像哈希只提供了一个二元答案:相同或不同。我们需要的是一个相似性度量，这样我们就可以决定如何将相似的图像归类为“副本”(伴随笔记本的<a class="ae jc" href="https://github.com/changsin/ClassifyImages/blob/main/notebooks/dedupe_images.ipynb" rel="noopener ugc nofollow" target="_blank">有一个演示，说明为什么这种方法在只有一个像素改变时会失败。)</a></li><li id="7393" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">传统方法:</strong>然后是传统的检测图像相似性的方法，比如取像素值的差值，比较直方图，计算结构相似性指数<a class="ae jc" href="https://en.wikipedia.org/wiki/Structural_similarity" rel="noopener ugc nofollow" target="_blank"> SSIM </a>，或者<a class="ae jc" rel="noopener" href="/data-breach/introduction-to-feature-detection-and-matching-65e27179885d">特征匹配</a>。每种方法的优缺点超出了本文的范围，但一般来说，它们适合一次比较两个或几个图像，但很难大规模使用。</li><li id="bd59" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">神经网络:</strong>第三种方法是利用深度学习来寻找副本:例如<a class="ae jc" href="https://conferences.oreilly.com/strata/strata-eu-2018/cdn.oreillystatic.com/en/assets/1/event/267/Using%20Siamese%20CNNs%20for%20removing%20duplicate%20entries%20from%20real%20estate%20listing%20databases%20Presentation.pdf" rel="noopener ugc nofollow" target="_blank">连体网络</a>。虽然这种方法是最鲁棒的，并且甚至可以处理旋转的复制图像，但是它需要使用另一个神经网络来进行繁重的训练和推理。</li></ol><h1 id="3420" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">要求</h1><p id="dfc2" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">根据对其他方法的调查，我们希望满足以下要求:</p><ol class=""><li id="c16f" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated"><strong class="ig hi">相似性度量:</strong>我们想要能够告诉我们两个给定图像有多相似的度量，而不是匹配或不匹配的单一二元决策。</li><li id="7653" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">可扩展:</strong>该解决方案应该能够处理两幅图像、多幅图像和一个大型图像数据集。</li><li id="d671" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">轻量级:</strong>删除重复是为了预处理深度学习的训练数据，所以我们希望解决方案尽可能轻量级。</li></ol><h1 id="0a51" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">解决办法</h1><p id="f58e" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我提出的解决方案是一种改进的聚类算法。这些步骤是:</p><ol class=""><li id="0831" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">基于要素地图对初始数据集进行聚类。</li><li id="c667" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">保存并加载质心值，以处理其他图像数据。</li><li id="4365" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">对于每幅图像，找到最近的质心。</li><li id="fa65" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">将相似性度量与该组中的其他图像进行比较。</li></ol><p id="bc49" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为聚类的副产品，您可以计算数据点之间的距离，这可以用作我们要寻找的相似性度量。然而，聚类算法的一个缺点和限制是它不能用于大量数据。在我的实验中，如果图像列表超过几百个，那么Colab会由于内存不足错误而崩溃。哎哟。</p><p id="5755" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决可伸缩性问题，建议的解决方案包括两个步骤。首先，要使用聚类作为查找相似性的方法，每个聚类应该保持在几百个图像上。第二，保存质心，并在处理一组新图像时使用它们。换句话说，在对不到几百幅图像进行初始聚类后，我们使用质心作为附加图像的比较点。</p><p id="6202" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于每幅新图像，计算与现有质心的距离，以找到最接近的聚类。确定最接近的聚类后，您可以与聚类中的所有数据点进行比较，以查找是否存在重复数据。让我们详细看看这是如何在代码中实现的。</p><h1 id="9609" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">履行</h1><p id="d8eb" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">这是我正在使用的一个示例视频剪辑。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Double rainbow and the sunset</figcaption></figure><p id="7c73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个特殊的日子里，我有幸目睹了太阳下山时，首尔汉江上悬挂的一道双彩虹。视频剪辑显示了一次拍摄中的双彩虹和日落。我期望的是应该有两个集群。第一个应该围绕双彩虹，第二个围绕日落场景。让我们看看聚类算法是否能做到这一点。</p><h2 id="0ddb" class="lm ju hh bd jv ln lo lp jz lq lr ls kd ip lt lu kh it lv lw kl ix lx ly kp lz bi translated">1.使聚集</h2><p id="5dee" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">使用Sklearn的知识管理工具很容易进行聚类。只需指定集群的数量并传递数据:</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="6fda" class="lm ju hh mb b fi mf mg l mh mi">from sklearn.cluster import KMeans</span><span id="1399" class="lm ju hh mb b fi mj mg l mh mi">kmeans = KMeans(n_clusters=2, random_state=0)<br/>X_clusters = kmeans.fit(X)</span></pre><p id="fb1f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用KMeans的一个警告是输入必须是二维数组。如果使用CV2的imread()方法加载图像，则形状可能如下所示，即73个图像，每个图像在3个通道上的分辨率为320x320:</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="d0c4" class="lm ju hh mb b fi mf mg l mh mi">X.shape<br/>&gt;(73, 320, 320, 3)</span></pre><p id="0e70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据需要像这样重塑:</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="959b" class="lm ju hh mb b fi mf mg l mh mi">X_reshaped = preprocessing.normalize(X.reshape(X.shape[0], -1))<br/>X_reshaped.shape</span><span id="2c78" class="lm ju hh mb b fi mj mg l mh mi">&gt;(73, 307200)</span></pre><p id="330a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在传递重新成形的图像数据之后，聚类结果是图像的看起来奇怪的连通点(两个白色标记是质心):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mk"><img src="../Images/2977858b7257a4d5ba1c0f88b0aa24fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*nfOplyn4rR7DlfI8DMfiPg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">KMeans clustering result of a video clip</figcaption></figure><p id="56a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是可以理解的，因为剪辑是一个相连的帧流。</p><p id="be2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了验证这两个聚类是否如我们所期望的那样，让我们挑选剪辑中的第一帧和最后一帧，并在聚类上用“X”标记它们:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ml"><img src="../Images/2fa07b8513dd3b40edd29ec7db3db809.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*jgo7dZnwe-Q6b4grli26OQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">The first and the last frames are marked with X</figcaption></figure><p id="7a9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相应的图像有:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/fec854574adfad9cfe6af5095b697534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNLlMBVMPxPoyrKP-RS-Eg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">The first and the last frame of the clip</figcaption></figure><p id="204b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果正是我们所希望的，现在我们可以确定聚类工作如预期。</p><p id="63d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">聚类也可以用CNN(回旋神经网络)特征图来完成。事实上，在大多数情况下，这种方法会给你更稳健的结果，因为特征图包含图像的结构信息，因此结果不容易受到亮度或颜色等其他因素的影响。</p><p id="84e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">获取美国有线电视新闻网的专题地图需要一点额外的工作。基本上，您正在将图像数据馈送到CNN的卷积层。在我们的案例中，我们使用的是VGG16。</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="1858" class="lm ju hh mb b fi mf mg l mh mi">from keras.applications.vgg16 import VGG16<br/>from keras.applications.vgg16 import preprocess_input<br/>from keras.models import Model</span><span id="4b16" class="lm ju hh mb b fi mj mg l mh mi">def to_feature_maps(X):<br/>  #include_top=False == not getting VGG16 last 3 layers<br/>  model = VGG16(weights="imagenet", include_top=False)</span><span id="a5a7" class="lm ju hh mb b fi mj mg l mh mi">  #Convert to VGG input format<br/>  X_processed = preprocess_input(X)</span><span id="0bb8" class="lm ju hh mb b fi mj mg l mh mi">  return model.predict(X_processed)</span></pre><p id="9ba5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据点的可视化看起来有所不同，但在我们的例子中，聚类结果保持不变:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mn"><img src="../Images/43b26ea005aabcda15a69378c7a1f540.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*7LCTKJFiA_XpMuBqpGlvOg.png"/></div></figure><p id="b45c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">无论您使用的是普通图像数组还是特征映射，聚类结果都是一个索引列表，该列表引用每个图像所属的聚类id(X _ clusters是KMeans fit()返回的结果):</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="4c94" class="lm ju hh mb b fi mf mg l mh mi">X_clusters.labels_</span><span id="ab99" class="lm ju hh mb b fi mj mg l mh mi">&gt;array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,        0, 0, 0, 0, 0, 0, 0], dtype=int32)</span></pre><h2 id="d788" class="lm ju hh bd jv ln lo lp jz lq lr ls kd ip lt lu kh it lv lw kl ix lx ly kp lz bi translated">2.保存质心</h2><p id="96fd" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">聚类结果(在我们的例子中是X_clusters)也有质心，它们是每个聚类的中心点。</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="a12a" class="lm ju hh mb b fi mf mg l mh mi">X_clusters.cluster_centers_</span><span id="a9f6" class="lm ju hh mb b fi mj mg l mh mi">&gt;array([[0.00180476, 0.00186183, 0.00188041, ..., 0.00079254, 0.00096068, 0.00138107], [0.00198384, 0.0019629 , 0.00188658, ..., 0.00086894, 0.00091189, 0.0009721 ]])</span></pre><p id="c0e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以将质心保存为JSON文件，并在以后反序列化它们以处理一组新的图像。</p><h2 id="8240" class="lm ju hh bd jv ln lo lp jz lq lr ls kd ip lt lu kh it lv lw kl ix lx ly kp lz bi translated">3.根据到质心的距离找到聚类</h2><p id="fa97" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">为了确定新图像是否与现有图像相似，我们首先将它与之前保存的质心进行比较。以下是一些测试图像:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mo"><img src="../Images/643c16ace51971ffa0ec0bc53f4b8c15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5q_VXbeFUaQkQZOr4NFlUQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">A few test images</figcaption></figure><p id="3fb8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">前两个图像与原始图像相似，因为它们都有水体，或者有双彩虹，或者有日落。让我们看看它们与两个质心相比如何。计算到一组点的距离的一种简单方法是NumPy的<a class="ae jc" href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html" rel="noopener ugc nofollow" target="_blank"> linalg.norm() </a>。从质心数组中减去图像数组得到距离列表:</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="ef97" class="lm ju hh mb b fi mf mg l mh mi">import numpy as np</span><span id="92b4" class="lm ju hh mb b fi mj mg l mh mi">np.linalg.norm(X_clusters_fm.cluster_centers_ -X_test_reshaped_fm[0], ord=2, axis=1)</span><span id="67dc" class="lm ju hh mb b fi mj mg l mh mi">&gt;array([0.4173012, 0.3990866], dtype=float32)</span></pre><p id="408c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从结果中，我们可以看到图像更接近第二个集群。如果我们把它们画在聚类图上，我们可以看到这种情况。这两幅河流图像标有“X ”,属于第二组:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/b9c087f4363793667e7a7bc498e185cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*FzOv1NSUao5QFvxjy9KDGw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Two new images plotted in the cluster map</figcaption></figure><p id="fe00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，其他三个不相关的图像离原始图像更远:</p><pre class="je jf jg jh fd ma mb mc md aw me bi"><span id="c42e" class="lm ju hh mb b fi mf mg l mh mi">np.linalg.norm(X_clusters_fm.cluster_centers_ - X_test_reshaped_fm[3], ord=2, axis=1)</span><span id="d99a" class="lm ju hh mb b fi mj mg l mh mi">&gt;array([0.55123425, 0.52316684], dtype=float32)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/163c77a5d6bdab96aa60c5e9dae15790.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*mv3lBYagTqikG8aO4ae2JA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Unrelated images are further apart from the original images</figcaption></figure><p id="0978" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以看到不相关的图像与原始图像有很大的距离，因此，在这一点上，您可以决定是创建一个新的集群还是简单地丢弃它们。</p><h2 id="4019" class="lm ju hh bd jv ln lo lp jz lq lr ls kd ip lt lu kh it lv lw kl ix lx ly kp lz bi translated">4.与群集内的其他映像进行比较</h2><p id="15f5" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">一旦确定了群集，您就可以与群集中的所有图像进行比较，以找到重复的图像。要计算距离的NxN矩阵，可以使用示例代码中的scipy cdist()方法:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mr ll l"/></div></figure><p id="3f0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该方法返回一组“重复”的图像，因为它们与群集中的其他图像相似。你可以决定相似度阈值。对于原始样本图像，阈值0.023导致以下一组副本(在聚类图中标记为X):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ms"><img src="../Images/708cb332452ce22931b7b748f883786f.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*BjMhXWgmvy4uUXQpJYvDlA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Duplicate images are marked as X in the cluster map</figcaption></figure><p id="eceb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是其余被视为独特的图像:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mt"><img src="../Images/2731074be8e1115cd11a63ce3c3cbe93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iLA4XhlyNy4fRFVHG0dyCw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Unique images</figcaption></figure><h1 id="da88" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="be87" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">检测重复图像是一个活跃的研究课题，因此可能有更好的方法。基于聚类和矩阵距离，给出的解决方案相对容易实现和理解，但我希望找到更好的解决方案。感谢阅读。</p><h1 id="de7f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考</h1><ul class=""><li id="6d46" class="kw kx hh ig b ih kr il ks ip mu it mv ix mw jb mx lc ld le bi translated">完整的代码样本可在<a class="ae jc" href="https://github.com/changsin/ClassifyImages/blob/main/notebooks/dedupe_images.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</li><li id="e82d" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb mx lc ld le bi translated">要了解集群工作的概况，请参考我的另一篇文章:<a class="ae jc" rel="noopener" href="/analytics-vidhya/oh-the-things-you-can-do-with-clustering-5dd2eed9460b">哦，你可以用集群做的事情</a></li><li id="36c9" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb mx lc ld le bi translated">我的另一篇文章<a class="ae jc" href="https://changsin.medium.com/understanding-k-means-clustering-graphically-5b90beafc900" rel="noopener">理解K均值聚类图</a>深入解释了K均值聚类是如何工作的。</li></ul></div></div>    
</body>
</html>
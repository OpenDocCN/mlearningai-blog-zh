<html>
<head>
<title>How noisy is your dataset? Sample and weight training samples to optimize the performance!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的数据集有多嘈杂？样本和重量训练样本，以优化性能！！！</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-noisy-is-your-dataset-sample-and-weight-training-samples-to-optimize-the-performance-aa8e0e3b7c43?source=collection_archive---------2-----------------------#2021-03-20">https://medium.com/mlearning-ai/how-noisy-is-your-dataset-sample-and-weight-training-samples-to-optimize-the-performance-aa8e0e3b7c43?source=collection_archive---------2-----------------------#2021-03-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="151e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练数据可能是干净的，也可能是有噪声的，从而影响机器学习模型的性能。本文讨论了处理各种情况的最佳策略。内容基于论文[5]。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/44980f151da2f2d193e3a72e4195b83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TF9zdJynPA8gJpi4Ns6r8w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd js">Figure 1:</strong> Human-Horse image classification: difficult samples for annotation.</figcaption></figure><h1 id="67e2" class="jt ju hh bd js jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">数据收集和注释中的实际问题</strong></h1><p id="1bb1" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">目前，深度学习是人工智能发展的一项重要技术。这种技术的功效取决于(1)训练样本的数量和(2)数据注释的质量。然而，大容量的训练数据导致注释工作的困难管理。例如，图1示出了一个简单图像分类问题的四个训练样本:人对马。为了收集这两个类别的大量图像，可以在互联网上抓取数据。大多数图像都区分出人和马，如图1 a、1b所示。然而，通常会看到如图1 c、1d所示的嘈杂图像，注释者很难决定哪一类图像更适合他们。显然，即使对于这种简单的两类识别，数据收集和注释也是具有挑战性的。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kv"><img src="../Images/811206cb90a1776e7b99bfda23702933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F-8cZINLlsNo-icsw9DBpg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd js">Figure 2:</strong> Trade-off between data cleanliness and annotation management.</figcaption></figure><p id="028b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据清洁度标准，我们可以将训练数据集组织成三类:<strong class="ig hi"> <em class="kw">【清洁】</em></strong><strong class="ig hi"><em class="kw"/></strong><strong class="ig hi"><em class="kw"/></strong>。如图2所示，在数据清洁度和注释管理之间有一个折衷。首先，<strong class="ig hi"> <em class="kw">干净</em> </strong>如果仔细管理数据收集和标注，这是耗时且需要劳动力的。第二，标签<strong class="ig hi"><em class="kw"/></strong>代表一个数据集被爬取(例如通过<a class="ae kx" href="https://pypi.org/project/icrawler/" rel="noopener ugc nofollow" target="_blank"> <em class="kw"> icrawler </em> </a>使用关键词)然后直接馈入深度学习模型进行训练。最后，我们使用术语<strong class="ig hi"> <em class="kw">不确定</em> </strong>来表示清洗过程具有粗略监督(例如，一轮)的数据集。然后，尽管进行了一轮评估，我们仍然不确定注释是否完全精确。</p><h1 id="3f8b" class="jt ju hh bd js jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">采样和加权训练数据</h1><p id="c18c" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">不同类型的训练数据集表现出不同的属性。因此，有必要对每个数据集采用不同的采样和加权策略来优化模型性能。在剩下的部分中，我将讨论四种采样策略，分别名为<strong class="ig hi"> <em class="kw">、统一的、自定进度的、硬示例挖掘的</em> </strong>和<strong class="ig hi"> <em class="kw">主动偏向的</em> </strong>学习。对于每种采样方法，我们还讨论了是否应该加权以进一步强调某些特定的训练样本。</p><h2 id="514a" class="ky ju hh bd js kz la lb jy lc ld le kc ip lf lg kg it lh li kk ix lj lk ko ll bi translated">制服</h2><p id="92c0" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">在训练机器学习模型时，由于计算机内存容量有限，训练样本集被分成更小的批次。一次迭代将处理单个批次的前馈和反馈。在某个时刻，应该选择哪些样本放入该批次还是一个问号。一个琐碎的解决方案，叫做<strong class="ig hi"> <em class="kw">统一</em> </strong>，就是平等对待每一个样本。换句话说，选择每个样本的概率是相同的。我们可以使用这种方法的两种变体之一。首先，一种叫做<strong class="ig hi"> SGD-Uni </strong>的方法基于概率选择一批训练样本:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lm"><img src="../Images/9c4b9e6e6d7a186059de5ab233591631.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*5QTnZXPnBjbo6VT1mycgwg.png"/></div></figure><p id="b209" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输入到模型中。然后，它将样本放回训练集，以参加下一次选择。第二，另一种方法，即<strong class="ig hi"> SGD-Scan </strong>基于概率:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/909aadc398f46c5f52cfb24d72f54d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*3xPm3PNFx4Myhg9Zbcnqkg.png"/></div></figure><p id="2430" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">选择训练样本。在一轮样本选择之后，该方法跳过选定的样本，只考虑队列中的其余样本。虽然<strong class="ig hi"> SGD-Uni </strong>可能会跳过一些训练样本，但<strong class="ig hi"> SGD-Scan </strong>会扫描所有数据。因此，<strong class="ig hi"> SGD-Scan </strong>很可能比<strong class="ig hi"> SGD-Uni </strong>执行得更好。</p><h2 id="345d" class="ky ju hh bd js kz la lb jy lc ld le kc ip lf lg kg it lh li kk ix lj lk ko ll bi translated">自定进度学习</h2><p id="ab0a" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">对于人类来说，学习过程通常是一种由易到难的策略。这启发了神经网络的一个训练过程，称为<strong class="ig hi"> <em class="kw">课程学习</em></strong>【1】，从容易到难的样本学习机器学习模型。然而，标注者很难定义每个训练样本的难度。此外，人类和机器对于样本是容易还是难的观点可能不一致。一种所谓的<strong class="ig hi"> <em class="kw">自定步调学习</em></strong>【2】，简称<strong class="ig hi"> SGD-SE </strong>的方法，提出采用当前模型的损失来评估训练样本的难度水平。具体来说，预测标签和实际标签之间的损失越低，意味着模型在处理样本时更有信心。相反，较大的损失对应于较低的置信度得分。训练数据优先队列选择样本<em class="kw"> i </em>的概率公式为:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lo"><img src="../Images/95df58057eca4549506b816c8bd1fb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*INRcYmrimJ68uqFoPsnt4g.png"/></div></figure><p id="446c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中第一个因子代表模型对样本<em class="kw"> i </em>正确预测的置信分数，第二个因子是偏差参数。这种方法在带有噪声标签的训练数据集中表现出更强的鲁棒性[3]。</p><p id="39ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，通过这种采样策略，模型会比较难的样本更频繁地扫描较容易的样本。这并不意味着模型偏向其参数，以满足更容易的样本多于更难的样本。为了产生这种偏差，将采用所谓的<strong class="ig hi"> SGD-WD </strong>加权策略，样本权重公式如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lp"><img src="../Images/e891eec6df5d725ef43b875e7c464d85.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*8gOIneQFtodEPt6uDOirfA.png"/></div></figure><p id="43ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中分母旨在归一化样本权重。</p><h2 id="26d7" class="ky ju hh bd js kz la lb jy lc ld le kc ip lf lg kg it lh li kk ix lj lk ko ll bi translated"><strong class="ak">硬例挖掘</strong></h2><p id="d335" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">课程学习[1]表现出一些缺点。首先，更简单的样本有助于更小的梯度，导致模型收敛缓慢。第二，硬训练样本由处理具有挑战性的测试样本的关键特征组成。例如，只有狗头的图像很难，但它是训练狗识别模型的好样本。通过这个硬样本，该模型可以识别出只露出头部而身体藏在灌木丛或沙发中的狗。因此，在整个训练过程中更优先考虑硬样本可以导致更强的性能。因此，在干净的训练数据的情况下，硬例挖掘[4]，简而言之<strong class="ig hi"> SGD-SD </strong>，策略更适用。这种方法为模型可信度较低的样本提供了更多的频率:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lq"><img src="../Images/c50594c0f75eda409a253e7900123c8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*NUxSTPfHs4yc06dc0s8z7Q.png"/></div></figure><p id="09cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们可以通过增加权重，让模型进一步关注硬样本:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lr"><img src="../Images/b84f675c7fd2b486400fc45074ea1acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*3Gd5S6FNfSKfRsgFvxO03Q.png"/></div></figure><p id="be99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在损失函数中。这种方法叫做<strong class="ig hi"> SGD-WD </strong>。</p><h2 id="a60a" class="ky ju hh bd js kz la lb jy lc ld le kc ip lf lg kg it lh li kk ix lj lk ko ll bi translated">主动偏向学习</h2><p id="317b" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">评估每个单一训练样本的注释是耗时的。况且，多少“干净”才够挑这两种学习策略中的一种。主动学习[5]，简称为<strong class="ig hi"> SGD-STC </strong>，通过关注停留在预测边界的样本来平衡它们。该方法寻找哪个样本是“几乎正确”或“几乎错误”的，然后将它们推入正确的一侧。选择这种样本的概率公式如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ls"><img src="../Images/23f1b15cdde8d927a9affe7f8c010ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*XKtmhVclm1oP8m19M8rAuA.png"/></div></figure><p id="bfd8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还可以检验在“边界”样本上加权是否可以提高模型的性能:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/d49241e6423199b3fee9dc3347e26515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*c1YtWOWEdXKXdJ84PzPkRQ.png"/></div></figure><p id="04bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该方法被命名为<strong class="ig hi"> SGD-WTC </strong>。</p><h1 id="add0" class="jt ju hh bd js jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">实验结果</h1><p id="86d2" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">为了评估具有不同清洁度级别的数据集上的采样和加权策略，论文[5]对两个机器学习问题进行了实验。第一个问题是在干净的<a class="ae kx" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> <em class="kw"> MNIST </em> </a>数据集上评估的手写识别。随机选择的10%训练图像被进一步重新分配标签，即噪声MNIST，以评估在噪声训练样本上训练的所呈现方法的鲁棒性。第二个问题是在数据集<a class="ae kx" href="https://www.cs.toronto.edu/ kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> <em class="kw"> CIFAR </em> </a>上评估的图像分类。图像被显著地下采样到32×32×3，使得这个问题更具挑战性，即使对于注释者来说也是如此。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lu"><img src="../Images/9675ef88075f7ce96817e569e0038cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JZPABdR9mmz1lV2W46zivA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd js">Table 1:</strong> The testing error rates of different sampling and weighting strategies. The smaller number indicates better performance.</figcaption></figure><p id="44b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当收集数据的清洁度已知时，哪种取样或称重策略更可取？表1给出了答案。以下是结果分析:</p><p id="99c8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">整齐划一。</strong>表1显示SGD-Scan的测试误差相对小于SGD-Uni。这两种方法之间的差距并不明显。以上四个问题，<strong class="ig hi"> <em class="kw">统一</em> </strong>并不是数据采样的最佳方案。</p><p id="ded8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自定进度的学习。如表1所示，对于噪声数据，易到难策略(SGD-SE，SGD-WE)是最有效的方法。然而，SGD-WE比SGD-SE更关注简单样本，似乎比SGD-SE引起相对更大的误差。这表明应该仔细考虑对简单样品的关注程度。</p><p id="17db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">硬例挖掘。</strong>在数据非常干净的情况下，更多地关注硬示例(SGDSD和SGD-WD)会得到更好的结果。这表明较难的样本比较容易的样本包含更多的区别特征。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lv"><img src="../Images/3be84c2f06b4a696c59469ac662470bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jnK45t6lZQHjGptZtmipTg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd js">Table 2: </strong>The testing error rates of different sampling and weighting strategies. The smaller number indicates better performance.</figcaption></figure><p id="4d16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">主动偏置学习。</strong>然而，我们通常不确定数据有多杂乱。此外，我们可能没有足够的计算机资源来验证自定进度或硬挖掘是否会产生更好的结果。因此，需要一种方法来处理这两种情况，并具有竞争性的性能。表2显示，主动偏置就是这样一种方法。当训练数据是干净的时，硬挖掘和主动偏向一起表现最好。否则，在数据嘈杂的情况下，出色的表现属于自定步调。然而，这种方法与主动偏置之间的差距并不明显。另一方面，抽样和加权没有太大区别。这表明，为了满足紧迫的截止日期，研究人员可能会选择其中之一，而不考虑如何进一步优化性能。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lw"><img src="../Images/837b2540542fdb88062ec3e723571996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bps-u9MKnQtgm-xl36w-rw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd js">Figure 3:</strong> Sampling and weighting strategies based on the cleanliness of training data.</figcaption></figure><h1 id="0aab" class="jt ju hh bd js jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h1><p id="ec24" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">图3示出了针对每种训练数据情况的适当训练方法。没有样本加权的自定步调学习对于有噪声的标签数据是优选的。对于干净的数据，应选择硬示例挖掘和样本加权。如果训练数据的清洁度不确定，主动偏向学习是更好的选择。</p><h1 id="26d5" class="jt ju hh bd js jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">参考</h1><p id="8ee3" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">[1] Yoshua Bengio、Jerome Louradour、Ronan Collobert和Jason Weston。课程学习。ICML 2009。</p><p id="5ede" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]帕万·库马尔、本杰明·帕克和达芙妮·柯勒。潜在变量模型的自定步调学习。NIPS 2010。</p><p id="0657" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3]，，，张，孟德宇，，，庄月婷.用于分类的自定进度推进学习。IJCAI 2016。</p><p id="a53c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4] A. Shrivastava、A. Gupta和R. Girshick。利用在线硬示例挖掘训练基于区域的对象检测器。CVPR 2016。</p><p id="a207" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[5] Haw-Shiuan Chang、Erik Learned-Miller和Andrew McCallum。主动偏向:通过强调高方差样本来训练更精确的神经网络。NIPS 2017。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Snap-It Find-It: Your Shopping Companion Bot</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Snap-It Find-It:您的购物伴侣机器人</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/snap-it-find-it-your-shopping-companion-bot-8101494545a8?source=collection_archive---------6-----------------------#2021-05-23">https://medium.com/mlearning-ai/snap-it-find-it-your-shopping-companion-bot-8101494545a8?source=collection_archive---------6-----------------------#2021-05-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="1d29" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">采用新型计算机视觉技术的图像检索应用</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/bfc04832fdc7ea09d92a0f3bb8d57125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZCUqvANKgORt5g69.jpg"/></div></div></figure></div><div class="ab cl ji jj go jk" role="separator"><span class="jl bw bk jm jn jo"/><span class="jl bw bk jm jn jo"/><span class="jl bw bk jm jn"/></div><div class="ha hb hc hd he"><p id="ca73" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi kl translated">寻找家具是一个令人惊讶的耗时且平凡的过程。宜家和HipVan等多家家具零售商的产品目录中有大量家具。通常，人们会花几个小时浏览目录，试图找到他们喜欢的东西，或者花几个小时逛实体店，试图找到符合他们新公寓主题的东西。通常，人们可能会在意外发现一件漂亮的家具时获得灵感，并决定拥有一件类似的家具。问题陈述浮出水面:<strong class="jr hi"> <em class="ku">哪里可以找到类似这件家具的东西？宜家或者HipVan有类似的吗？</em>T5】</strong></p><p id="213a" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这是团队试图解决的问题陈述。给定某些家居物品或家具的输入RGB图像，开发一个计算机视觉系统，从宜家和HipVan目录返回类似物品或家具的图像。计算机视觉系统将包括一个对象检测器模块和一个图像相似性模块，它们被巧妙地打包到一个电报机器人中作为用户界面。该系统可以帮助用户快速缩小用户应该访问的主要家具供应商的范围，并有助于使整个家具搜索过程更加高效。</p><blockquote class="kv kw kx"><p id="93ca" class="jp jq ku jr b js jt ii ju jv jw il jx ky jz ka kb kz kd ke kf la kh ki kj kk ha bi translated">我们的团队有答案:我们制作了一个电报机器人，帮助你从宜家和Hipvan搜索匹配的产品！</p></blockquote><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lb"><img src="../Images/b017634227d23d6c82cb4653342a7bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*meV5-kEU4NmE4VKz"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx">We created a Telegram bot to help you search for furniture and household products @ <a class="ae lg" href="https://t.me/SnapitFindit_bot" rel="noopener ugc nofollow" target="_blank">https://t.me/SnapitFindit_bot</a></figcaption></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="1364" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这是一系列由4名新加坡国立大学硕士研究生(理学硕士。工业4.0中)谁在拿ISY5004智能传感系统。以下是我们将要分享的内容的快照:</p><ul class=""><li id="45fc" class="lj lk hh jr b js jt jv jw jy ll kc lm kg ln kk lo lp lq lr bi translated"><a class="ae lg" href="https://jensen-wong.medium.com/snap-it-find-it-your-shopping-companion-bot-8101494545a8" rel="noopener"> Web报废、使用CNN的特征提取和图像搜索。(本帖)</a></li><li id="e0d9" class="lj lk hh jr b js ls jv lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><a class="ae lg" rel="noopener" href="/@renxiang91/object-detection-using-yolov3-51baa2bbac94">使用YOLOv3进行物体检测。</a></li><li id="609a" class="lj lk hh jr b js ls jv lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><a class="ae lg" href="https://jzys-low.medium.com/object-detection-and-background-removal-with-detectron2-2242a863cc51" rel="noopener">使用Detectron2进行对象检测和背景去除。</a></li><li id="3c4c" class="lj lk hh jr b js ls jv lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><a class="ae lg" href="https://haomingkoo.medium.com/helping-machines-visualize-our-world-f1c489bb2da9" rel="noopener">使用各种CNN模型的进一步改进。</a></li><li id="df66" class="lj lk hh jr b js ls jv lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><a class="ae lg" href="https://jensen-wong.medium.com/a-telegram-bot-with-the-power-of-computer-vision-f415fd2efae8" rel="noopener">电报机器人和云托管。</a></li></ul><blockquote class="kv kw kx"><p id="33b5" class="jp jq ku jr b js jt ii ju jv jw il jx ky jz ka kb kz kd ke kf la kh ki kj kk ha bi translated">那么，首先，我们如何获得数据？让我们从宜家和Hipvan那里刮数据吧！</p></blockquote><p id="de0b" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">让我们从了解宜家网站的HTML页面开始，我们需要获得所有产品类别的链接。为此，我使用BeautifulSoup提取我需要的链接:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="8302" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">现在，如果您熟悉使用Google Chrome开发工具，您可以公开API来查询包含产品id、价格、产品名称、图片URL(这是我们正在寻找的)的产品目录！下面先睹为快的代码…</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="e32e" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">all_data数据帧包含以下信息:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ly"><img src="../Images/5366ec7d4d8daddb2145f3e03a733ab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3LsVn3Bqkh8TNYLBicaRfQ.png"/></div></div></figure><p id="b410" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">现在，我们可以轻松下载所有产品图片:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="648e" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这是我们收集到的图片的快照:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lz"><img src="../Images/0a3a079ed6be77c1aa450d9f4657f587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8SJFkVD0qlTu6ToNy_hE0A.png"/></div></div></figure><p id="7e72" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">现在，让我们准备数据集，并将其分为训练集和测试集，以便进行特征提取和性能指标测量:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="b6eb" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">为了提取所有下载图像的特征，我们可以利用迁移学习方法，该方法使用来自<em class="ku"> imagenet的权重。</em>我们使用VGG16 CNN模型从FC2层获得输出，并将训练和测试特征保存到an中。npy文件。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="98e8" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">为了测量我们的模型有多好，然后我们定义函数来测量准确度和精度，以及通过使用欧几里德距离来测量来自两个图像的两个特征集的矢量距离:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="1e63" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">现在，我们可以使用以下代码来测量准确度和精度:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lx li l"/></div></figure><p id="dcf5" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这是结果，你可以看到精度和准确性不是很好，但是，我们的团队做了很多进一步的工作来改进这个直接开箱即用的基准，所以，请继续关注，直到这一系列帖子的结尾！</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ma"><img src="../Images/7adcabf20222900d082576fc1bf84166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*A6vXHeJPfWjAXcuVn_xQGQ.png"/></div></figure><p id="2553" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">尽管如此，让我们通过搜索沙发来想象一下结果…</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mb"><img src="../Images/88761a12bd85b758b6e6ddc3bfc00fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVOHoq5KQA6koBitokbNZw.png"/></div></div></figure><p id="e14a" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">没那么糟吧。这个沙发是样本外的数据，意味着它不存在于我们的数据库或提取特征，算法给我们前5名最匹配的家具！</p><p id="8d2f" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">然而，在现实生活中，任何相机拍摄的照片都由背景组成，并且可能有多个对象，在下面的帖子中，我们将分享如何使用不同的计算机视觉对象检测方法来识别对象并在进行搜索之前移除背景…敬请期待！</p><p id="bf01" class="pw-post-body-paragraph jp jq hh jr b js jt ii ju jv jw il jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><em class="ku">在第二部分(下面的链接)，我们将分享如何在搜索类似的产品之前首先使用YOLOv3作为物体检测模型！</em></p><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/@renxiang91/object-detection-using-yolov3-51baa2bbac94"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">使用YOLOv3的对象检测</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">这是一系列由4名新加坡国立大学硕士研究生(理学硕士。在工业4.0中)谁在服用is 5004…</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt jg mf"/></div></div></a></div></div></div>    
</body>
</html>
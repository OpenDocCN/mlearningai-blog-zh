<html>
<head>
<title>Image classification with transfer learning on PyTorch lightning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch闪电的迁移学习图像分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-lightning-6665ddb5b748?source=collection_archive---------1-----------------------#2022-06-19">https://medium.com/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-lightning-6665ddb5b748?source=collection_archive---------1-----------------------#2022-06-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="718e" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">提高深度学习代码的可读性和健壮性</h2></div><p id="c20e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在之前的文章<a class="ae js" rel="noopener" href="/mlearning-ai/image-classification-with-transfer-learning-on-tensorflow-68b6bc87ef4b"> 1 </a>、<a class="ae js" rel="noopener" href="/mlearning-ai/image-classification-with-transfer-learning-on-pytorch-2d718c85b58f"> 2 </a>中，我们回顾了用Tensorflow/Keras和PyTorch进行迁移学习的图像分类。Keras API很简单，因为Keras是高级API(与<a class="ae js" href="https://towardsdatascience.com/tensorflow-vs-keras-d51f2d68fdfc" rel="noopener" target="_blank">低级Tensorflow </a>相比)，然而，PyTorch在训练函数中有许多样板代码。PyTorch有没有类似Keras的东西？进入<a class="ae js" href="https://www.pytorchlightning.ai" rel="noopener ugc nofollow" target="_blank"> PyTorch闪电</a>的世界。</p><p id="227d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">关于使用PyTorch lightning的好处，你可以参考下面的文章。</p><div class="jt ju ez fb jv jw"><a href="https://devblog.pytorchlightning.ai/why-should-i-use-pytorch-lightning-488760847b8b" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">我为什么要用PyTorch Lightning？</h2><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">devblog.pytorchlightning.ai</p></div></div><div class="ke l"><div class="kf l kg kh ki ke kj kk jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://www.sabrepc.com/blog/Deep-Learning-and-AI/why-use-pytorch-lightning" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">为什么应该使用PyTorch Lightning以及如何开始使用</h2><div class="kl l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">随着您继续研究Python编码语言并探索它提供的各种框架，您可能会…</h3></div><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">www.sabrepc.com</p></div></div><div class="ke l"><div class="km l kg kh ki ke kj kk jw"/></div></div></a></div><p id="fb77" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如<a class="ae js" href="https://neptune.ai/blog/pytorch-lightning-vs-ignite-differences" rel="noopener ugc nofollow" target="_blank">文章</a>中所述，PyTorch Lightning具有以下关键特性:</p><ul class=""><li id="444f" class="kn ko hh iy b iz ja jc jd jf kp jj kq jn kr jr ks kt ku kv bi translated"><strong class="iy hi">在任何硬件</strong>上训练模型:CPU、GPU或TPU，无需更改源代码</li><li id="b0fc" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">可读性</strong>:减少不想要的或样板代码，将重点放在代码的研究方面</li><li id="3584" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">删除不需要的或样板代码</strong></li><li id="cce0" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">界面</strong>:简洁、整洁、易于导航</li><li id="8436" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">更容易复制</strong></li><li id="7ffe" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">可扩展</strong>:你可以使用多个数学函数(优化器、激活函数、损失函数等等)</li><li id="36b7" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">可重用性</strong></li><li id="74be" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ks kt ku kv bi translated"><strong class="iy hi">与可视化框架</strong>集成，如Neptune.ai、Tensorboard、MLFlow、Comet.ml、Wandb</li></ul><p id="e1ea" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这张<a class="ae js" href="https://pytorch-lightning.readthedocs.io/en/0.7.1/_images/pt_to_pl.jpg" rel="noopener ugc nofollow" target="_blank">图片</a>展示了PyTorch和PyTorch Lightning之间的代码差异，以快速感受其优势。</p><h1 id="3c75" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">利用迁移学习进行图像分类的一般步骤</h1><ol class=""><li id="cd79" class="kn ko hh iy b iz lt jc lu jf lv jj lw jn lx jr ly kt ku kv bi translated">数据加载器</li><li id="b81b" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ly kt ku kv bi translated">预处理</li><li id="50c5" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ly kt ku kv bi translated">加载预训练模型，根据需要冻结模型层</li><li id="8c6a" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ly kt ku kv bi translated">根据需要添加额外的层，以形成最终的模型</li><li id="f21d" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ly kt ku kv bi translated">编译模型，设置优化器和损失函数</li><li id="aa49" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ly kt ku kv bi translated">训练模型</li><li id="3398" class="kn ko hh iy b iz kw jc kx jf ky jj kz jn la jr ly kt ku kv bi translated">验证模型</li></ol><p id="ccf7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通常，前两步与数据加载和预处理相关，其他步骤与模型本身相关(加载预训练模型、修改/添加模型层、设置损失函数和优化器、训练/验证)。下面我们将使用PyTorch lightning下面的例子来回顾一下代码模式是什么样子的。</p><div class="jt ju ez fb jv jw"><a href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/domain_templates/computer_vision_fine_tuning.py" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">py torch-lightning/computer _ vision _ fine _ tuning . py at master pytorch lightning/py torch-lightning</h2><div class="kl l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">此文件包含双向Unicode文本，其解释或编译可能与下面显示的不同…</h3></div><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">github.com</p></div></div><div class="ke l"><div class="lz l kg kh ki ke kj kk jw"/></div></div></a></div><p id="8e53" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在此之前，请安装PyTorch lightning</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="4469" class="mj lc hh mf b fi mk ml l mm mn">pip install pandas torch pytorch-lightning</span></pre><h1 id="a92b" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">步骤0:导入必要的库</h1><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="a3b6" class="mj lc hh mf b fi mk ml l mm mn">import logging<br/>from pathlib import Path<br/>from typing import Union</span><span id="424f" class="mj lc hh mf b fi mo ml l mm mn">import torch<br/>import torch.nn.functional as F<br/>from torch import nn, optim<br/>from torch.optim.lr_scheduler import MultiStepLR<br/>from torch.optim.optimizer import Optimizer<br/>from torch.utils.data import DataLoader<br/>from torchmetrics import Accuracy<br/>from torchvision import models, transforms<br/>from torchvision.datasets import ImageFolder<br/>from torchvision.datasets.utils import download_and_extract_archive</span><span id="6963" class="mj lc hh mf b fi mo ml l mm mn">import pytorch_lightning as pl<br/>from pytorch_lightning import LightningDataModule<br/>from pytorch_lightning.callbacks.finetuning import BaseFinetuning<br/>from pytorch_lightning import Trainer<br/>from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping</span><span id="30b9" class="mj lc hh mf b fi mo ml l mm mn">log = logging.getLogger(__name__)<br/>DATA_URL = "<a class="ae js" href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip</a>"</span></pre><h1 id="3008" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">步骤1:点亮数据模块</h1><p id="9b28" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">像所有其他机器学习过程一样，您需要加载训练/验证数据集，进行一些预处理，这些将在以后的训练和验证中使用。LightningDataModule封装了这些并给你一个遵循的食谱。如LightningDataModule <a class="ae js" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html#lightningdatamodule-api" rel="noopener ugc nofollow" target="_blank"> API </a>中所述，主要的API有:</p><p id="4158" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ms">准备_数据:下载并保存数据的地方</em></p><p id="ad02" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ms"> train_dataloader:提供对列车数据集</em>的访问</p><p id="e2c3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ms"> val_dataloader:提供对验证数据集的访问</em></p><p id="2ebb" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ms">设置:一些初始化操作，例如构建词汇、执行训练/val/测试分割</em></p><p id="4bb7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ms"> test_dataloader:提供对测试数据集的访问</em></p><p id="5549" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ms"> predict_dataloader:提供对预测数据集的访问</em></p><p id="b336" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如您所见，它加强了一些常见的实践，例如模型的训练/验证/测试、数据集准备的中心位置、训练初始化。</p><h2 id="72eb" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">准备_数据</h2><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="7dff" class="mj lc hh mf b fi mk ml l mm mn">class CatDogImageDataModule(LightningDataModule):<br/>    def __init__(self, dl_path: Union[str, Path] = "data", num_workers: int = 0, batch_size: int = 8):<br/>        """CatDogImageDataModule.<br/>        Args:<br/>            dl_path: root directory where to download the data<br/>            num_workers: number of CPU workers<br/>            batch_size: number of sample in a batch<br/>        """<br/>        super().__init__()</span><span id="4ebe" class="mj lc hh mf b fi mo ml l mm mn">self._dl_path = dl_path<br/>        self._num_workers = num_workers<br/>        self._batch_size = batch_size</span><span id="d90a" class="mj lc hh mf b fi mo ml l mm mn">def prepare_data(self):<br/>        """Download images and prepare images datasets."""<br/>        download_and_extract_archive(url=DATA_URL, download_root=self._dl_path, remove_finished=True)</span></pre><h2 id="869b" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">train_dataloader</h2><p id="5698" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">在这里，您可以看到它只是从训练图像文件夹加载训练数据集，应用训练转换。data_path、normalize_transform、create_dataset、__dataloader方法只是在训练和验证数据集加载器之间共享的方法。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="48a6" class="mj lc hh mf b fi mk ml l mm mn"><a class="ae js" href="http://twitter.com/property" rel="noopener ugc nofollow" target="_blank">@property</a><br/>    def data_path(self):<br/>        return Path(self._dl_path).joinpath("cats_and_dogs_filtered")<br/><a class="ae js" href="http://twitter.com/property" rel="noopener ugc nofollow" target="_blank">@property</a><br/>    def normalize_transform(self):<br/>        return transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])<br/><a class="ae js" href="http://twitter.com/property" rel="noopener ugc nofollow" target="_blank">@property</a><br/>    def train_transform(self):<br/>        return transforms.Compose(<br/>            [<br/>                transforms.Resize((224, 224)),<br/>                transforms.RandomHorizontalFlip(),<br/>                transforms.ToTensor(),<br/>                self.normalize_transform,<br/>            ]<br/>        )<br/><br/>def create_dataset(self, root, transform):<br/>        return ImageFolder(root=root, transform=transform)<br/>def __dataloader(self, train: bool):<br/>        """Train/validation loaders."""<br/>        if train:<br/>            dataset = self.create_dataset(self.data_path.joinpath("train"), self.train_transform)<br/>        else:<br/>            dataset = self.create_dataset(self.data_path.joinpath("validation"), self.valid_transform)<br/>        return DataLoader(dataset=dataset, batch_size=self._batch_size, num_workers=self._num_workers, shuffle=train)<br/>def train_dataloader(self):<br/>        log.info("Training data loaded.")<br/>        return self.__dataloader(train=True)<br/></span></pre><h2 id="cd91" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">val_dataloader</h2><p id="87a6" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">从验证图像文件夹加载验证数据集，应用验证转换。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="0c1e" class="mj lc hh mf b fi mk ml l mm mn"><a class="ae js" href="http://twitter.com/property" rel="noopener ugc nofollow" target="_blank">@property</a><br/>    def valid_transform(self):<br/>        return transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), self.normalize_transform])</span><span id="7138" class="mj lc hh mf b fi mo ml l mm mn">def val_dataloader(self):<br/>        log.info("Validation data loaded.")<br/>        return self.__dataloader(train=False)</span></pre><h1 id="52e4" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">第二步:照明模块</h1><p id="25df" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">在<a class="ae js" href="https://www.analyticsvidhya.com/blog/2020/02/mathematics-behind-convolutional-neural-network/" rel="noopener ugc nofollow" target="_blank">高电平</a> l上，深度神经网络是取输入，取正向计算计算输出，然后用输出计算损耗，再用损耗做反向传播调整网络权值，重复直到达到某个稳定的“底部”使损耗最小。因此，您的模型中需要一个前向函数、损失函数、优化函数(通常是梯度下降)。与LightningDataModule类似，<a class="ae js" href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html" rel="noopener ugc nofollow" target="_blank"> LightningModule </a>也提供了相应的train/val/test/predict方法。</p><h2 id="270d" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">初始化</h2><p id="a58a" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">设置预训练模型信息、学习率调节器、建立迁移学习模型(在__build_model()方法中，resnet50 +全连接分类器)、损失函数。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="63f3" class="mj lc hh mf b fi mk ml l mm mn">class TransferLearningModel(pl.LightningModule):<br/>    def __init__(<br/>        self,<br/>        backbone: str = "resnet50",<br/>        train_bn: bool = False,<br/>        milestones: tuple = (2, 4),<br/>        batch_size: int = 32,<br/>        lr: float = 1e-3,<br/>        lr_scheduler_gamma: float = 1e-1,<br/>        num_workers: int = 6,<br/>        **kwargs,<br/>    ) -&gt; None:<br/>        """TransferLearningModel.<br/>        Args:<br/>            backbone: Name (as in ``torchvision.models``) of the feature extractor<br/>            train_bn: Whether the BatchNorm layers should be trainable<br/>            milestones: List of two epochs milestones<br/>            lr: Initial learning rate<br/>            lr_scheduler_gamma: Factor by which the learning rate is reduced at each milestone<br/>        """<br/>        super().__init__()<br/>        self.backbone = backbone<br/>        self.train_bn = train_bn<br/>        self.milestones = milestones<br/>        self.batch_size = batch_size<br/>        self.lr = lr<br/>        self.lr_scheduler_gamma = lr_scheduler_gamma<br/>        self.num_workers = num_workers</span><span id="d8db" class="mj lc hh mf b fi mo ml l mm mn">self.__build_model()</span><span id="fbf8" class="mj lc hh mf b fi mo ml l mm mn">self.train_acc = Accuracy()<br/>        self.valid_acc = Accuracy()<br/>        self.save_hyperparameters()</span><span id="574f" class="mj lc hh mf b fi mo ml l mm mn">def __build_model(self):<br/>        """Define model layers &amp; loss."""</span><span id="a981" class="mj lc hh mf b fi mo ml l mm mn"># 1. Load pre-trained network:<br/>        model_func = getattr(models, self.backbone)<br/>        backbone = model_func(pretrained=True)</span><span id="8ae0" class="mj lc hh mf b fi mo ml l mm mn">_layers = list(backbone.children())[:-1]<br/>        self.feature_extractor = nn.Sequential(*_layers)</span><span id="55a0" class="mj lc hh mf b fi mo ml l mm mn"># 2. Classifier:<br/>        _fc_layers = [nn.Linear(2048, 256), nn.ReLU(), nn.Linear(256, 32), nn.Linear(32, 1)]<br/>        self.fc = nn.Sequential(*_fc_layers)</span><span id="2646" class="mj lc hh mf b fi mo ml l mm mn"># 3. Loss:<br/>        self.loss_func = F.binary_cross_entropy_with_logits</span></pre><h2 id="6d77" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">前进传球</h2><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="d273" class="mj lc hh mf b fi mk ml l mm mn">def forward(self, x):<br/>        """Forward pass.<br/>        Returns logits.<br/>        """<br/># 1. Feature extraction:<br/>        x = self.feature_extractor(x)<br/>        x = x.squeeze(-1).squeeze(-1)<br/># 2. Classifier (returns logits):<br/>        x = self.fc(x)<br/>return x<br/>def loss(self, logits, labels):<br/>        return self.loss_func(input=logits, target=labels)</span></pre><h2 id="969c" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">训练步骤</h2><p id="c58c" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">向前传递，然后用输出和实际标签计算损耗。PyTorch Lightning将通过批次和时期进行迭代，从训练方法中获得损失，并使用该损失进行反向传播。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="707b" class="mj lc hh mf b fi mk ml l mm mn">def training_step(self, batch, batch_idx):<br/>        # 1. Forward pass:<br/>        x, y = batch<br/>        y_logits = self.forward(x)<br/>        y_scores = torch.sigmoid(y_logits)<br/>        y_true = y.view((-1, 1)).type_as(x)<br/># 2. Compute loss<br/>        train_loss = self.loss(y_logits, y_true)<br/># 3. Compute accuracy:<br/>        self.log("train_acc", self.train_acc(y_scores, y_true.int()), prog_bar=True)<br/>return train_loss</span></pre><h2 id="e901" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">验证步骤</h2><p id="5924" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">类似于训练循环，向前传递，然后用输出和实际标签计算损耗。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="7523" class="mj lc hh mf b fi mk ml l mm mn">def validation_step(self, batch, batch_idx):<br/>        # 1. Forward pass:<br/>        x, y = batch<br/>        y_logits = self.forward(x)<br/>        y_scores = torch.sigmoid(y_logits)<br/>        y_true = y.view((-1, 1)).type_as(x)<br/># 2. Compute loss<br/>        self.log("val_loss", self.loss(y_logits, y_true), prog_bar=True)<br/># 3. Compute accuracy:<br/>        self.log("val_acc", self.valid_acc(y_scores, y_true.int()), prog_bar=True)</span></pre><h2 id="32fa" class="mj lc hh bd ld mt mu mv lh mw mx my ll jf mz na ln jj nb nc lp jn nd ne lr nf bi translated">配置优化程序</h2><p id="9b1e" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">设置Adam优化器和学习率调节器</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="98cc" class="mj lc hh mf b fi mk ml l mm mn">def configure_optimizers(self):<br/>        parameters = list(self.parameters())<br/>        trainable_parameters = list(filter(lambda p: p.requires_grad, parameters))<br/>        optimizer = optim.Adam(trainable_parameters, lr=self.lr)<br/>        scheduler = MultiStepLR(optimizer, milestones=self.milestones, gamma=self.lr_scheduler_gamma)<br/>        return [optimizer], [scheduler]</span></pre><h1 id="bde1" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">训练循环</h1><p id="1448" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">现在你可以创建一个训练者，并开始你的训练，PyTorch Lightning将使你从编写样板训练循环中解脱出来。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="a87a" class="mj lc hh mf b fi mk ml l mm mn">dm = CatDogImageDataModule()<br/>model = TransferLearningModel()<br/>trainer = Trainer(max_epochs=3, progress_bar_refresh_rate=20,)<br/>trainer.fit(model=model, datamodule=dm)</span></pre><h1 id="a3aa" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">预言；预测；预告</h1><p id="e38e" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">与所有模型一样，它们只有在能够预测时才有用。要进行预测，您需要获取输入、加载模型并向前传递。PyTorch Lightning提供了predict_dataloader，但是，在模型预测与训练分离的情况下，下面是加载预测数据并进行预测的示例。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="c808" class="mj lc hh mf b fi mk ml l mm mn">import os<br/>from PIL import Image</span><span id="ba51" class="mj lc hh mf b fi mo ml l mm mn">from torchvision import transforms<br/>img_test_transforms = transforms.Compose([<br/>    transforms.Resize((224,224)),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )<br/>    ])</span><span id="934a" class="mj lc hh mf b fi mo ml l mm mn"># send model weights to GPU, <a class="ae js" href="https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte</a><br/>if torch.cuda.is_available():<br/>    model.cuda()</span><span id="ee5e" class="mj lc hh mf b fi mo ml l mm mn">def find_classes(dir):<br/>    classes = os.listdir(dir)<br/>    classes.sort()<br/>    class_to_idx = {classes[i]: i for i in range(len(classes))}<br/>    return classes, class_to_idx</span><span id="c6ec" class="mj lc hh mf b fi mo ml l mm mn">def make_prediction(model, filename):<br/>    labels, _ = find_classes('/content/data/cats_and_dogs_filtered/validation')<br/>    img = Image.open(filename)<br/>    # tensor size should [RGB, image dimension, image dimension,]: torch.Size([3, 224, 224])<br/>    img = img_test_transforms(img)<br/>    # make tensor first dimension as rows of images, torch.Size([1, 3, 224, 224])<br/>    img = img.unsqueeze(0)<br/>    model.eval()<br/>    # align image bits and model weights on same GPU or CPU<br/>    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')<br/>    outputs = model(img.to(device))<br/>    _, predicted = torch.max(outputs.data, 1)<br/>    print(predicted)</span><span id="7b51" class="mj lc hh mf b fi mo ml l mm mn">make_prediction(model, 'data/cats_and_dogs_filtered/validation/cats/cat.2000.jpg')</span><span id="52cf" class="mj lc hh mf b fi mo ml l mm mn"># tensor([0], device='cuda:0')</span></pre><h1 id="aa3c" class="lb lc hh bd ld le lf lg lh li lj lk ll in lm io ln iq lo ir lp it lq iu lr ls bi translated">附录</h1><p id="8b7a" class="pw-post-body-paragraph iw ix hh iy b iz lt ii jb jc lu il je jf mp jh ji jj mq jl jm jn mr jp jq jr ha bi translated">下面这篇文章给出了PyTorch Lightning与PyTorch在相同的机器学习问题上进行比较的很好的例子。</p><div class="jt ju ez fb jv jw"><a href="https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09" rel="noopener follow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">从PyTorch到py torch Lightning——一个温和的介绍</h2><div class="kl l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">这篇文章对使用PyTorch和PyTorch Lightning实现的MNIST进行了对比。</h3></div><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">towardsdatascience.com</p></div></div><div class="ke l"><div class="ng l kg kh ki ke kj kk jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a href="https://www.assemblyai.com/blog/pytorch-lightning-for-dummies/" rel="noopener  ugc nofollow" target="_blank"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">假人用PyTorch闪电-教程和概述</h2><div class="kl l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">在训练深度学习模型时，有许多标准的“样板”代码，它们独立于…</h3></div><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">www.assemblyai.com</p></div></div><div class="ke l"><div class="nh l kg kh ki ke kj kk jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/aimluae/tensorflow-vs-pytorch-which-will-be-the-top-deep-learning-framework-in-2022-a3488635029"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">tensor flow vs py torch:2022年顶级深度学习框架会是哪个？</h2><div class="kl l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">PyTorch和Tensorflow是目前最受欢迎的两个深度学习库。PyTorch是由…</h3></div><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="ke l"><div class="ni l kg kh ki ke kj kk jw"/></div></div></a></div><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kl l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kd l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="ke l"><div class="nj l kg kh ki ke kj kk jw"/></div></div></a></div></div></div>    
</body>
</html>
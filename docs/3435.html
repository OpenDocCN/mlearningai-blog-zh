<html>
<head>
<title>Azure Machine Learning implement general adversarial networks sample</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Azure机器学习实现一般敌对网络示例</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/azure-ml-implement-gan-sample-4896ec5bbb6?source=collection_archive---------5-----------------------#2022-09-03">https://medium.com/mlearning-ai/azure-ml-implement-gan-sample-4896ec5bbb6?source=collection_archive---------5-----------------------#2022-09-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="f737" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用Tensorflow在Azure ML中实现GAN</h1><h1 id="3a26" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">先决条件</h1><ul class=""><li id="cfbb" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="2e72" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure ML工作区</li><li id="b612" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure存储</li><li id="2656" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">我从—<a class="ae jz" href="https://livecodestream.dev/post/generating-images-with-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://livecodestream . dev/post/generating-images-with-deep-learning/</a>获取了样本</li><li id="a81f" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">尽管上面的网站展示了如何测试colab，我还是能够在AML中运行而不用安装任何东西。</li><li id="c3e7" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">这只是为了展示如何在Azure ML中实现GAN。仅演示</li></ul><h1 id="59bb" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">密码</h1><ul class=""><li id="6205" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">用python 3.8创建一个笔记本，以pytorch和tensorflow为内核</li></ul><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/472dc286949cb2f0e596f1d12038ac41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oDaq4TirMcaeVSzQ.jpg"/></div></div></figure><ul class=""><li id="b73d" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">导入必要的库</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="5dd3" class="kw if hh ks b fi kx ky l kz la">import os<br/>import time<br/>import numpy as np<br/>import tensorflow as tf<br/>from tensorflow.keras import layers<br/>import argparse<br/>from IPython import display<br/>import matplotlib.pyplot as plt<br/># %matplotlib inline<br/>from tensorflow import keras</span></pre><ul class=""><li id="53fb" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">设置环境或变量</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="4cb6" class="kw if hh ks b fi kx ky l kz la">parser = argparse.ArgumentParser()<br/>parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")<br/>parser.add_argument("--batch_size", type=int, default=128, help="size of the batches")<br/>parser.add_argument("--lr", type=float, default=2e-4, help="adam: learning rate")<br/>parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")<br/>parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")<br/>parser.add_argument("--latent_dim", type=int, default=100, help="dimension of the latent space (generator's input)")<br/>parser.add_argument("--image_dim", type=int, default=784, help="image size")<br/>parser.add_argument("--channels", type=int, default=1, help="image channels")<br/>args = parser.parse_args("")</span></pre><ul class=""><li id="4b77" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">下载样本数据</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="1cf5" class="kw if hh ks b fi kx ky l kz la">(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()<br/>x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')<br/>x_train = (x_train - 127.5) / 127.5 # Normalize the images to [-1, 1]<br/># Batch and shuffle the data<br/>train_dataset = tf.data.Dataset.from_tensor_slices(x_train).\<br/>shuffle(60000).batch(args.batch_size)</span></pre><ul class=""><li id="a694" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">现在创建发电机</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="6200" class="kw if hh ks b fi kx ky l kz la">def generator(image_dim):<br/>  inputs = keras.Input(shape=(100,), name='input_layer')<br/>  x = layers.Dense(128, kernel_initializer=tf.keras.initializers.he_uniform, name='dense_1')(inputs)<br/>  #print(x.dtype)<br/>  x = layers.LeakyReLU(0.2, name='leaky_relu_1')(x)<br/>  x = layers.Dense(256, kernel_initializer=tf.keras.initializers.he_uniform, name='dense_2')(x) <br/>  x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, name='bn_1')(x)<br/>  x = layers.LeakyReLU(0.2, name='leaky_relu_2')(x)<br/>  x = layers.Dense(512, kernel_initializer=tf.keras.initializers.he_uniform, name='dense_3')(x) <br/>  x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, name='bn_2')(x)<br/>  x = layers.LeakyReLU(0.2, name='leaky_relu_3')(x)<br/>  x = layers.Dense(1024, kernel_initializer=tf.keras.initializers.he_uniform,  name='dense_4')(x) <br/>  x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, name='bn_3')(x)<br/>  x = layers.LeakyReLU(0.2, name='leaky_relu_4')(x)<br/>  x = layers.Dense(image_dim, kernel_initializer=tf.keras.initializers.he_uniform, activation='tanh',  name='dense_5')(x) <br/>  outputs = tf.reshape(x, [-1, 28, 28, 1], name='Reshape_Layer')<br/>  model = tf.keras.Model(inputs, outputs, name="Generator")<br/>  return model</span></pre><ul class=""><li id="6dd2" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">调用生成器</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="1ec4" class="kw if hh ks b fi kx ky l kz la">generator = generator(args.image_dim)</span></pre><ul class=""><li id="ab3c" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">显示摘要</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="7d19" class="kw if hh ks b fi kx ky l kz la">generator.summary()</span></pre><ul class=""><li id="8a69" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">现在创建鉴别器</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="a65d" class="kw if hh ks b fi kx ky l kz la">def discriminator():<br/>  inputs = keras.Input(shape=(28,28,1), name='input_layer')<br/>  input = tf.reshape(inputs, [-1, 784], name='reshape_layer')<br/>  x = layers.Dense(512, kernel_initializer=tf.keras.initializers.he_uniform, name='dense_1')(input)<br/>  x = layers.LeakyReLU(0.2, name='leaky_relu_1')(x)<br/>  x = layers.Dense(256, kernel_initializer=tf.keras.initializers.he_uniform, name='dense_2')(x) <br/>  x = layers.LeakyReLU(0.2, name='leaky_relu_2')(x)<br/>  outputs = layers.Dense(1, kernel_initializer=tf.keras.initializers.he_uniform, activation='sigmoid', name='dense_3') (x) <br/>  model = tf.keras.Model(inputs, outputs, name="Discriminator")<br/>  return model</span></pre><ul class=""><li id="f53c" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">调用鉴别器</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="a28b" class="kw if hh ks b fi kx ky l kz la">discriminator = discriminator()</span></pre><ul class=""><li id="c98e" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">显示摘要</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="e95f" class="kw if hh ks b fi kx ky l kz la">discriminator.summary()</span></pre><ul class=""><li id="066b" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">现在让我们配置损失函数</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="3835" class="kw if hh ks b fi kx ky l kz la">binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()</span></pre><ul class=""><li id="ccc9" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">发电机损耗</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="bcdf" class="kw if hh ks b fi kx ky l kz la">def generator_loss(fake_output):<br/>  gen_loss = binary_cross_entropy(tf.ones_like(fake_output), fake_output)<br/>  #print(gen_loss)<br/>  return gen_loss</span></pre><ul class=""><li id="a45d" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">鉴频器损耗</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="35df" class="kw if hh ks b fi kx ky l kz la">def discriminator_loss(real_output, fake_output):<br/>  real_loss = binary_cross_entropy(tf.ones_like(real_output), real_output)<br/>  fake_loss = binary_cross_entropy(tf.zeros_like(fake_output), fake_output)<br/>  total_loss = real_loss + fake_loss<br/>  #print(total_loss)<br/>  return total_loss</span></pre><ul class=""><li id="b996" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">集合优化器</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="ae67" class="kw if hh ks b fi kx ky l kz la">generator_optimizer = tf.keras.optimizers.Adam(learning_rate = args.lr, beta_1 = args.b1, beta_2 = args.b2 )<br/>discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = args.lr, beta_1 = args.b1, beta_2 = args.b2 )</span></pre><ul class=""><li id="005f" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">配置培训功能</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="d2d6" class="kw if hh ks b fi kx ky l kz la">@tf.function<br/>def train_step(images):<br/>  noise = tf.random.normal([args.batch_size, args.latent_dim])<br/>  <br/>  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:<br/>    generated_images = generator(noise, training=True)</span><span id="d095" class="kw if hh ks b fi lb ky l kz la">    real_output = discriminator(images, training=True)<br/>    fake_output = discriminator(generated_images, training=True)<br/>    <br/>    gen_loss = generator_loss(fake_output)<br/>    disc_loss = discriminator_loss(real_output, fake_output)<br/>      <br/>      <br/>  gradients_of_gen = gen_tape.gradient(gen_loss, generator.trainable_variables) # computing the gradients<br/>  <br/>  <br/>  gradients_of_disc = disc_tape.gradient(disc_loss, discriminator.trainable_variables) # computing the gradients<br/>      <br/>  <br/>  generator_optimizer.apply_gradients(zip(gradients_of_gen, generator.trainable_variables)) # updating generator parameter <br/>  <br/>      <br/>  discriminator_optimizer.apply_gradients(zip(gradients_of_disc,discriminator.trainable_variables))</span></pre><ul class=""><li id="c628" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">播种</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="0774" class="kw if hh ks b fi kx ky l kz la"># We will reuse this seed overtime to visualize progress<br/>num_examples_to_generate = 25<br/>seed = tf.random.normal([num_examples_to_generate, args.latent_dim])</span></pre><ul class=""><li id="c252" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">创建目录</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="b137" class="kw if hh ks b fi kx ky l kz la">!mkdir tensor</span></pre><ul class=""><li id="98c4" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">设置检查点</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="db57" class="kw if hh ks b fi kx ky l kz la">import os<br/>checkpoint_dir = './training_checkpoints'<br/>checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")<br/>checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,<br/>                                 discriminator_optimizer=discriminator_optimizer,<br/>                                 generator=generator,<br/>                                 discriminator=discriminator)</span></pre><ul class=""><li id="81f6" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">火车模型</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="86f6" class="kw if hh ks b fi kx ky l kz la">def train(dataset, epochs):<br/>  for epoch in range(epochs):<br/>    start = time.time()<br/>    i = 0<br/>    D_loss_list, G_loss_list = [], []<br/>    for image_batch in dataset:<br/>      i += 1<br/>      train_step(image_batch)</span><span id="3cdc" class="kw if hh ks b fi lb ky l kz la">    display.clear_output(wait=True)<br/>    generate_and_save_images(generator,<br/>                              epoch + 1,<br/>                              seed)</span><span id="9fa5" class="kw if hh ks b fi lb ky l kz la">    # Save the model every 15 epochs<br/>    if (epoch + 1) % 15 == 0:<br/>      checkpoint.save(file_prefix = checkpoint_prefix)</span><span id="5d84" class="kw if hh ks b fi lb ky l kz la">    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))</span><span id="cbdf" class="kw if hh ks b fi lb ky l kz la">  # Generate after the final epoch<br/>  display.clear_output(wait=True)<br/>  generate_and_save_images(generator,<br/>                          epochs,<br/>                          seed)</span><span id="289c" class="kw if hh ks b fi lb ky l kz la">def generate_and_save_images(model, epoch, test_input):<br/>  # Notice `training` is set to False.<br/>  # This is so all layers run in inference mode (batchnorm).<br/>    predictions = model(test_input, training=False)<br/>    #print(predictions.shape)<br/>    fig = plt.figure(figsize=(4,4))</span><span id="4973" class="kw if hh ks b fi lb ky l kz la">    for i in range(predictions.shape[0]):<br/>        plt.subplot(5, 5, i+1)  <br/>        pred = (predictions[i, :, :, 0] + 1) * 127.5  <br/>        pred = np.array(pred)    <br/>        plt.imshow(pred.astype(np.uint8), cmap='gray')<br/>        plt.axis('off')</span><span id="63a2" class="kw if hh ks b fi lb ky l kz la">    plt.savefig('tensor/image_at_epoch_{:d}.png'.format(epoch))<br/>    plt.show()</span></pre><ul class=""><li id="79ff" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">训练模型创建图像</li></ul><pre class="kb kc kd ke fd kr ks kt ku aw kv bi"><span id="db4b" class="kw if hh ks b fi kx ky l kz la">train(train_dataset, args.n_epochs)</span></pre><ul class=""><li id="cf50" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">一旦运行，这些文件夹将出现</li></ul><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lc"><img src="../Images/96cc73c523ff91081c48487286c62d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/0*wsBNpMFMy2IPYAPz.jpg"/></div></figure><ul class=""><li id="bec9" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">检查点目录</li></ul><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ld"><img src="../Images/8f7f9c7e3e4253ba7a52a43944d163c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zwsq28whcDEguzy7.jpg"/></div></div></figure><ul class=""><li id="da76" class="jc jd hh je b jf km jh kn jj ko jl kp jn kq jp jq jr js jt bi translated">张量目录中的图像生成器</li></ul><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es le"><img src="../Images/2efd5de9ac862061f6ba5451c9d595e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GSB_8dcn5GrkvxxR.jpg"/></div></div></figure></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><p id="8a74" class="pw-post-body-paragraph lm ln hh je b jf km lo lp jh kn lq lr jj ls lt lu jl lv lw lx jn ly lz ma jp ha bi translated">原始文章位于—【github.com T2】samples 2022/gan sample . MD at main balakreshnan/samples 2022</p><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms kk me"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>A more complex Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">更复杂的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/a-more-complex-neural-network-4d05d2fabf1?source=collection_archive---------9-----------------------#2021-03-02">https://medium.com/mlearning-ai/a-more-complex-neural-network-4d05d2fabf1?source=collection_archive---------9-----------------------#2021-03-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6dc8" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">一种用于图像分类的简单神经网络</h2></div><h2 id="a87e" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">介绍</h2><p id="abe6" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">在<a class="ae kn" href="https://lucabar1995.medium.com/developing-the-first-neural-network-with-tensorflow-5fade1a23395" rel="noopener">之前的文章中，</a>我展示了如何创建最简单的神经网络，只有1个输入节点、1个隐藏节点和1个输出节点，在这种情况下，神经网络会稍微复杂一些，并将用于图像分类。</p><h1 id="987e" class="ko ix hh bd iy kp kq kr jc ks kt ku jg in kv io jk iq kw ir jo it kx iu js ky bi translated">图像分类</h1><p id="224b" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">图像识别是检测图像中的对象并识别它们或将它们分类的能力。</p><p id="a8cd" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">自从我们出生以来，我们每天都被训练成千上万的图像，甚至没有意识到这一点，因此，对我们来说，区分狗和猫或任何其他动物是很容易的。然而，计算机要模仿这一过程并不那么容易。<br/>计算机将图像视为一组数字，代表每个像素有多暗，它们试图寻找模式来识别和区分图像中的关键特征。</p><h1 id="3eb9" class="ko ix hh bd iy kp kq kr jc ks kt ku jg in kv io jk iq kw ir jo it kx iu js ky bi translated">用于图像分类的神经网络模型的实现</h1><p id="d1c0" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated"><strong class="jw hi">在这里，我们将训练一个神经网络来识别手写数字</strong>，来自一个叫做MNIST的公共数据集。<strong class="jw hi"> </strong>在TensorFlow库中，tf.keras dataset API中直接提供了一些数据集，如MNIST手写数字数据集，通常用作机器学习程序的hello world。</p><p id="9a48" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated"><strong class="jw hi">手写数字数据集包含70.000个</strong> (60.000个用于训练，10.000个用于测试)<strong class="jw hi">灰度图像，分为10个不同的类别</strong>，因此每个图像都有自己的标签，以低分辨率(28×28像素)表示从0到9的数字图像。</p><p id="929f" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">首先我们需要导入TensorFlow库:</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="efc0" class="iw ix hh lj b fi ln lo l lp lq"># Import<br/>import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span></pre><p id="13aa" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">现在我们可以加载数据集，如前所述，它被分为测试和训练图像，每个图像都有自己的标签，因此我们需要将这些数据保存在4个变量中:</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="a7e1" class="iw ix hh lj b fi ln lo l lp lq">mnist = tf.keras.datasets.mnist<br/>(train_images, train_labels), (test_images, test_labels) = <!-- -->mnist.load_data()</span></pre><h2 id="83e1" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">数据可视化</h2><p id="f56d" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">可视化我们的数据并理解它包含的内容对于每个机器学习应用程序来说始终是重要的一步。</p><p id="e747" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">首先，我们可以使用<strong class="jw hi"> shape属性打印数组</strong>的<strong class="jw hi">维度。</strong></p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="6ea6" class="iw ix hh lj b fi ln lo l lp lq">train_images.shape</span><span id="e8ef" class="iw ix hh lj b fi lr lo l lp lq">(60000, 28, 28)</span></pre><p id="9287" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">因此，我们确认图像为60k，尺寸为28x28像素。现在让我们尝试打印训练图像的第一个值:</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="721a" class="iw ix hh lj b fi ln lo l lp lq">import matplotlib.pyplot as plt</span><span id="50d8" class="iw ix hh lj b fi lr lo l lp lq">plt.imshow(training_images[0])</span><span id="9ce6" class="iw ix hh lj b fi lr lo l lp lq">print(training_labels[0])</span><span id="a159" class="iw ix hh lj b fi lr lo l lp lq">print(training_images[0])</span></pre><figure class="le lf lg lh fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ls"><img src="../Images/fc1a54e088d28eb6a36bc17bd11dc8bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sTjDT2FDztLKlE9H6Rm65A.png"/></div></div><figcaption class="ma mb et er es mc md bd b be z dx">Example of a training image(left) and how it is read by the computer as an array showing pixels intensity(right).</figcaption></figure><p id="01af" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">正如我们所看到的，数字中表示像素强度的值介于0和255之间，但是<strong class="jw hi">在使用神经网络时，我们需要对数据进行归一化，并使值介于0和1之间</strong>。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="daa7" class="iw ix hh lj b fi ln lo l lp lq">training_images = training_images / 255.0</span><span id="5ca5" class="iw ix hh lj b fi lr lo l lp lq">test_images = test_images / 255.0</span></pre><figure class="le lf lg lh fd lt er es paragraph-image"><div class="er es me"><img src="../Images/2c4dacb1c46372c5ae34aae6bcdbdb3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*QRj5DalhBGD4dKLeA1Oi6A.png"/></div><figcaption class="ma mb et er es mc md bd b be z dx">Example of number 5 image after normalization.</figcaption></figure><h2 id="a7dc" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">模型创建</h2><p id="8ad6" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">现在让我们来设计模型。</p><p id="e8cc" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">与前一篇文章中构建的模型相比，将会稍微复杂一些，但是很多事情都是如此</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="26d7" class="iw ix hh lj b fi ln lo l lp lq">model = tf.keras.models.Sequential([</span><span id="03cf" class="iw ix hh lj b fi lr lo l lp lq">tf.keras.layers.Flatten(),</span><span id="8767" class="iw ix hh lj b fi lr lo l lp lq">tf.keras.layers.Dense(128, activation=tf.nn.relu),</span><span id="5212" class="iw ix hh lj b fi lr lo l lp lq">tf.keras.layers.Dense(10, activation=tf.nn.softmax)])</span></pre><p id="0b96" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">在这里<strong class="jw hi"> </strong>我们首先将模型定义为顺序的，这意味着它将是一个具有一系列层的神经网络。第一层叫做<strong class="jw hi">展平</strong>，它允许我们将一个矩阵“展平”成一维数组。</p><figure class="le lf lg lh fd lt er es paragraph-image"><div class="er es mf"><img src="../Images/44fa715476cb858a48a3a937c0a8efea.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*cByhw0bUgOmo5MJ8DnKtLw.png"/></div><figcaption class="ma mb et er es mc md bd b be z dx">Example of Array flattening.</figcaption></figure><p id="7992" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">感谢扁平化层，我们现在可以转换每一个图像…这个数组作为我们的<strong class="jw hi">密集</strong>层的输入，它代表网络中的一层神经元。每个密集层都需要一个<strong class="jw hi">激活函数</strong>，来告诉它们做什么。</p><blockquote class="mg mh mi"><p id="029a" class="ju jv mj jw b jx kz ii jz ka la il kc mk lb ke kf ml lc kh ki mm ld kk kl km ha bi translated">现在你可能会问我“为什么你在上一篇文章中没有谈到激活功能？”。实际上，当我们使用密集层时，如果没有指定激活函数，其默认值是<strong class="jw hi">“线性”激活</strong> : <code class="du mn mo mp lj b">a(x) = x.</code></p></blockquote><p id="ac4b" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">在这种情况下，因为模型的第一层需要在训练期间学习什么是数字，所以我们使用<strong class="jw hi"> ReLU </strong>作为激活函数。数学上，ReLU函数对所有的<em class="mj">x</em>T37】0的值返回<em class="mj"> x </em>，对所有的<em class="mj"> x </em> ≤ 0的值返回0。</p><p id="8895" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">该输出将是该数字所属类别的估计，将是第二密集层的输入，该第二密集层将使用<strong class="jw hi"> softmax </strong>激活函数，该函数将给出具有最高概率的类别作为输出。</p><p id="d240" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">定义好模型后，我们需要用<strong class="jw hi"> model.compile() </strong>编译模型，这个函数用来配置模型的损耗、优化器和度量。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="e15d" class="iw ix hh lj b fi ln lo l lp lq">model.compile(optimizer = tf.keras.optimizers.Adam(),</span><span id="77d6" class="iw ix hh lj b fi lr lo l lp lq">loss = ‘sparse_categorical_crossentropy’,</span><span id="9a3d" class="iw ix hh lj b fi lr lo l lp lq">metrics=[‘accuracy’])</span></pre><p id="a4bc" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">使用命令<strong class="jw hi"> model.summary </strong>我们可以查看模型的概要:层、输入/输出的形状以及它处理的参数数量:</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="8733" class="iw ix hh lj b fi ln lo l lp lq">model.summary()</span></pre><figure class="le lf lg lh fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mq"><img src="../Images/bfdb883e90749cfb57ce24ae7e1bc3df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7J_9X4WmSumImGFr6aX4w.png"/></div></div></figure><p id="968e" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">从模型摘要的输出可以看出，<strong class="jw hi">这个简单的模型有超过101k的可训练参数！</strong></p><h2 id="7f2b" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">模特培训</h2><p id="2a7b" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated"><strong class="jw hi">现在该训练模特了</strong>。在此阶段，模型将尝试使训练数据符合训练标签，或者换句话说，找出训练数据与其标签之间的关系，以便在向模型提供新图像时，它可以预测该图像属于哪个类别。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="15b8" class="iw ix hh lj b fi ln lo l lp lq">model.fit(training_images, training_labels, epochs=5)</span></pre><figure class="le lf lg lh fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mr"><img src="../Images/30c4e8b210f36581d4047557d25ac830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e77xSSieOjNjXW8VfLnwSQ.png"/></div></div></figure><p id="8a43" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">正如我们所看到的，这个简单的神经网络在对训练数据进行分类时获得了98.6%的准确率！仅在5个时期内就达到了这种高精度，因此我们没有过度拟合该模型，尽管处理了60，000幅图像，训练还是非常快。</p><p id="fc19" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">现在让我们看看它是如何使用调用<strong class="jw hi">模型处理看不见的数据的。评估</strong>，将测试集及其标签作为参数传递，它将报告这个<strong class="jw hi">“新”数据的准确性。</strong></p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="a54f" class="iw ix hh lj b fi ln lo l lp lq">model.evaluate(test_images, test_labels)</span></pre><figure class="le lf lg lh fd lt er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ms"><img src="../Images/9c04ba0e08f1b73dfc4f332b8c6d3f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ELzfTWHuyen6Wym6rHqy0A.png"/></div></div></figure><p id="a1b4" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">不出所料，看不见的数据的准确性稍差<strong class="jw hi">，但97.6%仍是一个好结果。</strong></p><h1 id="32de" class="ko ix hh bd iy kp kq kr jc ks kt ku jg in kv io jk iq kw ir jo it kx iu js ky bi translated">对模型的思考</h1><p id="c4e9" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">因此，我们所做的是将原始像素输入到神经网络中，该网络用于建立图像识别。凭借97.6%的准确率，数字识别器在字母位于图像正中间的简单图像上确实工作得很好，但当数字没有完全位于图像中心时，识别器无法工作。哪怕是最轻微的位置变化都会毁掉一切。</p><blockquote class="mg mh mi"><p id="205e" class="ju jv mj jw b jx kz ii jz ka la il kc mk lb ke kf ml lc kh ki mm ld kk kl km ha bi translated"><strong class="jw hi">换句话说，模型学会了识别居中的数字，而不是组成数字的特征。</strong></p></blockquote><p id="b9d1" class="pw-post-body-paragraph ju jv hh jw b jx kz ii jz ka la il kc jh lb ke kf jl lc kh ki jp ld kk kl km ha bi translated">这就是卷积的强大之处。卷积是一种过滤器，它通过图像，对图像进行处理，并提取显示图像共性的特征。</p><h1 id="d532" class="ko ix hh bd iy kp kq kr jc ks kt ku jg in kv io jk iq kw ir jo it kx iu js ky bi translated">下一步是什么？</h1><p id="e528" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">在下一篇文章<a class="ae kn" rel="noopener" href="/mlearning-ai/the-importance-of-convolutions-45d16210f15">中，我将解释我们在图像识别方面面临的挑战，以及为什么全连接神经网络不是这项任务的最佳模型。</a></p><h2 id="1545" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">完整代码</h2><p id="2f71" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">在这里你可以看到完整的代码或者通过Google Colab试试看:</p><figure class="le lf lg lh fd lt"><div class="bz dy l di"><div class="mt mu l"/></div></figure></div></div>    
</body>
</html>
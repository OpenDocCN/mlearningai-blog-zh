<html>
<head>
<title>K-Nearest Neighbor</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-最近邻</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/k-nearest-neighbor-6d15a2b06772?source=collection_archive---------1-----------------------#2022-03-22">https://medium.com/mlearning-ai/k-nearest-neighbor-6d15a2b06772?source=collection_archive---------1-----------------------#2022-03-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c33d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">监督机器学习</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/0b57bcd6e419a6dc10f29115ed39f34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YAv6Ybpoi7q-D9ewK15_Vw.png"/></div></div></figure><blockquote class="jo jp jq"><p id="8477" class="ie if jr ig b ih ii ij ik il im in io js iq ir is jt iu iv iw ju iy iz ja jb ha bi translated"><strong class="ig hi">简介</strong></p></blockquote><p id="7ddb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">k-最近邻算法是一种监督机器学习算法，可用于分类<a class="ae jv" rel="noopener" href="/@vaibhavvishal1244/classification-vs-regression-38dd9d81d60a">和回归</a>。我们先来了解一下这个算法是如何工作的。它是最简单的机器学习算法之一，我们可以将其总结为三个步骤:</p><p id="d299" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第一步:最近邻:</strong>在你的数据集中找到K个离测试点“最近”的点(假设是‘y’)</p><p id="f6f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第二步:</strong>假设我们使用3-NN，这意味着k = 3。在第一步中，我们为测试点y找到了三个最近的邻居。假设这三个最近的邻居是x1，x2，x3。在步骤2中，我们需要从给定的数据集中找出这三个点的类别标签，假设是y1，y2，y3。</p><p id="c14b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第三步:多数投票:</strong>在这一步中，我们将对y1、y2和y3进行多数投票。具有最高投票的类别标签将被指定为给定查询或测试点y的类别标签</p><p id="836b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们通过一个例子来理解算法。</p><blockquote class="jo jp jq"><p id="647d" class="ie if jr ig b ih ii ij ik il im in io js iq ir is jt iu iv iw ju iy iz ja jb ha bi translated"><strong class="ig hi">示例</strong></p></blockquote><p id="def7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们有一个Flipkart移动评论的数据集。给定这个数据集，我们手中的任务是预测新的看不见的评论是正面评论还是负面评论。</p><p id="ba37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤1: </strong>加载数据集。加载我们的数据集后，看起来像这样(图1)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jw"><img src="../Images/682ec9172d18872e33673b97a13d45ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_ZGDFgzaH9LcgulRbSnZA.jpeg"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx">Fig 1: Review dataset</figcaption></figure><p id="2d11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤2: </strong>我们有一个查询点，我们想预测它的标签。(图二)</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jw"><img src="../Images/74244a8015cb84f076c42c955346e56b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cw1alLLMWR5c4YVoHdU_VQ.jpeg"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx">Fig 2: Query point with review dataset</figcaption></figure><p id="fe1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第三步:</strong>计算查询点与其最近的3个邻居之间的距离。(为简单起见，我们取k=3)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jw"><img src="../Images/31e298062fede123dcead072108b52ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2_CMcX44_pHyafxAF6kKFg.jpeg"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx">Fig 3: Distance from query point to 3 nearest neighbor</figcaption></figure><p id="2483" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤4:多数投票:</strong>从图3中可以看出，我们有2个最近邻作为正面评价，1个最近邻作为负面评价。因为我们有更多正面的最近评论，所以我们将该查询点推断为正面评论。</p><blockquote class="jo jp jq"><p id="d599" class="ie if jr ig b ih ii ij ik il im in io js iq ir is jt iu iv iw ju iy iz ja jb ha bi translated"><strong class="ig hi">代码示例</strong></p></blockquote><pre class="jd je jf jg fd kb kc kd ke aw kf bi"><span id="95dc" class="kg kh hh kc b fi ki kj l kk kl"><em class="jr"># Import necessary modules</em><br/><strong class="kc hi">from</strong> <strong class="kc hi">sklearn.neighbors</strong> <strong class="kc hi">import</strong> KNeighborsClassifier<br/><strong class="kc hi">from</strong> <strong class="kc hi">sklearn.model_selection</strong> <strong class="kc hi">import</strong> train_test_split<br/><strong class="kc hi">from</strong> <strong class="kc hi">sklearn.datasets</strong> <strong class="kc hi">import</strong> load_iris<br/><br/><em class="jr"># Loading data</em><br/>iris = load_iris()<br/><br/><em class="jr"># Create feature and target arrays</em><br/>X = iris.data<br/>y = iris.target<br/><br/><em class="jr"># Split the dataset into train and test</em><br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size = 0.2, random_state=42)<br/><br/><em class="jr">#appling KNN with K=3</em><br/>knn = KNeighborsClassifier(n_neighbors=3)<br/><br/>knn.fit(X_train, y_train)<br/><br/><em class="jr"># Calculatng the accuracy</em><br/>print(knn.score(X_test, y_test))</span></pre><p id="b327" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个简单的KNN算法代码示例。</p><p id="d3e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢阅读！</p><div class="km kn ez fb ko kp"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kq ab dw"><div class="kr ab ks cl cj kt"><h2 class="bd hi fi z dy ku ea eb kv ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kw l"><h3 class="bd b fi z dy ku ea eb kv ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kx l"><p class="bd b fp z dy ku ea eb kv ed ef dx translated">medium.com</p></div></div><div class="ky l"><div class="kz l la lb lc ky ld jm kp"/></div></div></a></div></div></div>    
</body>
</html>
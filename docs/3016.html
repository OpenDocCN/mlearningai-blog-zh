<html>
<head>
<title>Generating the Unreal: A GANs implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成虚幻:GANs实现</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/generating-the-unreal-a-gans-implementation-59f36bb4e015?source=collection_archive---------4-----------------------#2022-07-09">https://medium.com/mlearning-ai/generating-the-unreal-a-gans-implementation-59f36bb4e015?source=collection_archive---------4-----------------------#2022-07-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7612" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你知道吗？人类的大脑无法想象或创造新的面孔。是啊！做梦都没有。我们永远也不会梦到我们从未见过的人脸。但是，人工智能可以！</p><p id="4581" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">看下面的图片-</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/2e02c82fa4aac4348a94a8c6366a20aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r6rguO5Z-HxJ0EaVk5xGQQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image generated by StyleGAN2</figcaption></figure><p id="1e74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个形象是不是真实得惊人？这张图片来自网站:<a class="ae js" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">https://thispersondoesnotexist.com/</a>它因人工智能生成的人脸图片而广受欢迎，这些图片看起来极其逼真，可以让任何人措手不及。如果你对甘感兴趣，你一定要访问这个网站——每次你刷新他们的网页，它都会产生一个新面孔。</p><p id="eb11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然图像是高清晰度的，看起来很逼真的图像，但如果我们仔细观察，我们会开始注意到差异:例如，仔细看看这个人的耳朵-它们不成比例。我们还可以使用其他参数来检查图像是否是人工智能生成的，我在本文中进一步讨论了这一点。</p><p id="8339" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人工生成的人类肖像可以用于数据增强、游戏进步或增强现实将达到顶峰的元世界。我们也可以把这些假脸用在使用真脸变得有争议的应用中，比如犯罪纪录片。</p><p id="00df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章将使你能够自己生成假人脸！</p><h1 id="8d3b" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="0b82" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">生成对手网络(GANs)是算法机器学习模型，使用两种神经架构-生成器和鉴别器。这两个网络相互竞争，并使用零和游戏框架来增强其预测和准确性。GANs使用一种无人监督的学习方式；它们发现数据中隐藏的模式，然后从给定的数据集中生成新的数据。</p><p id="01ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有几种类型的gan，如-DC gan、WGANs、CycleGANs等。，每个都有自己独特的功能。在本文中，我们将使用深度卷积gan，即DCGANs。</p><p id="9633" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你还不熟悉GANs，请参考我以前的文章:<a class="ae js" rel="noopener" href="/@netra_hirani/a-beginners-guide-to-gans-86705602a519">GANs入门指南。</a></p><h1 id="e426" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">我们开始吧</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kw"><img src="../Images/16b88c9730f446e01b57422a12ccb63f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*utQOInwzjbDXn4yT"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@possessedphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Possessed Photography</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3d0f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了生成图像，我们需要为我们的模型提供初始训练数据集。如果我们提供一个由相似图像组成的数据集，即相似的背景、相似的面部特征或相似的属性，那么模型以一种有偏见的方式学习工作。例如，如果我们为我们的模型提供1000个图像:900个戴眼镜的人的图像和100个不戴眼镜的人的图像，我们可以预期我们的模型最有可能生成一个戴眼镜的人的图像。因此，建议使用具有男性/女性、不同头发颜色、不同属性等图像的多样化数据集。为了更好的模特训练。我们可以改变我们的数据集，用数据来观察不同的结果，就像我在本文后面演示的那样。</p><p id="878d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">代码的链接是- <a class="ae js" href="https://colab.research.google.com/drive/1Hjb6blG6FqR9KuXMFCnFoc-mzDTMmvM-?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>。<strong class="ig hi">为了更好地理解，我推荐平行于代码阅读这篇文章。</strong></p><p id="f43e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">导入所需的库，如tensorflow、keras、numpy、matplotlib等。是入门的第一步。接下来，我们将实施以下方法-</p><h2 id="c78c" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">方法:</h2><ul class=""><li id="f30b" class="ll lm hh ig b ih kr il ks ip ln it lo ix lp jb lq lr ls lt bi translated"><strong class="ig hi">预处理</strong>数据图像。</li><li id="a43b" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">建造</strong>发电机和鉴频器。</li><li id="d4c2" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">建立和<strong class="ig hi">培训</strong>甘模型。</li><li id="85c1" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">超参数</strong>调谐。</li><li id="a2de" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">测试</strong>和<strong class="ig hi">保存</strong>生成的图像。</li></ul><h1 id="a3d8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">预处理数据</h1><p id="d60e" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">任何流行的数据集都可以作为你的训练数据，比如流行数据集- <a class="ae js" href="https://www.kaggle.com/datasets/jessicali9530/celeba-dataset" rel="noopener ugc nofollow" target="_blank"> CelebA数据集</a>。然而，我使用了自己收集的数据集，从<a class="ae js" href="https://www.kaggle.com/gasgallo/faces-data-new" rel="noopener ugc nofollow" target="_blank"> Kaggle faces数据集</a>中选择了1200张图像，该数据集由大约8000张不同人在不同背景下以不同姿势拍摄的彩色图像组成，以实现最大可能的图像多样性。</p><p id="046b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该数据集被上传到<a class="ae js" href="https://drive.google.com/drive/folders/1bhmzoyikYiuUbgLFjAoGzq4hXJCKfUTk?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Drive </a>上，并通过该项目的Google Collaboratory进行访问。</p><p id="000c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据集由图像组成，如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lz"><img src="../Images/9685cc68ad6532d0da42248e35c46432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WXMM4BG2mUU-QWiDArvncQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Initial data set</figcaption></figure><p id="f693" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们使用的是Google Colab，所以图片的最大分辨率建议为128x128。请注意，分辨率必须是32的倍数。因此，为了减少训练时间和内存消耗，我们将图像分辨率调整为32的较低倍数，即96x96。</p><p id="4428" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于进一步的预处理:<br/> -我们执行<strong class="ig hi">抗锯齿</strong>来减少当高分辨率图像以较低分辨率呈现时出现的视觉缺陷。抗锯齿 python命令。<br/> - <strong class="ig hi">图像的归一化</strong>改变像素亮度值的范围。像素强度从0(黑色)到255(白色)不等，我们使用<strong class="ig hi">灰度归一化</strong>来归一化图像。<br/> -我们将图像除以127.5并减去1，这样所有图像都在<em class="ma"> tanh </em>激活函数的范围内，即-1和1。</p><p id="b1d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">调整大小和灰度归一化后的数据集图像如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mb"><img src="../Images/2f59c8b04260ad2fd8ff1ccb6b7cba39.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*EXMgj1PySPUJ1GcZU6FfXA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Preprocessed Images</figcaption></figure><h1 id="d9f4" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">搭建积木</h1><p id="5b8c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们现在需要构建我们的GANs网络的两个最重要的模块——生成器和鉴别器。</p><p id="a1a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用<strong class="ig hi">顺序模型</strong>在我们的DCGAN模型中添加神经网络层。序列模型是一个简单的层堆栈，其中每一层都有一个输入张量和一个输出张量。顺序模型创建一个顺序类，在其中创建和添加模型层。</p><p id="415b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">顾名思义，我们的GAN模型，即DCGAN，使用卷积神经网络(CNN)，这证明有利于图像处理任务。通过查看空间相关性，卷积网络有助于找到深层相关性。</p><p id="b9fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个项目，我们在生成器中使用了六个卷积层，即1个密集层和5个Conv2D层。Conv2D层创建与层输入卷积的卷积核，以产生输出张量。我们返回生成器中的<em class="ma"> tanh </em>激活函数，即一个介于-1和1之间的数字。</p><p id="52ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相反，我们使用5个Conv2D层作为鉴别器，并返回鉴别器中的<em class="ma"> sigmoid </em>函数，即0，1之间的数字。</p><h1 id="08a8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">构建和训练GAN模型</h1><p id="ec3c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">整体GAN模型需要将发生器和鉴频器与<strong class="ig hi">双反馈环路</strong>相结合。</p><p id="a4e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于这是一个对抗性的模型，重要的是要注意，训练生成器和鉴别器的权重不会给我们带来任何好处。这可以想象成两个摔跤手为了变得更好而训练。如果他们都训练有素，有竞争力，他们既不能从对方的错误中吸取教训，我们也不可能有一个明确的赢家。在这里，我们处理相同的场景，除了我们的摔跤手是两个竞争性的神经架构。因此，仅使用鉴别器模型的误差和输出来训练发生器的权重，而鉴别器模型是单独训练的。</p><p id="ede9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鉴别器的权重仅在GAN作为一个实体被训练时受到影响，而在鉴别器单独被训练时不受影响。GANs的目标是模拟一个<strong class="ig hi">概率分布</strong>。因此，<strong class="ig hi">损失函数</strong>是应该用来反映GAN产生的数据和真实数据分布之间的距离的最佳参数。</p><p id="ada2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">需要定义三个损失函数:<br/> -使用实像的发电机损失。<br/> -使用真实图像的鉴别器损耗。<br/> -使用假图像的鉴别器损失。</p><p id="8add" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鉴别器和发生器的工作原理如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mc"><img src="../Images/4032e3adab402176409c342c086e06d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*WRq-JItKGGhrI_EJmzNILQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image Source: <a class="ae js" href="https://miro.medium.com/max/1400/1*TKr1dtcNgJCA8uYY1OhmSg.png" rel="noopener">https://miro.medium.com/max/1400/1*TKr1dtcNgJCA8uYY1OhmSg.png</a></figcaption></figure><p id="0d0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，生成器和鉴别器的训练可以借助于下图来解释:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es md"><img src="../Images/18f9feb038b02397972fcddc5c7fe6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*SXPdXaj1e0oYsWMGv6tuww.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image Source: <a class="ae js" href="https://sites.wustl.edu/jeffheaton/t81-558/" rel="noopener ugc nofollow" target="_blank">https://sites.wustl.edu/jeffheaton/t81-558/</a></figcaption></figure><p id="3346" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我想快速重申，鉴别器和发生器的损失函数需要以对抗的方式训练，这需要两个独立的损失函数和两个独立的梯度更新。</p><p id="ff59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图显示，对于生成器训练集，x包含用于生成图像的随机种子。生成器的最佳情况是生成如此可信的图像，以至于鉴别器被愚弄而指定概率为1。鉴别器训练集包含值为0或1的y。如果鉴别器给出的概率大于0.5，则y的值为1，否则为0。</p><h1 id="815a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">超参数调谐</h1><p id="bf6b" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">由于我们使用了DCGANs，一个可以自学如何合成新图像的模型，我们实现了拉德福德在他介绍DCGANs的论文中提出的一些技巧。</p><ul class=""><li id="a616" class="ll lm hh ig b ih ii il im ip me it mf ix mg jb lq lr ls lt bi translated">所有模型都用小批量随机梯度下降(SGD)训练，小批量大小为128。</li><li id="1912" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">在LeakyReLU中，所有模型的泄漏斜率都设置为0.2。</li><li id="22ea" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">Adam optimizer与优化的超参数一起使用。<br/> { Adam是用于训练深度学习模型的随机梯度下降的替换优化算法。}</li><li id="11e7" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">汇集层被替换为步长卷积(鉴别器)和分数步长卷积(生成器)。</li><li id="6a99" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">使用80%的批量标准化。<br/>{它加速训练，使用更高的学习率，并提供正规化。}</li><li id="5e47" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">对于斜率设置为0.2的所有层，在鉴别器中使用LeakyReLU激活函数。<br/> {当输入小于零时，通过修改函数以允许增量负值，有助于防止出现垂死ReLU问题。}</li><li id="19f9" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">除了使用Tanh的输出层之外，所有层的生成器中都使用了ReLU激活。<br/>{校正线性单元(ReLU)用于防止消失梯度问题。}</li><li id="bcc3" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">鉴别器使用脱落层(25%)。<br/>{为了防止模型中的过拟合，执行了剔除正则化。}</li><li id="0120" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated">此外，还使用了UpSampling2D()来增强数量较少的样本的数量。</li></ul><h1 id="fc96" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">测试和保存图像</h1><p id="5670" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">生成器生成的图像作为输入提供给鉴别器，以揭示“现实的可能性”。如果鉴别器有一半的时间被愚弄，即图像被真实冒充的概率是0.5，则表明我们的生成器产生了似是而非的图像。</p><p id="b9b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到，我们的模型给出了0.5 的<strong class="ig hi">精度，这表明我们的生成器正在<strong class="ig hi">产生可信的图像</strong>，并且已经成功地在50%的时间里<strong class="ig hi">欺骗了鉴别器。</strong></strong></p><p id="f6a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">经过特定次数的训练后，生成的图像保存在用户需要的google位置和文件夹中，并可以从那里访问。</p><h1 id="fab7" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">获得的训练图像</h1><p id="a3c0" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">经过训练的图像保存在我们指定的位置，并显示我们生成的图像的进展，一个时期接一个时期。我的数据集的图像进展如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mh"><img src="../Images/f0d5a53e0872a8a1744722d27380ecff.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hAJL6IMX34B18L2HWEMqYQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 1</figcaption></figure><p id="da71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到，在我们的第一个时代产生的图像看起来像热图。它基本上是指定我们的脸在进一步训练后最终将出现的图像位置。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mi"><img src="../Images/70cecb3c40bec3a6ebcb50a2949d05da.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*qNhQW7qKMgXAYZMxqY-BOA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 10</figcaption></figure><p id="8123" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在可以看到，一些公式已经开始发生。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mj"><img src="../Images/b9432adba6a252fee3373c90a5a98071.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*ApDykkZnll9aWyoxrzVwMw.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 100</figcaption></figure><p id="d96b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你注意到左下角的图像，我们可以看到我们的模型几乎已经生成了一个可信的人脸。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mk"><img src="../Images/b15aa0c6d09dc95fd13c644eec8c09f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*T4HKuRm8gDsTfo4q9OIQOA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 100</figcaption></figure><p id="b3b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以注意到，还有一些图像可能<em class="ma">几乎</em>被认为是人脸，尽管大多数生成的人脸仍然是扭曲的，看起来像是直接从僵尸电影中走出来的。</p><p id="8ac9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果通过使用Google Colab GPU在150个时期内使用1200张图像的数据集，我们能够确保50%的准确性:这表明通过使用StyleGANs或NVIDIA框架，生成的人脸可能看起来非常具有欺骗性和真实性。</p><p id="5422" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想了解StyleGANs的更多信息，这里有一个视频我会推荐-<a class="ae js" href="https://www.youtube.com/watch?v=u8qPvzk0AfY" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=u8qPvzk0AfY</a><br/>你也可以访问相应的Tensorflow官方实现-<a class="ae js" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank">https://github.com/NVlabs/stylegan2</a></p><h1 id="da6c" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">玩弄数据</h1><p id="179b" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">以下是将同一模型应用于不同数据集时的输出。</p><ul class=""><li id="6745" class="ll lm hh ig b ih ii il im ip me it mf ix mg jb lq lr ls lt bi translated">使用具有相同背景、相同姿势并且只有男人的数据集。<br/> (500幅图像，50个时期，49.9%的准确度)</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ml"><img src="../Images/0d750175e14fabe6120e1b160f94f2f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*wX3ZV5LpZiHjHTftwqrlFA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 1</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mm"><img src="../Images/f7e5fe37131792a6d5a0bb919a34e6c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*4btzEOXhefYgagAXG6LaPA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 50</figcaption></figure><ul class=""><li id="eae5" class="ll lm hh ig b ih ii il im ip me it mf ix mg jb lq lr ls lt bi translated">使用具有不同背景、相同姿势并且只有女性的数据集。<br/> (500幅图像，100个时期，49.6%的准确度)</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mn"><img src="../Images/9925b3fec94bec4a4901d9c7d7e423e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*l8zqtQF7fqa_tm5bS4CM0g.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 1</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mo"><img src="../Images/b097c5b9c57873173be85d8a8d67b3f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*qPQreay_WXNapdH4hUSuhA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Epoch 100</figcaption></figure><p id="df8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们可以看到，生成的图像在很大程度上取决于我们使用的初始数据集。</p><h1 id="3a7a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">假的还是假的？</h1><p id="5135" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">正如我在本文中所讨论的，虽然这些技术有能力迷惑人的头脑，欺骗人的眼睛，但我们必须警惕并意识到硬币有两面。</p><p id="2b3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，既然我帮你生成了假图像，这里有一些提示也将帮助你识别人工生成的图像！</p><p id="56cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当你看到一张照片，留意-</p><ul class=""><li id="7450" class="ll lm hh ig b ih ii il im ip me it mf ix mg jb lq lr ls lt bi translated"><strong class="ig hi">扭曲/不寻常的背景</strong>:由于算法的工作原理是生成相似的人脸，或者可能改变所提供数据集中的人脸属性，因此模型可能会忽略背景。</li><li id="b072" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">不对称:</strong>正如我们在本文的第一张图片中注意到的，这个男人的耳朵不对称。GANs模型发现，在面部毛发、配饰或牙齿方面也会出现类似的对称错误(微笑时门牙数量更多)。</li><li id="77f7" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi">荧光渗色:</strong>同样在我们生成的图像中，我们可以看到荧光色透过图像，表明是人工生成的。</li></ul><p id="ec28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想知道更多，这里有一篇好文章给你-<a class="ae js" href="https://lifehacker.com/how-to-spot-an-ai-generated-photo-1834558395" rel="noopener ugc nofollow" target="_blank">https://life hacker . com/how-to-spot-an-ai-generated-photo-1834558395</a></p><h1 id="b720" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论:</h1><p id="a94c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们可以得出结论，GANs是一种强大的无监督学习方法，是一种方便的数据扩充工具。gan有助于独立的数据扩展，并解决需要生成性解决方案的问题。DCGANs是一种改进的GAN类型，可用于生成人工数据。GANs由两种不同类型的神经网络组成——生成器和鉴别器。神经网络结构、训练数据、超参数调整等的任何修改都会导致精确度的改变。</p><p id="6426" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管数据增强是机器学习行业日益增长的需求，但gan也可能被滥用于不道德的目的。生成看起来真实的假图像有可能增加欺诈性的社交媒体账户，甚至可能引发假新闻。为了解决这个问题，正在开发软件来更准确地识别任何音频/图像的真实性。</p><p id="7f65" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">GANs看到了未来研发的巨大潜力。我们已经可以看到一些应用程序，如3D对象生成、视频预测、人脸正面视图生成、GANs与虚拟现实的融合等等。</p><h1 id="4e5c" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">你已经征服了！</h1><p id="3d5d" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">恭喜你！这篇长文你已经看完了。你已经成功地实现了你的模型并生成了你自己的甚至不存在的人脸！这难道不令人兴奋吗？</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mp"><img src="../Images/fe36dd481708c9023390e474931a9b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*hzMDI9zWpbKZkAcVaPkpHQ.gif"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Giphy</figcaption></figure><p id="c421" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你喜欢这篇文章，请给它一个掌声和评论。感谢您的反馈和回应！</p><h1 id="6d98" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考:</h1><ul class=""><li id="d42c" class="ll lm hh ig b ih kr il ks ip ln it lo ix lp jb lq lr ls lt bi translated">拉德福德大学、梅斯大学和钦塔拉大学(2015年)。深度卷积生成对抗网络的无监督表示学习。<em class="ma"> arXiv预印本arXiv:1511.06434 </em>。</li><li id="62a8" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><a class="ae js" href="https://github.com/jeffheaton/present/blob/master/youtube/gan/gans_scratch.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/jeffheaton/present/blob/master/YouTube/gan/gans _ scratch . ipynb</a></li></ul><h2 id="0e0d" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">感谢您的阅读！</h2><p id="bf18" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">如有任何疑问或机会，请通过hiraninetra22@gmail.com或https://www.linkedin.com/in/netrahirani/<a class="ae js" href="https://www.linkedin.com/in/netrahirani/" rel="noopener ugc nofollow" target="_blank">联系我。<br/>附:我正在积极寻找数据分析/机器学习领域的机会，如果你能分享任何建议、意见或推荐，我会很高兴。</a></p><div class="mq mr ez fb ms mt"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mu ab dw"><div class="mv ab mw cl cj mx"><h2 class="bd hi fi z dy my ea eb mz ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="na l"><h3 class="bd b fi z dy my ea eb mz ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nb l"><p class="bd b fp z dy my ea eb mz ed ef dx translated">medium.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh jm mt"/></div></div></a></div></div></div>    
</body>
</html>
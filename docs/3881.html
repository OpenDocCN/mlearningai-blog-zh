<html>
<head>
<title>Building a dataset for testing and training is a pain.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为测试和训练建立数据集是一件痛苦的事情。</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/building-a-dataset-for-testing-and-training-is-a-pain-d56fb497f7ad?source=collection_archive---------9-----------------------#2022-11-02">https://medium.com/mlearning-ai/building-a-dataset-for-testing-and-training-is-a-pain-d56fb497f7ad?source=collection_archive---------9-----------------------#2022-11-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/c8b859e1132e60d218e9ff47c8d4d00f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHHckewP62eHkCN728zwIg.png"/></div></div></figure><p id="b662" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">零射击学习模型识别它以前没有见过的东西。全世界有1，899，587个描述的物种，因此需要一个包含大约200万个分类的数据集。</p><p id="46d1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有些人可能已经注意到，获取大量高质量的标记数据是一项挑战。当模型必须学习大量不同的类别(即动物种类)时，这并没有什么帮助，但这是零射击学习背后的动机。</p><p id="be5c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由开放人工智能提出的对比语言-图像预训练(CLIP)在零镜头设置中表现良好。CLIP旨在学习如何在没有明确标签的情况下对图像进行分类。</p><p id="94b3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP有两个阶段(像传统的监督模型一样):训练阶段(学习)和推理阶段(进行预测)。训练阶段通过“阅读”对应于每个图像的辅助文本(即句子)来教授图像。</p><p id="5b45" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">作为一个人(假设一个人以前从未见过猫)，他可能通过阅读这个文本来破译，并且在一个示例图像中的三个东西是“猫”因此，当模型看到不同对象的4亿个图文配对时，它可以理解特定的短语和单词如何对应某些图像模式。一旦它有了这种理解，它就可以使用这种积累的知识来推断其他任务。</p><p id="1fb4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“辅助文本的标题”是一种监督形式，但它们不是标签。这些辅助信息可以使用信息丰富的非结构化数据，而不是手工制作标签。</p><p id="c53f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP使用对比学习来理解图像和文本配对之间的关系。</p></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><p id="21fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">关于对比学习的注意事项:</strong></p><p id="9f25" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对比学习是一种机器学习技术，涉及在对比数据样本上训练模型。这种技术是基于这样的想法:当有对比的例子时，模型学习得更快更准确。例如，模型可被训练成通过同时呈现猫和狗来区分猫和狗。通过提供对比数据样本，模型可以学习区分这两个类别。</p><p id="4a3f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对比学习可以用于在各种应用中训练模型，例如自然语言处理、计算机视觉和自动车辆导航。此外，它还可以通过提供更好的示例和更多不同的数据来提高模型的准确性。使用对比学习，模型可以学习识别复杂的概念，否则很难教。</p><p id="c5df" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有各种各样的机器学习技术，每种技术都有其优点和缺点。</p><ol class=""><li id="0b35" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm jz ka kb kc bi translated">有监督的机器学习涉及使用有标签的数据来训练模型，而无监督的机器学习涉及无标签的数据来发现模式和关系。</li><li id="e5f1" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated">强化学习是机器学习，其中模型因正确执行某些任务而获得奖励。</li><li id="4bd5" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated">深度学习是一种使用神经网络处理大量数据的机器学习。</li><li id="d5b6" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated">最后，生成性对抗网络涉及训练模型来生成新数据或模仿现有数据。</li></ol></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><p id="0a9c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP试图减少图像编码与其后续文本之间的差异。因此，模型应该学会使图像尽可能相似。理解这一点是CLIP和大多数深度学习背后的前提。</p><p id="1267" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP强制模型使图像和文本编码相似。因为它通过最小化模型输出和预期输出(标签)之间的差异来学习合适的编码</p><p id="3f30" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在CLIP中，我们没有单一的模型输出。相反，我们可以将训练图像的图像编码视为模型输出，将文本编码器视为预期输出。记住，这是设置变得聪明的地方。</p><p id="9b1d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP是一种相对较新的方法，与更传统的零触发学习方法相比，具有独特的简单性。基于嵌入的方法和生成的方法将在下面的文章中直观地解释。</p><p id="54f8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">零起点学习(ZSL)是迁移学习的一种变体。这是一种模式识别，没有使用语义转移的例子。ML技术用于根据很少或没有标记的例子对数据进行分类。</p><p id="0278" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">没有数据或少量数据可用于训练。(没有用户提供数据的意图检测)</p><p id="87fb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">类别/标签的数量异常多。(成千上万)</p><p id="7a36" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">开箱即用的分类器降低了基础设施和开发方面的成本。</p><p id="19f2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用预训练的MNLI序列对分类器作为由尹等人(2019)提出的开箱即用的零镜头文本分类器</p><h2 id="9011" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">当主题是一个更抽象的术语时，零距离拍摄效果不好。</h2><p id="b42c" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji lh jk jl jm ha bi translated">零炮学习(Zero-shot learning)是一种机器学习的方法，允许在不需要标记数据的情况下训练模型。虽然这种技术很强大，但也有其局限性。特别是，当主题是一个更抽象的概念时，它的表现并不好。这是因为抽象概念需要上下文和多个示例才能准确识别。此外，用于训练模型的数据集可能不包括教导模型如何识别抽象概念的正确示例。</p><p id="036a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果没有足够的数据，模型将很难正确识别概念。此外，由于模型不能与环境交互，它们可能没有能力随着时间的推移学习和提高它们的分类精度。出于这些原因，重要的是要记住零起点学习并不适合所有类型的问题，最好是在主题明确的情况下使用。</p><p id="ae32" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">此外，它可能不会击败监督方法，但它对任何无监督的学习情况都是一个挑战。验证是一个挑战:这是我们目前面临的挑战。</p></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><h2 id="6671" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">什么是对比语言图像预处理？</h2><p id="e3ab" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji lh jk jl jm ha bi translated">对比语言图像预训练(CLIP)是OpenAI开发的一种革命性的机器学习技术。这是一种不使用显式标签对图像进行分类的方法，使其成为机器学习的宝贵工具。</p><p id="becd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP分两个阶段工作:训练阶段和推理阶段。在训练阶段，通过“阅读”与每个图像相关联的辅助文本来教导模型。这使得模型能够理解特定的短语和单词如何对应于特定的图像模式。一旦模型掌握了这些知识，它就可以推断出其他任务。</p><p id="14e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">推理阶段包括基于这种理解做出预测。CLIP使用不同对象的4亿个图像-文本对的大型数据集进行训练。这有助于模型准确快速地识别物体、人和场景。</p><p id="e2f6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">总的来说，CLIP是图像识别和分类的有力工具。从面部识别到自动驾驶汽车，这是一种多用途的技术。自动化图像识别过程可以降低部署模型所需的复杂性和时间。</p><p id="47be" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP，即对比语言图像预训练，是OpenAI开发的一种革命性的机器学习技术。这是一种不使用显式标签对图像进行分类的方法，是机器学习的宝贵工具。CLIP已被用于各种应用，从面部识别到自动驾驶汽车。</p><p id="5ce1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在人脸识别中，CLIP可以准确快速地识别出个人。它还可以用于图像搜索引擎和机器人中的图像识别和分类。此外，CLIP可以识别视频中的对象、人物和场景。它已被用于开发虚拟现实应用和提高医疗成像系统的准确性。它甚至可以用于在弱光条件下或运动中检测物体。总而言之，CLIP的可能性实际上是无限的。</p><p id="af48" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CLIP已经用于各种任务，包括自动车辆导航、自然语言处理和计算机视觉。这是一种通用技术，可用于许多不同的应用。通过自动化图像识别过程，它可以降低部署模型所需的复杂性和时间。</p><p id="94a7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">来源:</p><p id="a331" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[1]<a class="ae li" href="https://arxiv.org/abs/1912.13318" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1912.13318</a></p><p id="707d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[2]https://blog.openai.com/clip/<a class="ae li" href="https://blog.openai.com/clip/" rel="noopener ugc nofollow" target="_blank"/></p><p id="eef0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[3]https://arxiv.org/abs/1912.09357<a class="ae li" href="https://arxiv.org/abs/1912.09357" rel="noopener ugc nofollow" target="_blank"/></p><p id="8ef5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Tiu，E. (2021年7月7日)。<em class="lj">了解零投学习——让ML更人性化</em>。中等。<a class="ae li" href="https://towardsdatascience.com/understanding-zero-shot-learning-making-ml-more-human-4653ac35ccab" rel="noopener" target="_blank">https://towards data science . com/understanding-zero-shot-learning-making-ml-more-human-4653 AC 35 ccab</a></p><p id="d4bc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Kumar，A. (2021年9月22日)。<em class="lj">零拍分类</em>。中等。<a class="ae li" href="https://akgeni.medium.com/zeroshot-classification-864a278628f6" rel="noopener">https://AK geni . medium . com/zero shot-class ification-864 a 278628 F6</a></p><div class="lk ll ez fb lm ln"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">medium.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb in ln"/></div></div></a></div></div></div>    
</body>
</html>
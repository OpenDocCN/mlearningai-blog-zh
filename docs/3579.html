<html>
<head>
<title>Evaluation Methods for Classification Problems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类问题的评价方法</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/evaluation-methods-for-classification-problems-a388bb56d635?source=collection_archive---------3-----------------------#2022-09-23">https://medium.com/mlearning-ai/evaluation-methods-for-classification-problems-a388bb56d635?source=collection_archive---------3-----------------------#2022-09-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c312" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们将看看机器学习中分类问题的一些评估方法。我们将讨论的方法有:</p><ul class=""><li id="cdf2" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">混淆矩阵</li><li id="4618" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">准确(性)</li><li id="ebd0" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">精确</li><li id="ee1c" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">回忆</li><li id="6e0f" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">f1-分数</li><li id="5ae2" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">精确召回曲线</li><li id="ae74" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">ROC曲线(受试者工作特性曲线)</li><li id="9984" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">曲线下面积</li></ul><p id="1ea8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们从混淆矩阵开始…</p><h1 id="1d2e" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">混淆矩阵</h1><p id="5743" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">混淆矩阵是一个表格，我们可以清楚地看到预测类别和实际类别。二元分类的混淆矩阵如下所示:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es kt"><img src="../Images/8b163b7e5aab6adf7cd9d33b5d6e1772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*YLBnNDABNH1URZrQbAJiVQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="525d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">真阳性(TP): </strong>预测阳性和实际阳性。</p><p id="446e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">假阳性(FP): </strong>预测为阳性而实际为阴性。</p><p id="aa03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">真否定(TN): </strong>预测否定，实际否定。</p><p id="9362" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">假阴性(FN): </strong>预测为阴性，实际为阳性。</p><p id="8b12" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算混淆矩阵，我们将使用sklearn库中的ConfusionMatrixDisplay类。</p><p id="b4a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html" rel="noopener ugc nofollow" target="_blank">混淆矩阵显示文档</a></p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="c23e" class="ll jr hh lh b fi lm ln l lo lp">from sklearn.datasets import load_breast_cancer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import ConfusionMatrixDisplay<br/>from sklearn.linear_model import LogisticRegression</span><span id="e166" class="ll jr hh lh b fi lq ln l lo lp">X<strong class="lh hi">,</strong>y <strong class="lh hi">=</strong> load_breast_cancer<strong class="lh hi">(</strong>return_X_y <strong class="lh hi">=</strong> <strong class="lh hi">True)</strong></span><span id="2b99" class="ll jr hh lh b fi lq ln l lo lp">X_train<strong class="lh hi">,</strong> X_test<strong class="lh hi">,</strong> y_train<strong class="lh hi">,</strong> y_test <strong class="lh hi">=</strong> train_test_split<strong class="lh hi">(</strong>X<strong class="lh hi">,</strong> y<strong class="lh hi">,</strong> test_size<strong class="lh hi">=</strong>0.2<strong class="lh hi">,</strong> random_state<strong class="lh hi">=</strong>42<strong class="lh hi">)</strong></span><span id="f0ab" class="ll jr hh lh b fi lq ln l lo lp">clf <strong class="lh hi">=</strong> LogisticRegression<strong class="lh hi">(</strong>max_iter<strong class="lh hi">=</strong>10000<strong class="lh hi">)</strong><br/>clf<strong class="lh hi">.</strong>fit<strong class="lh hi">(</strong>X_train<strong class="lh hi">,</strong> y_train<strong class="lh hi">)</strong></span><span id="486b" class="ll jr hh lh b fi lq ln l lo lp">ConfusionMatrixDisplay<strong class="lh hi">.</strong>from_estimator<strong class="lh hi">(</strong>clf<strong class="lh hi">,</strong> X_test<strong class="lh hi">,</strong> y_test<strong class="lh hi">,</strong> display_labels <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>'malignant'<strong class="lh hi">,</strong> 'benign'<strong class="lh hi">])</strong></span></pre><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lr"><img src="../Images/433284118228f3c98fd3107f2fc87003.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*995mUX1DggQET_BQfwFnlQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="0c4a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据某些问题，查看假阴性或假阳性的数量可能非常重要。这就是混淆矩阵派上用场的地方，因为它就是这么做的。</p><p id="a051" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种情况下，我们有癌症数据集的精度矩阵。我们可以看到真阳性的数量是39。这意味着该模型能够正确识别39个癌症样本。</p><p id="7807" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，我们也有1个假阳性(病人实际上没有癌症，但模型说病人有癌症)。在这种情况下，假阳性可能不是那么严重，因为额外的医疗控制将在以后揭示患者没有癌症(除了对患者来说几天困难的日子……)。</p><p id="13b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里非常关键的是预测为无癌症的4名患者，但他们实际上患有癌症(假阴性)。这是一个我们根本不想要的病例，因为癌症患者的生命危在旦夕。因此，对于这个问题，我们的目标是尽可能减少假阴性。另一个问题是，减少误报的数量可能更重要。这就是为什么当涉及到分类问题时，混淆矩阵非常重要。</p><h1 id="deff" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">多类分类的混淆矩阵</h1><p id="9f97" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">当我们从二元分类问题转移到多类分类问题时，混淆矩阵变得更大。多类问题的混淆矩阵看起来是这样的:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/03946a9c85d6c95788559e975448ccb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZWPw-EXH1DjCyr3caf0rA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="2776" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">混淆矩阵的大小与目标类别的数量相同。混淆矩阵的一个很大的优点是，它允许我们看到哪个类别有多少样本被错误分类，以及哪个预测类别与哪个实际类别混淆。</p><h1 id="6e21" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">准确(性)</h1><p id="03f6" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">准确性是衡量分类器做出正确预测的频率。它是总正确预测与总预测的比率。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lx"><img src="../Images/b92e8e89018bcb1e953fa63cb4355195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*QeELXb2EdPmZAb2uDBrOuQ.png"/></div></figure><p id="21cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">准确性是一个易于理解的指标，在数据集平衡时非常有用。但是，在评估不平衡的数据集时可能会产生误导。当数据集中的目标类在样本方面存在较大差异时，就是一个不平衡的数据集。在处理不平衡的数据集时，准确性不是最佳的衡量标准。让我们看看下面的例子。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ly"><img src="../Images/b6e76a6db7f2824b51abf12d1c5a40e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_S3sHYtlmtzMHrleZYHuHg.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="9c55" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们仔细查看混淆矩阵时，我们发现只有25名患者实际患有癌症，而实际上没有癌症的患者为375名。该模型的精度为0.95，表现相当不错，是吗？不完全是，该模型在预测没有癌症的患者方面相当不错，但我们不能对实际患有癌症的患者说同样的话(在25名实际患有癌症的患者中，只有10名预测正确)。因为准确度只考虑正确预测与总预测的比率，所以最常见的类性能支配着度量，当数据集不平衡时，会导致对模型性能的误导性解释。</p><p id="308a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算准确度，我们将使用sklearn库中的accuracy_score函数。</p><p id="8569" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html" rel="noopener ugc nofollow" target="_blank">准确度分数文件()</a></p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="9d37" class="ll jr hh lh b fi lm ln l lo lp">y_pred <strong class="lh hi">=</strong> clf<strong class="lh hi">.</strong>predict<strong class="lh hi">(</strong>X_test<strong class="lh hi">)</strong></span><span id="abc2" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">#calling the accuracy_score function from metrics</em><br/>accuracy_score <strong class="lh hi">=</strong> metrics<strong class="lh hi">.</strong>accuracy_score<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> y_pred<strong class="lh hi">)</strong></span><span id="9982" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"Accuracy score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>accuracy_score<strong class="lh hi">))</strong></span><span id="d96b" class="ll jr hh lh b fi lq ln l lo lp">Accuracy score is: 0.96</span><span id="5684" class="ll jr hh lh b fi lq ln l lo lp">correct_predictions <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>pred <strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>pred <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>y_pred<strong class="lh hi">)</strong> <strong class="lh hi">if</strong> pred <strong class="lh hi">==</strong> y_test<strong class="lh hi">[</strong>i<strong class="lh hi">]]</strong></span><span id="47fe" class="ll jr hh lh b fi lq ln l lo lp">accuracy_manual <strong class="lh hi">=</strong> <em class="lz">len</em><strong class="lh hi">(</strong>correct_predictions<strong class="lh hi">)/</strong><em class="lz">len</em><strong class="lh hi">(</strong>y_pred<strong class="lh hi">)</strong></span><span id="8d10" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"Accuracy score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>accuracy_manual<strong class="lh hi">))</strong></span><span id="a674" class="ll jr hh lh b fi lq ln l lo lp">Accuracy score is: 0.96</span></pre><h1 id="1358" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">精确</h1><p id="563b" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">精度是模型的真实正预测与总正预测之比的度量。在假阳性比假阴性更重要的情况下，精度是一个有用的指标。这种情况可能是推荐系统，误报会导致客户流失，进而降低业务成功。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es ma"><img src="../Images/03f21064ae8ec5e1d78c2dedce185c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*N8UyRC0XxqJEq74ULtW9cg.png"/></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mb"><img src="../Images/f282b152415d14365410900de2bc034b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*s9-3x8HWLWqwjMJoQHIPnQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="30f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们前面例子的精度是:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mc"><img src="../Images/e069eae2c49a5d075c62e8687f05383b.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*aXvl78vQKuORGNNcSztYoA.png"/></div></figure><p id="473c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不如准确性好，对吧？在这种情况下，假阴性比假阳性更重要，我们不想误诊任何癌症患者为阴性，如果他们实际上有癌症！我们也有一个度量标准，召回！</p><p id="7533" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算精确度，我们将使用sklearn库中的precision_score函数。</p><p id="42ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">【precision _ score()文档</p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="8346" class="ll jr hh lh b fi lm ln l lo lp">precision_score <strong class="lh hi">=</strong> metrics<strong class="lh hi">.</strong>precision_score<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> y_pred<strong class="lh hi">)</strong></span><span id="2219" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"Precision score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>precision_score<strong class="lh hi">))</strong></span><span id="bf39" class="ll jr hh lh b fi lq ln l lo lp">Precision score is: 0.95</span><span id="e995" class="ll jr hh lh b fi lq ln l lo lp">TP <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>pred <strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>pred <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>y_pred<strong class="lh hi">)</strong> <strong class="lh hi">if</strong> <strong class="lh hi">(</strong>pred <strong class="lh hi">==</strong> y_test<strong class="lh hi">[</strong>i<strong class="lh hi">]</strong> <strong class="lh hi">&amp;</strong> pred <strong class="lh hi">==</strong> 1<strong class="lh hi">)]</strong><br/>TP_FP <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>pred <strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>pred <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>y_pred<strong class="lh hi">)</strong> <strong class="lh hi">if</strong> <strong class="lh hi">(</strong>pred <strong class="lh hi">==</strong> 1<strong class="lh hi">)]</strong></span><span id="633c" class="ll jr hh lh b fi lq ln l lo lp">precision_manual <strong class="lh hi">=</strong> <em class="lz">len</em><strong class="lh hi">(</strong>TP<strong class="lh hi">)</strong> <strong class="lh hi">/</strong> <em class="lz">len</em><strong class="lh hi">(</strong>TP_FP<strong class="lh hi">)</strong></span><span id="0b22" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"Precision score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>precision_manual<strong class="lh hi">))</strong></span><span id="0c16" class="ll jr hh lh b fi lq ln l lo lp">Precision score is: 0.95</span></pre><h1 id="b82b" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">回忆</h1><p id="95b5" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">回忆是模型能够正确预测的阳性病例数的比率。当假阴性比假阳性更重要时，召回是一个有用的指标。如我们所述，例如，在不想遗漏任何实际阳性的医疗病例(如癌症数据集)中，这一点很重要，而误报(假阳性)则不那么重要。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es md"><img src="../Images/aab9a5bb951edf6f2c128dbad5478dfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*mmSwN2zdoFW7LRoFfAFw_A.png"/></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es me"><img src="../Images/b8ffc6e593189e0e1db766f134d8fa2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cqtTKuz4vmnyjMg6Gxw2Nw.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="a6a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们前面示例中的召回将是:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mf"><img src="../Images/888297c53d498428face79d5227b9604.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*KOMCrBD5w5UHs3gnVEIogw.png"/></div></figure><p id="5f63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到，与准确度和精确度相比，我们的召回率要高得多，在这种情况下，准确度和精确度实际上是最重要的指标。在这里，我们可以清楚地看到，使用不平衡数据集的准确性可能会产生误导。</p><p id="6cac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算准确性，我们将使用sklearn库中的recall_score函数。</p><p id="7eac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" rel="noopener ugc nofollow" target="_blank">recall _ score()的文档</a></p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="e454" class="ll jr hh lh b fi lm ln l lo lp">recall_score <strong class="lh hi">=</strong> metrics<strong class="lh hi">.</strong>recall_score<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> y_pred<strong class="lh hi">)</strong></span><span id="a4a5" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"Recall score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>recall_score<strong class="lh hi">))</strong></span><span id="07e3" class="ll jr hh lh b fi lq ln l lo lp">Recall score is: 0.99</span><span id="cd03" class="ll jr hh lh b fi lq ln l lo lp">TP <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>pred <strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>pred <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>y_pred<strong class="lh hi">)</strong> <strong class="lh hi">if</strong> <strong class="lh hi">(</strong>pred <strong class="lh hi">==</strong> y_test<strong class="lh hi">[</strong>i<strong class="lh hi">]</strong> <strong class="lh hi">&amp;</strong> pred <strong class="lh hi">==</strong> 1<strong class="lh hi">)]</strong><br/>TP_FN <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>pred <strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>pred <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>y_pred<strong class="lh hi">)</strong> <strong class="lh hi">if</strong> <strong class="lh hi">(</strong>y_test<strong class="lh hi">[</strong>i<strong class="lh hi">]</strong> <strong class="lh hi">==</strong> 1<strong class="lh hi">)]</strong></span><span id="90d2" class="ll jr hh lh b fi lq ln l lo lp">recall_manual <strong class="lh hi">=</strong> <em class="lz">len</em><strong class="lh hi">(</strong>TP<strong class="lh hi">)</strong> <strong class="lh hi">/</strong> <em class="lz">len</em><strong class="lh hi">(</strong>TP_FN<strong class="lh hi">)</strong></span><span id="b9e8" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"Precision score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>recall_manual<strong class="lh hi">))</strong></span><span id="3568" class="ll jr hh lh b fi lq ln l lo lp">Precision score is: 0.99</span></pre><h1 id="5a75" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">f1-分数</h1><p id="3b41" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">F1分数是精确度和召回率的结合。它是查准率和查全率的调和平均值，当查准率等于查全率时最大。因此，当我们寻求两全其美时(当我们在假阳性和假阴性之间没有显著性差异时)，f1是我们的度量。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mg"><img src="../Images/cab4c857d72f3f071496668eeeb08d97.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*XRG6O6krkUm-ON6DbtRa2g.png"/></div></figure><p id="2638" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们之前示例中的F1分数为:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mh"><img src="../Images/c637415f024b02985a4a0b08dab60484.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*KzL-HpPb0S8yRhtN0_hEvg.png"/></div></figure><p id="4c33" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">F1分数对极端值的惩罚更大，当添加更多数据而对结果没有影响时，或者当我们有大量真阴性时，f1分数是一个有效的指标。当我们处理不平衡的数据时，与准确性相比，这也是一个更好的选择。</p><p id="4ab2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算准确性，我们将使用sklearn库中的f1_score函数。</p><p id="098f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" rel="noopener ugc nofollow" target="_blank">f1 _ score()的文档</a></p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="2fe5" class="ll jr hh lh b fi lm ln l lo lp">f1_score <strong class="lh hi">=</strong> metrics<strong class="lh hi">.</strong>f1_score<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> y_pred<strong class="lh hi">)</strong></span><span id="3cea" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"F1-score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>f1_score<strong class="lh hi">))</strong></span><span id="879b" class="ll jr hh lh b fi lq ln l lo lp">F1-score is: 0.97</span><span id="f813" class="ll jr hh lh b fi lq ln l lo lp">f1_manual <strong class="lh hi">=</strong> 2<strong class="lh hi">*</strong>precision_manual<strong class="lh hi">*</strong>recall_manual<strong class="lh hi">/(</strong>precision_manual <strong class="lh hi">+</strong> recall_manual<strong class="lh hi">)</strong></span><span id="c468" class="ll jr hh lh b fi lq ln l lo lp"><em class="lz">print</em><strong class="lh hi">(</strong>"F1-score is: {:.2f}"<strong class="lh hi">.</strong>format<strong class="lh hi">(</strong>f1_manual<strong class="lh hi">))</strong></span><span id="1a9c" class="ll jr hh lh b fi lq ln l lo lp">F1-score is: 0.97</span></pre><h1 id="9b27" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">精确召回曲线</h1><p id="094e" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">PR曲线是说明二进制分类的精度值相对于召回值的变化的图。通过计算分类器不同阈值的精度和召回值并绘制这些值来绘制PR曲线。《出埃及记》对于逻辑回归，阈值将是属于正类的预测的预测概率。</p><p id="fa60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它常用于不平衡数据集的问题。y轴上是精度值，x轴上是召回值。我们在前面的例子中看到了哪些用例精度和召回指标可能是合适的。PR曲线允许我们考虑指标和一个指标相对于另一个指标的变化。</p><p id="e5b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当两个目标类之间的样本不平衡时，同时考虑精度和召回率会很有用。当负类(类0)的样本多于正类(类1)的样本时，情况尤其如此。精确度和召回率都不考虑真阴性的数量，而是集中在对阳性类别的错误预测的纠正上。</p><p id="9ce3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了绘制分类器的pr曲线，我们将使用sklearn库中的precision_recall_curve()函数。</p><p id="3cdb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">【precision _ recall _ curve()的文档</p><p id="8556" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以使用predict_proba()方法获得概率，然后使用这些概率来构建PR曲线。决策阈值通常为0.5。这意味着如果概率大于0.5，那么它将被预测为正。</p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="4ea7" class="ll jr hh lh b fi lm ln l lo lp">from sklearn.metrics import precision_recall_curve<br/>import matplotlib.pyplot <strong class="lh hi">as</strong> plt<br/><strong class="lh hi">%</strong>matplotlib inline</span><span id="929a" class="ll jr hh lh b fi lq ln l lo lp">probabilities <strong class="lh hi">=</strong> clf<strong class="lh hi">.</strong>predict_proba<strong class="lh hi">(</strong>X_test<strong class="lh hi">)[:,</strong>1<strong class="lh hi">]</strong></span><span id="c723" class="ll jr hh lh b fi lq ln l lo lp">precision_vals<strong class="lh hi">,</strong>recall_vals<strong class="lh hi">,</strong>thresholds <strong class="lh hi">=</strong> precision_recall_curve<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> probabilities<strong class="lh hi">)</strong></span><span id="3932" class="ll jr hh lh b fi lq ln l lo lp">plt<strong class="lh hi">.</strong>plot<strong class="lh hi">(</strong>recall_vals<strong class="lh hi">,</strong> precision_vals<strong class="lh hi">,</strong> label <strong class="lh hi">=</strong> 'PR Curve'<strong class="lh hi">,</strong> marker<strong class="lh hi">=</strong>'o'<strong class="lh hi">)</strong><br/><strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>val <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>precision_vals<strong class="lh hi">):</strong><br/>  <strong class="lh hi">if</strong> precision_vals<strong class="lh hi">[</strong>i<strong class="lh hi">]</strong> <strong class="lh hi">!=</strong> precision_vals<strong class="lh hi">[-</strong>1<strong class="lh hi">]:</strong><br/>    plt<strong class="lh hi">.</strong>text<strong class="lh hi">(</strong>recall_vals<strong class="lh hi">[</strong>i<strong class="lh hi">],</strong> val<strong class="lh hi">,</strong> <em class="lz">str</em><strong class="lh hi">(</strong><em class="lz">round</em><strong class="lh hi">(</strong>thresholds<strong class="lh hi">[</strong>i<strong class="lh hi">],</strong>3<strong class="lh hi">)),</strong> fontsize<strong class="lh hi">=</strong>10<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>axvline<strong class="lh hi">(</strong>x<strong class="lh hi">=</strong>1<strong class="lh hi">,</strong>ymin<strong class="lh hi">=</strong>0<strong class="lh hi">,</strong> ymax<strong class="lh hi">=</strong>0.95<strong class="lh hi">,</strong> color<strong class="lh hi">=</strong>'r'<strong class="lh hi">,</strong> label<strong class="lh hi">=</strong>"Best Model"<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>axhline<strong class="lh hi">(</strong>y<strong class="lh hi">=</strong>1<strong class="lh hi">,</strong> xmin<strong class="lh hi">=</strong>0<strong class="lh hi">,</strong> xmax<strong class="lh hi">=</strong>0.95<strong class="lh hi">,</strong> color<strong class="lh hi">=</strong>'r'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>xlabel<strong class="lh hi">(</strong>'Recall'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>ylabel<strong class="lh hi">(</strong>'Precision'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>legend<strong class="lh hi">([</strong>'PR Curve'<strong class="lh hi">,</strong> 'Best model'<strong class="lh hi">],</strong> loc <strong class="lh hi">=</strong> 'best'<strong class="lh hi">)</strong></span><span id="7e13" class="ll jr hh lh b fi lq ln l lo lp">plt<strong class="lh hi">.</strong>show<strong class="lh hi">()</strong></span></pre><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mi"><img src="../Images/7c11d8256c043761030bde02dddb9396.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*aaV8HTw2h9zszoI370N64A.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="f973" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，我们计算了每个阈值的精度和召回值，并绘制了它们。红线代表完美的分类器应该是什么样子。我们的公关曲线似乎也表现不错。在每个标记上，我们还可以看到相关的阈值概率值。我们想选择更接近完美红线的门槛。这里取决于我们的目标是最大化哪个度量，我们可以据此选择阈值。如果我们对查全率或查准率没有偏好，我们也可以计算每个阈值的f1值，并据此进行选择。</p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="1b72" class="ll jr hh lh b fi lm ln l lo lp">f1_score <strong class="lh hi">=</strong> <strong class="lh hi">(</strong>2 <strong class="lh hi">*</strong> precision_vals <strong class="lh hi">*</strong> recall_vals<strong class="lh hi">)</strong> <strong class="lh hi">/</strong> <strong class="lh hi">(</strong>precision_vals <strong class="lh hi">+</strong> recall_vals<strong class="lh hi">)</strong></span><span id="11a7" class="ll jr hh lh b fi lq ln l lo lp">f1_score:</span><span id="07a5" class="ll jr hh lh b fi lq ln l lo lp">array([0.96598639, 0.95890411, 0.96551724, 0.97222222, 0.97902098,<br/>       0.97183099, 0.9787234 , 0.98571429, 0.97841727, 0.97101449,<br/>       0.96350365, 0.95588235, 0.94814815, 0.94029851, 0.93233083,<br/>       0.92424242, 0.91603053, 0.90769231, 0.89922481, 0.890625  ,<br/>       0.88188976, 0.87301587, 0.864     , 0.85483871, 0.84552846,<br/>       0.83606557, 0.82644628, 0.81666667, 0.80672269, 0.79661017,<br/>       0.78632479, 0.77586207, 0.76521739, 0.75438596, 0.74336283,<br/>       0.73214286, 0.72072072, 0.70909091, 0.69724771, 0.68518519,<br/>       0.6728972 , 0.66037736, 0.64761905, 0.63461538, 0.62135922,<br/>       0.60784314, 0.59405941, 0.58      , 0.56565657, 0.55102041,<br/>       0.53608247, 0.52083333, 0.50526316, 0.4893617 , 0.47311828,<br/>       0.45652174, 0.43956044, 0.42222222, 0.40449438, 0.38636364,<br/>       0.36781609, 0.34883721, 0.32941176, 0.30952381, 0.28915663,<br/>       0.26829268, 0.24691358, 0.225     , 0.20253165, 0.17948718,<br/>       0.15584416, 0.13157895, 0.10666667, 0.08108108, 0.05479452,<br/>       0.02777778, 0.        ])</span><span id="2877" class="ll jr hh lh b fi lq ln l lo lp">import numpy <strong class="lh hi">as</strong> np<br/>ix <strong class="lh hi">=</strong> np<strong class="lh hi">.</strong>argmax<strong class="lh hi">(</strong>f1_score<strong class="lh hi">)</strong><br/><em class="lz">print</em><strong class="lh hi">(</strong>'Best Threshold=%f, F1-Score=%.3f' <strong class="lh hi">%</strong> <strong class="lh hi">(</strong>thresholds<strong class="lh hi">[</strong>ix<strong class="lh hi">],</strong> f1_score<strong class="lh hi">[</strong>ix<strong class="lh hi">]))</strong></span><span id="c193" class="ll jr hh lh b fi lq ln l lo lp">Best Threshold=0.851244, F1-Score=0.986</span></pre><h1 id="e8c7" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">ROC曲线(受试者工作特性曲线)</h1><p id="537d" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">ROC曲线是通过绘制真阳性率(召回)对假阳性率(FPR)来指示不同分类阈值的分类模型的性能的图。它与PR曲线有相似的想法，但我们在这条曲线上绘制的是FPR而不是精度。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mj"><img src="../Images/6e81eeaf8f1e14c8610aefd4ed94094e.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*ARAp41JlrAaEVf__I-9DcQ.png"/></div></figure><p id="3575" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了绘制分类器的ROC曲线，我们将使用sklearn库中的roc_curve()函数。</p><p id="863d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html" rel="noopener ugc nofollow" target="_blank">roc _ curve()的文档</a></p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="aef7" class="ll jr hh lh b fi lm ln l lo lp">from sklearn.metrics import roc_curve<br/>fpr<strong class="lh hi">,</strong> tpr<strong class="lh hi">,</strong> thresholds <strong class="lh hi">=</strong> roc_curve<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> probabilities<strong class="lh hi">)</strong></span><span id="46e7" class="ll jr hh lh b fi lq ln l lo lp">plt<strong class="lh hi">.</strong>plot<strong class="lh hi">(</strong> fpr<strong class="lh hi">,</strong> tpr<strong class="lh hi">,</strong>  label <strong class="lh hi">=</strong> 'ROC Curve'<strong class="lh hi">,</strong> marker<strong class="lh hi">=</strong>'o'<strong class="lh hi">)</strong><br/><strong class="lh hi">for</strong> i<strong class="lh hi">,</strong>val <strong class="lh hi">in</strong> <em class="lz">enumerate</em><strong class="lh hi">(</strong>tpr<strong class="lh hi">):</strong><br/>    plt<strong class="lh hi">.</strong>text<strong class="lh hi">(</strong>fpr<strong class="lh hi">[</strong>i<strong class="lh hi">],</strong> val<strong class="lh hi">,</strong> <em class="lz">str</em><strong class="lh hi">(</strong><em class="lz">round</em><strong class="lh hi">(</strong>thresholds<strong class="lh hi">[</strong>i<strong class="lh hi">],</strong>3<strong class="lh hi">)),</strong> fontsize<strong class="lh hi">=</strong>10<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>xlabel<strong class="lh hi">(</strong>'FPR'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>ylabel<strong class="lh hi">(</strong>'TPR'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>legend<strong class="lh hi">(</strong>loc <strong class="lh hi">=</strong> 'best'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>show<strong class="lh hi">()</strong></span></pre><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mk"><img src="../Images/fcafa98dfa227ee20fb1f5a8c7979b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*yjLZq7cTWVYxauINJG1JxA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="5a54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过降低分类阈值，更多的预测被识别为肯定的。这增加了假阳性率和真阳性率。因此，该曲线看起来与PR曲线不同。</p><p id="775d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在ROC曲线中，我们寻找最接近左上角的理想点。用一个数字来估计我们的曲线离左上角有多近是有用的，对吗？曲线下面积(AUC)是另一种可以帮助我们的方法。</p><h1 id="9fba" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">曲线下面积</h1><p id="c9a2" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">曲线下的AUC /面积是ROC曲线下的整个二维面积。AUC帮助我们将ROC曲线(也可用于PR曲线)中的信息总结为一个值。</p><p id="06b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ROC曲线基本上是概率(阈值)曲线，AUC基本上是类别可分性的度量。它告诉我们该模型能够多好地预测类别。因此，更高的AUC值意味着更好的分类器。AUC值在0和1之间变化，意味着值1将意味着完美的分类器。</p><p id="f715" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算roc的AUC分数，我们将使用sklearn库中的roc_auc_score()函数。</p><p id="780d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">【roc _ auc _ score()的文档</p><p id="897c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在继续之前，让我们再次绘制ROC曲线，直观地检查曲线下的区域。</p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="6efc" class="ll jr hh lh b fi lm ln l lo lp">plt<strong class="lh hi">.</strong>plot<strong class="lh hi">(</strong> fpr<strong class="lh hi">,</strong> tpr<strong class="lh hi">,</strong>  label <strong class="lh hi">=</strong> 'ROC curve'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>fill_between<strong class="lh hi">(</strong>fpr<strong class="lh hi">,</strong> tpr<strong class="lh hi">,</strong> alpha<strong class="lh hi">=</strong>0.3<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>xlabel<strong class="lh hi">(</strong>'FPR'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>ylabel<strong class="lh hi">(</strong>'TPR'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>legend<strong class="lh hi">(</strong>loc <strong class="lh hi">=</strong> 'best'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>grid<strong class="lh hi">()</strong><br/>plt<strong class="lh hi">.</strong>show<strong class="lh hi">()</strong></span></pre><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mk"><img src="../Images/f7acd55c3f0b1857309560e8c861e2f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*RaWxkDNqtTFY4P99DCrtOQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="c170" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不能区分两个类别的分类器模型(无技能分类器)将预测最频繁出现的类别或所有预测的随机类别，并且它将具有0.5的AUC。它的ROC曲线是一条对角线，如下所示。一直预测错误(0%正确预测)的分类器看起来与最佳曲线完全相反。</p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="d140" class="ll jr hh lh b fi lm ln l lo lp">from sklearn.metrics import roc_curve</span><span id="3b27" class="ll jr hh lh b fi lq ln l lo lp">pnt_1 <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>0<strong class="lh hi">,</strong> 1<strong class="lh hi">]</strong><br/>pnt_2 <strong class="lh hi">=</strong> <strong class="lh hi">[</strong>0<strong class="lh hi">,</strong> 1<strong class="lh hi">]</strong><br/>fpr<strong class="lh hi">,</strong> tpr<strong class="lh hi">,</strong> thresholds <strong class="lh hi">=</strong> roc_curve<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> probabilities<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>plot<strong class="lh hi">(</strong> fpr<strong class="lh hi">,</strong> tpr<strong class="lh hi">,</strong>  label <strong class="lh hi">=</strong> 'ROC curve for DecisionTree'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>plot<strong class="lh hi">(</strong> pnt_1<strong class="lh hi">,</strong> pnt_2<strong class="lh hi">,</strong>  label <strong class="lh hi">=</strong> 'ROC curve for AUC=0.5'<strong class="lh hi">,</strong> color<strong class="lh hi">=</strong>'r'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>fill_between<strong class="lh hi">(</strong> pnt_1<strong class="lh hi">,</strong> pnt_2<strong class="lh hi">,</strong> alpha<strong class="lh hi">=</strong>0.3<strong class="lh hi">,</strong> facecolor<strong class="lh hi">=</strong>'r'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>axvline<strong class="lh hi">(</strong>x<strong class="lh hi">=</strong>1<strong class="lh hi">,</strong>ymin<strong class="lh hi">=</strong>0.05<strong class="lh hi">,</strong> ymax<strong class="lh hi">=</strong>0.95<strong class="lh hi">,</strong> color<strong class="lh hi">=</strong>'r'<strong class="lh hi">,</strong> linestyle<strong class="lh hi">=</strong>'--'<strong class="lh hi">,</strong> label<strong class="lh hi">=</strong>"ROC curve for AUC=0.0"<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>axhline<strong class="lh hi">(</strong>y<strong class="lh hi">=</strong>0<strong class="lh hi">,</strong> xmin<strong class="lh hi">=</strong>0.05<strong class="lh hi">,</strong> xmax<strong class="lh hi">=</strong>0.95<strong class="lh hi">,</strong> color<strong class="lh hi">=</strong>'r'<strong class="lh hi">,</strong> linestyle<strong class="lh hi">=</strong>'--'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>xlabel<strong class="lh hi">(</strong>'FPR'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>ylabel<strong class="lh hi">(</strong>'TPR'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>legend<strong class="lh hi">(</strong>loc <strong class="lh hi">=</strong> 'best'<strong class="lh hi">)</strong><br/>plt<strong class="lh hi">.</strong>show<strong class="lh hi">()</strong></span></pre><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mk"><img src="../Images/d19e1913f9054b58a42261ae7d177ab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*N2roek4I8Ld0MxYjdHqyhg.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Source: Author</figcaption></figure><p id="740d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以使用sklearn库中的roc_auc_score函数来计算上图的ROC AUC分数</p><pre class="ku kv kw kx fd lg lh li lj aw lk bi"><span id="0d02" class="ll jr hh lh b fi lm ln l lo lp">from sklearn.metrics import roc_auc_score</span><span id="d711" class="ll jr hh lh b fi lq ln l lo lp">roc_auc_score<strong class="lh hi">(</strong>y_test<strong class="lh hi">,</strong> probabilities<strong class="lh hi">)</strong></span><span id="4636" class="ll jr hh lh b fi lq ln l lo lp">0.9977071732721913</span></pre><p id="6a71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">优点:</strong></p><ul class=""><li id="0421" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">AUC不随比例变化。这是对预测排名好坏的衡量，而不是它们的绝对值。</li><li id="7a48" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">AUC对分类阈值是不变的。它是对模型性能(预测正确性)的一种度量，与选择的分类阈值无关。</li></ul><p id="c436" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">缺点:</strong></p><ul class=""><li id="43d9" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">对比例的不变性并不总是需要的。有时我们需要适应良好的概率输出。</li><li id="be94" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">对阈值的不变性并不总是需要的。当在假阴性和假阳性方面有很大差异时，我们可能希望只将其中一个最小化。例如，在前面的癌症例子中，我们提到了减少假阴性的重要性。在这种情况下，AUC将不是一个有用的指标。</li></ul><h1 id="33ee" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">PR曲线对ROC曲线</h1><ul class=""><li id="1e11" class="jc jd hh ig b ih ko il kp ip ml it mm ix mn jb jh ji jj jk bi translated">ROC曲线适用于处理更多的平衡数据集，而PR曲线适用于不平衡数据集。</li><li id="8052" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">PR cuve不考虑真正的否定，因此当我们有一个不平衡的数据集时，它是一个有用的度量，如果否定类是多数类，考虑做出正确的否定预测对问题来说不是那么关键。</li><li id="36a8" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">由于ROC曲线也考虑了真正的负面因素，如果当负面类别也很重要时(当TP和TN都很重要时)，这是一个更好的度量标准。</li></ul><p id="8a7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们讨论了分类问题的评估方法。我希望这有助于理解这些普遍使用的指标。如果您有任何问题或反馈，请随时在下面留言！</p><p id="dc8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你喜欢这个，欢迎关注我，获取更多免费的机器学习教程和课程！</p><div class="mo mp ez fb mq mr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hi fi z dy mw ea eb mx ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">medium.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf kz mr"/></div></div></a></div></div></div>    
</body>
</html>
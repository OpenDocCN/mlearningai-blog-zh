<html>
<head>
<title>Explain it to me like a 5-year-old: Beginners guide to Deep Learning &amp; Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">像5岁小孩一样给我解释:深度学习和神经网络初学者指南</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/explain-it-to-me-like-a-5-year-old-beginners-guide-to-deep-learning-neural-network-1eb6a979f74?source=collection_archive---------0-----------------------#2021-02-21">https://medium.com/mlearning-ai/explain-it-to-me-like-a-5-year-old-beginners-guide-to-deep-learning-neural-network-1eb6a979f74?source=collection_archive---------0-----------------------#2021-02-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8368" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我是一名具有深度学习和数据科学背景的项目经理。深度学习令人生畏，我正试图让它尽可能直观。如果您认为下面的任何内容需要纠正，请随时联系我或发表评论——我对反馈持开放态度。</p><p id="eb38" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我在这里的意图是让理解深度学习变得容易和有趣，而不是数学和全面。我还没有详细解释每件事，但我相信在博客结束时，你将能够理解神经网络是如何工作的，并且你将永远不会忘记它！！！；)</p><p id="8e83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">欢迎在LinkedIn 上与我联系！</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><h1 id="b380" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">AI vs ML vs深度学习:</h1><p id="a35b" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi kn translated"><span class="l ko kp kq bm kr ks kt ku kv di">人工智能顾名思义就是给计算机提供智能，类似于人类所拥有的。将人工智能视为一把大伞，由ANI(人工狭义智能)——面向目标并为单一任务编程，AGI(人工通用智能)——允许机器以与人类无法区分的方式行事，以及ASI(人工超级智能)——机器比最聪明的人类思维更聪明。</span></p><p id="4329" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi kn translated"><span class="l ko kp kq bm kr ks kt ku kv di"> M </span>机器学习是人工智能的一个子集，在给定数据和算法的情况下，机器会自动训练自己，变得更加智能，无需人工干预。有3种类型的最大似然算法——监督的、非监督的和强化的。</p><p id="3b23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi kn translated">eep学习模仿人类大脑如何运作(因此它有神经元、网络等)。类似于人脑所具有的)。当数据量开始增加时，ML只能应付到某个点，之后就会饱和。这就是深度学习发挥作用的地方——DL是一种用于大型数据集的ML。</p><p id="5b9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感知机如何工作的想法，深度学习的构建模块，早在1958年就被发现了，那么为什么当时没有使用DL，而现在却被广泛使用呢？数据！与运行DL算法相比，运行ML算法占用的资源要少得多，以我们在1958年可用的数据量，我们在ML上做得很好。但是随着硬件(GPU等)的进步。)、软件(新模型、工具箱等。)和数据量的增加—我们正处于需要使用DL来提高模型性能的阶段</p><p id="a40f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了理解DL算法是如何工作的，我们首先需要理解感知机是如何工作的。为了简单起见，您可以认为大多数DL模型只是混合了多种感知，仅此而已。这就好比如果你理解了数字的含义(即感知器)，那么你就很容易用它们做加法和减法(即DL模型)。</p><h1 id="23fd" class="jk jl hh bd jm jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh bi translated">感知器:</h1><p id="3ae9" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">感知器是一种神经网络单元，它执行某些计算来检测输入数据中的特征或商业智能。</p><p id="ea29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">直觉:</strong>考虑你想买房子——你会考虑多个因素，比如位置(x1)、卧室数量(x2)、总面积(x3)、宠物友好(x4)、上班距离(x4)等。有些因素对你来说比其他因素更重要，例如位置和卧室数量，所以你在做决定时会对每个因素给予不同的重视。因此，当你的大脑想要做出中间决定时，它会将这些因素以及重要性考虑在内，并添加一点多年来形成的偏见(例如，如果你整天都在吃白面包，你的大脑会偏向于选择白面包而不是黑面包)。这正是感知器的运作方式。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lb"><img src="../Images/94a5e4afb0a6a0e25fef9d84898dbdb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ECf7LOQ7q5qdW2Gd9-UwRQ.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 1.1 MIT 6.S191</figcaption></figure><p id="ee71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上图中，您考虑的因素是<em class="lr">输入，</em>您为每个因素提供的重要性是<em class="lr">权重</em>，您采取的中间决策只是输入和偏差<em class="lr">(橙色节点)</em>的线性组合。</p><p id="6ff1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你的大脑和DL感知器之间的唯一区别是，你需要应用一个非线性的组成(在DL中它被称为激活函数)来将你的中间决策转换为最终决策。为什么非线性和非线性？看下面的图表</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ls"><img src="../Images/c62ce1800dc996ccb4e3d45060f0d93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WxoEgwUjXQgbb1CrJQACrQ.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 1.2 MIT 6.S191</figcaption></figure><p id="a5fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有不同的非线性函数可以应用于你的中间决策——sigmoid、ReLU、双曲线等。，我们稍后会讲到。</p><p id="ef41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总而言之，我们可以说图1.1中的最终决策(y)只是应用于你的中间决策(z)的非线性组合(g)——这就是感知器的工作方式，又名<strong class="ig hi">正向传播</strong></p><h1 id="bca5" class="jk jl hh bd jm jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh bi translated">神经网络:</h1><p id="98ee" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">难道你不认为与其只有一个中间决策(z)来得出最终决策(y)，不如有多个中间决策(z1，z2，z3，…)来帮助你做出最终决策(y)更容易吗？我们刚刚描述了单个神经网络。多个中间决策的集合在DL行话中被称为“隐藏层”</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lt"><img src="../Images/a773eb3980dc65ad4fe34d6617c0601e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_rpq5O1FWXKwUb_fpChSTA.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.1 MIT 6.S191</figcaption></figure><p id="42bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上面的例子中，他们已经使用隐藏层吐出两个决定(y1和y2)，你也可以有一个决定。</p><h2 id="4570" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">应用神经网络:</h2><p id="c5b3" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated"><strong class="ig hi">直觉:</strong>我们举一个简单的吉他调音的例子。假设你想调E和弦——你拨动琴弦，检查它是否与E和弦匹配。如果你觉得你的E和弦听起来和它应该听起来的差别很大，那么你拧紧或松开旋钮，让琴弦听起来更接近E和弦。在几次拧紧和松开旋钮的尝试之后，你找到了达到E和弦的完美平衡——这就是你的大脑的工作方式，也正是神经网络的工作方式。</p><p id="4169" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在神经网络的情况下，考虑拨弦的动作为<em class="lr">输入</em>，旋钮为<em class="lr">权重。</em>因此，我们通过以下方式启动神经网络</p><ul class=""><li id="fcd4" class="mi mj hh ig b ih ii il im ip mk it ml ix mm jb mn mo mp mq bi translated"><strong class="ig hi">第一步:</strong>给出输入(拨弦)并计算<strong class="ig hi">经验损耗</strong>(了解它应该听起来和听起来的区别)，</li><li id="1b24" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated"><strong class="ig hi">第二步:</strong>基于损失，我们调整权重(旋钮)。</li></ul><p id="74a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个过程也被称为<strong class="ig hi">反向传播</strong></p><h2 id="87a7" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">步骤1:计算经验损失</h2><p id="db83" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">这是经验损失的计算方法:</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mw"><img src="../Images/6023625da09ee831f0ba24cf9949e27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HcxMfK8EdSo1BzOBiwKamA.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.2 MIT 6.S191</figcaption></figure><p id="e86f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以如果你看到，这主要是你的模型给出的和它应该给出的不同。正如我们所知，我们可以预期不同类型的输出:二进制(0/1)或连续实数，有不同的方法来计算它们的损失(见下文)</p><p id="06fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">二进制输出的交叉熵损失:</strong></p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mx"><img src="../Images/043c18d6858c585a99cf1046a14e84da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e3SEPEE86sUkfGr9JOz_Aw.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.3 MIT 6.S191</figcaption></figure><p id="a395" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">连续数字输出的均方误差:</strong></p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es my"><img src="../Images/800823c96a39818d83d676816090098d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O5p91fAXqNrvPmCXoyCaAw.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.4 MIT 6.S191</figcaption></figure><h2 id="084d" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">第二步:优化我们的损失</h2><p id="100e" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">如上所述，现在我们有了损失，我们将需要调整我们的权重(旋钮)来降低损失——这个过程被称为“损失优化”。<br/>为了降低损失，我们使用了<strong class="ig hi">【梯度下降】</strong>算法。</p><p id="ba03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">很简单:</p><ul class=""><li id="2106" class="mi mj hh ig b ih ii il im ip mk it ml ix mm jb mn mo mp mq bi translated">你首先要了解你目前所处的位置。</li><li id="4c70" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">然后你对损失函数求导，也就是<strong class="ig hi">计算梯度</strong>——你会问为什么要求导？如果你想最大化你的损失，求导会给你指明方向。等等！但是我们不需要把损失降到最低吗？当然，因此在下面的公式中，你会发现导数前面有一个负号。</li><li id="aeb6" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">通过使用梯度调整权重，你开始朝着这个方向迈出一小步——步长有多小，由<strong class="ig hi">“学习速率”(见图2.6的步骤4)</strong>定义</li></ul><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mz"><img src="../Images/6960e17b35f279e65d3f031496b44c6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gfqybbPhga2CWBmGeOmyqA.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.5 MIT 6.S191</figcaption></figure><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es na"><img src="../Images/a82ff5770f29a93dfa6b07e16dce508a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mwKI06MBt2pN0YQViRvvPg.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.6 MIT 6.S191</figcaption></figure><p id="8860" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失函数很难优化，因为很难知道我们需要采取多小的步骤(学习率)。如果太小，你可能会陷入局部极小值，如果太大，你会不断反弹，永远达不到全局极小值。</p><p id="f233" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有多种梯度下降法可以帮助你做到这一点:</p><ul class=""><li id="7707" class="mi mj hh ig b ih ii il im ip mk it ml ix mm jb mn mo mp mq bi translated">随机梯度下降</li><li id="cb29" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">圣经》和《古兰经》传统中）亚当（人类第一人的名字</li><li id="0314" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">阿达德尔塔</li><li id="0274" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">阿达格拉德</li><li id="adee" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">RMSProp</li></ul><h1 id="3e98" class="jk jl hh bd jm jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh bi translated">过度拟合的问题:</h1><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nb"><img src="../Images/a98a94d517cbbbbf8d66540af9d9e198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhh5KD-gCwf_vo8VHLzLpw.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.7 MIT 6.S191</figcaption></figure><p id="981e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">直觉:假设你即将面临一场考试，有人给你一个题库来修改你的材料。你不去修改，而是把Q银行作为唯一的学习来源，试着只学习银行的问题。因此，当你参加考试时，你可能知道Q银行中的问题的答案，但无法回答Q银行之外但与这些问题有一定关系的问题。这太合身了。</p><p id="4314" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决这个问题，我们有所谓的“<strong class="ig hi">正则化</strong>”——这有助于增加我们的模型对看不见的数据的泛化，在我们的情况下，问题不在Q Bank上。不同类型的正则化技术有:</p><ul class=""><li id="cf13" class="mi mj hh ig b ih ii il im ip mk it ml ix mm jb mn mo mp mq bi translated"><strong class="ig hi">退出</strong> —在训练过程中，随机设置一些激活为0</li><li id="59c9" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated"><strong class="ig hi">提前停止</strong> —一旦测试设备上的损耗开始增加，就停止训练。注意:训练集的损失永远不会增加(见图2.8)</li></ul><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nc"><img src="../Images/a4b441a1c67ad18fd36f5c94b435eb19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YYiNRc6RSxeDz9ekIDV8-Q.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx">Fig 2.8 MIT 6.S191</figcaption></figure><h1 id="f708" class="jk jl hh bd jm jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh bi translated">总结:</h1><ol class=""><li id="6b67" class="mi mj hh ig b ih ki il kj ip nd it ne ix nf jb ng mo mp mq bi translated">分配随机权重</li><li id="2906" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb ng mo mp mq bi translated">得到最初的预测</li><li id="4e89" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb ng mo mp mq bi translated">计算损失</li><li id="bc00" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb ng mo mp mq bi translated">尝试优化损失:使用SGD，Adam，Adaboost</li><li id="baf1" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb ng mo mp mq bi translated">避免过度拟合:正则化-退出，提前停止</li></ol></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="b441" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">学分:麻省理工学院开放式课程，Simplillearn</p></div></div>    
</body>
</html>
<html>
<head>
<title>Improving Crowd Wisdom with Machine Learning — part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习提高群体智慧—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/improving-crowd-wisdom-with-machine-learning-classification-721b5e0d7c9d?source=collection_archive---------1-----------------------#2021-05-18">https://medium.com/mlearning-ai/improving-crowd-wisdom-with-machine-learning-classification-721b5e0d7c9d?source=collection_archive---------1-----------------------#2021-05-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ea9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">大家好！我是Ivan，在这个系列中，我将介绍机器学习在预测数据集上的一些实际应用。我们的目标是展示几个简单的ML模型如何极大地提高我们对群体智慧的理解和效率，并将其与受访者的个性相关联。</p><p id="a143" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看，知道群体中每个人有多神经质是否能告诉我们他们对某些事情的普遍共识的预测有多准确。</p><h1 id="ba30" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">对群体智慧的快速介绍</h1><p id="c7ec" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">你可能听说过<a class="ae kf" href="https://en.wikipedia.org/wiki/The_Wisdom_of_Crowds" rel="noopener ugc nofollow" target="_blank">故事</a> …一个人去集市，一个人藏起一头死牛，人们猜测它的重量，误差在1%以内。自从这个经典的概念引入以来，即一群人可以提供比任何个人更精确的估计，“群体智慧”(WoC)现象已经遇到了无数次试图解释潜在机制的尝试，从纯科学到相当深奥。</p><p id="d487" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如今大多数研究人员都同意的一个解释是，群体智慧本质上是一个聚集信息的过程，它将个人判断建模为概率分布，并将中间结果视为最接近事实的结果。此外，有一个共识，即并非所有的群体生来平等，判断的多样性、信息偏见和领域专长都可以在决定群体智慧的成功方面发挥关键作用。然而，除此之外，研究人员试图解释是什么让一个群体比另一个群体更成功。</p><p id="5c83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不要在特定的理论上做太多的细节，对于这个将WoC与ML“结合”的实际尝试，我借用下面的假设:</p><ol class=""><li id="f775" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated"><strong class="ig hi"> WoC是一个集合模型，其中所有的估计量都会产生误差，在最优人群中，这些误差完全相互抵消。</strong></li></ol><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kp"><img src="../Images/932b6024cba8c8386fe2146b463587bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUklEYZVII99hq2OsrcIig.jpeg"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Image 1: Wisdom of Crowds viewed as an aggregation of estimator errors with a total sum of zero in perfectly balanced crowds</figcaption></figure><p id="49b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将我们的机器学习基于这一原则的一个直接结果是，我们不必寻找具有最佳估计量的人群，而是寻找估计其误差大小和方向的方法。正如信息偏差(或独立性)原理所述，如果所有评估者的观点都基于同一组来源，那么群体的质量就会下降。</p><p id="15de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从整体来说，</p><p id="df46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lf">来源多样化=信息增益</em></p><p id="e9ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">额外的估计量的价值取决于它们对熵的影响。类似的推理适用于判断的多样性原则，只是它不衡量信息的来源，而是衡量个体评估者处理这些信息的多样性。是的，我们仍然在这里谈论人，所以个人估计者是一个人或(希望)某一类型的人，他们总是相似地高估/低估基本事实。所以在这种情况下，</p><p id="79f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lf">判断类型的多样性=信息增益</em></p><p id="c486" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这一方面将是这篇文章/研究的重点，因为我们将研究评估者的偏好作为多样性的关键。</p><p id="da87" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。WoC中的最佳结果可以通过多种方式实现。</strong></p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lg"><img src="../Images/1045222d6b0133c51253f7b1a8a3ad51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oXf233A_4N2i1yb9_zspNQ.jpeg"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Image 2: Hypothetically, any combination of positive and negative errors can achieve a zero-error equilibrium</figcaption></figure><p id="6bfa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们将WoC视为误差的集合，任何误差的组合都可以假设达到平衡。例如，如果我们有100个误差呈正态分布的估计量，并以10个为一组创建随机组合，通过足够数量的模拟，我们将获得正态分布数量的最佳或接近最佳的组合。当然，真正的问题是，哪些组合比纯粹靠运气更有可能实现这一目标。</p><p id="7d15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或者用另一种方式来定义潜在的解决方案，<em class="lf">我们是否可以估计误差的大小和方向，以至于每个组合都可以重新计算为接近最优的组合？</em></p><p id="48fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。(可能)有一个最小人群规模要求</strong></p><p id="c6b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我说有可能，但是所有的研究都表明存在一定的最小值。从我们的错误汇总角度来看，这可能是因为存在<em class="lf"> n </em>种不同的类型，它们的存在对于实现有效的多样性是必要的，或者不同风格之间的界限不清楚，需要足够大的数量来确保清晰。</p><p id="3ba9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。领域专业知识可能会扭曲数据</strong></p><p id="4ef5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然我们可能专注于概括人格类型来估计错误，但领域专业知识已被证明会影响个人的错误率。我们将把这个问题作为WOC的特例来处理，因为我们使用的是主观数据。现在，我们只能说，在专业领域，我们将依赖于“惊人地普遍”原则的见解，这是一个概率原则，它将帮助我们覆盖地面真理和自信估计之间的许多地面。</p><p id="79a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5。受访者是弱估计量，人群是总体估计量</strong></p><p id="2788" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我再怎么强调这一点也不为过(主要是对我自己，但是如果你正在阅读，那就更好了！).在这个过程中，小规模人群(理想情况下是20-30人)是实际的估计者。考虑这是一个公平的警告，因为我们将做一些奇怪的事情，如人类维度的减少和目标变量的特征工程。</p><h1 id="fcb9" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">研究细节</h1><p id="fd30" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">除了在WoC的几种竞争性解释中接受这些假设之外，请记住，这项研究是在考虑一些具体情况的情况下设计的。</p><p id="1a77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">我们正在谈论主观的事情</strong></p><p id="6ffd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">WoC有不同的可能应用。它在<a class="ae kf" rel="noopener" href="/guess-market/crowd-intelligence-in-financial-markets-6aab50078b4a">金融市场非常流行，例如</a>，这主要是一个客观领域。然而，在这项研究中，我们研究的是主观领域的估计，即个人偏好。这些类型的预测是特定的，因为地面真相总是只能被设定为共识(在与当前人群相比相对较大的规模上)。这一特点有趣的一面是，它允许我们将基本事实缩小到特定的人群。正因为如此，成为主观预测的“专家”实际上意味着成为某一范围人群的味觉专家。</p><p id="17bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">重点解读</strong></p><p id="b9a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管最终目标是找到“完美”人群的公式，但在整个研究中，我们将主要关注解释。这意味着我们不会追求尽可能高的分数，而是留待以后实现。</p><p id="4851" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> TIVI/TIPI校准</strong></p><p id="7d2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了深入了解受访者的性格，我们使用了五大(海洋)性格测试和价值观测试的简化版。虽然问题数量大幅减少(从100多个减少到30个)，但这两份问卷在过去都取得了良好的效果。高斯林实验室的网页建议我们将数据集中在受访者的平均水平上，以更好地解释受访者内在特征的差异。在这一点上，我觉得有必要指出，在我们进入系列的项目反应理论部分之前，我将数据保留为原始形式，因为这一部分对Gosling说明中提到的基本原则给予了很多关注。</p><h1 id="80a4" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">关于数据集</h1><p id="98f3" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">这篇文章中使用的数据最初是我的公司在2018年与萨格勒布经济学院在信息聚合领域进行的一项研究的一部分。这意味着我不能自由地向公众完全公开数据集，但会尽可能多地发布。</p><p id="a27a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">957名受访者观看了6个视频，并回答是否会用“喜欢”来评价。他们还被要求估计百分之多少的回答者会给它一个“喜欢”的评价，并回答来自<a class="ae kf" href="https://gosling.psy.utexas.edu/scales-weve-developed/ten-item-personality-measure-tipi/#:~:text=The%20TIPI%20is%20a%2010,Five%2DFactor%20Model)%20dimensions.&amp;text=A%20Very%20Brief%20Measure%20of,%2C%2037%2C%20504%2D528." rel="noopener ugc nofollow" target="_blank"> TIPI </a>和<a class="ae kf" href="http://gosling.psy.utexas.edu/two-short-measures-of-values-tivi-and-twivi/" rel="noopener ugc nofollow" target="_blank"> TIVI </a>简短人格问卷的20个问题。</p><p id="dcfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在研究中，我们使用总体喜欢/不喜欢比率作为基本事实，95%置信水平下的置信区间如下:</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lh"><img src="../Images/67d378c355517ea5eff94d17e898732f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*RshKVvYfBfyGXzEzW7Ylcw.png"/></div></figure><h1 id="d8bc" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">数据探索</h1><p id="757d" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们注意到的第一件事是，对于分数较低(在0到0.1之间)和接近0.5时较低的视频，有高估更多的趋势。</p><pre class="kq kr ks kt fd li lj lk ll aw lm bi"><span id="c96b" class="ln jd hh lj b fi lo lp l lq lr">colors=["red","blue","green","orange","purple","pink"]</span><span id="096f" class="ln jd hh lj b fi ls lp l lq lr">f,axes=plt.subplots(6,1)</span><span id="7049" class="ln jd hh lj b fi ls lp l lq lr">  for i in range(0,predictions.columns.size):</span><span id="a6f4" class="ln jd hh lj b fi ls lp l lq lr">  x=predictions.iloc[:,i]</span><span id="41aa" class="ln jd hh lj b fi ls lp l lq lr">  sns.kdeplot(x,bw_adjust=3,fill=True,alpha=0.2, ax=axes[i], color=colors[i], clip=(0,1))</span><span id="8011" class="ln jd hh lj b fi ls lp l lq lr">  axes[i].axvline(x=x.mode()[0],color=colors[i], linestyle="dashed")</span><span id="0bea" class="ln jd hh lj b fi ls lp l lq lr">  real=likes.iloc[:,i].mean()</span><span id="5b0f" class="ln jd hh lj b fi ls lp l lq lr">  axes[i].axvline(x=real,color="black", linestyle="dashed")</span><span id="8ad1" class="ln jd hh lj b fi ls lp l lq lr">  axes[i].text(real,0, s=str(round(real,2)))</span><span id="16c0" class="ln jd hh lj b fi ls lp l lq lr">  axes[i].legend(["Predictions","Predictions mode","Actual mean"])</span><span id="5947" class="ln jd hh lj b fi ls lp l lq lr">plt.show()</span></pre><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/399796480eed83afbf04d6e84ff4e4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvSNigd0uzftm5ZdM1akqw.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Image 3: Distribution skew shows correlation to ground truth.</figcaption></figure><p id="9b58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是有道理的，因为在左侧有一面“墙”，即在问卷中没有负面评价，所以受访者更有可能高估。</p><p id="6946" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更好地了解正在发生的事情，我们可以比较高估/低估的数量。如下面的意大利霓虹旗所示，低估的数量基本上与高估的数量持平，为0.5分:</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lu"><img src="../Images/bf6545f85ba64382de5f93951d5841f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*McNYQgN9JUW4k9J4nz60vQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 3</figcaption></figure><p id="0dd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于我们的群体智慧场景，有趣的是，如果我们看中值结果，当我们达到0.5点时，这个群体实际上在估计地面真相方面变得更好。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lv"><img src="../Images/bda622694e3bef21451cc5fde1cfefc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nt50OnS_zNhCh3dhK6LYkA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 4: Overall prediction Median vs Ground truth</figcaption></figure><p id="aab8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是因为我们的分布越正态，误差就越能相互抵消。如图5所示，如果我们从绝对意义上来看误差，正态分布的误差将是偏斜概率的4倍。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/4abc0c7b45ea2c238da934ca50bc8a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GOUH9qm__L331ZrMB9kYjQ.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 5. Median errors in original form (left) drop to less than 1/4 value of their absolute counterparts (right).</figcaption></figure><p id="5d60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，如果我们的群体智慧测试的基本目标是能够聚集来自个体小组(n&gt;30)的预测以获得高度可信的结果，那么我们越接近屏幕的边缘，挑战就越大，因为误差不太可能被平衡。</p><p id="9f80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们手头的任务是找到这种偏斜的函数，所以我们也许能够有效地抵消积极和消极的因素，不管事实真相在哪里。</p><h1 id="0d90" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">预处理数据</h1><p id="b6cd" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们先来谈谈误差的底层分布。有一点是显而易见的，即偏斜至少部分与距离标尺中心的距离(0.5)和方向有关。换句话说，如果实际情况是5%,那么低估不能超过5%。虽然最初的分布曲线可能并不能告诉我们太多:</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/62232996472692e4d63c0656eaf393a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BuRVWGxy6DFpSK4HVLh8w.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 6: Skew of predictions ordered by Ground Truth values</figcaption></figure><p id="a16e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">承认这一点是可行的，即使我们只有高达50%的评级，如果事实真相是95%，也不可能有人高估超过5%(咄！).</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lu"><img src="../Images/7217a30662662f4d9b1cf52f6267e7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*DA6KrV0scDEH3rHiNl7QQQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 7. Even though our respondents only rated items up to a maximum of 0.5, the fact that our error distribution is controlled by the limits of the scale itself, indicates that the total distribution probably looks like this.</figcaption></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lu"><img src="../Images/544fb87b4b4f71144110146445ea9857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*HgR-T5ophZjpIeor7MqdZA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx">Image8: Not only a wonderful decoration for your festival tent, this 2-parameter graph is also how I assume the general distribution looks like, at least as far as it is parameterized by the scale of 0–1.</figcaption></figure><p id="8c18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，为了获得底层函数的公式，我们可以创建额外的模拟数据来增加数据集的密度。我们将通过在所有可能的组合中组合单独的视频分数，并提取它们的基本事实和偏差来做到这一点。我使用Itertools组合，取2-s、3-s、4-s、5-s和所有6个分数的平均值。我还创建了一个对称数据集，从1中减去地面实况得分，从0中减去偏斜，以模拟0.5以上的数据。</p><pre class="kq kr ks kt fd li lj lk ll aw lm bi"><span id="e4d1" class="ln jd hh lj b fi lo lp l lq lr">from itertools import combinations</span><span id="1214" class="ln jd hh lj b fi ls lp l lq lr">listExtraLikes,listExtraSkews=[],[]</span><span id="a306" class="ln jd hh lj b fi ls lp l lq lr">#we create combinations for 2-s, 3-s, etc.</span><span id="53e5" class="ln jd hh lj b fi ls lp l lq lr">for num in np.arange(2,7):</span><span id="5813" class="ln jd hh lj b fi ls lp l lq lr">targetPairs=combinations(np.arange(0,6),num)</span><span id="a89b" class="ln jd hh lj b fi ls lp l lq lr"># then for each combination we take the mean of like scores  <br/>      # and skew of the errors<br/>      for pair in list(targetPairs):</span><span id="639c" class="ln jd hh lj b fi ls lp l lq lr">curMiss=np.array(missCols)[list(pair)]</span><span id="95c8" class="ln jd hh lj b fi ls lp l lq lr">curMiss=df[curMiss].mean(axis=1)</span><span id="6a54" class="ln jd hh lj b fi ls lp l lq lr">curLike=np.array(likeCols)[list(pair)]</span><span id="bee5" class="ln jd hh lj b fi ls lp l lq lr">curLike=df[curLike].mean(axis=1)</span><span id="0e10" class="ln jd hh lj b fi ls lp l lq lr">listExtraLikes=listExtraLikes+[curLike.mean()]</span><span id="ff29" class="ln jd hh lj b fi ls lp l lq lr">listExtraSkews=listExtraSkews+[curMiss.skew()]</span><span id="e346" class="ln jd hh lj b fi ls lp l lq lr">#finally, we combine it into a single dataframe <br/>extras=pdc([pdf(listExtraLikes),pdf(listExtraSkews)],axis=1)</span><span id="cf99" class="ln jd hh lj b fi ls lp l lq lr">extras.columns=["like","skew"]</span></pre><p id="2065" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以平滑它，并使用核岭回归得到潜在的系数。</p><pre class="kq kr ks kt fd li lj lk ll aw lm bi"><span id="f74e" class="ln jd hh lj b fi lo lp l lq lr">from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.kernel_ridge import KernelRidge</span><span id="4b69" class="ln jd hh lj b fi ls lp l lq lr">#first we test our alpha and gamma parameters to ensure we're finding the best balance between bias and variance</span><span id="6da7" class="ln jd hh lj b fi ls lp l lq lr">X_train,X_test,y_train,y_test=train_test_split(X,y)</span><span id="c846" class="ln jd hh lj b fi ls lp l lq lr">alphas=[1,0.5,0.1,0.05,0.001]</span><span id="f201" class="ln jd hh lj b fi ls lp l lq lr">gammas=[0.5,1,2,3,4,5,10]</span><span id="c571" class="ln jd hh lj b fi ls lp l lq lr">scores=pd.DataFrame()</span><span id="c66c" class="ln jd hh lj b fi ls lp l lq lr">for alpha in alphas:</span><span id="35cb" class="ln jd hh lj b fi ls lp l lq lr">for gamma in gammas:</span><span id="7d97" class="ln jd hh lj b fi ls lp l lq lr">clf = KernelRidge(alpha=alpha, kernel="polynomial", gamma=gamma)</span><span id="020c" class="ln jd hh lj b fi ls lp l lq lr">clf.fit(X_train,y_train)</span><span id="9c65" class="ln jd hh lj b fi ls lp l lq lr">res=cross_val_score(clf, X_test,y_test)</span><span id="e2dd" class="ln jd hh lj b fi ls lp l lq lr">resDF=pd.DataFrame([np.mean(res),alpha,gamma]).T</span><span id="1d7c" class="ln jd hh lj b fi ls lp l lq lr">resDF.columns=["score","alpha","gamma"]</span><span id="4ccb" class="ln jd hh lj b fi ls lp l lq lr">scores=scores.append(resDF)</span><span id="b6a4" class="ln jd hh lj b fi ls lp l lq lr">&gt;&gt;&gt;  score     alpha   gamma<br/>&gt;&gt;&gt;  ...<br/>&gt;&gt;&gt;  0.796663  0.001   1.0<br/>&gt;&gt;&gt;  0.817670  0.001   2.0<br/>&gt;&gt;&gt;  0.821492  0.001   3.0<br/>&gt;&gt;&gt;  0.820842  0.001   4.0<br/>&gt;&gt;&gt;  0.819608  0.001   5.0<br/>&gt;&gt;&gt;  0.815899  0.001  10.0</span></pre><p id="25e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果——光滑如丝。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/60926391bda17a63610f7bedbe705aea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gXEqe1VbeLqeHFcyVJPC-Q.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 9: Kernel Ridge regression helps us find the balance between bias and variance and provides us with coefficients for our function.</figcaption></figure><p id="b718" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">TLDR；一部只有10%的人喜欢的电影出现-5%的误差</p><p id="81ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我可能错了，但这就是模拟的目的。现在，让我们假设这是准确的。如果是这样的话，我们可以使用该模型来消除位置效应，也就是说，无论地面实况可能在哪里，都将其归一化。</p><p id="1907" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果我们随机选取30名受访者，并使用他们的预测中值作为基本事实的估计值，标准偏差作为目标值:</p><pre class="kq kr ks kt fd li lj lk ll aw lm bi"><span id="388e" class="ln jd hh lj b fi lo lp l lq lr">#use our function to estimate the standard deviation</span><span id="9190" class="ln jd hh lj b fi ls lp l lq lr">x_=df[predCols[1]].iloc[45:70]</span><span id="7422" class="ln jd hh lj b fi ls lp l lq lr">x_=x_.reset_index(drop=True)</span><span id="8625" class="ln jd hh lj b fi ls lp l lq lr">y = extrasSymmetrical["std"]</span><span id="e924" class="ln jd hh lj b fi ls lp l lq lr">Krr=clf.fit(X, y)</span><span id="53df" class="ln jd hh lj b fi ls lp l lq lr">std_=Krr.predict([[x_.median()]])</span></pre><p id="0315" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，该估计可以与诸如分位数变换器之类的变换器一起使用，以就地归一化数据:</p><pre class="kq kr ks kt fd li lj lk ll aw lm bi"><span id="4a4b" class="ln jd hh lj b fi lo lp l lq lr">#use quantile transformer to normalize</span><span id="1b78" class="ln jd hh lj b fi ls lp l lq lr">qt = QuantileTransformer(n_quantiles=len(x_), output_distribution='normal')</span><span id="dd8c" class="ln jd hh lj b fi ls lp l lq lr">X_trans_qt = qt.fit(x_.values.reshape(-1, 1))</span><span id="5c33" class="ln jd hh lj b fi ls lp l lq lr">refQ=X_trans_qt.references_</span><span id="6448" class="ln jd hh lj b fi ls lp l lq lr">x_norm=X_trans_qt.transform(x_.values.reshape(-1, 1))</span><span id="58f1" class="ln jd hh lj b fi ls lp l lq lr">x_norm = pdf(x_norm)</span><span id="db88" class="ln jd hh lj b fi ls lp l lq lr">#Use minMax scaler to get the transformed data into the 0-1 range</span><span id="7fad" class="ln jd hh lj b fi ls lp l lq lr">x_norm=mm.fit_transform(x_norm)</span><span id="5098" class="ln jd hh lj b fi ls lp l lq lr">#And finally, use our std_ and mean_ to position inside the real range, for practicality</span><span id="06d7" class="ln jd hh lj b fi ls lp l lq lr">q_min=x_.mean()-3*std_</span><span id="ceef" class="ln jd hh lj b fi ls lp l lq lr">q_max=x_.mean()+3*std_</span><span id="38ca" class="ln jd hh lj b fi ls lp l lq lr">x_norm=(q_max-q_min)*x_norm</span><span id="fd75" class="ln jd hh lj b fi ls lp l lq lr">x_norm=x_.mean()+(x_norm-x_norm.mean())</span><span id="819b" class="ln jd hh lj b fi ls lp l lq lr">fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 10))</span><span id="d41a" class="ln jd hh lj b fi ls lp l lq lr">sns.kdeplot(x=x_,ax=ax, label="Original distribution")</span><span id="630b" class="ln jd hh lj b fi ls lp l lq lr">sns.kdeplot(x=x_norm.reshape(25),ax=ax, label="Transformed distribution")</span><span id="40ce" class="ln jd hh lj b fi ls lp l lq lr">ax.set(xlabel="Estimated ground truth",ylabel="Distribution")</span><span id="49dd" class="ln jd hh lj b fi ls lp l lq lr">ax.legend()</span><span id="27b8" class="ln jd hh lj b fi ls lp l lq lr">plt.hist(X_trans_qt)</span></pre><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/92f47fae1fc6be4097b0fbbfd67143fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LXpkIo3SH-fVLZLW1LDQCA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 9: Video 3 distribution before and after normalization</figcaption></figure><p id="870a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了提醒我们自己我们在这里取得了什么，我们拍摄了视频3，并通过应用从概率分布中得出的函数，将其归一化以获得更好的消除效果。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/5edc2d149ac2fe2730e9b957c49c40c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-AKWwHxEkO02XCuBJGC0og.png"/></div></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lt"><img src="../Images/e7edd1d32bf39cf02d55f5414dab76b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OnloQxh9xICQR-Dcud8H0Q.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx">Chart 10: A) count of under- vs over-estimates in the original dataset vs normalized, B) median of under- vs over-estimates in the original dataset vs normalized</figcaption></figure><p id="8940" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Oila！或者是奥立？从来不擅长德语…</p><p id="62f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">无论如何，我们以此结束第一部分，预处理和数据探索。在下一部分，我将解决房间里的机器学习大象:事实上，我们不会有新数据中的地面真相。</p><p id="d1fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">收听节目，了解群体智慧方法如何帮助克服这个问题，以及什么样的性格特征与此有关！</p></div></div>    
</body>
</html>
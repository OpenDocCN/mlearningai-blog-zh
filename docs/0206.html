<html>
<head>
<title>Imbalanced data and Linear regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据和线性回归</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/imbalanced-data-and-linear-regression-e8ff1b1e2f6f?source=collection_archive---------0-----------------------#2021-03-03">https://medium.com/mlearning-ai/imbalanced-data-and-linear-regression-e8ff1b1e2f6f?source=collection_archive---------0-----------------------#2021-03-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/169fdcacedc0bebb7d843d5bd6f293bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zGdVxokWnksxpP6weZxJXw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">“Necessity is the mother of invention”</figcaption></figure><p id="1862" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">线性回归(LR)用于寻找目标和一个或多个预测值之间的线性关系</strong>。核心思想是获得最适合数据的线。最佳拟合线是总预测误差(所有数据点)尽可能小的线。误差是点到回归线的距离。在这个博客中，我们将涵盖线性回归模型和执行预测模型的各种设置超参数。</p><blockquote class="jr js jt"><p id="08e0" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated"><strong class="iv hi">线性回归</strong>假设<strong class="iv hi">特征和目标向量之间的关系近似为线性</strong>。也就是说，特征对目标向量的影响(也称为系数、权重或参数)是恒定的。在我们的解决方案中，为了便于解释，我们仅使用两个特征来训练我们的模型。</p></blockquote><p id="c49a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在我们实验中，我们采用了4组不同比例的数据，即[(100:2)，(100:20)，(100:40)，(100:80)]和3组超参数“C”，即[0.001，1，100]。我们将看到所有这12种组合的结果，并逐一进行分析。</p><blockquote class="jr js jt"><p id="62d0" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated"><strong class="iv hi">设置1 </strong> <strong class="iv hi"> :-数据比= (100:2) </strong> - &gt;(蓝色:红色)</p></blockquote><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es jy"><img src="../Images/dbf29fe82aed83970e9a8a5d0660cc3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*Nbh4siSHQOm64hSw2DdAug.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx"><strong class="bd kd">Figure 1</strong></figcaption></figure><p id="767b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先我们取值<strong class="iv hi">‘C’= 0.001</strong>。在结果图1中，决策线位于X轴上的100k处，它远未分类，因为数据在最左侧，但决策线在最右侧，即使我们有2个红点，也有100个蓝点。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es ke"><img src="../Images/ad35b515da8767f1cd6e43a7f11a4ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*z4Se3JuDIgBw0KVPj5YvJA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 2</figcaption></figure><p id="ce7c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在来看第二个数字，我们增加了<strong class="iv hi">‘C’= 1</strong>的值。许多人会认为图1和图2没有任何区别。但是，再看看x轴。在图1中，数据点在0上，决策线在100k上。在图2中，数据在0和x轴附近，而决策线已经非常接近x轴上的8。所以，我们可以说‘C’对数据集有很大的影响。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kf"><img src="../Images/77f585b6b90033adf59fac42595e2736.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*n4gGnf_kfg9J_WQcKU-IyA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 3</figcaption></figure><p id="f114" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在第三张图中，我们将<strong class="iv hi">‘C’的值增加到100 </strong>。这里的决策线试图将红点与蓝点区分开来。但是我们不能说这是一个好的决策函数。</p><blockquote class="jr js jt"><p id="fa85" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated"><strong class="iv hi"> Set 2:-数据比率= (100:20) </strong> - &gt;(蓝色:红色)</p></blockquote><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kg"><img src="../Images/ab03d57798482041a14b44ea0cec3c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*CtMhA_QUpj-V_hZQsl9RJQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 4</figcaption></figure><p id="1570" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先我们看一下<strong class="iv hi">‘C’= 0.001</strong>的值。比较图1和图4看起来是一样的。但是仔细观察图1中的x轴，决策线位于100k处。另一方面，在图4中，决策线在x轴上大约600处。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kh"><img src="../Images/10854305130cc3f9ddd4261e917d47e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*fC9PvhWVqDpzBAtcvHng9w.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx"><strong class="bd kd">Figure 5</strong></figcaption></figure><p id="6c54" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在，我们取<strong class="iv hi">‘C’= 1</strong>的值。我们得到了一个决策线，它离数据点很近，但是没有用。因为它没有把蓝色和红色分开。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kg"><img src="../Images/8878c426223bbd0a4fecac151fb771c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*2zzmULSC0zyzBn7fH-LORw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 6</figcaption></figure><p id="2761" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在，我们将<strong class="iv hi">‘C’的值增加到100 </strong>。我们可以看到结果图6，其中决策行比以前的分类更好。但这仍然不是由马克决定的，因为这条线靠近红色，而两个蓝色在错误的一边。</p><blockquote class="jr js jt"><p id="08b2" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated"><strong class="iv hi"> Set 3:-数据比= (100:40) </strong> - &gt;(蓝色:红色)</p></blockquote><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kg"><img src="../Images/7cc77e03fc8a523c755d37da89816af4.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*UyzJ9lGLUkXDZjYaRAq9OA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 7</figcaption></figure><p id="25f9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们再次取值<strong class="iv hi">‘C’= 0.001</strong>。像图4一样，在图7中，决策线也移动到了x轴的数据点附近。但还是没用。不需要解释。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es ki"><img src="../Images/fb62368dc1ca911de1011e9e8bee0d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*qRZ4-bvBPPvLFedEaIe8yQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 8</figcaption></figure><p id="3f38" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在，我们取<strong class="iv hi">‘C’= 1</strong>的值。在图8中，我们可以看到试图对数据进行分类的决策线。但是它有很多错误，所以我们不能接受。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kj"><img src="../Images/671c48c9aa2240ff3a5180e6e2003037.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*Ys7wDlg2jAqnoygnwvWUFg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 9</figcaption></figure><p id="0c2f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在，我们增加了<strong class="iv hi">‘C’= 100</strong>的值。决策线很好的区分了红色和蓝色。我们可以接受这个决策函数。因此，我们可以得出这样的结论，随着这个比率的增加，C的值也将使我们得到一个好的模型。</p><blockquote class="jr js jt"><p id="e25a" class="it iu ju iv b iw ix iy iz ja jb jc jd jv jf jg jh jw jj jk jl jx jn jo jp jq ha bi translated"><strong class="iv hi">集合4:-数据比= (100:80) </strong> - &gt;(蓝:红)(几乎平衡数据集)</p></blockquote><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kk"><img src="../Images/5ed8252f57814f6bf8d85e26ea86a0e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*xoEha1f1U201GgOPqL2PvA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 10</figcaption></figure><p id="d266" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">再次，首先我们取<strong class="iv hi">‘C’= 0.001</strong>。它优于具有相同“C”值但不同数据比率的先前模型。在这个模型中，决策线接近120。因此，随着数据率的提高，情况会越来越好。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es kl"><img src="../Images/c52d7cd11fa03c2c5eb1d2be09e66bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*mzbNX-pQD4yPWFiOQM8R5w.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 11</figcaption></figure><p id="c4d3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我们取值为<strong class="iv hi">‘C’= 1</strong>。在结果图中，我们可以看到决策是对数据进行分类。但是一些蓝点正在穿越它们的边界。所以这个模型还是有误差的。但是很明显情况在好转。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es km"><img src="../Images/5de09ff73e8b11ce4c6cc708f1fbf406.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*dqv0Efolpdb6y_BrBQZqVA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 12</figcaption></figure><p id="ba40" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在向最后一个数字移动。我们取值为<strong class="iv hi">‘C’= 100</strong>。在上图中，我们可以清楚地看到一条很好的决策线，它对数据进行了很好的分类，但有一个例外。一红一蓝点正好在线上。所以我们可以说这是一个很好的契合。</p><h1 id="c67a" class="kn ko hh bd kd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">结论</h1><p id="d78e" class="pw-post-body-paragraph it iu hh iv b iw lk iy iz ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq ha bi translated">从上面的观察中，我们可以得出两点结论。</p><p id="b02d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 1。</strong>增加数据比率将使决策线与数据更加吻合。</p><p id="aaba" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 2。</strong>增加‘C’的值也会导致决策线的良好拟合。但在一定程度上，增加it，我们的模型将过度拟合数据。</p><p id="606b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">所以，明智地调整你的模型。！编码快乐！</p></div></div>    
</body>
</html>
<html>
<head>
<title>The Magic of Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">è‡ªåŠ¨ç¼–ç å™¨çš„é­”åŠ›</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/mlearning-ai/the-magic-of-autoencoders-73162e9bd43f?source=collection_archive---------1-----------------------#2021-04-14">https://medium.com/mlearning-ai/the-magic-of-autoencoders-73162e9bd43f?source=collection_archive---------1-----------------------#2021-04-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a85b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è‡ªåŠ¨ç¼–ç å™¨æ˜¯ä¸€ä¸ªé¡ºåºç¥ç»ç½‘ç»œï¼Œç”±ä¸¤ä¸ªç»„ä»¶ç»„æˆï¼Œ<strong class="ig hi">ç¼–ç å™¨</strong>å’Œ<strong class="ig hi">è§£ç å™¨</strong>ã€‚</p><p id="ba11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å‡è®¾æˆ‘ä»¬åœ¨å¤„ç†å›¾åƒã€‚æˆ‘ä»¬çš„ç¼–ç å™¨å°†ä»å›¾åƒä¸­æå–ç‰¹å¾ï¼Œè¿™å°†å‡å°‘ä¸€äº›ç»„ä»¶ï¼Œå¦‚å…¶é«˜åº¦å’Œå®½åº¦ï¼Œä½†ä¸ºå›¾åƒåˆ¶ä½œä¸€ä¸ª<strong class="ig hi">æ½œåœ¨è¡¨ç¤º</strong>ã€‚è¿™ç§æ½œåœ¨çš„è¡¨ç°å½¢å¼åªæ˜¯æ„å‘³ç€ç¥ç»ç½‘ç»œåªæ•æ‰è¾“å…¥çš„æœ€ç›¸å…³çš„ç‰¹å¾ã€‚</p><p id="c977" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è§£ç å™¨æ˜¯ç¥ç»ç½‘ç»œçš„ä¸€éƒ¨åˆ†ï¼Œå®ƒå­¦ä¹ å¦‚ä½•ä»ç¼–ç ç‰ˆæœ¬ä¸­é‡å»ºæ•°æ®ã€‚ä»¥å°½å¯èƒ½æ¥è¿‘åŸå§‹è¾“å…¥çš„æ–¹å¼é‡æ„æ•°æ®ã€‚</p><p id="33d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ª<strong class="ig hi">é‡å»ºæŸå¤±</strong>ï¼Œç”¨äºè¡¡é‡è§£ç å™¨çš„æ€§èƒ½ä»¥åŠè¾“å‡ºæ•°æ®ä¸åŸå§‹è¾“å…¥æ•°æ®çš„æ¥è¿‘ç¨‹åº¦ã€‚ä¸ºäº†æœ€å°åŒ–æŸå¤±ï¼Œè‡ªåŠ¨ç¼–ç å™¨ä½¿ç”¨<strong class="ig hi">åå‘ä¼ æ’­</strong>æ¥æœ€å°åŒ–ç¥ç»ç½‘ç»œçš„é‡å»ºæŸå¤±ã€‚</p><p id="c1a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è‡ªåŠ¨ç¼–ç å™¨å…è®¸æˆ‘ä»¬ä»¥æœ€ä½³æ–¹å¼å‹ç¼©æ•°æ®ï¼Œä»¥å‡å°‘ç»´åº¦å¹¶å¿½ç•¥æ•°æ®ä¸­çš„å™ªå£°ã€‚</p><p id="5eb0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸‹é¢æ˜¯å¦‚ä½•ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨å¯¹æ¥è‡ªMISTæ•°æ®é›†(æ‰‹å†™æ•°å­—)çš„å›¾åƒè¿›è¡Œç¼–ç å’Œè§£ç çš„ç¤ºä¾‹ã€‚å¦‚æ‚¨æ‰€è§ï¼ŒåŸå§‹è¾“å…¥å’Œé‡æ„è¾“å…¥éå¸¸ç›¸ä¼¼ã€‚</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/e76fe5cc48ef254e8c10c429b71faafa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b1OwjTyaj6smnbrB.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Image from google images.</figcaption></figure></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><h2 id="be11" class="jv jw hh bd jx jy jz ka kb kc kd ke kf ip kg kh ki it kj kk kl ix km kn ko kp bi translated">æ„å»ºè‡ªåŠ¨ç¼–ç å™¨</h2><p id="feec" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">æˆ‘å·²ç»ç”¨PyTorchæ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ï¼Œæˆ‘å°†ä¸€æ­¥ä¸€æ­¥åœ°å‘æ‚¨å±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ã€‚</p><p id="7a60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¹æ•´ä¸ªä»£ç åšä¸€ä¸ªæ¦‚è¿°:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="71fb" class="jv jw hh kw b fi la lb l lc ld">import torch<br/>import torch.nn as nn<br/>from torchvision import datasets<br/>from torch.autograd import Variable<br/>from torchvision.transforms import transforms<br/><br/>#transform data to pytorch tensors<br/>transforms = transforms.ToTensor()<br/><br/>fashion_data = datasets.FashionMNIST(root='./data',  download=True, transform=transforms) #train=True,<br/><br/>data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)<br/><br/>#iterating through our data<br/>dataiter = iter(data_loader)<br/>images, labels = dataiter.next()<br/><br/>#output will get the minimum tensor and the maximum tensor in the dataset --&gt; important for our last activation<br/>print(torch.min(images), torch.max(images))<br/><br/>class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay<br/><br/>        #encoder<br/>        self.encoder = nn.Sequential(<br/>            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>            nn.ReLU(),<br/>            nn.Linear(128, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 3)<br/>        )<br/><br/>        #decoder<br/>        self.decoder = nn.Sequential(<br/>            nn.Linear(3, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 128),<br/>            nn.ReLU(),<br/>            nn.Linear(128, 28 * 28),<br/>            nn.Sigmoid()  # cause tensors are 0, 1<br/>        )<br/><br/>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>        self.loss = nn.MSELoss()<br/><br/>    #feed data through network<br/>    def forward(self, x):<br/>        encoder = self.encoder(x)<br/>        decoder = self.decoder(encoder)<br/>        return decoder<br/><br/>    #training loop<br/>    def train(self):<br/>        for epoch in range(self.epochs):<br/>            for data in data_loader:<br/>                img, _ = data<br/>                img = img.view(img.size(0), -1)<br/>                img = Variable(img)<br/><br/>                #predict<br/>                output = self(img)<br/><br/>                # find loss<br/>                loss = self.loss(output, img)<br/><br/>                # perform back propagation<br/>                self.optimizer.zero_grad()<br/>                loss.backward()<br/>                self.optimizer.step()<br/><br/>            print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')<br/><br/>model = autoencoder()<br/>model.train()</span></pre></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="4677" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸ºäº†æ‰“ç ´åƒµå±€ï¼Œè®©æˆ‘ä»¬ä»æˆ‘ä»¬çš„è¿›å£å¼€å§‹:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="4a55" class="jv jw hh kw b fi la lb l lc ld">import torch<br/>import torch.nn as nn<br/>from torchvision import datasets<br/>from torch.autograd import Variable<br/>from torchvision.transforms import transforms</span></pre><p id="839d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¯¼å…¥torch â†’ PyTorchæ¨¡å—ã€‚</p><p id="9689" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¯¼å…¥torch.nnä½œä¸ºnn â†’ç”¨äºæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œç±»ã€‚</p><p id="0025" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»torchvisionå¯¼å…¥æ•°æ®é›†â†’å…è®¸æˆ‘ä»¬åœ¨PyTorchä¸­ä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®é›†ã€‚</p><p id="b2e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">from torch.autogradå¯¼å…¥å˜é‡â†’æˆ‘ä»¬ä½¿ç”¨å˜é‡æ¥å­˜å‚¨ç”±æŸå¤±å‡½æ•°è®¡ç®—çš„å€¼ã€‚å˜é‡æœ‰è®¸å¤šä¸å¼ é‡å’Œåå‘ä¼ æ’­ç›¸å…³çš„å‡½æ•°ã€‚</p><p id="2139" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">from torchvision.transformså¯¼å…¥è½¬æ¢â†’ç”¨äºå›¾åƒé¢„å¤„ç†ã€‚</p></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="5e48" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†å¯¼å…¥ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è·å–å’Œæµè§ˆæˆ‘ä»¬çš„æ•°æ®äº†:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="c1af" class="jv jw hh kw b fi la lb l lc ld">#transform data to pytorch tensors<br/>transforms = transforms.ToTensor()<br/><br/>fashion_data = datasets.FashionMNIST(root='./data',  download=True, transform=transforms) #train=True,<br/><br/>data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)<br/><br/>#iterating through our data<br/>dataiter = iter(data_loader)<br/>images, labels = dataiter.next()</span></pre><p id="2ccc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆå§‹åŒ–ä¸€ä¸ªåä¸ºtransformsçš„å˜é‡ï¼Œå½“å®ƒè¢«ä¼ é€’ç»™transformå‚æ•°æ—¶ï¼Œä¼šå°†ä¸€ä¸ªå›¾åƒè½¬æ¢æˆPyTorchå¼ é‡ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="9168" class="jv jw hh kw b fi la lb l lc ld">transforms = transforms.ToTensor()</span></pre><p id="db33" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºæˆ‘ä»¬çš„fashion_dataå˜é‡ï¼Œå®ƒå°†ä½¿ç”¨æ•°æ®é›†ã€‚FashionMNISTè·å–é¢„å…ˆåŠ è½½åœ¨PyTorchä¸­çš„FashionMNISTæ•°æ®ã€‚æˆ‘ä»¬è¿˜å°†æŠŠtransformså˜é‡ä¼ é€’ç»™transformå‚æ•°ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³æŠŠæˆ‘ä»¬çš„å›¾åƒè½¬æ¢æˆå¼ é‡ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="1aa5" class="jv jw hh kw b fi la lb l lc ld">fashion_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms)</span></pre><p id="c5d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">PyTorchæœ‰ä¸€ä¸ªæ¼‚äº®çš„ç±»ï¼Œå«åšDataLoaderï¼Œå®ƒå…è®¸æˆ‘ä»¬åŠ è½½æ•°æ®ï¼Œå¹¶è¿­ä»£å…ƒç´ ï¼Œä¸æ‰‹åŠ¨è¾“å…¥æ‰€æœ‰æ•°æ®ç›¸æ¯”ï¼Œå®ƒçš„æ•ˆç‡æé«˜äº†10å€ã€‚</p><p id="9770" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸‹é¢ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªdata_loaderå˜é‡ï¼Œå®ƒä½¿ç”¨PyTorchçš„DataLoaderè¿­ä»£æˆ‘ä»¬çš„fashion_dataï¼Œç»™å®ƒä¸€ä¸ª64çš„æ‰¹å¤„ç†å¤§å°ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œæ··æ’ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="c6f5" class="jv jw hh kw b fi la lb l lc ld">data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)</span></pre><p id="8855" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æœ€åï¼Œæˆ‘ä»¬å°†éå†data_loaderï¼Œéå†æ¯å¼ å›¾ç‰‡å’Œæ ‡ç­¾ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="ae6d" class="jv jw hh kw b fi la lb l lc ld">#iterating through our data<br/>dataiter = iter(data_loader)<br/>images, labels = dataiter.next()</span></pre><p id="f52f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å°†æ‰“å°å›¾åƒçš„torch.min()æ¥æŸ¥æ‰¾è¾“å…¥å¼ é‡ä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å°å€¼ï¼Œå¹¶æ‰“å°torch.max()æ¥æŸ¥æ‰¾è¾“å…¥å¼ é‡ä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="3c82" class="jv jw hh kw b fi la lb l lc ld">#output will get the minimum tensor and the maximum tensor in the dataset --&gt; important for our last activation</span><span id="c602" class="jv jw hh kw b fi le lb l lc ld">print(torch.min(images), torch.max(images))</span></pre><p id="b969" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™æœ€åä¸€å¥è¯å¾ˆé‡è¦ï¼Œå› ä¸ºè¿”å›çš„å¼ é‡å€¼å°†å†³å®šæˆ‘ä»¬åœ¨è§£ç å™¨çš„æœ€åä¸€å±‚éœ€è¦ä½¿ç”¨ä»€ä¹ˆå‡½æ•°ã€‚å› ä¸ºè¾“å‡ºæ˜¾ç¤ºæˆ‘ä»¬çš„æœ€å°å¼ é‡æ˜¯å¼ é‡(0ã€‚)å¹¶ä¸”æœ€å¤§å¼ é‡æ˜¯å¼ é‡(1ã€‚)ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰çš„å¼ é‡éƒ½åœ¨è¿™äº›æ•°ä¹‹é—´ï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»ä½¿ç”¨Sigmoidæ¿€æ´»ã€‚</p><p id="e58a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®°ä½sigmoidæ¿€æ´»å‡½æ•°æ˜¯è¿ç»­çš„ï¼Œæ‰€æœ‰ç‚¹ä¸Šçš„å¯¼æ•°æ€»æ˜¯äº§ç”Ÿæ•°å­—0å’Œ1ä¹‹é—´çš„è¾“å‡ºã€‚</p></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="2c24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ•°æ®ï¼Œå¹¶äº†è§£äº†ä¸€äº›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ„å»ºæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨ç¥ç»ç½‘ç»œã€‚</p><p id="8519" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»¥ä¸‹æ˜¯æˆ‘ä»¬æ•´ä¸ªä»£ç çš„æ¦‚è¿°:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="150c" class="jv jw hh kw b fi la lb l lc ld">class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay<br/><br/>        #encoder<br/>        self.encoder = nn.Sequential(<br/>            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>            nn.ReLU(),<br/>            nn.Linear(128, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 3)<br/>        )<br/><br/>        #decoder<br/>        self.decoder = nn.Sequential(<br/>            nn.Linear(3, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 128),<br/>            nn.ReLU(),<br/>            nn.Linear(128, 28 * 28),<br/>            nn.Sigmoid()  # cause tensors are 0, 1<br/>        )<br/><br/>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>        self.loss = nn.MSELoss()<br/><br/>    #feed data through network<br/>    def forward(self, x):<br/>        encoder = self.encoder(x)<br/>        decoder = self.decoder(encoder)<br/>        return decoder<br/><br/>    #training loop<br/>    def train(self):<br/>        for epoch in range(self.epochs):<br/>            for data in data_loader:<br/>                img, _ = data<br/>                img = img.view(img.size(0), -1)<br/>                img = Variable(img)<br/><br/>                #predict<br/>                output = self(img)<br/><br/>                # find loss<br/>                loss = self.loss(output, img)<br/><br/>                # perform back propagation<br/>                self.optimizer.zero_grad()<br/>                loss.backward()<br/>                self.optimizer.step()<br/><br/>            print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')<br/><br/>model = autoencoder()<br/>model.train()</span></pre><p id="cd20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¥½äº†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„è¿›æ­¥ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æŠŠå®ƒä¸€éƒ¨åˆ†ä¸€éƒ¨åˆ†çš„åˆ†è§£å§:)</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="e439" class="jv jw hh kw b fi la lb l lc ld">class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay<br/><br/>        #encoder<br/>        self.encoder = nn.Sequential(<br/>            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>            nn.ReLU(),<br/>            nn.Linear(128, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 3)<br/>        )<br/><br/>        #decoder<br/>        self.decoder = nn.Sequential(<br/>            nn.Linear(3, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 128),<br/>            nn.ReLU(),<br/>            nn.Linear(128, 28 * 28),<br/>            nn.Sigmoid()  # cause tensors are 0, 1<br/>        )<br/><br/>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>        self.loss = nn.MSELoss()</span></pre><p id="60f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å°†è°ƒç”¨æˆ‘ä»¬çš„ç±»autoencoderï¼Œå®ƒå°†ç»§æ‰¿nnã€‚æ¨¡å—ç±»ã€‚è¿™é€šå¸¸æ˜¯PyTorchä¸­æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç±»ã€‚</p><p id="a56a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸ºäº†ç®€å•åœ°è§£é‡Šè¿™ä¸ªæ¨¡å—ï¼Œå®ƒä½¿ç”¨å¼ é‡å’Œè‡ªåŠ¨å¾®åˆ†æ¨¡å—(è®¡ç®—å‡½æ•°å¯¼æ•°çš„æŠ€æœ¯)æ¥è®­ç»ƒå’Œæ„å»ºå±‚(è¾“å…¥ã€éšè—ã€è¾“å‡ºç­‰)ã€‚</p><p id="a100" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨æˆ‘ä»¬çš„__init__ä¸­ï¼Œæˆ‘ä»¬å°†ä¼ å…¥æˆ‘ä»¬çš„çºªå…ƒã€æ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œåˆå§‹åŒ–ã€‚ä½ å¯ä»¥æ‘†å¼„è¿™äº›æ•°å­—ï¼Œä½†æ˜¯ï¼Œè¿™äº›æ˜¯æˆ‘å‘ç°æ•ˆæœæœ€å¥½çš„æ•°å­—ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="027f" class="jv jw hh kw b fi la lb l lc ld">class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay</span></pre><p id="37bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åˆå§‹åŒ–ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ„å»ºæˆ‘ä»¬çš„ç¼–ç å™¨ã€‚</p><p id="6431" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é¡ºåºç»“æ„ï¼Œä¸€ä¸ªçº¿æ€§å±‚åé¢è·Ÿç€ä¸€ä¸ªreluæ¿€æ´»ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¼ å…¥çš„å›¾åƒå¤§å°ä¸º28 x 28ï¼Œå› ä¸ºæ—¶å°šMNISTæ•°æ®é›†çš„å›¾åƒä¸º784åƒç´ ã€‚æ¯ä¸€å±‚ï¼Œæˆ‘ä»¬éƒ½ä¼šå‡å°‘æŠ•å…¥ã€‚</p><p id="018e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½ å¯ä»¥æŠŠæˆ‘ä»¬çš„è¾“å…¥æƒ³è±¡æˆNï¼Œ784ï¼Œç¼–ç å™¨çš„è¾“å‡ºå°†ä¼šæ˜¾è‘—åœ°å‡å°‘åˆ°Nï¼Œ3ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="ca91" class="jv jw hh kw b fi la lb l lc ld">#encoder<br/>self.encoder = nn.Sequential(<br/>    nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>    nn.ReLU(),<br/>    nn.Linear(128, 64),<br/>    nn.ReLU(),<br/>    nn.Linear(64, 12),<br/>    nn.ReLU(),<br/>    nn.Linear(12, 3)<br/>)</span></pre><p id="b6fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬çš„è§£ç å™¨ä¸æˆ‘ä»¬çš„ç¼–ç å™¨ç»“æ„ç›¸ä¼¼ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹å‘ç›¸åï¼Œå³â†’ Nï¼Œ3åˆ°Nï¼Œ784ã€‚</p><p id="b1bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¯¹äºæˆ‘ä»¬çš„æœ€åä¸€å±‚ï¼Œæ³¨æ„æˆ‘ä»¬ä½¿ç”¨äº†sigmoidæ¿€æ´»(å‰é¢è§£é‡Šè¿‡)ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="fbc0" class="jv jw hh kw b fi la lb l lc ld">#decoder<br/>self.decoder = nn.Sequential(<br/>    nn.Linear(3, 12),<br/>    nn.ReLU(),<br/>    nn.Linear(12, 64),<br/>    nn.ReLU(),<br/>    nn.Linear(64, 128),<br/>    nn.ReLU(),<br/>    nn.Linear(128, 28 * 28),<br/>    nn.Sigmoid()  # cause tensors are 0, 1<br/>)</span></pre><p id="8f94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œæ ‡å‡†äº†ã€‚ä¸€å®šè¦ç¡®ä¿åœ¨ä½ çš„è‡ªåŠ¨ç¼–ç å™¨ä¸‹é¢å®šä¹‰å®ƒï¼Œå¦åˆ™ä½ å°†ä¸èƒ½ä¼ é€’ä»»ä½•ä¸œè¥¿ã€‚</p><p id="0124" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®°ä½â†’ä¼˜åŒ–å™¨æ˜¯æ”¹å˜å±äºä½ çš„ç¥ç»ç½‘ç»œçš„å±æ€§çš„ç®—æ³•ï¼Œæ¯”å¦‚æƒé‡å’Œå­¦ä¹ ç‡ï¼Œä»¥å‡å°‘æŸå¤±ã€‚</p><p id="eef3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¯¹äºæˆ‘ä»¬çš„ç½‘ç»œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Adamä¼˜åŒ–å™¨ã€‚æˆ‘ä»¬å°†éœ€è¦ä¼ å…¥self.parametersã€æˆ‘ä»¬çš„å­¦ä¹ ç‡å’Œæˆ‘ä»¬çš„weight_decay(è¿™æ˜¯æˆ‘ä»¬ä¹‹å‰åœ¨ç½‘ç»œä¸­åˆå§‹åŒ–çš„)ã€‚</p><p id="e507" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®°ä½â†’å­¦ä¹ ç‡æ§åˆ¶ç€ç½‘ç»œé€‚åº”é—®é¢˜çš„é€Ÿåº¦ã€‚</p><p id="b0dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è®°ä½â†’æ­£åˆ™åŒ–æ˜¯ä¸€ç§çº¦æŸæˆ‘ä»¬çš„ç½‘ç»œç²¾ç¡®æ‹Ÿåˆæˆ‘ä»¬çš„æ•°æ®ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆçš„æ–¹æ³•ã€‚Weight_decayæ˜¯ä¸€ç§åœ¨ç¥ç»ç½‘ç»œä¸Šæ‰§è¡Œæ­£åˆ™åŒ–çš„æ–¹æ³•ã€‚</p><p id="66a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨MSELossã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="0797" class="jv jw hh kw b fi la lb l lc ld">self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>self.loss = nn.MSELoss()</span></pre><p id="9a59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥æŠŠæ•°æ®è¾“å…¥ç½‘ç»œäº†ã€‚æˆ‘ä»¬å°†æ¥å—xï¼Œå°†å®ƒä¼ å…¥æˆ‘ä»¬çš„ç¼–ç å™¨ï¼Œå°†æˆ‘ä»¬çš„ç¼–ç å™¨ä¼ å…¥è§£ç å™¨ï¼Œæœ€åè¿”å›æˆ‘ä»¬çš„è§£ç å™¨çš„ç»“æœã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="fbf7" class="jv jw hh kw b fi la lb l lc ld">#feed data through network<br/>def forward(self, x):<br/>    encoder = self.encoder(x)<br/>    decoder = self.decoder(encoder)<br/>    return decoder</span></pre><p id="7c71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç°åœ¨æˆ‘ä»¬å·²ç»å»ºç«‹äº†æˆ‘ä»¬çš„ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚</p><p id="f0d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å°†åœ¨æ¯ä¸ªæ—¶æœŸè¿­ä»£æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œå¹¶å¢åŠ æˆ‘ä»¬çš„å›¾åƒä»¥é€‚åº”ç½‘ç»œã€‚æˆ‘ä»¬å°†è°ƒç”¨é¢„æµ‹ï¼Œè®¡ç®—æŸå¤±ï¼Œç„¶åæ‰§è¡Œåå‘ä¼ æ’­ã€‚åœ¨æ¯ä¸€ä¸ªæ—¶ä»£ä¹‹åï¼Œæˆ‘ä»¬å°†è¾“å‡ºæŸå¤±ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="8129" class="jv jw hh kw b fi la lb l lc ld">#training loop<br/>def train(self):<br/>    for epoch in range(self.epochs):<br/>        for data in data_loader:<br/>            img, _ = data<br/>            img = img.view(img.size(0), -1)<br/>            img = Variable(img)<br/><br/>            #predict<br/>            output = self(img)<br/><br/>            # find loss<br/>            loss = self.loss(output, img)<br/><br/>            # perform back propagation<br/>            self.optimizer.zero_grad()<br/>            loss.backward()<br/>            self.optimizer.step()<br/><br/>        print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')</span></pre><p id="50e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æœ€åï¼Œä¸ºäº†è¿è¡Œæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªautoencoderç±»çš„å¯¹è±¡ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªå¯¹è±¡ç§°ä¸ºæ¨¡å‹ã€‚ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å°†åœ¨å¯¹è±¡ä¸Šè°ƒç”¨æˆ‘ä»¬çš„è®­ç»ƒå‡½æ•°ã€‚</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="3593" class="jv jw hh kw b fi la lb l lc ld">model = autoencoder()<br/>model.train()</span></pre></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="aee7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡å…³äºå¦‚ä½•åœ¨PyTorchä¸­æ„å»ºè‡ªåŠ¨ç¼–ç å™¨çš„è§£é‡Šå’Œæ•™ç¨‹ï¼è¿™ä¸ªæ¨¡å‹è®­ç»ƒå¾—å¾ˆå¥½ï¼Œå‡ ä¹æ²¡æœ‰æŸå¤±ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»æ—¶å°šMNISTä¸­é€‰å–ä¸€ä¸ªç‰¹å®šçš„å›¾åƒæ¥æµ‹è¯•ç»“æœï¼Œå°†å®ƒè¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå¹¶ç»˜åˆ¶å‡ºä¹‹å‰å’Œä¹‹åçš„ç»“æœã€‚</p></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><h1 id="0744" class="lf jw hh bd jx lg lh li kb lj lk ll kf lm ln lo ki lp lq lr kl ls lt lu ko lv bi translated">å¦‚æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·è”ç³»æˆ‘ğŸš€</h1><p id="56b6" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">å—¨ï¼Œæˆ‘æ˜¯Ashleyï¼Œä¸€ä¸ª16å²çš„ç¼–ç¨‹å‘†å­ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½å’Œç¥ç»ç§‘å­¦çˆ±å¥½è€…ï¼</p><p id="f9e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘å¸Œæœ›ä½ å–œæ¬¢é˜…è¯»æˆ‘çš„æ–‡ç« ï¼Œå¦‚æœä½ å–œæ¬¢ï¼Œè¯·éšæ—¶æŸ¥çœ‹æˆ‘åœ¨Mediumä¸Šçš„å…¶ä»–ä½œå“:)</p><p id="2db6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™æ®µä»£ç çš„ä»“åº“åœ¨æˆ‘çš„GitHubä¸Šï¼Œåœ¨æˆ‘çš„â€œPytorchâ€ä»“åº“ä¸‹ã€‚</p><p id="425b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¦‚æœä½ è¯»äº†è¿™ç¯‡æ–‡ç« ï¼Œä½ ä¼šå–œæ¬¢çš„:</p><p id="068b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ğŸ’«<a class="ae lw" href="https://ashleyy-czumak.medium.com/mnist-digit-classification-in-pytorch-302476b34e4f" rel="noopener">py torchä¸­çš„MNISTæ•°å­—åˆ†ç±»</a></p><p id="0699" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ğŸ’«<a class="ae lw" rel="noopener" href="/swlh/an-overview-on-convolutional-neural-networks-ea48e76fb186">å·ç§¯ç¥ç»ç½‘ç»œæ¦‚è¿°</a></p><p id="ffe7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ğŸ’«<a class="ae lw" rel="noopener" href="/swlh/companies-need-to-mitigate-a-i-bias-830e7cae8149">å…¬å¸éœ€è¦å‡è½»äººå·¥æ™ºèƒ½åè§</a></p><p id="6486" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œæƒ³äº†è§£æ›´å¤šå…³äºæˆ‘çš„ä¿¡æ¯ï¼Œæˆ–è€…æƒ³è¦ä»»ä½•äººå·¥æ™ºèƒ½æˆ–ç¼–ç¨‹ç›¸å…³çš„èµ„æºï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘:</p><p id="4815" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ğŸ’«ç”µå­é‚®ä»¶:ashleycinquires@gmail.com</p><p id="7731" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ğŸ’«<a class="ae lw" href="https://github.com/ashthedash2k" rel="noopener ugc nofollow" target="_blank"> Github </a></p></div></div>    
</body>
</html>
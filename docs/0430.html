<html>
<head>
<title>The Magic of Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动编码器的魔力</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/the-magic-of-autoencoders-73162e9bd43f?source=collection_archive---------1-----------------------#2021-04-14">https://medium.com/mlearning-ai/the-magic-of-autoencoders-73162e9bd43f?source=collection_archive---------1-----------------------#2021-04-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a85b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动编码器是一个顺序神经网络，由两个组件组成，<strong class="ig hi">编码器</strong>和<strong class="ig hi">解码器</strong>。</p><p id="ba11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们在处理图像。我们的编码器将从图像中提取特征，这将减少一些组件，如其高度和宽度，但为图像制作一个<strong class="ig hi">潜在表示</strong>。这种潜在的表现形式只是意味着神经网络只捕捉输入的最相关的特征。</p><p id="c977" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解码器是神经网络的一部分，它学习如何从编码版本中重建数据。以尽可能接近原始输入的方式重构数据。</p><p id="33d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还有一个<strong class="ig hi">重建损失</strong>，用于衡量解码器的性能以及输出数据与原始输入数据的接近程度。为了最小化损失，自动编码器使用<strong class="ig hi">反向传播</strong>来最小化神经网络的重建损失。</p><p id="c1a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动编码器允许我们以最佳方式压缩数据，以减少维度并忽略数据中的噪声。</p><p id="5eb0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是如何使用自动编码器对来自MIST数据集(手写数字)的图像进行编码和解码的示例。如您所见，原始输入和重构输入非常相似。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/e76fe5cc48ef254e8c10c429b71faafa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b1OwjTyaj6smnbrB.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Image from google images.</figcaption></figure></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><h2 id="be11" class="jv jw hh bd jx jy jz ka kb kc kd ke kf ip kg kh ki it kj kk kl ix km kn ko kp bi translated">构建自动编码器</h2><p id="feec" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">我已经用PyTorch构建了一个自动编码器，我将一步一步地向您展示如何构建一个自动编码器。</p><p id="7a60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，让我们对整个代码做一个概述:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="71fb" class="jv jw hh kw b fi la lb l lc ld">import torch<br/>import torch.nn as nn<br/>from torchvision import datasets<br/>from torch.autograd import Variable<br/>from torchvision.transforms import transforms<br/><br/>#transform data to pytorch tensors<br/>transforms = transforms.ToTensor()<br/><br/>fashion_data = datasets.FashionMNIST(root='./data',  download=True, transform=transforms) #train=True,<br/><br/>data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)<br/><br/>#iterating through our data<br/>dataiter = iter(data_loader)<br/>images, labels = dataiter.next()<br/><br/>#output will get the minimum tensor and the maximum tensor in the dataset --&gt; important for our last activation<br/>print(torch.min(images), torch.max(images))<br/><br/>class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay<br/><br/>        #encoder<br/>        self.encoder = nn.Sequential(<br/>            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>            nn.ReLU(),<br/>            nn.Linear(128, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 3)<br/>        )<br/><br/>        #decoder<br/>        self.decoder = nn.Sequential(<br/>            nn.Linear(3, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 128),<br/>            nn.ReLU(),<br/>            nn.Linear(128, 28 * 28),<br/>            nn.Sigmoid()  # cause tensors are 0, 1<br/>        )<br/><br/>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>        self.loss = nn.MSELoss()<br/><br/>    #feed data through network<br/>    def forward(self, x):<br/>        encoder = self.encoder(x)<br/>        decoder = self.decoder(encoder)<br/>        return decoder<br/><br/>    #training loop<br/>    def train(self):<br/>        for epoch in range(self.epochs):<br/>            for data in data_loader:<br/>                img, _ = data<br/>                img = img.view(img.size(0), -1)<br/>                img = Variable(img)<br/><br/>                #predict<br/>                output = self(img)<br/><br/>                # find loss<br/>                loss = self.loss(output, img)<br/><br/>                # perform back propagation<br/>                self.optimizer.zero_grad()<br/>                loss.backward()<br/>                self.optimizer.step()<br/><br/>            print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')<br/><br/>model = autoencoder()<br/>model.train()</span></pre></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="4677" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了打破僵局，让我们从我们的进口开始:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="4a55" class="jv jw hh kw b fi la lb l lc ld">import torch<br/>import torch.nn as nn<br/>from torchvision import datasets<br/>from torch.autograd import Variable<br/>from torchvision.transforms import transforms</span></pre><p id="839d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">导入torch → PyTorch模块。</p><p id="9689" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">导入torch.nn作为nn →用于我们的神经网络类。</p><p id="0025" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从torchvision导入数据集→允许我们在PyTorch中使用预加载的数据集。</p><p id="b2e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">from torch.autograd导入变量→我们使用变量来存储由损失函数计算的值。变量有许多与张量和反向传播相关的函数。</p><p id="2139" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">from torchvision.transforms导入转换→用于图像预处理。</p></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="5e48" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">好了，现在我们有了导入，我们可以开始获取和浏览我们的数据了:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="c1af" class="jv jw hh kw b fi la lb l lc ld">#transform data to pytorch tensors<br/>transforms = transforms.ToTensor()<br/><br/>fashion_data = datasets.FashionMNIST(root='./data',  download=True, transform=transforms) #train=True,<br/><br/>data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)<br/><br/>#iterating through our data<br/>dataiter = iter(data_loader)<br/>images, labels = dataiter.next()</span></pre><p id="2ccc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们将初始化一个名为transforms的变量，当它被传递给transform参数时，会将一个图像转换成PyTorch张量。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="9168" class="jv jw hh kw b fi la lb l lc ld">transforms = transforms.ToTensor()</span></pre><p id="db33" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们将创建我们的fashion_data变量，它将使用数据集。FashionMNIST获取预先加载在PyTorch中的FashionMNIST数据。我们还将把transforms变量传递给transform参数，因为我们想把我们的图像转换成张量。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="1aa5" class="jv jw hh kw b fi la lb l lc ld">fashion_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms)</span></pre><p id="c5d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">PyTorch有一个漂亮的类，叫做DataLoader，它允许我们加载数据，并迭代元素，与手动输入所有数据相比，它的效率提高了10倍。</p><p id="9770" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面，我们创建了一个data_loader变量，它使用PyTorch的DataLoader迭代我们的fashion_data，给它一个64的批处理大小，并对数据进行混排。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="c6f5" class="jv jw hh kw b fi la lb l lc ld">data_loader = torch.utils.data.DataLoader(fashion_data, batch_size=64, shuffle=True)</span></pre><p id="8855" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们将遍历data_loader，遍历每张图片和标签。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="ae6d" class="jv jw hh kw b fi la lb l lc ld">#iterating through our data<br/>dataiter = iter(data_loader)<br/>images, labels = dataiter.next()</span></pre><p id="f52f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将打印图像的torch.min()来查找输入张量中所有元素的最小值，并打印torch.max()来查找输入张量中所有元素的最大值。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="3c82" class="jv jw hh kw b fi la lb l lc ld">#output will get the minimum tensor and the maximum tensor in the dataset --&gt; important for our last activation</span><span id="c602" class="jv jw hh kw b fi le lb l lc ld">print(torch.min(images), torch.max(images))</span></pre><p id="b969" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这最后一句话很重要，因为返回的张量值将决定我们在解码器的最后一层需要使用什么函数。因为输出显示我们的最小张量是张量(0。)并且最大张量是张量(1。)，这意味着所有的张量都在这些数之间，所以我们必须使用Sigmoid激活。</p><p id="e58a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记住sigmoid激活函数是连续的，所有点上的导数总是产生数字0和1之间的输出。</p></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="2c24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们已经准备好了数据，并了解了一些有用的信息，我们可以开始构建我们的自动编码器神经网络。</p><p id="8519" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是我们整个代码的概述:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="150c" class="jv jw hh kw b fi la lb l lc ld">class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay<br/><br/>        #encoder<br/>        self.encoder = nn.Sequential(<br/>            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>            nn.ReLU(),<br/>            nn.Linear(128, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 3)<br/>        )<br/><br/>        #decoder<br/>        self.decoder = nn.Sequential(<br/>            nn.Linear(3, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 128),<br/>            nn.ReLU(),<br/>            nn.Linear(128, 28 * 28),<br/>            nn.Sigmoid()  # cause tensors are 0, 1<br/>        )<br/><br/>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>        self.loss = nn.MSELoss()<br/><br/>    #feed data through network<br/>    def forward(self, x):<br/>        encoder = self.encoder(x)<br/>        decoder = self.decoder(encoder)<br/>        return decoder<br/><br/>    #training loop<br/>    def train(self):<br/>        for epoch in range(self.epochs):<br/>            for data in data_loader:<br/>                img, _ = data<br/>                img = img.view(img.size(0), -1)<br/>                img = Variable(img)<br/><br/>                #predict<br/>                output = self(img)<br/><br/>                # find loss<br/>                loss = self.loss(output, img)<br/><br/>                # perform back propagation<br/>                self.optimizer.zero_grad()<br/>                loss.backward()<br/>                self.optimizer.step()<br/><br/>            print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')<br/><br/>model = autoencoder()<br/>model.train()</span></pre><p id="cd20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">好了，这是一个很大的进步，所以让我们把它一部分一部分的分解吧:)</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="e439" class="jv jw hh kw b fi la lb l lc ld">class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay<br/><br/>        #encoder<br/>        self.encoder = nn.Sequential(<br/>            nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>            nn.ReLU(),<br/>            nn.Linear(128, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 3)<br/>        )<br/><br/>        #decoder<br/>        self.decoder = nn.Sequential(<br/>            nn.Linear(3, 12),<br/>            nn.ReLU(),<br/>            nn.Linear(12, 64),<br/>            nn.ReLU(),<br/>            nn.Linear(64, 128),<br/>            nn.ReLU(),<br/>            nn.Linear(128, 28 * 28),<br/>            nn.Sigmoid()  # cause tensors are 0, 1<br/>        )<br/><br/>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>        self.loss = nn.MSELoss()</span></pre><p id="60f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将调用我们的类autoencoder，它将继承nn。模块类。这通常是PyTorch中所有神经网络的基类。</p><p id="a56a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了简单地解释这个模块，它使用张量和自动微分模块(计算函数导数的技术)来训练和构建层(输入、隐藏、输出等)。</p><p id="a100" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的__init__中，我们将传入我们的纪元、批量大小和学习率，并对它们进行初始化。你可以摆弄这些数字，但是，这些是我发现效果最好的数字。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="027f" class="jv jw hh kw b fi la lb l lc ld">class autoencoder(nn.Module):<br/>    def __init__(self, epochs=10, batchSize=128, learningRate=1e-3, weight_decay=1e-5):<br/>        super(autoencoder, self).__init__()<br/>        self.epochs = epochs<br/>        self.batchSize = batchSize<br/>        self.learningRate = learningRate<br/>        self.weight_decay = weight_decay</span></pre><p id="37bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">初始化之后，我们可以开始构建我们的编码器。</p><p id="6431" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用一个简单的顺序结构，一个线性层后面跟着一个relu激活。请注意，我们传入的图像大小为28 x 28，因为时尚MNIST数据集的图像为784像素。每一层，我们都会减少投入。</p><p id="018e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以把我们的输入想象成N，784，编码器的输出将会显著地减少到N，3。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="ca91" class="jv jw hh kw b fi la lb l lc ld">#encoder<br/>self.encoder = nn.Sequential(<br/>    nn.Linear(28 * 28, 128),  # reduces from n * 724 to 128<br/>    nn.ReLU(),<br/>    nn.Linear(128, 64),<br/>    nn.ReLU(),<br/>    nn.Linear(64, 12),<br/>    nn.ReLU(),<br/>    nn.Linear(12, 3)<br/>)</span></pre><p id="b6fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的解码器与我们的编码器结构相似，但是，我们的方向相反，即→ N，3到N，784。</p><p id="b1bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于我们的最后一层，注意我们使用了sigmoid激活(前面解释过)。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="fbc0" class="jv jw hh kw b fi la lb l lc ld">#decoder<br/>self.decoder = nn.Sequential(<br/>    nn.Linear(3, 12),<br/>    nn.ReLU(),<br/>    nn.Linear(12, 64),<br/>    nn.ReLU(),<br/>    nn.Linear(64, 128),<br/>    nn.ReLU(),<br/>    nn.Linear(128, 28 * 28),<br/>    nn.Sigmoid()  # cause tensors are 0, 1<br/>)</span></pre><p id="8f94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以初始化优化器和标准了。一定要确保在你的自动编码器下面定义它，否则你将不能传递任何东西。</p><p id="0124" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记住→优化器是改变属于你的神经网络的属性的算法，比如权重和学习率，以减少损失。</p><p id="eef3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于我们的网络，我们将使用Adam优化器。我们将需要传入self.parameters、我们的学习率和我们的weight_decay(这是我们之前在网络中初始化的)。</p><p id="e507" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记住→学习率控制着网络适应问题的速度。</p><p id="b0dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记住→正则化是一种约束我们的网络精确拟合我们的数据，避免过度拟合的方法。Weight_decay是一种在神经网络上执行正则化的方法。</p><p id="66a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，我们将使用MSELoss。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="0797" class="jv jw hh kw b fi la lb l lc ld">self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=self.weight_decay)<br/>self.loss = nn.MSELoss()</span></pre><p id="9a59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">好了，现在我们可以把数据输入网络了。我们将接受x，将它传入我们的编码器，将我们的编码器传入解码器，最后返回我们的解码器的结果。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="fbf7" class="jv jw hh kw b fi la lb l lc ld">#feed data through network<br/>def forward(self, x):<br/>    encoder = self.encoder(x)<br/>    decoder = self.decoder(encoder)<br/>    return decoder</span></pre><p id="7c71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经建立了我们的网络，我们可以创建一个函数来训练我们的模型。</p><p id="f0d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将在每个时期迭代我们的数据集，并增加我们的图像以适应网络。我们将调用预测，计算损失，然后执行反向传播。在每一个时代之后，我们将输出损失。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="8129" class="jv jw hh kw b fi la lb l lc ld">#training loop<br/>def train(self):<br/>    for epoch in range(self.epochs):<br/>        for data in data_loader:<br/>            img, _ = data<br/>            img = img.view(img.size(0), -1)<br/>            img = Variable(img)<br/><br/>            #predict<br/>            output = self(img)<br/><br/>            # find loss<br/>            loss = self.loss(output, img)<br/><br/>            # perform back propagation<br/>            self.optimizer.zero_grad()<br/>            loss.backward()<br/>            self.optimizer.step()<br/><br/>        print(f'epoch {epoch + 1}/{self.epochs}, loss: {loss.data:.4f}')</span></pre><p id="50e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，为了运行我们的模型，我们需要创建一个autoencoder类的对象，我们将这个对象称为模型。为了训练模型，我们将在对象上调用我们的训练函数。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="3593" class="jv jw hh kw b fi la lb l lc ld">model = autoencoder()<br/>model.train()</span></pre></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><p id="aee7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望你喜欢这篇关于如何在PyTorch中构建自动编码器的解释和教程！这个模型训练得很好，几乎没有损失，您可以通过从时尚MNIST中选取一个特定的图像来测试结果，将它输入到模型中，并绘制出之前和之后的结果。</p></div><div class="ab cl jo jp go jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="ha hb hc hd he"><h1 id="0744" class="lf jw hh bd jx lg lh li kb lj lk ll kf lm ln lo ki lp lq lr kl ls lt lu ko lv bi translated">如有任何疑问，请联系我🚀</h1><p id="56b6" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">嗨，我是Ashley，一个16岁的编程呆子，也是一个人工智能和神经科学爱好者！</p><p id="f9e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望你喜欢阅读我的文章，如果你喜欢，请随时查看我在Medium上的其他作品:)</p><p id="2db6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这段代码的仓库在我的GitHub上，在我的“Pytorch”仓库下。</p><p id="425b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你读了这篇文章，你会喜欢的:</p><p id="068b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">💫<a class="ae lw" href="https://ashleyy-czumak.medium.com/mnist-digit-classification-in-pytorch-302476b34e4f" rel="noopener">py torch中的MNIST数字分类</a></p><p id="0699" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">💫<a class="ae lw" rel="noopener" href="/swlh/an-overview-on-convolutional-neural-networks-ea48e76fb186">卷积神经网络概述</a></p><p id="ffe7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">💫<a class="ae lw" rel="noopener" href="/swlh/companies-need-to-mitigate-a-i-bias-830e7cae8149">公司需要减轻人工智能偏见</a></p><p id="6486" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您有任何问题，想了解更多关于我的信息，或者想要任何人工智能或编程相关的资源，您可以通过以下方式联系我:</p><p id="4815" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">💫电子邮件:ashleycinquires@gmail.com</p><p id="7731" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">💫<a class="ae lw" href="https://github.com/ashthedash2k" rel="noopener ugc nofollow" target="_blank"> Github </a></p></div></div>    
</body>
</html>
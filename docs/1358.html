<html>
<head>
<title>Personalization and Recommendation with Contextual Bandits 🤖</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">个性化和推荐与上下文强盗🤖</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/simulating-content-personalization-with-contextual-bandits-6f4efb902af?source=collection_archive---------0-----------------------#2021-12-01">https://medium.com/mlearning-ai/simulating-content-personalization-with-contextual-bandits-6f4efb902af?source=collection_archive---------0-----------------------#2021-12-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="4340" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用Vowpal Wabbit模拟一个内容个性化场景，使用上下文土匪在给定的上下文中选择动作。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/19535a7299d6cc44040f4fb9b209a82b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ol5VB60WTwx-ybpk"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="e880" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="ada3" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">向用户推荐相关和个性化的内容对于媒体服务提供商、电子商务平台、基于内容的平台等至关重要。</p><p id="70b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事实上，有效的推荐系统通过帮助用户浏览大量内容，改善了用户在平台上的体验和参与度。</p><p id="05d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着对个性化系统、高效信息检索和异常检测等功能需求的增长，对优化这些功能的解决方案的需求也在增长。Contextual bandit是一个机器学习框架，旨在解决这些以及其他复杂的情况。</p><p id="038e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本教程包括强化学习的简要概述，这种机器学习范式的上下文强盗方法，并描述了如何用Vowpal Wabbit处理上下文强盗问题。</p><div class="kw kx ez fb ky kz"><a href="https://github.com/99sbr/fastapi-template" rel="noopener  ugc nofollow" target="_blank"><div class="la ab dw"><div class="lb ab lc cl cj ld"><h2 class="bd hi fi z dy le ea eb lf ed ef hg bi translated">GitHub - 99sbr/fastapi-template:完全可扩展的基于fastapi的机器学习模板…</h2><div class="lg l"><h3 class="bd b fi z dy le ea eb lf ed ef dx translated">完全可扩展的基于FastAPI的模板，用于机器学习、深度学习和任何其他软件项目</h3></div><div class="lh l"><p class="bd b fp z dy le ea eb lf ed ef dx translated">github.com</p></div></div><div class="li l"><div class="lj l lk ll lm li ln jm kz"/></div></div></a></div><h1 id="fd3d" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">什么是强化学习？</h1><p id="01b5" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><a class="ae js" href="https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/concepts-reinforcement-learning" rel="noopener ugc nofollow" target="_blank">强化学习</a>是一种机器学习范式，用于训练模型进行顺序决策。它包括使用与软件代理如何在复杂环境中采取适当行动有关的算法，并使用反馈来随着时间的推移最大化回报。这种方法提供了在给定的上下文中制定特定用户行为的自由，并提供了关于如何根据目标奖励所选行为的反馈。</p><h1 id="0768" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">土匪解释道</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lo"><img src="../Images/5b5d0920a338bff2d675ee655cf4caa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YnEP7eIWzsLwQp9nD3-8XQ.png"/></div></div></figure><p id="2a10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设您是一家在线零售商，希望在主页上显示个性化的产品建议。</p><p id="c360" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你只能给一个特定的客户展示有限数量的产品，你不知道哪些会有最好的回报。在这种情况下，如果客户不购买产品，我们将奖励设为0美元，如果他们购买，将商品价格设为0美元。</p><p id="b862" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了最大化你的回报，你可以利用多臂土匪(MAB)算法，其中每个产品都是土匪——可供算法尝试的选择。正如我们在下面看到的，多臂强盗代理必须在每次游戏中选择向用户展示物品1或物品2。每次游戏都是相互独立的——有时用户会花22美元购买物品2，有时用户会两次购买物品2，获得44美元的奖励。</p><div class="kw kx ez fb ky kz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/semantic-search-with-s-bert-is-all-you-need-951bc710e160"><div class="la ab dw"><div class="lb ab lc cl cj ld"><h2 class="bd hi fi z dy le ea eb lf ed ef hg bi translated">使用S-BERT进行语义搜索是您所需要的</h2><div class="lg l"><h3 class="bd b fi z dy le ea eb lf ed ef dx translated">从头开始构建内部语义搜索引擎—快速而准确</h3></div><div class="lh l"><p class="bd b fp z dy le ea eb lf ed ef dx translated">medium.com</p></div></div><div class="li l"><div class="lp l lk ll lm li ln jm kz"/></div></div></a></div><h1 id="2a20" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">背景强盗问题</h1><p id="3c58" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">现在，假设我们有一个客户，他是一名专业的室内设计师，也是一名狂热的针织爱好者。他们可能在工作时间订购壁纸和镜子，回家后浏览不同的纱线。根据他们访问我们网站的时间，我们可能会向他们展示不同的产品。</p><p id="61fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上下文bandit算法是多臂bandit方法的扩展，在选择bandit时，我们会考虑客户的环境或上下文。环境影响奖励如何与每个强盗相关联，因此随着环境的变化，模型应该学会适应它的强盗选择，如下所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lo"><img src="../Images/85afae248b4aa1d69e460a27f6b22327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mxFEnHrI3E907wKm2ouAmg.png"/></div></div></figure><p id="9b3e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在情境强盗问题中，学习者反复观察情境，选择行动，并且只观察所选行动的损失/成本/回报。上下文土匪算法使用额外的辅助信息(或上下文)来帮助现实世界的决策。它们非常适合在动态环境中选择操作，在这种环境中，选项变化很快，并且可用的操作集有限。</p><p id="2d2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有了contextual bandit，学习算法可以测试不同的动作，并自动学习哪一个在给定的情况下具有最有益的结果。这是一种强大的、通用的方法，可以解决从医疗保健到金融等行业的关键业务需求。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lq lr l"/></div></figure><h1 id="6d14" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">沃帕尔·瓦比特:与背景强盗一起工作</h1><p id="1224" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Vowpal Wabbit是一个交互式机器学习库，也是像<a class="ae js" href="https://azure.microsoft.com/en-us/services/cognitive-services/personalizer/" rel="noopener ugc nofollow" target="_blank">微软个性化器</a>这样的服务的强化学习框架。在进行个性化排序和用所有事件训练模型时，它允许最大吞吐量和最低延迟。</p><p id="f248" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本教程使用一个我们称之为<strong class="ig hi"> Con-Ban Agent </strong>的应用示例来介绍一种解决上下文强盗问题的Vowpal Wabbit方法，并探索这种强化学习方法的能力。<strong class="ig hi">网页内容个性化</strong>的问题场景激发了我们的例子<strong class="ig hi">禁止代理</strong>。目标是在每个页面上向用户展示最相关的网页内容，以最大化参与度(点击量)。</p><p id="8fdf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">禁止代理</strong>执行以下功能:</p><ul class=""><li id="c9e6" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated">某个上下文<strong class="ig hi"> x </strong>到达并被<strong class="ig hi">禁止代理</strong>观察到。</li><li id="ea9e" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated"><strong class="ig hi">禁止代理</strong>从一组动作<strong class="ig hi"> A </strong>中选择一个动作<strong class="ig hi"> a </strong>，即<strong class="ig hi">A</strong>∈<strong class="ig hi">A</strong>(<strong class="ig hi">A</strong>可能依赖于<strong class="ig hi"> x </strong>)。</li><li id="14bb" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">被选中的<strong class="ig hi"> a </strong>的某些奖励<strong class="ig hi"> r </strong>被<strong class="ig hi">控制代理</strong>观察到。</li></ul><p id="b4d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上下文bandit设置中，数据点有四个组成部分:</p><ul class=""><li id="bdbb" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated">语境</li><li id="2eb2" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">行动</li><li id="9925" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">选择行动的概率</li><li id="2bae" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">所选行动的奖励/成本</li></ul><p id="d9a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">例如:</strong></p><p id="8dca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Con-Ban代理</strong>新闻网站:</p><ul class=""><li id="9bef" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated"><strong class="ig hi">优化决策</strong>:显示给用户的文章。</li><li id="18b3" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated"><strong class="ig hi">上下文</strong>:用户数据(浏览历史、位置、设备、时间)</li><li id="9963" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated"><strong class="ig hi">动作</strong>:可用的新闻文章</li><li id="a36e" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated"><strong class="ig hi">奖励</strong>:用户参与度(点击或不点击)</li></ul><p id="5504" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们需要在模拟器中生成一个上下文，以获得给定上下文的操作/决策，并模拟生成奖励。模拟器的目标是最大化回报(CTR)——或最小化损失(CTR)。</p><p id="4585" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，<strong class="ig hi">上下文</strong>是(用户，一天中的时间):</p><ul class=""><li id="3d8a" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated">我们有两个网站访问者:“汤姆”和“安娜。”</li><li id="eb4a" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">汤姆和安娜在上午或下午访问网站。</li></ul><p id="42aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以选择向汤姆和安娜推荐各种各样的商品。因此，<strong class="ig hi">动作</strong>是文章的不同选择:“政治”、“体育”、“音乐”、“美食”、“金融”、“健康”，或者“奶酪”。</p><p id="7128" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">奖励</strong>是他们是否点击文章:“点击”或“不点击”</p><h1 id="4db2" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">Vowpal Wabbit中的上下文强盗功能</h1><p id="85c8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">VW包含一个上下文bandit模块，允许您根据已经收集的上下文bandit数据优化预测器。换句话说，该模块不实现浏览，它假定它只能使用通过浏览策略记录的当前可用数据。(注意:有关完整的在线上下文bandit，请参见此处的— cb_explore和— cb_explore_adf选项<a class="ae js" href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Contextual-Bandit-algorithms" rel="noopener ugc nofollow" target="_blank">的使用。)</a></p><p id="4881" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据被指定为一组元组(x，a，c，p ),其中x是决策的当前特征/上下文，a是上下文x的探索策略选择的动作，c是上下文x中动作a的观察成本，p是探索策略在上下文x中选择该动作的概率。</p><p id="7627" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个示例现在跨越多行，每个动作一行。对于每个动作，我们都有标签信息<code class="du mg mh mi mj b">(a,c,p)</code>，如果已知的话，和以前一样。动作字段<code class="du mg mh mi mj b">a</code>现在被忽略，因为动作由行号标识，通常设置为0。成本和概率的语义和以前一样。每个示例还允许精确地指定一个动作的标签信息。换行符表示多行示例的结束。此外，我们可以在一个例子的开头指定所有动作共享的上下文特性，这个例子总是有一个标签<code class="du mg mh mi mj b">shared</code>，就像上面第二个多行例子一样。因为共享行不与任何动作相关联，所以它不应该包含标签信息。</p><p id="4de9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">简单的例子</strong></p><p id="1917" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是一个简单的例子，说明了输入格式以及如何对这些数据使用vw。</p><p id="f082" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们考虑一个有4个动作的问题，我们观察到VW格式的以下5个数据点:</p><pre class="jd je jf jg fd mk mj ml mm aw mn bi"><span id="3dfe" class="mo ju hh mj b fi mp mq l mr ms">1:2:0.4 | a c  <br/>3:0.5:0.2 | b d  <br/>4:1.2:0.5 | a b c  <br/>2:1:0.3 | b c  <br/>3:1.5:0.7 | a d</span></pre><p id="9848" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里每一行都是一个单独的示例，每一行都采用以下形式:</p><pre class="jd je jf jg fd mk mj ml mm aw mn bi"><span id="70d8" class="mo ju hh mj b fi mp mq l mr ms">action:cost:probability | features</span></pre><p id="fc63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在哪里</p><ul class=""><li id="126f" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated">action是我们观察成本时所采取的操作的id ({ 1，k}中的正整数)</li><li id="1331" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">成本是此操作的观察成本(浮点，越低越好)</li><li id="7f10" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">概率是概率(浮点，以[0..1])，以在收集数据时选择此操作</li><li id="9c2b" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">特性是这个例子中所有特性的列表，通常指定用于vw的分类/回归问题</li></ul><p id="8561" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，上面的第一行表明，我们在一个具有特征a和c的示例中观察到动作1的成本为2，并且在收集数据时，该动作被环境中的探索策略以概率0.4选择。</p><h1 id="161e" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">模拟奖励沃帕尔瓦比特</h1><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mt lr l"/></div></figure><p id="2aa9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在现实世界中，我们在观察汤姆和安娜的互动时，必须了解他们对文章的偏好。由于这是一个模拟，我们必须定义Tom和Anna的偏好配置文件。</p><p id="c40a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们提供给学习者的奖励遵循这个偏好简档。我们希望看到，随着我们看到更多样本，学习者是否能做出越来越好的决定，这反过来意味着我们正在最大化回报。</p><p id="df79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了做到这一点，我们需要以几种不同的方式修改奖励函数，并看看上下文中的bandit学习者是否会发现这些变化。然后，我们比较有学习和没有学习的CTR。</p><p id="6312" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Vowpal Wabbit优化以最小化成本，这是回报的负数。</p><p id="f7d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，<strong class="ig hi">我们总是将报酬的负数作为成本传递给Vowpal Wabbit。</strong></p><pre class="jd je jf jg fd mk mj ml mm aw mn bi"><span id="d3c8" class="mo ju hh mj b fi mp mq l mr ms"><em class="mu"># VW tries to minimize loss/cost, therefore we will pass cost as -reward<br/></em>USER_LIKED_ARTICLE <strong class="mj hi">=</strong> <strong class="mj hi">-</strong>1.0<br/>USER_DISLIKED_ARTICLE <strong class="mj hi">=</strong> 0.0</span></pre><p id="b100" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的奖励函数指定了<strong class="ig hi"> <em class="mu">汤姆早上喜欢政治，下午喜欢音乐。安娜早上喜欢运动，下午喜欢政治。这看起来很难理解，但我们是在以学习者理解的反馈形式——成本——模拟一个假想的世界。</em></strong></p><p id="b845" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果学习者推荐了一篇符合奖励功能的文章，我们会给予积极的奖励。在我们的模拟中，这是一次点击。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><h1 id="10bd" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">了解Vowpal Wabbit格式</h1><p id="bfb0" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们需要采取一些步骤以Vowpal Wabbit理解的格式设置我们的输入。</p><p id="891e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个函数处理从我们的上下文(如字典、文章列表和费用，如果有的话)到它理解的文本格式的转换:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><p id="e0a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了理解这种格式，我们来看一个例子。在本例中，时间是早上，用户是Tom。有四种可能的文章。</p><p id="e6d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Vowpal Wabbit格式中，有一行以shared开始，即共享上下文，后面是四行，每行对应一篇文章:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mw"><img src="../Images/0ef93a95515543fdee5eab1047685df1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GJx3XYc4EKmEzzcVu44j3Q.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 3</figcaption></figure><p id="7f44" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多详情在这里:<a class="ae js" href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format" rel="noopener ugc nofollow" target="_blank">https://github . com/VowpalWabbit/vowpal _ wabbit/wiki/Input-format</a></p><h1 id="dbda" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">从沃帕尔·瓦比特那里得到一个决定</h1><p id="5890" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">当我们调用Vowpal Wabbit时，输出是一个<a class="ae js" href="https://en.wikipedia.org/wiki/Probability_mass_function" rel="noopener ugc nofollow" target="_blank">概率质量函数</a> (PMF)。Vowpal Wabbit提供了一系列行动的可能性列表，因为我们将勘探纳入了我们的战略。这种探索意味着列表中给定索引处的概率对应于选择特定动作的可能性。</p><p id="5895" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了做出决定/采取行动，我们必须从这份清单中取样。</p><p id="1879" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，给定list<strong class="ig hi">【0.7，0.1，0.1，0.1】</strong>，我们会以70%的概率选择第一个项目。命令<code class="du mg mh mi mj b"><strong class="ig hi">sample_custom_pmf</strong></code>获取这样一个列表，并给出它选择的索引以及选择该索引的概率。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><p id="1c77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们拥有为特定用户和上下文选择操作所需的所有信息。使用Vowpal Wabbit通过以下步骤实现这一点:</p><ol class=""><li id="c088" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb mx ly lz ma bi translated">将上下文和动作转换成所需的文本格式。</li><li id="01bc" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">将此示例传递给Vowpal Wabbit，并获得PMF输出。</li><li id="17cb" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">尝试此PMF以获取要展示的文章。</li><li id="8caa" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">返回选择的文章和选择它的概率。</li></ol><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><h1 id="81b9" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">强化学习模拟</h1><p id="06e1" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">现在我们已经完成了所有的设置工作，并且知道了如何与Vowpal Wabbit交互，让我们来模拟Tom和Anna的世界。场景如下:汤姆和安娜访问一个网站，看到一篇文章。请记住，奖励功能允许我们定义对Vowpal Wabbit推荐的内容的真实反应。</p><p id="4256" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们随机地在汤姆和安娜之间进行选择，并且随机地选择他们访问网站的时间。把这想象成抛硬币来选择汤姆和安娜，再抛一次硬币来选择一天中的时间。</p><h1 id="7642" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">实例化学员</h1><p id="9070" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们在Vowpal Wabbit中实例化一个上下文bandit学习器，然后模拟Tom和Anna的网站访问次数num_iterations。每次访问时，我们都要做以下工作:</p><ol class=""><li id="0942" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb mx ly lz ma bi translated">在汤姆和安娜之间做决定</li><li id="5cd9" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">决定一天中的时间</li><li id="d909" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">将上下文(即用户、一天中的时间)传递给学习者以获得行动(即文章推荐和选择行动的概率)。</li><li id="8fba" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">获得奖励(即，查看用户是否点击)。记住，成本只是一个负回报。</li><li id="ab88" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">以Vowpal Wabbit格式格式化上下文、动作、概率、奖励</li><li id="110c" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb mx ly lz ma bi translated">从例子中学习</li></ol><p id="4070" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种减少对于我们的每一个模拟都是一样的，所以我们在<code class="du mg mh mi mj b"><strong class="ig hi">run_simulation</strong></code>函数中定义这个过程。我们必须提供成本函数来模拟现实世界是如何工作的:</p><blockquote class="my mz na"><p id="d05e" class="ie if mu ig b ih ii ij ik il im in io nb iq ir is nc iu iv iw nd iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">现实世界中人们的偏好随着时间而变化。为了在模拟中说明这一点，我们合并了两个不同的成本函数，并在中途切换到第二个函数(图7)。</em> </strong></p></blockquote><p id="f5f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们改变成本函数时，我们开始奖励以前从未有过回报的行为:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ne"><img src="../Images/2eddcd93083bcd799fabbd22da96d318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RPE5SHL9S5wFfQ4sNSXZXw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">User Behaviour</figcaption></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><p id="1f9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们在几个样本之后切换到新的奖励函数(运行第一个奖励函数)。请记住，这个奖励功能会改变用户的偏好。它正在与一个<strong class="ig hi">不同的</strong>行动空间比以前。我们应该看到学习者接受这些变化并优化新的偏好。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mv lr l"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es nf"><img src="../Images/4c7bab0e561a3de825f223cbdc6f245e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CtvLDnmFj_StNdVWBmtWEg.png"/></div></div></figure><h1 id="a29d" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">模型保存和加载Python</h1><p id="3569" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">VW支持保存模型并将其加载到另一个VW流程中。该模型的内容包括:</p><ul class=""><li id="3037" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated">大众版本</li><li id="90dd" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">标记为<code class="du mg mh mi mj b">keep</code>的命令行参数</li><li id="3849" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">这是一些混乱的来源，模型的内容通常包含比最初运行VW时提供的更多或更少的参数。这是因为非<code class="du mg mh mi mj b">keep</code>参数不会被保存，一些缩减会插入额外的命令行参数，这些参数本身被标记为<code class="du mg mh mi mj b">keep</code></li><li id="aa9c" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">通用大众状态</li><li id="cb01" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">每个已启用缩减的状态</li></ul><p id="0e8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Python中使用VW时，几乎所有命令行参数都按预期工作。</p><h1 id="cfb0" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">保存模型</h1><p id="af27" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在Python中保存模型可以使用<code class="du mg mh mi mj b">final_regressor</code>。然而，需要注意的是，模型保存发生在VW清理的时候，所以你需要调用<code class="du mg mh mi mj b"><a class="ae js" href="https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/vowpalwabbit.pyvw.html?highlight=finish#vowpalwabbit.pyvw.vw.finish" rel="noopener ugc nofollow" target="_blank">finish</a></code>或者销毁对象(例如用<code class="du mg mh mi mj b">del</code>)，这将依次调用<code class="du mg mh mi mj b"><a class="ae js" href="https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/vowpalwabbit.pyvw.html?highlight=finish#vowpalwabbit.pyvw.vw.finish" rel="noopener ugc nofollow" target="_blank">finish</a></code>。</p><p id="a9c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你也可以随时调用<code class="du mg mh mi mj b"><a class="ae js" href="https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/vowpalwabbit.pyvw.html?highlight=finish#vowpalwabbit.pyvw.vw.save" rel="noopener ugc nofollow" target="_blank">save</a></code>来保存一个模型文件。这只支持保存二进制模型文件，不支持可读版本。</p><pre class="jd je jf jg fd mk mj ml mm aw mn bi"><span id="a9f1" class="mo ju hh mj b fi mp mq l mr ms">vw = pyvw.vw("-f vw.model")<br/>vw = pyvw.vw(final_regressor="vw.model")<br/>vw.save("vw.model")</span></pre><h1 id="25a3" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">加载模型</h1><p id="8414" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">要在Python中加载模型文件，您应该在创建<code class="du mg mh mi mj b">vw</code>实例时使用<code class="du mg mh mi mj b">initial_regressor</code>配置对象。</p><pre class="jd je jf jg fd mk mj ml mm aw mn bi"><span id="e23b" class="mo ju hh mj b fi mp mq l mr ms">vw = pyvw.vw("-i vw.model")<br/>vw = pyvw.vw(initial_regressor="vw.model")</span></pre><h1 id="d71b" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">资源</h1><p id="57d8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我没有试图修改大众现有的教程，并试图只收集相关的部分，为这个教程。这里可供探索的选择非常多。务必阅读他们的参考资料，并相应地进行实验。我希望这篇博客让你对大众的强大有了一个很好的了解。</p><ul class=""><li id="3ad0" class="ls lt hh ig b ih ii il im ip lu it lv ix lw jb lx ly lz ma bi translated"><a class="ae js" href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" rel="noopener ugc nofollow" target="_blank">https://github.com/VowpalWabbit/vowpal_wabbit/wiki</a></li><li id="1a51" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated"><a class="ae js" href="https://vowpalwabbit.org/tutorials/contextual_bandits.html#python-tutorial" rel="noopener ugc nofollow" target="_blank">https://vowpalwabbit . org/tutorials/contextual _ bandits . html # python-tutorial</a></li><li id="95aa" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated"><a class="ae js" href="https://www.microsoft.com/en-us/research/publication/a-contextual-bandit-bake-off-2/" rel="noopener ugc nofollow" target="_blank">https://www . Microsoft . com/en-us/research/publication/a-contextual-bandit-bake-off-2/</a></li></ul><p id="fcfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我以前的报道:<a class="ae js" href="https://subirverma.medium.com" rel="noopener">https://subirverma.medium.com</a></p><div class="kw kx ez fb ky kz"><a href="https://www.linkedin.com/in/sbrvrm/" rel="noopener  ugc nofollow" target="_blank"><div class="la ab dw"><div class="lb ab lc cl cj ld"><h2 class="bd hi fi z dy le ea eb lf ed ef hg bi translated">苏比尔维尔马-数据科学家lll -塔塔1mg | LinkedIn</h2><div class="lg l"><h3 class="bd b fi z dy le ea eb lf ed ef dx translated">Subir是一位充满激情、自学成才的数据科学家。他从2016年开始从事数据科学领域的工作…</h3></div><div class="lh l"><p class="bd b fp z dy le ea eb lf ed ef dx translated">www.linkedin.com</p></div></div><div class="li l"><div class="ng l lk ll lm li ln jm kz"/></div></div></a></div><p id="5369" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">谢谢</p><div class="kw kx ez fb ky kz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="la ab dw"><div class="lb ab lc cl cj ld"><h2 class="bd hi fi z dy le ea eb lf ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lg l"><h3 class="bd b fi z dy le ea eb lf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lh l"><p class="bd b fp z dy le ea eb lf ed ef dx translated">medium.com</p></div></div><div class="li l"><div class="nh l lk ll lm li ln jm kz"/></div></div></a></div></div></div>    
</body>
</html>
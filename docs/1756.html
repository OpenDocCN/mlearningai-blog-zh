<html>
<head>
<title>Training YOLOv5 custom dataset with ease</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轻松训练YOLOv5自定义数据集</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/training-yolov5-custom-dataset-with-ease-e4f6272148ad?source=collection_archive---------0-----------------------#2022-01-26">https://medium.com/mlearning-ai/training-yolov5-custom-dataset-with-ease-e4f6272148ad?source=collection_archive---------0-----------------------#2022-01-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/f9020a736c042e0c5ea6479d4af0f2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ymrwsI2CTerYFyuMLN0kgQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.pexels.com/video/a-woman-wearing-face-mask-4373912/" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="d574" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLOv5是性能最高的物体探测器之一。它速度快，精确度高，而且非常容易训练。</p><p id="0c47" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这个故事中，我们通过一个使用带标签的掩膜数据集的案例研究来讨论使用自定义数据集的YOLOv5模型训练。</p><p id="f8e7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">注意，本文是<a class="ae it" rel="noopener" href="/mlearning-ai/detecting-objects-with-yolov5-opencv-python-and-c-c7cf13d1483c">用YOLOv5、OpenCV、Python和C++ </a>检测物体的续篇。如果你是机器学习的新手，<a class="ae it" rel="noopener" href="/mlearning-ai/machine-learning-frontiers-modelling-basics-7269ae6f0729">值得在这里阅读建模概念的温和介绍</a>。</p><h1 id="b6d5" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">YOLOv5预建模型</h1><p id="9de7" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">YOLOv5出厂时有一套型号:<em class="kv"> YOLOv5n </em>、<em class="kv"> YOLOv5s </em>、<em class="kv"> YOLOv5m </em>等。他们使用MS COCO数据集进行预训练:</p><figure class="kx ky kz la fd ii er es paragraph-image"><div class="er es kw"><img src="../Images/400054d820eaf1bad49b522cc4d580fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*qquOmIAUw02FnfZI2sYeTA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.researchgate.net/profile/Li-Liu-76/publication/327550187/figure/fig5/AS:830132193353729@1574930346294/Recognition-problems-related-to-generic-object-detection-a-image-level-object.png" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="4623" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这些YOLOv5模型能够使用仅80个类别中的一个来对对象进行分类(“人”、“汽车”、“自行车”、“船”、“鸟”等)。</p><p id="46f6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果这些类不符合您的应用程序需求，那么您可能需要用一组不同的类和图像来训练YOLOv5。幸运的是，用自定义数据集训练YOLOv5非常容易。</p><h1 id="7255" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">但是什么是数据集呢？</h1><p id="60fb" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在对象检测的<strong class="iw hi">环境中，数据集是一组图像及其各自的注释。考虑下面的例子:</strong></p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lb"><img src="../Images/ceb1f5492c94dd662bd620c7e9e1b734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kaURkIXnr0SfoxSVSdAEmg.png"/></div></div></figure><p id="41fd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上图及其右边的注释文件是tech zizou的<a class="ae it" href="https://www.kaggle.com/techzizou/labeled-mask-dataset-yolo-darknet" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hi">标注为Mask </strong> </a> <strong class="iw hi"> </strong>数据集的一部分。这个注释文件有4行，每一行指的是图像中的一个特定的面。让我们检查第一行:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="48f1" class="lh jt hh ld b fi li lj l lk ll">0 0.8024193548387096 0.5887096774193549 0.1596774193548387 0.2557603686635945</span></pre><p id="3120" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第一个整数(0)是对象类id。对于这个数据集，类id 0指的是“使用掩码”的类，而类id 1指的是“不使用掩码”的类。以下浮点数是<code class="du lm ln lo ld b">xywh</code>边界框坐标。可以看到，这些坐标被归一化为<code class="du lm ln lo ld b">[0, 1[</code>。</p><p id="dbe1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以按如下方式组合图像及其注释:</p><figure class="kx ky kz la fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/e1bc0981e6632ad505e7e78c12f77b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hq_b1DJLhbybSuDhimvSSA.png"/></div></div></figure><p id="f3d6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，在这种情况下，数据集基本上是用于训练和验证对象检测模型的若干对(图像、注释文件)的集合。</p><h1 id="3fb2" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">训练模型</h1><p id="d50e" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">我们可以按照4个步骤来训练我们的模型。</p><h1 id="aa6e" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">步骤1 —克隆并安装YOLOv5及其依赖项</h1><p id="0f59" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">创建一个工作区文件夹并将YOLOv5克隆到其中:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="1d2a" class="lh jt hh ld b fi li lj l lk ll">$ mkdir yolov5_ws <br/>$ cd yolov5_ws <br/>$ git clone https://github.com/ultralytics/yolov5 <br/>$ cd yolov5 <br/>$ pip install -r requirements.txt</span></pre><p id="481f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">个人电脑。:注意，可能需要在最后一个命令之前升级pip。可以使用以下命令升级pip:<em class="kv">pip安装—升级pip </em></p><p id="264f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">之后，<code class="du lm ln lo ld b">pip</code>将安装所有需要的依赖项。如果您收到类似以下的错误:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="9a0d" class="lh jt hh ld b fi li lj l lk ll">Could not find a version that satisfies the requirement torch (from versions: none)</span></pre><p id="c39d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">很可能您有一个旧的python版本或者更早的版本。在我的例子中，为了让Pytorch在我的机器上运行，我需要将Python 3.10降级到3.9。</p><h1 id="8746" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">步骤2 —获取和准备数据</h1><p id="2c2b" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">访问<a class="ae it" href="https://www.kaggle.com/techzizou/labeled-mask-dataset-yolo-darknet" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/techzizou/labelled-Mask-dataset-yolo-darknet</a>下载带标签的掩膜数据集。将<code class="du lm ln lo ld b">archive.zip</code>文件解压缩到<code class="du lm ln lo ld b">yolov5_ws</code>内的<code class="du lm ln lo ld b">data</code>文件夹中。检查<code class="du lm ln lo ld b">obj</code>文件夹，我们可以确认数据集确实是一堆图像和各自的注释文件:</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/1779a7685182deff5df466a664eaac97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KPpmUan6JoB59KDmcLHUmw.png"/></div></div></figure><p id="3e79" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们需要将这些数据分成两组:训练和验证。大约90%的图像必须复制到<code class="du lm ln lo ld b">yolov5_ws/data/images/training/</code>文件夹中。剩余的图像(全部数据的10%)必须保存在文件夹<code class="du lm ln lo ld b">yolov5_ws/data/images/validation/</code>中。</p><p id="5b62" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">值得注意的是，我们必须小心地将成对的注释文件复制到各自的文件夹<code class="du lm ln lo ld b">yolov5_ws/data/labels/training/</code>和<code class="du lm ln lo ld b">yolov5_ws/data/labels/validation/</code>中。为了避免在执行这些复制时出现任何故障，我建议使用以下python脚本:</p><figure class="kx ky kz la fd ii"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="5d1e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">用您喜欢的名称保存该脚本，并在<code class="du lm ln lo ld b">yolov5_ws</code>文件夹中运行它:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="7d43" class="lh jt hh ld b fi li lj l lk ll">$ cd yolov5_ws <br/>$ python split_data.py</span></pre><p id="4822" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">YOLOv5训练过程将使用<strong class="iw hi">训练子集</strong>来实际学习如何检测物体。<strong class="iw hi">验证数据集</strong>用于在训练期间检查模型性能。</p><h1 id="9fbe" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">步骤3 —准备培训配置文件</h1><p id="39ec" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">我们快到了！下一步是在文件夹<code class="du lm ln lo ld b">yolov5_ws</code>中创建一个名为<code class="du lm ln lo ld b">dataset.yaml</code>的文本文件，内容如下:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="dfd4" class="lh jt hh ld b fi li lj l lk ll">train: ../data/images/training/<br/>val: ../data/images/validation/<br/><br/># number of classes<br/>nc: 2<br/><br/># class names<br/>names: ['with mask', 'without mask']</span></pre><p id="26f3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是列车的最终文件夹结构和文件:</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lt"><img src="../Images/8d6fda18d0840c1aeb6455492a15833e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRA1Z6uQPCV2Z1K9_SwUkg.png"/></div></div></figure><h1 id="8a5c" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">步骤4 —运行列车</h1><p id="e493" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">现在我们都准备好了，是时候实际运行火车了:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="8a46" class="lh jt hh ld b fi li lj l lk ll">$ python train.py --img 640 --batch 16 --epochs 5 --data dataset.yaml --weights yolov5s.pt</span></pre><p id="2b6c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">根据您的硬件，此培训可能需要更长时间，也可能只需要几分钟。在培训过程中，该流程输出如下内容:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="d2ed" class="lh jt hh ld b fi li lj l lk ll">0/9        0G    0.1184    0.0347   0.03127        47       640:   4%|▎         | 3/85 [01:08&lt;30:00, 21.95s/it]</span></pre><p id="0d40" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，我们得到以下输出:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="274a" class="lh jt hh ld b fi li lj l lk ll">10 epochs completed in 1.719 hours.<br/>Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB<br/>Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB<br/><br/>Validating runs/train/exp/weights/best.pt...<br/>Fusing layers... <br/>Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs<br/>               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 5/5 [00:54&lt;00:00, 10.90s/it]                                                                     <br/>                 all        151        283      0.973      0.847       0.95      0.606<br/>          using mask        151        218      0.982      0.862      0.968      0.599<br/>        without mask        151         65      0.964      0.831      0.932      0.613<br/>Results saved to runs/train/exp</span></pre><p id="bfe9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，确认您有一个<code class="du lm ln lo ld b">yolov5_ws/yolov5/runs/train/exp/weights/best.pt</code>文件:</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/f2e8f7ef6f82d712d3aa06fd234a43d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hCvTtHKJMVRk3bmiz60v-w.png"/></div></div></figure><p id="f5a4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你做到了！<code class="du lm ln lo ld b">best.pt</code>是训练过程的模型结果。现在，模型可以进行预测了！</p><h1 id="31db" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">使用训练好的模型</h1><p id="01e2" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">现在我们已经用带标签的掩膜数据集训练了我们的模型，是时候进行一些预测了。这可以使用专门为此设计的现成YOLOv5脚本轻松完成:</p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="0bf3" class="lh jt hh ld b fi li lj l lk ll">python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.4 --source ../../downloads/mask-teens.jpg</span></pre><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lv"><img src="../Images/cdbad0cdc0a52b2b5eae2ca9d484c555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*er1NE0k2jF4hKG-sUSjY2A.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.pexels.com/photo/a-group-of-skaters-with-their-skateboards-on-the-sidewalk-6337382/" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="3557" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在生产中使用<code class="du lm ln lo ld b">best.pt</code>之前，有必要对其性能进行评估。模型评估和选择是机器学习模型设计中最重要的课题之一。然而，用适当的细节来描述这个主题超出了本文的范围。</p><p id="cb1b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">同时，我们可以检查<code class="du lm ln lo ld b">runs/train/exp/results.png</code>的输出，它在训练期间演示模型性能指标:</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/63fb7d554ac7ab4b1020e046377e8af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rxvpvfv7C7_HuPe9V-UmnA.png"/></div></div></figure><p id="cd9c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">特别是，我们应该注意在验证集上展示模型性能的<code class="du lm ln lo ld b">val/</code>指标。这允许我们识别建模问题，例如<em class="kv">过拟合</em>和<em class="kv">欠拟合</em>。</p><h1 id="8e13" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">额外收获:将模型转换成不同的格式</h1><p id="b903" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">该命令将<code class="du lm ln lo ld b">best.pt</code>转换为torchscript和onnx格式，生成两个新文件:<code class="du lm ln lo ld b">best.torchscript</code>和<code class="du lm ln lo ld b">best.onnx</code></p><pre class="kx ky kz la fd lc ld le lf aw lg bi"><span id="1d07" class="lh jt hh ld b fi li lj l lk ll">$ python3 export.py --weights yolov5n.pt --img 640 --include torchscript onnx</span></pre><p id="6ac8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">详情可以查看<a class="ae it" href="https://github.com/doleron/yolov5-opencv-cpp-python#exporting-yolo-v5-models-to-onnx-format" rel="noopener ugc nofollow" target="_blank"> github回购描述</a>。</p><p id="2186" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，您可以将转换后的文件用于不能识别pytorch模型的库。</p><h1 id="f26a" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h1><p id="3143" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">几年前，训练计算机视觉模型是一项极其艰巨的任务，只有那些能够深入挖掘体重更新的复杂动态的天才才能完成。如今，像YOLOv5这样的引擎打破了这一障碍，提供了一套高性能但易于使用的工具。</p><h1 id="9fcb" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">谷歌colab笔记本</h1><p id="2579" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">检查<a class="ae it" href="https://colab.research.google.com/drive/1Plz91PHWwf04bYt21mnWp7qBcDIvJ6J6" rel="noopener ugc nofollow" target="_blank">这里的</a></p><div class="lx ly ez fb lz ma"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mb ab dw"><div class="mc ab md cl cj me"><h2 class="bd hi fi z dy mf ea eb mg ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mh l"><h3 class="bd b fi z dy mf ea eb mg ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mi l"><p class="bd b fp z dy mf ea eb mg ed ef dx translated">medium.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo in ma"/></div></div></a></div></div></div>    
</body>
</html>
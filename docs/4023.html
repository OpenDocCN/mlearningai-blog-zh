<html>
<head>
<title>What is Web scraping and How can I scrape my data from the web?!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是web抓取，我如何从Web上抓取我的数据？！</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/what-is-web-scraping-and-how-can-i-scrape-my-data-from-the-web-e1adfd438a3e?source=collection_archive---------5-----------------------#2022-11-25">https://medium.com/mlearning-ai/what-is-web-scraping-and-how-can-i-scrape-my-data-from-the-web-e1adfd438a3e?source=collection_archive---------5-----------------------#2022-11-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="857d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di"> W </span> eb抓取是利用机器人从网站中提取内容和数据的过程。</p><p id="92e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与只复制屏幕上显示的像素的屏幕抓取不同，网络抓取提取潜在的HTML代码，以及存储在数据库中的数据。然后，抓取工具可以将整个网站内容复制到其他地方。</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jl"><img src="../Images/67a1e0989dec88d9a31340a8556f9137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*keQpmIE8PIDpDGnr"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx">Photo by <a class="ae kb" href="https://unsplash.com/@ilyapavlov?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ilya Pavlov</a> on <a class="ae kb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1284" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">网络抓取用于各种依赖数据采集的数字业务。合法的使用案例包括:</p><ul class=""><li id="8681" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">搜索引擎机器人抓取网站，分析其内容，并对其进行排名。</li><li id="ad9a" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">价格比较网站部署机器人自动获取联合卖家网站的价格和产品描述。</li><li id="cc00" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">市场研究公司使用抓取工具从论坛和社交媒体中提取数据(例如，用于情感分析)。</li></ul><p id="7964" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">网络抓取也被用于非法目的，包括降低价格和窃取版权内容。被“掠夺者”盯上的在线实体可能会遭受严重的财务损失，尤其是如果它是一家严重依赖竞争性定价模式或内容分发交易的企业。</p><h1 id="a98b" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">我如何从网上搜集数据？</h1><p id="8226" class="pw-post-body-paragraph ie if hh ig b ih lo ij ik il lp in io ip lq ir is it lr iv iw ix ls iz ja jb ha bi translated">网络搜集经历已知的阶段，这些阶段除了在某些情况下不会改变，但是网络搜集的基本阶段是:</p><ul class=""><li id="1dfb" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">识别独特的HTML站点结构</li><li id="8df8" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">提取和转换内容</li><li id="020a" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">存储抓取的数据</li></ul><p id="9091" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文使用Python的一个名为Beautiful Soup的web抓取框架的实现来讨论Web抓取中涉及的步骤。<strong class="ig hi">抓取网页的步骤:</strong></p><ol class=""><li id="bd43" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb lt ki kj kk bi translated">向您想要访问的网页的URL发送HTTP请求。服务器通过返回网页的HTML内容来响应请求。对于这个任务，我们将使用第三方HTTP库来处理python请求。</li><li id="63d7" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb lt ki kj kk bi translated">一旦我们访问了HTML内容，就剩下解析数据的任务了。由于大多数HTML数据是嵌套的，我们不能简单地通过字符串处理来提取数据。我们需要一个解析器来创建HTML数据的嵌套/树结构。有许多可用的HTML解析器库，但最先进的是lxml。</li><li id="6c15" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb lt ki kj kk bi translated">现在，我们需要做的就是导航和搜索我们创建的解析树，即树遍历。对于这个任务，我们将使用另一个第三方python库，<a class="ae kb" href="http://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank">【美汤】</a>。这是一个Python库，用于从HTML和XML文件中提取数据。</li><li id="72bc" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb lt ki kj kk bi translated">在我们提取数据后，我们希望将它们存储在CSV或表中，我们将使用pandas库来完成这项任务。</li></ol><p id="dd07" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">安装所需的第三方库</strong></p><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="98ea" class="lz kr hh lv b be ma mb l mc md">pip install requests<br/>pip install bs4<br/>pip install pandas</span></pre><p id="5fed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">从网页访问HTML内容</strong></p><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="7fff" class="lz kr hh lv b be ma mb l mc md">import requests<br/>URL = "https://www.thewhiskyexchange.com/p/29388/hibiki-harmony"<br/>r = requests.get(URL)<br/>print(r.content)</span></pre><p id="05c8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们试着理解这段代码。</p><ul class=""><li id="d99a" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">首先导入请求库。</li><li id="9643" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">然后，指定要抓取的网页的URL。</li><li id="910e" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">向指定的URL发送HTTP请求，并将来自服务器的响应保存在名为r的响应对象中。</li><li id="db6e" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">现在，作为print r.content来获取网页的<strong class="ig hi">原始HTML内容</strong>。它属于“字符串”类型。</li></ul><p id="0392" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意:有时你可能会得到一个错误“不接受”,所以尝试添加一个浏览器用户代理，如下所示。从这里找到你的基于设备和浏览器的用户代理【https://deviceatlas.com/blog/list-of-user-agent-strings T2】</p><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="515d" class="lz kr hh lv b be ma mb l mc md">headers = {'User-Agent': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246"}<br/># Here the user agent is for Edge browser on windows 10. You can find your browser user agent from the above given link.<br/>r = requests.get(url=URL, headers=headers)<br/>print(r.content)</span></pre><p id="3777" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">解析HTML内容</strong></p><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="9a9a" class="lz kr hh lv b be ma mb l mc md">import requests<br/>from bs4 import BeautifulSoup<br/>  <br/>URL = "https://www.thewhiskyexchange.com/p/29388/hibiki-harmony"<br/>r = requests.get(URL)<br/>  <br/>soup = BeautifulSoup(r.content, 'lxml') # If this line causes an error, run 'pip install lxml' or install html5lib<br/>print(soup.prettify())</span></pre><p id="44d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">BeautifulSoup库的一个非常好的地方是它建立在html5lib、lxml、html.parser等HTML解析库之上。所以BeautifulSoup对象和指定解析器库可以同时创建。在上面的例子中，</p><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="33c7" class="lz kr hh lv b be ma mb l mc md">soup = BeautifulSoup(r.content, 'lxml')</span></pre><p id="833d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们通过传递两个参数来创建一个BeautifulSoup对象:</p><ul class=""><li id="a4ac" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated"><strong class="ig hi"> r.content </strong>:是原始的HTML内容。</li><li id="6b89" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">lxml :指定我们想要使用的HTML解析器。</li></ul><p id="3cb1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在<strong class="ig hi">soup . pretify()</strong>被打印出来，<strong class="ig hi"> </strong>它给出了从原始HTML内容创建的解析树的可视化表示。</p><h2 id="0178" class="me kr hh bd ks mf mg mh kw mi mj mk la ip ml mm le it mn mo li ix mp mq lm mr bi translated"><strong class="ak">在解析树中搜索和导航</strong></h2><p id="7a95" class="pw-post-body-paragraph ie if hh ig b ih lo ij ik il lp in io ip lq ir is it lr iv iw ix ls iz ja jb ha bi translated">现在，我们想从HTML内容中提取一些有用的数据。soup对象包含嵌套结构中的所有数据，这些数据可以通过编程方式提取。在我们的例子中，我们正在抓取一个包含一些产品的网页。因此，我们希望创建一个程序来保存“名称”、“浓度”、“评级”、“描述”、“股票_行动”和“价格”(以及所有与它们相关的信息)。</p><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="51ef" class="lz kr hh lv b be ma mb l mc md">#Python program to scrape website <br/>#and save products infomation from website<br/>import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd<br/><br/>URL = "https://www.thewhiskyexchange.com/p/29388/hibiki-harmony"<br/>r = requests.get(URL)<br/>soup = BeautifulSoup(r.content , 'lxml')<br/>name = soup.find('h1', class_ = 'product-main__name').text.strip()<br/>concentration = soup.find('p' , class_ = 'product-main__data').text.strip()<br/>try:<br/>    rating = soup.find('div', class_="review-overview").text.strip()<br/>except:<br/>    rating = 'no rating'<br/>desc = soup.find('div', class_="product-main__description").find('p').text.strip()<br/>stock_action = soup.find('p',class_="product-action__stock-flag").text.strip()<br/>price = soup.find('p',class_="product-action__price").text.strip()<br/>    <br/>wisky = {<br/>        'Name':name,<br/>        'Concentration':concentration,<br/>        'Rating':rating,<br/>        'Description':desc,<br/>        'Stock_Action':stock_action,<br/>        'Price':price<br/>        }<br/>df = pd.DataFrame(wisky, index = [1])<br/>df.to_csv('japanes_wisky_store_data.csv',index = False)</span></pre><p id="8b6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在继续之前，我们建议您浏览我们使用soup.prettify()方法打印的网页的HTML内容，并尝试找到一种模式或导航到该信息的方法。关于“名称”、“集中度”、“评级”、“描述”、“股票_行动”和“价格”。</p><ul class=""><li id="3cc2" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">注意，名称位于“h1”容器中，该容器的类是“product-main__name”。因此，我们使用<strong class="ig hi"> find() </strong>方法找到‘h1’元素:</li></ul><pre class="jm jn jo jp fd lu lv lw bn lx ly bi"><span id="ba48" class="lz kr hh lv b be ma mb l mc md">name = soup.find('h1', class_ = 'product-main__name').text.strip()</span></pre><ul class=""><li id="4f5b" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">第一个参数是要搜索的HTML标记，第二个参数是一个字典类型的元素，用于指定与该标记相关联的附加属性。<strong class="ig hi"> find() </strong>方法返回第一个匹配的元素。你可以试着打印<strong class="ig hi">table . pretify()</strong>来了解这段代码做了什么。</li><li id="777c" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">我们从它的文本中提取我的。文本并通过strip()删除空格和其他内容</li><li id="2262" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">我们可以通过右键单击，然后单击inspect，了解我想要的术语的标签和属性，从而了解名称和其他名称的标签。</li><li id="5234" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">通过知道术语的标签和属性，我可以像在程序中一样通过find()提取它。</li></ul><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es ms"><img src="../Images/efce8ed1577d6963346d7fd6ba4d8ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*04Gv0EPKa9X0gl8a5lMqRg.png"/></div></figure><p id="af2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我可以对术语“集中度”、“评级”、“描述”、“股票_行动”和“价格”执行相同的步骤。</p><p id="7171" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们创建了一个字典来保存我们产品的所有信息。</p><p id="b388" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是笔记本，它包含了从网站上抓取所有产品的完整代码。<a class="ae kb" href="https://github.com/talalatef/Data-Science-Portofolio/blob/main/Web-Scraping/japanes_wisky/product_scraping.ipynb" rel="noopener ugc nofollow" target="_blank">代码</a></p><p id="4ec3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们可以说我们对网络抓取有了一个很好的看法，并且知道它的发展阶段:</p><ul class=""><li id="ca87" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">识别独特的HTML站点结构</li><li id="3274" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">提取和转换内容</li><li id="3715" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">存储抓取的数据</li></ul><p id="90b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据提取是一个例行程序，除了在简单的情况下不会失败，我们将面临的最大挑战是，我们没有机会使用页面的HTML文件，所以我们将使用另一种方法，即我们将通过selenium library提取数据，这是另一个可能在未来讨论的问题。</p><p id="8405" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">如果你想要一个学习网页抓取的好课程，我建议你看这个</strong> <a class="ae kb" href="https://youtube.com/playlist?list=PLRzwgpycm-Fio7EyivRKOBN4D3tfQ_rpu" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">课程</strong> </a>，我的文章就摘自其中。</p><p id="2284" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您发现我的文章对您有用，我希望您支持我，并关注我以获得更多有用的文章😊😊。</p><div class="mt mu ez fb mv mw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mx ab dw"><div class="my ab mz cl cj na"><h2 class="bd hi fi z dy nb ea eb nc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nd l"><h3 class="bd b fi z dy nb ea eb nc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ne l"><p class="bd b fp z dy nb ea eb nc ed ef dx translated">medium.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk jv mw"/></div></div></a></div></div></div>    
</body>
</html>
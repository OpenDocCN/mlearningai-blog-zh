<html>
<head>
<title>Landcover classification using LiDAR and Hyperspectral data Fusion</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于激光雷达和高光谱数据融合的土地覆盖分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/landcover-classification-using-lidar-and-hyperspectral-data-fusion-895fd0703d1b?source=collection_archive---------3-----------------------#2022-12-26">https://medium.com/mlearning-ai/landcover-classification-using-lidar-and-hyperspectral-data-fusion-895fd0703d1b?source=collection_archive---------3-----------------------#2022-12-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ba62" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">学习使用高光谱和激光雷达数据的融合来执行稳健的土地覆盖分类。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/73e798e17b6f5d9c342a4c4bc9b30b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J4awhRFzNuq-UE-rihECwg.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/es/@danroizer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Dan Roizer</a> on <a class="ae js" href="https://unsplash.com/photos/ETAKnrWhbCs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="3caa" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="e38b" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">本文是土地覆盖分类系列的第3部分。在第一部分中，我们学习了使用来自激光雷达的<a class="ae js" rel="noopener" href="/mlearning-ai/a-quick-guide-to-lidar-part-2-cd2dcd2e60fd">单像素</a>进行土地覆盖分类。在第二部分中，我们学习了使用来自激光雷达的像素周围的<a class="ae js" rel="noopener" href="/mlearning-ai/a-quick-guide-to-lidar-part-3-7871ed6c3f2c"> NxN邻域进行分类。</a></p><p id="e9d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将使用高光谱图像(HSI)和激光雷达数据的融合来提高分类性能。每个传感器或模态从感兴趣的区域捕获一些独特的信息。因此，合并来自多个传感器的信息将提供对感兴趣区域的洞察。例如，如果我们合并来自文本和语音的数据，我们可以执行更好的情感分析。仅仅依靠文本情态会导致不正确的结果，因为一个句子可以用于不同的情感/情绪。同样，融合来自激光雷达和HSI的信息可以导致更准确的土地覆盖分类。因此，在本文中，我们将逐步学习使用深度神经网络来执行这两种模态的融合。</p><h1 id="709f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">数据</h1><p id="d5d4" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们在这次演示中使用了<a class="ae js" href="https://github.com/GatorSense/MUUFLGulfport" rel="noopener ugc nofollow" target="_blank"> MUUFL Gulfport </a>数据集。数据在一个<em class="kw">中。mat </em>文件。我们可以读一下<em class="kw">。使用S <em class="kw"> cipy </em>库的python中的mat </em>文件。HSI数据中有64个光谱带。HSI数据的形状为(325 x 220 x 64)。激光雷达数据包含高度和强度。激光雷达数据的形状为(325 x 220 x 2)。</p><p id="2b14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">HSI数据的光谱分辨率为10纳米，空间分辨率为0.5米x 1米。HSI的波长范围为0.375微米–1.05微米。激光雷达的空间分辨率为0.6米x 0.7米，波长为1.06微米</p><h1 id="a3aa" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">履行</h1><h2 id="63ae" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤1:导入库</h2><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="8c76" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤2:读取文件并提取激光雷达和HSI数据和地面实况</h2><p id="bf1e" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><em class="kw">。mat </em>文件包含几个MATLAB struct字段名。名为'<em class="kw"> hsi' </em>的字段包含地面实况、激光雷达数据等。在第9-10行，我们提取了高光谱数据。在第16行，我们提取了激光雷达数据。在第20行，我们得到了地面真相。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="12f5" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤3:查找激光雷达数据中每个像素周围的NxN邻域</h2><p id="1488" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">对于激光雷达数据，我们在一个像素周围取一个11x11的邻域。我们这样做是为了更好地理解目标像素周围的地形。在这个11×11的小块中，高度的标准偏差可以判断表面是不平的还是平坦的。我们可以使用这些信息来区分像树和道路这样的类。由于树叶的原因，树木的高度标准偏差会更高。相比之下，道路和人行道将具有较低的标准偏差。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="a0b0" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤4:修改地面实况和HSI数据</h2><p id="90d8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">地面真相包含标签- <em class="kw"> 1，1，2，…，和11 </em>。<em class="kw"> '-1' </em>为未标注数据。我们需要标签<em class="kw"> 1，2，…，和11 </em>。现在，我们需要从0到10对标签进行编码。一个简单的方法是从基本事实标签中减去<em class="kw"> 1 </em>。</p><p id="155a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">HSI数据的形状为(325 x 220 x 64)。我们还拉平了恒指数据。现在，形状是(325*220 x 64)。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="c277" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤5:将数据分成训练测试</h2><p id="976c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们将数据分为训练/测试。稍后，我们将执行蒙特卡罗实验，并最终报告平均准确度。为此，我们需要在每个实验中随机训练和测试样本。</p><p id="6255" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将训练和测试数据保存到一个. npz文件中，这样，如果我们多次运行代码，就可以轻松地加载相同的数据。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="10b9" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤6:标签的一次性编码以及训练和测试数据的标准化</h2><p id="b889" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">现在，我们一次性加热目标标签。使用最小/最大缩放在0和1之间缩放数据。激光雷达的每个通道都单独缩放。HSI数据已经存在于0和1之间。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="fff5" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤7:为分类定义一个CNN模型</h2><p id="805a" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">对于我们的CNN模型，我们有两个输入。一个是激光雷达数据，另一个是HSI数据。首先，我们添加卷积层来提取每个模态的潜在特征。然后，两种模态的卷积特征被连接以生成融合的表示。现在，这个融合的表示被作为输入传递给分类神经网络。分类器使用softmax激活将每个样本分类为不同的类别。使用“分类交叉熵”损失和“Adam”优化器来训练该模型。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ln"><img src="../Images/1537968f8e73b10a340e6688a4bcf353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJjC_Td2m4OOpo7ISpqFnA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Fusion Model (Image by Author)</figcaption></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h2 id="9eef" class="kx ju hh bd jv ky kz la jz lb lc ld kd ip le lf kh it lg lh kl ix li lj kp lk bi translated">步骤8:训练模型，根据测试数据进行预测，并报告准确性</h2><p id="d070" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">模型训练40个历元，批量设置为128。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="9576" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们已经对相同网络架构的<em class="kw"> 7 </em>次迭代进行了蒙特卡罗实验。每次我们随机抽取一组训练和测试样本。我们实现了平均准确率<em class="kw"> 93.18% 1.3 </em>。最佳精度的混淆矩阵如下所示。在<a class="ae js" rel="noopener" href="/mlearning-ai/a-quick-guide-to-lidar-part-3-7871ed6c3f2c">最后一部分</a>中，我们仅使用激光雷达数据对土地覆盖进行分类，并获得了<em class="kw">87.65%±3.08的精度。</em>所以，使用融合后，准确率显著提高。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lo"><img src="../Images/14bcd2b63821c5a1d0486e018db28c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dnJuaKWhTWbTZEThF67pyA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Confusion matrix (Image by Author)</figcaption></figure><blockquote class="lp lq lr"><p id="0520" class="ie if kw ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">完整的代码在这里给出<a class="ae js" href="https://github.com/namratadutt/LiDAR-and-Hyperspectral-Fusion-classification" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><h1 id="04bf" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="d9ff" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在这一部分中，我们学习了通过融合HSI和LiDAR数据对土地覆盖分类。在激光雷达中，NxN邻域可以更好地反映感兴趣区域内的高度和强度变化。HSI数据提供了每种材料的独特特征，有助于我们轻松分类。然而，它在某些情况下无法区分，比如草和树，因为它们有相似的特征。但是，如果我们借助激光雷达等其他设备，它可以为我们提供目标区域/类别的高度。使用激光雷达，我们可以更好地区分草和树，因为高度不同。我们观察了多模态融合如何比单一模态场景产生更高的准确性。</p><blockquote class="lp lq lr"><p id="4470" class="ie if kw ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">感谢阅读！我希望它是有用的。</p><p id="cbea" class="ie if kw ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">如果你有任何问题或者你想合作一个基于深度学习的项目，请告诉我。</p><p id="3fbe" class="ie if kw ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">加油鳄鱼队！<em class="hh">🐊</em></p></blockquote><h1 id="c667" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考</h1><p id="f2f2" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">页（page的缩写）Gader，a .扎雷亚，r .克洛斯，J. Aitken，G. Tuell，“MUUFL Gulfport超光谱和激光雷达机载数据集”，佛罗里达大学，盖恩斯维尔，佛罗里达州，技术。REP . REP-2013–570，2013年10月。</p><p id="731e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">X.杜和，“技术报告:MUUFL Gulfport数据集的场景标签地面真值图”，佛罗里达大学，盖恩斯维尔，佛罗里达州，技术。代表20170417，2017年4月。</p><div class="lv lw ez fb lx ly"><a href="https://github.com/GatorSense/MUUFLGulfport" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">GitHub-gator sense/muuflgulport:MUUFL gulf port超光谱和激光雷达数据:该数据集…</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">MUUFL Gulfport超光谱和激光雷达数据:该数据集包括HSI和激光雷达数据，评分代码，照片…</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">github.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm jm ly"/></div></div></a></div><div class="lv lw ez fb lx ly"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">medium.com</p></div></div><div class="mh l"><div class="mn l mj mk ml mh mm jm ly"/></div></div></a></div></div></div>    
</body>
</html>
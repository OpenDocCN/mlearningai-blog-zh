<html>
<head>
<title>Generative Adversarial Network for speech synthesis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于语音合成的生成对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/generative-adversarial-network-for-speech-synthesis-9af5f66dc63d?source=collection_archive---------1-----------------------#2021-02-13">https://medium.com/mlearning-ai/generative-adversarial-network-for-speech-synthesis-9af5f66dc63d?source=collection_archive---------1-----------------------#2021-02-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/44065888080b50347cbeab02ba4ad637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cb0hK6amHMZIysec8pMNUw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">The image is taken from Speech Signal Processing Laboratory</figcaption></figure><p id="77b2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi jr translated">生成对抗网络(GANs)在计算机视觉的图像生成中取得了可信的质量。最近，NLP社区对使用GAN进行语音合成表现出浓厚的兴趣。由于文本和语音的性质，在文本到语音转换中使用GANs将更具挑战性，但同时它将改进语音合成任务并克服传统方法中的一些问题。</p><p id="8482" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">GAN由两个独立的神经网络组成:生成器和鉴别器。生成器接收一个随机变量，z遵循分布Pz(z ),并尝试将其映射到数据分布Px(x)。期望发生器的输出分布在训练期间收敛到数据分布。另一方面，期望鉴别器通过分别输出0和1来从生成的样本中辨别真实样本。在训练过程中，生成器和鉴别器分别通过相互对立地影响对方的表现来生成样本并对其进行分类。这是一个双人极大极小游戏。</p><p id="996e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">语音合成是将文本转换成类似人类声音的过程。两种传统的方法被用于TTS任务:串联TTS和参数TTS [1]。基于深度学习的方法通过深度神经网络将语言特征映射到声学特征，DL-method实现了从数据中学习特征的有效工具[1]。有不同的DL模型提供语音合成，例如:深度信念网络(DBN) [2]，深度混合密度网络(DMDN) [3]，深度双向长短期记忆(DBLSTM) [4，5]，WaveNet [6]，以及Tacotron和卷积神经网络(CNN) [7，8]。但是随着今天大规模的并行计算和大数据，最近基于GAN的语音合成被应用于获得更有效的并行化模型。在[9]中引入的GAN-TTS作为条件前馈发生器，其产生原始音频语音(基于多频率随机窗口),并且鉴别器在不同大小的随机窗口上操作(总体随机窗口鉴别器),并且检查所产生的音频如何与期望的话语相关。他们在处理TTS时关注语言学和音高特征[9]。</p><p id="54dc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">由于我们在工作中选择了GAN-TTS，我们应该如[9]中所述调整我们的数据集以适应模型并实现目标。G的输入是200Hz的语言和音高特征序列，其输出是24kHz的原始波形。使用GAN-TTS需要用于训练的高性能GPU，增加鉴别器的数量将需要更多的GPU[9]。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="eb85" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">参考资料:</p><ol class=""><li id="c542" class="kh ki hh iv b iw ix ja jb je kj ji kk jm kl jq km kn ko kp bi translated">宁，等，“基于深度学习的语音合成研究综述”应用科学9.19 (2019): 4050。</li><li id="0c73" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">康，，钱晓军，孟海伦。"用于语音合成的多分布深度信念网络."<em class="kv"> 2013 IEEE声学、语音和信号处理国际会议</em>。IEEE，2013年。‏</li><li id="d516" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">Zen，Heiga和Andrew Senior。"统计参数语音合成中声学建模的深度混合密度网络."<em class="kv"> 2014 IEEE声学、语音和信号处理国际会议(ICASSP) </em>。IEEE，2014年。‏</li><li id="a137" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">基于深度双向长短时记忆的多尺度音乐动态情感预测方法。<em class="kv"> 2016 IEEE声学、语音和信号处理国际会议(ICASSP) </em>。IEEE，2016。</li><li id="7c1b" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">穆萨、阿姆尔·德索基和比约恩·舒勒。"深度双向长短期记忆递归神经网络，用于利用复杂的多对多排列进行字形到音素的转换."<em class="kv">穿插</em>。2016.</li><li id="67ed" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">平行波网:快速高保真语音合成。<em class="kv">机器学习国际会议</em>。2018.</li><li id="6845" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">用tacotron实现表达性语音合成的端到端韵律转换。<em class="kv"> arXiv预印本arXiv:1803.09047 </em> (2018)。‏</li><li id="dd2a" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">立花，秀之，胜矢上野山和俊介相原。“基于深度卷积网络的可有效训练的文本到语音系统，具有引导注意力。”<em class="kv"> 2018 IEEE声学、语音和信号处理国际会议(ICASSP) </em>。IEEE，2018。</li><li id="2958" class="kh ki hh iv b iw kq ja kr je ks ji kt jm ku jq km kn ko kp bi translated">用对抗性网络进行高保真语音合成。<em class="kv"> arXiv预印本arXiv:1909.11646 </em> (2019)。</li></ol></div></div>    
</body>
</html>
<html>
<head>
<title>Apache Spark: Approaches to Debug and Improve Performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark:调试和提高性能的方法</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/apache-spark-performance-tuning-techniques-bad4b0c857c9?source=collection_archive---------3-----------------------#2022-12-29">https://medium.com/mlearning-ai/apache-spark-performance-tuning-techniques-bad4b0c857c9?source=collection_archive---------3-----------------------#2022-12-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/86dd129c0b086d8831866dac3d91c17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BAfcikOFJgBw_dfM"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@krisroller?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kristopher Roller</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="4c53" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h2><p id="2e5f" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">Apache Spark是一个快速的内存数据处理引擎，支持批处理和流处理。它被设计成可伸缩和灵活的，允许您在一个机器集群上运行大规模的数据处理应用程序。</p><p id="7183" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">尽管spark可以处理大规模数据处理，但也存在spark作业因内存问题而出错的情况。以下是spark作业中的一些常见错误。</p><h2 id="362a" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">Spark常见错误</strong></h2><ol class=""><li id="638a" class="ks kt hh ju b jv jw jz ka jf ku jj kv jn kw km kx ky kz la bi translated"><strong class="ju hi">内存不足</strong>:如果Spark试图处理一个大于worker节点上可用内存的数据集，就会出现OOM错误。这可能是由大型输入数据集或需要大量内存来执行的复杂转换造成的。</li><li id="a742" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated"><strong class="ju hi">内存泄漏</strong>:如果Spark应用程序中存在内存泄漏，也会发生OOM错误，内存被分配但没有被正确释放。这可能导致可用内存量随着时间的推移逐渐减少，最终导致OOM错误。</li><li id="7024" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated"><strong class="ju hi">配置不正确</strong>:如果配置不正确，Spark应用程序也会遇到OOM错误。例如，如果Spark执行器或驱动程序的内存分配设置得太低，可能不足以处理数据。</li><li id="4d2f" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated"><strong class="ju hi">资源争用</strong>:如果工作节点上存在对CPU或磁盘IO等资源的争用，也会发生OOM错误，这会导致Spark在等待这些资源变得可用时耗尽内存。</li></ol><h2 id="86ee" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">调试和改进Spark作业的方法</h2><p id="db9f" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">要对Spark中的错误进行故障排除，首先要确定问题的<strong class="ju hi">根本原因，然后实施适当的措施来解决它，例如增加内存分配、优化Spark作业以使用更少的内存，或者确定并修复任何内存泄漏。</strong></p><h2 id="7a1c" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> 1。适当的资源分配</strong>:</h2><p id="f2d9" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">为Spark分配适量的资源，比如内存和CPU，有助于确保应用程序有足够的资源来高效地处理数据。您可以使用<code class="du lg lh li lj b">spark.executor.memory</code>和<code class="du lg lh li lj b">spark.executor.cores</code>配置来控制Spark执行器的资源分配。</p><h2 id="56d1" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> 2。数据分区</strong>:</h2><p id="8daa" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">Spark中的数据分区是将大型数据集划分为可以并行处理的较小分区的过程，从而提高Spark作业的性能和可伸缩性。</p><p id="b34d" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">对数据进行正确的分区有助于确保数据均匀地分布在工作节点上，这可以提高涉及在节点之间转移数据的Spark操作(如连接和聚合)的性能。</p><p id="7f04" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">以下是spark中不同的分区类型。</p><ol class=""><li id="38de" class="ks kt hh ju b jv kn jz ko jf lk jj ll jn lm km kx ky kz la bi translated"><strong class="ju hi">散列分区:</strong>散列分区是一种使用散列函数来确定记录应该被分配到哪个分区的技术。这确保了具有相同哈希值的记录被分配到相同的分区。散列分区有助于在分区之间均匀分布记录，并确保记录被一致地分配给同一个分区。</li><li id="e2d3" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated"><strong class="ju hi">范围分区</strong>:范围分区是一种根据某些关键字段的值将记录分配给分区的技术。这有助于确保将具有相似键值的记录分配到同一个分区，从而提高按这些键值进行筛选或分组的查询和聚合的性能。</li><li id="2962" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated"><strong class="ju hi">自定义分区:</strong>自定义分区是一种允许用户定义自己的分区函数的技术，使他们能够指定如何将记录分配给分区。这有助于实现更复杂的分区方案，而这对于散列或范围分区是不可能的。</li></ol><h2 id="0fce" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> 3。数据持久性</strong>:</h2><p id="f8bb" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">通过避免重复从磁盘读取数据的开销，将数据保存在内存中有助于提高Spark应用程序的性能。您可以使用<code class="du lg lh li lj b">cache()</code>和<code class="du lg lh li lj b">persist()</code>功能将数据存储在内存中，使用<code class="du lg lh li lj b">unpersist()</code>功能将不再需要的数据从内存中删除。</p><p id="aa8e" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">Spark提供一系列存储级别可供选择，包括:</p><ul class=""><li id="2c14" class="ks kt hh ju b jv kn jz ko jf lk jj ll jn lm km ln ky kz la bi translated"><strong class="ju hi"> MEMORY_ONLY </strong>:数据存储在内存中，但不持久存储到磁盘。这是最快的存储级别，但在内存使用方面也是最昂贵的。</li><li id="51f9" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><strong class="ju hi"> MEMORY_AND_DISK </strong>:数据存储在内存中，但是如果数据量超过可用内存，就会溢出到磁盘。这种存储级别在性能和成本之间提供了良好的平衡，因为它允许您将内存用作缓存，同时仍然能够在磁盘上存储大量数据。</li><li id="8576" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><strong class="ju hi"> DISK_ONLY </strong>:数据只存储在磁盘上，不保存在内存中。这是最慢的存储级别，因为每次访问数据时都必须从磁盘中读取。不过从内存使用上来说是性价比最高的。</li><li id="7144" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><strong class="ju hi"> MEMORY_ONLY_SER </strong>:数据以序列化的形式存储在内存中，比原始数据占用的空间少，但访问速度较慢。当您需要在内存中存储大量数据，但没有足够的空间以原始形式存储数据时，此存储级别非常有用。</li><li id="77df" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><strong class="ju hi"> MEMORY_AND_DISK_SER </strong>:数据以序列化的形式存储在内存中，如果数据量超过可用内存，则以序列化的形式溢出到磁盘。这种存储级别类似于MEMORY_AND_DISK，但使用的内存更少，代价是访问速度更慢。</li></ul><h2 id="a52a" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> 4。数据偏斜</strong>:</h2><p id="666f" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">数据不对称，即数据集的某些分区明显大于其他分区，会导致Spark中的性能瓶颈。要解决这个问题，您可以使用数据采样、数据重新平衡或自定义分区等技术，将数据均匀地分布在工作节点上。</p><p id="0a17" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">我在这里创建了一个关于数据偏斜<a class="ae it" rel="noopener" href="/@dishanka/data-skew-101-e5a7bda36f76">的独立帖子。</a></p><h2 id="b64b" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> 5。优化Spark SQL </strong>:</h2><p id="65e0" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">您可以使用谓词下推、列修剪和分区修剪等技术来优化Spark SQL查询的性能。您还可以使用<code class="du lg lh li lj b">EXPLAIN</code>命令来获得查询执行计划的详细分解，并识别任何潜在的优化机会。</p><ol class=""><li id="42bd" class="ks kt hh ju b jv kn jz ko jf lk jj ll jn lm km kx ky kz la bi translated">数据过滤—尽早过滤数据</li><li id="983c" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated">数据分布—将数据均匀分布在所有节点上</li><li id="28b7" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated">连接顺序-连接表的顺序</li><li id="fffa" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated">连接类型—为用例使用正确的连接类型。分类合并，散列和广播。默认为排序合并。</li><li id="177e" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated">避免笛卡尔连接</li><li id="afbe" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated">尽可能避免按顺序排列</li><li id="fbb0" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km kx ky kz la bi translated">使用高效的函数、数据结构</li></ol><h2 id="9097" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">重要的火花配置</h2><ul class=""><li id="fa38" class="ks kt hh ju b jv jw jz ka jf ku jj kv jn kw km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.driver.memory</code>:该配置指定驱动程序进程应该使用的内存量。适当地设置这个值很重要，因为它会影响Spark应用程序的性能。</li><li id="735f" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.executor.memory</code>:这个配置指定了每个执行器应该使用的内存量。适当地设置这个值很重要，因为它会影响Spark应用程序的性能。</li><li id="830a" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.executor.cores</code>:这个配置指定了每个执行器应该使用的内核数量。通过增加内核数量，您可以提高Spark应用程序的并行性。</li><li id="2a0a" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.sql.shuffle.partitions</code>:该配置指定在Spark SQL查询中混排数据时使用的分区数量。增加该值可以让Spark更快地处理数据，但也会增加应用程序的内存和CPU使用率。</li><li id="1296" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.default.parallelism</code>:该配置指定运行Spark操作时应使用的默认并行度。它可以用来控制Spark创建的任务数量，并且可以根据内核数量和您正在处理的数据大小进行设置。</li><li id="ece0" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.serializer</code>:该配置指定了应该用于序列化数据以便存储和传输的序列化库。默认的序列化库是Java序列化，但是您也可以使用其他库，比如Kryo序列化，它在某些情况下会更快更有效。</li><li id="5b21" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.shuffle.service.enabled</code>:该配置指定是否启用用于管理数据混洗的混洗服务。启用shuffle服务可以通过减少网络流量来提高Spark应用程序的性能</li><li id="56db" class="ks kt hh ju b jv lb jz lc jf ld jj le jn lf km ln ky kz la bi translated"><code class="du lg lh li lj b">spark.memory.fraction</code>:这个配置指定了Spark中用于执行和存储的可用内存的比例。它表示为0到1之间的十进制值，可以用来控制Spark中执行和存储之间的平衡</li></ul><h1 id="7674" class="lo iv hh bd iw lp lq lr ja ls lt lu je lv lw lx ji ly lz ma jm mb mc md jq me bi translated">结论</h1><p id="2d93" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km ha bi translated">只要以正确的方式处理配置和资源，Apache spark可以有效地处理大规模数据。小的改变可以带来大的不同。</p><p id="128b" class="pw-post-body-paragraph js jt hh ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km ha bi translated">感谢阅读！</p><div class="mf mg ez fb mh mi"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hi fi z dy mn ea eb mo ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">medium.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw in mi"/></div></div></a></div></div></div>    
</body>
</html>
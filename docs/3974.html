<html>
<head>
<title>Word Processing Approaches— Where Modern NLP Starts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文字处理方法——现代自然语言处理的起点</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/word-processing-approaches-where-modern-nlp-starts-8ccef781d23e?source=collection_archive---------2-----------------------#2022-11-18">https://medium.com/mlearning-ai/word-processing-approaches-where-modern-nlp-starts-8ccef781d23e?source=collection_archive---------2-----------------------#2022-11-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2c65" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我概述了什么是文字处理方法以及当前的技术水平。在深入研究这些方法之前，我先介绍自然语言处理(NLP)和一些重要的任务。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/03ef7583e2c6fd4ed87b6e96f8e85b7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*27xjH78V-m4OuxTr"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kelly Sikkema</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5bce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Natural in <strong class="ig hi">“自然语言处理”</strong>允许我们区分人类语言(如英语或法语)和机器语言(如Python或C++)。现代NLP是数据科学和人工智能领域，它使用文本数据来解决诸如<strong class="ig hi">文本分类</strong>、<strong class="ig hi">语言建模</strong>、<strong class="ig hi">翻译</strong> …</p><p id="2267" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这显然是最难处理的数据之一，因为一个单词、一个句子、一段文字的实际含义……根据句子的上下文，一些单词可能有不同的含义，对于一些语言来说，这种情况会成倍增加。</p><p id="3350" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在现代NLP之前，开始研究文本的工程师们正在寻找一套经典的<strong class="ig hi">规则</strong>来理解任何句子的意思。但是语言并不是可以用<strong class="ig hi"> if/then/else </strong>规则概括的数据，这样做效果不好。</p><blockquote class="jt"><p id="4cc6" class="ju jv hh bd jw jx jy jz ka kb kc jb dx translated">现代NLP是应用于单词、句子、段落的模式识别(用Python深度学习，Franç ois Chollet)。</p></blockquote><p id="4b33" class="pw-post-body-paragraph ie if hh ig b ih kd ij ik il ke in io ip kf ir is it kg iv iw ix kh iz ja jb ha bi translated">这种模式识别是由机器实现的，不是通过编程规则，而是通过使用它们的计算能力。机器通过对训练数据集进行学习来帮助找到语言的含义，以便解决特定的任务。</p><p id="f6ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在深入主要的文本预处理方法之前，让我们了解机器如何处理数据以及NLP中需要的主要任务。</p><h2 id="d532" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">从文本到矢量—文本矢量化</h2><p id="6a2e" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">文本数据不能不加修改就使用，机器必须处理数值，当你给它文本时，数据就丢失了。</p><p id="54f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">文本矢量化</strong>是将文本转化为矢量(数值张量)的过程。它由多项任务组成，每项任务都很重要:<em class="li">文本标准化</em>、<em class="li">文本标记化</em>和<em class="li">文本索引</em>。</p><ol class=""><li id="41c0" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated">文本标准化旨在消除不想要的字符，并转换文本以便于处理。<br/>例如:删除标点符号、特殊字符、重音符号、大写字母……<br/><strong class="ig hi">词干</strong>是一种更高级的标准化，因为它将一个术语的变体转换为其词干，词干是给定单词的基础或词根(<em class="li">【鱼】</em>是<em class="li">【钓鱼】</em>的词干)。</li><li id="e8ad" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">文本记号化</strong>或<strong class="ig hi">拆分</strong>顾名思义，就是将每个单词拆分成记号的过程，记号可以是一个字符、一个单词、一组词。<strong class="ig hi"> N-grams </strong>是一种标记化类型，专注于分裂N长度的单词组:<em class="li">双元是2个单词的组</em>。</li><li id="c204" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">文本索引</strong>包括两个步骤:<br/> -首先，<strong class="ig hi">构建词汇表</strong>，该词汇表是在整个数据集(语料库)中找到的所有术语的索引。<br/> - <strong class="ig hi">为词汇表中的每个术语</strong>分配一个唯一的整数。因此，每个单词都可以用它在词汇表中的索引来代替，这可以被看作是一个巨大的字典。<br/> <strong class="ig hi">不在词汇表中(OOV) </strong>是不存在于词汇表中的术语，通常放在索引1中。<br/> <strong class="ig hi">掩码标记</strong>是词汇自愿忽略的术语，放在索引0中(这一般用来填充过短的序列)。</li></ol><p id="0df5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是对以下句子执行的文本矢量化过程:<em class="li">我是数据科学家，你呢？</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lx"><img src="../Images/364ce65a3008f381614bcc701774d093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsRx_CyuHEaqcneazf_uVA@2x.jpeg"/></div></div></figure><p id="c2b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们知道了如何将文本表示成向量，让我们看看不同的单词预处理方法…</p><h1 id="ac44" class="ly kj hh bd kk lz ma mb ko mc md me ks mf mg mh kv mi mj mk ky ml mm mn lb mo bi translated">词序重要性——词汇预处理模型</h1><p id="bbd5" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">一种语言和另一种语言的词序是不同的，即使在同一种语言中，你也可以改变句子中的词序，同时保持意思不变。</p><p id="0fbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是最常见的单词预处理方法的主要区别:<strong class="ig hi">单词袋模型</strong>与<strong class="ig hi">序列模型</strong>。</p><h2 id="9dfb" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">词汇袋模型</h2><p id="5afc" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">这种方法将文本视为一组无序的单词，不考虑任何顺序。</p><blockquote class="mp mq mr"><p id="4950" class="ie if li ig b ih ii ij ik il im in io ms iq ir is mt iu iv iw mu iy iz ja jb ha bi translated">一个<strong class="ig hi">包</strong>指的是你处理<strong class="ig hi">套令牌</strong>而不是一个<strong class="ig hi">列表</strong>或者<strong class="ig hi">序列</strong>(用Python深度学习)。</p></blockquote><p id="70f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，你可以连接所有的文本，把它们混合在一起，而不会有任何问题。<br/> <strong class="ig hi">字袋</strong>也可以称为<strong class="ig hi">N字袋</strong>，因为它可以将N个字编码为集合。</p><p id="bace" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是这个想法是将整个文本表示为由0和1组成的单一向量，但主要是0，这产生了<strong class="ig hi">稀疏度</strong>。它基本上是一个<strong class="ig hi">巨大的多热点编码</strong>。</p><p id="6817" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那些词预处理的模型已经通过从<strong class="ig hi">添加的信息</strong> <strong class="ig hi">每个词/N元文法的频率</strong>而被<strong class="ig hi">增强</strong>和<strong class="ig hi">改进</strong>。但这还不够，因为有些词毫无意义，在任何文本中都存在:<em class="li"> a </em>，<em class="li"> the </em>，<em class="li">have</em>…这就是<strong class="ig hi"> TF-IDF </strong> <strong class="ig hi">规范化</strong>出现的原因，它可以最大限度地利用词的频率，同时限制无用的词。</p><blockquote class="mp mq mr"><p id="9282" class="ie if li ig b ih ii ij ik il im in io ms iq ir is mt iu iv iw mu iy iz ja jb ha bi translated">TF-IDF代表<strong class="ig hi">词频—逆文档频率</strong></p></blockquote><p id="3db2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在看TF-IDF之前，我们先介绍一下什么是<strong class="ig hi">文档</strong>，什么是<strong class="ig hi">文档集</strong>。文档可以由任意长度的句子或几个句子(一个文本)组成，而语料库是各种文档的集合。例如，语料库可以是几部电影描述的集合。</p><p id="81a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在清楚了，这是TF-IDF的两个术语:</p><ul class=""><li id="203b" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb mv lp lq lr bi translated"><strong class="ig hi">词频</strong>是一个词在特定文档中的计数。</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mw"><img src="../Images/eb6cc21f93f736f7940218b6a7e70a45.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*nHOTjDImd4jsHDUqJYLp7g.png"/></div></figure><ul class=""><li id="74e4" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb mv lp lq lr bi translated"><strong class="ig hi">逆文档频率</strong>是一个单词在整个语料库中至少出现一次的文档数的倒数。</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mx"><img src="../Images/b5ac8a889264401870cf254daad2c61c.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*3mTUJFFSqWN47SBO9R3NWQ.png"/></div></figure><p id="bdc0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<strong class="ig hi"> <em class="li"> N </em> </strong>是语料库中的文档数，分母是术语<strong class="ig hi"><em class="li"/></strong>的<strong class="ig hi">文档频率</strong>。我们添加1以防止被零除的错误，并使用对数来削弱大型语料库的重要性(如果N是10M，文档频率是10，则IDF将是10M/10 = 1M，而使用log将其更改为6)。</p><p id="faa5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es my"><img src="../Images/4b9455abfde8bf2875f053fddc3634f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/0*XZlE1Km_IoKMf0wG.png"/></div></figure><p id="6683" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">TF-IDF允许为文档中的单词提供更多的信息和意义，但并没有改变单词袋模型的原则，即在单词的重要性很强的情况下放弃单词顺序。</p><h2 id="d7c6" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">序列模型</h2><p id="bfad" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">虽然单词袋方法将文本输入表示为唯一的固定表示，但是<strong class="ig hi">序列模型</strong>保留原始单词序列，目的是找到其中的模式。</p><p id="7bda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些是顺序模型的<strong class="ig hi"> 3步</strong>:</p><ol class=""><li id="e653" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated"><strong class="ig hi">文本索引</strong>:序列的每一项由一个整数索引表示。</li><li id="9277" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">文本矢量化</strong>:将每一个整数映射到一个矢量，从而得到矢量序列。</li><li id="0f24" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><strong class="ig hi">将这些矢量序列输入到一堆层中</strong> (RNN，变形金刚)，目的是从这些原始序列中找到模式。</li></ol><p id="cc0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，使用一键编码来表示创建向量并不是最好的方法，因为输入的维数会非常大(词汇表也是如此)。这将导致神经网络的计算缓慢和性能不佳。这就是<strong class="ig hi">单词嵌入</strong>出现并彻底改变单词表示的地方。</p><p id="b26e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">的确，<strong class="ig hi"> <em class="li">单词嵌入</em> </strong> <em class="li">是将人类语言映射到结构化几何空间的单词的向量表示</em> <em class="li">(用Python深度学习)</em>。</p><p id="88ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与将每个单词独立于其他单词并因此独立于正交矢量的独热编码相反，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mz"><img src="../Images/da5a5dd52b9e810ffe47da19cab8daf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qFDf2JOJOY-SUaJZfBGRBA@2x.jpeg"/></div></div></figure><p id="39dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单词嵌入认为两个单词的<strong class="ig hi">几何关系</strong>应该代表它们的<strong class="ig hi">语义关系</strong>通过某种<strong class="ig hi">几何距离</strong>来计算，例如余弦相似度。</p><blockquote class="mp mq mr"><p id="90d0" class="ie if li ig b ih ii ij ik il im in io ms iq ir is mt iu iv iw mu iy iz ja jb ha bi translated">单词嵌入将更多的信息打包到比一热编码少得多的维度中，因为后者是二进制和稀疏向量。</p></blockquote><p id="3403" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单词嵌入的一大优势是<strong class="ig hi">它可以整合信息，因为它从单词的相似性中学习到另一个</strong>(结构化表示)。表示同一事物的两个词应该有相近的向量。</p><p id="9816" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，用车辆词语:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es na"><img src="../Images/4abcb033b30172f34c4093b41a5c148a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*isNzJ6AdnhXykbuFANzHmQ@2x.jpeg"/></div></div></figure><p id="def0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在神经网络中有两种使用单词嵌入的方法:</p><ul class=""><li id="432b" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb mv lp lq lr bi translated">要么<strong class="ig hi">基于你想要完成的任务(文本分类、翻译……)构建你自己的单词嵌入</strong>。</li><li id="5934" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb mv lp lq lr bi translated">或者通过<strong class="ig hi">加载从不同的机器学习任务构建的预训练嵌入</strong>。</li></ul><p id="9c70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">建造自己的房子</strong></p><p id="7b42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">想法是训练一个模型，并添加一个<strong class="ig hi">嵌入层</strong>，该层将调整最初的随机字向量，该向量可以被视为具有反向传播过程的层中的权重。在训练结束时，嵌入表示给定任务的最佳语义关系。</p><p id="94c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">加载预加应力的预埋件</strong></p><p id="4bfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预训练嵌入背后的假设是<strong class="ig hi">将从另一个任务中获得的知识</strong>转移到你自己的任务中。</p><blockquote class="mp mq mr"><p id="795b" class="ie if li ig b ih ii ij ik il im in io ms iq ir is mt iu iv iw mu iy iz ja jb ha bi translated">您期望您需要的特性是相当通用的——通用的语义特性，因此即使预训练的嵌入空间来自不同的问题(使用Python的深度学习)也是有用的。</p></blockquote><p id="38b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那些嵌入的预训练不一定用神经网络来完成，而是特别使用<strong class="ig hi">单词出现统计</strong>。</p><p id="2e25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预训练嵌入的示例:</p><ul class=""><li id="660c" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb mv lp lq lr bi translated"><a class="ae js" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> Word2vec </strong> </a></li><li id="af90" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb mv lp lq lr bi translated"><a class="ae js" href="https://nlp.stanford.edu/projects/glove" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">手套</strong> </a></li><li id="4d9a" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb mv lp lq lr bi translated">来自HuggingFace的<a class="ae js" href="https://huggingface.co/sentence-transformers" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">句子变形金刚库</strong> </a>的任何模型</li></ul><p id="82ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，今天的最佳序列模型是<strong class="ig hi"> Transformers </strong>，一种彻底改变了现代NLP的神经网络架构。</p><h1 id="ab58" class="ly kj hh bd kk lz ma mb ko mc md me ks mf mg mh kv mi mj mk ky ml mm mn lb mo bi translated">结论</h1><p id="dc3e" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated"><strong class="ig hi">现代NLP </strong>代表使用大型文本数据集，以获得有用的模式来解决特定问题。</p><p id="5be0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文本数据需要特殊的<strong class="ig hi">预处理</strong>，因为特征就是单词本身。这一过程从通过移除不想要的字符的<strong class="ig hi">标准化</strong>开始，继续通过分割N元语法的<strong class="ig hi">标记化</strong>，并以将词汇表中的每个单词关联到唯一整数的<strong class="ig hi">索引</strong>结束。</p><p id="e9c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种预处理导致了词序重要性的问题。事实上，可以区分两种方法:<strong class="ig hi">词汇袋</strong>和<strong class="ig hi">序列模型</strong>。后者目前最常用于复杂的NLP任务，因为它认为词序是学习的基础。</p><p id="6232" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢你阅读这篇文章，我希望你喜欢它，现在更好地理解什么是文本/文字预处理！如果你对数据科学和机器学习感兴趣，可以在这里查看我的其他文章<a class="ae js" href="https://www.npogeant.com/#articles" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="7a4b" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">资源</h2><div class="nb nc ez fb nd ne"><a href="https://www.manning.com/books/deep-learning-with-python" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab dw"><div class="ng ab nh cl cj ni"><h2 class="bd hi fi z dy nj ea eb nk ed ef hg bi translated">使用Python进行深度学习</h2><div class="nl l"><h3 class="bd b fi z dy nj ea eb nk ed ef dx translated">Python深度学习介绍了使用Python语言和强大的Keras的深度学习领域</h3></div><div class="nm l"><p class="bd b fp z dy nj ea eb nk ed ef dx translated">www.manning.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns jm ne"/></div></div></a></div><div class="nb nc ez fb nd ne"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nf ab dw"><div class="ng ab nh cl cj ni"><h2 class="bd hi fi z dy nj ea eb nk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nl l"><h3 class="bd b fi z dy nj ea eb nk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nm l"><p class="bd b fp z dy nj ea eb nk ed ef dx translated">medium.com</p></div></div><div class="nn l"><div class="nt l np nq nr nn ns jm ne"/></div></div></a></div></div></div>    
</body>
</html>
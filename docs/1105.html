<html>
<head>
<title>Non-linear Mixed Model in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R中的非线性混合模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/non-linear-mixed-model-in-r-a6fc054c3f82?source=collection_archive---------0-----------------------#2021-10-03">https://medium.com/mlearning-ai/non-linear-mixed-model-in-r-a6fc054c3f82?source=collection_archive---------0-----------------------#2021-10-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f4ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章是关于我如何在2016年使用非线性混合模型(NLMIXED)处理数据集的。我对NLMIXED既爱又恨，因为他们高度的自由，以及建模和统计的完美结合。这些模型不适合胆小的人，因为它们需要干净的数据集和足够的粒度来估计方差分量。</p><p id="622f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据集本身处理的是牛胃里草的降解。在多个时间点，对几个试验和奶牛进行评估，得到一个包含多个水平的嵌套数据集——试验、奶牛、重复。该数据集不是“完整的”数据集，这意味着不是每头奶牛都有相同数量的重复，或者每个试验都有相同数量的奶牛。</p><p id="5495" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码并不是NLMIXED的完美方法。它只强调了我在2016年如何处理数据集，如果我必须重做，我肯定会选择不同的选择。尽管如此，下面显示的代码和示例应该为您提供了一个入门的工具箱。因此，我试图尽可能多地保留当时的原始代码。</p><p id="fd96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最终，建模更多的是基于生物学理解做出科学选择，而不是让统计数据做出所有选择。</p><p id="615d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望这篇文章能让这一点更加清晰。</p><p id="351f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，让我们开始吧，如果你对我为什么和如何做有任何疑问，你知道在哪里可以找到我！</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">First line cleans the environment. The rest are the libraries loaded.</figcaption></figure><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Simple import, unique ID creation, and scatterplot made.</figcaption></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es jn"><img src="../Images/1d0c19864c1e57289b41da8a9d13fc06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wtcmq82va8BwJxGL7tN0lw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Scatterplot of Time by DMres shows the decline in values over time. Data such as this can be approximated by polynomials or spline, but the will have difficulties with the almost full horizontal part at the end of the curve.</figcaption></figure><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Some data wrangling to create additional columns, clean data, create factors etc. The end shows way to plot the data, diving a bit deeper inside its nested structure.</figcaption></figure><p id="3a01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码结果显示了测量的时间点、每个时间点的观察次数、试验次数、试验中的奶牛数量以及每次试验中每头奶牛的观察次数。最后一个表显示了重复。</p><p id="ea1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果不小心的话，嵌套的数据结构会变得难以处理。如果您希望在以后的阶段解释结果，创建唯一的标识符和声音标签结构是关键。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="bf9f" class="jz ka hh jv b fi kb kc l kd ke">&gt; unique(Grass$x)<br/>[1]   0   3   8  16  32  56  96 332 336</span><span id="e99d" class="jz ka hh jv b fi kf kc l kd ke">&gt; table(Grass$x)<br/> 0   3   8   16  32  56  96  332 336 <br/> 56  84  84  87  87  90  96  18  117</span><span id="c722" class="jz ka hh jv b fi kf kc l kd ke">&gt; table(Grass$Trial, Grass$Cow)<br/>             <br/>               1  2  3<br/>  RRC032_09   19 15 15<br/>  RRC032_19   19 15 15<br/>  RRC03201_21 19 15 15<br/>  RRC03201_32 19 15 15<br/>  RRC050_01   19 15 15<br/>  RRCGrass_1  28 24 24<br/>  RRCGrass_2  21 17 17<br/>  RRCGrass_3  19 15 15<br/>  RRCGrass_4  19 15 15<br/>  RRCGrass_5  19 15 15<br/>  RRCGrass_6  38 30 30<br/>  RRCGrass_7  19 15 15<br/>  RRCGrass_8  19 15 15</span><span id="77f8" class="jz ka hh jv b fi kf kc l kd ke">&gt; table(Grass$Trial, Grass$Replicate)<br/>             <br/>               1  2  3  4  5  6<br/>  RRC032_09   22 22  4  1  0  0<br/>  RRC032_19   22 22  4  1  0  0<br/>  RRC03201_21 22 22  4  1  0  0<br/>  RRC03201_32 22 22  4  1  0  0<br/>  RRC050_01   22 22  4  1  0  0<br/>  RRCGrass_1  22 22 13 10  6  3<br/>  RRCGrass_2  22 22 10  1  0  0<br/>  RRCGrass_3  22 22  4  1  0  0<br/>  RRCGrass_4  22 22  4  1  0  0<br/>  RRCGrass_5  22 22  4  1  0  0<br/>  RRCGrass_6  44 44  8  2  0  0<br/>  RRCGrass_7  22 22  4  1  0  0<br/>  RRCGrass_8  22 22  4  1  0  0</span><span id="2773" class="jz ka hh jv b fi kf kc l kd ke">&gt; table(Grass$Cow, Grass$Replicate)<br/>   <br/>      1   2   3   4   5   6<br/>  1 112 112  33  17   2   1<br/>  2  98  98  19   3   2   1<br/>  3  98  98  19   3   2   1</span></pre><div class="jc jd je jf fd ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/3b2456a91caaf72f866d14a03a908958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*-FFoLB69vYhYcVV4FXKeKQ.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/ffb056606d296e357be82fa28363cfe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QjworMBuCtEoIBURkTUqsA.png"/></div></figure></div><div class="ab cb"><figure class="kg jg km ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/ce77d7265f8f7e0531d076b68d505660.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*kV04eiaSI8v6pqn7DkWiCQ.png"/></div></figure><figure class="kg jg kn ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/871b91e6459d75c65f5e52d55aebc714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*0wJmJtA7RCfeEULZUjax3A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx ko di kp kq">Several plots trying to make sense of the data I received, at various levels (Trial, Cow, Replicate).</figcaption></figure></div><p id="f022" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在对数据进行初步探索之后，就是开始建模的时候了。在NLMIXED或NLIN(非线性回归)中，方法非常简单，特别是如果你已经知道要使用的公式。那时候，我从一开始就拿到了配方，这让我的生活轻松了许多。</p><p id="4660" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码显示了该公式在数据集上的适用性。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><div class="jc jd je jf fd ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/ad4c471472b9841fc7c2b8928cac0f8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*adgWjUwpQNXPCneIAmP_Ug.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/bae45726967a2f5cbfda34e02c250033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*R7Y25ZXNoftGWpo1i9Fujw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx kr di ks kq">The plots shows that the formulae definitely makes sense, and that changing some of the values for the coefficients can change the curve quite a bit. The purple lines hint at a common problem in line-plots — if you do not have enough observations within a curve, the lines will not be smooth. Hence, to apply the formula, we cannot venture on a level to deep, otherwise we cannot model the curve due to an absence of observations.</figcaption></figure></div><p id="fb7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码显示了一个NLIN的输出。每个参数的重要性并不有趣。更有趣的是与标准误差相比的值。标准误差最好比估计值小一两个数量级。</p><p id="50a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相关矩阵非常重要。高度相关的值很容易阻止算法收敛。如果相关性很高，一个更简单的公式可能也足够了。你可以看到在U和d。</p><p id="8b59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，但同样重要的是，我应用了折叠刀来迭代地删除观察结果，以评估它们的重要性。这是在最低水平上完成的，并且似乎许多数据点对参数估计有一些影响。</p><p id="b739" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们没有查看这个嵌套数据集中每个级别的重要性，所以我不会根据下面的输出做出任何决定。还没有。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="61c6" class="jz ka hh jv b fi kb kc l kd ke">&gt;nlstools::overview(try)</span><span id="7702" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Formula: y ~ U + D * exp(-(Kd * x))</span><span id="c0d6" class="jz ka hh jv b fi kf kc l kd ke">Parameters:<br/>    Estimate Std. Error t value Pr(&gt;|t|)    <br/>U  2.000e+01  4.738e-01   42.21   &lt;2e-16 ***<br/>D  5.088e+01  6.223e-01   81.77   &lt;2e-16 ***<br/>Kd 2.698e-02  9.069e-04   29.75   &lt;2e-16 ***<br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><span id="b6ec" class="jz ka hh jv b fi kf kc l kd ke">Residual standard error: 5.793 on 634 degrees of freedom</span><span id="0385" class="jz ka hh jv b fi kf kc l kd ke">Number of iterations to convergence: 5 <br/>Achieved convergence tolerance: 3.259e-06</span><span id="a8fb" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Residual sum of squares: 21300</span><span id="1cea" class="jz ka hh jv b fi kf kc l kd ke">------<br/>t-based confidence interval:<br/>          2.5%       97.5%<br/>U  19.07080923 20.93167944<br/>D  49.66065888 52.10463568<br/>Kd  0.02520037  0.02876208</span><span id="a2b4" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Correlation matrix:<br/>            U           D          Kd<br/>U   1.0000000 -0.62690611  0.63539027<br/>D  -0.6269061  1.00000000 -0.04101318<br/>Kd  0.6353903 -0.04101318  1.00000000</span><span id="c2ed" class="jz ka hh jv b fi kf kc l kd ke">&gt;confint(try)<br/>Waiting for profiling to be done...<br/>          2.5%      97.5%<br/>U  19.03739598 20.9534555<br/>D  49.66056255 52.1048493<br/>Kd  0.02514392  0.0289665</span><span id="0e5d" class="jz ka hh jv b fi kf kc l kd ke">&gt; summary(try.jack)<br/>------<br/>Jackknife statistics<br/>     Estimates          Bias<br/>U  20.02060949 -1.936516e-02<br/>D  50.87891113  3.736147e-03<br/>Kd  0.02701635 -3.512655e-05</span><span id="2aaf" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Jackknife confidence intervals<br/>           Low          Up<br/>U  19.20385608 20.83736290<br/>D  49.75286614 52.00495612<br/>Kd  0.02500967  0.02902303</span></pre><div class="jc jd je jf fd ab cb"><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/bf2401bfe5da986c6a735185827a1dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*9fxWmJLV4MabwgWMrXUELg.png"/></div></figure><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/89926b1665ed858d62f3910f8995efa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*BgCXnGggDiuUizBrWyOqkQ.png"/></div></figure><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/9b0a2c790bf456a5a85a0e65e95810f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qtyRBT-vgz4nBfQfA627cg.png"/></div></figure></div><div class="ab cb"><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/acd713310c14eae39e1c7b50e7eb0f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*P9qOieTxDU51fDw94TzgIg.png"/></div></figure><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/cd6253d4b05300dc6b961638e33d614f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Po79wUqFcT4nZ5F9AflBsg.png"/></div></figure><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/01b1e5a8a2982ad3f133c52b818a5312.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ioE47-xm5823aEE8ehlluQ.png"/></div></figure></div><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es ku"><img src="../Images/4351026a4e330e1bcdbef2f7af1b9814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nZGDOkrdjtrdPlCgfGv2Dw.png"/></div></div></figure><p id="755e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从发给我代码的研究员那里，我知道有一个标识变量，我可能需要用它来分割参数估计。这个变量叫做‘标准’。“样本”被包括在后来的模型中，并与一个更简单的模型进行比较，以查看其对解释方差的潜在影响。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="f011" class="jz ka hh jv b fi kb kc l kd ke">&gt; F.value; P.value # For sure indication to use grouping functions<br/>[1] 52.7006<br/>[1] 2.088696e-30</span></pre><p id="6b5a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">毫无疑问，上面的输出表明，添加标识变量确实可以解释方差。多少和在哪里我还不知道，但我需要把它考虑进去。我将在下面的代码中探索更多。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">A model with no identification variable, a second model which will split all three parameters by use of the identification variable, and a third model which will try two provide two estimates for K and D, and a single estimate for Kd. After that, code follows to compare the models by lookin at residuals.</figcaption></figure><p id="be61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的输出来自第三个模型——分别是K和D的两个参数，以及Kd的一个估计值。估计值和标准误差显示了首选的数量级，U (U1对U2)和D (D1对D2)的不同估计值确实暗示了必要的拆分。置信区间和相关矩阵看起来不错。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="ffa2" class="jz ka hh jv b fi kb kc l kd ke">&gt; nlstools::overview(try3) # shows t-based confidence intervals</span><span id="ef49" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Formula: y ~ f1(x, U[Standard.sample2], D[Standard.sample2], Kd)</span><span id="2a4c" class="jz ka hh jv b fi kf kc l kd ke">Parameters:<br/>    Estimate Std. Error t value Pr(&gt;|t|)    <br/>U1 21.795971   0.550592   39.59   &lt;2e-16 ***<br/>U2 18.400811   0.522118   35.24   &lt;2e-16 ***<br/>D1 53.177046   0.833959   63.77   &lt;2e-16 ***<br/>D2 49.618981   0.751888   65.99   &lt;2e-16 ***<br/>Kd  0.027218   0.000815   33.40   &lt;2e-16 ***<br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><span id="c51a" class="jz ka hh jv b fi kf kc l kd ke">Residual standard error: 5.195 on 632 degrees of freedom</span><span id="23f1" class="jz ka hh jv b fi kf kc l kd ke">Number of iterations to convergence: 5 <br/>Achieved convergence tolerance: 3.143e-06</span><span id="b986" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Residual sum of squares: 17100</span><span id="c668" class="jz ka hh jv b fi kf kc l kd ke">------<br/>t-based confidence interval:<br/>          2.5%       97.5%<br/>U1 20.71476007 22.87718125<br/>U2 17.37551456 19.42610814<br/>D1 51.53937899 54.81471275<br/>D2 48.14247924 51.09548309<br/>Kd  0.02561791  0.02881864</span><span id="ecd7" class="jz ka hh jv b fi kf kc l kd ke">------<br/>Correlation matrix:<br/>            U1          U2           D1           D2          Kd<br/>U1  1.00000000  0.25297211 -0.667137685 -0.019617333  0.50571390<br/>U2  0.25297211  1.00000000 -0.005825520 -0.700438348  0.50022772<br/>D1 -0.66713769 -0.00582552  1.000000000  0.000451754 -0.01164574<br/>D2 -0.01961733 -0.70043835  0.000451754  1.000000000 -0.03879137<br/>Kd  0.50571390  0.50022772 -0.011645737 -0.038791366  1.00000000</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es jn"><img src="../Images/b8971d96f3e71e6f63a668fa850c900e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G8sUd21_ESzdiwMLaf-B5w.png"/></div></div></figure><div class="jc jd je jf fd ab cb"><figure class="kg jg kv ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/60e998a81aae7cfae30afc1bea96b6ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*_NM3ksDdqqUhhn4TioHV-w.png"/></div></figure><figure class="kg jg kw ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/09eca45395cfd3e8b86f590cd6b9f093.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*_8KhMSSlqxR445TCASNayw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx kx di ky kq">Residuals of all three models look good. The plot bottom right also shows the autocorrelation of the residuals coming from model 3. Do remember that models looking into time have correlated errors, since part of their future values can be predicted by their past values. The slight diagonal slope does seem to hint at autocorrelation.</figcaption></figure></div><p id="bd9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管残差图可以很好地观察模型的假设是否得到满足，包括方差分量是独立同分布的随机变量，但更严格的比较必须来自测试，如方差分析或似然比测试(LRT)。这些测试只适用于嵌套模型——新模型需要是以前模型的简化。</p><p id="2df9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型2是最大的模型，参数最多。然后遵循模型3，最简单的模型是模型1。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="95d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的结果表明模型2比模型1好，但是模型3并不比模型2好。因此，我们应该坚持使用2，除非有其他事情鼓励我们使用不同的模型。此时此刻，我没有任何理由去假设，所以我坚持模型2。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="451a" class="jz ka hh jv b fi kb kc l kd ke"><br/>&gt; anova(try1,try3,try2) <br/>Analysis of Variance Table</span><span id="b804" class="jz ka hh jv b fi kf kc l kd ke">Model 1: y ~ f1(x, U, D, Kd)<br/>Model 2: y ~ f1(x, U[Standard.sample2], D[Standard.sample2], Kd)<br/>Model 3: y ~ f1(x, U[Standard.sample2], D[Standard.sample2], Kd[Standard.sample2])<br/>  Res.Df Res.Sum Sq Df Sum Sq F value Pr(&gt;F)    <br/>1    634      21275                             <br/>2    632      17054  2 4220.8 78.2079 &lt;2e-16 ***<br/>3    631      17013  1   41.8  1.5498 0.2136    <br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><span id="5899" class="jz ka hh jv b fi kf kc l kd ke">&gt; Q&lt;-(-2)*(logLik(try3)-logLik(try2))<br/>&gt; df.Q&lt;-df.residual(try3)-df.residual(try2)<br/>&gt; 1-pchisq(Q,df.Q)<br/>'log Lik.' 0.2112772 (df=6)</span></pre><p id="fa40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到目前为止，我们已经使用了“原始”数据文件，并进行了一些小的调整。这个<a class="ae kz" href="https://cran.r-project.org/web/packages/nlme/nlme.pdf" rel="noopener ugc nofollow" target="_blank"> nlme </a>包有一段很棒的代码可以让你开始，你可以在下面看到它。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">By using the groupedData code, I specify a dataset and the levels I want. Here, I just used the ID level to provide me with a dataset structured by the ID variable. If I plot the data, as requested here, I expect to see all the data points per ID.</figcaption></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es ku"><img src="../Images/6adae77a84f3080b55ec96a6f6c140ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6t4kaPtlaTutzozS4siXg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">As I expected, a plot showing curved for each ID. Not all of them have complete data. Hence, should I want to create a NLMIXED model at this level, I am not too sure the algorithm would converge.</figcaption></figure><p id="89f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们使用完整的NLMIXED模型之前，nlme包有一个中间步骤，您不必采取这个步骤。这可能会让你的生活更轻松，因为为一个生物公式找到正确的系数并不总是那么简单。</p><p id="e5d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该函数名为nlsList，正如您在下面看到的，它将使用U1、U2、D1、D2和Kd的初始值，尝试在刚刚创建的嵌套数据集上拟合非线性模型。代码的其余部分将让你深入了解固定的和随机的效果。请记住，每个试验或试验中嵌套的每头奶牛的参数估计值不同，这是需要包含在NLMIXED模型中的随机成分的提示。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><div class="jc jd je jf fd ab cb"><figure class="kg jg la ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/9026a9bfffb1ee87d605f6c171927eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*u9PTv28l9-l_cW5aeHg1pg.png"/></div></figure><figure class="kg jg lb ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/5d86591d33db35e8835c2bc060673a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*VOkz6K3xexJLktWnviKJaw.png"/></div></figure><figure class="kg jg la ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/91f50b85871c8356fe756d1442996e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*-GFj4HrMgo2zJoDIhG_GDw.png"/></div></figure></div><div class="ab cb"><figure class="kg jg la ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/92d3a4a777626c137f7a6a93156a2f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*jy2jnNlcX-8b23sIH_Kt6Q.png"/></div></figure><figure class="kg jg la ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/8eccc253a3013e156aef57df3bcde6ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*L5otRoGfgdQIvsLQyMB67w.png"/></div></figure><figure class="kg jg lb ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/2aa59cfeb9d59839c27b8efc1c80428a.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*2HyTDqKEOxyAduSa4C0lfg.png"/></div></figure></div><div class="ab cb"><figure class="kg jg lc ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/c57f18cc0ef1a10b5595be09b71a4b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*4nrvNevTED8LbcrieKMOeA.png"/></div></figure><figure class="kg jg ld ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/cc676ab878651b0b6c4ad6589acfb236.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*m4d0Fb_4hVoMj0YLpTjzBw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx le di lf kq">The nlme package is a powerhouse when it comes to output, but it is not just to please you visually. Most of the time, you really need it to see if the parameter estimates make sense, if they vary per level and if they are correlated.</figcaption></figure></div><p id="3974" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们开始真正的东西，并应用一个NLMIXED。为此，我们创建了一个完全嵌套的数据集，使用Trial、Cow和Id作为级别标识符。我们还包含了Standard.sample2标识符变量来分割K、D和/或Kd的估计值。</p><p id="e3cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">nlme公式看起来很复杂，但是很简单。在代码中，我指定了以下内容:</p><ol class=""><li id="342a" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">应用于数据的公式。</li><li id="62a6" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">U基于标准样本2 +试验标识符的固定效果。对于D和Kd，我估计单个参数。</li><li id="586e" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">我估计了U和d的一个随机分量，这意味着我希望在各个级别上有足够的粒度来构建U和d的方差分量。</li></ol><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="e1a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码很难理解。首先也是最重要的是我收到的警告，模型没有收敛，这意味着我获得的所有结果都不可信——模型对数据来说太多了。尽管如此，输出如下，在这里您可以确切地看到我上面指定的内容就是我收到的内容:</p><ol class=""><li id="9c2b" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">Standard.sample2 +试验的独立U参数及其相关性。请记住，这些是虚拟变量——标准样品2[1]和试验13是参照方。</li><li id="6281" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">全局D和Kd参数。</li><li id="027c" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">U和D的方差分量及其相关性。</li></ol><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="af5e" class="jz ka hh jv b fi kb kc l kd ke">Warning message:<br/>In nlme.formula(y ~ U + D * exp(-(Kd * x)), data = Grass_new, fixed = list(U ~  :<br/>  Iteration 1, LME step: nlminb() did not converge (code = 1). Do increase 'msMaxIter'!<br/>&gt; summary(fit)<br/>Nonlinear mixed-effects model fit by maximum likelihood<br/>  Model: y ~ U + D * exp(-(Kd * x)) <br/>  Data: Grass_new <br/>      AIC      BIC   logLik<br/>  3196.82 3309.578 -1572.41</span><span id="3fbd" class="jz ka hh jv b fi kf kc l kd ke">Random effects:<br/> Formula: list(U ~ 1, D ~ 1)<br/> Level: Trial<br/> Structure: General positive-definite, Log-Cholesky parametrization<br/>              StdDev   Corr  <br/>U.(Intercept) 1.892197 U.(In)<br/>D             3.004500 -1</span><span id="f567" class="jz ka hh jv b fi kf kc l kd ke">Formula: list(U ~ 1, D ~ 1)<br/> Level: Code %in% Trial<br/> Structure: General positive-definite, Log-Cholesky parametrization<br/>              StdDev   Corr  <br/>U.(Intercept) 3.164850 U.(In)<br/>D             4.601667 -1</span><span id="69be" class="jz ka hh jv b fi kf kc l kd ke">Formula: list(U ~ 1, D ~ 1)<br/> Level: id %in% Code %in% Trial<br/> Structure: General positive-definite, Log-Cholesky parametrization<br/>              StdDev        Corr  <br/>U.(Intercept) 3.102183e-100 U.(In)<br/>D             4.042386e-101 0     <br/>Residual       3.674515e+00</span><span id="7136" class="jz ka hh jv b fi kf kc l kd ke">Fixed effects:  list(U ~ Standard.sample2 + Trial, D + Kd ~ 1) <br/>                       Value Std.Error  DF  t-value p-value<br/>U.(Intercept)       25.22320 1.0079186 459 25.02503  0.0000<br/>U.Standard.sample22 -8.93781 1.0017410 459 -8.92227  0.0000<br/>U.Trial1             0.16555 0.7802254 459  0.21219  0.8321<br/>U.Trial2             3.42710 0.7671317 459  4.46742  0.0000<br/>U.Trial3             4.70411 0.7683217 459  6.12258  0.0000<br/>U.Trial4            -6.54268 0.8033764 459 -8.14397  0.0000<br/>U.Trial5            -1.06034 0.7508373 459 -1.41220  0.1586<br/>U.Trial6            -5.23902 0.8173058 459 -6.41010  0.0000<br/>U.Trial7             0.01426 0.8494760 459  0.01679  0.9866<br/>U.Trial8            -3.05043 0.8723032 459 -3.49698  0.0005<br/>U.Trial9            -0.38279 0.8536689 459 -0.44841  0.6541<br/>U.Trial10           -2.57297 0.8854630 459 -2.90579  0.0038<br/>U.Trial11            1.92660 0.4964003 459  3.88114  0.0001<br/>U.Trial12            2.99829 0.7576033 459  3.95760  0.0001<br/>D                   49.94279 1.2116216 459 41.21979  0.0000<br/>Kd                   0.02701 0.0006590 459 40.99312  0.0000<br/> Correlation: <br/>                    U.(In) U.S.22 U.Trl1 U.Trl2 U.Trl3 U.Trl4 U.Trl5 U.Trl6 U.Trl7 U.Trl8 U.Trl9 U.Tr10 U.Tr11 U.Tr12 D     <br/>U.Standard.sample22 -0.581                                                                                                  <br/>U.Trial1             0.308 -0.540                                                                                           <br/>U.Trial2             0.324 -0.549  0.234                                                                                    <br/>U.Trial3             0.308 -0.547  0.232  0.239                                                                             <br/>U.Trial4             0.298 -0.523  0.214  0.221  0.221                                                                      <br/>U.Trial5             0.335 -0.562  0.243  0.251  0.248  0.229                                                               <br/>U.Trial6            -0.422  0.710 -0.431 -0.436 -0.434 -0.423 -0.442                                                        <br/>U.Trial7            -0.388  0.682 -0.422 -0.426 -0.426 -0.414 -0.431  0.447                                                 <br/>U.Trial8            -0.380  0.665 -0.416 -0.420 -0.420 -0.409 -0.426  0.431  0.407                                          <br/>U.Trial9            -0.402  0.681 -0.421 -0.426 -0.423 -0.412 -0.433  0.446  0.420  0.405                                   <br/>U.Trial10           -0.370  0.655 -0.413 -0.417 -0.417 -0.406 -0.422  0.421  0.399  0.384  0.396                            <br/>U.Trial11           -0.071  0.093 -0.108 -0.105 -0.106 -0.114 -0.100  0.033  0.020  0.011  0.018  0.007                     <br/>U.Trial12            0.317 -0.555  0.239  0.246  0.245  0.226  0.255 -0.438 -0.429 -0.423 -0.428 -0.420 -0.103              <br/>D                   -0.760 -0.004  0.013 -0.002  0.006  0.010  0.000 -0.002 -0.007  0.000 -0.001 -0.003 -0.010  0.005       <br/>Kd                   0.262 -0.036  0.014  0.021 -0.018 -0.016  0.057 -0.031  0.006 -0.002 -0.046  0.000  0.011  0.003 -0.025</span><span id="3b32" class="jz ka hh jv b fi kf kc l kd ke">Standardized Within-Group Residuals:<br/>        Min          Q1         Med          Q3         Max <br/>-3.23305944 -0.61215325 -0.04371685  0.59392080  5.44906014</span><span id="1edc" class="jz ka hh jv b fi kf kc l kd ke">Number of Observations: 565<br/>Number of Groups: <br/>                  Trial         Code %in% Trial id %in% Code %in% Trial <br/>                     13                      42                      91</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es lu"><img src="../Images/fadf6972fc4549fbd0d78a1a3261f2b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4_Gf5tf1QPOTOLSigjZS_g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">The beautiful graph showing you if the model predictions for the various levels actually make sense. You can clearly see that predicting for all three levels — Trial, Code, ID — is simply too much based on the granularity and hierarchy of the data.</figcaption></figure><p id="f01f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的输出显示，基于数据的粒度和层次结构对所有三个级别进行估计太多了。因此，我们需要创建额外的模型，看看我们能做什么，不能做什么。这就是事情变得非常混乱的地方，因为NLMIXED允许您做出如此多的选择。</p><p id="f48c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，您可以更改数据集的层次结构。你可以改变生物配方。固定效果。随机效应。它们之间的相互关系。估算方法。协变量。你说吧。</p><p id="470e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，下面的例子肯定不是应该如何做的完美例子，但如果它们给你一个复杂性的暗示，我就非常满意了。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Above, you see several models with changing levels of structures.</figcaption></figure><div class="jc jd je jf fd ab cb"><figure class="kg jg lv ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/b7a33eca04f39dcd96a738c11d270df1.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*OCqaJ9KAlmR9zIBJt6_jfg.png"/></div></figure><figure class="kg jg lw ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/cc81bcb62f164a07e8af969fbd727975.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*8CwisF_lHgmhaf_jK41iJA.png"/></div></figure><figure class="kg jg lw ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/8ec4cb0111f31d5e8ed37d5d06092704.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*atyZl1E5VZrQkSyRw9g-DQ.png"/></div></figure></div><div class="ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/ffc6996fee42f4c19926dd5e997f646d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*XFJO5jSeiVaB6hr_rX53yw.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/5167638174dcf5e3a8629888dc22cfe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*Hc4UbbEqmXsptOBg8UufVQ.png"/></div></figure></div><div class="ab cb"><figure class="kg jg lx ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/e6e757b04de21cf0be2e6011956d362d.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*_1CpWQjnT6ilAKZAMR71tQ.png"/></div></figure><figure class="kg jg ly ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/360d7c7609a4c90a557fe431ed551859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*QecsAvNiSifj6eUcSZNE1Q.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx lz di ma kq">The output from the codes above showing you if it makes sense to limit predictions at a certain levels, make distinctions between levels, estimate parameters separately, and how the predictions hold up in terms of autocorrelation and level.</figcaption></figure></div><p id="a283" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，如果我一直都是错的，并且不需要混合呢？没有人从一开始就说试验中的奶牛真的表现出那么大的方差，它保证了方差分量的估计。也许，使用一个NLIN就足够了。此外，NLIN模型也可以在不同的水平上提供不同的估计。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Code to create a dataframe with a single hierarchy — trial — and to provide estimates from both a NLIN and NLMIXED model.</figcaption></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es jn"><img src="../Images/2c187d013f6eed7f63f9b965707f92eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sfy_iHrKUGljq2g6szp_Hw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">I can’t say that a NLMIXED is really that much better than a NLIN model on the trial level.</figcaption></figure><p id="7575" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码显示了U、D和Kd在试验水平上的系数。我们期望Kd有相同的估计，因为我们没有指定随机成分。虽然输出似乎暗示了每次试验U和D的不同估计值，以及方差分量的存在，但我们也需要看看置信水平。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="4d30" class="jz ka hh jv b fi kb kc l kd ke">&gt; coef(nlmixed, level=1)<br/>                   U        D         Kd<br/>RRC03201_32 12.93202 45.52694 0.02690547<br/>RRC050_01   12.79088 53.59955 0.02690547<br/>RRC032_09   18.86513 46.48913 0.02690547<br/>RRCGrass_1  20.67794 48.87412 0.02690547<br/>RRCGrass_7  21.24971 47.01689 0.02690547<br/>RRC032_19   18.74008 51.44783 0.02690547<br/>RRC03201_21 24.14823 45.37416 0.02690547<br/>RRCGrass_3  20.27294 52.69700 0.02690547<br/>RRCGrass_5  20.16830 53.51800 0.02690547<br/>RRCGrass_6  20.17919 53.24526 0.02690547<br/>RRCGrass_2  22.79165 53.48099 0.02690547<br/>RRCGrass_8  20.62042 51.72504 0.02690547<br/>RRCGrass_4  26.84359 46.74550 0.02690547</span></pre><p id="f94a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，在试验水平上似乎有足够的差异。现在，让我们也包括代码(Cow)级别，向数据帧的层次结构添加第二个级别。然后我们来看看标准的影响。样本2标识符也是模型7中的协变量，但不是模型6中的协变量。</p><p id="518d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这两个模型通过图表和方差分析进行比较。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="0427" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">方差分析表明，模型7比模型6更适合，这与我们在以前的模型中看到的一致——标准。样本2为U和d的单独估计提供了良好的分割。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="4f9e" class="jz ka hh jv b fi kb kc l kd ke">anova(fit6, fit7)<br/>     Model df      AIC      BIC    logLik   Test L.Ratio p-value<br/>fit6     1  8 3271.749 3306.401 -1627.874                       <br/>fit7     2 11 3267.777 3315.365 -1622.889 1 vs 2 9.97115  0.0188</span></pre><div class="jc jd je jf fd ab cb"><figure class="kg jg mb ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/b986a2619b00327af5e2fe0e61cc1fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*-y51O2-kUGHpFyDDgvIo6g.png"/></div></figure><figure class="kg jg mc ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/e282dc0af2015899ccb431eca2202337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_j8AgM5X-dODOdWlb9as4A.png"/></div></figure></div><div class="ab cb"><figure class="kg jg mc ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/e54c283503af9076d6b466474b8b55a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SS_JwYfOTj30vXeDEEq7tw.png"/></div></figure><figure class="kg jg mb ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/d1f310afc12c8dcddbbf78e1b93b4683.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*IN7LPdb9QmQ_ns8eGw2gNQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx md di me kq">Plots to compare random effect estimates and residuals for each of the two models.</figcaption></figure></div><p id="f4fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如我所说，在nlme中可以实现的建模选择非常广泛。例如，如果我们知道标准。样本2对固定参数估计有如此大的影响，也许它们也可以用来分离随机效应。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="e0fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的结果是模型结果与方差分析比较结果不一致的一个很好的例子。在这里，模型8似乎同意基于标准的独立的固定和随机效应。Samppl2，但是ANOVA比较不同意。模型8中增加的系数不足以取代模型7。</p><p id="be43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是你的选择。记住:生物学应该压倒统计学。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="e3f9" class="jz ka hh jv b fi kb kc l kd ke">&gt; summary(fit8)<br/>Nonlinear mixed-effects model fit by REML<br/>  Model: y ~ U + D * exp(-(Kd * x)) <br/>  Data: Grass_new <br/>       AIC      BIC    logLik<br/>  3269.692 3321.606 -1622.846</span><span id="3710" class="jz ka hh jv b fi kf kc l kd ke">Random effects:<br/> Formula: list(U ~ 1, D ~ 1)<br/> Level: Trial<br/> Structure: Diagonal<br/>        U.(Intercept) D.(Intercept)<br/>StdDev:      3.279933      3.411419</span><span id="cf9e" class="jz ka hh jv b fi kf kc l kd ke">Formula: list(U ~ 1, D ~ 1)<br/> Level: Code %in% Trial<br/> Structure: Diagonal<br/>        U.(Intercept) D.(Intercept) Residual<br/>StdDev:      1.735127      1.932955 3.849455</span><span id="a070" class="jz ka hh jv b fi kf kc l kd ke">Variance function:<br/> Structure: Different standard deviations per stratum<br/> Formula: ~1 | Standard.sample2 <br/> Parameter estimates:<br/>        2         1 <br/>1.0000000 0.9811761 <br/>Fixed effects:  list(U + D + Kd ~ Standard.sample2) <br/>                        Value Std.Error  DF  t-value p-value<br/>U.(Intercept)        22.14817 1.3570340 518 16.32101  0.0000<br/>U.Standard.sample22  -3.53108 1.5599922 518 -2.26353  0.0240<br/>D.(Intercept)        52.85253 1.5240713 518 34.67851  0.0000<br/>D.Standard.sample22  -5.03140 1.8385784 518 -2.73657  0.0064<br/>Kd.(Intercept)        0.02619 0.0009255 518 28.30060  0.0000<br/>Kd.Standard.sample22  0.00147 0.0013496 518  1.08627  0.2779<br/> Correlation: <br/>                     U.(In) U.S.22 D.(In) D.S.22 Kd.(I)<br/>U.Standard.sample22  -0.658                            <br/>D.(Intercept)        -0.190  0.208                     <br/>D.Standard.sample22   0.200 -0.307 -0.691              <br/>Kd.(Intercept)        0.284 -0.255 -0.031  0.031       <br/>Kd.Standard.sample22 -0.195  0.335  0.022 -0.038 -0.686</span><span id="377a" class="jz ka hh jv b fi kf kc l kd ke">Standardized Within-Group Residuals:<br/>        Min          Q1         Med          Q3         Max <br/>-3.13244980 -0.56706124 -0.07313164  0.60639687  4.99330842</span><span id="b138" class="jz ka hh jv b fi kf kc l kd ke">Number of Observations: 565<br/>Number of Groups: <br/>          Trial Code %in% Trial <br/>             13              42</span><span id="6983" class="jz ka hh jv b fi kf kc l kd ke">&gt; intervals(fit8)<br/>Approximate 95% confidence intervals</span><span id="6f56" class="jz ka hh jv b fi kf kc l kd ke">Fixed effects:<br/>                            lower        est.        upper<br/>U.(Intercept)        19.482200208 22.14816698 24.814133760<br/>U.Standard.sample22  -6.595773437 -3.53108429 -0.466395152<br/>D.(Intercept)        49.858406050 52.85252669 55.846647332<br/>D.Standard.sample22  -8.643391412 -5.03140445 -1.419417491<br/>Kd.(Intercept)        0.024374038  0.02619223  0.028010432<br/>Kd.Standard.sample22 -0.001185351  0.00146604  0.004117431<br/>attr(,"label")<br/>[1] "Fixed effects:"</span><span id="c3b3" class="jz ka hh jv b fi kf kc l kd ke">Random Effects:<br/>  Level: Trial <br/>                     lower     est.    upper<br/>sd(U.(Intercept)) 2.067949 3.279933 5.202236<br/>sd(D.(Intercept)) 1.928149 3.411419 6.035728<br/>  Level: Code <br/>                      lower     est.    upper<br/>sd(U.(Intercept)) 0.9792957 1.735127 3.074316<br/>sd(D.(Intercept)) 0.6644724 1.932955 5.622983</span><span id="18de" class="jz ka hh jv b fi kf kc l kd ke">Variance function:<br/>      lower      est.   upper<br/>1 0.8673578 0.9811761 1.10993<br/>attr(,"label")<br/>[1] "Variance function:"</span><span id="1aa8" class="jz ka hh jv b fi kf kc l kd ke">Within-group standard error:<br/>   lower     est.    upper <br/>3.513017 3.849455 4.218114</span><span id="8622" class="jz ka hh jv b fi kf kc l kd ke">&gt; anova(fit7, fit8)<br/>Model df      AIC      BIC    logLik   Test    L.Ratio p-value<br/>fit7     1 11 3267.777 3315.365 -1622.889                          <br/>fit8     2 12 3269.692 3321.606 -1622.846 1 vs 2 0.08556909  0.7699</span></pre><p id="9711" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到目前为止，模型诊断在混合模型中的重要性应该变得非常清楚了。以下是一些关于如何使用新数据框架和新模型进行诊断的附加代码。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="b116" class="jz ka hh jv b fi kb kc l kd ke">&gt; fixed.effects((try.nlm1))<br/>          U           D          Kd <br/>20.00529999 49.90397194  0.02673931</span><span id="d120" class="jz ka hh jv b fi kf kc l kd ke">&gt; random.effects(try.nlm1)[1] <br/>$Trial<br/>                     U          D<br/>RRC032_09   -1.6493250 -2.3858655<br/>RRC032_19   -0.8960877  0.8824592<br/>RRC03201_21  2.7903606 -2.7772807<br/>RRC03201_32 -7.0503852 -3.2073010<br/>RRC050_01   -5.6763221  1.5427231<br/>RRCGrass_1   0.4484500 -0.5504275<br/>RRCGrass_2   3.1739196  2.1773564<br/>RRCGrass_3   0.7271474  1.6375856<br/>RRCGrass_4   5.3659893 -1.3561530<br/>RRCGrass_5   0.6897547  2.2731617<br/>RRCGrass_6   0.4170218  2.5908224<br/>RRCGrass_7   0.5737690 -1.7102218<br/>RRCGrass_8   1.0857076  0.8831412</span><span id="337d" class="jz ka hh jv b fi kf kc l kd ke">&gt; random.effects(try.nlm1)[2] <br/>$Code<br/>                                          U          D<br/>RRC032_09/RRC032_09_GS106_1     -1.10425606  1.4702397<br/>RRC032_09/RRC032_09_GS106_2     -1.57153189  1.0192723<br/>RRC032_09/RRC032_09_GS106_3      4.60458821 -7.4116499<br/>RRC032_19/RRC032_19_GS130_1     -2.45883690  2.4955908<br/>RRC032_19/RRC032_19_GS130_2      0.80465687 -1.8950342<br/>RRC032_19/RRC032_19_GS130_3     -0.07696925  2.2397417<br/>RRC03201_21/RRC03201_21_GS138_1 -2.48592971  2.9886320<br/>RRC03201_21/RRC03201_21_GS138_2  2.75677370 -6.0731752<br/>RRC03201_21/RRC03201_21_GS138_3  5.15729386 -5.8342753<br/>RRC03201_32/RRC03201_32_GS155_1 -2.52723529  4.9529592<br/>RRC03201_32/RRC03201_32_GS155_2  1.22063630 -2.3650206<br/>RRC03201_32/RRC03201_32_GS155_3  0.63348664 -5.9323153<br/>RRC050_01/RRC050_01_GS112_1     -1.45661716  4.0358327<br/>RRC050_01/RRC050_01_GS112_2     -4.07692455  5.2180634<br/>RRC050_01/RRC050_01_GS112_3     -0.26999920 -1.5058615<br/>RRCGrass_1/RRCGrass_1_GS1_1     -0.90101393  0.3028745<br/>RRCGrass_1/RRCGrass_1_GS1_2     -2.39299384  3.3087425<br/>RRCGrass_1/RRCGrass_1_GS1_3      4.29914514 -5.3084310<br/>RRCGrass_2/RRCGrass_2_GS15.1_1  -1.28926032  3.2797061<br/>RRCGrass_2/RRCGrass_2_GS15.1_2   0.12781739 -1.2630349<br/>RRCGrass_2/RRCGrass_2_GS15.1_3   0.52883498  1.3454552<br/>RRCGrass_3/RRCGrass_3_GS29.1_1  -0.48599678  1.7132460<br/>RRCGrass_3/RRCGrass_3_GS29.1_2  -2.52273836  2.9726927<br/>RRCGrass_3/RRCGrass_3_GS29.1_3   1.41125955 -1.0333884<br/>RRCGrass_4/RRCGrass_4_GS43.1_1   3.11806239 -5.2087166<br/>RRCGrass_4/RRCGrass_4_GS43.1_2  -4.78566177  5.7951964<br/>RRCGrass_4/RRCGrass_4_GS43.1_3   7.02345554 -7.6521718<br/>RRCGrass_5/RRCGrass_5_GS51_1     0.31579910  0.7231365<br/>RRCGrass_5/RRCGrass_5_GS51_2    -0.33800420  1.2415489<br/>RRCGrass_5/RRCGrass_5_GS51_3    -2.41125298  3.3218839<br/>RRCGrass_6/RRCGrass_6_GS72.1_1   1.28923174  4.5542984<br/>RRCGrass_6/RRCGrass_6_GS72.1_2   1.78072012  3.8145485<br/>RRCGrass_6/RRCGrass_6_GS72.1_3  -0.69812186  3.4100002<br/>RRCGrass_6/RRCGrass_6_GS72.2_1  -1.81333179 -1.6694444<br/>RRCGrass_6/RRCGrass_6_GS72.2_2  -2.52345731 -2.1911771<br/>RRCGrass_6/RRCGrass_6_GS72.2_3  -1.05798988 -1.6429690<br/>RRCGrass_7/RRCGrass_7_GS85_1    -0.90088378 -0.1855209<br/>RRCGrass_7/RRCGrass_7_GS85_2     1.64915908 -3.6659136<br/>RRCGrass_7/RRCGrass_7_GS85_3     1.82093084 -0.8657749<br/>RRCGrass_8/RRCGrass_8_GS99_1    -2.51347082  3.4343488<br/>RRCGrass_8/RRCGrass_8_GS99_2     0.99367907 -1.0729189<br/>RRCGrass_8/RRCGrass_8_GS99_3     1.12694715 -0.8612175</span></pre><div class="jc jd je jf fd ab cb"><figure class="kg jg mf ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/df7920031a57386125d76a7f1917a883.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*-ZE-_ZQJdzg342PcoyrmDw.png"/></div></figure><figure class="kg jg mg ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/a5bb3bdd71c8bea1632f3b2ca800c7d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*sQv0wTGI2gR3Q0Cdcx8B0Q.png"/></div></figure><figure class="kg jg mg ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/2613fc18dfe7ca1b73469776aca3166a.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*hl0F3TKFIHaPPKbf1gxf8g.png"/></div></figure></div><div class="ab cb"><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/9386db7a56cd99e0d9a25612e4100982.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*W9YHYnv0gfdB3EbU1YW9jw.png"/></div></figure><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/f21b67ec224d31d5180f5428598d984c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*tv5K1ZoBBSQu1QC8BqIOkA.png"/></div></figure><figure class="kg jg kt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/0d3bdb62092b9b27cb801a69fe764d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ZgnHdYSJaXVo-Mrr-4Bftg.png"/></div></figure></div><div class="ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/a362efa5a127a4daeb196552db589383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*NwZ3A4ZU1tgW300XqDBBMA.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/23d985959c5f35f2328a4280c6bce3be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*u89xsteGk1_amOllu9DErw.png"/></div></figure></div><div class="ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/f44360de2dc88f5230af78d2e65db4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*2hOt5XurcYpsYMIUMBQMKQ.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/1ebd68bdce89c1446f6d6c841c243d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*t52YjjwH_YVgERYCJebrpg.png"/></div></figure></div><p id="d849" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人们甚至可以通过对模型的误差部分建模来更深入地研究随机效应。这是nlme中的“关联”线，有几个选项可用。</p><p id="b14d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我不得不说，每当有更多的东西被添加到模型中时，如果你幸运的话，以前的选择很容易就过时了。然而，大多数情况下，模型不会收敛或发出警告。这里发生的是后者，但无论如何它提供了输出。</p><p id="deb3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用ARMA技术建模相关性时(AR =自相关，MA =移动平均)，P和Q分别定义AR和MA的参数。不适合胆小的人。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="917c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不能说下面描述的输出和图表说服了我在模型内部实现一个关联结构。话又说回来，我没有包括标准。此处固定效果中的Sample2标识符。这肯定会发挥作用。</p><pre class="jc jd je jf fd ju jv jw jx aw jy bi"><span id="a789" class="jz ka hh jv b fi kb kc l kd ke">&gt; summary(nlm_auto)</span><span id="c758" class="jz ka hh jv b fi kf kc l kd ke">Nonlinear mixed-effects model fit by maximum likelihood<br/>  Model: y ~ U + D * exp(-(Kd * x)) <br/>  Data: Grass_new <br/>     AIC      BIC   logLik<br/>  3368.7 3429.415 -1670.35</span><span id="1203" class="jz ka hh jv b fi kf kc l kd ke">Random effects:<br/> Formula: list(U ~ 1, D ~ 1, Kd ~ 1)<br/> Level: id<br/> Structure: General positive-definite, Log-Cholesky parametrization<br/>         StdDev      Corr         <br/>U        2.540932294 U      D     <br/>D        3.475426888 -0.214       <br/>Kd       0.004192809 -0.953  0.498<br/>Residual 4.064917201</span><span id="bc18" class="jz ka hh jv b fi kf kc l kd ke">Correlation Structure: ARMA(1,3)<br/> Formula: ~1 | id <br/> Parameter estimate(s):<br/>      Phi1     Theta1     Theta2     Theta3 <br/>0.07421349 0.14024498 0.14024498 1.00000000</span><span id="dbdf" class="jz ka hh jv b fi kf kc l kd ke">Fixed effects:  U + D + Kd ~ 1 <br/>      Value Std.Error  DF  t-value p-value<br/>U  19.58990 0.4965723 472 39.45025       0<br/>D  50.43286 0.6703818 472 75.23006       0<br/>Kd  0.02578 0.0008117 472 31.76226       0</span><span id="a400" class="jz ka hh jv b fi kf kc l kd ke">Correlation: <br/>   U       D     <br/>D  -0.521       <br/>Kd  0.120  0.128</span><span id="45bf" class="jz ka hh jv b fi kf kc l kd ke">Standardized Within-Group Residuals:<br/>        Min          Q1         Med          Q3         Max <br/>-3.50473556 -0.54586130 -0.03989232  0.54272121  2.70816333</span><span id="4802" class="jz ka hh jv b fi kf kc l kd ke">Number of Observations: 565<br/>Number of Groups: 91</span></pre><div class="jc jd je jf fd ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/8c98f42660056c92fab74a7d0f745603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*NI1-l2MFaTiZ7pbBDfoOOg.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/05afcd54de2fbd6f2a1f6ab05d1b88e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*z4bCjVGHGwIC-WcPoHQruQ.png"/></div></figure></div><p id="04e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，到了最后一部分——预测！虽然我们展示了很多预测输出(原始预测和残差)，但下一行代码将很好地展示NLMIXED模型可以做什么以及它的用途。如果它能运行。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Code to create a new dataframe with a Trial and Cow-in-Trial hierarchy. Fixed and Random effect estimates are not split. After running the model, we create a new dataset and ask the model to provide predictions for each of the values of x. The plot below shows the results.</figcaption></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es jn"><img src="../Images/88f002c5e371d19f5f137a63d540ae13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q8wuN6ZhkuVzijVpJsxXWQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Looks like the models captures the biological part of the data. However, this pot is nothing fancy. Nested structures are not shown.</figcaption></figure><p id="56ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码使用了一种不同的方法，在原始数据集上应用了带有试验和试验中的母牛随机效应的模型。标准。没有应用Sample2变量，但肯定可以使用。</p><p id="714c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样在这里，必须创建一个新的数据集，这次使用模型的嵌套结构。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><div class="jc jd je jf fd ab cb"><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/8302d6d78c50d2c19e6294ed8cc7b8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5ViiR9QgzB_3ZZKuknt1Hw.png"/></div></figure><figure class="kg jg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/87451de5702c855922bda05741bd79e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Tm0GqVDL4uK1sBDvMrd-RA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx kr di ks kq">The results are beautiful, showing the population mean, trial means, and cow means in the plot to the left. The pot right shows the population mean and trial means, colored differently.</figcaption></figure></div><p id="2703" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这最后两个情节把我带到了这篇文章的结尾。这是一个相当长的旅程，尽管帖子中充满了大量代码和图片，但它仍然只提供了NLMIXED所能做的有限视图。</p><p id="72aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么，你还在等什么？抓住一个数据集，开始自己应用这些知识！我等不及要向你学习了！</p><div class="mh mi ez fb mj mk"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">medium.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my js mk"/></div></div></a></div></div></div>    
</body>
</html>
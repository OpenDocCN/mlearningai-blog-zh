<html>
<head>
<title>Multitask Prompted Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多任务激励学习</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/multitask-prompted-learning-62b87a9b8665?source=collection_archive---------3-----------------------#2022-02-15">https://medium.com/mlearning-ai/multitask-prompted-learning-62b87a9b8665?source=collection_archive---------3-----------------------#2022-02-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="8408" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">训练多大的语言模型？</h2></div><h2 id="d979" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">背景</h2><p id="baa8" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">在现代NLP领域，都是关于迁移学习的。当前基于神经网络的模型的优势是可扩展性，这意味着我们可以简单地在更大的数据集上训练更大的模型。值得庆幸的是，我们有一个成熟的自我监督学习框架，互联网上的文本数据也非常丰富— —例如，通用爬虫<a class="ae kn" href="https://commoncrawl.org/" rel="noopener ugc nofollow" target="_blank">项目</a>每月产生大约20TB的从网页中提取的文本数据。</p><p id="0ee6" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">因此，近年来，自然语言处理研究者们致力于发展迁移学习方法。一切都从这篇论文开始:用统一的文本到文本转换器— <a class="ae kn" href="https://arxiv.org/abs/1910.10683" rel="noopener ugc nofollow" target="_blank">链接</a>探索迁移学习的极限。</p><p id="2553" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">简而言之，它是一个统一的框架，将每个文本处理问题都形成一个“文本到文本”的问题:给定一个文本序列作为输入，模型输出一个文本序列。它允许将相同的模型、目标、训练过程和解码过程应用于每个常见的NLP任务。(包括翻译、问答、分类等)。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es kt"><img src="../Images/d37c4efa60974c04da238e6dd3c7a093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*36i2FGPaux4JIdjDWqli9w.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">T5 stands for “Text To Text Transfer Transformer”, <a class="ae kn" href="https://arxiv.org/pdf/1910.10683.pdf" rel="noopener ugc nofollow" target="_blank">link</a></figcaption></figure><h2 id="d7c2" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">提示</h2><p id="8766" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">T5等文本到文本预训练模型的开发使提示成为多任务学习的一种特别有用的方法。如上所示，我们首先从不同的任务中获取数据集，然后在原始训练集之前添加一些指导性描述。经过预处理的训练数据称为提示。</p><p id="d2d9" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">重要的是输入是人类可读的(！)我们走过了漫长的道路。当前的大型NLP模型像人类一样阅读，像人类一样回答。把预先训练好的大型模型想象成婴儿尤达:它对其包含在模型内部的通用知识是非常强大的W.R.T，但我们不知道在下游任务中什么样的行为(提示)可以触发超能力。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lj"><img src="../Images/6fa2004824027c708b45b0e95457a9b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*OyaMYEUr7ILyj5k54OwQlw.jpeg"/></div><figcaption class="lf lg et er es lh li bd b be z dx">From internet</figcaption></figure><p id="dd6e" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">对于每种数据集(或任务类别)，它选择一个提示模板来将训练数据传输到提示。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lk"><img src="../Images/fe49907fb42033233c3738e1b2e8609d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w6fGv7e7yErJWuxzJL8Xhw.jpeg"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">From paper, <a class="ae kn" href="https://arxiv.org/abs/1910.10683" rel="noopener ugc nofollow" target="_blank">link</a></figcaption></figure><h2 id="7724" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">零镜头文本概括</h2><p id="15cb" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">在前人工作的基础上，论文《多任务提示训练实现零射击任务泛化——<a class="ae kn" href="https://arxiv.org/abs/2110.08207" rel="noopener ugc nofollow" target="_blank">环节</a>》重点研究了在监督和大规模多任务方式下对语言模型的显式训练。它试图回答这两个问题:</p><ol class=""><li id="6ddc" class="ll lm hh jw b jx ko ka kp jh ln jl lo jp lp km lq lr ls lt bi translated">多任务提示训练能提高对看不见的任务的概括吗？</li><li id="8ff9" class="ll lm hh jw b jx lu ka lv jh lw jl lx jp ly km lq lr ls lt bi translated">对更大范围的提示进行训练是否能提高对提示措辞的稳健性？</li></ol><p id="cf9e" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">它以这种方式进行实验:按任务对数据集进行分组，在一些组上进行训练，并在保留的数据集上测试模型。通过确保不发生数据泄漏，它能够测试零镜头泛化的能力。</p><h2 id="ee25" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">什么是“任务”？</h2><blockquote class="lz ma mb"><p id="e47d" class="ju jv mc jw b jx ko ii jz ka kp il kc md kq ke kf me kr kh ki mf ks kk kl km ha bi translated">我们使用术语“任务”来指代由一组特定数据集测试的一般NLP能力。为了评估对新任务的零命中率概括，我们在任务的子集上进行训练，并在坚持的任务组上进行评估。</p><p id="002c" class="ju jv mc jw b jx ko ii jz ka kp il kc md kq ke kf me kr kh ki mf ks kk kl km ha bi translated">— <a class="ae kn" href="https://arxiv.org/pdf/2110.08207.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></p></blockquote><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mg"><img src="../Images/d90317ca37d4b715426e88440beec758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lOzUpZuOP_kxGbOPen8RpA.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx">Yellow datasets are in the training mixture. Green datasets are held out and represent tasks that were not seen during training. Zero-shot task generalization experiments are evaluated on green datasets. — <a class="ae kn" href="https://arxiv.org/pdf/2110.08207.pdf" rel="noopener ugc nofollow" target="_blank">link</a></figcaption></figure><h2 id="b1c1" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">模型培训详细信息</h2><p id="a9fa" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">关键词:编码器-解码器架构/自回归/最大似然训练</p><blockquote class="lz ma mb"><p id="9c79" class="ju jv mc jw b jx ko ii jz ka kp il kc md kq ke kf me kr kh ki mf ks kk kl km ha bi translated">我们训练的所有模型都基于T5，这是一个基于转换器的编码器-解码器语言模型，在来自C4的1T令牌上使用掩蔽语言建模风格的目标进行预训练(<a class="ae kn" href="https://arxiv.org/abs/1910.10683" rel="noopener ugc nofollow" target="_blank"> Raffel等人，2020 </a>)。由于T5的预训练目标包括从已删除的输入文本中填充标记，因此它与我们提示数据集中使用的条件文本生成格式有很大不同。因此，我们使用公开可用的来自<a class="ae kn" href="https://arxiv.org/abs/2104.08691" rel="noopener ugc nofollow" target="_blank"> Lester et al. (2021) </a>的LM适应的T5模型(称为T5+LM)，该模型是通过在标准语言建模目标上在来自C4的100B个附加标记上训练T5而产生的。除非另有说明，否则我们使用具有11B参数的XXL版本。</p></blockquote><p id="0ef5" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">(未完待续)</p><h2 id="1698" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">参考</h2><ul class=""><li id="71ea" class="ll lm hh jw b jx jy ka kb jh mh jl mi jp mj km mk lr ls lt bi translated">用统一的文本到文本转换器探索迁移学习的极限—<a class="ae kn" href="https://arxiv.org/abs/1910.10683" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1910.10683</a></li><li id="78dd" class="ll lm hh jw b jx lu ka lv jh lw jl lx jp ly km mk lr ls lt bi translated">多任务提示训练使零射击任务普遍化—<a class="ae kn" href="https://arxiv.org/abs/2110.08207" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2110.08207</a></li><li id="0bd6" class="ll lm hh jw b jx lu ka lv jh lw jl lx jp ly km mk lr ls lt bi translated">参数高效的快速调优的规模力量—<a class="ae kn" href="https://arxiv.org/abs/2104.08691" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2104.08691</a></li></ul><div class="ml mm ez fb mn mo"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">medium.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc ld mo"/></div></div></a></div><p id="d51a" class="pw-post-body-paragraph ju jv hh jw b jx ko ii jz ka kp il kc jh kq ke kf jl kr kh ki jp ks kk kl km ha bi translated">🟠在MLearning.ai  成为<a class="ae kn" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfbv">作家</a></p></div></div>    
</body>
</html>
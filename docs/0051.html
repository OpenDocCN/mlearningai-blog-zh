<html>
<head>
<title>Facial mask overlay with OpenCV-dlib</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用OpenCV-dlib覆盖面膜</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d?source=collection_archive---------1-----------------------#2020-10-07">https://medium.com/mlearning-ai/facial-mask-overlay-with-opencv-dlib-4d948964cc4d?source=collection_archive---------1-----------------------#2020-10-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1042" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用OpenCV-dlib库叠加面罩</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/626be749386fca1d2b94079af2d69ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Q7u1VGzQMC0Wmf8z3-_ABw.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Photo by <a class="ae jo" href="https://unsplash.com/@miracletwentyone?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Joseph Gonzalez</a> on <a class="ae jo" href="https://unsplash.com/s/photos/face?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a> (original image edited using facial mask overlay)</figcaption></figure></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><p id="5bce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事实证明，口罩是防止新冠肺炎病毒传播的最佳手段之一。然而，这也导致了面部识别算法的失败，这些算法是围绕包括鼻子、嘴和下颌线在内的面部特征建立的。在全局疫情之前，面部识别系统通过在检测到的不同面部特征之间执行比较测量来验证两幅图像中的面部。在一个人的鼻子、嘴和脸颊上戴上面具，已经大大减少了通常用于识别他/她的身份的信息。</p><p id="5c61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将需要重新训练或重新设计有效的识别系统来识别受管制区域中的蒙面人脸。为了做到这一点，需要一个大的蒙面人脸数据集来训练深度学习模型，以检测戴口罩的人和不戴口罩的人。目前，可用于训练和评估面部识别系统的带面罩的人的图像数据集有限。据报道，美国国家标准和技术研究所(NIST)的研究解决了这个问题，方法是将(各种颜色、大小和位置的)面具叠加在无面具人脸的图像上。[ <a class="ae jo" href="https://www.cnet.com/news/face-masks-are-thwarting-even-the-best-facial-recognition-algorithms-study-finds/?ftag=COS-05-10aaa0b&amp;TheTime=2020-07-27T22%3A23%3A21&amp;PostType=link&amp;UniqueID=C7330AC8-D057-11EA-8580-DE063A982C1E&amp;ServiceType=twitter" rel="noopener ugc nofollow" target="_blank">来源</a></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es jw"><img src="../Images/b79c2bdba4a30d98c0334052436a7572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1djjgo3ljWhwBnwnK8YMQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Figure 1 — NIST superimposed 5 types of face masks to immigration photos to test 89 facial recognition algorithms. [<a class="ae jo" href="https://www.cnet.com/news/face-masks-are-thwarting-even-the-best-facial-recognition-algorithms-study-finds/?ftag=COS-05-10aaa0b&amp;TheTime=2020-07-27T22%3A23%3A21&amp;PostType=link&amp;UniqueID=C7330AC8-D057-11EA-8580-DE063A982C1E&amp;ServiceType=twitter" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><p id="ef0f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章试图使用OpenCV和dlib库来复制这个过程，在那里我们综合生成了5种类型的人脸面具来绘制在人脸图像上。图1显示了生成的5种类型的面罩。</p><p id="d897" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还将在另一篇文章中使用深度学习方法之一——mt CNN(多任务级联卷积网络)对“被掩盖”的人脸进行测试或验证。</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><h1 id="8404" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">入门指南</h1><p id="8ede" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">要开始使用这个脚本，<em class="le">用本文末尾的链接克隆库</em>。</p><h1 id="2f39" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">安装所需的软件包</h1><p id="f6cd" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">建议<a class="ae jo" href="https://towardsdatascience.com/setting-up-python-platform-for-machine-learning-projects-cfd85682c54b" rel="noopener" target="_blank">用Python 3.7制作一个新的虚拟环境</a>并安装依赖项。所需的库如下所述:</p><pre class="jd je jf jg fd lk ll lm ln aw lo bi"><span id="7c7b" class="lp kc hh ll b fi lq lr l ls lt">#requirements_facemask.txt<br/>numpy == 1.18.5<br/>pip == 20.2.2<br/>imutils == 0.5.3<br/>python &gt;=3.7<br/>dlib == 19.21.0<br/>cmake == 3.18.0<br/>opencv-python == 4.4.0</span></pre><p id="5440" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于该脚本需要dlib库，因此在开始运行该脚本之前安装dlib非常重要。您可以通过以下链接了解如何使用Python绑定安装dlib:</p><div class="lu lv ez fb lw lx"><a href="https://www.pyimagesearch.com/2017/03/27/how-to-install-dlib/" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hi fi z dy mc ea eb md ed ef hg bi translated">如何安装dlib - PyImageSearch</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">两周前，我采访了dlib库的创建者和主要维护者Davis King。今天我打算…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">www.pyimagesearch.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml ji lx"/></div></div></a></div><p id="d50b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Dlib是一个高级机器学习库，旨在解决复杂的现实世界问题。这个库是使用C++编程语言创建的，它可以与C/C++、Python和Java一起工作。</p><h1 id="674b" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">导入库</h1><p id="e689" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">我们将从导入执行面罩数字叠加所需的必要库开始:OpenCV、dlib、numpy、os和imutils。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="cbf2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是初始化面罩的颜色，并设置导入图像的目录和路径。请注意，OpenCV的色彩空间是BGR顺序，而不是RGB顺序。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="17ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的链接可以让你立即从视觉上探索这种颜色。它可以用来做颜色从十六进制到RGB的转换，反之亦然—<a class="ae jo" href="https://www.rgbtohex.net/rgb/" rel="noopener ugc nofollow" target="_blank">https://www.rgbtohex.net/rgb/</a></p><h1 id="6655" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">预处理图像</h1><p id="dfa0" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">接下来，我们将通过OpenCV加载我们的输入图像，然后通过调整图像大小使其宽度为500像素并将其转换为灰度来预处理图像。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><h1 id="f317" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">使用dlib、OpenCV和Python检测和提取面部标志</h1><p id="a737" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">为了覆盖面具，我们需要进行人脸检测。有许多方法可以完成这项任务。我们可以使用OpenCV内置的Haar Cascade XML文件甚至TensorFlow或者使用Keras。在这篇文章中，我们使用的是dlib的人脸检测器。</p><p id="5d14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们进一步进行之前，了解dlib的面部检测器和面部标志检测是如何工作的很重要。dlib中的正面人脸检测器基于<em class="le">方向梯度直方图(HOG) </em>和<em class="le">线性SVM。</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/0742f212642d8fbcc775d77841105bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*GMiZolUNqbuhf1xD4jPlkg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Figure 2— Output of dlib’s face landmarking [<a class="ae jo" href="http://blog.dlib.net/2014/08/real-time-face-pose-estimation.html" rel="noopener ugc nofollow" target="_blank">source</a>].</figcaption></figure><p id="c8b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们正在使用dlib的正面人脸检测来首先检测人脸，然后使用dlib库中的面部标志预测器dlib.shape_predictor来检测面部标志。</p><blockquote class="mp mq mr"><p id="e964" class="ie if le ig b ih ii ij ik il im in io ms iq ir is mt iu iv iw mu iy iz ja jb ha bi translated">面部标志检测被定义为检测面部关键标志并跟踪它们的任务(对由于头部运动和面部表情引起的刚性和非刚性面部变形具有鲁棒性)</p></blockquote><h2 id="f1ea" class="lp kc hh bd kd mv mw mx kh my mz na kl ip nb nc kp it nd ne kt ix nf ng kx nh bi translated">什么是面部标志？</h2><p id="aef2" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">面部标志用于定位和表示面部的显著区域，例如眼睛、眉毛、鼻子、下颌线、嘴等。</p><p id="133f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一种已经应用于诸如面部对准、头部姿态估计、面部交换、眨眼检测、睡意检测等应用的技术。</p><p id="ee1d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在面部标志的情况下，有必要使用形状预测方法来检测面部上的重要面部结构。面部标志检测包括两个步骤:</p><ol class=""><li id="ed4c" class="ni nj hh ig b ih ii il im ip nk it nl ix nm jb nn no np nq bi translated">定位图像中检测到的面部。</li><li id="c8b2" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nn no np nq bi translated">面部关键面部结构的检测</li></ol><p id="be01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，我们可以用多种方式执行面部检测，但每种方法本质上都试图定位和标记以下面部区域:</p><ul class=""><li id="42ff" class="ni nj hh ig b ih ii il im ip nk it nl ix nm jb nw no np nq bi translated">鼻子</li><li id="8456" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">下巴</li><li id="b0eb" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">左右眼</li><li id="a5e0" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">左右眉</li><li id="d002" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">口</li></ul><p id="45b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们使用了基于深度学习的人脸定位算法。该算法也将用于检测图像中的人脸。我们还将通过一些方法获得人脸包围盒，其中我们分别使用图像中人脸的(x，y)坐标。一旦面部区域被检测和界定，我们将进行下一步检测面部区域中的关键面部结构。</p><p id="d371" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用dlib库中包含的预训练面部标志检测器。它是卡泽米和沙利文(2014年)论文的<a class="ae jo" href="https://www.semanticscholar.org/paper/One-millisecond-face-alignment-with-an-ensemble-of-Kazemi-Sullivan/d78b6a5b0dcaa81b1faea5fb0000045a62513567?p2df" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="le">一毫秒人脸对齐与回归树</em> </strong> </a>集合的实现，其中它估计映射到人脸面部结构的<em class="le"> 68 (x，y)</em>坐标的位置。我们可以使用下图来可视化这些68个坐标或点的索引:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es nx"><img src="../Images/2942d1239f4db3bd82bfb932ac3e1b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QV-7cBgxcxknDFjqUbFblQ.jpeg"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Figure 3 — The 68 facial landmark points from the iBUG 300-W dataset [<a class="ae jo" href="https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure><p id="1319" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从图3中，面部特征的位置可以通过不同组的点[起点，终点]来评估:</p><ul class=""><li id="2e27" class="ni nj hh ig b ih ii il im ip nk it nl ix nm jb nw no np nq bi translated">左眼:点数[42，47]</li><li id="b56b" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">口:分[48，67]</li><li id="7dd8" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">左眉:分[22，26]</li><li id="676a" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">鼻子:点[27，34]</li><li id="b8cc" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">右眉:分[17，21]</li><li id="add8" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">右眼:点数[36，41]</li><li id="c08d" class="ni nj hh ig b ih nr il ns ip nt it nu ix nv jb nw no np nq bi translated">下颌线:点数[0，16]</li></ul><p id="c158" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，标志点从0开始</p><p id="0d74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些注释是dlib面部标志预测器被训练的68点<a class="ae jo" href="https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> iBUG 300-W数据集</strong> </a>的一部分。</p><h1 id="973c" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">面部检测和面部标志检测</h1><p id="6251" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">下一步包括基于对用于对象检测的标准<a class="ae jo" href="https://pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">方向梯度直方图+线性SVM方法</strong> </a>的修改，初始化dlib的预训练人脸检测器。这个检测器将处理图像中人脸包围盒的检测。</p><p id="f0f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">检测器的第一个参数是我们的灰度图像。(这种方法也适用于彩色图像)。</p><p id="8b82" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第二个参数是在应用检测器之前放大图像时要应用的图像金字塔层数。在人脸检测之前增加输入图像的分辨率的优点是，它可以允许我们在图像中检测更多的人脸。然而，缺点是输入图像越大，计算成本越高，检测过程的速度越慢。</p><p id="cbd8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还将打印出边界框的坐标以及检测到的面的数量。我们也可以使用cv2通过for循环在检测到的人脸周围绘制边界框。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="e144" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了检测面部标志，我们需要从dlib库中下载面部标志预测器dlib.shape_predictor。</p><p id="7a79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的形状预测方法需要下载名为“shape _ predictor _ 68 _ face _ landmarks . dat”的文件，该文件可以从以下链接下载:<a class="ae jo" href="http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2" rel="noopener ugc nofollow" target="_blank">http://dlib . net/files/shape _ predictor _ 68 _ face _ landmarks . dat . bz2</a><br/>需要强调的是，该模型文件仅设计用于dlib的HOG人脸检测器，不应用于dlib的基于CNN的人脸检测器。原因是它期望来自面部检测器的边界框按照dlib的HOG面部检测器的方式对齐。</p><p id="1bb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当与产生不同对齐框的另一个面部检测器(例如基于CNN的mmod_human_face_detector.dat面部检测器)一起使用时，结果不会很好。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="8808" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦下载了形状预测器，我们就可以初始化该预测器，以便随后用于检测在输入图像中检测到的每个面部上的面部标志。</p><p id="f0ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦检测到面部标志，我们将能够开始“绘制”/通过使用OpenCV   中的<a class="ae jo" href="https://docs.opencv.org/master/dc/da5/tutorial_py_drawing_functions.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="le">绘制功能连接所需的点，将面具覆盖在面部上</em></strong></a></p><h1 id="7a77" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">Dlib掩蔽方法</h1><p id="4ea7" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">以下步骤包括确定绘制不同类型面罩所需的点。我们正在复制的面罩类型由<a class="ae jo" href="https://doi.org/10.6028/NIST.IR.8311" rel="noopener ugc nofollow" target="_blank"> NIST研究论文附录a中提到的不同点集合定义。</a>视觉效果见图4。</p><div class="jd je jf jg fd ab cb"><figure class="ny jh nz oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/e59779db1098d55b8cb74261a3dbe93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*vB9WYL9I0pmvEP77n8rA7A.png"/></div></figure><figure class="ny jh oe oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/e2bd7c9ad7b41df01ad44fdfe629008c.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*k-1Ze3_F_PY0U4N4qf_O8g.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx of di og oh">Figure 4 — Dlib Masking Methodology (left image) and the 5 different types of facemasks to be superimposed (right image) [<a class="ae jo" href="https://doi.org/10.6028/NIST.IR.8311" rel="noopener ugc nofollow" target="_blank">source</a>]</figcaption></figure></div><p id="0e5f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将通过连接论文附录a中定义的标志点来定义面罩的形状。例如，为了形成宽和中等覆盖范围的面罩，我们将连接(绘制)下颌线[0，16]的标志点，标志点坐标为点29。</p><p id="1ee2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用OpenCV<strong class="ig hi"><em class="le"/></strong>中的<a class="ae jo" href="https://docs.opencv.org/master/dc/da5/tutorial_py_drawing_functions.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="le">绘图功能，可以绘制椭圆形和其他三种规则形状遮罩的轮廓。然后我们可以使用<a class="ae jo" href="https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html?highlight=fillpoly" rel="noopener ugc nofollow" target="_blank"> <em class="le"> cv2.fillpoly </em> </a>函数给绘制的面具填充颜色。</em></strong></a></p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">facemask_pts.py defines the 3 regular shapes of face masks — wide, high/medium/low coverage</figcaption></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">facemask_roundpts.py defines the ellipse shape of face masks — round, high coverage</figcaption></figure><p id="9b35" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">面罩的颜色和类型将由用户在图像检测开始之前通过选择来预先确定。我们已经在用户输入功能中为面罩预先选择了两种颜色——蓝色和黑色。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><h1 id="8056" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">结果</h1><div class="jd je jf jg fd ab cb"><figure class="ny jh oi oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/b6a625e5b3a0074878370062db66d9de.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*bfkP2J8w4XZLLe_vu9Cfxg.jpeg"/></div></figure><figure class="ny jh oj oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/69833b544ada3fc3e56b72f0a72ab97f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*4u-KGM6NifKuFkPyZbWHgg.jpeg"/></div></figure><figure class="ny jh oj oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/847baada3b0a21a28a64bc9678e47259.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*iq-YWMoZMj00XAgLg356MQ.jpeg"/></div></figure></div><div class="ab cb"><figure class="ny jh ok oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/30f23c5e50fdd4d5d336c3b9c1439c3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*VP0xoGB-gQ2eXcywh990sA.jpeg"/></div></figure><figure class="ny jh ok oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/549dbf6c02de8a7f5e2e5dafe7bb5629.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*-9qbRajoijpi-xDXFGPBlQ.jpeg"/></div></figure><figure class="ny jh ok oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/bdf36370cf9d4713a54fad61f483bf94.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*issbEqTUYwj8tjSfzt7pVg.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx ol di om oh">Figure 5 — (First row left image) Input : original image of Barack Obama | Output : Five different types of facemasks superimposed on Barack Obama’s face</figcaption></figure></div><div class="ab cb"><figure class="ny jh on oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/db3b156364cf11e788a46ab1936de58f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*X07HmK45KPMk-3-bLfKs7w.jpeg"/></div></figure><figure class="ny jh oo oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/78383e409efaacc0030a3765f62ae2ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*fGOYzh6043NRImBBeEn7Jw.jpeg"/></div></figure><figure class="ny jh oo oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/14e79a6eb094a4bca39e97852c8a5066.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*lDm9y9Jscnjcp175LJk3uA.jpeg"/></div></figure></div><div class="ab cb"><figure class="ny jh ok oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/e6f2c6603e0eecc546c46bfd67daa6d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*9AtxyQOmSF_MX-yz-F3GMg.jpeg"/></div></figure><figure class="ny jh ok oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/7a0e93dc24019ffd3990c591905805df.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*QVriuSPNKKTvab1l541ATw.jpeg"/></div></figure><figure class="ny jh ok oa ob oc od paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><img src="../Images/6cefd99345dd534c79999854572dce94.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*iSKGmYdUxf8aCV4yfx9axw.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx ol di om oh">Figure 6 — (First row left image) Input : original image of Ellen’s wefie shot | Output : Five different types of facemasks superimposed on group faces detected</figcaption></figure></div><p id="e511" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图5显示了原始输入图像(巴拉克·奥巴马的图像)和使用脚本叠加了面具的输出图像之间的比较。我们也可以在集体照中使用这个脚本。在著名的Ellen's wefie镜头中，在检测到的人脸上叠加面罩的结果见图6。</p><p id="8c90" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们能够成功地复制生成5种不同类型的面罩(详见附录A)的过程，这些面罩可以使用dlib和OpenCV叠加在无面罩面部的图像上。</p><p id="a2ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图7到图9展示了在不直视摄像机的人脸上运行这个脚本的更多例子。</p><div class="jd je jf jg fd ab cb"><figure class="ny jh op oa ob oc od paragraph-image"><img src="../Images/5e45c37187b3164b2f6d3cfdc92ed733.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/format:webp/1*hpHF8wWFXT1Yok1SeEvFUg.jpeg"/></figure><figure class="ny jh op oa ob oc od paragraph-image"><img src="../Images/3f7f349348ba62c825f0dbcfe5c0680d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*UEY6-WwkufqTMeEfmx4P4w.jpeg"/><figcaption class="jk jl et er es jm jn bd b be z dx oq di or oh">Figure 7— (left image) Input : original image of Ben Affleck | Output : wide, medium coverage facemask superimposed</figcaption></figure></div><div class="ab cb"><figure class="ny jh op oa ob oc od paragraph-image"><img src="../Images/df25a60b399cbe4381e0672ffd92123d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*BG_6-09suQq71AVBAQ7shw.jpeg"/></figure><figure class="ny jh op oa ob oc od paragraph-image"><img src="../Images/5d520e99377bb476929e1f9786551f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Z3sNgefkg_8jRkNRTeJieQ.jpeg"/><figcaption class="jk jl et er es jm jn bd b be z dx oq di or oh">Figure 8— (left image) Input : original image of Elton John | Output : wide, high coverage facemask superimposed</figcaption></figure></div><div class="ab cb"><figure class="ny jh os oa ob oc od paragraph-image"><img src="../Images/57879911d2d52ed97a91b43ba1b29690.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*sU-pYPH0vFe4t8FxfcC9Kw.jpeg"/></figure><figure class="ny jh ot oa ob oc od paragraph-image"><img src="../Images/047fd77ceea3ea5f6b27eea813c9890b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*yFn-Q7wttv-Ua1RYsRIHAQ.jpeg"/><figcaption class="jk jl et er es jm jn bd b be z dx oq di or oh">Figure 9— (left image) Input : original image of Mindy Kaling | Output : wide, medium facemask superimposed</figcaption></figure></div><h1 id="8b86" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">结论</h1><p id="9f7b" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">该脚本能够在检测到的人脸上生成合成面具人脸，然后输出图像可用于<strong class="ig hi"> <em class="le">测试或验证</em> </strong>其他面向应用的ML网络，如室内考勤系统的人脸识别、面具检测等。</p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><p id="97d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在这里下载我的完整代码</p><p id="ed8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jo" href="https://github.com/xictus77/Facial-mask-overlay-with-OpenCV-Dlib.git" rel="noopener ugc nofollow" target="_blank">https://github . com/xictus 77/face-mask-overlay-with-OpenCV-dlib . git</a></p><h1 id="d17f" class="kb kc hh bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">参考资料:</h1><p id="b78a" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated"><a class="ae jo" href="https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/" rel="noopener ugc nofollow" target="_blank"> 1。用dlib、OpenCV和Python实现的面部标志</a></p><p id="5900" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jo" href="https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/" rel="noopener ugc nofollow" target="_blank"> 2。面部点标注</a></p><p id="edcd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jo" href="http://blog.dlib.net/2014/08/real-time-face-pose-estimation.html" rel="noopener ugc nofollow" target="_blank"> 3。实时人脸姿态估计</a></p><p id="0ac9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jo" href="https://docs.opencv.org/master/dc/da5/tutorial_py_drawing_functions.html" rel="noopener ugc nofollow" target="_blank"> 4。OpenCV中的绘图功能</a></p><p id="ad70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.图片来源——开源和<a class="ae jo" href="https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset</a></p></div></div>    
</body>
</html>
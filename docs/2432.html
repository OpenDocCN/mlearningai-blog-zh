<html>
<head>
<title>Learned Data Augmentation using VQ-Vae</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用VQ-Vae的学习数据扩充</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/learned-data-augmentation-using-vq-vae-339a8e12b779?source=collection_archive---------4-----------------------#2022-05-01">https://medium.com/mlearning-ai/learned-data-augmentation-using-vq-vae-339a8e12b779?source=collection_archive---------4-----------------------#2022-05-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="66fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">摘要:</strong></p><p id="b33c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">在这篇论文中，我提出了一种简单且易于再现的方法来增强和扩展数据集，从少至1000幅图像到多达10000幅图像，或者本质上是用户需要的那么多。我的方法结合了适当的VAE潜在空间模型，然后使用称为矢量量化的过程进行修改。利用这些技术以及增强的模型参数化和训练，简单的卷积神经网络可以在合成数据上实现高达93%的准确度，这被证明是非常有用的，尤其是在处理具有很少图像的数据集时。</strong></p><p id="6a8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">简介:</strong></p><p id="26d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">机器学习是计算机科学中规模最大、发展最快的领域之一，也是数据最密集的领域之一，行业可接受的模型需要近百万张图像。像GPT-3和BERT这样的模型是当前自然语言处理的旗舰，它们在数千亿个单词上进行训练，BERT-Base在4个TPU上训练需要4天以上[1]，请记住，TPU是专门为训练机器学习模型而构建的，相比之下，在8个GPU上训练BERT-Base需要7天以上[2]。主要的要点是，机器学习模型需要极其大量的数据和长时间的训练。如果不改进硬件或云计算或额外的计算库(如JAX)，机器学习的时间因素就不容易克服，这些计算库可以显著加快矩阵计算的速度，而数据因素可以使用线性变换(如裁剪、调整大小或随机噪声生成)来解决。虽然这些方法本身是有效的，但它们不能解决缺乏数据的固有问题。线性变换是相同的图像，只是在一定程度上进行了修改，对数据的缺乏没有提供真正的优势；它们只是为过度拟合问题提供了一个解决方案。为了解决数据问题，研究人员多年来一直在尝试学习数据增强的方法[3][4]，然而，这些方法中的大多数利用了需要大量计算资源的生成对立神经网络，或者利用了在从潜在空间做出有意义的表示方面不如vq-vaes有效的变分自动编码器。视觉上的差异将在文章的最后讨论。</p><p id="c53e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">变型自动编码器:</strong></p><p id="1f19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2013年，Diederik P. Kingma和Max Welling首次提出了可变自动编码器。变分自动编码器试图从Z或潜在空间中再现原始X数据，该潜在空间存在于比原始数据更低维度的空间中。它被编码器压缩。等式可以写成:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/915c38bba493b5f1dafc482eda1d6309.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/0*SadzBT0yvlz97HCU"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/f748bb7fc32593ca8dfc1f5eff169db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/0*t3MGK7Rx3DhLvSby"/></div></figure><p id="5a2a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中表示样本分布，通常表示为高斯噪声或伯努利分布。解码器是另一个神经网络。它的输入是表示z，它输出参数到数据的概率分布，并且有权重和偏差<em class="jk"> ϕ </em>。以mnist数据集为例，假设手写数字图像是黑白的，将每个像素表示为0或1。然后可以使用伯努利分布来表示单个像素的概率分布。解码器获得数字<em class="jk"> z </em>的潜在表示作为输入，并输出784(在28×28图像的情况下)伯努利参数，图像中784个像素中的每一个都有一个伯努利参数。然后，解码器获取潜在空间，并试图将潜在空间返回到传递到编码器中的原始数据，但是因为所有数据不能包含在缩减/压缩的数据中，所以解码器经常在重建图像中产生某些变化，这在这种情况下是非常有利的，因为需要增加数据。</p><p id="cf94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">矢量量化变分自动编码器:</strong></p><p id="6b03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">矢量量化变分自动编码器(简称VQ-VAE编码器)于2013年在一篇题为“神经离散表示学习”的论文[6]中首次提出。VQ-Vae提供了优于诸如基本变分自动编码器或甚至GANs的方法的多个优点，在某种意义上，VQ-Vae的使用将防止“后验崩溃”,这是由于Vae中极其强大的解码器导致某些延迟被忽略而发生的现象。这造成了一个主要问题，尤其是在处理数据生成时，因为被忽略的潜在空间会导致数据丢失，从而从潜在空间形成不正确的图像。为了解释这个问题的重要性，让我们举个例子。在医学成像(CT扫描、肺炎识别等)的情况下。)如果解码器遭受后验崩溃，作为产生有意义的数据表示的手段就变得无用。这可能会带来一个重大问题，特别是对于医疗数据，当模型的准确性可以挽救患者的生命时，这意味着模型再现的数据必须足够准确，以允许识别器模型(如卷积神经网络)能够复制这种准确性。然而，VQ-维斯利用了离散的潜在空间，这导致了运行反向传播的问题，其中模型不能通过潜在空间运行反向传播。这个问题通过使用称为直接到梯度的方法来解决，该方法将梯度从解码器复制到编码器，从而绕过VQ-Vae产生的“码本”向量。如前所述，这是反向传播产生误差的原因，因为潜在空间是不可微的，并且梯度不能被推过瓶颈，而瓶颈是用前面提到的通过复制梯度的过程解决的。</p><p id="a3a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">实验运行:</strong></p><p id="02e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了探索和相对于其他型号(如GAN和)的优势，我训练了最流行的发电机型号的每个变体，作为与和比较的基线。让我们深入研究结果</p><p id="3671" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">深度卷积生成对抗神经网络(DCGAN)产生的结果。利用卷积神经网络通过鉴别器进行更好的图像分类。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jl"><img src="../Images/9897e9c807146b7e7838ab86726504ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/0*QIWnCm7E0cRjHevu"/></div></figure><p id="7814" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">25个时期后的结果(每个模型的时期基线数)</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jl"><img src="../Images/c5d81ced981f13a3c4f51cfa7a005a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/0*kMHPAeTMKvnpIJKd"/></div></figure><p id="28ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果经过550个时代的训练。</p><p id="fede" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些结果真实地说明了实现能够产生有意义的数据表示的生成性对抗网络的成本有多高。大约需要5000个历元才能产生与原始数据非常相似的图像，这还没有考虑到我们可以访问的数据量。</p><p id="a066" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">变分自动编码器在25个时期的训练后产生的结果。还不错，但还不足以解决数据不足的问题。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jm"><img src="../Images/2f2048aa64177083776dd461e3b92d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/0*os6r4jN_mC1xuGG7"/></div></figure><p id="e8a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在对于矢量量化变分自动编码器:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jn"><img src="../Images/d4d465b8b5d83c6c165afec95222b7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/0*sCCwADAR-y4xm-3H"/></div></figure><p id="35aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">30次训练后的结果。绝对惊艳。它能够产生几乎直接复制模型的表示，除了在重建图像中有一点噪声。让我们看另一个例子。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jo"><img src="../Images/3fa27f76ff95cc199a2d0ae2ae438bf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1F8MfX4FPGYNrl3L"/></div></figure><p id="ba0c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然这确实令人惊讶，但我们确实需要进一步测试这种方法。从数值中创建一个有意义的表示，其复杂性很小或没有，无法与图像(如大脑或人类肺部的CT扫描)的复杂性相比。因此，让我们用kaggle[7]的肺炎数据集进一步测试该方法。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/2427e4bf9b05bbcc7ecd0bfc712ed7ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*QKL0JCwOz4M6lIxO"/></div></figure><p id="55f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相当不错，尤其是只有500个纪元。同样重要的是要考虑这样一个事实，即原始表示也非常嘈杂，这意味着重建图像可能不太准确，但该表示确实包含与原始图像一样的重要特征。如果我们运行模型5000个或10000个历元会好得多，但考虑到广泛的用例，让模型训练430000次更新可能会更好，因为Dall-E被训练为包括当然更高计算效率的设备，如GPU和TPU。解构的图像和潜在的空间显示了编码器网络在仅仅500个时代后是多么强大。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/2e7d883af65b9059afb2f866e0d58a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*YuVWWgXCuNhfT8Sd"/></div></figure><p id="72c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为一个实验，我想利用一个具有各种场景和照明效果的数据集[8]，看看该模型是否可以重建一个具有主要差异的图像，这些差异是由于数据集中原始图像之间的各种图像造成的。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jr"><img src="../Images/45e31960acf6b407fed924b717beba81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QPVvE0_tD-1UTWTu"/></div></div></figure><p id="efd3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">300个时代后的最佳代表。几乎没有区别的是云的位置和山的形状。连灯光好像都配！然而，山的高度略有不同。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jq"><img src="../Images/afae82ab46bbe4dd032515a9a1eeaf57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*jXpkFLQfTQ3gD6lE"/></div></div></figure><p id="76e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最糟糕的表现。图像具有相同的总体形状，但噪声极大。</p><p id="aca0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">模型推进方式:</strong></p><p id="4980" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一如既往，总是有多种方法来改进模型。在这种情况下，可以使用PixelCNN作为编码器。PixelCNN是一个非常强大的卷积神经网络，可以使用CNN的特征提取功能来对数据进行有意义的表示，从而使解码器更容易重新映射原始图像。也有可能使用某种形式的歧管取样，在低样本设置规模，如这里提出的[9]。</p><p id="4eda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论:</strong></p><p id="738b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总之，我提出了一种将具有相对少的图像4000或更多的数据集扩展到极大数量的数据的方法，该数据在理论上可以无限扩展，但是引入了图像稀释的问题，导致特征的过度损失，但是至少是数据量的两倍。我还提出了一些方法，读者可以利用这些方法有效地改进VQ-VAE法案的给定基线。检查代码来运行你自己的实验[10]。</p><p id="fafe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">资源:</strong></p><p id="6b83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1] <a class="ae jw" href="https://towardsdatascience.com/training-bert-at-a-university-eedcf940c754" rel="noopener" target="_blank">在大学培训BERT——迈向数据科学https://Towards Data science . com Training-BERT-at-a-univ…</a></p><p id="cffc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2] <a class="ae jw" href="https://towardsdatascience.com/training-bert-at-a-university-eedcf940c754" rel="noopener" target="_blank">在大学培训BERT——走向数据科学https://Towards Data science . com Training——BERT-at-a-univ…</a></p><p id="915c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://arxiv.org/pdf/2105.00026.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2105.00026.pdf</a></p><p id="5088" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://arxiv.org/pdf/2012.00848.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2012.00848.pdf</a></p><p id="8e9a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1312.6114.pdf</a></p><p id="8379" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://arxiv.org/pdf/1711.00937.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1711.00937.pdf</a></p><p id="5ae3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">【7】<a class="ae jw" href="https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/paultimothymooney/chest-x-ray-pneumonia</a></p><p id="4bf5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://www.kaggle.com/datasets/arnaud58/landscape-pictures" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets/arnaud58/landscape-pictures</a></p><p id="c55b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://arxiv.org/pdf/2103.13751.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2103.13751.pdf</a></p><p id="faec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jw" href="https://github.com/arnavdantuluri/Vq-Vae-Image-Generation" rel="noopener ugc nofollow" target="_blank">https://github.com/arnavdantuluri/Vq-Vae-Image-Generation</a></p><div class="jx jy ez fb jz ka"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kb ab dw"><div class="kc ab kd cl cj ke"><h2 class="bd hi fi z dy kf ea eb kg ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kh l"><h3 class="bd b fi z dy kf ea eb kg ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ki l"><p class="bd b fp z dy kf ea eb kg ed ef dx translated">medium.com</p></div></div><div class="kj l"><div class="kk l kl km kn kj ko ji ka"/></div></div></a></div></div></div>    
</body>
</html>
# 数据科学(以及分析和人工智能)与黑历史月有什么关系？

> 原文：<https://medium.com/mlearning-ai/what-does-data-science-and-analytics-and-artificial-intelligence-have-to-do-with-black-history-99f6e2678462?source=collection_archive---------8----------------------->

![](img/68f72aaf24f5e34390128d1e62e2b5a9.png)

The sun breaking through in February, shedding light and warmth for new growth. Photo by the author.

如果从更广的角度来看历史，答案是“很多！”读完这篇文章后，我希望你会同意。 提醒一句——我意识到我的观点是由我自己的特权决定的，我下面提到的故事和链接并非来自我自己的生活经历。但这个话题，以及黑数据分析、数据科学和人工智能(AI)专业人士的生活经验，都太重要了，不能不分享。考虑到这一点，我认为黑人历史月有一些重要的联系，但不是显而易见的联系。

《牛津英语词典》将历史定义为“处理过去事件的知识分支”但是，当主流文化对过去的事件提供了一个不完整的记录时，就像黑人历史的情况一样，我们该怎么办呢？一个很好的起点是关注[黑人视角](https://www.aaihs.org/about-black-perspectives/)中的学者和思想家，这是[非裔美国人知识历史学会(AAIHS)](https://www.aaihs.org/) 的获奖博客。当然，继续学习更多关于黑人历史学家的知识，比如多萝西·波特·韦斯利、约翰·霍普·富兰克林和约翰·w·布拉辛游戏，以及他们的重要工作。

***但是让我们更进一步。让我们包括数据科学、分析和人工智能领域的黑人从业者，他们正在创新和创造历史。***

黑人从业者和研究人员所做的工作至关重要；人工智能和机器学习有潜力以积极、可持续的方式改变世界。然而，除非这些已知问题得到解决，否则大赦国际的积极影响正在并将继续受到损害:

*   人工智能中的偏见是[一个重大问题](https://peopleofcolorintech.com/articles/meet-the-black-women-trying-to-fix-ai/)，一个推动[新法规](/@loriaustex/5-things-you-must-know-now-about-the-coming-eu-ai-regulation-d2f8b4b2a4a9)
*   用于训练和测试人工智能和人工智能系统的数据集[经常会有偏见](https://cacm.acm.org/magazines/2021/12/256932-datasheets-for-datasets/fulltext)，这源于结构性种族主义
*   这些问题给黑人社区带来了不成比例的负面影响。

确保数据科学和分析项目由不同的团队推动，这些团队由黑人从业者和研究人员领导并包括他们，可以帮助减轻有偏见的人工智能和人工智能带来的历史和现实伤害。

除此之外，这项工作的技术方面可以被认为是历史的一种形式——毕竟，即使是最快的“实时”数据流也只是过去事件的即时记录。在这个框架中，AI 和 ML 工作流中使用的数据是历史性的。 ***通过使用(和批判)这些比特和字节，黑 AI 和 ML 从业者和研究人员正在改造历史，创造未来。***

# ***这个黑历史月，花点时间详细了解黑*** 从业者在 ***数据科学、分析学、AI*** 所做的工作

在这种关联的背景下，以下是十几位黑人数据分析、数据科学和人工智能领袖，他们的观点正在塑造未来，即使他们通过自己的贡献创造历史。我承认这是一个武断的、非常不完整的清单；为了弥补它的缺点，我鼓励你发现更多“数据中的黑”、“AI 中的黑”和“数据科学中的黑”的研究人员和从业者，并在评论中自由分享。

[***Rediet Abebe。Abebe 博士是加州大学伯克利分校的计算机科学助理教授，也是哈佛大学研究员协会的初级研究员。她的研究广泛涉及算法和人工智能领域，重点是不平等和分配正义问题。推特:https://twitter.com/red_abebe***](https://www.redietabebe.com/)

[***露丝·阿卡巴。***](https://blkindata.github.io/author/ruth-agbakoba/)Agbakoba 博士在健康信息学、数字健康和电子健康领域拥有广泛的背景，曾参与英国迄今最大的医疗保健创新计划，并领导了苏格兰首个国家数字健康和福利服务的评估。推特:[https://twitter.com/RuthAgbakoba](https://twitter.com/RuthAgbakoba)

[***特尼卡歪斜。***](https://www.teneikaaskew.com/)tene ika ask 是一家分析领导者，在提供分析、业务流程改进和咨询服务方面拥有超过 9 年的经验。她专门从事财务、人才和运营数据的数据分析，并为财富 500 强公司推动劳动力战略。推特:[https://twitter.com/teneikaask_you](https://twitter.com/teneikaask_you)

[***茹哈本雅明。本杰明博士是普林斯顿大学非裔美国人研究系的教授，她在普林斯顿大学研究科学、技术和医学的社会层面。她也是 IDA B. WELLS Just 数据实验室的创始主任和知名作者。推特:***](https://www.ruhabenjamin.com/)***[https://twitter.com/ruha9](https://twitter.com/ruha9)***

[***Abeba Birhane。Abeba Birhane 是爱尔兰都柏林大学计算机科学学院复杂软件实验室的认知科学博士研究员。她的跨学科研究位于复杂适应系统、机器学习和关键种族研究的交叉点。推特:***](https://abebabirhane.github.io/)***[https://twitter.com/Abebab](https://twitter.com/Abebab)***

[***uche black stock。Blackstock 博士毕业于哈佛大学，是医疗保健领域偏见和种族主义问题的思想领袖，曾任急诊医学系副教授和 NYU 医学院多元化事务办公室招聘、保留和包容主任。推特:***](https://advancinghealthequity.com/about/)***[https://twitter.com/uche_blackstock](https://twitter.com/uche_blackstock)***

[***喜出望外。***](https://www.poetofcode.com/)Buolamwini 博士的研究拥有全球受众，她在 WEF 和联合国倡导对算法公正的需求。她是欧洲委员会召集的全球技术小组的成员，该小组为世界领导人和技术高管提供减少人工智能推特危害的建议:[https://twitter.com/jovialjoy](https://twitter.com/jovialjoy)

[***Timnit Gebru。***](https://www.dair-institute.org/about) 格布鲁博士是分布式人工智能研究所(DAIR)的创始人兼执行董事。在此之前，她指出，她在 2020 年 12 月被谷歌解雇，因为她提出了工作场所的歧视问题，当时她是伦理人工智能研究团队的联合负责人。推特:[https://twitter.com/timnitGebru](https://twitter.com/timnitGebru)

[***乔丹·哈罗德。***](https://www.youtube.com/c/JordanHarrod/about) 乔丹·哈罗德(Jordan Harrod)是美国研究科学家，也是从事神经工程、脑机接口和医学机器学习的优图伯。她写道，“我一直对我们越来越多地与人工智能和算法互动的方式感兴趣，从社交媒体到教育，到军事，等等！”推特:[https://twitter.com/JordanBHarrod](https://twitter.com/JordanBHarrod)

[***Yeshimabeit Milner。***](https://d4bl.org/about.html)Yeshimabeit Milner 是[黑人生活数据](https://d4bl.org/about.html)的创始人和执行董事，他曾是运动设计师、技术专家和数据科学家。她是一个呼应绿色黑人男性成就的研究员，一个阿育王研究员，最近被授予福布斯“30 岁以下 30 岁以下”社会企业家的荣誉。领英:[https://www.linkedin.com/in/yeshimabeit-milner-a7788944/](https://www.linkedin.com/in/yeshimabeit-milner-a7788944/)

[***黛博拉·拉吉。***](https://www.linkedin.com/in/deborah-raji-065751b2/)Mozilla 研究员 Deborah Raji 正在研究算法审计和评估，与算法正义联盟密切合作开展了几个关于计算机视觉偏见的获奖项目，并且一直是纽约大学人工智能和人工智能伙伴关系研究所的研究员。推特:[https://twitter.com/rajiinio](https://twitter.com/rajiinio)

[***西蒙娜·韦布。Webb 博士是英国纽卡斯尔大学生物信息学副研究员和英国惠康桑格研究所的访问科学家。她专攻单细胞 RNA 测序分析、免疫学和造血领域，还参与了高等教育公平、社区建设和志愿科学推广工作。推特:***](https://www.simone-webb.com/)***[https://twitter.com/SimSci9](https://twitter.com/SimSci9)***

还有许多其他人的工作也很重要——在推特上关注 **#BlackInData** 、 **#BlackInDataScience** 和 **#BlackInAI 标签**，从他们的工作、经历和观点中了解更多。

# **光认可这些领导是不够的；拥有特权的人必须支持他们的工作**

在数据科学和人工智能的情况下，这个黑色历史月正在创造许多未来黑色历史。至关重要的是，不仅要认可和庆祝，还要与那些最受影响的人合作，为他们改变结构和制度。

一些资源可以帮助读者了解更多信息并采取下一步行动:

[***算法正义联盟。***](https://www.ajl.org/about) “通过艺术、研究、政策指导和媒体宣传的结合，算法正义联盟正在引领一场走向公平和负责任的人工智能的文化运动。这需要我们看看人工智能系统是如何开发的，并积极防止人工智能系统的有害使用。我们的目标是赋予社区权力，激励决策者采取行动，减轻人工智能的伤害和偏见。”

[***数据为黑命。*** 来自](https://d4bl.org/about.html)[福布斯](https://www.forbes.com/sites/ashoka/2019/12/11/why-we-need-data-for-black-lives/):"……在我们改变算法之前，在我们改变数据的来源之前，我们必须改变负责这一切的人。这就是 Data 4 Black Lives 的创意来源。”

[***【分布式人工智能研究院】(DAIR)。***](https://www.dair-institute.org/about) “我们是一家跨学科、全球分布的人工智能研究机构，我们坚信人工智能并非不可避免，其危害是可以预防的，当其生产和部署包括不同的视角和深思熟虑的过程时，它会是有益的。我们的研究反映了我们的生活经历，并以我们的社区为中心。……我们鼓励从一开始就分析其最终目标和潜在风险和危害的研究过程，而不是不断努力减轻主导团体进行的人工智能研究的危害。”

我希望你能花时间关注并支持上面提到的人和组织。

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
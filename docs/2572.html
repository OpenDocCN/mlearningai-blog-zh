<html>
<head>
<title>Denoising autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">降噪自动编码器</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/denoising-autoencoders-b54ecacc0b40?source=collection_archive---------9-----------------------#2022-05-19">https://medium.com/mlearning-ai/denoising-autoencoders-b54ecacc0b40?source=collection_archive---------9-----------------------#2022-05-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="5532" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我之前的一篇文章中，我讨论了不同类型的自动编码器。在这篇文章中，我将更多地关注一种特定的类型——去噪自动编码器。</p><p id="e884" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">去除图像中的噪声是图像处理和计算机视觉中具有挑战性的重要任务。分析图像时，去除噪声会非常有帮助。目标可能是提取最重要的特征，如果你有办法扔掉所有不必要的信息，这是可取的。</p><p id="d4ec" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们看一个autoencoder能够消除噪声的例子。由此可知:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jk"><img src="../Images/6163ebbcbb16876901de3a76efaedea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*96sm-11MR7L3hA8btMuBWg.png"/></div></figure><p id="4b42" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这个网络被训练成这样:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es js"><img src="../Images/2983efaa5986772cb037dd12ffacb2b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*1rHl78_RKBiKfu_m1fOVvA.png"/></div></div></figure><p id="1c35" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这个想法是扰动输入图像，但是将原始图像设置为期望的输出。这样，我们的网络将不仅仅学习身份函数，因为输入和输出是不同的。</p><p id="6ec5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们深入去噪自动编码器的实现。对于数据集，我选择了mnist。</p><p id="5dd5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">首先，导入必要的库:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="b7ec" class="kc kd hh jy b fi ke kf l kg kh">import numpy  as np</span><span id="b0b0" class="kc kd hh jy b fi ki kf l kg kh">import matplotlib.pyplot as plt</span><span id="bf31" class="kc kd hh jy b fi ki kf l kg kh">from keras.models import Sequential</span><span id="932c" class="kc kd hh jy b fi ki kf l kg kh">from keras.layers import Dense</span><span id="63b0" class="kc kd hh jy b fi ki kf l kg kh">import PIL</span><span id="cfa2" class="kc kd hh jy b fi ki kf l kg kh">import tensorflow as tf</span><span id="28c1" class="kc kd hh jy b fi ki kf l kg kh">from keras.datasets import mnist</span><span id="7c4e" class="kc kd hh jy b fi ki kf l kg kh">from tensorflow import keras</span><span id="b67b" class="kc kd hh jy b fi ki kf l kg kh">from keras.models import Sequential</span><span id="c935" class="kc kd hh jy b fi ki kf l kg kh">from keras.layers import (</span><span id="54bb" class="kc kd hh jy b fi ki kf l kg kh">Conv2DTranspose,Reshape,BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, Conv2D,UpSampling2D,Input</span><span id="1974" class="kc kd hh jy b fi ki kf l kg kh">)</span><span id="e3a0" class="kc kd hh jy b fi ki kf l kg kh">from PIL import Image as im</span><span id="2762" class="kc kd hh jy b fi ki kf l kg kh">from keras.models import Model</span><span id="802b" class="kc kd hh jy b fi ki kf l kg kh">from sklearn.model_selection import train_test_split</span><span id="4894" class="kc kd hh jy b fi ki kf l kg kh">import cv2</span></pre><p id="d99b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然后定义<strong class="in hi">加载数据</strong>的函数，<strong class="in hi">归一化</strong>图像:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="b3d8" class="kc kd hh jy b fi ke kf l kg kh">def load_data():</span><span id="f24a" class="kc kd hh jy b fi ki kf l kg kh">     (x_train, y_train), (x_test, y_test) = mnist.load_data()</span><span id="4cef" class="kc kd hh jy b fi ki kf l kg kh">     m = x_train.shape[0]</span><span id="70ea" class="kc kd hh jy b fi ki kf l kg kh">     n = x_test.shape[0]</span><span id="8d60" class="kc kd hh jy b fi ki kf l kg kh">     x_train = np.reshape(x_train, (-1,28,28,1))</span><span id="048c" class="kc kd hh jy b fi ki kf l kg kh">     x_test = np.reshape(x_test,(-1,28,28,1))</span><span id="de21" class="kc kd hh jy b fi ki kf l kg kh">     y_train = tf.keras.utils.to_categorical(y_train) </span><span id="3a5a" class="kc kd hh jy b fi ki kf l kg kh">     y_test = tf.keras.utils.to_categorical(y_test)</span><span id="d916" class="kc kd hh jy b fi ki kf l kg kh">     x_train = x_train.astype('float32')</span><span id="47e4" class="kc kd hh jy b fi ki kf l kg kh">     x_test = x_test.astype('float32')</span><span id="d312" class="kc kd hh jy b fi ki kf l kg kh">     x_train /= 255</span><span id="abe9" class="kc kd hh jy b fi ki kf l kg kh">     x_test /= 255</span><span id="2887" class="kc kd hh jy b fi ki kf l kg kh">     return x_train,y_train,x_test,y_test</span></pre><p id="a2b7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">并加载数据:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="1e14" class="kc kd hh jy b fi ke kf l kg kh">x_train,y_train,x_test,y_test = load_data()</span></pre><p id="2e97" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们想给输入添加噪声，所以我们定义了<strong class="in hi">高斯噪声函数</strong>:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="93eb" class="kc kd hh jy b fi ke kf l kg kh">def add_gaussian_noise(X_imgs):</span><span id="2e62" class="kc kd hh jy b fi ki kf l kg kh">  gaussian_noise_imgs = []</span><span id="182c" class="kc kd hh jy b fi ki kf l kg kh">  row, col, ch= X_imgs[0].shape</span><span id="975d" class="kc kd hh jy b fi ki kf l kg kh">  for X_img in X_imgs:</span><span id="d4f9" class="kc kd hh jy b fi ki kf l kg kh">     gaussian = X_img + 0.3*np.random.normal(loc = 0.0,scale =    1.0,size = (row, col, 1))</span><span id="46bb" class="kc kd hh jy b fi ki kf l kg kh">     gaussian_img = np.clip(gaussian, 0., 1.)</span><span id="d408" class="kc kd hh jy b fi ki kf l kg kh">     gaussian_noise_imgs.append(gaussian_img)</span><span id="2f85" class="kc kd hh jy b fi ki kf l kg kh">     gaussian_noise_imgs = np.array(gaussian_noise_imgs, dtype =   np.float32)</span><span id="00fc" class="kc kd hh jy b fi ki kf l kg kh">  return gaussian_noise_imgs</span></pre><p id="a854" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">向输入图像添加噪声:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="b844" class="kc kd hh jy b fi ke kf l kg kh">x_train_noisy = add_gaussian_noise(x_train)</span><span id="7c5f" class="kc kd hh jy b fi ki kf l kg kh">x_test_noisy = add_gaussian_noise(x_test)</span></pre><p id="0be8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们看看与原始数据相比，我们的扰动数据是什么样的:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es kj"><img src="../Images/7504f33ead4be8124e6918fdc3a5b15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*IMyYLE1G41xNw6LuHEAW5A.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx">perturbed image</figcaption></figure><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es kj"><img src="../Images/da1ec88746ba895db528fc0264ef0c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*503cSjZVsJCwr3COSE6iSQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx">original image</figcaption></figure><p id="9b13" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为我们的自动编码器创建编码器:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="095c" class="kc kd hh jy b fi ke kf l kg kh">def encoder(input_img):</span><span id="7f1f" class="kc kd hh jy b fi ki kf l kg kh">  conv1_1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)</span><span id="49ae" class="kc kd hh jy b fi ki kf l kg kh">  conv1_2 = BatchNormalization()(conv1_1)</span><span id="4f43" class="kc kd hh jy b fi ki kf l kg kh">  conv1_3 = MaxPooling2D((2,2))(conv1_2)</span><span id="2ce7" class="kc kd hh jy b fi ki kf l kg kh">  conv2_1 =   Conv2D(32,kernel_size=3,strides=2,padding='same',activation='relu')(conv1_3)</span><span id="f08e" class="kc kd hh jy b fi ki kf l kg kh">  conv2_2 = BatchNormalization()(conv2_1)</span><span id="948b" class="kc kd hh jy b fi ki kf l kg kh">  conv2_3 = MaxPooling2D((2,2))(conv2_2)</span><span id="747e" class="kc kd hh jy b fi ki kf l kg kh">  conv3_1 =  Conv2D(64,kernel_size=3,strides=2,padding='same',activation='relu')(conv2_3)</span><span id="5fb7" class="kc kd hh jy b fi ki kf l kg kh">  conv3_2 = BatchNormalization()(conv3_1)</span><span id="4be8" class="kc kd hh jy b fi ki kf l kg kh">  conv4 = Flatten()(conv3_2)</span><span id="cf96" class="kc kd hh jy b fi ki kf l kg kh">  conv4 = Dense(576)(conv4)</span><span id="ea5d" class="kc kd hh jy b fi ki kf l kg kh">  return conv4</span></pre><p id="84e2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">并创建解码器:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="bd7f" class="kc kd hh jy b fi ke kf l kg kh">def decoder(encode):</span><span id="a13b" class="kc kd hh jy b fi ki kf l kg kh">  conv5_1 = Reshape((3,3,64))(encode)</span><span id="9756" class="kc kd hh jy b fi ki kf l kg kh">  conv5_2 = Conv2DTranspose(32, kernel_size = 3, strides = 2,activation='relu', padding='valid')(conv5_1)</span><span id="37d2" class="kc kd hh jy b fi ki kf l kg kh">  conv6_1 = Conv2DTranspose(16, kernel_size = 3, strides = 2,activation='relu', padding='same')(conv5_2)</span><span id="a90d" class="kc kd hh jy b fi ki kf l kg kh">  conv7_1 = Conv2DTranspose(1, kernel_size=3, strides=2, padding='same', activation="sigmoid")(conv6_1)</span><span id="df68" class="kc kd hh jy b fi ki kf l kg kh">  return conv7_1</span></pre><p id="fa30" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">定义我们的模型:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="41f9" class="kc kd hh jy b fi ke kf l kg kh">inChannel = 1</span><span id="f0b3" class="kc kd hh jy b fi ki kf l kg kh">x, y = 28, 28</span><span id="1e4a" class="kc kd hh jy b fi ki kf l kg kh">input_img = Input(shape = (x, y,inChannel))</span><span id="53e7" class="kc kd hh jy b fi ki kf l kg kh">autoencoder = Model(input_img, decoder(encoder(input_img)))</span></pre><p id="9ac4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">编译我们的模型。这里我使用了SGD优化器:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="6fb8" class="kc kd hh jy b fi ke kf l kg kh">opt = tf.keras.optimizers.SGD(learning_rate=0.5)</span><span id="476b" class="kc kd hh jy b fi ki kf l kg kh">autoencoder.compile(loss='binary_crossentropy', optimizer = opt)</span></pre><p id="9731" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">分割训练数据:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="d856" class="kc kd hh jy b fi ke kf l kg kh">train_X,valid_X,train_ground,valid_ground =<br/>train_test_split(x_train_noisy,x_train,test_size=0.2,random_state=13)</span></pre><p id="d83f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">训练模型并保存权重:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="5227" class="kc kd hh jy b fi ke kf l kg kh">autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))</span><span id="caeb" class="kc kd hh jy b fi ki kf l kg kh">autoencoder.save_weights('autoencoder.h5')</span></pre><p id="2731" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">训练结束后，看看结果:</p><pre class="jl jm jn jo fd jx jy jz ka aw kb bi"><span id="7735" class="kc kd hh jy b fi ke kf l kg kh">reconstructs = autoencoder.predict(x_test_noisy)</span><span id="e3c9" class="kc kd hh jy b fi ki kf l kg kh">reconstructs = np.reshape(reconstructs,(-1,28,28))</span><span id="0db7" class="kc kd hh jy b fi ki kf l kg kh">x_test_noisy = np.reshape(x_test_noisy,(-1,28,28))</span><span id="4904" class="kc kd hh jy b fi ki kf l kg kh">plt.figure(figsize=(15,12))</span><span id="1db2" class="kc kd hh jy b fi ki kf l kg kh">for i in range(5):</span><span id="990a" class="kc kd hh jy b fi ki kf l kg kh">  plt.subplot(2,5,1+i)</span><span id="1819" class="kc kd hh jy b fi ki kf l kg kh">  plt.imshow(x_test_noisy[i])</span><span id="e56f" class="kc kd hh jy b fi ki kf l kg kh">  plt.axis('off')</span><span id="2ba5" class="kc kd hh jy b fi ki kf l kg kh">  plt.subplot(2,5,6+i)</span><span id="aacf" class="kc kd hh jy b fi ki kf l kg kh">  plt.imshow(reconstructs[i])</span><span id="8bab" class="kc kd hh jy b fi ki kf l kg kh">  plt.axis('off')</span><span id="87aa" class="kc kd hh jy b fi ki kf l kg kh">  plt.show()</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es ko"><img src="../Images/909c4afc5f1f56552b47cf5449873a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEYZxDtuEUacDCM-sDt2OA.png"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx">input</figcaption></figure><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es ko"><img src="../Images/b017f7536fdb8bc2143e8c1f540d4da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F4FOVc2LTvnpAMVRZ9qwEw.png"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx">output</figcaption></figure><p id="60d5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">噪音已成功消除。结果是惊人的，我真的建议玩不同的架构和不同的数据集。</p><p id="dcce" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">此外，尝试将获得的结果用于某些分类。但是，请注意，去噪自动编码器在与训练数据没有显著差异的数据上表现良好。例如，如果我在ImageNet数据集上尝试这个模型，我可能会得到很大的重建误差。</p><p id="4cf1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">希望这篇文章有用:)</p><div class="kp kq ez fb kr ks"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kt ab dw"><div class="ku ab kv cl cj kw"><h2 class="bd hi fi z dy kx ea eb ky ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kz l"><h3 class="bd b fi z dy kx ea eb ky ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="la l"><p class="bd b fp z dy kx ea eb ky ed ef dx translated">medium.com</p></div></div><div class="lb l"><div class="lc l ld le lf lb lg jq ks"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Line detection: Computer Vision VS Deep Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">直线检测:计算机视觉VS深度神经网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/line-detection-computer-vision-vs-deep-neural-network-27c6b40a14c8?source=collection_archive---------2-----------------------#2022-05-07">https://medium.com/mlearning-ai/line-detection-computer-vision-vs-deep-neural-network-27c6b40a14c8?source=collection_archive---------2-----------------------#2022-05-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="0b08" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">使用简单CV算法与复杂神经网络的直线检测分析以及何时使用何种方法的结论</h2></div><p id="29ba" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">直线检测有许多应用:例如估计图像的透视或创建矢量化图像，边缘检测等等。在这篇文章中，我不谈论应用，但我展示了如何使用两种算法，我们将比较它们，并得出结论，当我们想使用女巫的。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es js"><img src="../Images/3ace10688830e85c6c7676be2a114128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxVkz5ZT78O7lVU2T2OQ3g.png"/></div></div><figcaption class="ke kf et er es kg kh bd b be z dx">An example of classical canny+hough transform line detection</figcaption></figure><h2 id="e306" class="ki kj hh bd kk kl km kn ko kp kq kr ks jf kt ku kv jj kw kx ky jn kz la lb lc bi translated">使用CV进行直线检测</h2><p id="0db5" class="pw-post-body-paragraph iw ix hh iy b iz ld ii jb jc le il je jf lf jh ji jj lg jl jm jn lh jp jq jr ha bi translated">使用<a class="ae li" href="https://pypi.org/project/opencv-python/" rel="noopener ugc nofollow" target="_blank"> opencv-python </a>(我们可以获得关于这个<a class="ae li" href="https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html" rel="noopener ugc nofollow" target="_blank">链接</a>的更多信息)，使用<a class="ae li" href="https://en.wikipedia.org/wiki/Canny_edge_detector" rel="noopener ugc nofollow" target="_blank"> canny </a>检测和概率<a class="ae li" href="https://en.wikipedia.org/wiki/Hough_transform" rel="noopener ugc nofollow" target="_blank">霍夫变换</a>的基本思想，读取图像和获得线条的简单方法如下:</p><pre class="jt ju jv jw fd lj lk ll lm aw ln bi"><span id="14a6" class="ki kj hh lk b fi lo lp l lq lr">import cv2 as cv</span><span id="0f94" class="ki kj hh lk b fi ls lp l lq lr">rc = cv.imread(cv.samples.findFile(path), cv.IMREAD_GRAYSCALE)<br/>dst = cv.Canny(src, 50, 200, None, 3)<br/>linesP = cv.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10)</span></pre><p id="7557" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">colab笔记本完整演示可从<a class="ae li" href="https://colab.research.google.com/drive/1x8Q9dJWsCm4IkJEDjbV7FfEO9nrzEP8m?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h2 id="5854" class="ki kj hh bd kk kl km kn ko kp kq kr ks jf kt ku kv jj kw kx ky jn kz la lb lc bi translated">神经方法</h2><p id="62d7" class="pw-post-body-paragraph iw ix hh iy b iz ld ii jb jc le il je jf lf jh ji jj lg jl jm jn lh jp jq jr ha bi translated">有许多神经方法，例如一些使用hough变换，如用于语义线检测的深度Hough变换，也有web演示。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lt"><img src="../Images/094e50ad05a1299cb7b2650952d5f6e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*vdRkMafDVkPPaJZYvstrkg.jpeg"/></div><figcaption class="ke kf et er es kg kh bd b be z dx">Example of <a class="ae li" href="https://github.com/Hanqer/deep-hough-transform" rel="noopener ugc nofollow" target="_blank">Deep Hough Transform</a></figcaption></figure><p id="1a4a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但是我们也有其他方法，如<a class="ae li" href="https://github.com/mlpc-ucsd/LETR" rel="noopener ugc nofollow" target="_blank"> LETR(线段检测)</a>使用线框数据集来寻找更多可以描述3D对象的线(<a class="ae li" href="https://huggingface.co/spaces/z-uo/LETR" rel="noopener ugc nofollow" target="_blank"> web演示</a></p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lu"><img src="../Images/f4eef8191d7dcc56c7ae63f39b2f2399.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*Y7-NoAKtzij0azjm6s4YBw.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx">Example of <a class="ae li" href="https://github.com/mlpc-ucsd/LETR" rel="noopener ugc nofollow" target="_blank">LETR</a> (with resnet50 and 256*256 image scaling, it is possible to obtain better results with resnet 101 and more image resolution, use the <a class="ae li" href="https://huggingface.co/spaces/z-uo/LETR" rel="noopener ugc nofollow" target="_blank">web demo</a> to test more)</figcaption></figure><p id="daad" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第一种方法找到覆盖所有图像的无限多条线，因此它可以用于找到更好的透视线，例如自动操作<a class="ae li" href="https://fspy.io/" rel="noopener ugc nofollow" target="_blank"> fSpy </a>(关于fSpy使用的应用示例，请参见<a class="ae li" href="https://z-uo.medium.com/open-source-architecture-rendering-eb302f6b5f0e" rel="noopener">开源架构渲染</a>)。第二个是寻找元素边界的片段，可以用来创建一个3D模型，在很短的时间内对图像进行纹理处理，并通过使用一个延长的法线贴图(例如使用<a class="ae li" href="https://github.com/EPFL-VILAB/XTConsistency" rel="noopener ugc nofollow" target="_blank"> XTConsistency </a>一些视觉效果<a class="ae li" href="https://epfl-vilab.github.io/project_website_template/" rel="noopener ugc nofollow" target="_blank">这里</a>)我们使用低多边形网格得到一个很好的3D房间模型。</p><h2 id="4f71" class="ki kj hh bd kk kl km kn ko kp kq kr ks jf kt ku kv jj kw kx ky jn kz la lb lc bi translated">结论</h2><p id="67e8" class="pw-post-body-paragraph iw ix hh iy b iz ld ii jb jc le il je jf lf jh ji jj lg jl jm jn lh jp jq jr ha bi translated">如果我们需要解决简单的任务，如检测桌子或数独或网球场的线条，在特定的光线条件下不会有太大变化，计算机视觉方法就是你的解决方案:简单，可控，不需要太多的计算能力。</p><p id="d33a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但是对于更多可变的任务，如寻找真实世界图像的透视，神经模型可以表现得更好，并且可以接收更一般化的图像。</p><p id="3828" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">深度学习以更一般化的方式解决问题，这很好，但如果你有一个简单的问题，就简单地解决它<a class="ae li" href="https://www.interaction-design.org/literature/topics/keep-it-simple-stupid" rel="noopener ugc nofollow" target="_blank">吻</a>！</p><p id="0099" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请注意，我上面展示的所有内容都是开源的，所以请使用它并做出贡献！</p><div class="lv lw ez fb lx ly"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">medium.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm kc ly"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Topic Modelling using Latent Dirichlet Allocation - Easiest way— with source code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用潜在狄利克雷分配的主题建模——最简单的方法——带源代码</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/topic-modeling-using-latent-dirichlet-allocation-easiest-way-with-source-code-649df6d84427?source=collection_archive---------7-----------------------#2022-01-12">https://medium.com/mlearning-ai/topic-modeling-using-latent-dirichlet-allocation-easiest-way-with-source-code-649df6d84427?source=collection_archive---------7-----------------------#2022-01-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6019" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以在今天的博客中，我们将看到如何使用<a class="ae jc" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在的狄利克雷分配</a>来执行主题建模。我们在主题建模中所做的是试图根据一些相似的单词将不同的对象(在本例中是文档)组合在一起。这意味着如果两个文档包含相似的单词，那么它们很有可能属于同一类别。所以不用浪费任何时间。</p><p id="cf15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">点击此处查看视频—【https://youtu.be/a9WGoIiWwXg T2】</p><h1 id="e7cb" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">让我们开始吧…</h1><h2 id="cbf1" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">步骤1-导入所需的库。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="31a7" class="kb je hh ku b fi ky kz l la lb">import pandas as pd<br/>import numpy as np<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.decomposition import LatentDirichletAllocation</span></pre><h2 id="08ea" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">步骤2 —读取输入数据。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="2290" class="kb je hh ku b fi ky kz l la lb">articles = pd.read_csv('npr.csv')<br/>articles.head()</span></pre><figure class="kp kq kr ks fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/e4b828093699c5996c43949265bf0eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/0*iglOMp68zwA3hBXZ.png"/></div></div></figure><h2 id="cefe" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">步骤3-检查我们数据的信息。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="3625" class="kb je hh ku b fi ky kz l la lb">articles.info()</span></pre><ul class=""><li id="5822" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">我们可以看到我们的数据只有一个名为<strong class="ig hi">文章</strong>的列，有11992个条目。</li></ul><figure class="kp kq kr ks fd ld er es paragraph-image"><div class="er es lt"><img src="../Images/0aed23ae8b0471270b3f295824182c2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/0*uXNIeJm2LrL0fRxR.png"/></div></figure><h2 id="5913" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">步骤4-创建我们数据的文档术语矩阵。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="4130" class="kb je hh ku b fi ky kz l la lb">cv = CountVectorizer(max_df=0.95,min_df=2,stop_words='english')<br/>dtm = cv.fit_transform(articles['Article'])<br/>dtm.shape</span></pre><ul class=""><li id="970e" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">这里我们使用<a class="ae jc" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> CountVectorizer </a>将我们的文档转换成字数数组。</li><li id="57ef" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated">在这里，我们可以看到我们的dtm具有(11992，54777)的形状，其中11992表示我们的数据集中文档的数量，54777表示我们的总词汇表中不同单词的数量。</li></ul><figure class="kp kq kr ks fd ld er es paragraph-image"><div class="er es lz"><img src="../Images/e748c1ab9e2104058a94bb78198886b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/0*YNOIOS6r4aYWN0tb.png"/></div></figure><h2 id="5603" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">步骤5-初始化潜在的狄利克雷分配对象。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="d31b" class="kb je hh ku b fi ky kz l la lb">LDA = LatentDirichletAllocation(n_components=7,random_state=42)<br/>topic_results = LDA.fit_transform(dtm)<br/>LDA.components_.shape</span></pre><ul class=""><li id="ebbf" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">让我们初始化<a class="ae jc" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html" rel="noopener ugc nofollow" target="_blank">LatentDirichletAllocation</a>对象。</li><li id="aa22" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated">将此对象放在我们上面创建的文档术语矩阵中。</li><li id="bd6d" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated">检查它的形状。</li><li id="6886" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated">我们可以看到LDA组件的形状是(7，54777)，其中7是组件的数量，54777是词汇的大小。</li></ul><figure class="kp kq kr ks fd ld er es paragraph-image"><div class="er es ma"><img src="../Images/7c38fda1e4bcf2e26f8c4f10015f2290.png" data-original-src="https://miro.medium.com/v2/resize:fit:250/format:webp/0*OYrluX8fTB4jDtsK.png"/></div></figure><h2 id="c811" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">步骤6-打印将要进行聚类的特征/单词的列表。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="47ea" class="kb je hh ku b fi ky kz l la lb">for i,arr in enumerate(LDA.components_):<br/>    <br/>    print(f'TOP 15 WORDS FOR TOPIC #{i}')<br/>    print([cv.get_feature_names()[i] for i in arr.argsort()[-15:]]) <br/>    print('\n\n')</span></pre><ul class=""><li id="a68b" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated"><strong class="ig hi"> arr.argsort() </strong>将根据单词在特定主题的文档中出现的概率，以升序对单词进行排序。我们采用了最后15个单词，这意味着15个最有可能出现在该主题中的单词。</li><li id="236f" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated"><strong class="ig hi"> cv.get_feature_names </strong>只是我们语料库中所有单词的列表</li><li id="f084" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated">看，<strong class="ig hi">话题#0 </strong>的前15个单词是公司、金钱、年百分比等。看来是金融集团。</li><li id="e63a" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated"><strong class="ig hi">话题#1 </strong>好像是政治团体。</li><li id="23ab" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated"><strong class="ig hi">话题#3 </strong>好像是健康话题。</li><li id="9240" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated">T21看起来是一个教育团体。</li></ul><figure class="kp kq kr ks fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mb"><img src="../Images/f29e7edcaaa18ea776874d0079ac41f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Fnva0ZDIQ49O0NJD.png"/></div></div></figure><h2 id="e754" class="kb je hh bd jf kc kd ke jj kf kg kh jn ip ki kj jr it kk kl jv ix km kn jz ko bi translated">第7步—最终结果。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="1e6d" class="kb je hh ku b fi ky kz l la lb">articles[‘topic’] = topic_results.argmax(axis=1)<br/>articles</span></pre><ul class=""><li id="42e2" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">最后给文档指定主题号。</li></ul><figure class="kp kq kr ks fd ld er es paragraph-image"><div class="er es mc"><img src="../Images/604982dd62a2c9b0f8cf75ce6d27b84f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/0*-E3uDd4UwI_XjwI8.png"/></div></figure><p id="11f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果对这个话题有任何疑问，请通过电子邮件或LinkedIn联系我。我已经尽力解释这个代码了。</p><p id="be6a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="md">探索更多机器学习、深度学习、计算机视觉、NLP、Flask项目访问我的博客— </em> </strong> <a class="ae jc" href="https://machinelearningprojects.net/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="md">机器学习项目</em> </strong> </a></p><p id="15b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">如需进一步的代码解释和源代码，请访问此处</strong>—<a class="ae jc" href="https://machinelearningprojects.net/latent-dirichlet-allocation/" rel="noopener ugc nofollow" target="_blank">https://machine learning projects . net/latent-Dirichlet-allocation/</a></p><p id="7636" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="md">所以这就是我写给这个博客的所有内容，感谢你阅读它，我希望你在阅读完这篇文章后会有所收获，直到下一次👋… </em></p><p id="75d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="md">看我以前的帖子:</em> </strong> <a class="ae jc" href="https://machinelearningprojects.net/words-to-vectors-using-spacy/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="md">用SPACY的话来向量——证明国王-男人+女人=女王</em> </strong> </a></p><div class="me mf ez fb mg mh"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv li mh"/></div></div></a></div></div></div>    
</body>
</html>
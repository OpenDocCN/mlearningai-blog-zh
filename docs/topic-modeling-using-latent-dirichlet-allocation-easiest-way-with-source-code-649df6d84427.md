# ä½¿ç”¨æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…çš„ä¸»é¢˜å»ºæ¨¡â€”â€”æœ€ç®€å•çš„æ–¹æ³•â€”â€”å¸¦æºä»£ç 

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/topic-modeling-using-latent-dirichlet-allocation-easiest-way-with-source-code-649df6d84427?source=collection_archive---------7----------------------->

æ‰€ä»¥åœ¨ä»Šå¤©çš„åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨[æ½œåœ¨çš„ç‹„åˆ©å…‹é›·åˆ†é…](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)æ¥æ‰§è¡Œä¸»é¢˜å»ºæ¨¡ã€‚æˆ‘ä»¬åœ¨ä¸»é¢˜å»ºæ¨¡ä¸­æ‰€åšçš„æ˜¯è¯•å›¾æ ¹æ®ä¸€äº›ç›¸ä¼¼çš„å•è¯å°†ä¸åŒçš„å¯¹è±¡(åœ¨æœ¬ä¾‹ä¸­æ˜¯æ–‡æ¡£)ç»„åˆåœ¨ä¸€èµ·ã€‚è¿™æ„å‘³ç€å¦‚æœä¸¤ä¸ªæ–‡æ¡£åŒ…å«ç›¸ä¼¼çš„å•è¯ï¼Œé‚£ä¹ˆå®ƒä»¬å¾ˆæœ‰å¯èƒ½å±äºåŒä¸€ç±»åˆ«ã€‚æ‰€ä»¥ä¸ç”¨æµªè´¹ä»»ä½•æ—¶é—´ã€‚

ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹è§†é¢‘â€”ã€https://youtu.be/a9WGoIiWwXg 

# è®©æˆ‘ä»¬å¼€å§‹å§â€¦

## æ­¥éª¤ 1-å¯¼å…¥æ‰€éœ€çš„åº“ã€‚

```
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
```

## æ­¥éª¤ 2 â€”è¯»å–è¾“å…¥æ•°æ®ã€‚

```
articles = pd.read_csv('npr.csv')
articles.head()
```

![](img/e4b828093699c5996c43949265bf0eb2.png)

## æ­¥éª¤ 3-æ£€æŸ¥æˆ‘ä»¬æ•°æ®çš„ä¿¡æ¯ã€‚

```
articles.info()
```

*   æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ•°æ®åªæœ‰ä¸€ä¸ªåä¸º**æ–‡ç« **çš„åˆ—ï¼Œæœ‰ 11992 ä¸ªæ¡ç›®ã€‚

![](img/0aed23ae8b0471270b3f295824182c2e.png)

## æ­¥éª¤ 4-åˆ›å»ºæˆ‘ä»¬æ•°æ®çš„æ–‡æ¡£æœ¯è¯­çŸ©é˜µã€‚

```
cv = CountVectorizer(max_df=0.95,min_df=2,stop_words='english')
dtm = cv.fit_transform(articles['Article'])
dtm.shape
```

*   è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) å°†æˆ‘ä»¬çš„æ–‡æ¡£è½¬æ¢æˆå­—æ•°æ•°ç»„ã€‚
*   åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„ dtm å…·æœ‰(11992ï¼Œ54777)çš„å½¢çŠ¶ï¼Œå…¶ä¸­ 11992 è¡¨ç¤ºæˆ‘ä»¬çš„æ•°æ®é›†ä¸­æ–‡æ¡£çš„æ•°é‡ï¼Œ54777 è¡¨ç¤ºæˆ‘ä»¬çš„æ€»è¯æ±‡è¡¨ä¸­ä¸åŒå•è¯çš„æ•°é‡ã€‚

![](img/e748c1ab9e2104058a94bb78198886b5.png)

## æ­¥éª¤ 5-åˆå§‹åŒ–æ½œåœ¨çš„ç‹„åˆ©å…‹é›·åˆ†é…å¯¹è±¡ã€‚

```
LDA = LatentDirichletAllocation(n_components=7,random_state=42)
topic_results = LDA.fit_transform(dtm)
LDA.components_.shape
```

*   è®©æˆ‘ä»¬åˆå§‹åŒ–[LatentDirichletAllocation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)å¯¹è±¡ã€‚
*   å°†æ­¤å¯¹è±¡æ”¾åœ¨æˆ‘ä»¬ä¸Šé¢åˆ›å»ºçš„æ–‡æ¡£æœ¯è¯­çŸ©é˜µä¸­ã€‚
*   æ£€æŸ¥å®ƒçš„å½¢çŠ¶ã€‚
*   æˆ‘ä»¬å¯ä»¥çœ‹åˆ° LDA ç»„ä»¶çš„å½¢çŠ¶æ˜¯(7ï¼Œ54777)ï¼Œå…¶ä¸­ 7 æ˜¯ç»„ä»¶çš„æ•°é‡ï¼Œ54777 æ˜¯è¯æ±‡çš„å¤§å°ã€‚

![](img/7c38fda1e4bcf2e26f8c4f10015f2290.png)

## æ­¥éª¤ 6-æ‰“å°å°†è¦è¿›è¡Œèšç±»çš„ç‰¹å¾/å•è¯çš„åˆ—è¡¨ã€‚

```
for i,arr in enumerate(LDA.components_):

    print(f'TOP 15 WORDS FOR TOPIC #{i}')
    print([cv.get_feature_names()[i] for i in arr.argsort()[-15:]]) 
    print('\n\n')
```

*   **arr.argsort()** å°†æ ¹æ®å•è¯åœ¨ç‰¹å®šä¸»é¢˜çš„æ–‡æ¡£ä¸­å‡ºç°çš„æ¦‚ç‡ï¼Œä»¥å‡åºå¯¹å•è¯è¿›è¡Œæ’åºã€‚æˆ‘ä»¬é‡‡ç”¨äº†æœ€å 15 ä¸ªå•è¯ï¼Œè¿™æ„å‘³ç€ 15 ä¸ªæœ€æœ‰å¯èƒ½å‡ºç°åœ¨è¯¥ä¸»é¢˜ä¸­çš„å•è¯ã€‚
*   **cv.get_feature_names** åªæ˜¯æˆ‘ä»¬è¯­æ–™åº“ä¸­æ‰€æœ‰å•è¯çš„åˆ—è¡¨
*   çœ‹ï¼Œ**è¯é¢˜#0** çš„å‰ 15 ä¸ªå•è¯æ˜¯å…¬å¸ã€é‡‘é’±ã€å¹´ç™¾åˆ†æ¯”ç­‰ã€‚çœ‹æ¥æ˜¯é‡‘èé›†å›¢ã€‚
*   **è¯é¢˜#1** å¥½åƒæ˜¯æ”¿æ²»å›¢ä½“ã€‚
*   **è¯é¢˜#3** å¥½åƒæ˜¯å¥åº·è¯é¢˜ã€‚
*   T21 çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªæ•™è‚²å›¢ä½“ã€‚

![](img/f29e7edcaaa18ea776874d0079ac41f1.png)

## ç¬¬ 7 æ­¥â€”æœ€ç»ˆç»“æœã€‚

```
articles[â€˜topicâ€™] = topic_results.argmax(axis=1)
articles
```

*   æœ€åç»™æ–‡æ¡£æŒ‡å®šä¸»é¢˜å·ã€‚

![](img/604982dd62a2c9b0f8cf75ce6d27b84f.png)

å¦‚æœå¯¹è¿™ä¸ªè¯é¢˜æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·é€šè¿‡ç”µå­é‚®ä»¶æˆ– LinkedIn è”ç³»æˆ‘ã€‚æˆ‘å·²ç»å°½åŠ›è§£é‡Šè¿™ä¸ªä»£ç äº†ã€‚

***æ¢ç´¢æ›´å¤šæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€NLPã€Flask é¡¹ç›®è®¿é—®æˆ‘çš„åšå®¢â€”*** [***æœºå™¨å­¦ä¹ é¡¹ç›®***](https://machinelearningprojects.net/)

**å¦‚éœ€è¿›ä¸€æ­¥çš„ä»£ç è§£é‡Šå’Œæºä»£ç ï¼Œè¯·è®¿é—®æ­¤å¤„**â€”[https://machine learning projects . net/latent-Dirichlet-allocation/](https://machinelearningprojects.net/latent-dirichlet-allocation/)

*æ‰€ä»¥è¿™å°±æ˜¯æˆ‘å†™ç»™è¿™ä¸ªåšå®¢çš„æ‰€æœ‰å†…å®¹ï¼Œæ„Ÿè°¢ä½ é˜…è¯»å®ƒï¼Œæˆ‘å¸Œæœ›ä½ åœ¨é˜…è¯»å®Œè¿™ç¯‡æ–‡ç« åä¼šæœ‰æ‰€æ”¶è·ï¼Œç›´åˆ°ä¸‹ä¸€æ¬¡ğŸ‘‹â€¦*

***çœ‹æˆ‘ä»¥å‰çš„å¸–å­:*** [***ç”¨ SPACY çš„è¯æ¥å‘é‡â€”â€”è¯æ˜å›½ç‹-ç”·äºº+å¥³äºº=å¥³ç‹***](https://machinelearningprojects.net/words-to-vectors-using-spacy/)

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai æäº¤å»ºè®®

### å¦‚ä½•æˆä¸º Mlearning.ai ä¸Šçš„ä½œå®¶

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
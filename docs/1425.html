<html>
<head>
<title>Font Recognition with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的字体识别</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/font-recognition-with-deep-learning-e6ad9c344048?source=collection_archive---------0-----------------------#2021-12-14">https://medium.com/mlearning-ai/font-recognition-with-deep-learning-e6ad9c344048?source=collection_archive---------0-----------------------#2021-12-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/05944629a63cf5a4941e3e2cec41ba16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXrNcJxrwmM1u1VJ4TBmZQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">A Calligraphy A being Scanned.</figcaption></figure><p id="b574" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这是基于DeepFont的<a class="ae jr" href="https://arxiv.org/pdf/1507.03196v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，一种由<strong class="iv hi"> <em class="js"> Adobe创造的技术。Inc </em> </strong>利用深度学习从图像中检测字体。他们将他们的工作作为面向公众的论文发表，实现的代码也是同样的衍生。这篇博客在概述代码的同时讨论了相关的步骤。</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jt"><img src="../Images/b6b0e86a907c65eaa4e90e5a9ab250dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jyCDtrUdWoo4UYbU.png"/></div></div></figure><h2 id="38c0" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">DeepFont的要点:</h2><ul class=""><li id="0933" class="kt ku hh iv b iw kv ja kw je kx ji ky jm kz jq la lb lc ld bi translated">它在AdobeVFR数据集上训练，该数据集包含<em class="js"> 2383字体</em>类别！</li><li id="261f" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">其域改编CNN <a class="ae jr" href="https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f" rel="noopener" target="_blank">(点击此处了解更多)</a></li><li id="b4ad" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">它的学习基于模型压缩</li></ul><p id="793a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在我们开始之前，让我们从我们需要什么库开始。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="fd0f" class="jy jz hh lk b fi lo lp l lq lr"><strong class="lk hi">from</strong> matplotlib.pyplot <strong class="lk hi">import</strong> imshow<br/><strong class="lk hi">import</strong> matplotlib.cm <strong class="lk hi">as</strong> cm<br/><strong class="lk hi">import</strong> matplotlib.pylab <strong class="lk hi">as</strong> plt<br/><strong class="lk hi">from</strong> keras.preprocessing.image <strong class="lk hi">import</strong> ImageDataGenerator<br/><strong class="lk hi">import</strong> numpy <strong class="lk hi">as</strong> np<br/><strong class="lk hi">import</strong> PIL<br/><strong class="lk hi">from</strong> PIL <strong class="lk hi">import</strong> ImageFilter<br/><strong class="lk hi">import</strong> cv2<br/><strong class="lk hi">import</strong> itertools<br/><strong class="lk hi">import</strong> random<br/><strong class="lk hi">import</strong> keras<br/><strong class="lk hi">import</strong> imutils<br/><strong class="lk hi">from</strong> imutils <strong class="lk hi">import</strong> paths<br/><strong class="lk hi">import</strong> os<br/><strong class="lk hi">from</strong> keras <strong class="lk hi">import</strong> optimizers<br/><strong class="lk hi">from</strong> keras.preprocessing.image <strong class="lk hi">import</strong> img_to_array<br/><strong class="lk hi">from</strong> sklearn.model_selection <strong class="lk hi">import</strong> train_test_split<br/><strong class="lk hi">from</strong> keras.utils <strong class="lk hi">import</strong> to_categorical<br/><strong class="lk hi">from</strong> keras <strong class="lk hi">import</strong> callbacks<br/><strong class="lk hi">from</strong> keras.models <strong class="lk hi">import</strong> Sequential<br/><strong class="lk hi">from</strong> keras.layers.normalization <strong class="lk hi">import</strong> BatchNormalization<br/><strong class="lk hi">from</strong> keras.layers <strong class="lk hi">import</strong> Dense, Dropout, Flatten<br/><strong class="lk hi">from</strong> keras.layers <strong class="lk hi">import</strong> Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose<br/><strong class="lk hi">from</strong> keras <strong class="lk hi">import</strong> backend <strong class="lk hi">as</strong> K<br/><br/><strong class="lk hi">%matplotlib</strong> inline</span></pre><p id="1364" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因为我们将操作图像，所以让我们使用PIL (Python图像库)并创建一个从目录中读取图像并根据需要调整大小的函数。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="f25c" class="jy jz hh lk b fi lo lp l lq lr"><strong class="lk hi">def</strong> pil_image(img_path):<br/>    pil_im <strong class="lk hi">=</strong>PIL<strong class="lk hi">.</strong>Image<strong class="lk hi">.</strong>open(img_path)<strong class="lk hi">.</strong>convert('L')<br/>    pil_im<strong class="lk hi">=</strong>pil_im<strong class="lk hi">.</strong>resize((105,105))<br/>    <em class="js">#imshow(np.asarray(pil_im))</em><br/>    <strong class="lk hi">return</strong> pil_im</span></pre><p id="6db9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们现在将整个工作分成4个步骤或阶段。</p><h2 id="b687" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">步骤1:数据集</h2><p id="e532" class="pw-post-body-paragraph it iu hh iv b iw kv iy iz ja kw jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">由于AdobeVFR Dataset<a class="ae jr" href="https://www.dropbox.com/sh/o320sowg790cxpe/AADDmdwQ08GbciWnaC20oAmna?dl=0" rel="noopener ugc nofollow" target="_blank">datalink</a>非常大，并且包含许多字体类别，简单的方法是使用TextRecognitionDataGenerator<a class="ae jr" href="https://github.com/Belval/TextRecognitionDataGenerator" rel="noopener ugc nofollow" target="_blank">github</a>基于所需的字体补丁创建一个自定义数据集。</p><p id="27a3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">一旦你有了一套样品，你就可以开始了！</p><h2 id="84eb" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">步骤2:数据预处理</h2><p id="8fe8" class="pw-post-body-paragraph it iu hh iv b iw kv iy iz ja kw jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">字体不像物体，需要庞大的空间信息来分类它们的特征。为了识别非常微小的特征变化，DeepFont使用某些预处理技术，如下所示</p><ul class=""><li id="f0c2" class="kt ku hh iv b iw ix ja jb je lv ji lw jm lx jq la lb lc ld bi translated">噪音</li><li id="ec9f" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">虚化</li><li id="b22d" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">透视旋转</li><li id="313f" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">阴影(渐变照明)</li><li id="bbf2" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">可变字符间距</li><li id="74a1" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">可变纵横比</li></ul><p id="c611" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">基于这些——我们为每个增强步骤提供了<strong class="iv hi">函数</strong>:</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="22d4" class="jy jz hh lk b fi lo lp l lq lr"><strong class="lk hi">def</strong> noise_image(pil_im):<br/>    <em class="js"># Adding Noise to image</em><br/>    img_array <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>asarray(pil_im)<br/>    mean <strong class="lk hi">=</strong> 0.0   <em class="js"># some constant</em><br/>    std <strong class="lk hi">=</strong> 5   <em class="js"># some constant (standard deviation)</em><br/>    noisy_img <strong class="lk hi">=</strong> img_array <strong class="lk hi">+</strong> np<strong class="lk hi">.</strong>random<strong class="lk hi">.</strong>normal(mean, std, img_array<strong class="lk hi">.</strong>shape)<br/>    noisy_img_clipped <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>clip(noisy_img, 0, 255)<br/>    noise_img <strong class="lk hi">=</strong> PIL<strong class="lk hi">.</strong>Image<strong class="lk hi">.</strong>fromarray(np<strong class="lk hi">.</strong>uint8(noisy_img_clipped))<br/>    noise_img<strong class="lk hi">=</strong>noise_img<strong class="lk hi">.</strong>resize((105,105))<br/>    <strong class="lk hi">return</strong> noise_img<br/></span><span id="e854" class="jy jz hh lk b fi ly lp l lq lr"><strong class="lk hi">def</strong> blur_image(pil_im):<br/>    <em class="js">#Adding Blur to image </em><br/>    blur_img <strong class="lk hi">=</strong> pil_im<strong class="lk hi">.</strong>filter(ImageFilter<strong class="lk hi">.</strong>GaussianBlur(radius<strong class="lk hi">=</strong>3))<br/>    blur_img<strong class="lk hi">=</strong>blur_img<strong class="lk hi">.</strong>resize((105,105))<br/>    <strong class="lk hi">return</strong> blur_img<br/></span><span id="0105" class="jy jz hh lk b fi ly lp l lq lr"><strong class="lk hi">def</strong> affine_rotation(img):<br/>    rows, columns <strong class="lk hi">=</strong> img<strong class="lk hi">.</strong>shape<br/><br/>    point1 <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>float32([[10, 10], [30, 10], [10, 30]])<br/>    point2 <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>float32([[20, 15], [40, 10], [20, 40]])<br/><br/>    A <strong class="lk hi">=</strong> cv2<strong class="lk hi">.</strong>getAffineTransform(point1, point2)<br/><br/>    output <strong class="lk hi">=</strong> cv2<strong class="lk hi">.</strong>warpAffine(img, A, (columns, rows))<br/>    affine_img <strong class="lk hi">=</strong> PIL<strong class="lk hi">.</strong>Image<strong class="lk hi">.</strong>fromarray(np<strong class="lk hi">.</strong>uint8(output))<br/>    affine_img<strong class="lk hi">=</strong>affine_img<strong class="lk hi">.</strong>resize((105,105))<br/>    <strong class="lk hi">return</strong> affine_img<br/></span><span id="e7c6" class="jy jz hh lk b fi ly lp l lq lr"><strong class="lk hi">def</strong> gradient_fill(image):<br/>    laplacian <strong class="lk hi">=</strong> cv2<strong class="lk hi">.</strong>Laplacian(image,cv2<strong class="lk hi">.</strong>CV_64F)<br/>    laplacian <strong class="lk hi">=</strong> cv2<strong class="lk hi">.</strong>resize(laplacian, (105, 105))<br/>    <strong class="lk hi">return</strong> laplacian</span></pre><p id="25cc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在，一旦我们准备好这些，我们就可以准备数据集了。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="361b" class="jy jz hh lk b fi lo lp l lq lr">data_path <strong class="lk hi">=</strong> "font_patch/" #Link to all samples created<br/>data<strong class="lk hi">=</strong>[]<br/>labels<strong class="lk hi">=</strong>[]<br/>imagePaths <strong class="lk hi">=</strong> sorted(list(paths<strong class="lk hi">.</strong>list_images(data_path)))<br/>random<strong class="lk hi">.</strong>seed(42)<br/>random<strong class="lk hi">.</strong>shuffle(imagePaths)</span><span id="9f18" class="jy jz hh lk b fi ly lp l lq lr">#These were the 5 fonts taken as sample</span><span id="c800" class="jy jz hh lk b fi ly lp l lq lr"><strong class="lk hi">def</strong> conv_label(label):<br/>    <strong class="lk hi">if</strong> label <strong class="lk hi">==</strong> 'Lato':<br/>        <strong class="lk hi">return</strong> 0<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 'Raleway':<br/>        <strong class="lk hi">return</strong> 1<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 'Roboto':<br/>        <strong class="lk hi">return</strong> 2<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 'Sansation':<br/>        <strong class="lk hi">return</strong> 3<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 'Walkway':<br/>        <strong class="lk hi">return</strong> 4</span><span id="9b96" class="jy jz hh lk b fi ly lp l lq lr">augument<strong class="lk hi">=</strong>["blur","noise","affine","gradient"]<br/>a<strong class="lk hi">=</strong>itertools<strong class="lk hi">.</strong>combinations(augument, 4)<br/><br/><strong class="lk hi">for</strong> i <strong class="lk hi">in</strong> list(a): <br/>    print(list(i))</span></pre><p id="0eae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在，基于a，我们使用刚刚生成的组合对图像进行迭代，每次都追加输出数据和标签。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="2778" class="jy jz hh lk b fi lo lp l lq lr">counter<strong class="lk hi">=</strong>0<br/><strong class="lk hi">for</strong> imagePath <strong class="lk hi">in</strong> imagePaths:<br/>    label <strong class="lk hi">=</strong> imagePath<strong class="lk hi">.</strong>split(os<strong class="lk hi">.</strong>path<strong class="lk hi">.</strong>sep)[<strong class="lk hi">-</strong>2]<br/>    label <strong class="lk hi">=</strong> conv_label(label)<br/>    pil_img <strong class="lk hi">=</strong> pil_image(imagePath)<br/>    <em class="js">#imshow(pil_img)</em><br/>    <br/>    <em class="js"># Adding original image</em><br/>    org_img <strong class="lk hi">=</strong> img_to_array(pil_img)<br/>    <em class="js">#print(org_img.shape)</em><br/>    data<strong class="lk hi">.</strong>append(org_img)<br/>    labels<strong class="lk hi">.</strong>append(label)<br/>    <br/>    augument<strong class="lk hi">=</strong>["noise","blur","affine","gradient"]<br/>    <strong class="lk hi">for</strong> l <strong class="lk hi">in</strong> range(0,len(augument)):<br/>    <br/>        a<strong class="lk hi">=</strong>itertools<strong class="lk hi">.</strong>combinations(augument, l<strong class="lk hi">+</strong>1)<br/><br/>        <strong class="lk hi">for</strong> i <strong class="lk hi">in</strong> list(a): <br/>            combinations<strong class="lk hi">=</strong>list(i)<br/>            print(len(combinations))<br/>            temp_img <strong class="lk hi">=</strong> pil_img<br/>            <strong class="lk hi">for</strong> j <strong class="lk hi">in</strong> combinations:<br/>            <br/>                <strong class="lk hi">if</strong> j <strong class="lk hi">==</strong> 'noise':<br/>                    <em class="js"># Adding Noise image</em><br/>                    temp_img <strong class="lk hi">=</strong> noise_image(temp_img)<br/>                    <br/>                <strong class="lk hi">elif</strong> j <strong class="lk hi">==</strong> 'blur':<br/>                    <em class="js"># Adding Blur image</em><br/>                    temp_img <strong class="lk hi">=</strong> blur_image(temp_img)<br/>                    <em class="js">#imshow(blur_img)</em><br/>                    <br/>    <br/>                <strong class="lk hi">elif</strong> j <strong class="lk hi">==</strong> 'affine':<br/>                    open_cv_affine <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>array(pil_img)<br/>                    <em class="js"># Adding affine rotation image</em><br/>                    temp_img <strong class="lk hi">=</strong> affine_rotation(open_cv_affine)<br/><br/>                <strong class="lk hi">elif</strong> j <strong class="lk hi">==</strong> 'gradient':<br/>                    open_cv_gradient <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>array(pil_img)<br/>                    <em class="js"># Adding gradient image</em><br/>                    temp_img <strong class="lk hi">=</strong> gradient_fill(open_cv_gradient)<br/>  <br/>            temp_img <strong class="lk hi">=</strong> img_to_array(temp_img)<br/>            data<strong class="lk hi">.</strong>append(temp_img)<br/>            labels<strong class="lk hi">.</strong>append(label)</span></pre><p id="8bda" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们的下一步非常简单——我们对数据进行分区，这样我们可以将75%的数据用于训练，剩下的25%用于测试。然后我们将标签从整数转换成向量。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="cf88" class="jy jz hh lk b fi lo lp l lq lr">data <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>asarray(data, dtype<strong class="lk hi">=</strong>"float") <strong class="lk hi">/</strong> 255.0<br/>labels <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>array(labels)<br/>print("Success")<br/><br/>(trainX, testX, trainY, testY) <strong class="lk hi">=</strong> train_test_split(data,<br/>	labels, test_size<strong class="lk hi">=</strong>0.25, random_state<strong class="lk hi">=</strong>42)</span><span id="6cc5" class="jy jz hh lk b fi ly lp l lq lr">trainY <strong class="lk hi">=</strong> to_categorical(trainY, num_classes<strong class="lk hi">=</strong>5)<br/>testY <strong class="lk hi">=</strong> to_categorical(testY, num_classes<strong class="lk hi">=</strong>5)</span><span id="6d7c" class="jy jz hh lk b fi ly lp l lq lr">aug <strong class="lk hi">=</strong> ImageDataGenerator(rotation_range<strong class="lk hi">=</strong>30, width_shift_range<strong class="lk hi">=</strong>0.1,height_shift_range<strong class="lk hi">=</strong>0.1, shear_range<strong class="lk hi">=</strong>0.2, zoom_range<strong class="lk hi">=</strong>0.2,horizontal_flip<strong class="lk hi">=True</strong>)</span></pre><h2 id="a4b0" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">步骤3:了解CNN架构</h2><p id="eac4" class="pw-post-body-paragraph it iu hh iv b iw kv iy iz ja kw jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">与其他图像分类CNN网络不同，它们遵循一个新的模式，像两个子网络，</p><ul class=""><li id="0196" class="kt ku hh iv b iw ix ja jb je lv ji lw jm lx jq la lb lc ld bi translated"><em class="js">低级子网络</em>:从合成和真实世界数据的合成集中学习。</li><li id="8f50" class="kt ku hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated"><em class="js">高级子网</em>:从低级特征中学习深度分类器，了解更多细节和澄清，请阅读他们的<a class="ae jr" href="https://arxiv.org/pdf/1507.03196v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li></ul><p id="6e47" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们创建论文中给出的模型，并对其进行编译。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="03c5" class="jy jz hh lk b fi lo lp l lq lr">K.set_image_data_format('channels_last')</span><span id="f0f6" class="jy jz hh lk b fi ly lp l lq lr"><strong class="lk hi">def</strong> create_model():<br/>  model<strong class="lk hi">=</strong>Sequential()<br/><br/>  <em class="js"># Cu Layers </em><br/>  model<strong class="lk hi">.</strong>add(Conv2D(64, kernel_size<strong class="lk hi">=</strong>(48, 48), activation<strong class="lk hi">=</strong>'relu', input_shape<strong class="lk hi">=</strong>(105,105,1)))<br/>  model<strong class="lk hi">.</strong>add(BatchNormalization())<br/>  model<strong class="lk hi">.</strong>add(MaxPooling2D(pool_size<strong class="lk hi">=</strong>(2, 2)))<br/><br/>  model<strong class="lk hi">.</strong>add(Conv2D(128, kernel_size<strong class="lk hi">=</strong>(24, 24), activation<strong class="lk hi">=</strong>'relu'))<br/>  model<strong class="lk hi">.</strong>add(BatchNormalization())<br/>  model<strong class="lk hi">.</strong>add(MaxPooling2D(pool_size<strong class="lk hi">=</strong>(2, 2)))<br/><br/>  model<strong class="lk hi">.</strong>add(Conv2DTranspose(128, (24,24), strides <strong class="lk hi">=</strong> (2,2), activation <strong class="lk hi">=</strong> 'relu', padding<strong class="lk hi">=</strong>'same', kernel_initializer<strong class="lk hi">=</strong>'uniform'))<br/>  model<strong class="lk hi">.</strong>add(UpSampling2D(size<strong class="lk hi">=</strong>(2, 2)))<br/><br/>  model<strong class="lk hi">.</strong>add(Conv2DTranspose(64, (12,12), strides <strong class="lk hi">=</strong> (2,2), activation <strong class="lk hi">=</strong> 'relu', padding<strong class="lk hi">=</strong>'same', kernel_initializer<strong class="lk hi">=</strong>'uniform'))<br/>  model<strong class="lk hi">.</strong>add(UpSampling2D(size<strong class="lk hi">=</strong>(2, 2)))<br/><br/>  <em class="js">#Cs Layers</em><br/>  model<strong class="lk hi">.</strong>add(Conv2D(256, kernel_size<strong class="lk hi">=</strong>(12, 12), activation<strong class="lk hi">=</strong>'relu'))<br/><br/>  model<strong class="lk hi">.</strong>add(Conv2D(256, kernel_size<strong class="lk hi">=</strong>(12, 12), activation<strong class="lk hi">=</strong>'relu'))<br/><br/>  model<strong class="lk hi">.</strong>add(Conv2D(256, kernel_size<strong class="lk hi">=</strong>(12, 12), activation<strong class="lk hi">=</strong>'relu'))<br/><br/>  model<strong class="lk hi">.</strong>add(Flatten())<br/><br/>  model<strong class="lk hi">.</strong>add(Dense(4096, activation<strong class="lk hi">=</strong>'relu'))<br/><br/>  model<strong class="lk hi">.</strong>add(Dropout(0.5))<br/><br/>  model<strong class="lk hi">.</strong>add(Dense(4096,activation<strong class="lk hi">=</strong>'relu'))<br/><br/>  model<strong class="lk hi">.</strong>add(Dropout(0.5))<br/><br/>  model<strong class="lk hi">.</strong>add(Dense(2383,activation<strong class="lk hi">=</strong>'relu'))<br/><br/>  model<strong class="lk hi">.</strong>add(Dense(5, activation<strong class="lk hi">=</strong>'softmax'))<br/> <br/>  <strong class="lk hi">return</strong> model</span><span id="6c35" class="jy jz hh lk b fi ly lp l lq lr"><br/>batch_size = 128<br/>epochs = 50<br/>model= create_model()<br/>sgd = tensorflow.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)<br/>model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])</span><span id="b39f" class="jy jz hh lk b fi ly lp l lq lr">early_stopping<strong class="lk hi">=</strong>callbacks<strong class="lk hi">.</strong>EarlyStopping(monitor<strong class="lk hi">=</strong>'val_loss', min_delta<strong class="lk hi">=</strong>0, patience<strong class="lk hi">=</strong>10, verbose<strong class="lk hi">=</strong>0, mode<strong class="lk hi">=</strong>'min')<br/><br/>filepath<strong class="lk hi">=</strong>"top_model.h5"<br/><br/>checkpoint <strong class="lk hi">=</strong> callbacks<strong class="lk hi">.</strong>ModelCheckpoint(filepath, monitor<strong class="lk hi">=</strong>'val_loss', verbose<strong class="lk hi">=</strong>1, save_best_only<strong class="lk hi">=True</strong>, mode<strong class="lk hi">=</strong>'min')<br/><br/>callbacks_list <strong class="lk hi">=</strong> [early_stopping,checkpoint]</span></pre><p id="2437" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们现在拟合模型并测试损失和准确性。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="78b6" class="jy jz hh lk b fi lo lp l lq lr">model<strong class="lk hi">.</strong>fit(trainX, trainY,shuffle<strong class="lk hi">=True</strong>,<br/>          batch_size<strong class="lk hi">=</strong>batch_size,<br/>          epochs<strong class="lk hi">=</strong>epochs,<br/>          verbose<strong class="lk hi">=</strong>1,<br/>          validation_data<strong class="lk hi">=</strong>(testX, testY),callbacks<strong class="lk hi">=</strong>callbacks_list)</span><span id="0128" class="jy jz hh lk b fi ly lp l lq lr">score <strong class="lk hi">=</strong> model<strong class="lk hi">.</strong>evaluate(testX, testY, verbose<strong class="lk hi">=</strong>0)<br/>print('Test loss:', score[0])<br/>print('Test accuracy:', score[1])</span></pre><p id="fd0e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="js">测试损耗:0.1341324895620346 </em> </strong></p><p id="0b98" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="js">测试精度:0.6410256624221802 </em> </strong></p><h2 id="9ad8" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">第四步:框架</h2><p id="47b3" class="pw-post-body-paragraph it iu hh iv b iw kv iy iz ja kw jc jd je ls jg jh ji lt jk jl jm lu jo jp jq ha bi translated">作为原型，我们使用Keras来构建整个管道。</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="7c7b" class="jy jz hh lk b fi lo lp l lq lr"><strong class="lk hi">from</strong> keras.models <strong class="lk hi">import</strong> load_model<br/>model <strong class="lk hi">=</strong> load_model('top_model.h5')<br/>score <strong class="lk hi">=</strong> model<strong class="lk hi">.</strong>evaluate(testX, testY, verbose<strong class="lk hi">=</strong>0)<br/>print('Test loss:', score[0])<br/>print('Test accuracy:', score[1])</span></pre><p id="4fc6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="js">测试损耗:0.12708203494548798 </em> </strong></p><p id="a869" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="js">测试精度:0.583333134651184</em></strong></p><p id="6dfe" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我们取一个样本图像，试着做同样的事情并显示结果！</p><pre class="ju jv jw jx fd lj lk ll lm aw ln bi"><span id="cff6" class="jy jz hh lk b fi lo lp l lq lr">img_path="sample/sample.jpg"<br/>pil_im =PIL.Image.open(img_path).convert('L')<br/>pil_im=blur_image(pil_im)<br/>org_img = img_to_array(pil_im)</span><span id="0ae0" class="jy jz hh lk b fi ly lp l lq lr"><strong class="lk hi">def</strong> rev_conv_label(label):<br/>    <strong class="lk hi">if</strong> label <strong class="lk hi">==</strong> 0 :<br/>        <strong class="lk hi">return</strong> 'Lato'<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 1:<br/>        <strong class="lk hi">return</strong> 'Raleway'<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 2 :<br/>        <strong class="lk hi">return</strong> 'Roboto'<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 3 :<br/>        <strong class="lk hi">return</strong> 'Sansation'<br/>    <strong class="lk hi">elif</strong> label <strong class="lk hi">==</strong> 4:<br/>        <strong class="lk hi">return</strong> 'Walkway'</span><span id="41ee" class="jy jz hh lk b fi ly lp l lq lr">data<strong class="lk hi">=</strong>[]<br/>data<strong class="lk hi">.</strong>append(org_img)<br/>data <strong class="lk hi">=</strong> np<strong class="lk hi">.</strong>asarray(data, dtype<strong class="lk hi">=</strong>"float") <strong class="lk hi">/</strong> 255.0</span><span id="b567" class="jy jz hh lk b fi ly lp l lq lr">y = model.predict(data)<br/>y = np.round(y).astype(int)</span><span id="9fe9" class="jy jz hh lk b fi ly lp l lq lr">label <strong class="lk hi">=</strong> rev_conv_label(y[0,0]))<br/>fig, ax <strong class="lk hi">=</strong> plt<strong class="lk hi">.</strong>subplots(1)<br/>ax<strong class="lk hi">.</strong>imshow(pil_im, interpolation<strong class="lk hi">=</strong>'nearest', cmap<strong class="lk hi">=</strong>cm<strong class="lk hi">.</strong>gray)<br/>ax<strong class="lk hi">.</strong>text(5, 5, label , bbox<strong class="lk hi">=</strong>{'facecolor': 'white', 'pad': 10})<br/>plt<strong class="lk hi">.</strong>show()</span></pre><figure class="ju jv jw jx fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/3c7df0a28c9ee6ef4258d8e44fdb5e16.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*zU82mjZnGeVeGjJbtmHSOA.png"/></div></figure><p id="bfa3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这就是所有的人！使用DeepFont进行字体识别。</p><div class="ma mb ez fb mc md"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="me ab dw"><div class="mf ab mg cl cj mh"><h2 class="bd hi fi z dy mi ea eb mj ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mk l"><h3 class="bd b fi z dy mi ea eb mj ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ml l"><p class="bd b fp z dy mi ea eb mj ed ef dx translated">medium.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr in md"/></div></div></a></div></div></div>    
</body>
</html>
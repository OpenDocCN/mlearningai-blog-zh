<html>
<head>
<title>Build your own AI-powered content generator with 7 lines of Python code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用7行Python代码构建您自己的人工智能内容生成器</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/build-your-own-ai-powered-content-generator-with-7-lines-of-python-code-a679e7d5a563?source=collection_archive---------0-----------------------#2022-08-16">https://medium.com/mlearning-ai/build-your-own-ai-powered-content-generator-with-7-lines-of-python-code-a679e7d5a563?source=collection_archive---------0-----------------------#2022-08-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/6cd46b83d063f5ee717a6d2794612346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-lvtQclOglMebO-3"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/es/@anniespratt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Annie Spratt</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="3bf5" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h1><p id="a945" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在本教程中，我们将使用GPT-尼奥创建我们自己的内容生成器，这是一个开源的免费替代品，可以替代<a class="ae it" href="https://openai.com" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi"> <em class="kq"> OpenAI的</em> </strong> </a> GPT-3。</p><p id="6691" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">GPT-3是一个基于深度学习的语言模型，仅在<strong class="ju hi"><em class="kq">1750亿个参数上进行训练。</em> </strong>由于其海量的训练参数，在多种自然语言处理任务上表现出色。该模型是大多数自然语言处理过程的理想模型，包括文本生成、情感分析和对话模型。</p><p id="930f" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">虽然它有很多优点，但该模型不是开源的，只能通过封闭的测试版获得。这意味着无论你是一个爱好者还是一个商业领袖，你都必须请求许可。</p><p id="729f" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">幸运的是，我们可以利用一个名为<strong class="ju hi"><em class="kq">【GPT-尼奥】</em>的GPT克隆体，它是由一个名为<em class="kq"/></strong><a class="ae it" href="https://www.eleuther.ai/projects/gpt-neo/" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kq">EleutherAI</em></strong></a><strong class="ju hi"><em class="kq">的组织构建的。我们将利用这个预先训练好的模型，因为许多开发者声称它几乎和GPT 3的达芬奇模型一样强大。</em> </strong> </p><h1 id="d286" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">PyTorch和变压器安装</h1><p id="85d9" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">作为默认的安装方法，您可以在anaconda提示符或cmd中复制并粘贴这段代码来安装<a class="ae it" href="https://pytorch.org" rel="noopener ugc nofollow" target="_blank"> <em class="kq"> PyTorch。</em> </a></p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="0964" class="lf iv hh lb b fi lg lh l li lj">pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html</span></pre><p id="9aec" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">接下来我们要做的是安装一个强大的自然语言处理库— <em class="kq"> transformers。变形金刚</em>包括不同的自然语言处理流水线。我们将使用文本生成管道。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="a5d3" class="lf iv hh lb b fi lg lh l li lj">pip install transformers</span></pre><p id="4b5e" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">现在我们已经安装了必要的工具，让我们继续下一步。</p><p id="bd64" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">打开Jupyter笔记本，导入变形金刚。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="671c" class="lf iv hh lb b fi lg lh l li lj">from transformers import pipeline</span></pre><h1 id="fafd" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">生成您的内容创建者</h1><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="b397" class="lf iv hh lb b fi lg lh l li lj">gen = pipeline('text-generation', model ='EleutherAI/gpt-neo-2.7B')</span></pre><p id="2184" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">此代码调用管道函数，指定其类型，并将预训练的定义为关键字参数。在我们的例子中，我们使用的是拥有27亿个参数的GPT近地天体。根据计算机的速度，您可能希望减小大小。下面的例子说明了如何减少参数。</p><p id="a8b5" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">对于13亿个参数；</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="5456" class="lf iv hh lb b fi lg lh l li lj">gen = pipeline('text-generation', model ='EleutherAI/gpt-neo-1.3B')</span></pre><p id="03c1" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">对于1.25亿个参数；</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="fbdb" class="lf iv hh lb b fi lg lh l li lj">gen = pipeline('text-generation', model ='EleutherAI/gpt-neo-125M')</span></pre><h1 id="21c4" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">生成文本</h1><p id="52d1" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">如果您想要基于上下文生成文本，您将需要指定该上下文，以便模型能够理解并根据该上下文生成文本。创建一个名为<em class="kq"> context </em>的变量，用字符串格式写一个句子。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="70fe" class="lf iv hh lb b fi lg lh l li lj">context = "Deep Learning is a sub-field of Artificial Intelligence."</span><span id="8c15" class="lf iv hh lb b fi lk lh l li lj">output = generator(context, max_length=50, do_sample=True, temperature=0.9)</span></pre><p id="9682" class="pw-post-body-paragraph js jt hh ju b jv kr jx jy jz ks kb kc kd kt kf kg kh ku kj kk kl kv kn ko kp ha bi translated">输出变量的第一个参数是我们指定为字符串格式的<em class="kq">上下文</em>。第二个关键字参数，<em class="kq"> max_length </em>定义了输出的字数。您可能希望根据需要生成更长的文本。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ll"><img src="../Images/0c9dee33a80563d5853df882614e6fcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_SZKF58myuZ5avR9vIlaDA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Output, image by author</figcaption></figure><h1 id="e6bc" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">将输出写入文本文件</h1><p id="4e1b" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">最后，因为输出是字典格式的，我们将把它写到文本文件中，这将使编辑过程相对容易。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="cea8" class="lf iv hh lb b fi lg lh l li lj">with open('dl.txt', 'w') as f:<br/>       f.write(str(output))</span></pre><div class="lm ln ez fb lo lp"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lq ab dw"><div class="lr ab ls cl cj lt"><h2 class="bd hi fi z dy lu ea eb lv ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lw l"><h3 class="bd b fi z dy lu ea eb lv ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lx l"><p class="bd b fp z dy lu ea eb lv ed ef dx translated">medium.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md in lp"/></div></div></a></div></div></div>    
</body>
</html>
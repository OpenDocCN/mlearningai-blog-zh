<html>
<head>
<title>The First Cut is the Shallowest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第一刀是最浅的</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/the-first-cut-is-the-shallowest-bdbc657001b7?source=collection_archive---------10-----------------------#2021-12-27">https://medium.com/mlearning-ai/the-first-cut-is-the-shallowest-bdbc657001b7?source=collection_archive---------10-----------------------#2021-12-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="df0f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在激活函数之前加权数据</p><p id="d346" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本帖中，我们将通过观察在将数据提交给激活函数之前，将随机权重和偏差值应用于我们的数据时会发生什么，来迈出使我们的数学变得真实的第一步。</p><p id="0953" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">回想一下，我们已经通过使用矩阵乘法简化了我们的神经网络数学，并通过向数据和权重向量添加一个维度来吸收我们的偏差计算。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/aafae92ed6cb36e55f5b2382ea7172f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wr450f9Oj1eSpZsfItHKLw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Reduces number of calculations by approximately 50%!</figcaption></figure><p id="49ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，逻辑流程是这样的:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es js"><img src="../Images/f6bec9ba4228232526f449c64d0f2ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwdbmIuF3XZ1JzAtMuHgxQ.png"/></div></div></figure><p id="a71b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">…对此:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jt"><img src="../Images/882362196b06992f7a732b81df7e4fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TbZwIYzJ7oZtSTImd1fxDw.png"/></div></div></figure><p id="02ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我将去掉x和w符号中的<strong class="ig hi"> "+" </strong>，我们将简单地假设，如果您在计算中没有看到偏差，那么它已经被吸收到数据和权重中。</p><p id="5da9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记住我们现在用的是矩阵乘法。我们的输入数据实际上是一个矩阵:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ju"><img src="../Images/4591192a3d77ea4af74827ff89b11b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*o6-zSh4zB2v7zloI_Jw3MA.png"/></div></figure><p id="07e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，神经网络中需要生成随机权重的每一步，我们实际生成的是一个随机权重+偏差向量。让我们将这些值用于我们的示例运行:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jv"><img src="../Images/36cdf9d2b1747b619288cf6399cb061e.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*sDdpb2su4t75Cbhpp3ZUdQ.png"/></div></figure><p id="66a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我大学时的物理学教授鲍勃·基钦过去常说的那样:从这里开始，一切都只是“砰”的一声！</p><h1 id="7ff9" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">施加重量</h1><p id="ac00" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">我们可以只使用NumPy为我们做数学，但我认为它将帮助我们手动完成一些工作，以确保我们理解正在发生的事情。</p><p id="8eba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们从第一个随机选择的权重值w1开始，它等于(1.4，-2.1，3.1)。我们需要计算这个权重和我们的x值之间的内积，从x中的第一个观察值开始。但是请记住，内积的工作方式是第一个矩阵(权重)将按行计算，而第二个矩阵(数据)将按列计算。因此，为了正确地将权重应用于第一次观察中的所有内容，我们需要转置数据，并将行转换为列。一会儿我们将看到如何用代码来实现这一点。</p><p id="ea66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么，第一个结果将考虑的x值是(1，-1，1)。<a class="ae kz" href="https://jasondeden.medium.com/matrix-multiplication-e2cf007d0755" rel="noopener">内积</a>得出1.4 + 2.1 + 3.1= 6.6。这是我们反应矩阵中的第一个值，它被传递到第一个神经元的激活节点。</p><p id="d002" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在底部神经元上，我们用第二组权重w3重复这个过程，w3是(1.8，0，-1.6)。这给了我们1.8 + 0 + -1.6，即0.2，这是gest传递给第二个神经元中激活节点的响应矩阵中的第一个值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es la"><img src="../Images/5831f9e0fed59a00f06db8f1c2885cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*pNzkKh2GluxaaJ2J8OmiOg.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Math checks out so far…</figcaption></figure><h1 id="7a67" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">所有的数学一步到位？</h1><p id="e4cd" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated"><strong class="ig hi">看看</strong>使用矩阵乘法来简化这一点的能力。当我说简化的时候，我的姐妹们、非姐妹们和兄弟们，我是指<strong class="ig hi"> <em class="lb">简化</em> </strong>。</p><p id="e0f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以一次用手算出一个结果。或者，你可以变聪明，简单地计算每个神经元的一个内积。然而，事实证明我们甚至不需要做这么多工作。你可以求解整个第一层，不管神经元的数量，数据点，权重等等。用单个矩阵乘法。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lc ld l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Stupid butterfly. I (used to) have Gold airline status!</figcaption></figure><p id="a3d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们首先将数据创建为NumPy矩阵:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es le"><img src="../Images/ff5ecd7d8b4db133e51044e547acdcac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UGG8y7diyWYXrDcsxYL6rQ.png"/></div></div></figure><p id="80b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，让我们使用随机生成的w1和w3的权重创建第二个数组:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lf"><img src="../Images/df9618307e033a650a2278bab9588b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*53KYsOUDkusTND_QLbcMzw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Note the weight shape is such we don’t need to transpose anything to perform inner product calculations.</figcaption></figure><p id="0938" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以简单地将w13和x的内积转置，得到以下输出:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lg"><img src="../Images/ad98f40f6678b7698d4d60f9081a4733.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*JtEaC8ia3G3oT-pNvj5x9Q.png"/></div></figure><p id="83cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，数组中的每一行都对应于我们在单独执行计算时手动收集的输出(6.6是第一个神经元中的第一个值，0.2是第二个神经元中的第一个值……)我们已经用一次矩阵乘法完成了整个第一层计算。</p><p id="1a92" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里是令人兴奋的部分:这种单一计算方法将是正确的<strong class="ig hi">* *不管神经网络中的观察值、特征和神经元的数量。** </strong>如果您有10，000个观察值、2，000个特征和一个宽度为500个神经元的神经网络，则神经网络过程第一步的全部输出将由一个矩阵乘法来表示。</p><p id="0e4a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我的。介意。吹了。你呢。</p><p id="e792" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来:激活功能到底是什么，它到底是如何工作的？乐趣才刚刚开始！</p><div class="lh li ez fb lj lk"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hi fi z dy lp ea eb lq ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">medium.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly jm lk"/></div></div></a></div></div></div>    
</body>
</html>
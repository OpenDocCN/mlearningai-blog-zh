<html>
<head>
<title>Keras Losses Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras损失函数</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/keras-losses-functions-a61f693a9b2e?source=collection_archive---------3-----------------------#2021-02-08">https://medium.com/mlearning-ai/keras-losses-functions-a61f693a9b2e?source=collection_archive---------3-----------------------#2021-02-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="56e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">分类交叉熵损失，二元交叉熵损失ve MSE损失</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/20ecb1853de4c8dd3721d027f9f5f31a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I--BFFOB_GRnjRMq"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Chris Ried</a> on <a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ab9a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗨！今天让我们更深入地研究一下这些神经网络，你认为呢？让我们先搞清楚为什么要用损失函数，然后再搞清楚它们的含义。我不得不说。利用我们将在项目中使用的超参数，我们可以很好地捕捉变化。由于这个原因，高于预期的准确率再次通过这些参数的形成。</p><h1 id="27fc" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">什么是损失函数？</h1><p id="934e" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">首先，我要告诉你目标函数。用英语来称呼这个会更正确。目标函数是一种函数，用于评估我们创建或使用的优化算法中存在的候选解决方案。事实上，它是优化算法的必要条件。</p><p id="4f3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🏋🏻‍♀️，现在我们来看损失函数。顾名思义，我们在这里有一个损失，所以它对我们有一个负面的结果。我们希望将这种错误率降至最低，以提高我们创建的神经网络的准确性。这些错误率是由一些有效的原因引起的，可以被认为是优化算法中的目标函数。所以我们的目标函数在这里变成了损失函数。损失函数以某种方式伤害了我们的目标。为此，我们尽量将损失值保持在尽可能低的水平。</p><blockquote class="kx ky kz"><p id="e8b3" class="ie if jc ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">我们想要最小化或最大化的函数称为目标函数或标准。当我们将其最小化时，我们也可以称之为成本函数、损失函数或误差函数。</p><p id="0bb8" class="ie if jc ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">—第82页，<a class="ae jt" href="https://amzn.to/2NJW3gE" rel="noopener ugc nofollow" target="_blank">深度学习</a>，2016。</p></blockquote><p id="9202" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为注释，我想补充一点，选择权完全在我们手中。由于这个原因，我们必须决定在哪个函数上工作。对此我补充一句好话👇🏻</p><blockquote class="kx ky kz"><p id="e8dc" class="ie if jc ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">这就是函数忠实地代表我们的设计目标非常重要的原因。如果我们选择了一个不好的误差函数，得到了不令人满意的结果，那么错误地确定搜索的目的就是我们的错。</p><p id="4268" class="ie if jc ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">——155页，<a class="ae jt" href="https://amzn.to/2S8qRdI" rel="noopener ugc nofollow" target="_blank">神经锻造:前馈人工神经网络中的监督学习</a>，1999年。</p></blockquote><h1 id="5b86" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">使用哪个损失函数？</h1><p id="6081" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">🪄损失函数的选择甚至影响你创建的人工神经网络层的输出。出于这个原因，我们需要做正确的设计。</p><p id="3506" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🪄，我们需要很好地了解我们的问题，以便能够很好地评估要选择的损失函数。比如有回归问题，要知道通常使用的是<strong class="ig hi"> mean_square_error </strong>函数。当然，这些功能也有各种选项。让我们转到Keras的文档，以便我们可以选择它们。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/71d922c2ab73b3afaae4ce93588fb44e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hYyxYFCE76Vwg49qWCNRtg.png"/></div></div></figure><p id="6b26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🧚🏼‍♂️正如我们所看到的，有太多缺少类和函数选项的函数，这完全取决于我们。相同方法的类和函数属性已经给出。刚刚打开一个函数实例事件，我想多接触一点代码。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="1190" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一个例子是<strong class="ig hi">compile()</strong>方法。我们在这里创建的结构实际上正在经历CNN模型的编译。SGD，即随机梯度下降，被用作优化算法，而<strong class="ig hi"> MeanSquaredError </strong>被用作损失函数。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="a11e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一个缺失的函数是<strong class="ig hi">分类交叉熵</strong>。这是一个我非常熟悉的功能。我们也可以将我们的函数作为一个类来使用，并且有可能在模型中使用它。但首先，让我们稍微了解一下他们。</p><p id="e274" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Keras的原始文档提到:</p><blockquote class="kx ky kz"><p id="192a" class="ie if jc ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">计算标签和预测之间的交叉熵损失。</p></blockquote><p id="0887" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯，让我们再开一点你的意思是什么？据说当有两个或两个以上标签类时，我们应该使用这个交叉熵损失函数。下面你可以找到这个加载为<strong class="ig hi">类</strong>的损失函数。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="3369" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以🖇为例，考虑一下时尚杂志的数据。当我们检查这些数据时，我们会看到它由10个类别组成。因此，当有多个类别时，使用这个损失函数会更明智。</p><p id="d53b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是如果我们在创建模型时想要使用它，我们应该编写什么样的代码呢？</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="6f69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">📥因此，我们可以在多类分类问题中使用该函数。现在我们有最后一个损失函数，我们将检查。当然是<strong class="ig hi">二元交叉熵</strong>，我们在二元分类中经常用到的！</p><p id="af19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">二元交叉熵损失函数</strong>用于我们将一个例子分为两类的问题。例如，我们需要确定一个图像是一只猫还是一只狗。在这个阶段，这个损失函数就发挥作用了。例如，狗可以标记1，而猫标记为0。</p><p id="fd42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在来看看它的编码，大家觉得怎么样？</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="e6c5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们看到上面的<strong class="ig hi"> BinaryCrossentropy </strong>类。因为我们可以将它用作类结构，所以我们也可以将下面的结构加载到我们的模型中。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="0dbd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🎉因此，我们通过使用<strong class="ig hi"> tf.keras API </strong>在我们的模型中使用了我们的损失函数。</p><p id="58ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我的下一篇文章中，我将解释在深度学习领域训练人工神经网络时如何选择损失函数。坚持下去，✨</p><h1 id="8d5f" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><ol class=""><li id="8217" class="lg lh hh ig b ih ks il kt ip li it lj ix lk jb ll lm ln lo bi translated"><a class="ae jt" href="https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/loss-and-loss-functions-for-training-deep-learning-neural-networks/</a></li><li id="e804" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated"><a class="ae jt" href="https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/</a></li><li id="3c25" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">https://keras.io/api/losses/<a class="ae jt" href="https://keras.io/api/losses/" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>
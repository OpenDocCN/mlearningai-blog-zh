<html>
<head>
<title>Learning to Compare: Relation Network for Few-shot Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习比较:少量学习的关系网络</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/learning-to-compare-relation-network-for-few-shot-learning-fa9c40c22701?source=collection_archive---------5-----------------------#2019-07-16">https://medium.com/mlearning-ai/learning-to-compare-relation-network-for-few-shot-learning-fa9c40c22701?source=collection_archive---------5-----------------------#2019-07-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="c40b" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="395f" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在传统的监督机器学习系统中，需要大量的标记数据和多次迭代训练来训练模型的参数。由于注释成本，这严重限制了它们适应新类的可伸缩性和通用性。因此，作者提出了他们的方法称之为RN，简称关系网络。它从头开始接受端到端的培训。在元学习过程中，它学习距离深度度量来度量输入图像之间的差异。它学习可转移的深度度量，用于比较图像之间或图像与类描述之间的关系。一旦训练了模型，RN就能够通过计算来自查询样本的输入和来自支持集的输入之间的关系/相似性分数来对新类别的图像进行分类，而无需进一步更新网络。除了在少投学习上取得有希望的表现，他们的网络还可以扩展到零投学习。</p><h1 id="14a7" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">提议的方法</h1><p id="5a22" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">少数镜头学习</strong></p><p id="ae71" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">作者提出了<strong class="je hi">二分支关系网络</strong>，通过学习将来自查询集的输入图像与少数镜头标记样本图像进行比较来执行少数镜头分类。网络由两个模块组成:<strong class="je hi"> <em class="kf">嵌入模块</em> </strong> &amp; <strong class="je hi"> <em class="kf">关系模块</em> </strong>。<strong class="je hi"> <em class="kf">嵌入模块</em> </strong>产生查询和支持集图像的表示。然后，<strong class="je hi"> <em class="kf">关系模块</em> </strong>对这些嵌入进行比较，以确定它们是否属于同一类。所提出的方法优于先前的方法，更简单(没有RNNs)和更快(不需要微调)。</p><p id="19da" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">查询集和支持集中的图像样本都被采样并馈入嵌入模块以产生它们相应的特征图。然后，两个特征图与操作符c(⋅(⋅)连接，并被传递到关系模块<em class="kf"> g_ϕ </em>中，以生成相似性/关系分数[0，1]。这个关系分数，<em class="kf"> r_{i，j} </em>将告诉查询输入和支持样本实例之间的接近程度。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/60aef03612114e8927786500aef9bbe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*e9_87wuU8dFzfA9LY4EwTA.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx">sources: <a class="ae ks" href="https://arxiv.org/pdf/1711.06025.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1711.06025.pdf</a></figcaption></figure><p id="2aa5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">均方误差损失用于训练网络，将关系分数回归到地面真实值。具有最接近相似性的配对将获得更接近1的值，而不匹配的配对将获得0。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kt"><img src="../Images/317a0136ad6f03553a968c5c40a78288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAIlQLNbbj9nO74kzil5xQ.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx">Figure 1: Relation Network Architecture for a 5-way 1-shot problem with one query example</figcaption></figure><p id="c94c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">例如，为了训练5路1次分类任务，来自5个不同类别的每个样本将被采样以构成“支持集”，并且1个输入图像将被选择作为“查询集”或被称为“测试集”。在图1中，最左边的5张图片是“支持集”的图片，而旁边的另一张图片是“查询集”，它将用于与“测试集”进行比较。它们将首先被送入嵌入模块，以从高维向量中提取特征。然后，在关系模块中连接每个特征向量以产生关系分数，确定来自查询集的图像属于哪一类。如图1所示，当“查询集”中的特征向量与“支持集”中的狗图像共享相对接近时，关系分数将被给予较高的分数。</p><p id="7e07" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">零射击学习</strong></p><p id="9267" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">它通过修改样本分支来输入单个类别描述而不是单个训练图像，从而优雅地将空间扩展到零镜头学习。它学习对齐图像和类别嵌入，并通过预测图像和类别嵌入对是否匹配来执行分类任务。</p><p id="89c6" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">它包含语义类嵌入向量，而不是为每个C训练类给出具有单镜头/k镜头图像的支持集。作者为图像查询集使用第二个异构嵌入模块。然后应用关系网络。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ky"><img src="../Images/6404609b8c06253228841c003cd7c406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*XPseNuz31prHMlU95yHRWA.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx">sources: <a class="ae ks" href="https://arxiv.org/pdf/1711.06025.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1711.06025.pdf</a></figcaption></figure><p id="498c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">网络架构</strong></p><p id="ea76" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">四个卷积块用于<strong class="je hi">嵌入模块</strong>，每个块包含64-滤波器3x3卷积、一层批量归一化和一个Relu非线性函数。前两个卷积块包含一个2x2 max-pooling层，而后两个没有。而对于r <strong class="je hi">关联模块</strong>，它由两个卷积块和两个全连接层组成。每个卷积块是64个滤波器的3×3卷积，接着是一层批量归一化、Relu非线性函数，最后是2×2最大池层。除了最后的输出层——sigmoid函数，所有完全连接的层都是ReLU函数，以便产生范围从0到1的关系分数。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kz"><img src="../Images/fef5e5d23388ebfe564d49b22b9e4973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*VqRUf6xJSZfKjnWiy6gFkg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx">Figure 2: Relation Network architecture for few-shot learning.</figcaption></figure><h1 id="5581" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">实验和结果</h1><p id="e4b1" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">该方法在两个相关任务上进行了评估:Omniglot和miniImagenet数据集上的少镜头分类，以及带属性的动物(AwA)和加州理工学院-加州大学圣迭戈分校Birds-200–2011上的零镜头分类。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es la"><img src="../Images/ff538d0a30b5e7c290e8f84d1e5bdbb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-R1hnw82koKJtgEyKXJ0zg.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx">Table 1: Omniglot few-shot classification.</figcaption></figure><p id="7569" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">表1显示了Omniglot数据集上的少数镜头分类精度。关系网络在C路K-shot的所有实验设置下实现了最先进的性能，具有更高的平均精度和更低的标准偏差，除了5路5-shot。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lb"><img src="../Images/faaf01d65f1655737a0467c37efafdc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*Uk4-2qpk6t7FRP5eWDUqFQ.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx">Table 2: Few-shot classification accuracies on miniImageNet.</figcaption></figure><p id="98af" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">表2显示了miniImagenet数据集上的少数镜头分类任务的精度。可以看出，所提出的关系网络在5路1投设置上取得了有希望的性能，并且在5路5投上取得了有竞争力的结果。模型在5路上被训练，每个训练集1次1镜头的查询和5次5镜头的查询，训练查询少得多。</p><p id="04a4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">与固定度量学习或固定特征相反，关系网络可以被视为学习深度嵌入和学习深度非线性度量。通过使用灵活的函数逼近器来学习相似性，以数据驱动的方式学习好的度量，而不必手动选择适当的度量，如欧几里德、余弦等。用间歇训练来训练网络调整了用于有效的少量学习的嵌入和距离度量。</p><h1 id="de26" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="6b0c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">[1]<a class="ae ks" href="https://arxiv.org/pdf/1711.06025.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1711.06025.pdf</a></p><p id="e592" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">[2]Github:【https://github.com/floodsung/LearningToCompare_FSL.git】T2</p></div></div>    
</body>
</html>
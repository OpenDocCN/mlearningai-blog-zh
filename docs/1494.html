<html>
<head>
<title>An Introduction to Occam’s Razor Bound in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的奥卡姆剃刀界限引论</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/an-introduction-to-occams-razor-bound-in-machine-learning-80ba5456c8dc?source=collection_archive---------4-----------------------#2021-12-26">https://medium.com/mlearning-ai/an-introduction-to-occams-razor-bound-in-machine-learning-80ba5456c8dc?source=collection_archive---------4-----------------------#2021-12-26</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><div class=""/><p id="1e5f" class="pw-post-body-paragraph ii ij hl ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf he bi translated">在本文中，我们将介绍奥卡姆剃刀的直观思想。然后我们将把它应用于机器学习，特别是学习背后的理论。为此，我们将需要使用<a class="ae jg" href="https://najamogeltoft.medium.com/machine-learning-the-intuition-of-hoeffdings-inequality-970a59c2b519" rel="noopener">赫夫丁不等式</a>，因为我们已经看到，它可以给我们一个选定假设的概率界限。本文将作为下一篇文章的基础，在下一篇文章中，我们将介绍PAC-Bayesian分析。</p><h2 id="bc5c" class="jh ji hl bd jj jk jl jm jn jo jp jq jr it js jt ju ix jv jw jx jb jy jz ka kb bi translated">重温赫夫丁不等式</h2></div></div>    
</body>
</html>
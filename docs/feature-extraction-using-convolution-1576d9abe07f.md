# 使用卷积的特征提取

> 原文：<https://medium.com/mlearning-ai/feature-extraction-using-convolution-1576d9abe07f?source=collection_archive---------8----------------------->

## 卷积运算，特征提取数学背后。

# 概观

在本文中，我们将开发一些方法，允许我们将这些方法扩展到具有更大图像的更真实的数据集。

# 全连接网络

在稀疏自动编码器中，我们做出的一个设计选择是将所有秘密单元“完全连接”到所有输入单元。在我们正在处理的相对较小的图像上(例如，用于稀疏自动编码器分配的 8×8 面片，用于 MNIST 数据集的 28×28 图像)，学习整个图像的特征在计算上是可行的。然而，对于更广泛的图像(例如 96×96 的图像)，学习遍历整个图像(完全连接的网络)的特征在计算上是非常昂贵的——您将有大约 104×104 个输入单元，并且假设您想要学习 100 个特征，您将有大约 106×106 个参数要学习。与 28×28 图像相比，前馈和反向传播计算也将慢大约 102×102 倍。

# 本地连接的网络

这个问题的一个简单解决方案是限制隐藏单元和输入单元之间的连接，允许每个隐藏单元只连接到输入单元的一个小的子集。具体来说，每个隐藏单元将仅连接到输入中的一个小的连续像素区域。(对于不同于图像的输入模态，通常也有一种自然的方式来选择输入单元的“连续组”以连接到单个隐藏单元；例如，对于音频，隐藏单元可以仅连接到与输入音频剪辑的特定时间跨度相对应的输入单元。)

这种拥有局部连接网络的想法也从生物学中早期视觉系统的连接方式中获得了灵感。具体来说，视觉皮层中的神经元具有局部感受野(即，它们只对特定位置的刺激做出反应)。

# 回旋

自然图像具有“静止”的属性，这意味着图像的一部分的统计数据与任何其他部分相同。这表明，我们在图像的一部分学到的特征也可以应用到图像的其他部分，我们可以在所有位置使用相同的特征。

更准确地说，在学习了从较大图像中随机采样的小(比如说 8×8)片上的特征之后，我们可以将这个学习的 8×8 特征检测器应用到图像中的任何地方。具体来说，我们可以采用所学习的 8×8 特征，并将它们与较大的图像进行“卷积”，从而在图像中的每个位置获得不同的特征激活值。

举一个具体的例子，假设你已经学习了从一个 96x96 的图像中采样的 8×8 的面片上的特征。进一步假设这是用具有 100 个隐藏单元的自动编码器完成的。要获得卷积特征，对于 96x96 图像的每个 8×8 区域，即从(1，1)，(1，2)，(89，89)(1，1)，(1，2)，(89，89)开始的 8×8 区域，您将提取 8×8 面片，并通过您训练的稀疏自动编码器运行它以获得特征激活。这将产生 100 组 89×89 的卷积特征。

![](img/907965a37c57fa37efba48e90ce39520.png)

形式上，给定一些大的 r×cr×c 图像，我们首先在从这些图像采样的小的 a×ba×b 片上训练稀疏自动编码器，学习 kk 特征 f =σ(W(1)x small+b(1))f =σ(W(1)x small+b(1))(其中σσ是 sigmoid 函数)，由权重 W(1)W(1)和从可见单元到隐藏单元的偏差 b(1)b(1)给出。对于大图像中的每个 a×ba×b 补片 xs，我们计算 fs =σ(W(1)xs+b(1))fs =σ(W(1)xs+b(1))，从而得到卷积特征的 k×(ra+1)×(c b+1)k×(ra+1)×(c b+1)阵列。

谢谢你的时间，希望你喜欢。

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
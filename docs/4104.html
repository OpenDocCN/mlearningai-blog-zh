<html>
<head>
<title>How to generate music using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用机器学习生成音乐</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-generate-music-using-machine-learning-72360ba4a085?source=collection_archive---------4-----------------------#2022-12-09">https://medium.com/mlearning-ai/how-to-generate-music-using-machine-learning-72360ba4a085?source=collection_archive---------4-----------------------#2022-12-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ec30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">曾经想用Python和机器学习生成音乐吗？下面就来看看我们怎么做吧！</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/c2b1c53be617f5530a03d5803d6784de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rzxhuvdW9ByyK7cN"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@namroud?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Namroud Gorguis</a> on <a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7243" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为一名音乐爱好者和数据科学家，我一直想知道是否有办法将音乐和机器学习结合起来，创造出人工智能生成的音乐。嗯，有！有几种方法来处理这个主题，一种方法是使用序列模型(如GRU或LSTM ),并基于n个先前的序列创建音符和/或和弦的序列。另一种方法是将原始音频处理成可训练的VAE(可变自动编码器),并让它输出不同的声音。</p><p id="e99f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将在本文中使用前者，以后再尝试后者。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="7050" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为此，我们将需要一个巨大的音乐数据集(最好都属于一个特定的音乐流派或类似的)，以馈入我们的序列模型，这样我们就可以尝试重新创建一些歌曲，或创建我们自己的歌曲。</p><p id="abe9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个项目中，我们将使用LoFi风格。我发现了一个充满LoFi片段的伟大数据集，它将帮助我们获得我们想要的LoFi声音。这个数据集来自<a class="ae js" href="https://www.kaggle.com/datasets/zakarii/lofi-hip-hop-midi" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>和其他几个来源。</p><p id="1842" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经获得了充满MIDIs的数据集，我们如何将它转化为机器可读的数据呢？我们将使用music21将我们充满MIDIs的数据集转换成音符和和弦序列的列表。</p><p id="3874" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要获取存储MIDIs的目录</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="4f98" class="kg kh hh kc b be ki kj l kk kl">from pathlib import Path<br/><br/>songs = []<br/>folder = Path('insert directory here')<br/>for file in folder.rglob('*.mid'):<br/>  songs.append(file)</span></pre><p id="c206" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或者，我们可以使用整个MIDIs列表的一个子集来使训练更加容易和快速(尽管如果我们这样做，我们可能不会得到更好的结果)</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="56f6" class="kg kh hh kc b be ki kj l kk kl">import random<br/># Get a subset of 1000 songs<br/>result =  random.sample([x for x in songs], 1000)</span></pre><p id="36c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们有了一个MIDI歌曲的路径列表，我们必须将它转换成一系列的音符/和弦，所有的音符/和弦都集中在一个称为音符的列表中。</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="6745" class="kg kh hh kc b be ki kj l kk kl">from music21 import converter, instrument, note, chord<br/>notes = []<br/>for i,file in enumerate(result):<br/>    print(f'{i+1}: {file}')<br/>    try:<br/>      midi = converter.parse(file)<br/>      notes_to_parse = None<br/>      parts = instrument.partitionByInstrument(midi)<br/>      if parts: # file has instrument parts<br/>          notes_to_parse = parts.parts[0].recurse()<br/>      else: # file has notes in a flat structure<br/>          notes_to_parse = midi.flat.notes<br/>      for element in notes_to_parse:<br/>          if isinstance(element, note.Note):<br/>              notes.append(str(element.pitch))<br/>          elif isinstance(element, chord.Chord):<br/>              notes.append('.'.join(str(n) for n in element.normalOrder))<br/>    except:<br/>      print(f'FAILED: {i+1}: {file}')</span></pre><p id="7f27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(我们暂时不要忘记music21！我们稍后将再次使用它)在将所有歌曲处理成一个列表(音符/和弦序列)后，我们最好保存这个列表以供将来运行。</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="5f00" class="kg kh hh kc b be ki kj l kk kl">import pickle<br/>with open('notes', 'wb') as filepath:<br/>  pickle.dump(notes, filepath)</span></pre><p id="d667" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在保存的列表如下所示</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="2c40" class="kg kh hh kc b be ki kj l kk kl">&gt;&gt;&gt; ['C2', 'A4', 'F1', 'F1', ..., '0.6', '0.4.7']</span></pre><p id="1edd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在必须将它转换成我们的机器可以读取的东西(在我们的例子中，我们的序列模型接受从0到1的数字)。为此，我们将使用一个处理函数，将我们的笔记分成n个序列+ 1列数据的块。在我们的例子中，在我们对第33个音符/和弦进行预测之前，我们将使用32个音符/和弦的n _序列。我在整个代码中添加了一些注释，这样我们就可以跟上了</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="2a3b" class="kg kh hh kc b be ki kj l kk kl">def prepare_sequences(notes, n_vocab):<br/>    """ Prepare the sequences used by the Neural Network """<br/>    sequence_length = 32<br/><br/>    # Get all unique pitchnames<br/>    pitchnames = sorted(set(item for item in notes))<br/>    numPitches = len(pitchnames)<br/><br/>     # Create a dictionary to map pitches to integers<br/>    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))<br/><br/>    network_input = []<br/>    network_output = []<br/><br/>    # create input sequences and the corresponding outputs<br/>    for i in range(0, len(notes) - sequence_length, 1):<br/>        # sequence_in is a sequence_length list containing sequence_length notes<br/>        sequence_in = notes[i:i + sequence_length]<br/>        # sequence_out is the sequence_length + 1 note that comes after all the notes in<br/>        # sequence_in. This is so the model can read sequence_length notes before predicting<br/>        # the next one.<br/>        sequence_out = notes[i + sequence_length]<br/>        # network_input is the same as sequence_in but it containes the indexes from the notes<br/>        # because the model is only fed the indexes.<br/>        network_input.append([note_to_int[char] for char in sequence_in])<br/>        # network_output containes the index of the sequence_out<br/>        network_output.append(note_to_int[sequence_out])<br/><br/>    # n_patters is the length of the times it was iterated <br/>    # for example if i = 3, then n_patterns = 3<br/>    # because network_input is a list of lists<br/>    n_patterns = len(network_input)<br/><br/>    # reshape the input into a format compatible with LSTM layers<br/>    # Reshapes it into a n_patterns by sequence_length matrix<br/>    print(len(network_input))<br/>    <br/>    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))<br/>    # normalize input<br/>    network_input = network_input / float(n_vocab)<br/><br/>    # OneHot encodes the network_output<br/>    network_output = np_utils.to_categorical(network_output)<br/><br/>    return (network_input, network_output)<br/><br/><br/>n_vocab = len(set(notes))<br/>network_input, network_output = prepare_sequences(notes,n_vocab)<br/>n_patterns = len(network_input)<br/>pitchnames = sorted(set(item for item in notes))<br/>numPitches = len(pitchnames)</span></pre><p id="46fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看，如果我们把网络输入转换成一个<em class="jt"> nxm </em>矩阵，然后再转换成一个数据帧，它会是什么样子</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es km"><img src="../Images/49c27d3ec062b5d1aba0f3fea382f579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Dj-D_csKPXsok5eGa63nQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">DataFrame for network_input</figcaption></figure><p id="5a97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果数据集碰巧不平衡，没关系，不是每个音符/和弦都一样频繁，但我们可能会遇到这样的情况，一个音符出现4000多次，而另一个音符只出现一次。我们可以尝试对数据集进行过采样，但这并不总是产生最佳结果，但可能值得一试。对于我们的例子，我们不会过采样，因为我们的数据集是平衡的。</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="e0ef" class="kg kh hh kc b be ki kj l kk kl">def oversample(network_input,network_output,sequence_length=15):<br/><br/>  n_patterns = len(network_input)<br/>  # Create a DataFrame from the two matrices<br/>  new_df = pd.concat([pd.DataFrame(network_input),pd.DataFrame(network_output)],axis=1)<br/><br/>  # Rename the columns to numbers and Notes<br/>  new_df.columns = [x for x in range(sequence_length+1)]<br/>  new_df = new_df.rename(columns={sequence_length:'Notes'})<br/><br/>  print(new_df.tail(20))<br/>  print('###################################################')<br/>  print(f'Distribution of notes in the preoversampled DataFrame: {new_df["Notes"].value_counts()}')<br/>  # Oversampling<br/>  oversampled_df = new_df.copy()<br/>  #max_class_size = np.max(oversampled_df['Notes'].value_counts())<br/>  max_class_size = 700<br/>  print('Size of biggest class: ', max_class_size)<br/><br/>  class_subsets = [oversampled_df.query('Notes == ' + str(i)) for i in range(len(new_df["Notes"].unique()))] # range(2) because it is a binary class<br/><br/>  for i in range(len(new_df['Notes'].unique())):<br/>    try:<br/>      class_subsets[i] = class_subsets[i].sample(max_class_size,random_state=42,replace=True)<br/>    except:<br/>      print(i)<br/><br/>  oversampled_df = pd.concat(class_subsets,axis=0).sample(frac=1.0,random_state=42).reset_index(drop=True)<br/><br/>  print('###################################################')<br/>  print(f'Distribution of notes in the oversampled DataFrame: {oversampled_df["Notes"].value_counts()}')<br/><br/>  # Get a sample from the oversampled DataFrame (because it may be too big, and we also have to convert it into a 3D array for the LSTM)<br/>  sampled_df = oversampled_df.sample(n_patterns,replace=True) # 99968*32 has to be equals to (99968,32,1)<br/><br/>  print('###################################################')<br/>  print(f'Distribution of notes in the oversampled post-sampled DataFrame: {sampled_df["Notes"].value_counts()}')<br/><br/>  # Convert the training columns back to a 3D array<br/>  network_in = sampled_df[[x for x in range(sequence_length)]]<br/>  network_in = np.array(network_in)<br/>  network_in = np.reshape(networkInput, (n_patterns, sequence_length, 1))<br/>  network_in = network_in / numPitches<br/>  print(network_in.shape)<br/>  print(sampled_df['Notes'].shape)<br/>  # Converts the target column into a OneHot encoded matrix<br/>  network_out = pd.get_dummies(sampled_df['Notes'])<br/>  print(network_out.shape)<br/><br/>  return network_in,network_out<br/><br/>networkInputShaped,networkOutputShaped = oversample(networkInput,networkOutput,sequence_length=seqLength)<br/>networkOutputShaped = np_utils.to_categorical(networkOutput)</span></pre></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="58f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然我们已经处理完了我们的歌曲，我们现在继续训练我们的模型。但首先，回顾一下我们迄今为止所做的工作，我们有:</p><ul class=""><li id="fe5f" class="kn ko hh ig b ih ii il im ip kp it kq ix kr jb ks kt ku kv bi translated">收集了我们的MIDI文件</li><li id="8235" class="kn ko hh ig b ih kw il kx ip ky it kz ix la jb ks kt ku kv bi translated">将MIDI文件加载到内存中</li><li id="449b" class="kn ko hh ig b ih kw il kx ip ky it kz ix la jb ks kt ku kv bi translated">将MIDI文件转换为有序音符/和弦列表</li><li id="aa5f" class="kn ko hh ig b ih kw il kx ip ky it kz ix la jb ks kt ku kv bi translated">将列表转换成一个(n，m，1)矩阵和(n，1)向量(n = 99968，m = 32)</li></ul><p id="c3fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于我们的模型，我们将使用LSTM网络来预测第33个音符/和弦，同时考虑到我们之前的32个音符/和弦。我们将使用LSTMs，因为它的反馈连接。它们在处理有序数据时非常有用。</p><p id="00a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LSTMs是一种递归神经网络，但不同于其他网络。其它网络在每次条目接收到新信息时重复该模块。然而，LSTM会更长时间地记住问题，并具有类似字符串的结构来重复模块。</p><p id="b708" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LSTM基本上是如下所示的单位:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lb"><img src="../Images/a3fbff2e1cf36258168395ae748672d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NQj4SwG7rotUPYW9.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image taken from <a class="ae js" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Long_short-term_memory</a></figcaption></figure><p id="7a95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LSTM单元由单元、输入门、输出门和遗忘门组成。让我们看看这意味着什么，以及为什么LSTMs适合于顺序数据。</p><p id="0dc1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">遗忘门的工作是决定是保留还是遗忘信息。sigmoid函数仅保留来自先前隐藏层和当前输入的信息。任何接近1的值都会保留，任何接近0的值都会消失。</p><p id="b2f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输入门有助于更新单元的状态。当前输入和先前状态信息通过<em class="jt"> sigmoid </em>函数传递，该函数将通过将该值乘以0和1来更新该值。同样，为了规范网络，数据也要通过<em class="jt"> tanh </em>函数。现在，<em class="jt">的输出与<em class="jt">的输出相乘。<em class="jt"> sigmoid </em>的输出将识别有价值的信息以避免<em class="jt"> tanh </em>的输出。</em></em></p><p id="2ca0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出门决定下一个隐藏状态的值。为了找到隐藏的状态信息，我们需要将<em class="jt"> sigmoid </em>输出乘以<em class="jt"> tanh </em>输出。现在，新的隐藏状态和新的单元格状态将进入下一步。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="ec35" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练LSTM网络时，需要使用GPU。在我的例子中，我在训练神经网络时使用了Google Colab Pro。当我们用GPU训练时，Google Colab对我们可以使用的计算单位有一个设定的限制。您可以使用免费的GPU进行几十次更新。</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="9cec" class="kg kh hh kc b be ki kj l kk kl">model = Sequential()<br/>model.add(Dropout(0.2))<br/>model.add(LSTM(<br/>    512,<br/>    input_shape=(networkInputShaped.shape[1], networkInputShaped.shape[2]),<br/>    return_sequences=True<br/>))<br/>model.add(Dense(256))<br/>model.add(Dense(256))<br/>model.add(LSTM(512, return_sequences=True))<br/>model.add(Dense(256))<br/>model.add(LSTM(512))<br/>#model.add(Dense(numPitches))<br/>model.add(Dense(numPitches))<br/>model.add(Activation('softmax'))<br/>model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])</span></pre><p id="1c36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">确保通过以下回调保存每一次重量提升:</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="2418" class="kg kh hh kc b be ki kj l kk kl">num_epochs = 100<br/><br/>filepath = "weights-improvement-{epoch:02d}-{loss:.4f}-bigger_1.hdf5"<br/>checkpoint = ModelCheckpoint(<br/>    filepath, monitor='loss', <br/>    verbose=1,        <br/>    save_best_only=True,        <br/>    mode='min'<br/>)    <br/>callbacks_list = [checkpoint]<br/><br/>history = model.fit(networkInputShaped, networkOutputShaped, epochs=num_epochs, batch_size=64, callbacks=callbacks_list)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lc"><img src="../Images/59ab97e0f34ef0a6405104209cff5f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3tpYiDdP43xp2SUF8bO8Q.png"/></div></div></figure><p id="6ca5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练网络100次以上会产生最好的结果。</p><p id="aba9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下图显示了训练神经网络的结果。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ld"><img src="../Images/3a37d983c02082c6bd43124abc090d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F_eXaOeHU56yVIWlo56VhA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Graph on the left shows the accuracy in relation to the epochs. Graph on the right shows the loss in relation to the epochs.</figcaption></figure><p id="7807" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练完我们的网络后，我们该做什么？我们从0到网络输入的长度中选择一个随机数，这将是训练矩阵中行的索引，我们将使用它来进行预测。我们将这32个音符/和弦的序列作为起点来预测1个音符。在这之后，我们做这个<em class="jt">(n-1)</em>更多次(在这个例子中n是500)。在每个预测中，我们将32个音符/和弦的窗口向右移动一个元素。换句话说，在第二个预测中，一旦我们预测了一个音符/和弦，我们就消除第一个音符，并且我们的第一个预测成为长度为32的序列中的最后一个音符/和弦。下图显示了之前解释的代码</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es le"><img src="../Images/40a5ecf53e5fd2d41419a739f3c19f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rnNfKrh08LsS2dZbdBSbyQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Illustration sequence of the first prediction</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lf"><img src="../Images/add59d60fc57aca19817f18b3d5963ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*82cjhG4RT48ftrj77r562A.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Illustration sequence of the second prediction</figcaption></figure><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="afd6" class="kg kh hh kc b be ki kj l kk kl">def generate_notes(model, network_input, pitchnames, n_vocab):<br/>    """ Generate notes from the neural network based on a sequence of notes """<br/>    # pick a random sequence from the input as a starting point for the prediction<br/>    # Selects a random row from the network_input<br/>    start = numpy.random.randint(0, len(network_input)-1)<br/>    print(f'start: {start}')<br/>    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))<br/><br/>    # Random row from network_input<br/>    pattern = network_input[start]<br/>    prediction_output = []<br/><br/>    # generate 500 notes<br/>    for note_index in range(500):<br/>        # Reshapes pattern into a vector<br/>        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))<br/>        # Standarizes pattern<br/>        prediction_input = prediction_input / float(n_vocab)<br/><br/>        # Predicts the next note<br/>        prediction = model.predict(prediction_input, verbose=0)<br/><br/>        # Outputs a OneHot encoded vector, so this picks the columns<br/>        # with the highest probability<br/>        index = numpy.argmax(prediction)<br/>        # Maps the note to its respective index<br/>        result = int_to_note[index]<br/>        # Appends the note to the prediction_output<br/>        prediction_output.append(result)<br/><br/>        # Adds the predicted note to the pattern<br/>        pattern = numpy.append(pattern,index)<br/>        # Slices the array so that it contains the predicted note<br/>        # eliminating the first from the array, so the model can<br/>        # have a sequence<br/>        pattern = pattern[1:len(pattern)]<br/><br/>    return prediction_output<br/><br/>n_vocab = len(set(allNotes))<br/>pitchnames = sorted(set(item for item in allNotes))<br/>prediction_output = generate_notes(model, networkInputShaped, pitchnames, n_vocab)</span></pre><p id="ce78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这样，我们就生成了500个音符的输出序列，看起来像这样</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="cb61" class="kg kh hh kc b be ki kj l kk kl">&gt;&gt;&gt; ['B2', 'B2', 2.7, ..., 5.10]</span></pre><p id="fead" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们如何将这个音符/和弦数组转换回MIDI？这就是music21重新发挥作用的地方！这个库不仅可以让我们将MIDI转换成数组，还可以让我们将数组转换回MIDI！</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="697f" class="kg kh hh kc b be ki kj l kk kl">def create_midi(prediction_output):<br/>    offset = 0<br/>    output_notes = []<br/><br/>    # create note and chord objects based on the values generated by the model<br/>    for pattern in prediction_output:<br/>        # pattern is a chord<br/>        if ('.' in pattern) or pattern.isdigit():<br/>            notes_in_chord = pattern.split('.')<br/>            notes = []<br/>            for current_note in notes_in_chord:<br/>                new_note = note.Note(int(current_note))<br/>                new_note.storedInstrument = instrument.Piano()<br/>                notes.append(new_note)<br/>            new_chord = chord.Chord(notes)<br/>            new_chord.offset = offset<br/>            output_notes.append(new_chord)<br/>        # pattern is a note<br/>        else:<br/>            new_note = note.Note(pattern)<br/>            new_note.offset = offset<br/>            new_note.storedInstrument = instrument.Piano()<br/>            output_notes.append(new_note)<br/><br/>        # increase offset each iteration so that notes do not stack<br/>        offset += 0.5<br/>    midi_stream = stream.Stream(output_notes)<br/>    midi_stream.write('midi', fp='output.mid')</span></pre><p id="aa45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是我们作为MIDI的预测输出！现在你只需要把它导入你的DAW，看看它听起来是什么样的！我建议我们应该对模型进行微调，并对其进行试验，看看我们能生产出什么。我在其中一个预测中加入了一些环境噪音和鼓声，结果如下:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lg lh l"/></div></figure><p id="abc9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可选:在训练神经网络时，每个时期都会产生一组不同的权重，在音乐生成中，每组权重都会产生不同的结果(不同的音符/和弦序列)，因此最好跟踪每个权重。</p><p id="3e40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以更进一步，检查所有先前保存的权重的预测。首先，让我们获取存储权重的位置，并遍历该文件夹:</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="ace7" class="kg kh hh kc b be ki kj l kk kl">songs = []<br/>folder = Path('Training Weights LoFi')<br/>for file in folder.rglob('*.hdf5'):<br/>  songs.append(file)</span></pre><p id="63c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，遍历每个. hdf5，获得预测序列，然后将其存储到DataFrame中，以列作为权重的位置，并输出序列。</p><pre class="jd je jf jg fd kb kc kd bn ke kf bi"><span id="7d54" class="kg kh hh kc b be ki kj l kk kl">songsList = []<br/>weightsList = []<br/>for i in range(len(songs)):<br/>  try:<br/>    model.load_weights(songs[i])<br/>    prediction_output = generate_notes(model, networkInputShaped, pitchnames, n_vocab)<br/>    songsList.append(prediction_output)<br/>    weightsList.append(str(songs[i]))<br/>  except:<br/>    pass<br/><br/>songs_df = pd.DataFrame({'Weights':weightsList,<br/>                         'Notes':songsList})</span></pre><p id="b599" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据帧应该是这样的:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es li"><img src="../Images/309240dce3fbb94d07f53926b5b3bc48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*b6e4XJdjSSPJHNNk7QDrDA.png"/></div></div></figure><p id="8fad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想复制你在这里看到的，这里显示的所有代码都在我的<a class="ae js" href="https://github.com/AReyH/ai-generated-music" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中。有了这些信息，你应该能够创作自己的歌曲。如果你有，请把它们上传到某个地方，并链接到我这里，这样我就可以查看它们了！</p><p id="aed7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另外，非常感谢扎卡里写了<a class="ae js" href="https://ai.plainenglish.io/building-a-lo-fi-hip-hop-generator-e24a005d0144" rel="noopener ugc nofollow" target="_blank">这篇文章</a>，这也是我获得灵感的地方。</p><p id="4626" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一如既往，感谢您抽出时间阅读本文。我希望你今天学到了一些东西！</p><div class="lj lk ez fb ll lm"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ln ab dw"><div class="lo ab lp cl cj lq"><h2 class="bd hi fi z dy lr ea eb ls ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lt l"><h3 class="bd b fi z dy lr ea eb ls ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lu l"><p class="bd b fp z dy lr ea eb ls ed ef dx translated">medium.com</p></div></div><div class="lv l"><div class="lw l lx ly lz lv ma jm lm"/></div></div></a></div></div></div>    
</body>
</html>
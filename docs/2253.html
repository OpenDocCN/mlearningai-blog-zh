<html>
<head>
<title>End to End Responsible AI with AML pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反洗钱渠道端到端负责任的人工智能</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/end-to-end-responsible-ai-with-aml-pipelines-b104705220bc?source=collection_archive---------2-----------------------#2022-04-02">https://medium.com/mlearning-ai/end-to-end-responsible-ai-with-aml-pipelines-b104705220bc?source=collection_archive---------2-----------------------#2022-04-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="944a" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">在培训脚本中使用负责任的AI和Azure ML进行端到端分类</h1><h1 id="c050" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">先决条件</h1><ul class=""><li id="8245" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="288d" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">存储帐户</li><li id="cca9" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">天蓝色ML</li></ul><h1 id="2d73" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">设置</h1><ul class=""><li id="9403" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">登录Azure ML工作区</li><li id="30a3" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">使用Python 3.6和Azure ML SDK创建笔记本</li><li id="14ed" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">让安装</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6685" class="ki if hh ke b fi kj kk l kl km">!pip install raiwidgets<br/>!pip install --upgrade raiwidgets<br/>!pip install --upgrade pandas</span></pre><ul class=""><li id="10c6" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">安装后重启内核</li><li id="82fa" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">测试安装</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="1274" class="ki if hh ke b fi kj kk l kl km">from raiwidgets import ResponsibleAIDashboard<br/>from responsibleai import RAIInsights</span></pre><h1 id="c6b4" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">代码/步骤</h1><ul class=""><li id="e321" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">检查AML版本</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="247b" class="ki if hh ke b fi kj kk l kl km">import azureml.core</span><span id="044c" class="ki if hh ke b fi ks kk l kl km">print("SDK version:", azureml.core.VERSION)</span></pre><ul class=""><li id="098d" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">发送诊断遥测</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="d520" class="ki if hh ke b fi kj kk l kl km">from azureml.telemetry import set_diagnostics_collection</span><span id="fb88" class="ki if hh ke b fi ks kk l kl km">set_diagnostics_collection(send_diagnostics=True)</span></pre><ul class=""><li id="9e98" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">登录Azure ML工作区</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="789f" class="ki if hh ke b fi kj kk l kl km">import azureml.core<br/>from azureml.core import Workspace<br/>import pandas as pd</span><span id="4f4e" class="ki if hh ke b fi ks kk l kl km"># Load the workspace from the saved config file<br/>ws = Workspace.from_config()<br/>print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))</span></pre><ul class=""><li id="2e12" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">加载数据</li><li id="b9e7" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">确保在相应的文件夹中有titanic.csv</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="a06a" class="ki if hh ke b fi kj kk l kl km">df= pd.read_csv('./Data/titanic.csv')<br/>print(df.shape)<br/>print(df.columns)</span><span id="36b4" class="ki if hh ke b fi ks kk l kl km">df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))<br/>df.isnull().sum()</span></pre><ul class=""><li id="f238" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">将客舱转换为loc</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="5984" class="ki if hh ke b fi kj kk l kl km">df['Loc']= df['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'X')</span></pre><ul class=""><li id="5af6" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">删除我们不需要的列</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="a2ad" class="ki if hh ke b fi kj kk l kl km">df.drop(['Cabin', 'Ticket'], axis=1, inplace=True)</span><span id="612d" class="ki if hh ke b fi ks kk l kl km">df.loc[:,'GroupSize'] = 1 + df['SibSp'] + df['Parch']</span></pre><ul class=""><li id="780d" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">为空值填充S</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="f8bf" class="ki if hh ke b fi kj kk l kl km">df['Embarked'] = df['Embarked'].fillna('S')</span></pre><ul class=""><li id="c310" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">清理数据集</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6cfa" class="ki if hh ke b fi kj kk l kl km">LABEL = 'Survived'<br/>columns_to_keep = ['Pclass', 'Sex','Age', 'Fare', 'Embared', 'Deck', 'GroupSize']<br/>columns_to_drop = ['Name','SibSp', 'Parch', 'Survived']<br/>df_train = df<br/>df = df_train.drop(['Name','SibSp', 'Parch', 'PassengerId'], axis=1)</span><span id="f0ff" class="ki if hh ke b fi ks kk l kl km">df.head(5)</span></pre><ul class=""><li id="add8" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创建培训文件夹</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="4d8f" class="ki if hh ke b fi kj kk l kl km">import os<br/>script_folder = os.path.join(os.getcwd(), "train_remote")<br/>print(script_folder)<br/>os.makedirs(script_folder, exist_ok=True)</span></pre><ul class=""><li id="8aac" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">验证文件是否已上传</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="a284" class="ki if hh ke b fi kj kk l kl km">df.to_csv('./train_remote/titanic.csv')<br/>df.head(2)</span></pre><ul class=""><li id="f699" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创建数据集</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="96c8" class="ki if hh ke b fi kj kk l kl km">from azureml.core import Dataset</span><span id="c012" class="ki if hh ke b fi ks kk l kl km">#use default datastore retrieved from the workspace through the AML SDK<br/>default_ds = ws.get_default_datastore()<br/></span><span id="cf05" class="ki if hh ke b fi ks kk l kl km">default_ds.upload_files(files=['./train_remote/titanic.csv'], # Upload the diabetes csv files in /data<br/>                        target_path= 'Titanic-data', # Put it in a folder path in the datastore<br/>                        overwrite=True, # Replace existing files of the same name<br/>                        show_progress=True)<br/>#Create a tabular dataset from the path on the datastore <br/>dataset = Dataset.Tabular.from_delimited_files(default_ds.path('Titanic-data/titanic.csv'))</span><span id="32f1" class="ki if hh ke b fi ks kk l kl km"># Register the dataset<br/>try:<br/>    tab_data_set = dataset.register(workspace=ws, <br/>                                name= 'Titanic-tabular-dataset',<br/>                                description='Tintanic data',<br/>                                tags = {'format':'csv'},<br/>                                create_new_version=True)<br/>    print('Dataset registered.')<br/>except Exception as ex:<br/>        print(ex)</span></pre><ul class=""><li id="f7ae" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在从数据集读取</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="fbaa" class="ki if hh ke b fi kj kk l kl km"># azureml-core of version 1.0.72 or higher is required<br/># azureml-dataprep[pandas] of version 1.1.34 or higher is required<br/>from azureml.core import Workspace, Dataset</span><span id="3d37" class="ki if hh ke b fi ks kk l kl km">subscription_id = 'xxxxxxxxxxxxxxxxxxxx'<br/>resource_group = 'RGName'<br/>workspace_name = 'AMLWorkspaceName'</span><span id="02b0" class="ki if hh ke b fi ks kk l kl km">workspace = Workspace(subscription_id, resource_group, workspace_name)</span><span id="874a" class="ki if hh ke b fi ks kk l kl km">dataset = Dataset.get_by_name(workspace, name='Titanic-tabular-dataset')<br/>dataset.to_pandas_dataframe()</span></pre><ul class=""><li id="53c3" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创造一个实验</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="2869" class="ki if hh ke b fi kj kk l kl km">from azureml.core.experiment import Experiment<br/>experiment = Experiment(ws, 'titanic_remote_compute')</span></pre><ul class=""><li id="5f8c" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创建一个文件夹来存储培训脚本</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="dc7f" class="ki if hh ke b fi kj kk l kl km">import os<br/>script_folder = os.path.join(os.getcwd(), "train")<br/>print(script_folder)<br/>os.makedirs(script_folder, exist_ok=True)</span></pre><ul class=""><li id="81f1" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创建培训脚本</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="c749" class="ki if hh ke b fi kj kk l kl km">%%writefile $script_folder/training.py</span><span id="a8f1" class="ki if hh ke b fi ks kk l kl km">import os<br/>import sys<br/>import argparse<br/>import joblib<br/>import pandas as pd<br/>import numpy as np</span><span id="ccc4" class="ki if hh ke b fi ks kk l kl km">from azureml.core import Run, Dataset, Workspace, Experiment</span><span id="f194" class="ki if hh ke b fi ks kk l kl km">from sklearn.compose import ColumnTransformer<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import OneHotEncoder, StandardScaler<br/>from sklearn.metrics import roc_auc_score,roc_curve<br/>from interpret.ext.blackbox import TabularExplainer<br/>from azureml.interpret import ExplanationClient</span><span id="a23c" class="ki if hh ke b fi ks kk l kl km">from raiwidgets import ResponsibleAIDashboard<br/>from responsibleai import RAIInsights</span><span id="1d6a" class="ki if hh ke b fi ks kk l kl km"># Calculate model performance metrics<br/>from sklearn.metrics import confusion_matrix</span><span id="1c62" class="ki if hh ke b fi ks kk l kl km">import matplotlib.pyplot as plt</span><span id="62d5" class="ki if hh ke b fi ks kk l kl km">from azureml.core import Model<br/>from azureml.core.resource_configuration import ResourceConfiguration</span><span id="e8e0" class="ki if hh ke b fi ks kk l kl km">def getRuntimeArgs():<br/>    parser = argparse.ArgumentParser()<br/>    <br/>    parser = argparse.ArgumentParser()<br/>    parser.add_argument("--input-data", type=str)<br/>    args = parser.parse_args()<br/>    return args</span><span id="5a7c" class="ki if hh ke b fi ks kk l kl km">def buildpreprocessorpipeline(X_raw):<br/>    categorical_features = X_raw.select_dtypes(include=['object']).columns<br/>    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns</span><span id="125f" class="ki if hh ke b fi ks kk l kl km">    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value="missing")),<br/>                                              ('onehotencoder', OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])<br/>    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])<br/>    <br/>    preprocessor = ColumnTransformer(<br/>        transformers=[<br/>            ('numeric', numeric_transformer, numeric_features),<br/>            ('categorical', categorical_transformer, categorical_features)<br/>        ], remainder="drop")<br/>    <br/>    return preprocessor</span><span id="7048" class="ki if hh ke b fi ks kk l kl km">def model_train(LABEL, df, run):  <br/>    y_raw = df[LABEL]<br/>    X_raw = df.drop([LABEL], axis=1)<br/>    <br/>     # Train test split<br/>    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.3, random_state=0)<br/>    <br/>    lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')<br/>    preprocessor = buildpreprocessorpipeline(X_train)<br/>    <br/>    #estimator instance<br/>    clf = Pipeline(steps=[('preprocessor', preprocessor),<br/>                               ('regressor', lg)])</span><span id="3d83" class="ki if hh ke b fi ks kk l kl km">    model = clf.fit(X_train, y_train)<br/>    <br/>    <br/>    # calculate AUC<br/>    y_scores = model.predict_proba(X_test)<br/>    auc = roc_auc_score(y_test,y_scores[:,1])<br/>    print('AUC: ' + str(auc))<br/>    run.log('AUC', np.float(auc))</span><span id="959c" class="ki if hh ke b fi ks kk l kl km">    <br/>    # calculate test accuracy<br/>    y_hat = model.predict(X_test)<br/>    acc = np.average(y_hat == y_test)<br/>    print('Accuracy:', acc)<br/>    run.log('Accuracy', np.float(acc))</span><span id="ebd3" class="ki if hh ke b fi ks kk l kl km">    # plot ROC curve<br/>    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])<br/>    fig = plt.figure(figsize=(6, 4))<br/>    # Plot the diagonal 50% line<br/>    plt.plot([0, 1], [0, 1], 'k--')<br/>    # Plot the FPR and TPR achieved by our model<br/>    plt.plot(fpr, tpr)<br/>    plt.xlabel('False Positive Rate')<br/>    plt.ylabel('True Positive Rate')<br/>    plt.title('ROC Curve')<br/>    run.log_image(name = "ROC", plot = fig)<br/>    plt.show()</span><span id="5cc7" class="ki if hh ke b fi ks kk l kl km">    # plot confusion matrix<br/>    # Generate confusion matrix<br/>    cmatrix = confusion_matrix(y_test, y_hat)<br/>    cmatrix_json = {<br/>        "schema_type": "confusion_matrix",<br/>           "schema_version": "v1",<br/>           "data": {<br/>               "class_labels": ["0", "1"],<br/>               "matrix": [<br/>                   [int(x) for x in cmatrix[0]],<br/>                   [int(x) for x in cmatrix[1]]<br/>               ]<br/>           }<br/>    }<br/>    <br/>    run.log_confusion_matrix('ConfusionMatrix_Test', cmatrix_json)<br/>    <br/>    os.makedirs('outputs', exist_ok=True)<br/>    <br/>    <br/>    model_file = os.path.join('outputs', 'titanic_model.pkl')<br/>    joblib.dump(value=model, filename=model_file)<br/>    <br/>    run.upload_file(name='titanic_model.pkl', path_or_stream=model_file)<br/>    run.log('accuracy', acc)<br/>    run.set_tags({ 'Accuracy' : np.float(acc)})<br/>    <br/>    # Register the model<br/>    print('Registering model...')<br/>    run.register_model(model_path='titanic_model.pkl', model_name= 'titanic-model',<br/>                   tags={'Model Type':'Logistic Regresssion'},<br/>                   properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})<br/>    <br/>    #features = "'Column1', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Loc', 'GroupSize'"<br/>    #df1 = df.drop('Survived', inplace=true)<br/>    #df1 = df<br/>    columns = ['Survived']<br/>    #df = df.drop('Survived', axis=1, inplace=True)<br/>    df = df.drop(columns, axis=1)<br/>    print(df.columns)<br/>    client = ExplanationClient.from_run(run)<br/>    # Explain predictions on your local machine<br/>    tabular_explainer = TabularExplainer(model, X_train, features=df.columns)</span><span id="fe19" class="ki if hh ke b fi ks kk l kl km">    # Explain overall model predictions (global explanation)<br/>    # Passing in test dataset for evaluation examples - note it must be a representative sample of the original data<br/>    # x_train can be passed as well, but with more examples explanations it will<br/>    # take longer although they may be more accurate<br/>    global_explanation = tabular_explainer.explain_global(X_test)</span><span id="5565" class="ki if hh ke b fi ks kk l kl km">    # Uploading model explanation data for storage or visualization in webUX<br/>    # The explanation can then be downloaded on any compute<br/>    comment = 'Global explanation on regression model trained on boston dataset'<br/>    client.upload_model_explanation(global_explanation, comment=comment, model_id=model)<br/>    categorical_features = X_raw.select_dtypes(include=['object']).columns<br/>    target_feature = LABEL<br/>    train_data = X_train.copy()<br/>    test_data = X_test.copy()<br/>    train_data[target_feature] = y_train<br/>    test_data[target_feature] = y_test<br/>    #data.feature_names</span><span id="bf67" class="ki if hh ke b fi ks kk l kl km">    rai_insights = RAIInsights(model, train_data, test_data, LABEL, 'classification', <br/>                               categorical_features=['Sex','Embarked','Loc'])<br/>    # Interpretability<br/>    rai_insights.explainer.add()<br/>    # Error Analysis<br/>    rai_insights.error_analysis.add()<br/>    # Counterfactuals: accepts total number of counterfactuals to generate, the range that their label should fall under, <br/>    # and a list of strings of categorical feature names<br/>    rai_insights.counterfactual.add(total_CFs=20, desired_class='opposite')<br/>    rai_insights.compute()<br/>    ResponsibleAIDashboard(rai_insights)<br/></span><span id="aa0d" class="ki if hh ke b fi ks kk l kl km">    return model, auc, acc<br/>    # Save the trained model<br/>    <br/>    <br/>def main():<br/>    # Create an Azure ML experiment in your workspace<br/>    args = getRuntimeArgs()<br/>    <br/>    run = Run.get_context()<br/>    client = ExplanationClient.from_run(run)</span><span id="9372" class="ki if hh ke b fi ks kk l kl km">    dataset_dir = './dataset/'<br/>    os.makedirs(dataset_dir, exist_ok=True)<br/>    ws = run.experiment.workspace<br/>    print(ws)<br/>    </span><span id="59a7" class="ki if hh ke b fi ks kk l kl km">    print("Loading Data...")<br/>    dataset = Dataset.get_by_id(ws, id=args.input_data)<br/>    # Load a TabularDataset &amp; save into pandas DataFrame<br/>    df = dataset.to_pandas_dataframe()<br/>    <br/>    print(df.head(5))<br/> <br/>    model, auc, acc = model_train('Survived', df, run)<br/>    <br/>    #os.makedirs('outputs', exist_ok=True)<br/>    <br/>    <br/>    #model_file = os.path.join('outputs', 'titanic_model.pkl')<br/>    #joblib.dump(value=model, filename=model_file)<br/>    <br/>    #run.upload_file(name='titanic_model.pkl', path_or_stream=model_file)<br/>    #run.log('accuracy', acc)<br/>    #run.set_tags({ 'Accuracy' : np.float(acc)})<br/>    <br/>    # Register the model<br/>    #print('Registering model...')<br/>    #run.register_model(model_path='titanic_model.pkl', model_name= 'titanic-model',<br/>    #               tags={'Model Type':'Logistic Regresssion'},<br/>    #               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})<br/>   </span><span id="d7a8" class="ki if hh ke b fi ks kk l kl km">    run.complete()</span><span id="fd75" class="ki if hh ke b fi ks kk l kl km">if __name__ == "__main__":<br/>    main()</span></pre><ul class=""><li id="0728" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创建环境文件</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="8766" class="ki if hh ke b fi kj kk l kl km">%%writefile $script_folder/experiment_env.yml<br/>name: experiment_env<br/>dependencies:<br/>  # The python interpreter version.<br/>  # Currently Azure ML only supports 3.5.2 and later.<br/>- python=3.6.2<br/>- scikit-learn<br/>- ipykernel<br/>- matplotlib<br/>- pandas<br/>- pip<br/>- pip:<br/>  - azureml-defaults<br/>  - pyarrow<br/>  - interpret<br/>  - azureml-interpret<br/>  - lightgbm<br/>  - raiwidgets</span></pre><ul class=""><li id="b01a" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">创建环境对象并提供上述文件</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="2240" class="ki if hh ke b fi kj kk l kl km">from azureml.core import Environment</span><span id="d93d" class="ki if hh ke b fi ks kk l kl km"># Create a Python environment for the experiment (from a .yml file)<br/>experiment_env = Environment.from_conda_specification('experiment-env', script_folder + "/experiment_env.yml")</span><span id="d5b4" class="ki if hh ke b fi ks kk l kl km"># Let Azure ML manage dependencies<br/>experiment_env.python.user_managed_dependencies = False </span><span id="742c" class="ki if hh ke b fi ks kk l kl km"># Print the environment details<br/>print(experiment_env.name, 'defined.')<br/>print(experiment_env.python.conda_dependencies.serialize_to_string())</span></pre><ul class=""><li id="1720" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在在本地模式下运行实验</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="8343" class="ki if hh ke b fi kj kk l kl km">import azureml.core.runconfig<br/>from azureml.core import Environment, Experiment<br/>from azureml.core import ScriptRunConfig<br/>from azureml.widgets import RunDetails</span><span id="965f" class="ki if hh ke b fi ks kk l kl km"># Get the training dataset<br/>titanic_ds = ws.datasets.get('Titanic-tabular-dataset')</span><span id="2f7e" class="ki if hh ke b fi ks kk l kl km"># Create a script config<br/>script_config = ScriptRunConfig(source_directory=script_folder,<br/>                                script='training.py',<br/>                                arguments=['--input-data', titanic_ds.as_named_input('titanic')], # Reference to dataset<br/>                                environment=experiment_env) </span><span id="36e6" class="ki if hh ke b fi ks kk l kl km"># submit the experiment<br/>run = experiment.submit(config=script_config)<br/>RunDetails(run).show()<br/>run.wait_for_completion()</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kt"><img src="../Images/38f6d64a3b50c542ba895c9facd48f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xr-HCvqQancUOSsH.jpg"/></div></div></figure><ul class=""><li id="07c7" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">本地运行是确保代码正常工作</li><li id="4309" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">实际代码应该在远程计算机上运行</li><li id="443c" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">现在创建远程计算机群集</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="88fe" class="ki if hh ke b fi kj kk l kl km">from azureml.core.compute import ComputeTarget, AmlCompute<br/>from azureml.core.compute_target import ComputeTargetException</span><span id="6e8e" class="ki if hh ke b fi ks kk l kl km">cluster_name = "cpu-cluster"</span><span id="a14f" class="ki if hh ke b fi ks kk l kl km">try:<br/>    # Check for existing compute target<br/>    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)<br/>    print('Found existing cluster, use it.')<br/>except ComputeTargetException:<br/>    # If it doesn't already exist, create it<br/>    try:<br/>        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)<br/>        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)<br/>        training_cluster.wait_for_completion(show_output=True)<br/>    except Exception as ex:<br/>        print(ex)</span></pre><ul class=""><li id="bcde" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在在远程模式下运行实验</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="f635" class="ki if hh ke b fi kj kk l kl km">import azureml.core.runconfig<br/>from azureml.core import Environment, Experiment<br/>from azureml.core import ScriptRunConfig<br/>from azureml.widgets import RunDetails</span><span id="b8d0" class="ki if hh ke b fi ks kk l kl km"># Get the training dataset<br/>titanic_ds = ws.datasets.get('Titanic-tabular-dataset')</span><span id="d619" class="ki if hh ke b fi ks kk l kl km"># Create a script config<br/>script_config = ScriptRunConfig(source_directory=script_folder,<br/>                                script='training.py',<br/>                                arguments=['--input-data', titanic_ds.as_named_input('titanic')], # Reference to dataset<br/>                                environment=experiment_env,<br/>                                compute_target=cluster_name)</span><span id="36b5" class="ki if hh ke b fi ks kk l kl km"># submit the experiment<br/>run = experiment.submit(config=script_config)<br/>RunDetails(run).show()</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lb"><img src="../Images/0a69b3385c7ea3f117d03ac5f9e674a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rm__L5HB29jMEbeH.jpg"/></div></div></figure><ul class=""><li id="97d6" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在运行超空间引擎优化模型</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="9c0f" class="ki if hh ke b fi kj kk l kl km">from azureml.core.run import Run<br/>run_logger = Run.get_context()<br/>#run_logger.log("accuracy", float(accuracy))</span></pre><ul class=""><li id="21be" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">设置提前终止</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="b108" class="ki if hh ke b fi kj kk l kl km">from azureml.train.hyperdrive import BanditPolicy<br/>early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)</span></pre><ul class=""><li id="9d27" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">加载数据集以获取数据集id</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="83e1" class="ki if hh ke b fi kj kk l kl km">ds = Dataset.get_by_name(ws, name="Titanic-tabular-dataset")</span></pre><ul class=""><li id="b51e" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">现在运行超光速引擎</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="084c" class="ki if hh ke b fi kj kk l kl km">from azureml.train.hyperdrive.runconfig import HyperDriveConfig<br/>from azureml.train.hyperdrive.sampling import RandomParameterSampling<br/>from azureml.train.hyperdrive.run import PrimaryMetricGoal<br/>from azureml.train.hyperdrive.parameter_expressions import choice<br/>    <br/>#arguments=['--input-data', titanic_ds.as_named_input('titanic')], # Reference to dataset</span><span id="8bfe" class="ki if hh ke b fi ks kk l kl km">titanic_ds = ws.datasets.get('Titanic-tabular-dataset')</span><span id="5fb4" class="ki if hh ke b fi ks kk l kl km"># Create a script config<br/>script_config = ScriptRunConfig(source_directory=script_folder,<br/>                                script='training.py',<br/>                                arguments=['--input-data', titanic_ds.as_named_input('titanic')], # Reference to dataset<br/>                                environment=experiment_env,<br/>                                compute_target=cluster_name) </span><span id="61a6" class="ki if hh ke b fi ks kk l kl km">param_sampling = RandomParameterSampling( {<br/>    "input-data": ds.id<br/>    }<br/>)</span><span id="ee46" class="ki if hh ke b fi ks kk l kl km">early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)</span><span id="cc7e" class="ki if hh ke b fi ks kk l kl km">hd_config = HyperDriveConfig(run_config=script_config,<br/>                             hyperparameter_sampling=param_sampling,<br/>                             policy=early_termination_policy,<br/>                             primary_metric_name="accuracy",<br/>                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,<br/>                             max_total_runs=4,<br/>                             max_concurrent_runs=4)<br/>hyperdrive_run = experiment.submit(hd_config)<br/>from azureml.widgets import RunDetails<br/>RunDetails(hyperdrive_run).show()</span></pre><figure class="jz ka kb kc fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lc"><img src="../Images/1c22fbd1e9279cd82dd7b65f63d3b802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YuI-0_Q-jYpmVfFU.jpg"/></div></div></figure><ul class=""><li id="fead" class="jc jd hh je b jf kn jh ko jj kp jl kq jn kr jp jq jr js jt bi translated">原文—<a class="ae ld" href="https://github.com/balakreshnan/Samples2022/blob/main/AzureML/etoeRAI.md" rel="noopener ugc nofollow" target="_blank">samples 2022/eto erai . MD at main balakreshnan/samples 2022(github.com)</a></li></ul><div class="le lf ez fb lg lh"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="li ab dw"><div class="lj ab lk cl cj ll"><h2 class="bd hi fi z dy lm ea eb ln ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lo l"><h3 class="bd b fi z dy lm ea eb ln ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lp l"><p class="bd b fp z dy lm ea eb ln ed ef dx translated">medium.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv kz lh"/></div></div></a></div></div></div>    
</body>
</html>
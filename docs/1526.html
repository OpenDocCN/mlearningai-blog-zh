<html>
<head>
<title>Whats the point of Matrix decomposition?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">矩阵分解的意义是什么？</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/whats-the-point-of-matrix-decompositions-15435781658f?source=collection_archive---------5-----------------------#2021-12-30">https://medium.com/mlearning-ai/whats-the-point-of-matrix-decompositions-15435781658f?source=collection_archive---------5-----------------------#2021-12-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/43941bf8b20bf79fb77a460045fe8bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HfrUozVjgUvxN5-RGnIg3w.jpeg"/></div></div></figure><div class=""/><p id="1733" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个话题是我脑海中的一个大黑洞，所以我试图将帮助我理解<strong class="ir ht">特征分解</strong>和<strong class="ir ht">奇异值分解(SVD) </strong>的信息汇集在一起。</p><p id="cd00" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为此，我将快速概括<strong class="ir ht">决定因素</strong>和<strong class="ir ht">基础</strong>。如果你已经很熟悉了，可以直接跳到<strong class="ir ht">特征分解</strong>这一段。</p><h1 id="1b39" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">决定因素</h1><p id="fd6c" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">一个行列式通过某种变换<strong class="ir ht"> <em class="kq"> E </em> </strong>回答面积如何缩放的问题？</p><p id="7034" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">例如:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kr"><img src="../Images/e507d9eaf92395b1c0976ecf847355c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJBj2ya3WUScJ18HpqlhwQ.png"/></div></div></figure><p id="d48c" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以在这个给定的例子中<strong class="ir ht"> <em class="kq"> E </em> </strong>的行列式，或者说一个变换的缩放因子，就是<strong class="ir ht"> <em class="kq"> -3 </em> </strong>。负行列式现在是什么意思？这意味着空间的方向已经颠倒或者轴已经翻转。所以行列式<em class="kq"> </em> <strong class="ir ht"> <em class="kq"> -3 </em> </strong>就意味着轴翻转过来，面积按<strong class="ir ht"> <em class="kq"> 3 </em> </strong>缩放。</p><p id="d24e" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一个有趣的性质是当一个变换的行列式等于<strong class="ir ht"> <em class="kq"> 0 </em> </strong>时。这意味着变换的面积将变为零，因为基向量彼此对齐。这种情况降低了向量的维数。</p><h1 id="da88" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">基础</h1><p id="9ce0" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">坐标系的基本向量描述了坐标系中轴的方向。例如，二维坐标系可以通过基向量<strong class="ir ht"> <em class="kq"> x </em> </strong>和<strong class="ir ht"> <em class="kq"> y </em> </strong>来描述。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kw"><img src="../Images/f45f1b29b294e35172e943b8a82c2fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*72o6c5IRHGbVQH5jwerzHw.png"/></div></div></figure><p id="9681" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以无论何时你在这个基础上描述任何东西，这些值都会和基础向量成比例。这些基向量包含什么值并不重要，所以它们也可以是:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kx"><img src="../Images/0a75a448813799b2ecb7efc6330e3ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9I-am2wXp_QiBLjQKZ01zg.png"/></div></div></figure><p id="c5bc" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以要把一个矢量<strong class="ir ht"> <em class="kq"> x_b </em> </strong>从坐标系<strong class="ir ht"> <em class="kq"> b </em> </strong>平移到我们的坐标系<strong class="ir ht"> <em class="kq"> a </em> </strong>中，我们可以使用坐标系的平移。我们知道<strong class="ir ht"> <em class="kq"> b </em> </strong>的基向量是如何在基<strong class="ir ht"> <em class="kq"> a </em> </strong>中表示的:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ky"><img src="../Images/d501cdb92333bb64c28cd4bac9d84537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfVL1_YMRb987nUlixATWA.png"/></div></div></figure><p id="ba01" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以为了翻译<strong class="ir ht"> <em class="kq"> x_b </em> </strong>我们将每个基向量<strong class="ir ht"> <em class="kq"> b </em> </strong>与向量<strong class="ir ht"> <em class="kq"> x </em> </strong>的某个坐标相乘:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kz"><img src="../Images/803122c087b5f366ea7f3475918b1e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-lptRb1YiqN8STc9Tb35g.png"/></div></div></figure><p id="a96a" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们有一个转换矩阵，它从基<strong class="ir ht"> <em class="kq"> b → a </em> </strong>:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es la"><img src="../Images/a6857d33570e3f0312fb08f06a178812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*STSnbSUGlv67eCOaogjiqw.png"/></div></div></figure><p id="2d62" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了反过来，从基础<strong class="ir ht"> <em class="kq"> a →b </em> </strong>我们需要<strong class="ir ht"> <em class="kq"> T </em> </strong>什么是<strong class="ir ht"><em class="kq"/></strong>(我不涵盖如何计算逆)。</p><p id="7912" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了将一个变换<strong class="ir ht"><em class="kq">【oₐ】</em></strong>从一个基础<strong class="ir ht"> <em class="kq"> a </em> </strong>转换到基础<strong class="ir ht"> <em class="kq"> b </em> </strong>需要完成以下操作:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lb"><img src="../Images/1faeda95c8bc927c2ac8c71486f0eed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tMWjjy9PW0uXFNW3il2GQA.png"/></div></div></figure><p id="dd92" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先，我们从base <strong class="ir ht"> <em class="kq"> b → a </em> </strong>转换为<strong class="ir ht"> <em class="kq"> T </em> </strong>。然后，在我们使用逆变换<strong class="ir ht"><em class="kq">【t⁻</em></strong>】将其再次变换回基数<strong class="ir ht"><em class="kq">【b】</em></strong>之前，我们在基数a中应用变换<strong class="ir ht"><em class="kq"/></strong>。因此，将矢量<strong class="ir ht"> <em class="kq"> v </em> </strong>转换为如下形式:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lc"><img src="../Images/69a0e70225f45f7f7aa77a35a4dde55a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9hLX6d9Ia77m0K8xkcP4g.png"/></div></div></figure><h1 id="d1e8" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">特征分解</h1><p id="0965" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">特征向量<strong class="ir ht"> <em class="kq"> v </em> </strong>是某个矩阵变换<strong class="ir ht"> <em class="kq"> A </em> </strong>不通过这个变换改变方向的向量。但它可以被拉伸或压缩一个因子，这个因子叫做特征值<strong class="ir ht"> <em class="kq"> λ </em> </strong>。因此，对其特征值<strong class="ir ht"><em class="kq"/></strong>的变换<strong class="ir ht"> <em class="kq"> A </em> </strong>将给出与仅仅拉伸或挤压特征向量<strong class="ir ht"> <em class="kq"> v </em> </strong>相同的结果。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es ld"><img src="../Images/e42514c5ce1b2352b91abab9a0d5a9da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8aJKa08vRe8XEXLL3Yyb9w.png"/></div></div></figure><p id="ac18" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果特征值等于<strong class="ir ht"> <em class="kq"> 1 </em> </strong>，那么特征向量描述的是矩阵变换的旋转轴。</p><p id="8dc7" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了计算特征向量，我们可以将该方程转化为以下形式:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es le"><img src="../Images/b8d404f8c61e1c1365369bf48a2b2924.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F-drxliFRr4P1-nzUwNCow.png"/></div></div></figure><p id="a090" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以<em class="kq"/><strong class="ir ht"><em class="kq">A-λI</em></strong>和<strong class="ir ht"> <em class="kq"> v </em> </strong>的乘积需要为零。一个变换(<strong class="ir ht"> <em class="kq"> A - λI </em> </strong>)和一个向量(<strong class="ir ht"> <em class="kq"> v </em> </strong>)的乘积只有在相关联的变换<strong class="ir ht"> <em class="kq"> A - λI </em> </strong>将向量<strong class="ir ht"> <em class="kq"> v </em> </strong>挤压到一个更低维的空间中时才能变成零——这意味着行列式(通过变换的面积缩放因子)必须为零！这是在低维空间中，因为基本向量排列成相同的方向，因此它们没有打开一个区域(行列式描述的)。</p><p id="ba1b" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在低维向量中<strong class="ir ht"> <em class="kq"> v </em> </strong>变成了一个点而不是一个向量。</p><h2 id="07dc" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">特征向量现在有什么用？</h2><p id="097a" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">特征向量对于计算对矩阵复杂但对对角矩阵简单的运算很有帮助，因为它们可以将矩阵转换成对角形式。在对角线形式的计算中，像矩阵的乘方要容易得多。</p><p id="5164" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为此，矩阵必须被带入特征向量的基向量表示，称为<strong class="ir ht">特征基</strong>。如果矩阵有足够的特征向量(最少的轴数)，转换将保证一个可以应用复杂计算的<strong class="ir ht">对角矩阵</strong>表示。那么结果可以很容易地被带回原点坐标系。对角矩阵包含对角线上的特征值，即特征基中特定轴的比例因子。</p><h2 id="c986" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">摘要</h2><ul class=""><li id="ac80" class="lt lu hs ir b is kl iw km ja lv je lw ji lx jm ly lz ma mb bi translated">将变换引入特征基:</li></ul><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mc"><img src="../Images/d2c49f98c4b2c7d34718d1542c8240e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QEplnq0xEo6y41_nKzPB4w.png"/></div></div></figure><ul class=""><li id="7e47" class="lt lu hs ir b is it iw ix ja md je me ji mf jm ly lz ma mb bi translated">将特征基中的对角矩阵带到原始基中:</li></ul><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mg"><img src="../Images/ac92a214f8bf76845e9a17cf41127053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o_YhDNDUkSmTFcyB1K2Giw.png"/></div></div></figure><h2 id="8d6d" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">例子</h2><p id="6380" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为了利用这一点，这里有一个例子:</p><p id="a55c" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们有一个变换矩阵<strong class="ir ht"> <em class="kq"> A </em> </strong>，我们想对其应用一个运算，例如将它提升到幂<strong class="ir ht"> <em class="kq"> b </em> </strong>。由于这个操作对于非对角矩阵来说是复杂的，所以我们希望采用对角形式。为此我们需要特征向量<strong class="ir ht"> <em class="kq"> p </em> </strong>来构建矩阵<strong class="ir ht"> <em class="kq"> P </em> </strong>的列。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mh"><img src="../Images/203191c80a0430d2bd1494af71fe4ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eDoqF55LHtFwc5ZXj1pNNA.png"/></div></div></figure><p id="3d36" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将<strong class="ir ht"> <em class="kq"> A </em> </strong>带入了本征基，其中这种变换通过对角矩阵<strong class="ir ht"> <em class="kq"> D </em> </strong>来说明。</p><p id="1bf0" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们可以将我们想要的操作应用到<strong class="ir ht"> <em class="kq"> D </em> </strong>并将其带回我们的原点:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mi"><img src="../Images/c19ba41ab314d820abac7887b592e540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DC4oPfn9t3M1phGiQjYYyw.png"/></div></div></figure><p id="fad6" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">仅此而已！</p><h1 id="9a05" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">奇异值分解</h1><p id="d73f" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为什么会有另一种形式的分解？特征分解还不够吗？</p><p id="4bea" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">可惜没有！特征分解只适用于方阵。奇异值分解处理所有类型的矩阵，并且始终存在！</p><p id="3f5a" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是概念保持不变:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mj"><img src="../Images/5e27dee7eda49b48502b1d04a1e61fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29XVdeSXIgPNcKC4B3Yj1g.png"/></div></div></figure><p id="9d59" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们有一个变换<strong class="ir ht"><em class="kq"/></strong>，它可以分成三个操作，将变换带入另一个发生挤压或拉伸的基底。与本征分解相反，我们没有另外一个基，而是有两个。其原因是原点矩阵<strong class="ir ht"><em class="kq"/></strong>的给定维数。它可以是<strong class="ir ht"> <em class="kq"> m×n </em> </strong>的形式，而不是正方形。</p><p id="3dad" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先，<strong class="ir ht"> <em class="kq">大小为<strong class="ir ht"> <em class="kq"> (n×n) </em> </strong>的V^T </em> </strong>将一个矢量从基<strong class="ir ht"> <em class="kq"> A </em> </strong>带入基<strong class="ir ht"> <em class="kq"> B </em> </strong>。</p><p id="81cc" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后<strong class="ir ht"><em class="kq">【σ】</em></strong><strong class="ir ht"><em class="kq">(m×n)</em></strong>像<strong class="ir ht"><em class="kq"/></strong>一样对基向量执行缩放，因为它是对角矩阵。然而，它不仅应用变换，而且将计算从基数<strong class="ir ht"> <em class="kq"> B </em> </strong>变换到基数<strong class="ir ht"> <em class="kq"> C </em> </strong>。</p><p id="a0d9" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，大小为<strong class="ir ht"> <em class="kq"> (m×m) </em> </strong>的<strong class="ir ht"> <em class="kq"> U </em> </strong>将计算从基数<strong class="ir ht"> <em class="kq"> C </em> </strong>带回基数<strong class="ir ht"> <em class="kq"> A </em> </strong>。</p><p id="f73d" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">特征分解和奇异值分解有着密切的联系。在下面我们可以看到为什么。</p><h2 id="f740" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">催单</h2><p id="b690" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我们知道，对于方阵<strong class="ir ht"><em class="kq">a∈</em>ℝ<em class="kq">^{n×n}</em></strong>总有一个矩阵<strong class="ir ht"> <em class="kq"> P </em> </strong>可以将矩阵转化为特征基。</p><p id="f2bf" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一个矩阵<strong class="ir ht"> <em class="kq">一个</em> </strong>可以通过乘以逆矩阵<strong class="ir ht"><em class="kq"/></strong>变换成一个方阵:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mk"><img src="../Images/f17b22b4bd955e0f3abf525a0cbfb370.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrOgxOcHa9jAb98kJ9225g.png"/></div></div></figure><h2 id="14e4" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">德拉贡诺夫狙击步枪（Snayperskaya Vinyovka Dragunov的缩写）</h2><p id="e110" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">对于奇异值分解我们需要找出的是形状为<strong class="ir ht"> <em class="kq"> n×n </em> </strong>和形状为<strong class="ir ht"> <em class="kq"> m×m </em> </strong>的<strong class="ir ht"><em class="kq"/></strong>矩阵。所以我们先从<strong class="ir ht"> <em class="kq"> V、</em> </strong>右边的——奇异向量开始，因为<strong class="ir ht"> <em class="kq"> V </em> </strong>的右边部分是方程<strong class="ir ht"><em class="kq">a = uσv^t</em></strong>并说明了<em class="kq"> n×n </em> 的基础。相应地，我们通过计算形状<strong class="ir ht"> <em class="kq"> m×m </em> </strong>的<strong class="ir ht"><em class="kq"/></strong>来执行左奇异向量。</p><h2 id="b573" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">右奇异向量<em class="ml"> V </em></h2><p id="4ef8" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">这一知识有助于我们将形状为<strong class="ir ht"> <em class="kq"> n×n </em> </strong>的矩形矩阵<strong class="ir ht"> <em class="kq"> A </em> </strong>变成正方形，然后允许我们应用特征分解:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mm"><img src="../Images/dfb9c6120cbec43a0928e74f407844f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hpL4IrEuvJEpwnbZb0iqQ.png"/></div></div></figure><p id="7a08" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">用奇异值分解方程对其进行分解，还可以得到以下结果:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mn"><img src="../Images/1c38df12e70be6525f3d3a95bbb5db84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1u6-ajv5RgA7lSfevBKiA.png"/></div></div></figure><p id="cf40" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这两个公式看起来非常相似，并导致这样的假设:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mo"><img src="../Images/ab92c418b4373ce681707eb0140c6491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SFAmKB91eBm7zOCTT1_a_A.png"/></div></div></figure><p id="9ecc" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">相应地，我们可以应用<strong class="ir ht"><em class="kq"/></strong>的特征分解来计算特征矩阵<strong class="ir ht"> <em class="kq"> P </em> </strong>等于<strong class="ir ht"> <em class="kq"> V </em> </strong>。</p><h2 id="50ec" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">左奇异向量U</h2><p id="1ab1" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">类似于右奇异向量，我们想得到一个形状为<strong class="ir ht"> <em class="kq"> n×n </em> </strong>的矩阵，我们可以通过<strong class="ir ht"><em class="kq">【aa^t】</em></strong>得到。</p><p id="8aae" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">相应地，我们可以计算构成矩阵<strong class="ir ht"> <em class="kq"> P </em> </strong>的特征向量，该矩阵等于<strong class="ir ht"><em class="kq"/></strong>。</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mp"><img src="../Images/0125f25e7512b1b7c912c581444a3c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mU0jkIU-_698hPyqMLDoSA.png"/></div></div></figure><p id="5989" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为此，我们可以找到u中的特征向量。</p><h2 id="be49" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">奇异值<strong class="ak">σ</strong></h2><p id="e49b" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为了获得奇异值<strong class="ir ht"><em class="kq"/></strong>，我们必须从右奇异或左奇异向量中取出已经计算的对角矩阵<strong class="ir ht"><em class="kq">【d(σ^{t}σ)</em></strong>并求平方根。这很容易，因为<strong class="ir ht"> <em class="kq"> D </em> </strong>是一个对角线矩阵，包含对角线上的特征值。</p><p id="65e1" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir ht"><em class="kq">σ</em></strong>形状为<strong class="ir ht"><em class="kq"/></strong>，若<strong class="ir ht"> <em class="kq"> m≠n </em> </strong>较大轴用零填充。</p><p id="afc1" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">例如:</p><figure class="ks kt ku kv fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es mq"><img src="../Images/176c27e9e7eac2e69f248202b5f946a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJq3bvBaqAXH271op_8A8Q.png"/></div></div></figure><h2 id="f574" class="lf jo hs bd jp lg lh li jt lj lk ll jx ja lm ln kb je lo lp kf ji lq lr kj ls bi translated">有什么好处？</h2><p id="bfca" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">通过奇异值分解可以得到重要的信息。<strong class="ir ht">中的奇异值<em class="kq">σ</em>中的奇异值</strong>告诉矩阵的每个值是如何判别的。因此，如果一个值很高，这意味着某个维度对于数据表示很重要。因此，如果维度很低，就不能携带大量信息。</p><p id="fd1b" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这对我们有什么帮助？</p><p id="c7e2" class="pw-post-body-paragraph ip iq hs ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这有助于我们识别对全局不重要的维度。例如，我们可以删除不包含重要信息的维度来压缩数据。</p><h1 id="50cc" class="jn jo hs bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="4d26" class="pw-post-body-paragraph ip iq hs ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">特征分解和奇异值分解的关键要点是，您可以将矩阵转换为另一种基，以便简化复杂的运算(特征分解)，或者通过只考虑最有意义的数据点(SVD)来压缩数据。</p><div class="hg hh ez fb hi mr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd ht fi z dy mw ea eb mx ed ef hr bi translated">Mlearning.ai提交建议</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">medium.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf ho mr"/></div></div></a></div></div></div>    
</body>
</html>
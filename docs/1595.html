<html>
<head>
<title>Paper Summary [Deep Deterministic Uncertainty for Semantic Segmentation]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文摘要[语义分割的深度确定性不确定性]</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/paper-summary-deep-deterministic-uncertainty-for-semantic-segmentation-6ab6d2029c8c?source=collection_archive---------3-----------------------#2022-01-09">https://medium.com/mlearning-ai/paper-summary-deep-deterministic-uncertainty-for-semantic-segmentation-6ab6d2029c8c?source=collection_archive---------3-----------------------#2022-01-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="cb58" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated"><strong class="ik hi">请注意，这篇帖子是为了我将来可能的研究在没有完全阅读</strong> <a class="ae jg" href="https://arxiv.org/pdf/2111.00079" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi">论文</strong> </a> <strong class="ik hi">的情况下，回看和复习关于这个题目的材料。</strong></p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/5362056ef2c51ced8aae57406590cb51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpNoOJbfKjapbXOd1Njlwg.jpeg"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">source is <a class="ae jg" href="https://www.pexels.com/photo/grayscale-photography-of-concrete-road-during-daytime-68272/" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="ec29" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">深度确定性不确定性(DDU)使得计算和分离模型中的随机不确定性变得可行。在这种情况下，主要关注的是同一类中不同位置的像素的特征表示的熟悉程度。其结论是，有可能独立使用DDU位置。与像素相关的像素相比，这种DDU将导致消耗的存储器显著减少。研究人员使用<a class="ae jg" href="https://arxiv.org/abs/1802.02611v3" rel="noopener ugc nofollow" target="_blank"> DeepLab-v3+架构</a>，并在Pascal VOC 2012上应用，以展示他们在MC丢失和深度集成方面的改进。</p><h1 id="79da" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">介绍</h1><p id="88fb" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">除了部署深度学习模型中的预测，不确定性可靠性对于安全关键型应用(例如自动驾驶、医疗诊断等)至关重要。).在这个问题上已经提出了许多方法，要求通过该模型向前传递几次。</p><p id="0983" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">有几种方法可以获得向前传球的不确定性，如<a class="ae jg" href="https://proceedings.mlr.press/v119/van-amersfoort20a.html" rel="noopener ugc nofollow" target="_blank"> DUQ </a>和<a class="ae jg" href="https://arxiv.org/abs/2006.10108" rel="noopener ugc nofollow" target="_blank">ANP</a>；然而，尽管这两种方法是合适的，但是它们需要对结构和训练设置进行全面的改变，并且需要对额外的超参数进行微调。</p><p id="5679" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated"><strong class="ik hi"> DDU: </strong></p><ul class=""><li id="2bee" class="ld le hh ik b il im ip iq jx lf jy lg jz lh jf li lj lk ll bi translated">可以利用具有适当归纳偏差的特征空间密度</li><li id="6614" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated">防止功能崩溃问题</li></ul><p id="32ee" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">由于要素折叠，样本(非分布(OoD))被映射到要素空间中的非分布区域，使得模型对输入数据过于自信。因此，模型上适当的归纳偏差对于捕捉特征空间密度的不确定性是必要的。</p><p id="da94" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">有两种类型的不确定性:</p><ol class=""><li id="9992" class="ld le hh ik b il im ip iq jx lf jy lg jz lh jf lr lj lk ll bi translated"><strong class="ik hi"> <em class="ij">认知不确定性:</em></strong><em class="ij"/><br/><strong class="ik hi">*</strong>捕捉到什么模式不知道<br/> <strong class="ik hi"> * </strong>对于看不见的或OoD输入为高，并且可以随着更多的训练数据而降低</li><li id="3710" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf lr lj lk ll bi translated"><strong class="ik hi"> <em class="ij">随机不确定性</em> </strong> <br/> <strong class="ik hi"> * </strong>捕捉分布内样本中的模糊性和观测噪声</li></ol><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es ls"><img src="../Images/a56377660e704435583f69ed8daf98eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*F-Fms4Nkz4EsdWXYeLezzg.jpeg"/></div></figure><p id="50c9" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">本研究使用DDU进行语义分割，以生成与分类输入相同维度的输出。之所以选择语义分割，是因为它对阶级不平衡有好处。</p><h1 id="b952" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">语义分割中的DDU</h1><h2 id="a1f0" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated">DDU简介:</h2><p id="5061" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">当我们训练模型时(使用<a class="ae jg" href="https://en.wikipedia.org/wiki/Lipschitz_continuity" rel="noopener ugc nofollow" target="_blank">双Lipschitz约束</a>)，我们可以使用对所有训练样本的一次遍历来计算每个类别的特征空间均值和协方差。这两个将被用来拟合一个<a class="ae jg" href="https://towardsdatascience.com/gaussian-discriminant-analysis-an-example-of-generative-learning-algorithms-2e336ba7aa5c" rel="noopener" target="_blank">高斯判别分析(GDA) </a>。</p><h2 id="7a81" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated">独立于像素的类均值和协方差:</h2><p id="b99a" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">在语义分割中，每个像素都有自己的预测和相应的分布。在这项研究中，我们可以计算均值和协方差矩阵，而不需要像素，就像在多类分类中一样。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mh"><img src="../Images/4bc69db4f5132108f9e7c5112b48708f.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*u3V2Kj_zI-NxnSJTy393GA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Figure 1. L2 distances between the feature space mean of different classes for a pair of distant pixels on the Pascal VOC 2021. vals set: (left) Pixels (10,255) and (500,225), (middle) Pixels (234,349) and (36,22) and (right) Pixels (300,500) and (400,255)</figcaption></figure><p id="a44e" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">在该图中，作者绘制了所有对的特征空间平均值之间的L2距离。结果是<strong class="ik hi">同等级</strong>的平均值<strong class="ik hi">比其他等级</strong>更接近。很明显，卷积核在整个特征空间表示中是共享的。</p><h2 id="4645" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated">计算特征密度:</h2><p id="ed5a" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">作者拟合了一个GDA，假设像素是自主样本。有两个动作同时执行:</p><ol class=""><li id="5bd1" class="ld le hh ik b il im ip iq jx lf jy lg jz lh jf lr lj lk ll bi translated">获得每个类别(非像素)的一个平均值和一个协方差，然后应用GDA。</li><li id="932d" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf lr lj lk ll bi translated">获得来自该模型的每像素softmax熵。</li></ol><p id="2a58" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">因此，作者可以在语义分割中用单一的确定性模型来释放任意的和认知的不确定性。从下图可以看出:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mi"><img src="../Images/f11a9b4d66c704f9eb3671dffb57d057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5N0YYBp0adDi_UqR8-Y7g.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Applying DDU in the context of semantic segmentation</figcaption></figure><h1 id="9398" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">E<span class="l mj mk ml bm mm mn mo mp mq di">实验</span></h1><p id="522e" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">为了评估DDU在语义分割上的可靠性，研究人员使用Pascal VOC数据集，并将其与其他三种不确定性基线(softmax熵、MC Dropout和Deep Ensembles)进行比较。</p><h2 id="d02e" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated"><strong class="ak"> <em class="mr">架构和培训设置:</em> </strong></h2><p id="3788" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">用于本研究的超参数可描述如下:</p><ul class=""><li id="f411" class="ld le hh ik b il im ip iq jx lf jy lg jz lh jf li lj lk ll bi translated">纪元= 50</li><li id="2ef8" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated">优化器= SGD(动量=0.9，重量衰减=5e-4)</li><li id="757a" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated">lr = 0.007</li></ul><h2 id="b671" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated"><strong class="ak">基线和不确定性指标:</strong></h2><ol class=""><li id="9177" class="ld le hh ik b il ky ip kz jx ms jy mt jz mu jf lr lj lk ll bi translated"><a class="ae jg" href="https://towardsdatascience.com/softmax-and-uncertainty-c8450ea7e064" rel="noopener" target="_blank">软最大熵</a></li><li id="4925" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf lr lj lk ll bi translated"><a class="ae jg" href="https://arxiv.org/abs/2110.03260" rel="noopener ugc nofollow" target="_blank"> MC辍学(MCDO) </a></li><li id="af24" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf lr lj lk ll bi translated"><a class="ae jg" href="https://arxiv.org/pdf/2007.08792" rel="noopener ugc nofollow" target="_blank">深度合奏</a></li></ol><h2 id="47d8" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated">评估指标:</h2><p id="72ef" class="pw-post-body-paragraph ih ii hh ik b il ky in io ip kz ir is jx la iv iw jy lb iz ja jz lc jd je jf ha bi translated">为了评估每种方法，作者使用了<em class="ij"> p(准确—确定)、p(不确定—不准确)、</em>和<em class="ij"> PAPU，如下所示:</em></p><ul class=""><li id="6204" class="ld le hh ik b il im ip iq jx lf jy lg jz lh jf li lj lk ll bi translated"><strong class="ik hi"> <em class="ij"> p(准确—确定)</em> </strong> <em class="ij"> : </em>假设模型对预测有信心，预测准确的概率</li><li id="b362" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated"><strong class="ik hi"> <em class="ij"> p(不确定—不准确)</em> </strong> <em class="ij"> : </em>模型在不准确预测上不确定的概率。</li><li id="5dd3" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated"><strong class="ik hi"><em class="ij">PAPU</em></strong><em class="ij">:</em>模型对准确预测有信心或对不准确预测不确定的概率。</li></ul><p id="71c1" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">这三个可以形象化如下:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mv"><img src="../Images/6b60cc2cf849dbdc71a597f647464e35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oalTZU8XXvoxKHhCJ3OhxA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Fig 3. Evaluation metrics on various baselines</figcaption></figure><p id="55dd" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">四个样本的不确定性估计值可以如下所示:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mw"><img src="../Images/ef6c0dd1c83d3b95677d3fd0c0e43b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*YbJuLQKStjGCiAeSpcVHCA.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx">(a) shows pixel-wise accuracy with bright signifying accurate and dark, inaccurate. (b) and (c) show predictive entropy (PE) and mutual information (MI) obtained from the MC Dropout (MCDO) baseline respectively, (d) and (e) show the PE and MI from deep ensembles. (f) maps per-pixel softmax entropy. Finally, (g) is feature density</figcaption></figure><p id="ed56" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">下表提供了对Pascal VOC 2012验证集准确性的评估及其所需时间:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mx"><img src="../Images/205f73ad9f62ea1b6d954a549a41aa3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*6ww7M5x4TZVyl5jSRDetDA.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx">Table 2. Pascal VOC validation set and runtime in milliseconds of a single forward pass for each above-mentioned baselines</figcaption></figure><p id="57f5" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated"><em class="ij">注意:</em>单次向前传球:</p><ol class=""><li id="5c27" class="ld le hh ik b il im ip iq jx lf jy lg jz lh jf lr lj lk ll bi translated">MC辍学:它包括5个随机向前传球。</li><li id="4d47" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf lr lj lk ll bi translated">集合:它从3个集合成分得到预测。</li></ol><h2 id="f194" class="lt kb hh bd kc lu lv lw kg lx ly lz kk jx ma mb ko jy mc md ks jz me mf kw mg bi translated">观察:</h2><ul class=""><li id="cf18" class="ld le hh ik b il ky ip kz jx ms jy mt jz mu jf li lj lk ll bi translated">DDU和normal softmax的运行时间优于其他软件。(表1)</li><li id="76fd" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated">DDU在这三项指标上都有较高的值。(图3)</li><li id="96db" class="ld le hh ik b il lm ip ln jx lo jy lp jz lq jf li lj lk ll bi translated">DDU特征密度捕捉认知的不确定性，而softmax熵捕捉随机的不确定性。(图4)</li></ul><h1 id="180a" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">结论:</h1><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es my"><img src="../Images/573209ec3962b1b8c0e76e6d99676ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*Q0VPlRBea-RbOpo3Q2Ahng.png"/></div></figure><p id="6f3a" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">最后，我们发现DDU在FCNN架构下可以很好地完成语义切分任务。它可以独立于像素执行。</p><p id="0919" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated">结论是，DDU比其他同龄人表现得更好。</p><p id="a1c0" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jx iu iv iw jy iy iz ja jz jc jd je jf ha bi translated"><em class="ij"> NB。深度/机器学习中可能包含的不确定性可以帮助我们</em> <a class="ae jg" href="https://becominghuman.ai/using-uncertainty-to-interpret-your-model-67a97c28fea5" rel="noopener ugc nofollow" target="_blank"> <em class="ij">调试模型</em> </a> <em class="ij">并使它们更加健壮。</em></p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mz"><img src="../Images/d0938424ad56d354a9965bbf05e01783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zpjXsgafOCQcXdWv2Nq39g.jpeg"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">source is <a class="ae jg" href="https://unsplash.com/photos/PXB7yEM5LVs" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><blockquote class="ie if ig"><p id="e640" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">如果发现任何错误，请发电子邮件到rezayazdanfar1111@gmail.com找我。同时，在我的推特 <a class="ae jg" href="https://twitter.com/reza__yazdanfar" rel="noopener ugc nofollow" target="_blank"> <em class="hh">这里</em> </a> <em class="hh">关注我，在我的领英</em> <a class="ae jg" href="https://www.linkedin.com/in/reza-yazdanfar-b69055156/" rel="noopener ugc nofollow" target="_blank"> <em class="hh">这里</em> </a> <a class="ae jg" href="https://rezayazdanfar.medium.com/" rel="noopener"> <em class="hh">访问我。</em> </a> <em class="hh">最后，如果你有任何想法或建议，我对此持开放态度，你只需要在</em><a class="ae jg" href="https://www.linkedin.com/in/reza-yazdanfar-b69055156/" rel="noopener ugc nofollow" target="_blank"><em class="hh">LinkedIn</em></a><em class="hh">上给我发消息。🙂</em></p></blockquote><div class="na nb ez fb nc nd"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hi fi z dy ni ea eb nj ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">medium.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr jr nd"/></div></div></a></div></div></div>    
</body>
</html>
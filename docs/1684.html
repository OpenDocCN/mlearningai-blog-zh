<html>
<head>
<title>Credit Risk Modelling in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的信用风险建模</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/credit-risk-modelling-in-python-7b21a0b794b1?source=collection_archive---------0-----------------------#2022-01-19">https://medium.com/mlearning-ai/credit-risk-modelling-in-python-7b21a0b794b1?source=collection_archive---------0-----------------------#2022-01-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/edeaa73baefe6d3b0403ddc08ef67d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1kuLl_N1AsrWDdd2.jpg"/></div><figcaption class="il im et er es in io bd b be z dx">The Source of the image is <a class="ae ip" href="https://cascadebusnews.com/understanding-credit-risk-management-matters/" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><h1 id="c6d7" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是信用风险？</h1><p id="b005" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi km translated">信用风险是借款人无法及时还款并拖欠债务的可能性。它是指贷款人可能无法按时获得到期的利息或本金。</p><p id="9d8e" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">金融组织关心的是降低违约风险。因此，商业和投资银行、风险资本基金、资产管理组织和保险公司等越来越依赖技术来预测哪些客户最有可能违约。</p><h1 id="1c1c" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是信用风险建模？</h1><p id="b145" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">一个人的信用风险受多种因素影响。因此，确定借款人的信用风险是一项艰巨的任务。信用风险建模已经进入场景，因为有这么多的钱依赖于我们的能力，以适当预测借款人的信用风险。</p><p id="640b" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">信用风险建模是应用数据模型来确定两个关键因素的实践。首先是借款人拖欠贷款的可能性。第二个因素是如果发生违约，贷款人的财务影响。</p><p id="7255" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">金融机构使用信用风险模型来评估潜在借款人的信用风险。</p><blockquote class="la lb lc"><p id="7ae0" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated">对于参与金融系统的公司来说，保持客户的财务健康至关重要。然而，你可能想知道如何保护每个客户的财务健康。要应对这一挑战，需要根据一套标准评估每个客户的支付可能性，并设计策略来预测客户的需求。</p><p id="544e" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated">因此，这项研究的目标是预测特定债务违约的可能性，在本例中是信用卡。这将有助于创建降低客户财务健康恶化风险的解决方案。此外，建议采用聚类技术来定位群体中的同类部分，从而为每个客户提供区别对待，以帮助创建收集策略。</p></blockquote><blockquote class="lh"><p id="43dd" class="li lj hh bd lk ll lm ln lo lp lq kl dx translated">将使用以下程序构建模型。</p></blockquote><p id="93eb" class="pw-post-body-paragraph jo jp hh jq b jr lr jt ju jv ls jx jy jz lt kb kc kd lu kf kg kh lv kj kk kl ha bi translated">1.数据准备和预处理</p><p id="e864" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">2.特征工程和选择</p><p id="18ee" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">3.模型开发和模型评估</p><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es lw"><img src="../Images/744e21ab64775f7c1199080517bb0c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6KcRkfNyIhpHbZiO.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">(Source: <a class="ae ip" href="https://www.omnisci.com/technical-glossary/feature-engineering)" rel="noopener ugc nofollow" target="_blank">https://www.omnisci.com/technical-glossary/feature-engineering)</a></figcaption></figure><h1 id="d21c" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">关于数据</h1><p id="6a94" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">数据集取自卡格尔<a class="ae ip" href="https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="5d0c" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">本研究以台湾消费者违约付款为例，分析六种资料探勘方法对违约机率的预测准确度。从风险管理的角度来看，预测违约概率的预测准确性结果将比分类的二元结果(可信或不可信客户)更有益。因为违约的真实可能性是未知的，本研究使用了一种新的排序平滑方法来逼近它。反应变量(Y)是真实的违约概率，而自变量是违约的预测机会(X)。</p><p id="77ba" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><strong class="jq hi">变量:</strong></p><p id="df20" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld"> LIMIT_BAL </em>:授信额度(新台币):包括个人消费信贷和家庭(补充)信贷。性别:性别(1 =男性；2 =女性)。</p><p id="b38e" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld">教育</em>:教育(1 =读研；2 =大学；3 =高中；4 =其他)。</p><p id="e96d" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld">婚姻</em>:婚姻状况(1 =已婚；2 =单身；3 = divorse，0=其他)。</p><p id="eef6" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld">年龄</em>:年龄(年)。</p><p id="f1ef" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld"> PAY0 — PAY6 </em>:过去的支付历史。我们跟踪了过去每月的还款记录(2005年4月至9月)如下:pay 0 = 2005年9月的还款情况；pay 1 = 2005年8月的还款状态；。。。；pay 6 = 2005年4月的还款状态。还款状态的衡量尺度为:-2:无消费；-1:全额支付；0:使用循环信贷；1 =延迟一个月付款；2 =付款延迟两个月；。。。；8 =付款延迟八个月；9 =付款延迟9个月及以上。</p><p id="2a48" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld"> BILL_AMT1- BILL_AMT6 </em>:账单金额(新台币)。BILL _ AMT1 =年9月账单对账单金额；BILL _ AMT2 =年8月账单金额；。。。；BILL _ AMT6 =年4月账单金额。</p><p id="7bde" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><em class="ld"> PAY_AMT1-PAY_AMT2 </em>:上次付款金额(新台币)。PAY _ AMT1 =年9月支付的金额；PAY _ AMT2 =年8月支付的金额；。。。；PAY _ AMNT6 =年4月支付的金额。</p><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="775f" class="mk ir hh mg b fi ml mm l mn mo"><em class="ld"># Reading the data </em><br/>credit_risk<strong class="mg hi">=</strong> pd<strong class="mg hi">.</strong>read_csv("UCI_credit_card.csv")<br/>credit_risk<strong class="mg hi">.</strong>head()</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mp"><img src="../Images/9affcbd0587084ecc1f8b3dfbef91d85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g0cYsuyaOJbZv4PvTmkFAQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Data</figcaption></figure><h1 id="bfc6" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">数据准备和预处理</h1><p id="4740" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">这就是信用风险建模的数据来源。最初，数据揭示了总共25个属性。在开发任何机器学习模型之前，以合适的格式清理数据是至关重要的。</p><h2 id="c528" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">“教育”栏目分析</h2><p id="b51a" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">教育程度:(1 =研究生院，2 =大学，3 =高中，4 =其他，5 =未知，6 =未知)</p><blockquote class="la lb lc"><p id="e64b" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated"><em class="hh">从给出的数据描述中，我们知道在df。教育，5和6代表“未知”</em> <br/> <em class="hh">改变0、5和6，使其保持在1类之下。</em></p></blockquote><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="a70d" class="mk ir hh mg b fi ml mm l mn mo">df['EDUCATION']<strong class="mg hi">.</strong>replace({0:1,1:1,2:2,3:3,4:4,5:1,6:1}, inplace<strong class="mg hi">=True</strong>)<br/>df<strong class="mg hi">.</strong>EDUCATION<strong class="mg hi">.</strong>value_counts()</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es nd"><img src="../Images/d5d92dfc56b07e6aa195d27ac0255cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*lyOg-ovnuNjmetHi6tb2vQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Education column in data</figcaption></figure><h2 id="1205" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">“婚姻”栏目分析</h2><p id="77bb" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">婚姻状况(1 =已婚，2 =单身，3 =其他)</p><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="683d" class="mk ir hh mg b fi ml mm l mn mo"><em class="ld"># lets see the values count in column marriage</em><br/>df['MARRIAGE']<strong class="mg hi">.</strong>value_counts()</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es ne"><img src="../Images/6ba1f2d569b9b73249cd4f9cc7d9c7a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*CM93Q-zJL_OHdkCdpXW3Jw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Marriage column in data</figcaption></figure><p id="3a15" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">在这里，我将把0映射到1。</p><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="c4fe" class="mk ir hh mg b fi ml mm l mn mo">df['MARRIAGE']<strong class="mg hi">.</strong>replace({0:1,1:1,2:2,3:3}, inplace<strong class="mg hi">=True</strong>)<br/>df['MARRIAGE']<strong class="mg hi">.</strong>value_counts()</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/e1304e80b2b85884bd454ab1f23fd75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*VcOQ1dqgGshGofJPnsXswA.png"/></div><figcaption class="il im et er es in io bd b be z dx">marriage column after mapping</figcaption></figure><h2 id="90cc" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">“PAY_0到PAY_6”列的分析</h2><p id="bee8" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">PAY _ 0:2005年9月还款状态(-1 =按时还款，1 =延迟还款一个月，2 =延迟还款两个月，…8 =延迟还款八个月，9 =延迟还款九个月及以上)</p><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es ng"><img src="../Images/84996ef24316647e0de451092aff1521.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*0dMAB_uw-NqIPNldsqqrTg.png"/></div><figcaption class="il im et er es in io bd b be z dx">pay_0 column in data</figcaption></figure><h1 id="d5a3" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">数据可视化</h1><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es nh"><img src="../Images/f575cc455f3c12853c26cb615aed6ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*A-TUx5nmTeMVMGbelT6Zhg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Target variable (Author image)</figcaption></figure><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ni"><img src="../Images/51aacce0e2f29a3511d478ba967663c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e5v-M8wkh5WJzzh1celrUQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Education column (Author image)</figcaption></figure><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es nj"><img src="../Images/61458ff6fcb7e359cb8fcfb0ee66e415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*NgL_BXELqYF5-NmW3SeaGg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Age column distribution (Author image)</figcaption></figure><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es nk"><img src="../Images/d1dbc312076543d9275c530c27247c33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*mSEG_VxvanX7WCgQ7sroUA.png"/></div><figcaption class="il im et er es in io bd b be z dx">Sex column ( Author image)</figcaption></figure><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nl"><img src="../Images/7bb1d35af118b4c7ee63ef7df75b74bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*viLjqTEoI4PjyiY1Z-tlkA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Scatter plot ( Author image)</figcaption></figure><h2 id="3b3c" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">创建独立特征和从属特征</h2><ul class=""><li id="27f0" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">独立变量(也称为特征)是被分析过程的输入。因变量是流程的输出。</li></ul><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="98a9" class="mk ir hh mg b fi ml mm l mn mo"><em class="ld"># Independnet features</em><br/>X <strong class="mg hi">=</strong> df<strong class="mg hi">.</strong>drop(['default.payment.next.month'], axis<strong class="mg hi">=</strong>1)<br/><em class="ld"># Dependent feature</em><br/>y <strong class="mg hi">=</strong> df['default.payment.next.month']<br/>X<strong class="mg hi">.</strong>head()</span></pre><h2 id="8cb3" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">缩放要素</h2><ul class=""><li id="752c" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">将数据集中的所有变量缩放或转换到给定比例的过程称为要素缩放。梯度下降优化用于一些机器学习方法，如线性回归、逻辑回归等。为了使这些算法正常工作，必须对数据进行缩放。</li><li id="50ae" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated">标准化是以获得标准正态分布属性的方式缩放数据值的过程。这意味着数据以这样的方式被重新调整，即平均值变为零，并且数据具有单位标准偏差。</li></ul><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es oa"><img src="../Images/7959dd382d9f41087c2123ac0a6a4d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C9nhpuiviXJqMcIzNQRYug.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Formula for standardization</figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="ad2f" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> sklearn.preprocessing <strong class="mg hi">import</strong> StandardScaler<br/>scaler<strong class="mg hi">=</strong> StandardScaler()<br/>X<strong class="mg hi">=</strong> scaler<strong class="mg hi">.</strong>fit_transform(X)</span></pre><h2 id="a9ef" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">列车测试分离</h2><ul class=""><li id="d1c2" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">整个数据集(群体)被分成两组:训练集和测试集。根据使用情形，数据可以分为70–30或60–40、75–25或80–20，甚至50–50。一般来说，训练数据的比例必须大于测试数据的比例。</li></ul><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ob"><img src="../Images/8ce30a67a4ad3529c1a8de21516e3f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pr4nVYDtuNNq4Rck-wa9iw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Splitting the data (Image Source: DataVedas)</figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="ed36" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> sklearn.model_selection <strong class="mg hi">import</strong> train_test_split<br/>X_train,X_test,y_train,y_test<strong class="mg hi">=</strong> train_test_split(X,y,test_size<strong class="mg hi">=</strong>0.20,random_state<strong class="mg hi">=</strong>42)</span></pre><h2 id="9cd5" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated"><strong class="ak">阶层失衡</strong></h2><ul class=""><li id="9fb0" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">对于过采样技术，SMOTE(合成少数过采样技术)被认为是ML和数据挖掘中最流行和最有影响力的数据采样算法之一。使用SMOTE，少数类通过创建“合成”示例进行过采样，而不是通过替换进行过采样[2]。这些引入的合成示例是基于沿着连接定义数量的k个少数类最近邻居的线段，在学习包中默认设置为5个。</li></ul><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="f8e4" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> imblearn.over_sampling <strong class="mg hi">import</strong> SMOTE<br/><strong class="mg hi">from</strong> collections <strong class="mg hi">import</strong> Counter<br/><br/><em class="ld"># summarize class distribution</em><br/>print("Before oversampling: ",Counter(y_train))<br/><br/><em class="ld"># define oversampling strategy</em><br/>SMOTE<strong class="mg hi">=</strong> SMOTE()<br/><br/><em class="ld"># fit and apply the transform </em><br/>X_train,y_train<strong class="mg hi">=</strong> SMOTE<strong class="mg hi">.</strong>fit_resample(X_train,y_train)<br/><br/><em class="ld"># summarize class distribution</em><br/>print("After oversampling: ",Counter(y_train))</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es oc"><img src="../Images/e6cfcc1f53d393bd858499702d09dc3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*SxzvOVlJNnAvUgeDWdjWLg.png"/></div></figure><h1 id="de9a" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">建筑模型</h1><ul class=""><li id="7243" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">逻辑回归</li><li id="3485" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated">随机森林分类器</li><li id="e02c" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated">XGBoost分类器</li><li id="b5a6" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated">交叉验证</li></ul><h2 id="21cd" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">逻辑回归模型</h2><ul class=""><li id="a4c1" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">逻辑回归的主要目的是确定特征和特定结果的概率之间的关系。</li><li id="9b68" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated">它使用Sigmoid函数来绘制数据。</li></ul><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es od"><img src="../Images/3be7d90d77022ae6949ea429f311b604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4WAwVBLfngaGciU6ENM4vw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Image source <a class="ae ip" href="https://www.analyticsvidhya.com/blog/2021/03/logistic-regression/" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="d82a" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> sklearn.linear_model <strong class="mg hi">import</strong> LogisticRegression<br/>logit<strong class="mg hi">=</strong> LogisticRegression()</span><span id="9cf1" class="mk ir hh mg b fi oe mm l mn mo">logit<strong class="mg hi">.</strong>fit(X_train, y_train)</span><span id="30fe" class="mk ir hh mg b fi oe mm l mn mo"><em class="ld"># Predicting the model</em><br/>pred_logit<strong class="mg hi">=</strong> logit<strong class="mg hi">.</strong>predict(X_test)</span></pre><h2 id="7174" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">评估logit模型</h2><ul class=""><li id="fd22" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated"><strong class="jq hi">准确率</strong>:正确预测总数的比例。</li><li id="eb38" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated"><strong class="jq hi">阳性预测值或精确度</strong>:被正确识别的阳性病例的比例。</li><li id="135e" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated"><strong class="jq hi">阴性预测值</strong>:被正确识别的阴性病例的比例。</li><li id="0660" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated"><strong class="jq hi">灵敏度或召回率</strong>:被正确识别的实际阳性病例的比例。</li><li id="0fcc" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated"><strong class="jq hi">特异性</strong>:被正确识别的实际阴性病例的比例。</li></ul><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es of"><img src="../Images/6d93cb049ed25e38bb29826cc2357e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HH0OTfLcj2eIy3U_.jpg"/></div></div><figcaption class="il im et er es in io bd b be z dx">Confusion metrics (Image source <a class="ae ip" href="https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html" rel="noopener ugc nofollow" target="_blank">here</a>)</figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="42af" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> sklearn.metrics <strong class="mg hi">import</strong> classification_report, accuracy_score, confusion_matrix, roc_auc_score, plot_confusion_matrix, plot_precision_recall_curve<br/><br/>print("The accuracy of logit model is:", accuracy_score(y_test, pred_logit))<br/>print(classification_report(y_test, pred_logit))</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es og"><img src="../Images/18c7012e8e707819755200bd01cd9a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*M-XxGM3cX6mIi5JAK1KnSQ.png"/></div><figcaption class="il im et er es in io bd b be z dx">Classification report of Logit model</figcaption></figure><h2 id="5239" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">随机森林分类器</h2><blockquote class="la lb lc"><p id="0db0" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated">步骤1:在随机森林中，从具有k个记录的数据集中取出n个随机记录。</p><p id="6398" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated">步骤2:为每个样本构建单独的决策树。</p><p id="19ea" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated">步骤3:每个决策树都会生成一个输出。</p><p id="4528" class="jo jp ld jq b jr kv jt ju jv kw jx jy le kx kb kc lf ky kf kg lg kz kj kk kl ha bi translated">第四步:根据<strong class="jq hi"> <em class="hh">多数表决或平均</em> </strong>分别考虑分类和回归的最终输出。</p></blockquote><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es oh"><img src="../Images/ade96f91663992dd46d30d984a109850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JxLAfrbH7WzAjLyVxKmGaQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Random forest(Image source <a class="ae ip" href="https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/" rel="noopener ugc nofollow" target="_blank">here</a>)</figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="4d3d" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> sklearn.ensemble <strong class="mg hi">import</strong> RandomForestClassifier<br/>rf<strong class="mg hi">=</strong> RandomForestClassifier()<br/><em class="ld"># Fitting the model</em><br/>rf<strong class="mg hi">.</strong>fit(X_train,y_train)</span><span id="9f93" class="mk ir hh mg b fi oe mm l mn mo"><em class="ld"># Predicting the model</em><br/>pred_rf<strong class="mg hi">=</strong> rf<strong class="mg hi">.</strong>predict(X_test)</span></pre><h2 id="ad87" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">评估随机森林模型</h2><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="1e3d" class="mk ir hh mg b fi ml mm l mn mo">print("The accuracy of logit model is:", accuracy_score(y_test, pred_rf))<br/>print(classification_report(y_test,pred_rf ))</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es oi"><img src="../Images/99114503bd1f716afcd23034fdf603c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*Se7TyplLHw670ZSCW_2Gog.png"/></div><figcaption class="il im et er es in io bd b be z dx">classification report of the Random Forest model</figcaption></figure><h2 id="23e8" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">XGBoost分类器</h2><ul class=""><li id="90b8" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated">另一种突出的增强方法是极端梯度增强或XGBoost。实际上，XGBoost只是GBM算法的一个改进版本！XGBoost的操作与GBM的操作相同。在XGBoost中，树是按顺序生成的，每棵树都试图修复前一棵树的错误。</li></ul><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es oj"><img src="../Images/79a72f720acfc3e397548a4029661570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HVUCSrNehO91ZI1zPWu4yg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Image source <a class="ae ip" href="https://www.analyticsvidhya.com/blog/2020/02/4-boosting-algorithms-machine-learning/" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="7bf4" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">import</strong> xgboost <strong class="mg hi">as</strong> xgb<br/><br/>xgb_clf<strong class="mg hi">=</strong> xgb<strong class="mg hi">.</strong>XGBClassifier()<br/><em class="ld">#fitting the model</em><br/>xgb_clf<strong class="mg hi">.</strong>fit(X_train,y_train)</span><span id="e90f" class="mk ir hh mg b fi oe mm l mn mo"><em class="ld">## Predicting the model</em><br/>xgb_predict<strong class="mg hi">=</strong> xgb_clf<strong class="mg hi">.</strong>predict(X_test)</span></pre><h2 id="3fd9" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">评估Xgboost模型</h2><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es ok"><img src="../Images/5e6a87d40c6c170ba6b62772470fccca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*ziwa7-6qXxrDhKw_79BETw.png"/></div><figcaption class="il im et er es in io bd b be z dx">classification report of xgboost model</figcaption></figure><h2 id="d79d" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">超参数调整xgboost模型</h2><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="c13e" class="mk ir hh mg b fi ml mm l mn mo"><em class="ld">## Hyper Parameter Optimization</em><br/><br/>params<strong class="mg hi">=</strong>{<br/> "learning_rate"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,<br/> "max_depth"        : [ 3, 4, 5, 6, 8, 10, 12, 15],<br/> "min_child_weight" : [ 1, 3, 5, 7 ],<br/> "gamma"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],<br/> "colsample_bytree" : [ 0.3, 0.4, 0.5 , 0.7 ]<br/>    <br/>}</span><span id="8d9a" class="mk ir hh mg b fi oe mm l mn mo"><em class="ld">## Hyperparameter optimization using RandomizedSearchCV</em><br/><strong class="mg hi">from</strong> sklearn.model_selection <strong class="mg hi">import</strong> RandomizedSearchCV, GridSearchCV</span><span id="abc3" class="mk ir hh mg b fi oe mm l mn mo">random_search<strong class="mg hi">=</strong>RandomizedSearchCV(xgb_clf,param_distributions<strong class="mg hi">=</strong>params,n_iter<strong class="mg hi">=</strong>5,scoring<strong class="mg hi">=</strong>'roc_auc',n_jobs<strong class="mg hi">=-</strong>1,cv<strong class="mg hi">=</strong>5,verbose<strong class="mg hi">=</strong>3)<br/><br/><em class="ld"># fitting the RandomizedSearchCV</em><br/>random_search<strong class="mg hi">.</strong>fit(X_train,y_train)</span></pre><p id="43cd" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">然后我们会找到最好的估计和参数。</p><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="6115" class="mk ir hh mg b fi ml mm l mn mo"><em class="ld"># Finding the best estimators</em><br/>random_search<strong class="mg hi">.</strong>best_estimator_</span><span id="59d7" class="mk ir hh mg b fi oe mm l mn mo"><em class="ld"># Finding the best param</em><br/>random_search<strong class="mg hi">.</strong>best_params_</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es ol"><img src="../Images/853e3b8dbbb1a80e0b0ec20f6346ea0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*SdhfvzUNLxDlS8qS3_Np9A.png"/></div><figcaption class="il im et er es in io bd b be z dx">Optimal parameters</figcaption></figure><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es om"><img src="../Images/2420f2ea14bb994a9708d92aaf7c548b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qKG5WsJT7M8VHQnQlrVjdw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Best estimators</figcaption></figure><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="f3e2" class="mk ir hh mg b fi ml mm l mn mo"><em class="ld"># Predicting model</em><br/>y_pred<strong class="mg hi">=</strong> classifier<strong class="mg hi">.</strong>predict(X_test)</span></pre><h2 id="36c2" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">k倍交叉验证</h2><p id="41ed" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">让我们将最后一个例子从2重交叉验证外推至k重。现在，我们将尝试可视化k倍验证是如何工作的。</p><figure class="lx ly lz ma fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es on"><img src="../Images/3f2fc80b44d399f866109eec0a89be88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7GByn7i7tAaa1etn.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">(Image source<a class="ae ip" href="https://dataaspirant.com/10-k-fold-cross-validation/" rel="noopener ugc nofollow" target="_blank"> here</a>)</figcaption></figure><p id="61e9" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">这是一个七重交叉验证程序。</p><p id="1820" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated">它是这样工作的:我们将总人口分成5个相等的样本。模型现在在四个样本(蓝框)上训练，在一个样本(黄框)上验证。然后，在第二次迭代中，使用作为验证的新样本对模型进行训练。我们在5次迭代中对每个样本开发了一个模型，并将它们作为验证。这是一种降低选择偏差和预测能力方差的方法。一旦我们有了所有五个模型，我们平均误差项，以确定哪一个是最好的。</p><pre class="lx ly lz ma fd mf mg mh mi aw mj bi"><span id="c984" class="mk ir hh mg b fi ml mm l mn mo"><strong class="mg hi">from</strong> sklearn.model_selection <strong class="mg hi">import</strong> cross_val_score<br/>score<strong class="mg hi">=</strong>cross_val_score(classifier,X,y,cv<strong class="mg hi">=</strong>10)</span><span id="3dc3" class="mk ir hh mg b fi oe mm l mn mo">score<strong class="mg hi">.</strong>mean()</span></pre><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="ab fe cl oo"><img src="../Images/da50b70e876e6ff15a679847ed27bbe8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ALS6w4dPH07iPds9yzKk7A.png"/></div><figcaption class="il im et er es in io bd b be z dx">Final accuracy</figcaption></figure><h1 id="8d45" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论:</h1><p id="b8fe" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated">我们用python建立了信用风险模型。我们已经尝试了不同的机器学习算法。逻辑回归、随机森林和Xgboost分类器。我们还进行了超参数调整和交叉验证。我们实现的模型的最终准确率为82%。</p><h2 id="1ea0" class="mk ir hh bd is mq mr ms iw mt mu mv ja jz mw mx je kd my mz ji kh na nb jm nc bi translated">完整代码请参考<a class="ae ip" href="https://github.com/rahkum96/Credit-Risk-Modelling-in-Python/blob/main/Credit%20Risk%20Modelling%20in%20Python.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本。</a></h2><h1 id="3823" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">来源:</h1><ul class=""><li id="e361" class="nm nn hh jq b jr js jv jw jz no kd np kh nq kl nr ns nt nu bi translated"><a class="ae ip" rel="noopener" href="/analytics-vidhya/credit-risk-modelling-in-python-3ab4b00f6505">信号源1 </a></li><li id="87a9" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated"><a class="ae ip" href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" rel="noopener ugc nofollow" target="_blank">信号源2 </a></li><li id="4731" class="nm nn hh jq b jr nv jv nw jz nx kd ny kh nz kl nr ns nt nu bi translated"><a class="ae ip" href="https://towardsdatascience.com/credit-risk-analysis-with-machine-learning-736e87e95996" rel="noopener" target="_blank">信号源3 </a></li></ul><h1 id="cc0f" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">跟我来</h1><p id="43b8" class="pw-post-body-paragraph jo jp hh jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ha bi translated"><a class="ae ip" href="https://www.linkedin.com/in/rahulsisodia06/" rel="noopener ugc nofollow" target="_blank">领英</a></p><p id="c7e4" class="pw-post-body-paragraph jo jp hh jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl ha bi translated"><a class="ae ip" href="https://github.com/rahkum96" rel="noopener ugc nofollow" target="_blank"> GitHub </a></p><div class="op oq ez fb or os"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ot ab dw"><div class="ou ab ov cl cj ow"><h2 class="bd hi fi z dy ox ea eb oy ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="oz l"><h3 class="bd b fi z dy ox ea eb oy ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="pa l"><p class="bd b fp z dy ox ea eb oy ed ef dx translated">medium.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg ij os"/></div></div></a></div></div></div>    
</body>
</html>
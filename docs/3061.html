<html>
<head>
<title>FinRL: Population-Based algorithms implementation using Ray tune and RLlib</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FinRL:使用光线调节和RLlib实现基于群体的算法</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/finrl-population-based-algorithms-implementation-using-ray-tune-and-rllib-cdce7df66208?source=collection_archive---------1-----------------------#2022-07-15">https://medium.com/mlearning-ai/finrl-population-based-algorithms-implementation-using-ray-tune-and-rllib-cdce7df66208?source=collection_archive---------1-----------------------#2022-07-15</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><div class=""/><p id="21a0" class="pw-post-body-paragraph ii ij hl ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf he bi translated">在之前的<a class="ae jg" rel="noopener" href="/mlearning-ai/population-based-algorithms-for-hyperparameter-optimization-in-reinforcement-learning-b04ce2165533">文章</a>中，我总结了关于基于种群的训练和基于种群的bandit优化算法的论文，并解释了它们的理论实现细节。在本文中，我们将使用Ray tune和RLlib讨论它们的实际实现细节。</p></div></div>    
</body>
</html>
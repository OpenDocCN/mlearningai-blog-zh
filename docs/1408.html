<html>
<head>
<title>Invisible Man using Mask-RCNN — with source code — Fun Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隐形人使用面具-RCNN-带源代码-趣味项目</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/invisible-man-using-mask-rcnn-with-source-code-fun-project-956815e61a44?source=collection_archive---------5-----------------------#2021-12-10">https://medium.com/mlearning-ai/invisible-man-using-mask-rcnn-with-source-code-fun-project-956815e61a44?source=collection_archive---------5-----------------------#2021-12-10</a></blockquote><div><div class="es gk gl gm gn go"/><div class="gp gq gr gs gt"><div class=""/><p id="ed90" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated">所以在今天的博客中，我们将看到我们如何使用掩模R-CNN来执行人体分割。这是一个非常先进的项目，许多事情正在发生引擎盖下。所以没有任何进一步的原因。</p><p id="7a69" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><strong class="hv gx">点击此处阅读带源代码的整篇文章—</strong><a class="ae ir" href="https://machinelearningprojects.net/invisible-man-using-mask-rcnn/" rel="noopener ugc nofollow" target="_blank">https://machine learning projects . net/invisible-man-using-mask-rcnn/</a></p><figure class="it iu iv iw ek ix dy dz paragraph-image"><div class="dy dz is"><img src="../Images/b0f6282d7c529306a900f611a2745b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*_GTtihiTeUiv1woNfs5K-w.gif"/></div></figure><h1 id="52a2" class="ja jb gw bd jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx bi translated">让我们开始吧…</h1><h2 id="942a" class="jy jb gw bd jc jz ka kb jg kc kd ke jk ie kf kg jo ii kh ki js im kj kk jw kl bi translated">代码为人类分割使用掩模-RCNN…</h2><pre class="it iu iv iw ek km kn ko kp aw kq bi"><span id="6bd6" class="jy jb gw kn b ev kr ks l kt ku">from imutils.video import FPS<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import cv2<br/>import os<br/><br/>webcam = 1<br/>expected_confidence = 0.3<br/>threshold = 0.1<br/>show_output = 1<br/>save_output = 1<br/>kernel = np.ones((5,5),np.uint8)<br/>writer = None<br/>fps = FPS().start()<br/><br/>weightsPath = "mask-rcnn-coco/frozen_inference_graph.pb"<br/>configPath = "mask-rcnn-coco/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt"<br/><br/>print("[INFO] loading Mask R-CNN from disk...")<br/>net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)<br/><br/>if use_gpu:<br/>    # set CUDA as the preferable backend and target<br/>    print("[INFO] setting preferable backend and target to CUDA...")<br/>    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)<br/>    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)<br/><br/>print("[INFO] accessing video stream...")<br/>cap = cv2.VideoCapture(0)<br/><br/>print("[INFO] background recording...")<br/>for _ in range(60):<br/>    _,bg = cap.read()<br/>print("[INFO] background recording done...")<br/><br/>fourcc = cv2.VideoWriter_fourcc(*"MJPG")<br/>writer = cv2.VideoWriter('output.avi', fourcc, 20,(bg.shape[1], bg.shape[0]), True)<br/><br/>while True:<br/>    grabbed, frame = cap.read()<br/>    cv2.imshow('org',frame)<br/>    if not grabbed:<br/>        break<br/><br/>    blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)<br/>    net.setInput(blob)<br/>    (boxes, masks) = net.forward(["detection_out_final","detection_masks"])<br/>    for i in range(0, boxes.shape[2]):<br/>        classID = int(boxes[0, 0, i, 1])<br/>        if classID!=0:continue<br/>        confidence = boxes[0, 0, i, 2]<br/><br/>        if confidence &gt; expected_confidence:<br/>            (H, W) = frame.shape[:2]<br/>            box = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])<br/>            (startX, startY, endX, endY) = box.astype("int")<br/>            boxW = endX - startX<br/>            boxH = endY - startY<br/>            mask = masks[i, classID]<br/>            mask = cv2.resize(mask, (boxW, boxH),interpolation=cv2.INTER_CUBIC)<br/>            mask = (mask &gt; threshold)<br/>            bwmask = np.array(mask,dtype=np.uint8) * 255<br/>            bwmask = np.reshape(bwmask,mask.shape)<br/>            bwmask = cv2.dilate(bwmask,kernel,iterations=1)<br/><br/>            frame[startY:endY, startX:endX][np.where(bwmask==255)] = bg[startY:endY, startX:endX][np.where(bwmask==255)]<br/><br/>    if show_output:<br/>        cv2.imshow("Frame", frame)<br/><br/>        if cv2.waitKey(1) ==27:<br/>            break<br/><br/>    if save_output:<br/>        writer.write(frame)<br/><br/>    fps.update()<br/><br/>fps.stop()<br/>print("[INFO] elasped time: {:.2f}".format(fps.elapsed()))<br/>print("[INFO] approx. FPS: {:.2f}".format(fps.fps()))</span></pre><ul class=""><li id="add7" class="kv kw gw hv b hw hx ia ib ie kx ii ky im kz iq la lb lc ld bi translated">第1–5行—导入Mask-RCNN所需的库。</li><li id="f839" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第7–14行—声明一些常量。</li><li id="534e" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第16–20行—加载屏蔽RCNN网络。</li></ul><figure class="it iu iv iw ek ix dy dz paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="dy dz lj"><img src="../Images/0796cd318a2f371477304706c26867aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*95ld2kTdy_rTAql6.png"/></div></div></figure><ul class=""><li id="2a8d" class="kv kw gw hv b hw hx ia ib ie kx ii ky im kz iq la lb lc ld bi translated">第22–26行—如果您想使用GPU，请将后端和目标设置为CUDA。</li><li id="ce14" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第28–29行—从实时流中读取帧。</li><li id="acfa" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第31–34行—记录背景。</li><li id="eb00" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第36–37行—使用<a class="ae ir" href="https://docs.opencv.org/3.4/dd/d9e/classcv_1_1VideoWriter.html#ad59c61d8881ba2b2da22cff5487465b5" rel="noopener ugc nofollow" target="_blank"> cv2。VideoWriter() </a>以视频格式保存输出。</li><li id="baaf" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第39–43行—启动while循环，并开始从网络摄像头抓取帧。如果网络摄像头没有反馈任何信息，请中断。</li><li id="077d" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第45–47行——使用<a class="ae ir" href="https://docs.opencv.org/4.5.2/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7" rel="noopener ugc nofollow" target="_blank"> cv2.dnn.blobFromImage() </a>从图像中创建一个斑点，然后该斑点被设置为网络的输入，它流经网络，我们得到作为边界框和遮罩的输出。</li><li id="698d" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第48–66行—遍历所有输出，并对掩膜进行一些预处理以进一步增强它。现在，在这个蒙版中，无论哪里的像素是白色的，都用背景像素替换原始图像中的像素(第66行)。</li><li id="cc8b" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第68–72行—显示当有人按ESC键时的输出和中断。</li><li id="60a6" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第74–75行—以视频形式保存输出。</li><li id="c06b" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第77行—更新fps。</li><li id="602a" class="kv kw gw hv b hw le ia lf ie lg ii lh im li iq la lb lc ld bi translated">第79–81行—打印fps。</li></ul><h2 id="134e" class="jy jb gw bd jc jz ka kb jg kc kd ke jk ie kf kg jo ii kh ki js im kj kk jw kl bi translated">最终结果…</h2><figure class="it iu iv iw ek ix dy dz paragraph-image"><div class="dy dz is"><img src="../Images/b0f6282d7c529306a900f611a2745b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*_GTtihiTeUiv1woNfs5K-w.gif"/></div></figure><p id="cbcb" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><em class="lo"> PS —我知道结果并不完美，但这些结果也是不可思议的。</em></p><p id="042f" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><strong class="hv gx"> <em class="lo">注意——如果您的系统中没有GPU，请不要尝试运行它，因为它将永远运行，因为使用了Mask-RCNN。即使在GPU上，它也很难达到5-8 fps。</em>T13】</strong></p><p id="2666" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated">如果对使用Mask-RCNN进行人体分割有任何疑问，请通过电子邮件或LinkedIn联系我。你也可以在下面评论任何问题。</p><p id="1693" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><strong class="hv gx"> <em class="lo">探索更多机器学习、深度学习、计算机视觉、NLP、Flask项目访问我的博客— </em> </strong> <a class="ae ir" href="https://machinelearningprojects.net/" rel="noopener ugc nofollow" target="_blank"> <strong class="hv gx"> <em class="lo">机器学习项目</em> </strong> </a></p><p id="af54" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><strong class="hv gx">如需进一步的代码解释和源代码，请访问此处</strong> —</p><div class="lp lq eg ei lr ls"><a href="https://machinelearningprojects.net/invisible-man-using-mask-rcnn/" rel="noopener  ugc nofollow" target="_blank"><div class="lt ab fy"><div class="lu ab lv cl cj lw"><h2 class="bd gx ev z lx ly lz ma mb mc md gv bi translated">隐形人使用面具-RCNN -附源代码-趣味工程- 2021 -机器学习项目</h2><div class="me l"><h3 class="bd b ev z lx ly lz ma mb mc md ft translated">因此，在今天的博客中，我们将看到我们如何使用掩模R-CNN来执行人体分割。这是一个非常…</h3></div><div class="mf l"><p class="bd b fc z lx ly lz ma mb mc md ft translated">machinelearningprojects.net</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml iy ls"/></div></div></a></div><p id="5e34" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><em class="lo">所以这就是这篇博客的全部内容，感谢你的阅读，我希望你在阅读完这篇文章后，能有所收获，直到下一次👋… </em></p><p id="2e4b" class="pw-post-body-paragraph ht hu gw hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq gp bi translated"><strong class="hv gx"> <em class="lo">看我以前的帖子:</em></strong><a class="ae ir" href="https://machinelearningprojects.net/sudoku-solver/" rel="noopener ugc nofollow" target="_blank"><strong class="hv gx"><em class="lo">NEUR</em></strong></a><a class="ae ir" href="https://machinelearningprojects.net/neural-style-transfer/" rel="noopener ugc nofollow" target="_blank"><strong class="hv gx"><em class="lo">AL风格转移</em> </strong> </a></p><div class="lp lq eg ei lr ls"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lt ab fy"><div class="lu ab lv cl cj lw"><h2 class="bd gx ev z lx ly lz ma mb mc md gv bi translated">Mlearning.ai提交建议</h2><div class="me l"><h3 class="bd b ev z lx ly lz ma mb mc md ft translated">如何成为Mlearning.ai上的作家</h3></div><div class="mf l"><p class="bd b fc z lx ly lz ma mb mc md ft translated">medium.com</p></div></div><div class="mg l"><div class="mm l mi mj mk mg ml iy ls"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Vision beyond classification: Tasks beyond classification: Task II: Image Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越分类的视觉:超越分类的任务:任务二:图像分割</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/vision-beyond-classification-tasks-beyond-classification-task-ii-image-segmentation-5c5e81edf2b0?source=collection_archive---------5-----------------------#2022-04-19">https://medium.com/mlearning-ai/vision-beyond-classification-tasks-beyond-classification-task-ii-image-segmentation-5c5e81edf2b0?source=collection_archive---------5-----------------------#2022-04-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="aa93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2020年DeepMind <a class="ae jc" href="https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf" rel="noopener ugc nofollow" target="_blank">系列讲座</a>第4课笔记</p><p id="6428" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图像分割是一项计算机视觉任务，在这项任务中，我们用相应的类别来标记图像中特定的像素区域。由于我们预测图像中的每个像素，这个任务通常被称为<strong class="ig hi"> <em class="jd">一个密集预测</em> </strong>问题，而分类则是一个<strong class="ig hi"> <em class="jd">稀疏预测</em> </strong>问题。图像分割有两种类型:语义分割和实例分割。</p><p id="7a4d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们来探索一下吧！</p><h2 id="6937" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">什么是语义切分？</h2><p id="7aa0" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">语义分割</em> </strong>是对图像中一个或多个特定的感兴趣区域进行标注的过程。此过程将单个类别中的多个对象视为一个实体。例如:在<em class="jd">图1中，</em>语义分割对羊的所有像素赋予相同的标签。</p><p id="1497" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输入</strong>:带有一个或多个物体的图像。(RGB图像<code class="du ke kf kg kh b">H x W x 3</code>)</p><p id="a013" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输出:</strong>每个像素的类别标签</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/b98395ea575fea5e3c20adbc8536e9e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*927ZgvpwMxGb-j97NqlyPA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 1:</strong> Left: Input: an RGB image; Right: Output: class label for every pixel</figcaption></figure><p id="6505" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与稀疏预测问题不同，密集预测问题需要精确分辨率的输出作为输入。那么，我们如何产生相同分辨率的输出呢？</p><p id="13ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从前面的笔记中，我们已经遇到了降低分辨率的池技术。现在，让我们取消采样以提高分辨率！(<em class="jd">图二</em>)</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es ku"><img src="../Images/bfaa9651ab08a7b89515bb0945ab135e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LOcmk7vBCz9yq47YRxhP2g.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 2</strong>: Unpooling: upsample to increase resolution; here we use 2x2 kernel (<strong class="bd jg">Source</strong>: <a class="ae jc" href="https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L4%20-%20UCLxDeepMind%20DL2020.pdf" rel="noopener ugc nofollow" target="_blank">DeepMind Lecture 4</a>)</figcaption></figure><p id="7270" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们通过探索U-NET的体系结构来看看如何将unpooling技术合并到一个模型中:当前语义分段中最先进的模型！</p><h2 id="ec20" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">U-NET:</h2><p id="5793" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd"> U-NET </em> </strong>是一种编码器-解码器模型，其中添加了跳过连接以保留细节。这个网络架构<em class="jd">(图3) </em>由一个收缩路径(左侧的编码器)和一个扩展路径(右侧的解码器)组成。</p><p id="b333" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">编码器</em> </strong>路径遵循卷积网络的典型架构。该路径由两个3×3卷积的重复应用组成，每个卷积之后是一个整流线性单元(ReLU)和一个跨距为2的2×2最大池操作，用于下采样。</p><p id="d92c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">解码器</em> </strong>路径具有与编码器路径相似的结构。但是，它用2x2上采样操作取代了2x2最大池操作。这条路径将精确分辨率的输出作为输入。</p><p id="632a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，由于上采样，我们可以得到一个滴状特征图。因此，为了保留细节，我们从相同分辨率级别的编码器层添加了一些长跳跃连接。因此，通过添加这些跳过连接，我们可以添加回在池化和取消池化操作中可能丢失的高频细节。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kz"><img src="../Images/971b3ce3aebda9ae97eaa55cb873cecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*heYepbEuxmrooBWVaXsPsg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 3: </strong>U-NET architecture</figcaption></figure><p id="0048" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们如何训练这个系统？</p><p id="46b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">T3】输出T5:<em class="jd">H</em>x<em class="jd">W</em>x<em class="jd">N _ classes</em></strong></p><p id="5f03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">损失</em> </strong>:逐像素交叉熵<em class="jd">(图4) </em>。</p><p id="22a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们得到了输出中每个像素在可能类别上的概率分布。为了训练这一点，我们使用与分类相同的交叉熵损失，但现在它是输入中所有像素的平均值。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es la"><img src="../Images/b9efad0b9f63bcd3cec88645ec630130.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*iOUGmBAYVz_hQBOvjtxpzg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 4</strong>: pixel-wise cross entropy</figcaption></figure><h2 id="e2af" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">什么是实例分段？</h2><p id="154a" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">实例分割</em> </strong>是检测和描绘图像中每个感兴趣对象的过程。这个过程是对象检测和语义分割的结合。然而，它不同于语义分割，因为它给图像中特定对象的每个实例一个唯一的标签。例如:在<em class="jd">图5(右)</em>中，实例分割为每只羊分配不同的颜色(标签)，而语义分割只为所有那些羊分配相同的颜色(标签)(<em class="jd">图5，左</em>)。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lb"><img src="../Images/0e5d82627c81fe336c9cb27320e7ee2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JAx_WVsSNs35DYpJIMOl5w.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 5</strong>: Left: semantic segmentation; Right: instance segmentation</figcaption></figure><h2 id="8ea0" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">屏蔽R-CNN:</h2><p id="0d60" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated"><a class="ae jc" href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jd">掩膜R-CNN: </em> </strong> </a>(区域卷积神经网络)在图像分割和实例分割方面是最先进的。Mask R-CNN建立在速度更快的R-CNN  之上，这是一个流行的对象检测框架。在这个框架中有两个阶段:</p><ul class=""><li id="bb26" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">第一阶段，一个<strong class="ig hi">区域提议网络</strong> (RPN)，提议候选对象包围盒。</li><li id="1fad" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">第二阶段从每个候选框中提取特征，并执行分类、边界框回归和<strong class="ig hi">二元掩码</strong>。</li></ul><h2 id="2fc8" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">指标和基准:</h2><p id="c9c7" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">评价指标:</em> </strong></p><p id="b5f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd"> 1。</em>分类:</strong></p><p id="22e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">评估分类模型性能的最简单指标是<strong class="ig hi">准确性</strong>:正确预测的百分比(<em class="jd">图6 </em>)。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lq"><img src="../Images/b8b5f1d336cc0458ef238d65dc2adf43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eydCiZufPX-M1JQDDfyboQ.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 6</strong>: Accuracy</figcaption></figure><p id="b79a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中:</p><ul class=""><li id="df77" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">TP:真阳性</li><li id="c5d7" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">TN:真阴性</li><li id="b0e4" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">FP:假阳性</li><li id="eac0" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">FN:假阴性</li></ul><p id="122b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，我们使用:</p><ul class=""><li id="8a08" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">Top-1: top预测是正确的类。</li><li id="caba" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">前5名:正确的类别在前5名预测中。</li></ul><p id="d640" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd"> 2。</em>物体检测与分割:</strong></p><p id="5f42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，我们使用一个<strong class="ig hi">交集-并集(IoU) </strong>来评估对象检测和分割<em class="jd">(图7) </em>。由于IoU是不可微的，我们只能用它来评估。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lr"><img src="../Images/afabd397baabd811fbb55d80933f2d24.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*3OVns81v-8p95z0kmwLZCw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx"><strong class="bd jg">Figure 7</strong>: Intersection over union</figcaption></figure><p id="c6a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jd">基准:</em> </strong></p><ul class=""><li id="9437" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated"><a class="ae jc" href="https://image-net.org/challenges/LSVRC/index.php" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>:大规模评估对象检测和图像分类算法的主要计算机视觉基准。</li><li id="178a" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated"><a class="ae jc" href="https://www.cityscapes-dataset.com/" rel="noopener ugc nofollow" target="_blank"> Cityscapes: </a>大规模像素级、实例级和全景语义标注的基准套件和评估服务器。</li><li id="6dd4" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated"><a class="ae jc" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> Coco: </a>大规模对象检测、分割和字幕数据集。</li></ul><h2 id="39b7" class="je jf hh bd jg jh ji jj jk jl jm jn jo ip jp jq jr it js jt ju ix jv jw jx jy bi translated">总结:</h2><p id="e269" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">综上所述，我们探讨了分类之外的第二个任务:图像分割。</p><p id="41a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">具体而言，我们解决了:</p><ul class=""><li id="24a6" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated"><strong class="ig hi">语义分割</strong>:对图像中一个或多个感兴趣的特定区域进行标记的过程，同时将单个类别中的多个对象视为一个实体。</li><li id="047e" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">U-NET :对象语义分割的编解码模型</li><li id="0c0f" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated"><strong class="ig hi">实例分割</strong>:对象检测和语义分割相结合的过程，其中同一类别中的每个实例被区分。</li><li id="c36c" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated"><strong class="ig hi">屏蔽R-CNN </strong>:对象实例分割的快速R-CNN扩展模型。</li><li id="8ddf" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated"><strong class="ig hi">度量和基准</strong>:为分类、对象检测和图像分割提供一些众所周知的度量和基准。</li></ul><blockquote class="ls"><p id="2815" class="lt lu hh bd lv lw lx ly lz ma mb jb dx translated">接下来是DeepMind深度学习系列讲座4的笔记:超越分类的视觉:超越单一图像输入</p></blockquote><div class="mc md me mf mg mh"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ko mh"/></div></div></a></div></div></div>    
</body>
</html>
# OSS & NCR

> 原文：<https://medium.com/mlearning-ai/oss-ncr-c16f69627715?source=collection_archive---------0----------------------->

针对不平衡数据集的另一个有趣的欠采样技术

![](img/ce2eeb00f9297af9d49dcc2b3d4bbe65.png)

大家好，我们又像承诺的那样，讨论了一个来自数据科学领域的有趣话题。

今天，我们将研究针对欠采样不平衡数据集的保留和删除方法的组合。

单侧选择(OSS)是另一种欠采样技术，结合了 Tomek 链接和压缩(CNN)规则。

**托梅克链接**是在多数类中被移除的类边界上的模糊点，并且 **CNN** 方法被用于从远离决策边界的多数类中移除冗余的例子。

该方法首先由 Miroslav Kubat 和 Stan Matwin 在 1997 年发表的题为“[解决不平衡训练集的诅咒:单边选择](https://sci2s.ugr.es/keel/pdf/algorithm/congreso/kubat97addressing.pdf)”的论文中提出

```
#One-Sided Selection
from collections import Counter
from sklearn.datasets import make_classification
from imblearn.under_sampling import OneSidedSelection
from matplotlib import pyplot
from numpy import where#define dataset
X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)#summarize class distribution
counter = Counter(y)
print(counter)#define the undersampling method
undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)#transform the dataset
X, y = undersample.fit_resample(X, y)#summarize the new class distribution
counter = Counter(y)
print(counter)#plot
for label, _ in counter.items():
row_ix = where(y == label)[0]pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))
pyplot.legend()
pyplot.show()
```

就是这样！

现在让我们来看看什么是 NCR

**NCR 代表邻域清理**规则一种欠采样技术，结合了 CNN 来去除冗余数据和 ENN 来去除噪声或模糊数据。

这里的重点不是改善类分布的平衡，而是保留在多数类中的数据的质量(明确性)。

这种方法包括首先从少数群体中选择所有的例子。然后，使用 ENN 规则识别并移除多数类中的所有模糊数据。最后，使用 CNN 的一步版本，其中多数类中那些相对于存储错误分类的剩余数据被移除，但是仅当多数类中的数据数量大于少数类大小的一半时。

```
#neighborhood cleaning rulefrom collections import Counter
from sklearn.datasets import make_classification
from imblearn.under_sampling import NeighbourhoodCleaningRule
from matplotlib import pyplot
from numpy import where#define dataset
X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)#summarize class distribution
counter = Counter(y)
print(counter)#define the undersampling method
undersample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)#transform the dataset
X, y = undersample.fit_resample(X, y)#summarize the new class distribution
counter = Counter(y)
print(counter)#scatter plot of examples by class labelfor label, _ in counter.items():
  row_ix = where(y == label)[0]
  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))
pyplot.legend()
pyplot.show()
```

就是这样。

我希望你喜欢它，如果你想了解更多细节，你可以谷歌一下 OSS&NCR——欠采样技术或者你可以访问机器学习大师网站。

同样，我会尽我所能带来更多数据科学的新方法。

如果您希望探索更多关于数据科学的新方法，请关注我的其他文章。

我的一些另类网络存在[脸书](https://www.facebook.com/rupakroybob)、 [Instagram](https://www.instagram.com/bobrupak/) 、 [Udemy](https://www.udemy.com/course/ai-master-class) 、Blogger、Issuu 等等。

也可以在 Quora @上找到[https://www.quora.com/profile/Rupak-Bob-Roy](https://www.quora.com/profile/Rupak-Bob-Roy)

![](img/83e41b92e06a7fc4330ed4b12fa1bb34.png)

[https://www.quora.com/profile/Rupak-Bob-Roy](https://www.quora.com/profile/Rupak-Bob-Roy)

# 祝你愉快。

![](img/4dc68161d36061a1ccb474947424e2a9.png)[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
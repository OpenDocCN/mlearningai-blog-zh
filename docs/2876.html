<html>
<head>
<title>Your Starter Guide for Natural Language Processing in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python自然语言处理入门指南</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/your-starter-guide-for-natural-language-processing-in-python-854f0a38ce17?source=collection_archive---------3-----------------------#2022-06-21">https://medium.com/mlearning-ai/your-starter-guide-for-natural-language-processing-in-python-854f0a38ce17?source=collection_archive---------3-----------------------#2022-06-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d912" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你有没有想过你的手机是如何生成文本并为你预测正确的单词的(即使不是一直如此)？纠正你的话？或者你想过计算机如何进行情感分析并预测客户对某些主题的感受吗？</p><p id="8ee5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">答案是自然语言处理或NLP。定义NLP最简单的方法是计算机或机器如何理解和解释我们的人类语言，以提供输出，如垃圾邮件检测或情感分类。</p><p id="3807" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">NLP领域始于20世纪40年代，几十年来不断发展，出现了许多新的应用和用例。如今，使用Python等开源软件构建NLP模型并不困难，这就是我在这里提供的，一个可以开始构建模型的指南。</p><p id="0e54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我将展示我为文本分类开发的代码，该代码用于构建应急响应，它将在两个方面为救灾组织带来好处:</p><p id="2a59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.过滤并提取推特上的求救信息。</p><p id="44b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.正确分类这些求救信息，以提供所需的帮助。</p><p id="eedc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文章分为三个部分。第一部分将描述文本处理所需的步骤，如所需的库、文本规范化、标记化和其他附加步骤。第二部分是我将要展示代码的地方，我将使用它作为一个例子来解释第一部分中提到的步骤。最后一节将解释单词嵌入和文本生成背后的理论。最后，您可以在文章末尾找到一些资源的链接。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="7f0a" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">第1部分:文本处理步骤</h1><p id="71ad" class="pw-post-body-paragraph ie if hh ig b ih kh ij ik il ki in io ip kj ir is it kk iv iw ix kl iz ja jb ha bi translated">文本处理包括以下主要步骤:</p><ol class=""><li id="4e43" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb kr ks kt ku bi translated">文本规范化:这一步包括去掉标点符号，将大写字母转换成小写字母。这对于避免文本分类过程中的混淆很重要，并且最终将大写字母的单词与小写字母的单词进行不同的分类。</li><li id="5863" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">文本标记化:将文本分割成单个单词，并作为列表。这将有助于将文本信息作为数字信息处理。这对于接下来的单词计数或矢量化非常重要。此外，下一个过程(词干化或词汇化)处理的是单词而不是句子。</li><li id="3119" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">词干化或词汇化:这发生在标记化之后，其中每个单词被转换为其词根，以避免因单词具有不同形式而造成的任何混淆，其中每个形式将被视为唯一的单词，而实际上它不是(单词write、write、writing具有与write相同的词根)。</li><li id="173c" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">去除停用词:停用词(如；The，a，an，This)以避免错误的分类或更长的文本处理时间。此外，这些词本身对句子没有任何意义。</li><li id="1ec1" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">特征提取:文本处理的这一部分是以两种方式中的一种来处理的，这取决于所寻找的是什么。例如，用于文档级任务(如垃圾邮件检测)的特征提取不同于用于单词或句子级的特征提取(如文本生成)。第一种要求我们使用单词包或<strong class="ig hi">计数矢量器</strong>。而第二个将使用<strong class="ig hi"> Tfidf矢量器。</strong>在计数矢量器中，我们计算单词出现的次数。而在Tfidf中，矢量器(Tfidf =术语频率-逆文档频率)通过将单词出现的次数除以它出现在文档中的次数来为每个单词分配权重。例如，如果单词<em class="la">苹果</em>在十(10)个文档中出现五(5)次，那么它的权重为0.5。</li></ol><p id="a8b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里要陈述的最后一件事是，我们到目前为止所看到的是否适用于阿拉伯语？简单的回答是肯定的。在参考资料部分，我将包括一些与用于阿拉伯语的NLP库相关的参考资料。此外，在第二部分的最后，我将展示相关的代码。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="83ff" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">第2部分:代码示例</h1><p id="5079" class="pw-post-body-paragraph ie if hh ig b ih kh ij ik il ki in io ip kj ir is it kk iv iw ix kl iz ja jb ha bi translated">下面你会看到一个简单而全面的文本处理管道的例子。由于每一行都有编号，我将参考行号并解释其含义。我不会浏览完整的代码，只讨论与文本处理相关的部分，这些部分与第1节中提到的步骤相关。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lb"><img src="../Images/bcefdda6d072e47e61cba90a73361188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*oO3YSYhbOTvN129cNM8QKg.png"/></div></figure><ul class=""><li id="45a5" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb lj ks kt ku bi translated">第一部分是导入类和库。在第21行中，整个nltk库被导入。<strong class="ig hi">第6、7、22行</strong>分别导入了三个类；标记化、词汇化和停用词。然而，为了让这三个类工作，需要下载三个文件。这些文件是:</li></ul><ol class=""><li id="e788" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb kr ks kt ku bi translated"><strong class="ig hi"><em class="la">punket</em></strong><em class="la"/>为了更好的分词处理(<strong class="ig hi">第23行</strong>)</li><li id="6b91" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated"><strong class="ig hi"><em class="la">wordnet</em></strong><em class="la"/>作引理(<strong class="ig hi">第24行</strong>)</li><li id="1241" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated"><strong class="ig hi"> <em class="la">停用词</em> </strong> <em class="la"> </em>文件中有所有停用词的英文(<strong class="ig hi">第25行</strong>)</li></ol><ul class=""><li id="7fa9" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb lj ks kt ku bi translated">第二部分是构建管道来执行处理步骤规范化、标记化、词汇化和停用词删除。<strong class="ig hi">在第38行，</strong>定义了一个名为<em class="la"> tokenize </em>的函数，这里我们有任何文本作为输入，输出是干净的tokenized单词列表。<strong class="ig hi">在第39行</strong>，英文停用词被上传到列表中以备后用。<strong class="ig hi">在第41行，</strong>文本被规范化，其中标点符号被替换为空格，所有字母都被转换为小写。<strong class="ig hi">在第43行，</strong>文本被标记化，其中每个文本被分割并存储在一个列表中。<strong class="ig hi">在第44行，</strong>创建了lemmatize类，文本将通过它将每个单词转换回它的根形式。文本处理管道的最后一部分，<strong class="ig hi">在第46行，</strong>停用词从词汇列表中取出，并返回一个称为“<em class="la">干净标记</em>的干净单词列表。</li><li id="f72b" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated">代码的最后一部分是构建机器学习(ML)模型，从l <strong class="ig hi">行51到56 </strong>开始。该模型从管道类开始，管道类由三部分组成:计数矢量器、Tfidf转换器和多分类器。通过使tokenizer等于tokenize，文本处理函数(<em class="la"> tokenize </em>)被用作计数矢量器类的输入参数。如前所述，计数矢量器将计算词频。ML管道的下一部分是进行Tfidf-Transformation，其中通过将词频除以单词出现的文档数来对每个单词进行加权。这两个ML过程相当于使用Tfidf-vectorizer。pipeline类的最后一个参数是多分类器，因为有多个标签(超过2个标签)，所以使用它。机器学习功能的最后一部分是网格搜索，它使用估计器20和40的两个不同值作为多分类器类的输入参数来应用ML流水线。</li></ul><p id="528e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些都是大部分英文文本处理所需要的部分。一旦文本被处理，你可以使用任何机器学习算法。</p><p id="60bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于阿拉伯语的文本处理，困难的部分是词汇化和词干化。这是因为没有多少库可以完成这个功能，但是很少。下面是你需要添加到我上面显示的代码中的唯一修改。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es lk"><img src="../Images/488ce4d38b85d50c27dbfae69457d582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*O0j369JT_uk5zhF39VcxKA.png"/></div></figure><p id="ed3e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第一部分是获取阿拉伯语的停用词，将其从与第一代码相似的词列表中删除。接下来的三个部分是进行词干化或词汇化的不同选项。第一个和第二个选项是使用ISRIStemmer或snowballstemmer。这两个选项都不完美，但对于简单的文本来说可能足够了。至于提供最佳结果的最后一个选项是使用Farasa库。你所需要做的就是使用显示的代码行，但是使用你的API代码，一旦你注册到他们的网站，你就会在你的电子邮件中收到这些代码。然而，这个库的主要问题是它的局限性。您只需要处理有限的文本，因为这个过程是通过Farasa库的API完成的。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="3646" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated"><strong class="ak">第三部分:单词嵌入和文本生成概念</strong></h1><p id="b702" class="pw-post-body-paragraph ie if hh ig b ih kh ij ik il ki in io ip kj ir is it kk iv iw ix kl iz ja jb ha bi translated">在这最后一节，我将解释单词嵌入(矢量化)背后的概念，以及文本生成是如何工作的，而不会深入讨论数学算法的细节。附加的参考资料显示在最后，这将有助于编程&amp;提供更深入的数学解释。现在让我们从文本处理的最后一部分开始，这是计数单词或计数矢量器，我们在这里计数词频，从这一点我们可以进行单词矢量化(将单词表示为矢量)。让我们通过这三个文本来看一些简单例子:</p><ul class=""><li id="92c8" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb lj ks kt ku bi translated">文本1:“我将去日本旅游”</li><li id="ea1a" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated">文本2:“约翰将飞往日本”</li><li id="25de" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated">文本3:“我要去德国旅游”</li></ul><p id="92e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在第一个表格中，我们看到每个文本都由单词组成，这给了我们一个向量</p><figure class="lc ld le lf fd lg er es paragraph-image"><div class="er es ll"><img src="../Images/f44d88f54d47e27dd7c2b4dce1de9bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*0o3QJaK4xGUTH433_h7ahw.png"/></div></figure><p id="7b13" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，文本一有一个向量(1，1，1，1，0，0，0，0)，而文本二有一个向量(0，1，0，1，1，1，1，0，0)，通过对两个向量之间的角度取余弦，我们可以看到它们有多相似，对于这两个向量，余弦相似度为0.6 (1表示相同，0表示不相似，而-1表示相反)。因此，有了这个我们就可以检测出不同的单词有多么相似。</p><p id="342d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将文本转换为向量是神经网络和机器学习算法的重要输入，因为它们只接受数值。因此，这种神经网络可以用于情感分类、寻找相似的词或文本生成。</p><p id="6d36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在来谈谈文本世代，这个想法真的很简单。假设有一个由六(6)个单词组成的文本，现在我们决定用黄色突出显示一个单词窗口(见下图)。让我们假设我们有单词2，这个单词在许多文本中重复出现，所以我们在这里做的是计算概率，这可以用两种方法之一来完成:</p><ol class=""><li id="7bd0" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb kr ks kt ku bi translated">如果我们有单词-2，我们计算单词-1、单词-3或单词-4出现的概率。所以它将是<em class="la"> P(Word-1|Word-2)，</em>给定我们有Word-2，有Word-1的概率。这对于单词3和单词4也是一样的。</li><li id="03fd" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">我们反过来做，因此我们计算<em class="la"> P(单词-2 |单词-1)、P(单词-2 |单词-3)和P(单词-2 |单词-4)，</em>这是在给定单词-1、单词-3和单词-4的情况下拥有单词-2的概率。</li></ol><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/bc304f9e533503b5dea21502cc7765bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g2Lj0nIVdq75MmG2xU2aSg.png"/></div></div></figure><p id="507a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面你会发现一个简单的代码，你可以键入和尝试不同的文本，以简单的方式理解文本生成的概念。</p><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lr"><img src="../Images/355d945510a0cd5639a52d33ef44a1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cbOAlu_uzBXAUW68xXbF9g.png"/></div></div></figure><p id="bdee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，好消息是单词嵌入和文本生成可以由已经为Python开发的高级模型来处理，比如word2vec和Glove。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="23e3" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">帮助您入门的有用链接</h1><p id="111a" class="pw-post-body-paragraph ie if hh ig b ih kh ij ik il ki in io ip kj ir is it kk iv iw ix kl iz ja jb ha bi translated">下面我将列出三个有用的资源来丰富你的知识:</p><ul class=""><li id="9c74" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb lj ks kt ku bi translated"><a class="ae ls" href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/2004-05/nlp/overview_history.html" rel="noopener ugc nofollow" target="_blank">NLP的历史</a></li><li id="8444" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://www.nltk.org/index.html" rel="noopener ugc nofollow" target="_blank"> NLTK文档</a></li><li id="d21a" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://towardsdatascience.com/understanding-nlp-word-embeddings-text-vectorization-1a23744f7223" rel="noopener" target="_blank">理解NLP单词嵌入</a></li><li id="12d2" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://www.geeksforgeeks.org/word-embeddings-in-nlp/" rel="noopener ugc nofollow" target="_blank">自然语言处理中的单词嵌入</a></li><li id="999f" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">手套字嵌入</a></li><li id="7ccf" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://www.tensorflow.org/tutorials/text/word2vec" rel="noopener ugc nofollow" target="_blank"> Word2vec单词嵌入</a></li><li id="7cc2" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://monkeylearn.com/blog/natural-language-processing-applications/" rel="noopener ugc nofollow" target="_blank">自然语言处理应用使用案例</a></li><li id="f1d0" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb lj ks kt ku bi translated"><a class="ae ls" href="https://farasa.qcri.org/" rel="noopener ugc nofollow" target="_blank">用于阿拉伯语处理的Farasa</a></li></ul><div class="lt lu ez fb lv lw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">medium.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk lh lw"/></div></div></a></div></div></div>    
</body>
</html>
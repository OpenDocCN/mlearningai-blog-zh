<html>
<head>
<title>Linear Regression and its capabilities</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归及其能力</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/linear-regression-and-its-capabilities-ce6bccd7b92c?source=collection_archive---------3-----------------------#2022-02-01">https://medium.com/mlearning-ai/linear-regression-and-its-capabilities-ce6bccd7b92c?source=collection_archive---------3-----------------------#2022-02-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3967" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">80%的人倾向于忘记线性回归的基础知识</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/212c13faa04c5df7312c48a98b4e9c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VksCQ3_mSQublkyGS6Lr8Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">linear relationship between body mass and flipper length</figcaption></figure><h2 id="f14c" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">线性回归在ML中的应用及其能力</h2><p id="56aa" class="pw-post-body-paragraph kk kl hh km b kn ko ii kp kq kr il ks jx kt ku kv kb kw kx ky kf kz la lb lc ha bi translated">我们大多数人都已经学习了线性回归，但我们往往会忘记所有算法中最基本和最简单的算法。</p><p id="16b3" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">在这个故事中，我们将探索线性回归，了解线性回归算法的假设，线性回归的数据准备，不同的训练技术和线性回归在机器学习中的应用。</p><p id="24df" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">让我们开始吧…</p></div><div class="ab cl li lj go lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ha hb hc hd he"><p id="95af" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated"><strong class="km hi">什么是线性回归？</strong></p><p id="26a1" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">线性回归在属性(输入变量)和目标变量之间建立了线性关系。目标是找到最佳拟合线(/平面/超平面)。关系方程的形式是，</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lp"><img src="../Images/806e32aed6f13e60a6c274d599c18ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*GHnx2cNBsh8GYOy0hghyDA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">linear equation</figcaption></figure><p id="7a77" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">x代表<strong class="km hi">输入特征向量</strong>，而<strong class="km hi"> α是向量系数</strong>。<strong class="km hi"> b(偏置)决定了坐标空间中关系的线性位移</strong>。</p><p id="7149" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">现在让我们理解线性回归算法对输入数据变量(特征)所做的假设</p><p id="809d" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated"><strong class="km hi">线性回归的数据假设</strong></p><ol class=""><li id="862c" class="lq lr hh km b kn ld kq le jx ls kb lt kf lu lc lv lw lx ly bi translated"><strong class="km hi">线性假设</strong>:假设输出/目标属性与输入属性具有线性关系。换句话说，它认为输入和输出要素之间预先存在线性关系</li><li id="71b6" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><strong class="km hi">无噪声</strong>:算法认为数据无噪声。</li><li id="c78e" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><strong class="km hi">无共线性</strong>:假设输入属性之间没有相关性或相关性最小。(当一个属性的变化影响到另一个属性的值时，它们被认为是相关的)</li><li id="e2f9" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><strong class="km hi">高斯分布</strong>:当输入和输出属性为高斯分布时，线性回归表现更好</li><li id="1455" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><strong class="km hi">相同标度输入:</strong>假设输入属于相同的参考标度，比如标准化为0-1或围绕平均值标准化</li><li id="df1e" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><a class="ae me" href="https://www.statisticshowto.com/homoscedasticity/" rel="noopener ugc nofollow" target="_blank"> <strong class="km hi">同方差:</strong> </a>残差的方差(实际值和预测值之间的差异)在所有观测值中是相似的，并且与输入要素本身无关。</li></ol><p id="99d8" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">(为什么homoscedasticity很重要？)</p><p id="429c" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">使用线性回归模型时，必须检查上述假设。我们可以应用诸如<a class="ae me" href="https://www.isixsigma.com/tools-templates/normality/making-data-normal-using-box-cox-power-transformation/" rel="noopener ugc nofollow" target="_blank"> <strong class="km hi"> box-cox </strong> </a> <strong class="km hi">或对数变换</strong>用于高斯分布，<a class="ae me" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank"> <strong class="km hi">标准化或归一化</strong> </a>用于重新缩放。</p><p id="fad2" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">消除共线性很重要，否则算法会更加强调相关属性，增加过度拟合的机会。</p><p id="8122" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">线性回归主要根据输入属性的数量分为简单线性回归(1个输入属性)和多元线性回归(多个输入)</p><p id="bfd8" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">然而，基于用于拟合算法的训练方法，以各种形式研究线性回归。它们是什么？让我们来找出…</p><p id="4a37" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated"><strong class="km hi">线性回归的训练技巧</strong></p><p id="bb60" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">线性回归是研究最多的算法，有许多技术来拟合方程的系数。有4个最受欢迎的，我们将讨论</p><ol class=""><li id="2fa8" class="lq lr hh km b kn ld kq le jx ls kb lt kf lu lc lv lw lx ly bi translated"><strong class="km hi">统计</strong>:使用简单线性回归时，统计可用于估计系数。计算统计测量值，如平均值、标准偏差、相关性和协方差。</li><li id="fd09" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><strong class="km hi">普通最小二乘法</strong>:程序寻求最小化残差平方和(残差是真实值和预测值之间的差值)。<a class="ae me" href="https://machinelearningmastery.com/solve-linear-regression-using-linear-algebra/" rel="noopener ugc nofollow" target="_blank">线性代数</a>用于寻找最佳拟合。然而，这种技术要求所有的输入数据都适合内存</li><li id="832c" class="lq lr hh km b kn lz kq ma jx mb kb mc kf md lc lv lw lx ly bi translated"><a class="ae me" href="https://www.analyticsvidhya.com/blog/2021/03/understanding-gradient-descent-algorithm/" rel="noopener ugc nofollow" target="_blank"> <strong class="km hi">梯度下降</strong> </a>:梯度下降算法试图通过基于梯度(斜率)逐渐更新系数来最小化误差。当适合大型数据集时，它是有效的。</li></ol><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mf"><img src="../Images/619f0dde901752db401741bb6830589b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dp2Tn_n9iE5kqpiZ_fNIdw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">loss minimization using Gradient descent</figcaption></figure><p id="30d5" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">4.<strong class="km hi">正则化</strong>:正则化技术试图最小化残差的平方以及线性回归的复杂性。有两种方法:套索回归(L1) |岭回归(L2) ( <a class="ae me" href="https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b" rel="noopener" target="_blank"> <em class="mg">了解更多</em> </a>)。</p><blockquote class="mh mi mj"><p id="61fc" class="kk kl mg km b kn ld ii kp kq le il ks mk lf ku kv ml lg kx ky mm lh la lb lc ha bi translated">既然我们已经了解了线性回归的基本假设和用于拟合系数的技术。让我们了解机器学习的实际应用，以及如何使用Python应用这些应用</p></blockquote></div><div class="ab cl li lj go lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ha hb hc hd he"><p id="8f59" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated"><strong class="km hi">线性回归在ML中是如何使用的？？</strong></p><p id="0977" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">让我们使用<a class="ae me" href="https://colab.research.google.com/drive/1rLhGiRq1ICxiDldxhCsQaPFkwZqtBTFZ?usp=sharing" rel="noopener ugc nofollow" target="_blank">链接</a>中的一个例子快速探究线性回归中使用的各种指标(在桌面环境中打开该链接以便更好地查看)</p><p id="0909" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">一些度量和模型选择方法，如<a class="ae me" href="https://machinelearningmastery.com/probabilistic-model-selection-measures/" rel="noopener ugc nofollow" target="_blank"> AIC(阿凯克信息标准)和BIC(贝叶斯信息标准)</a>在上面的链接中进行了探讨。</p><p id="5b3e" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">线性回归主要用于理解变量之间的关联。它还用于检查变量之间的相关性。</p></div><div class="ab cl li lj go lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ha hb hc hd he"><h2 id="d03e" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">结论</strong></h2><p id="c040" class="pw-post-body-paragraph kk kl hh km b kn ko ii kp kq kr il ks jx kt ku kv kb kw kx ky kf kz la lb lc ha bi translated">线性回归是最简单的机器学习算法，多年来已经得到了非常彻底的研究。这是一个功能有限的简单模型。然而，我们经常倾向于忽略模型带来的简单性，尤其是在理解概念方面。</p><p id="4e47" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">通过这篇文章，我试图帮助你回忆或学习线性回归的一些基本概念。</p><p id="38c2" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">如果我能帮助你理解至少一个概念，我会认为我的工作已经完成。</p><p id="9eef" class="pw-post-body-paragraph kk kl hh km b kn ld ii kp kq le il ks jx lf ku kv kb lg kx ky kf lh la lb lc ha bi translated">不要忘记表达你对❤的支持，并关注更多有趣的博客！！</p><div class="mn mo ez fb mp mq"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hi fi z dy mv ea eb mw ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jg mq"/></div></div></a></div></div></div>    
</body>
</html>
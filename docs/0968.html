<html>
<head>
<title>Audio Classification using Wavelet Transform and Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于小波变换和深度学习的音频分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/audio-classification-using-wavelet-transform-and-deep-learning-f9f0978fa246?source=collection_archive---------1-----------------------#2021-09-05">https://medium.com/mlearning-ai/audio-classification-using-wavelet-transform-and-deep-learning-f9f0978fa246?source=collection_archive---------1-----------------------#2021-09-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="74fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用连续小波变换(CWT)作为特征对音频信号进行分类的逐步实现。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/bfc800f9fb60d2628e149709350c7f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ehpVs4_hE-1WYr-JKeD1g.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Photo by <a class="ae js" href="https://unsplash.com/@jan_huber?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Jan Huber</a> on <a class="ae js" href="https://unsplash.com/s/photos/frequency?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="74d0" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="ad62" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">音频分类是一项非常重要的任务。在过去的十年中，已经进行了大量的研究，使用不同种类的特征和神经网络架构对音频进行分类。这方面的一些实际应用是说话人识别、环境声音分类、音乐流派分类和鸟声分类。音频中最常用的功能是Spectrograms/Mel-spectrograms和最先进的MFCCs。然而，研究人员还探索了一些其他方法来对音频数据进行分类。一种这样的方法是小波变换。在本文中，我们将了解小波变换，以及如何将它与机器学习一起用于分类任务。</p><h1 id="9c74" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">什么是小波？</h1><p id="3c51" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">首先，我们将讨论为什么需要小波。</p><p id="483d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，傅立叶变换用于从信号中提取频率。傅立叶变换使用一系列不同频率的正弦波来分析信号。但是它有一个很大的缺点。它正在选择合适的窗口大小。根据海森堡的测不准原理:</p><ul class=""><li id="b573" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">窄的窗口将在时间上定位信号，但是在频率上将有显著的不确定性。</li><li id="7495" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">如果窗口足够宽，那么时间不确定性增加。</li></ul><p id="917e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是时间和频率分辨率之间的权衡。</p><p id="1f94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">避免这个问题的一种方法是<strong class="ig hi">多分辨率分析(MRA) </strong>。MRA的一个例子是小波变换。在MRA中，以不同的分辨率水平分析信号。</p><blockquote class="lk ll lm"><p id="4dc0" class="ie if ln ig b ih ii ij ik il im in io lo iq ir is lp iu iv iw lq iy iz ja jb ha bi translated">小波是一种在时间上局部化的波状振荡。小波有两个基本属性:尺度和位置。尺度定义了小波的“拉伸”或“压缩”程度。位置是时间上的位置。</p></blockquote><p id="222b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是小波变换的公式。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lr"><img src="../Images/a8390045cf4f7b2c32832863f3be4607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QexPITo-qkjjInOcjswt5w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">The formula of Wavelet Transform</figcaption></figure><p id="d676" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">小波变换可以改变“标度”参数，以找到信号中的不同频率及其位置。<strong class="ig hi">所以，现在我们知道时间信号中存在哪些频率，它们存在于哪里</strong>。较小的尺度意味着小波被挤压。因此，它可以捕捉更高的频率。另一方面，较大的音阶可以捕捉较低的频率。你可以在下图中看到一个压缩和拉伸小波的例子。</p><div class="jd je jf jg fd ab cb"><figure class="ls jh lt lu lv lw lx paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/70dc516c7358a9a8fbb1298a59a431a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*G9JL4tzlvzv4V28LQqmJjA.png"/></div></figure><figure class="ls jh ly lu lv lw lx paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/f010200a02d2fee39a6e40ae748366c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*gSFniIBseGC7aKMSBaIosg.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx lz di ma mb">(Left) Smaller-scale or squished wavelet, (Right) Larger scale or stretched wavelet</figcaption></figure></div><p id="aa02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">这是小波变换相对于FFT的优势。它可以同时捕捉光谱和时间信息</strong>。因此，基本上，一个信号与一组不同尺度和位置的小波进行卷积。被缩放和移位的原始小波被称为“母小波”。有这么多小波可供选择。不同的小波用于不同的应用。</p><p id="c4a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将在本教程中使用Morlet小波。</p><blockquote class="lk ll lm"><p id="91e9" class="ie if ln ig b ih ii ij ik il im in io lo iq ir is lp iu iv iw lq iy iz ja jb ha bi translated">Morlet小波(或Gabor小波)用于听觉和视觉，因为它与人类感知密切相关。它由复数指数乘以一个高斯窗口组成。Morlet小波的公式如下所示:</p></blockquote><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mc"><img src="../Images/ba3df7a564fa52b6366c2633a8dfff73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*rN6FUywzuUUZ7fPUP8dF_A.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Morlet wavelet formula</figcaption></figure><p id="fa99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是Morlet小波的样子:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es md"><img src="../Images/8396918d65760504b5a952b1dbafd63f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*ad0c3WWM9og7qfqxoFFC7Q.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Morlet wavelet</figcaption></figure><p id="2cdd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里有一篇关于介质的文章，详细讨论了小波。</p><div class="me mf ez fb mg mh"><a href="https://towardsdatascience.com/what-is-wavelet-and-how-we-use-it-for-data-science-d19427699cef" rel="noopener follow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">什么是小波，我们如何在数据科学中使用它</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">你好，这是我关于信号处理主题的第二篇文章。目前，我有兴趣学习更多关于信号的知识…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv jm mh"/></div></div></a></div><h1 id="3aa6" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">问题陈述</h1><p id="9f8f" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><strong class="ig hi">目标:</strong>我们想用连续小波变换对音频进行分类。我们将使用<a class="ae js" href="https://github.com/Jakobovski/free-spoken-digit-dataset" rel="noopener ugc nofollow" target="_blank">自由口语数字数据集(FSDD) </a>。我们将提取每个样本的小波变换，并尝试使用深度神经网络从该数据集中对说话人进行分类。为了演示这种方法，我们将在本教程中只对3个说话者进行分类。</p><h1 id="be9d" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">数据描述</h1><p id="7a48" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><a class="ae js" href="https://github.com/Jakobovski/free-spoken-digit-dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">自由口语数字数据集(FSDD) </strong> </a> <strong class="ig hi"> : </strong>一个简单的音频/语音开放数据集，包括在。8kHz的wav文件。录音经过修剪，因此在开始和结束时几乎没有静音。它包含:</p><ul class=""><li id="3cf6" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">6个扬声器</li><li id="5867" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">3，000个录音(每个扬声器每个数字50个)</li><li id="0262" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">英语发音</li></ul><h1 id="52d2" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">履行</h1><p id="de23" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我会解释所有的步骤。<em class="ln">最后，GitHub上还有完整代码的链接。</em></p><h2 id="5992" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated">步骤1:导入所有库</h2><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><h2 id="8c5d" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated">小波变换示例(用于演示目的的可选步骤)</h2><p id="e75a" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><strong class="ig hi"><em class="ln">python中的Librosa </em> </strong>库用于音乐和音频分析。我们可以使用这个库读取音频文件并提取频谱图。对于小波变换，我们将使用<strong class="ig hi"> <em class="ln"> pywt </em> </strong>库。</p><p id="7c41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是来自自由口语数字数据集的样本的小波变换。</p><p id="68f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在第7行，我们将小波类型设置为“Morlet”。第8行设置了采样率。在第9行，我们已经设置了小波的尺度。在第17行，我们已经计算了小波变换。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="50d2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输出:</strong></p><p id="1231" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些是我们正在使用的标度:<em class="ln">【1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 56 57 58 59 69 60</em></p><p id="4ffe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些是与音阶相关的频率:<em class="ln">【6500。3250.2166.66666667 1625.1300.1083.33333333 928.57142857 812.5 722.22222222 650.590.90909091 541.66666667 500.464.28571429 433.33333333 406.25 382.35294118 361.11111111 342.10526316 325.309.52380952 295.45454545 282.60869565 270.83333333 260.250.240.74074074 232.14285714 224.13793103 216.66666667 209.67741935 203.125 196.96969697 191.17647059 185.71428571 180.55555556 175.67567568 171.05263158 166.66666667 162.5 158.53658537 154.76190476 151.1627907 147.72727273 144.44444444 141.30434783 138.29787234 135.41666667 132.65306122 130.127.45098039 125.122 . 5508772 1110 . 1206586586</em></p><p id="4405" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">小波变换的形状:<em class="ln"> (63，6571) </em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nm"><img src="../Images/ca216ea1562c7f6244497b4f546ccbac.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*yl_SHZ75tcw0ie2E-TGAmw.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Wavelet Transform of a small frame of audio sample</figcaption></figure><p id="af61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们读取所有的数据，并提取它们的所有特征。</p><h2 id="3045" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated">步骤2:读取音频文件，并将它们分成训练/测试数据</h2><p id="62c2" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们在这里只对3个扬声器进行分类。因此，我们将从3个说话者身上提取样本:乔治、杰克逊和卢卡斯。我们将把所有数据写入一个. npz文件。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="b93b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输出:</strong></p><p id="374c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练数据类分布:(数组([0，1，2])，数组([360，352，338])</p><p id="25dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">测试数据类分布:(数组([0，1，2])，数组([140，148，162])</p><h2 id="a252" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated"><strong class="ak">第三步:提取小波变换特征</strong></h2><p id="c6ce" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">让我们创建一个函数来提取小波变换。在计算小波特征之后，<strong class="ig hi">我们将把时间序列分成长度为400 </strong>的帧。采样速率为8 kHz。所以，400帧相当于50毫秒。我们还创建了一个带通滤波器。我们将只采用80Hz到1000 kHz之间的频率。</p><p id="4d8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">人声频率范围:</strong>人耳可以听到20到20，000赫兹(20千赫兹)之间的声音，但它对250到5，000赫兹之间发生的一切最敏感。典型的成年男性的有声语音将具有从85到180 Hz的基频，而典型的成年女性的有声语音将具有从165到255 Hz的基频。对于孩子的声音，平均基频是300赫兹。辅音占据2千赫到5千赫之间的空间。元音在500赫兹到2千赫兹之间很突出。</p><p id="8dea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将把所有特性写在一个. npz文件中，这样我们以后就可以很容易地从那里加载特性。<strong class="ig hi">特征的形状为(76×400)。它的格式是:(Features x timesteps)。</strong></p><p id="ce09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还保存了每个样本的唯一id。这很重要，因为我们将每个样本分成多个帧，我们需要知道哪个帧属于哪个样本。来自一个样本的所有帧将具有相同的id。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="06f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">提取训练数据的特征:</strong>我们从训练数据中抽取随机样本，并从每个样本中抽取一些随机帧，以减少训练数据。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="8b06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">提取测试数据的特征:</strong></p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="9c87" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练数据的形状为:(8267 x 76 x 400)。</p><p id="25ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练数据的形状为:(12326 x 76 x 400)。</p><p id="46aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">数据格式为:(数量_样本x特征x时间步长)。</strong></p><h2 id="9bcd" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated"><strong class="ak">第四步:构建深度学习模型</strong></h2><p id="941e" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们将使用扩张1D卷积以及批量标准化层。我们使用时间分布1D卷积，因为这是一个多变量时间序列。<strong class="ig hi">光谱图和小波变换不是标准图像。在标准图像中，x轴和y轴承载相似的像素内容。但是，在频谱图和小波变换的情况下，x轴是时间，y轴是频率。在这里阅读更多关于此</strong><a class="ae js" href="https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd" rel="noopener" target="_blank"><strong class="ig hi"/></a><strong class="ig hi">。但是，也可以随意使用2D卷积，因为许多人也将2D卷积用于频谱图，并取得了良好的效果。</strong></p><p id="e7b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">无论如何，扩张卷积将有助于增加接收场，同时保持参数数量不变。这将很有帮助，因为我们有一个长度为400的多元时间序列。批次标准化层在训练期间标准化小批次，并解决<strong class="ig hi">内部协变量移位</strong>的问题。它使训练更快，模型变得更健壮。我强烈推荐在你的模型中使用这个。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><h2 id="3689" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated">第五步:训练网络</h2><p id="4347" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们将使用5重交叉验证来训练网络。在开始训练过程之前，我们需要更改数据格式。对于深度学习模型，我们需要格式为:<strong class="ig hi">(Num _ samples x time steps x Features)的数据。</strong></p><p id="7560" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要使用标准的定标器来标准化数据。我们将保存训练数据的平均值和标准差。在测试过程中，我们将使用这个平均值和标准差来标准化数据，然后进行预测。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><h2 id="bd68" class="mw ju hh bd jv mx my mz jz na nb nc kd ip nd ne kh it nf ng kl ix nh ni kp nj bi translated">步骤6:测试模型</h2><p id="9fbf" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在测试期间，首先我们将进行预测。但是，我们从一个样本中创建了多个帧。我们将对所有帧进行分类，然后基于帧的多数投票，我们将为样本分配最终类别。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="nk nl l"/></div></figure><h1 id="e5a2" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结果</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lr"><img src="../Images/6ae46bddb05a3a5c5d39bbeb06322baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nuEH59JfZ7LzU1epeh4LDg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Classification report</figcaption></figure><p id="88a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在测试数据集上获得了97%的准确率。</p><p id="25a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是GitHub上完整代码的链接:</p><div class="me mf ez fb mg mh"><a href="https://github.com/AdityaDutt/Audio-Classification-Using-Wavelet-Transform" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">GitHub-AdityaDutt/Audio-class ification-Using-Wavelet-Transform:使用小波对音频进行分类…</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">使用连续小波变换(CWT)作为特征对音频信号进行分类的分步教程。创建一个…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">github.com</p></div></div><div class="mq l"><div class="nn l ms mt mu mq mv jm mh"/></div></div></a></div><h1 id="8ce1" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="84a5" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们已经学会了如何使用小波变换和机器学习进行分类，并在测试数据集上获得了97%的准确率。您也可以将它用于其他分类问题。它也可以用于图像分类。可以使用其他神经网络结构。还可以使用2D卷积、迁移学习模型等。</p><p id="c6c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法的唯一缺点是需要处理的数据太多。<strong class="ig hi">但是，如果</strong> <strong class="ig hi">您可以将变换保存为图像并缩减采样/缩小图像，那么您将拥有更少的数据。</strong>我不确定这会对信息产生什么影响，因为时间步长也会缩短。但看看它的表现会很有趣。</p><blockquote class="lk ll lm"><p id="218c" class="ie if ln ig b ih ii ij ik il im in io lo iq ir is lp iu iv iw lq iy iz ja jb ha bi translated">感谢阅读！我希望它是有用的。👋</p><p id="ac5d" class="ie if ln ig b ih ii ij ik il im in io lo iq ir is lp iu iv iw lq iy iz ja jb ha bi translated">如果你有任何问题让我知道。</p></blockquote><h1 id="4963" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考</h1><div class="me mf ez fb mg mh"><a href="https://arxiv.org/abs/1511.07122v3" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">基于扩张卷积的多尺度上下文聚合</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">语义分割的最新模型是基于卷积网络的改编，卷积网络具有…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">arxiv.org</p></div></div><div class="mq l"><div class="no l ms mt mu mq mv jm mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://github.com/Jakobovski/free-spoken-digit-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">GitHub-Jakobovski/free-口语数字数据集:一个免费的口语数字音频数据集。想想MNIST…</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">一个简单的音频/语音数据集，由8kHz的wav文件中的语音数字记录组成。这些录音是…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">github.com</p></div></div><div class="mq l"><div class="np l ms mt mu mq mv jm mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://arxiv.org/abs/1502.03167" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">批量标准化:通过减少内部协变量转移加速深度网络训练</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">训练深度神经网络是复杂的，因为每层输入的分布在训练过程中会发生变化</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">arxiv.org</p></div></div><div class="mq l"><div class="nq l ms mt mu mq mv jm mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">机器学习中使用小波变换的指南</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">在以前的博客文章中，我们已经看到了如何使用信号处理技术对时间序列进行分类…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">ataspinar.com</p></div></div><div class="mq l"><div class="nr l ms mt mu mq mv jm mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://towardsdatascience.com/what-is-wavelet-and-how-we-use-it-for-data-science-d19427699cef" rel="noopener follow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">什么是小波，我们如何在数据科学中使用它</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">你好，这是我关于信号处理主题的第二篇文章。目前，我有兴趣学习更多关于信号的知识…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv jm mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd" rel="noopener follow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">spectrograms和CNN做音频处理有什么问题？</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">CNN在图像方面做了惊人的事情，但是为什么它们在声音方面做得不好呢？</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="ns l ms mt mu mq mv jm mh"/></div></div></a></div></div></div>    
</body>
</html>
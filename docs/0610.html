<html>
<head>
<title>Machine Learning Basics: K-Nearest Neighbours Python Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础:K近邻Python实现</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/machine-learning-basics-k-nearest-neighbours-python-implementation-b2f836d5ee96?source=collection_archive---------2-----------------------#2021-05-25">https://medium.com/mlearning-ai/machine-learning-basics-k-nearest-neighbours-python-implementation-b2f836d5ee96?source=collection_archive---------2-----------------------#2021-05-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1e61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">k-最近邻(KNN)算法是一种简单、易于实现但功能强大的监督机器学习算法，可用于解决分类问题，并可扩展到回归问题。</p><h2 id="e8f9" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">KNN是如何在幕后工作的？</h2><p id="36f8" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">k-最近邻(KNN)算法使用“特征相似性”来预测新数据点的值，这意味着新数据点将根据其与训练集中的点的匹配程度来分配值。</p><p id="8a54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">KNN算法假设相似的事物存在于附近。换句话说，相似的事物彼此靠近。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/f03f0ac5829e635619fbe655fdfdb860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*UIEh6yyrqYXKxJEsxII1WA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx">Source: <a class="ae ko" href="https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_iris_knn.html" rel="noopener ugc nofollow" target="_blank">https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_iris_knn.html</a></figcaption></figure><p id="6601" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意在上面的图中，大多数相似的数据点是如何彼此接近的。KNN算法基于这样一个假设，即该假设足够真实，使得该算法在进行预测时非常有用。</p><p id="aab8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们从KNN的实施开始，只需3个步骤:</strong></p><ol class=""><li id="c9fe" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated">计算查询数据点<code class="du ky kz la lb b">q</code>与每个训练数据点xᵢ.之间的距离<code class="du ky kz la lb b">d</code>欧几里得距离是KNN最常用的距离度量(也是scikit learn library提供的默认距离)，但Manhattan、Minkowski或Hamming距离也同样适用。</li></ol><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/ae32c4831da98b3454f6ac98e6c19057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*mwMQwhTXavtgGGXptb0kow.gif"/></div></div></figure><p id="a137" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.将距离按升序排列成一个数组，并从该数组中选择<code class="du ky kz la lb b">K</code>最近的距离(第一个<code class="du ky kz la lb b">K</code>条目)。这些将是与您给定的查询数据点<code class="du ky kz la lb b">q</code>最近的<code class="du ky kz la lb b">K</code>邻居。</p><p id="0044" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.获取所选k个邻域的分类标签(yᵢ值)。最常见的标签(多数投票的标签)将是我们的查询数据点<code class="du ky kz la lb b">q</code>的预测标签。</p><p id="c141" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lh">即预测的类标签无非是</em> <code class="du ky kz la lb b"><em class="lh">k</em></code> <em class="lh">条目的模式。(额外提示——如果您正在为回归问题实现KNN，相同的</em> <code class="du ky kz la lb b"><em class="lh">k</em></code> <em class="lh">条目的中值将是您的类标签)</em></p><p id="2ae5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对测试集中的所有测试数据点重复上面的一切。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es li"><img src="../Images/3d87b44efe371f17024e1cda0a95014b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GgUlBjQfSSUV1bGqMwrCmQ.jpeg"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx">Source: <a class="ae ko" href="https://cambridgecoding.wordpress.com/2016/01/16/machine-learning-under-the-hood-writing-your-own-k-nearest-neighbour-algorithm/" rel="noopener ugc nofollow" target="_blank">Cambridge Coding</a></figcaption></figure><h2 id="b7d5" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">不使用scikit的Python实现-学习:</h2><p id="00d2" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">我将使用可靠的虹膜数据集和谷歌colab。虹膜数据集可以从<a class="ae ko" href="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="lj lk l"/></div></figure><p id="d2bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当k=5时，上述代码的结果如下:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ll"><img src="../Images/5c8af0c5627b610cb3755da32d61fd1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b22ab93RZ6xMyzzrHBYWNA.png"/></div></div></figure><p id="dacf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们将这段代码与sklearn实现进行比较:</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="lj lk l"/></div></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lm"><img src="../Images/28c466fea456fae63afbf903b25862a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*FTRynptb7jXPUsCqGR7y-w.png"/></div></figure><p id="b16d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当k=5时，使用sklearn的结果将完全相同。在这两种情况下，预测值为Iris-virginica，相邻值为[141，139，120，145，144]。</p><h2 id="b260" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">如何找到最优的<code class="du ky kz la lb b">K</code>值？</h2><p id="ffc9" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">在实现KNN算法时要记住的最重要的事情之一是如何选择<code class="du ky kz la lb b">k</code>值&amp;不同的<code class="du ky kz la lb b">k</code>值如何影响模型的性能。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ln"><img src="../Images/c1c0a6fa48f01fe379efe6b1895a03e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2kspPfATiPmPqgKAHtyvQw.png"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx">Source: <a class="ae ko" href="https://morioh.com/p/39a8acaae3ce" rel="noopener ugc nofollow" target="_blank">https://morioh.com/p/39a8acaae3ce</a></figcaption></figure><p id="d01e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上图中，当<code class="du ky kz la lb b">k=16</code>预测的班级标签是<code class="du ky kz la lb b">X</code>，同时当<code class="du ky kz la lb b">k=8</code>预测的班级标签是<code class="du ky kz la lb b">Y</code>。因此，我们现在可以得出结论，<code class="du ky kz la lb b">k</code>值对模型性能有显著影响。</p><blockquote class="lo lp lq"><p id="b7db" class="ie if lh ig b ih ii ij ik il im in io lr iq ir is ls iu iv iw lt iy iz ja jb ha bi translated">k值小意味着噪声对结果的影响更大，而k值大则计算量大。</p></blockquote><p id="2976" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据科学家通常选择:</p><ol class=""><li id="9fb2" class="kp kq hh ig b ih ii il im ip kr it ks ix kt jb ku kv kw kx bi translated">二进制分类问题中的奇数。</li></ol><p id="ef9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.另一种选择<code class="du ky kz la lb b">k</code>的简单方法是设置<code class="du ky kz la lb b">k=sqrt(n)</code>。其中n =训练数据中数据点的数量。</p><p id="8728" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里有一篇由<a class="lu lv ge" href="https://medium.com/u/1d1372f34524?source=post_page-----b2f836d5ee96--------------------------------" rel="noopener" target="_blank">叶达鑫乐队</a>撰写的关于如何选择最佳k值的精彩文章，如果你想深潜的话:</p><div class="lw lx ez fb ly lz"><a href="https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb" rel="noopener follow" target="_blank"><div class="ma ab dw"><div class="mb ab mc cl cj md"><h2 class="bd hi fi z dy me ea eb mf ed ef hg bi translated">如何找到KNN K的最优值？</h2><div class="mg l"><h3 class="bd b fi z dy me ea eb mf ed ef dx translated">可视化误差率与K的关系图，找出最合适的K值。</h3></div><div class="mh l"><p class="bd b fp z dy me ea eb mf ed ef dx translated">towardsdatascience.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ki lz"/></div></div></a></div></div><div class="ab cl mo mp go mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ha hb hc hd he"><p id="7b72" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">今天到此为止。我将在我的下一篇文章中看到你。</p><p id="cb7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在我的GitHub <a class="ae ko" href="https://github.com/sindhuseelam/knn-implementation" rel="noopener ugc nofollow" target="_blank">这里</a>找到本教程的代码和数据。</p><p id="ca9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参考资料:</p><p id="4ce2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]<a class="ae ko" href="https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb" rel="noopener" target="_blank">https://towards data science . com/how-to-find-the-optimal-value-of-k-in-KNN-35d 936 e 554 EB</a></p><p id="ded6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]<a class="ae ko" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/03/introduction-k-neighbors-algorithm-clustering/</a></p></div><div class="ab cl mo mp go mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ha hb hc hd he"><p id="8a0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我学习并写下我在机器学习、统计和深度学习方面的学习。跟随我进入人工智能世界<a class="ae ko" href="https://twitter.com/SindhuSeelam_" rel="noopener ugc nofollow" target="_blank"> Twitter </a>，<a class="ae ko" href="https://www.linkedin.com/in/sindhuseelam/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae ko" href="https://sindhuseelam.medium.com/" rel="noopener"> Medium </a>。</p></div></div>    
</body>
</html>
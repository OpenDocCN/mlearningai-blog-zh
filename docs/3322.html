<html>
<head>
<title>Google’s New AI Learned To See In The Dark [RawNeRF] in Neural Radiance Field (NeRF)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌的新人工智能在神经辐射场(NeRF)中学会了在黑暗中看东西[RawNeRF]</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/googles-new-ai-learned-to-see-in-the-dark-rawnerf-in-neural-radiance-field-nerf-6803973e579f?source=collection_archive---------6-----------------------#2022-08-18">https://medium.com/mlearning-ai/googles-new-ai-learned-to-see-in-the-dark-rawnerf-in-neural-radiance-field-nerf-6803973e579f?source=collection_archive---------6-----------------------#2022-08-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f46f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我看到了谷歌研究团队在神经辐射场(NeRF)领域发布的一篇新论文，这是一个了不起的进步😱在NeRF领域。让我们看看是什么。</p><h1 id="6a49" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">📕<strong class="ak">什么是神经辐射场(NeRF)？</strong></h1><p id="b817" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi kf translated"><span class="l kg kh ki bm kj kk kl km kn di">一个</span>神经辐射场(NeRF)是一个全连接的神经网络，它可以基于2D图像的部分集合生成复杂3D场景的新视图。它被训练使用渲染损失来再现场景的输入视图。它的工作原理是获取代表一个场景的输入图像，并在它们之间进行插值，以呈现一个完整的场景。NeRF是一种为合成数据生成图像的高效方法。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="79d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以观看上面的视频，以了解神经辐射场(NeRF)论文的概述。也可以参考以下链接了解更多关于NeRF的信息。</p><p id="5221" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔗【https://www.matthewtancik.com/nerf】网址:<a class="ae kv" href="https://www.matthewtancik.com/nerf" rel="noopener ugc nofollow" target="_blank"/></p><p id="3230" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔗<strong class="ig hi">论文:</strong> <em class="kw"> NeRF:将场景表示为用于视图合成的神经辐射场</em>—<a class="ae kv" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2003.08934</a></p><p id="5917" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔗<strong class="ig hi">Github:</strong><a class="ae kv" href="https://github.com/bmild/nerf" rel="noopener ugc nofollow" target="_blank">https://github.com/bmild/nerf</a></p><h1 id="0d82" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">📕谷歌的新论文[RawNeRF]</h1><p id="1f5e" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi kf translated">这是谷歌研究团队对NeRF的改进方法。现在RawNeRF可以清楚地看到黑暗的图像，并可以渲染它们。论文摘要可以在下面看到。</p><p id="e84a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">摘要:</strong></p><blockquote class="kx ky kz"><p id="017e" class="ie if kw ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">神经辐射场(NeRF)是一种从设定的输入图像集合进行高质量新视图合成的技术。像大多数视图合成方法一样，NeRF使用色调映射的低动态范围(LDR)作为输入；这些图像已经由有损相机流水线处理，该流水线平滑细节、剪辑高光并扭曲原始传感器数据的简单噪声分布。我们修改了NeRF，直接在线性原始图像上训练，保留了场景的全动态范围。通过从最终的NeRF渲染原始输出图像，我们可以执行新颖的高动态范围(HDR)视图合成任务。除了改变相机的视角，我们还可以在事后控制焦点、曝光和色调映射。虽然一个单一的原始图像似乎明显比一个后处理的噪声，我们表明，NeRF是非常稳健的零均值分布的原始噪声。当在许多噪声原始输入(25–200)上优化时，NeRF产生的场景表示如此精确，以至于其渲染的新视图优于在相同的宽基线输入图像上运行的专用单幅和多幅图像深度原始降噪器。因此，我们的方法，我们称之为RawNeRF，可以从近乎黑暗中捕捉到的极度嘈杂的图像中重建场景。</p></blockquote><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/3d65115042afceaa5995d0c605a882c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dy0K7LIWFpUw6w4oaGgQmg.jpeg"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx">NeRF pipeline vs RawNeRF pipeline</figcaption></figure><p id="0178" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的视频显示了新RawNeRF文件的概述。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="c41e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔗<strong class="ig hi">网址:</strong>【https://bmild.github.io/rawnerf/ T2】</p><p id="f01d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔗论文: <em class="kw">黑暗中的NeRF:从嘈杂的原始图像合成高动态范围视图</em>s—<a class="ae kv" href="https://arxiv.org/abs/2111.13679" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2111.13679</a></p><p id="687f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔗<strong class="ig hi">Github:</strong><a class="ae kv" href="https://github.com/google-research/multinerf" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/multinerf</a></p><p id="bf98" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以观看下面的视频，很好地解释了两分钟论文youtube频道上的新RawNeRF论文。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure></div><div class="ab cl lo lp go lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ha hb hc hd he"><p id="5af4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">✅👉如何看待NeRF 的<strong class="ig hi">新改进？💭下面评论。</strong></p><p id="f54c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">✅👉如果你喜欢这篇文章，👏对这篇文章鼓掌。</p><p id="529f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">✅👉如果你喜欢我的文章或者需要阅读新的文章，请➕关注我。</p><p id="beb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">✌️What，你下一步需要什么？为…建议标题📃新文章。</p><p id="0dd7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🙏谢谢你看我的文章。</p><div class="lv lw ez fb lx ly"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hi fi z dy md ea eb me ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">medium.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm li ly"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Partially Observed Markov Decision Processes (POMDPs) for Reinforcement Learning (RL)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于强化学习的部分观察马尔可夫决策过程</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/partially-observed-markov-decision-processes-pomdps-for-reinforcement-learning-rl-437b8ae412dd?source=collection_archive---------3-----------------------#2022-09-01">https://medium.com/mlearning-ai/partially-observed-markov-decision-processes-pomdps-for-reinforcement-learning-rl-437b8ae412dd?source=collection_archive---------3-----------------------#2022-09-01</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><div class=""/><figure class="ev ex ij ik il im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es ii"><img src="../Images/2fb4d3703ff58eb0f611d2a084ec0cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qAOxUEMEhCTbO4Bm0i7K1Q.jpeg"/></div></div><figcaption class="it iu et er es iv iw bd b be z dx">Photo by <a class="ae ix" href="https://unsplash.com/@katiemoum?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Katie Moum</a> on <a class="ae ix" href="https://unsplash.com/s/photos/uncertainty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9f93" class="pw-post-body-paragraph iy iz hl ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv he bi translated">在强化学习(RL)的初级模型下，你可能学习了马尔可夫决策过程(MDP)。这个模型只有一个主要问题。实际上，代理很少知道所有时间的全部状态。我们研究人员说，状态对代理人来说是部分可观察的。由于大多数人固有的这种缺陷…</p></div></div>    
</body>
</html>
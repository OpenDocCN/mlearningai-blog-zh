<html>
<head>
<title>Mask-RCNN for Object Detection with Detectron2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用探测器2进行目标探测的掩模-RCNN</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/mask-rcnn-for-object-detection-with-dectectron2-46f62f6b7826?source=collection_archive---------3-----------------------#2022-05-22">https://medium.com/mlearning-ai/mask-rcnn-for-object-detection-with-dectectron2-46f62f6b7826?source=collection_archive---------3-----------------------#2022-05-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e073" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们之前的文章中，我们给出了物体检测背后的直觉。可以在这里 阅读<a class="ae jc" rel="noopener" href="/@pmegne/introduction-to-object-detection-8be574b82d5c"> <strong class="ig hi">进行刷新。</strong></a></p><p id="1a52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当考虑图像中具有多于一个对象的情况时，当前的最新模型已经被证明在识别和定位图像中的多个对象方面非常强大和有力。其中有R-CNN，快速R-CNN，更快R-CNN，屏蔽R-CNN。在这篇文章中，我们将提供一个简单的理解<strong class="ig hi">屏蔽R-CNN </strong>以及如何使用PyTorch中的Detectron2框架来检测对象。</p><p id="b878" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了理解Mask R-CNN，我们将首先回顾R-CNN的变体，从R-CNN架构开始。</p><h2 id="25ed" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated"><strong class="ak"> 1。R-CNN </strong></h2><p id="953b" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">R-CNN代表基于区域的卷积神经网络，由<em class="kd"> Ross Girshick等人</em>【1】开发。它使用选择性搜索[2]从一幅图像中提出一堆盒子(~ 2k)；这些方框被称为区域提案。R-CNN架构由三个主要模块组成(图1)。第一个生成区域建议，第二个使用大CNN从每个候选区域(感兴趣区域/ ROI)中提取固定长度的特征。第三个模块是分类器(线性SVM)，用于将对象分类到建议的类别中。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ke"><img src="../Images/08545d8ab3be8c4b819a44c131b0609c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HfwVmMGhLE_QvsAviUGrow.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx">Figure1: <a class="ae jc" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank">R-CNN architecture</a></figcaption></figure><p id="71f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，在特征提取步骤期间，CNN将独立地通过每个ROI，使得算法非常慢。</p><h2 id="2ea7" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated"><strong class="ak"> 2。快速R-CNN </strong></h2><p id="69ad" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">快速R-CNN通过一次提取特征来修复R-CNN的缺点，而不是对每个图像运行CNN 2k次。在快速R-CNN架构中，CNN处理整个输入图像并生成特征图。此后，应用感兴趣区域池层从特征图中为每个对象提议提取一个小的固定长度特征向量。最后，每个特征向量被输入到一系列完全连接的层中，这些层将输出类别标签和边界框(图2)。回想一下，这里的提议是使用启发式选择性搜索算法完成的。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ku"><img src="../Images/a6899ffeb3703f95f176d6d2915949e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mzmzi4Gxg2kipZWyx-m17A.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx">Figure2: <a class="ae jc" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">Fast R-CNN architecture</a></figcaption></figure><h2 id="92c8" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated"><strong class="ak"> 3。更快的R-CNN </strong></h2><p id="a2c5" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">该架构由两个阶段组成:</p><ul class=""><li id="6e09" class="kv kw hh ig b ih ii il im ip kx it ky ix kz jb la lb lc ld bi translated"><strong class="ig hi">区域提议网络</strong> (RPN):在像以前一样在CNN中传递输入图像之后，RPN是用于生成区域提议的深度网络；</li><li id="3eb0" class="kv kw hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated"><strong class="ig hi">快速R-CNN检测器</strong>:使用建议区域，输出包围盒和类别标签。</li></ul><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es lj"><img src="../Images/6e8fd54308b0ff7b3d2be5ddc30e7a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*VGKCCfLS-JeUfb3O1V0P9g.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx">Figure3: <a class="ae jc" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">Faster R-CNN architecture</a></figcaption></figure><p id="143a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与更快的R-CNN架构相比，快速R-CNN忽略了花费在区域提议上的时间，因此称为更快R-CNN。</p><p id="29c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意，边界框没有给出关于属于对象前景/背景的像素的信息。为了正确地分割对象，可以生成掩模。</p><h2 id="0dca" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated"><strong class="ak"> 4。屏蔽R-CNN </strong></h2><p id="b7c9" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">由何等人【3】创建的Mask R-CNN是更快的R-CNN的扩展。它采用相同的两阶段过程，但是在第二阶段，除了输出类别标签和边界框之外，它还输出对象遮罩。这种额外掩模输出需要提取对象的更精细的空间布局。</p><p id="8257" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，作者认识到，尽管RoI池中的量化不影响标签分类，但它在提取的特征和RoI之间引入了不对准。为了避免这种情况，他们通过使用<strong class="ig hi"> RoI对齐</strong>层(图4)来将提取的特征与输入正确对齐，从而实现了像素到像素的对齐。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es lk"><img src="../Images/a107ab651e8321ec3031f91ff5431789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*ZWxC5c52qdah8cWfXMa4Hw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx">Figure4: <a class="ae jc" href="https://arxiv.org/pdf/1703.06870.pdf" rel="noopener ugc nofollow" target="_blank">Mask R-CNN architecture</a></figcaption></figure><h2 id="e93e" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated"><strong class="ak"> 5。使用detector 2</strong>实现屏蔽R-CNN</h2><p id="cb01" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">Detectron2是由脸书人工智能研究所构建的框架，并在Pytroch中实现。它包括实现一些目标检测模型，即快速R-CNN，快速R-CNN，掩模R-CNN等。</p><p id="af9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们使用<a class="ae jc" href="https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> Mask R-CNN (R-101) </strong> </a>以ResNet为骨干架构。这个主干架构在<a class="ae jc" href="https://arxiv.org/abs/1405.0312" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> COCO数据集</strong> </a>上进行了预训练。</p><h2 id="afa6" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated"><strong class="ak"> 6。结果</strong></h2><p id="bd26" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">我们在此提出一些我们在各种图像(人、动物)上测试的实验结果和评论。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ll"><img src="../Images/c8de313a2a54a10f6d2e7258413318eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b_hOSDvnKLTyT0JzyfpQ2g.png"/></div></div></figure><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lm"><img src="../Images/7b779e80e233fd2cce8d6c0d8ff0b244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3Mlb9J9B5KSW8slKjC5ZQ.png"/></div></div></figure><p id="e4ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是获得的一些观察结果:</p><ul class=""><li id="e4d2" class="kv kw hh ig b ih ii il im ip kx it ky ix kz jb la lb lc ld bi translated">在图5中，该模型能够检测图像中的人以及周围的物体。同样，在图6中，它检测到图像中的人和狗。</li><li id="96ca" class="kv kw hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated">另一方面，在图7中，图像中有一只狗、一只猫和两只兔子，但是模型检测到所有的对象都是猫或狗。这可能是由于兔子与猫和狗有相似的形态，所以在预测兔子时似乎很混乱。</li><li id="abe1" class="kv kw hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated">在图8中，有一群人，模型只成功检测到其中的一些人。原因可能是人群中更远的个体看起来模糊不清，因此模型不能清楚地识别他们。另一方面，在第一线的个体表现出明显的形态特征，因此容易识别。</li></ul><p id="1b0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里找到<a class="ae jc" href="https://github.com/MEGNEOrnela/My_medium_Posts/tree/main/Mask-RCNN%20for%20Object%20Detection%20with%20Dectectron2" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"/></a><strong class="ig hi"/>代码关联的链接。</p><h1 id="2948" class="ln je hh bd jf lo lp lq jj lr ls lt jn lu lv lw jq lx ly lz jt ma mb mc jw md bi translated">结论</h1><p id="6258" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">在这篇文章的最后，我们使用了一个R-CNN遮罩，通过Detectron2框架来检测图像中的对象。该模型执行惊人的预测，但在某些情况下似乎是混乱的。</p><p id="fd8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢你的时间，希望这篇文章是有帮助的。</p><h2 id="58c8" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">参考</h2><p id="8b0c" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">[1]: Girshick，r .，Donahue，j .，Darrell，t .和Malik，j .，用于精确对象检测和语义分割的丰富特征层次。arXiv 2013。<em class="kd"> arXiv预印本arXiv:1311.2524 </em>。</p><p id="908a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]: Uijlings，J.R .，Van De Sande，K.E .，Gevers，t .和Smeulders，A.W .，2013年。物体识别的选择性搜索。<em class="kd">国际计算机视觉杂志</em>，<em class="kd">第104期</em> (2)，第154–171页。</p><p id="9c28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3]: He，k .，Gkioxari，g .，Dollár，p .和Girshick，r .，2017年。屏蔽r-cnn。IEEE计算机视觉国际会议记录(第2961-2969页)。</p><div class="me mf ez fb mg mh"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ko mh"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Use Case: Breast Cancer Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用例:乳腺癌检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/use-case-breast-cancer-detection-aa0f080aff31?source=collection_archive---------4-----------------------#2021-07-19">https://medium.com/mlearning-ai/use-case-breast-cancer-detection-aa0f080aff31?source=collection_archive---------4-----------------------#2021-07-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/ee99f6f7a70bacfb62bb153438383569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HKKOgb3iz6lzY-rPQVk36Q.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://unsplash.com/photos/nJv6xnlpNaA" rel="noopener ugc nofollow" target="_blank">Image Source</a>.</figcaption></figure><p id="d4fc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在世界范围内，乳腺癌是最常见的侵袭性癌症，影响全球七分之一的女性。与肺癌一样，乳腺癌是最常见的诊断癌症，2018年各有209万例。</p><p id="0bd8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">受医疗保健中越来越多使用ML的启发，我们决定在针对恶性和良性显微活检图像训练的<a class="ae it" href="https://www.perceptilabs.com/" rel="noopener ugc nofollow" target="_blank">感知实验室</a>中建立一个图像识别模型。使用这样的ML模型可以帮助医生、乳房x光检查者、研究人员和其他医疗从业者更容易地对乳腺癌进行分类和检测。</p><p id="f76a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">数据集</strong></p><p id="5326" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了训练我们的模型，我们从<a class="ae it" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获取了<a class="ae it" href="https://www.kaggle.com/forderation/breakhis-400x" rel="noopener ugc nofollow" target="_blank"> BreaKHis 400X </a>数据集，其中包含良性和恶性乳腺肿瘤的显微活检图像。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es js"><img src="../Images/0bf5e103e6d9f3f70e0d514029a2c9c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WiuYwfZHheZHvXeF.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jx">Figure 1: Examples of images from the dataset.</em></figcaption></figure><p id="8cae" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">数据集包括400倍光学变焦的1146幅恶性图像和547幅良性图像。每个图像都是700x460像素的. png文件。</p><p id="2933" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们创建了一个. csv文件(<em class="jy"> dataset.csv </em>)来将图像文件映射到它们各自的标签(<em class="jy">良性</em>和<em class="jy">恶性</em>)，以便在使用PerceptiLabs的<a class="ae it" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>加载数据时使用。</p><p id="7fae" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是一个部分的例子。csv文件看起来:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jz"><img src="../Images/cf05b7175c751cf7d6b716877923d827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MCa4lehdmRBGAJo3pBDUeg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jx">Example of the .csv file to load data into PerceptiLabs that maps the image files to their associated labels.</em></figcaption></figure><p id="b875" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">型号总结</strong></p><p id="c996" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的模型由四个<a class="ae it" href="https://docs.perceptilabs.com/perceptilabs/references/components" rel="noopener ugc nofollow" target="_blank">组件</a>组成:</p><p id="5e6d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">组件1: <a class="ae it" href="https://keras.io/api/applications/resnet/" rel="noopener ugc nofollow" target="_blank"> ResNet50 </a>，include_top=false，pretrained=imagenet</p><p id="cb9b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">成分2:密集，激活= <a class="ae it" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，神经元=128</p><p id="6c5b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">成分3:密集，激活= <a class="ae it" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，神经元=64</p><p id="3a9f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">组件4:密集，激活= <a class="ae it" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>，神经元=2</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ka"><img src="../Images/8080b8422946fc0e3daf1c7ea6d1a741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D3xczti9AIbGAbrE.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jx">Figure 2: Topology of the model in PerceptiLabs.</em></figcaption></figure><p id="1ff2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">训练和结果</strong></p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ka"><img src="../Images/dd5cfe7d8ee3be40e7aa318ceebfb9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WLD82-DNT42XVcWX"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jx">Figure 3: PerceptiLabs’ Statistics View during training.</em></figcaption></figure><p id="0ea3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">训练时间刚刚超过256秒，<strong class="iw hi">我们能够实现100%的训练准确率和85.5%的验证准确率。</strong>在下面来自PerceptiLabs的截图中，您可以看到在第一个时期，训练和验证精度如何快速上升，之后验证精度保持相当稳定。训练精度继续攀升，直到大约第三个时期才稳定在100%:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kb"><img src="../Images/74fb46524051ffb84c8bcbad6d7f5fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uD2PUqSBUi2LhArY"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 4: Accuracy Plot.</figcaption></figure><p id="90e6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">垂直应用</strong></p><p id="6648" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">像这样的模型可能有助于增加医疗从业者进行诊断的数量。特别是，它可以帮助丢弃真正的阴性病例，只留下阳性和假阴性病例供医生辨别。</p><p id="7f59" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这样的项目也可以被医学学生或寻求建立下一代基于ML的医疗技术的从业者使用。该模型本身也可以用作<a class="ae it" href="https://blog.perceptilabs.com/when-to-use-transfer-learning-in-image-processing/" rel="noopener ugc nofollow" target="_blank">转移学习</a>的基础，以创建用于在其他类型的医学扫描/成像中检测肿瘤的其他模型。</p><p id="3f70" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">总结</strong></p><p id="d03c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个用例是一个简单的例子，说明了如何使用ML通过图像识别来识别疾病。如果你想建立一个类似这样的深度学习模型，<a class="ae it" href="https://docs.perceptilabs.com/perceptilabs/getting-started/quickstart-guide" rel="noopener ugc nofollow" target="_blank">运行PerceptiLabs </a>并从<a class="ae it" href="https://github.com/PerceptiLabs/breakhis-400x" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中抓取一份我们预处理过的数据集。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Transfer learning and active learning to find images of a small class in an unlabeled dataset.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迁移学习和主动学习在未标记的数据集中寻找小类的图像。</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/transfer-learning-and-active-learning-to-find-images-of-a-small-class-in-an-unlabeled-dataset-ad9b2a16c343?source=collection_archive---------7-----------------------#2022-02-11">https://medium.com/mlearning-ai/transfer-learning-and-active-learning-to-find-images-of-a-small-class-in-an-unlabeled-dataset-ad9b2a16c343?source=collection_archive---------7-----------------------#2022-02-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/608f9a2adb1fb40a41f9a66aec4c4a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qS2Se2EUFm5mU2YsEJCKWQ.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx"><em class="ip">All images are licensed CC-BY, creators are listed in the LICENSE.txt file </em><a class="ae iq" href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz" rel="noopener ugc nofollow" target="_blank"><em class="ip">here</em></a><em class="ip">.</em></figcaption></figure><p id="7dd8" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">实践中可能出现的一个常见的机器学习任务是<strong class="it hi">寻找特定类别的图像，对于这些图像，您没有带标签的数据集</strong>。</p><p id="f3a9" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">当怀疑人工智能系统在特定类型或特征的对象上表现不佳时，可能会发生这种情况。或者当您想要收集特定类型的影像数据集，但标注该数据集非常耗时且耗费资源时。</p><p id="b000" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">示例:</p><ul class=""><li id="a91d" class="jp jq hh it b iu iv iy iz jc jr jg js jk jt jo ju jv jw jx bi translated">在历史数据中找到带有交通锥的场景，以评估自主车辆视觉识别系统在这些特定情况下的性能</li><li id="6b17" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo ju jv jw jx bi translated">收集戴着外科口罩的人的照片数据集，以更新面部识别模型</li></ul><p id="b3f2" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">主要的障碍是完全缺乏带标签的数据集。你知道你有所需类型的图像(有交通锥的场景，戴面具的人的照片，等等。)但是它们很少并且没有被标记。</p><h1 id="f4b0" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">我们想要实现什么？</h1><p id="9826" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">最终目标是开发一个<strong class="it hi">系统，该系统可以过滤图像数据库，并找到包含所需类别</strong>的许多对象的子集。生成的子集可以稍后发送进行手动标记，因此它不必100%准确。然而，在许多情况下，所需类的大小非常小，这意味着随机采样数据库对于标注来说效率极低。例如，如果所需的类别很少，比如说100个图像中有1个，那么要手动标记10.000个图像才能找到所需类型的100个图像。</p><h1 id="c810" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">演示任务描述</h1><blockquote class="lg lh li"><p id="6df0" class="ir is lj it b iu iv iw ix iy iz ja jb lk jd je jf ll jh ji jj lm jl jm jn jo ha bi translated">完整的解决方案请查看我在Github 上的<a class="ae iq" href="https://github.com/NataliaTarasovaNatoshir/NataliaTarasovaNatoshir/blob/main/find_insects_on_flowers.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab笔记本。</a></p></blockquote><p id="40ae" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">让我们看看这种类型的任务的例子，以及它在一个小型公共数据集上的可能解决方案。我们将使用花的照片作为数据库来过滤，并试图找到也包含昆虫的图像——蜜蜂、苍蝇、蜘蛛等。</p><p id="8d97" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">下面是我们正在处理的数据集中的一个典型图像示例:</p><figure class="lo lp lq lr fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/82e195dadf49878889074f45fe0505b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*J6ndOXKYWQvrvrQr3MOyQA.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx"><em class="ip">All images are licensed CC-BY, creators are listed in the LICENSE.txt file </em><a class="ae iq" href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz" rel="noopener ugc nofollow" target="_blank"><em class="ip">here</em></a><em class="ip">.</em></figcaption></figure><p id="3573" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">这是我们试图寻找的图像的一个例子:</p><figure class="lo lp lq lr fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/caa6e70e07abadde382c9c7fcd9070a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*-2kXStCqIEhnPIRAw04fww.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx"><em class="ip">All images are licensed CC-BY, creators are listed in the LICENSE.txt file </em><a class="ae iq" href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz" rel="noopener ugc nofollow" target="_blank"><em class="ip">here</em></a><em class="ip">.</em></figcaption></figure><p id="73e1" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">下面是主要步骤的一般描述。</p><h1 id="7346" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据标记</h1><p id="9277" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">为了训练一个图像分类模型，我们仍然需要<em class="lj">一些</em>标记的图像。手动标记少量是可能的。在我们的示例中，我们可以直接从Colab笔记本中完成:</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="908a" class="lx ke hh lt b fi ly lz l ma mb"><strong class="lt hi">def</strong> label_images(images_dir, max_images_num<strong class="lt hi">=None</strong>):<br/>  file_names <strong class="lt hi">=</strong> os<strong class="lt hi">.</strong>listdir(images_dir)<br/>  i <strong class="lt hi">=</strong> 0<br/>  <strong class="lt hi">if</strong> max_images_num <strong class="lt hi">==</strong> <strong class="lt hi">None</strong>:<br/>    max_num <strong class="lt hi">=</strong> len(file_names)<br/>  <strong class="lt hi">else</strong>:<br/>    max_num <strong class="lt hi">=</strong> max_images_num<br/>  labels <strong class="lt hi">=</strong> []<br/><br/>  print('Starting labeling from {}th image\n'<strong class="lt hi">.</strong>format(i))<br/>  <strong class="lt hi">while</strong> i <strong class="lt hi">&lt;</strong> max_num:<br/>    image_id <strong class="lt hi">=</strong> file_names[i]<br/>    im <strong class="lt hi">=</strong> PIL<strong class="lt hi">.</strong>Image<strong class="lt hi">.</strong>open(os<strong class="lt hi">.</strong>path<strong class="lt hi">.</strong>join(images_dir, image_id))<br/>    print("Image {} out of {}\n"<strong class="lt hi">.</strong>format(i<strong class="lt hi">+</strong>1, max_num))<br/>    print("Label the image:")<br/>    print("0 - No insects in the picture\n1 - Insects in the picture (bees, flies, spiders, ants, etc.)")<br/>    grid <strong class="lt hi">=</strong> widgets<strong class="lt hi">.</strong>Grid(2, 2, header_row<strong class="lt hi">=True</strong>, header_column<strong class="lt hi">=True</strong>)<br/>    <strong class="lt hi">with</strong> grid<strong class="lt hi">.</strong>output_to(1, 1):<br/>      display(im)<br/>    <strong class="lt hi">with</strong> grid<strong class="lt hi">.</strong>output_to(0, 0):<br/>      userinput <strong class="lt hi">=</strong> input()<br/>    clear_output(wait<strong class="lt hi">=True</strong>)<br/>    <br/>    i <strong class="lt hi">+=</strong> 1<br/>    <strong class="lt hi">if</strong> userinput <strong class="lt hi">not</strong> <strong class="lt hi">in</strong> ('0', '1'):<br/>      print('Incorrect input. Please try again')<br/>      time<strong class="lt hi">.</strong>sleep(3)<br/>      clear_output()<br/>      i <strong class="lt hi">-=</strong> 1<br/>    <strong class="lt hi">else</strong>:<br/>      <strong class="lt hi">if</strong> userinput <strong class="lt hi">==</strong> '1': labels<strong class="lt hi">.</strong>append(image_id)<br/><br/>  <strong class="lt hi">return</strong> list(set(labels)), i</span></pre><h1 id="9573" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">设置工作管道</h1><p id="6bb3" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">在开发任何模型之前，最好<strong class="it hi">建立一个测试的工作管道。深度学习解决方案通常很难调试，因此首先调试管道的其他元素至关重要。</strong></p><p id="a7eb" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">在这里，我们对模型的测试过程进行了形式化，该模型通过数据库进行过滤，并产生包含所需稀有类的许多图像的对象子集。</p><p id="ee9e" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">在这种情况下，测试过程如下:</p><ol class=""><li id="5220" class="jp jq hh it b iu iv iy iz jc jr jg js jk jt jo mc jv jw jx bi translated"><strong class="it hi">将模型应用于测试数据集。</strong>这是我们原始花卉数据集中的随机样本。它包含了612张有昆虫和没有昆虫的未标记图像。该文件夹中没有图像用于模型训练或超参数调整。</li><li id="5133" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated"><strong class="it hi">选择模型预测的“图像中的昆虫”类概率</strong>最高的前50幅图像。这些是我们的模型认为可能有昆虫的图像。</li><li id="8e2d" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated"><strong class="it hi">检查top-50中有多少图片实际上含有昆虫</strong>。为此，我们手动标记这些图像。这样，我们就可以了解我们的模型可以多有效地找到所需稀有类的对象。我们已经有了一个基准:当我们随机采样图像时，大约10%的图像包含昆虫。</li></ol><h1 id="6473" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">迁移学习</h1><p id="c390" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">我们当然没有足够的数据来从头训练一个定制的CNN。相反，我们可以使用迁移学习:</p><ol class=""><li id="614e" class="jp jq hh it b iu iv iy iz jc jr jg js jk jt jo mc jv jw jx bi translated">以CNN为例，它已经在ImageNet或COCO等大型图像数据集上进行了训练</li><li id="7fb9" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated">去掉它的“头”，换上一个适合我们分类问题的图层</li><li id="0f06" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated">在我们现有的小数据集上训练这个额外的层</li></ol><p id="1efb" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated"><em class="lj">注</em>:有可能找到一个预先训练好的CNN，它已经被训练好分辨昆虫了。我们在这里不使用这种方法，因为当最小的类不那么简单时，这个特定的任务被用作实际问题的例子。</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="4876" class="lx ke hh lt b fi ly lz l ma mb"><strong class="lt hi">import</strong> tensorflow_hub <strong class="lt hi">as</strong> hub<br/><br/><em class="lj"># take a "headless" CNN from tensorflow_hub</em><br/>mobilenet_v2 <strong class="lt hi">=</strong> "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"<br/><br/>feature_extractor_model <strong class="lt hi">=</strong> mobilenet_v2</span><span id="0d03" class="lx ke hh lt b fi md lz l ma mb"><em class="lj"># convert this model into an untrainable layer</em><br/>feature_extractor_layer <strong class="lt hi">=</strong> hub<strong class="lt hi">.</strong>KerasLayer(<br/>    feature_extractor_model,<br/>    input_shape<strong class="lt hi">=</strong>IMAGE_SHAPE<strong class="lt hi">+</strong>(3,),<br/>    trainable<strong class="lt hi">=False</strong>)</span><span id="66ce" class="lx ke hh lt b fi md lz l ma mb"><em class="lj"># add a layer suitable for binary classification and layers for image preprocessing - resizing and rescaling</em></span><span id="899a" class="lx ke hh lt b fi md lz l ma mb">model <strong class="lt hi">=</strong> tf<strong class="lt hi">.</strong>keras<strong class="lt hi">.</strong>Sequential([                          tf<strong class="lt hi">.</strong>keras<strong class="lt hi">.</strong>layers<strong class="lt hi">.</strong>Resizing(height<strong class="lt hi">=</strong>IMAGE_SHAPE[0], width<strong class="lt hi">=</strong>IMAGE_SHAPE[1]), <br/>tf<strong class="lt hi">.</strong>keras<strong class="lt hi">.</strong>layers<strong class="lt hi">.</strong>Rescaling(1.<strong class="lt hi">/</strong>255),<br/>feature_extractor_layer,<br/>tf<strong class="lt hi">.</strong>keras<strong class="lt hi">.</strong>layers<strong class="lt hi">.</strong>Dense(1)])</span><span id="d482" class="lx ke hh lt b fi md lz l ma mb"><em class="lj"># define optimization, loss and quality metrics for the model</em><br/>model<strong class="lt hi">.</strong>compile(loss<strong class="lt hi">=</strong>tf<strong class="lt hi">.</strong>keras<strong class="lt hi">.</strong>losses<strong class="lt hi">.</strong>BinaryCrossentropy(from_logits<strong class="lt hi">=True</strong>), optimizer<strong class="lt hi">=</strong>'adam',metrics<strong class="lt hi">=</strong>tf<strong class="lt hi">.</strong>keras<strong class="lt hi">.</strong>metrics<strong class="lt hi">.</strong>BinaryAccuracy())</span><span id="9abb" class="lx ke hh lt b fi md lz l ma mb"><em class="lj"># train the model on our dataset</em><br/>NUM_EPOCHS <strong class="lt hi">=</strong> 30<br/>history <strong class="lt hi">=</strong> model<strong class="lt hi">.</strong>fit(train_ds, epochs<strong class="lt hi">=</strong>NUM_EPOCHS)</span></pre><p id="d345" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">这种模型在寻找所需小类的对象时比随机抽样效率高得多！</p><h1 id="a15d" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">主动学习</h1><p id="8563" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">如何提高模型性能？我们的主要问题是我们的训练数据集太小——最小类的大约30个对象。它的小尺寸也限制了我们使用单独的数据集进行验证来测量过度拟合和调整超参数(学习率、提前停止、辍学率等)的能力。)这意味着现在提高模型性能的最有效方法是收集更多的数据。</p><p id="1329" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">获取模式数据的唯一方法是手动标记附加图像。有没有一种有效的方法可以用最少的附加标签来提高模型质量？我们可以采用<strong class="it hi">主动学习</strong>的方法。让我们标记来自未标记数据集的图像，其中我们的模型是<em class="lj">不确定的</em>。这是一种有效应用标记工作的方法。</p><p id="9234" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">建议的解决方案是对未标记的数据使用我们的模型:</p><ol class=""><li id="ecec" class="jp jq hh it b iu iv iy iz jc jr jg js jk jt jo mc jv jw jx bi translated"><strong class="it hi">将模型应用于未标记的数据集。</strong>这是我们原始花卉数据集中的随机样本。它包含了619张带有和不带有昆虫的未标记图像。这些图像以前没有用于模型训练或测试。</li><li id="104f" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated"><strong class="it hi">选择不确定度最高的前100张图像</strong>。如果p是第一类的预测概率，那么它的不确定性度量是“(p-1)*log(1-p)-p*log(p)”</li><li id="e944" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated"><strong class="it hi">手动标记前100个不确定性度量组</strong>中的所有图像，并将这些图像添加到训练数据集中。</li><li id="5734" class="jp jq hh it b iu jy iy jz jc ka jg kb jk kc jo mc jv jw jx bi translated">在这个新的更大的训练数据集上训练相同的模型</li></ol><p id="1cc7" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">这个更新的模型在查找稀有类的对象时比以前的模型更有效！</p><p id="803e" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">可以重复“将模型应用于未标记的数据集并手动标记具有最高不确定性的前100个图像”的过程。不幸的是，每次迭代将产生越来越少的具有高不确定性度量的对象。</p><h1 id="9290" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><p id="55f4" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">我们的目标是开发一种有效扫描数据库并找到稀有类对象的方法。</p><p id="45e7" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">使用迁移学习、主动学习方法和适量的手动标记，我们成功开发了一个模型，其执行效率大约是随机采样的4-7倍。</p><h1 id="6150" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">警告和建议</h1><p id="0fb1" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">对于此解决方案，有几个注意事项和建议:</p><h2 id="4a80" class="lx ke hh bd kf me mf mg kj mh mi mj kn jc mk ml kr jg mm mn kv jk mo mp kz mq bi translated">数据偏差</h2><p id="4565" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">用于手动标注的初始随机数据样本可能会对模型行为产生巨大影响。不幸的是，它可能是有偏见的，或者不包含具有某些特定特征的稀有类的图像。例如，假设在这个初始样本中没有蝴蝶的图像。很可能将在这种有偏差的数据上训练的模型应用于未标记的数据集也不会提供任何带有蝴蝶的图像(这种图像将具有低概率分数和低不确定性度量)。所以这种偏见会持续下去。它可以使模型对期望类别的图像类别“视而不见”。使用这种有偏见的方式来获得用于其他模型训练的数据也可能损害这些模型的可生成性。</p><p id="9f05" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated">我们必须意识到这个问题，并采取一些预防措施。例如，我们可以定期添加随机抽样和标记的步骤，以确保我们提供有代表性的数据。也可以“随机”发送图像进行标记，发送图像进行标记的机会与其不确定性度量成比例。这样，即使我们的模型感到有信心的图像也有机会被标记并用于偏差校正。</p><h2 id="c376" class="lx ke hh bd kf me mf mg kj mh mi mj kn jc mk ml kr jg mm mn kv jk mo mp kz mq bi translated">模型训练效率低下</h2><p id="8647" class="pw-post-body-paragraph ir is hh it b iu lb iw ix iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo ha bi translated">如果我们的模型对他们的类别没有“信心”,我们会发送图像进行标记。不幸的是，随着每次迭代，我们得到的具有高不确定性度量的图像越来越少，因此手动标记过程和模型再训练也变得越来越低效。</p><div class="mr ms ez fb mt mu"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hi fi z dy mz ea eb na ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">medium.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni ij mu"/></div></div></a></div><p id="5b7b" class="pw-post-body-paragraph ir is hh it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ha bi translated"><a class="ae iq" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb">成为ML作家</a></p></div></div>    
</body>
</html>
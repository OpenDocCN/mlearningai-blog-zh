<html>
<head>
<title>Looking for uniformity in chickens</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">寻找鸡的一致性</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/looking-for-uniformity-in-chickens-763ca9c18a1e?source=collection_archive---------6-----------------------#2022-01-19">https://medium.com/mlearning-ai/looking-for-uniformity-in-chickens-763ca9c18a1e?source=collection_archive---------6-----------------------#2022-01-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="865c" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">通过使用混合模型和R</h2></div><p id="5d3d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi js translated"><span class="l jt ju jv bm jw jx jy jz ka di"> W </span>母鸡建模动物大部分时间感兴趣的结果是生长、采食量和饲料转化率。然而，从商业上来说，一批或一群的一致性同样令人感兴趣，如果不是更多的话。这也是很难实现的，因为动物在成长过程中有偏离的趋势。就像人类一样。</p><p id="adaf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，我现在向你们展示的不是生长模型，而是我如何试图在一个商业数据集上模拟鸡的一致性。因此，我不能分享数据集，但我会尽可能展示数据的结构。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="5c44" class="kk kl hh kg b fi km kn l ko kp">rm(list = ls())</span><span id="b184" class="kk kl hh kg b fi kq kn l ko kp">#### LIBRARIES ####<br/>library(lme4)<br/>library(ggplot2)<br/>library(rms)<br/>library(plyr)<br/>library(reshape2)<br/>library(boot)<br/>library(sjPlot)<br/>library(sjstats)<br/>library(sjmisc)<br/>library(interval)<br/>library(AICcmodavg)<br/>library(parallel) <br/>library(gridExtra)<br/>library(coefplot) <br/>library(coda)      <br/>library(aods3)     <br/>library(plotMCMC) <br/>library(bbmle)     <br/>library(nlme)<br/>library(merTools)<br/>library(RLRsim) <br/>library(pbkrtest)<br/>library(multcomp)<br/>library(lsmeans)<br/>library(multcompView)<br/>library(lattice)<br/>library(splines)<br/>library(lmtest)<br/>library(mgcv)<br/>library(gamm4)<br/>library(car)<br/>library(grid)<br/>library(varComp)</span><span id="e521" class="kk kl hh kg b fi kq kn l ko kp">### DATA MANAGEMENT ####<br/>library(readxl)<br/>Uniformity_P07700_03_NPB70_ &lt;- read_excel("Uniformity P07700-03 NPB70 .xlsx")<br/>Uniformity&lt;-Uniformity_P07700_03_NPB70_<br/>rm(Uniformity_P07700_03_NPB70_)<br/>str(Uniformity)<br/>attach(Uniformity)<br/>Uniformity$TT&lt;-as.factor(Uniformity$TT)<br/>Uniformity$Block&lt;-as.factor(Uniformity$Block)<br/>Uniformity$Room&lt;-as.factor(Uniformity$Room)<br/>Uniformity$BOX&lt;-as.factor(Uniformity$BOX)<br/>length(Uniformity$n)<br/>length(Uniformity$Label)<br/>length(Uniformity$day)<br/>colnames(Uniformity)[7]&lt;-"Time"<br/>colnames(Uniformity)[8]&lt;-"BW"<br/>Uniformity$BW&lt;-as.numeric(gsub(",","",Uniformity$BW ,<br/>                               fixed=TRUE))<br/>Uniformity$BWkg&lt;-Uniformity$BW/1000<br/>head(Uniformity)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es kr"><img src="../Images/42a6f4bcacb80d915df5ab7c7785f70f.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*pDKN1fnnLXGhYxOSS0cCHQ.png"/></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="25b1" class="kk kl hh kg b fi km kn l ko kp">Uniformity$number&lt;-rep(1:7,each=7, length.out=2240)</span><span id="0d54" class="kk kl hh kg b fi kq kn l ko kp">TREATmelt&lt;-ddply(Uniformity, c("Time", "TT"), summarise,<br/>                 N = sum(!is.na(BWkg)),<br/>                 Mis = sum(is.na(BWkg)),<br/>                 Mean = round(mean(BWkg, na.rm=T),3),<br/>                 Median = round(median(BWkg, na.rm=T),3),<br/>                 SD = round(sd(BWkg, na.rm=T),3),<br/>                 SE = round(sd(BWkg, na.rm=T) / sqrt(N),5),<br/>                 LCI = round(Mean - (2*SE),3), <br/>                 HCI = round(Mean + (2*SE),3))</span><span id="61b7" class="kk kl hh kg b fi kq kn l ko kp">UniformityCOMPL&lt;-Uniformity[!is.na(Uniformity$BWkg),]<br/>TREATmelt2&lt;-ddply(UniformityCOMPL, c("Time", "TT"), summarise,<br/>                 N = sum(!is.na(BWkg)),<br/>                 Mis = sum(is.na(BWkg)),<br/>                 Mean = round(mean(BWkg, na.rm=T),3),<br/>                 Median = round(median(BWkg, na.rm=T),3),<br/>                 SD = round(sd(BWkg, na.rm=T),3),<br/>                 SE = round(sd(BWkg, na.rm=T) / sqrt(N),5),<br/>                 LCI = round(Mean - (2*SE),3), <br/>                 HCI = round(Mean + (2*SE),3),<br/>                 CV=100*(SD/Mean))</span><span id="fd42" class="kk kl hh kg b fi kq kn l ko kp">TREATmelt_BW&lt;-ddply(Uniformity, c("Time", "TT"), summarise,<br/>                 N = sum(!is.na(BW)),<br/>                 Mis = sum(is.na(BW)),<br/>                 Mean = round(mean(BW, na.rm=T),3),<br/>                 Median = round(median(BW, na.rm=T),3),<br/>                 SD = round(sd(BW, na.rm=T),3),<br/>                 SE = round(sd(BW, na.rm=T) / sqrt(N),5),<br/>                 LCI = round(Mean - (2*SE),3), <br/>                 HCI = round(Mean + (2*SE),3))<br/>BLOCKmelt&lt;-ddply(Uniformity, c("Time", "Block"), summarise,<br/>                 N = sum(!is.na(BWkg)),<br/>                 Mis = sum(is.na(BWkg)),<br/>                 Mean = round(mean(BWkg, na.rm=T),3),<br/>                 Median = round(median(BWkg, na.rm=T),3),<br/>                 SD = round(sd(BWkg, na.rm=T),3),<br/>                 SE = round(sd(BWkg, na.rm=T) / sqrt(N),5),<br/>                 LCI = round(Mean - (2*SE),3), <br/>                 HCI = round(Mean + (2*SE),3))<br/>BOXmelt&lt;-ddply(Uniformity, c("Time", "BOX"), summarise,<br/>                 N = sum(!is.na(BWkg)),<br/>                 Mis = sum(is.na(BWkg)),<br/>                 Mean = round(mean(BWkg, na.rm=T),3),<br/>                 Median = round(median(BWkg, na.rm=T),3),<br/>                 SD = round(sd(BWkg, na.rm=T),3),<br/>                 SE = round(sd(BWkg, na.rm=T) / sqrt(N),5),<br/>                 LCI = round(Mean - (2*SE),3), <br/>                 HCI = round(Mean + (2*SE),3))</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es kv"><img src="../Images/add12b2ad5c66fef5bdd801da72e8f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*gFm2b-4WYLEpsoi97yhxUg.png"/></div></figure><p id="b612" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们更深入地看看缺失的数据。上面的图并没有暗示大量的遗漏，但是它们会影响均匀度的估计。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="85d6" class="kk kl hh kg b fi km kn l ko kp">Z&lt;-!is.na(Uniformity_wide[,7:13])<br/>Uniformity_wide[ ,"nr_asses"]&lt;- as.numeric(rowSums(Z))</span><span id="6d43" class="kk kl hh kg b fi kq kn l ko kp">last.observed &lt;- function (x, time = NULL) {<br/>  if (is.null (time)) {<br/>    time &lt;- 1:length (x)}<br/>  dropout &lt;- sapply (1:length(x),<br/>                     function (i, y) all(y[i:length(y)]), is.na (x))<br/>  ifelse (any (dropout), time[which(dropout)[1]-1], time[length(x)])}<br/>otime&lt;-c(0,02,04,07,14,21,37)<br/>Uniformity_wide$last.observed &lt;- apply(Uniformity_wide[,7:13], 1, last.observed)<br/>table(Uniformity_wide$last.observed)<br/>Uniformity_wide$miss&lt;-ifelse(Uniformity_wide$last.observed==7&amp;Uniformity_wide$nr_asses==7, "NoMissing",                             ifelse(Uniformity_wide$last.observed&lt;7&amp;Uniformity_wide$nr_asses&lt;7,"Mono", "NonMono"))<br/>Uniformity_wide &lt;- dcast(Uniformity, Room+BOX+TT+Block+Label+n ~ Time, value.var="BW")<br/>Uniformity&lt;-merge(Uniformity, Uniformity_wide[,6])<br/>colnames(Uniformity)[11]&lt;-"Missing"<br/>Uniformity$Missing&lt;-as.factor(Uniformity$Missing)</span><span id="82f5" class="kk kl hh kg b fi kq kn l ko kp">MISSINGmelt&lt;-ddply(Uniformity, c("Time", "Missing"), summarise,<br/>               N = sum(!is.na(BWkg)),<br/>               Mis = sum(is.na(BWkg)),<br/>               Mean = round(mean(BWkg, na.rm=T),3),<br/>               Median = round(median(BWkg, na.rm=T),3),<br/>               SD = round(sd(BWkg, na.rm=T),3),<br/>               SE = round(sd(BWkg, na.rm=T) / sqrt(N),5),<br/>               LCI = round(Mean - (2*SE),3), <br/>               HCI = round(Mean + (2*SE),3))</span><span id="0b4c" class="kk kl hh kg b fi kq kn l ko kp">Uniformity$number&lt;-NULL</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es kw"><img src="../Images/7a0bdb9161c19f583fea15c614cff2d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*UxKYTvdTPHtpG6vEY1cLqw.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx">Not a lot of missing.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="fd84" class="kk kl hh kg b fi km kn l ko kp">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 3, by = 1))<br/>ggplot(UniformityCOMPL, aes(x=Time, y=BWkg, colour=TT, group=UniformityCOMPL$n))+<br/>  myx+<br/>  myy+<br/>  geom_line(colour="grey80")+<br/>  stat_summary(aes(group=TT),fun.y="mean", geom="line",lwd=1.5)</span><span id="fd72" class="kk kl hh kg b fi kq kn l ko kp">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>myy&lt;-scale_y_continuous(breaks = seq(35, 3500, by = 25))<br/>ggplot(subset(TREATmelt_BW,Time%in%c(0,2,4,7)), aes(x=Time, y=Mean, colour=TT))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  # geom_ribbon(aes(ymin=LCI, ymax=HCI, fill=TT), alpha=0.1)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "Growth over Time between Treatments", y="BW (gram)", x="Time")</span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks lc ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/09f8bfd68f8b378c6d940f473c23d4e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*gA08KF_lXnJH3Nl8gDluiQ.png"/></div></figure><figure class="lb ks lc ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/8e49ee6fb817f7e88ceae356f7962bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*WMmFVmQGajCY9hUCoO-Oqg.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx ll di lm ln">Graphs showing how the chickens diverge in their bodyweight (BW) as they grow. This is a real problem to uniformity but also to be expected. Variance is often exponetntially related to growth. Next to that, a plot showing the mean treatment values in the beginning.</figcaption></figure></div><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="ea35" class="kk kl hh kg b fi km kn l ko kp">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>myy&lt;-scale_y_continuous(breaks = seq(35, 3500, by = 25))<br/>ggplot(UniformityCOMPL, aes(x=Time, y=BW, colour=TT))+<br/>  geom_boxplot()+<br/>  facet_wrap(~Time, ncol=3, scales = "free")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lo"><img src="../Images/a6f5e849e59234453170311f307defc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MuSXOeGpyGQvSWrpVMDIrQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Treatment comparisons and uniformity across time-points.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="02de" class="kk kl hh kg b fi km kn l ko kp">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 3, by = 0.1))<br/>ggplot(BLOCKmelt, aes(x=Time, y=Mean, colour=Block))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=LCI, ymax=HCI, fill=Block), alpha=0.1)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lo"><img src="../Images/40534c32db0c23479ec3fa458ed88034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vqrvhuW8847JmJclKMkoEg.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Across blocks</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="de08" class="kk kl hh kg b fi km kn l ko kp">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 3, by = 0.1))<br/>ggplot(BOXmelt, aes(x=Time, y=Mean, colour=BOX))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=LCI, ymax=HCI, fill=BOX), alpha=0.1)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lp"><img src="../Images/9ec84b72a678c82acd023b8bc385cb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vHt2_Fc1Jd_a6R2Qw3-GVA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Across pens or here BOX</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="e203" class="kk kl hh kg b fi km kn l ko kp">theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>myy&lt;-scale_y_continuous(breaks = seq(0, 3, by = 0.1))<br/>ggplot(MISSINGmelt, aes(x=Time, y=Mean, colour=Missing))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1) + <br/>  theme(legend.position="none")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lq"><img src="../Images/839802e214a1495354ad8b29cd5f909f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ycDqDXa6OMIC8KK2KIaBMQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">And the mean number of missing across time. Nothing to really worry about.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="7051" class="kk kl hh kg b fi km kn l ko kp">xyplot(BWkg~Time|n, data=Uniformity,<br/>       panel = function(x, y, ...) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         panel.loess(x, y, lty = 2, col="red")<br/>         panel.abline(0, 0)<br/>       } )</span><span id="5309" class="kk kl hh kg b fi kq kn l ko kp">xyplot(BWkg~Time|TT, data=Uniformity,<br/>       panel = function(x, y, ...) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         panel.loess(x, y, lty = 2, col="red")<br/>         panel.abline(0, 0)<br/>       } )</span><span id="2efb" class="kk kl hh kg b fi kq kn l ko kp">xyplot(BWkg~Time|BOX, data=Uniformity,<br/>       panel = function(x, y, ...) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         panel.loess(x, y, lty = 2, col="red")<br/>         panel.abline(0, 0)<br/>       } )</span><span id="b8a9" class="kk kl hh kg b fi kq kn l ko kp">xyplot(BWkg~Time|Missing, data=Uniformity,<br/>       panel = function(x, y, ...) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         panel.loess(x, y, lty = 2, col="red")<br/>         panel.abline(0, 0)<br/>       } )</span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks lr ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/95fb7feed0690546ae4344a563015daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*Gt4k2gRWlF3iWrjwxd8fSw.png"/></div></figure><figure class="lb ks ls ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/483a96449ac4e5e4eb02e8ed12ae7bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*27r-2zFpyI4AiuSFbrw0Lw.png"/></div></figure></div><div class="ab cb"><figure class="lb ks ls ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/08ad0f678591052b9a481110e9c77709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*aWDJc0eiS7RwUCkE9bAsow.png"/></div></figure><figure class="lb ks lr ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/c5a5fc73cd048132fad12df17b3e1272.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*dYkzq2SxdHtpXn4-l_sKww.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx lt di lu ln">Plots looking for differences in animals, blocks, boxes, treatments.</figcaption></figure></div><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="b9ee" class="kk kl hh kg b fi km kn l ko kp">histogram(~UniformityCOMPL$BW|UniformityCOMPL$Time, breaks=20,scales=list(relation="free")) # data looks mostly normal</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lv"><img src="../Images/c6dd0be65b71d07b1704ebe14a306ff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2ioyP1IV-yRg5TpKHjWRA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Uniformity check of BW per time. The scales are different, so the variances does increase as weight increases, but the structure is the same. No hint at a <a class="ae lw" href="https://blog.devgenius.io/mixture-component-zero-inflated-and-hurdle-models-44c5e6fe5d7f" rel="noopener ugc nofollow" target="_blank">mixed distribution.</a></figcaption></figure><p id="0767" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">处理随时间推移而增加的方差或一般意义上的方差的最佳方法之一是应用转换。这里，我使用Box-Cox。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="1b5c" class="kk kl hh kg b fi km kn l ko kp">fit.lm&lt;-lm(BWkg~ns(Time,3)*TT+Room, data=UniformityCOMPL)<br/>bc1&lt;-boxcox(fit.lm,lambda=seq(-2,2,by=0.1),plotit=T)<br/>which.max(bc1$y)<br/>LV&lt;-bc1[1]$x[as.numeric(which.max(bc1$y))]<br/>LV # -0.1818182 -&gt; better log transform<br/>p1&lt;-powerTransform(BWkg~ns(Time,3)*TT+Room, data=UniformityCOMPL)<br/>summary(p1)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lv"><img src="../Images/73ac2f164e98d5424a0c44eda903db3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-seIA-4l-asD0SwEMeA6kA.png"/></div></div></figure><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es lx"><img src="../Images/2f861707dd0a71478e5a0e846bca8c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*mycFlbghy6VENhjW0aAF0g.png"/></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="5d90" class="kk kl hh kg b fi km kn l ko kp">symbox(~BW,data=UniformityCOMPL) </span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lv"><img src="../Images/34a29e4a0c834cbd6bb20da6f9ade9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q17v4vpvQFBAxZ7W62ezwg.png"/></div></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="92f2" class="kk kl hh kg b fi km kn l ko kp">histogram(~sqrt(UniformityCOMPL$BW)|UniformityCOMPL$Time, breaks=20,scales=list(relation="free")) <br/>histogram(~log(UniformityCOMPL$BW)|UniformityCOMPL$Time, breaks=20,scales=list(relation="free"))</span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks lc ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/2adf7a4af110aebb1853b6c6a4471085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*hzlDbcgs4a8L-QWIvrHW8A.png"/></div></figure><figure class="lb ks lc ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/84c5935af7f8ce3a669d1a3f787d699e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*vTwhM-v4yDwbDnFSSiymgA.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx ll di lm ln">Log transformation seems best, which makes sense. To counteract an exponential you can best employ a log. Multiplication will become addition, and division becomes subtraction.</figcaption></figure></div><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="81cf" class="kk kl hh kg b fi km kn l ko kp">bwplot(~sqrt(UniformityCOMPL$BW)|UniformityCOMPL$Time, breaks=20,scales=list(relation="free")) <br/>bwplot(UniformityCOMPL$Time~log(UniformityCOMPL$BW)) <br/>bwplot(UniformityCOMPL$Time~sqrt(UniformityCOMPL$BW))</span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks ly ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/666ebb43525e94919bfb74cd0a9f6d7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*JZotwrAHgJWiggFbo257Yw.png"/></div></figure><figure class="lb ks ly ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/97790f621fd66443e899868dc922a140.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*BVy8PqSefrGg4Ni5JGaL-g.png"/></div></figure><figure class="lb ks ly ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/755f7297c4c5aa1c24d65cd1727c3b6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*zNlTZCRjStUfm2Nv8lintw.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx lz di ma ln">The middle graph, the log transform, shows almost equal variance on the raw data.</figcaption></figure></div><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="05d0" class="kk kl hh kg b fi km kn l ko kp">fit.lm2&lt;-lm(BWkg~ns(Time,3)*TT+Room+as.factor(n), data=UniformityCOMPL) <br/>bc2&lt;-boxcox(fit.lm2,lambda=seq(-2,2,by=0.1),plotit=T)<br/>bc2[1]$x[as.numeric(which.max(bc2$y))] # -0.1414141</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lv"><img src="../Images/789afaf46332aeda631e10e8d72b5ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dw3ELn2miFkpW_eaA4gkzA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Also in this model the log transform is best.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="c54e" class="kk kl hh kg b fi km kn l ko kp">fitbc&lt;-lm((BWkg^LV-1/LV)~ns(Time,2)*TT+Room, data=UniformityCOMPL) # TRANSFORMATION SEEMS TO DEAL WITH IT ALL <br/>fitlog&lt;-lm(log(BWkg)~ns(Time,3)*TT+Room, data=UniformityCOMPL)<br/>fitsqrt&lt;-lm(sqrt(BWkg)~ns(Time,3)*TT+Room, data=UniformityCOMPL)<br/>fitreciproc&lt;-lm(BWkg/1~ns(Time,3)*TT+Room, data=UniformityCOMPL)</span><span id="47e1" class="kk kl hh kg b fi kq kn l ko kp">par(mfrow=c(3,4))<br/>plot(fit.lm, which=2, main="BW")<br/>plot(fit.lm, which=1, main="BW")<br/>plot(fitbc, which=2, main="BW_bc") <br/>plot(fitbc, which=1, main="BW_bc") <br/>plot(fitlog, which=2, main="BW_log") <br/>plot(fitlog, which=1, main="BW_log") <br/>plot(fitsqrt, which=2, main="BW_sqrt")<br/>plot(fitsqrt, which=1, main="BW_sqrt")<br/>plot(fitreciproc, which=2, main="BW_sqrt")<br/>plot(fitreciproc, which=1, main="BW_sqrt")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mb"><img src="../Images/78ad6462220b8b900b8471a802671cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CvmabieDRMsEfcNz9iBLgA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">This time, however, the exact Box-Cox seems to be the best. So lambda is not zero, but -0.1414141. This does make a difference it seems.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="20d3" class="kk kl hh kg b fi km kn l ko kp">## BACKTRANSFORMATION when Lambda is negative<br/># when lambda = -0.50 or reciprocal square root<br/>par(mfrow=c(2,1))<br/>attach(UniformityCOMPL)<br/>y&lt;-1/(BWkg^(0.5)) # when lambda = -0.50 or reciprocal square root<br/>x=1/y^(1/0.5) # back transformation involves exponential which is the opposite of square root <br/>plot(x-BWkg) ## gives the same results, difference is practically zero <br/>## When Lambda is -0.1<br/>UniformityCOMPL$BWkg_bc&lt;-1/(BWkg^(0.1))<br/>x=1/UniformityCOMPL$BWkg_bc^(1/0.1)<br/>plot(x-BWkg)<br/>summary(x-BWkg)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lv"><img src="../Images/7d9c9b46c9790b2538de9ff5e264443a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MTke10EwHPFZS167IjsXgg.png"/></div></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="0642" class="kk kl hh kg b fi km kn l ko kp">#### MODEL BUILDING #####<br/>#### LM ####<br/>fitlm&lt;-lm(BWkg~Time*TT, data=Uniformity)<br/>fitlm2&lt;-lm(BWkg~ns(Time,2)*TT, data=Uniformity)<br/>fitlm3&lt;-lm(BWkg~ns(Time,3)*TT, data=Uniformity) # spline with 2 knots does nothing extra, so leave it at ns,2<br/>fitlm4&lt;-lm(BWkg~ns(Time,2)*TT+as.factor(n)-1, data=Uniformity)</span><span id="98e7" class="kk kl hh kg b fi kq kn l ko kp">#### LMER ####<br/>fit.lmer&lt;-lmer(BWkg~ns(Time,2)+TT+Room+(ns(Time,2)|BOX/n), data=UniformityCOMPL)<br/>fit2.lmer&lt;-lmer(BWkg~ns(Time,2)+TT+Room+(1|Block)+(0+ns(Time,2)|BOX/n), data=UniformityCOMPL)<br/>fit3.lmer&lt;-lmer(BWkg~ns(Time,2)*TT+Room+(ns(Time,2)|BOX/n), data=UniformityCOMPL)<br/>fit4.lmer&lt;-lmer(BWkg~ns(Time,2)*TT+Room+(1|Block)+(0+ns(Time,2)|BOX/n), data=UniformityCOMPL)<br/>#fit5.lmer&lt;-lmer(BWkg~ns(Time,2)*TT+Room+(ns(Time,2)|Block/BOX/n), data=UniformityCOMPL) # convergence issues <br/>#fit6.lmer&lt;-lmer(BWkg~ns(Time,2)*TT+Room+(ns(Time,2)|Block/BOX/n), data=UniformityCOMPL, control = lmerControl(optimizer="Nelder_Mead"))  # convergence issues <br/>#fit7.lmer&lt;-lmer(BWkg~ns(Time,2)*TT+Room+(ns(Time,2)|Block)+ (ns(Time,2)|BOX/n),data=UniformityCOMPL) # convergence issues <br/>fit8.lmer&lt;-lmer(BWkg~ns(Time,2)*TT+Room+(1|BOX)+(0+ns(Time,2)|n),data=UniformityCOMPL) <br/>fit9.lmer&lt;-lmer(BWkg~ns(Time,2)+TT+(ns(Time,2)|BOX/n),data=UniformityCOMPL)</span><span id="1df5" class="kk kl hh kg b fi kq kn l ko kp">### See if interaction effect is worth including <br/>KRSumFun &lt;- function(object, objectDrop, ...) {<br/>  krnames &lt;- c("ndf","ddf","Fstat","p.value","F.scaling")<br/>  r &lt;- if (missing(objectDrop)) {<br/>    setNames(rep(NA,length(krnames)),krnames)<br/>  } else {<br/>    krtest &lt;- KRmodcomp(object,objectDrop)<br/>    unlist(krtest$stats[krnames])<br/>  }<br/>  attr(r,"method") &lt;- c("Kenward-Roger via pbkrtest package")<br/>  r<br/>}<br/>drop1(fit3.lmer,test="user",sumFun=KRSumFun)<br/>### Compare models via AIC<br/>AICctab(fit.lmer, <br/>        fit2.lmer, <br/>        fit3.lmer, <br/>        fit4.lmer,<br/>        fit8.lmer,<br/>        fit9.lmer) </span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es mc"><img src="../Images/e4c098a85697186099c53c00c23ef722.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*qXjROzd9annRwL2SZf_GgA.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx"><strong class="bd md">fit.lmer </strong>has the<strong class="bd md"> </strong>lowest AIC</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="ed7f" class="kk kl hh kg b fi km kn l ko kp">final.model2&lt;-lmer(log(BWkg)~1+ns(Time,2)+TT+(ns(Time,2)|BOX/n),data=UniformityCOMPL)<br/>fit15.lmer&lt;-lmer(log(BWkg)~ns(Time,3)*TT+Room+(ns(Time,3)|Block/BOX/n),data=UniformityCOMPL) <br/>fit16.lmer&lt;-lmer(log(BWkg)~ns(Time,4)*TT+Room+(ns(Time,4)|Block/BOX/n),data=UniformityCOMPL) <br/>anova(final.model2, fit15.lmer, fit16.lmer) # fit15.lmer better model</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es me"><img src="../Images/cbf5db228729ce8dc866bdf6333fe90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*wYNfpqQI6NsF8GqTdBGSNg.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx"><strong class="bd md">fit15.lmer</strong> fits best</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="635c" class="kk kl hh kg b fi km kn l ko kp">UniformityCOMPL$BWlog&lt;-log(UniformityCOMPL$BW)<br/>fit.lme&lt;-lme(BWlog~ns(Time,3)*TT+Room,<br/>             random=~ns(Time,3)|Block/BOX/n,<br/>             data=UniformityCOMPL,<br/>             correlation = corCAR1(),<br/>             method="REML",<br/>             control=lmeControl(opt="optim",maxIter=1000000, msMaxIter = 10000))<br/>summary(fit.lme)</span><span id="e44d" class="kk kl hh kg b fi kq kn l ko kp">final.model&lt;-lmer(log(BW)~ns(Time,3)*TT+Room+(ns(Time,3)|Block/BOX/n),data=UniformityCOMPL) <br/>summary(final.model)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mf"><img src="../Images/9344c398550652c0c101485fbdbe158f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AichnbIi2cBXOeK_oFjE2w.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">What a model!!!! Perhaps not the best of models to have, although I am sure it will impress some people. In a research setting, such a model can be O.K., but if you create a prediction model like this you are bound to run into problems when a new dataset emerges.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="fbec" class="kk kl hh kg b fi km kn l ko kp">final.model&lt;-lmer(log(BW)~ns(Time,3)*TT+Room+(Time|Block/BOX/n),data=UniformityCOMPL) <br/>summary(final.model)<br/>fit.gls&lt;-gls(BW~TT*Time,correlation=corAR1(form=~Time|BOX/n), data=UniformityCOMPL)<br/>UniformityCOMPL$fit.gls&lt;-fitted(fit.gls)<br/>UniformityCOMPL$fit&lt;-exp(fitted(final.model))</span><span id="9c42" class="kk kl hh kg b fi kq kn l ko kp">ggplot(UniformityCOMPL, aes(x=Time, group=n))+<br/>  geom_point(aes(y=BW))+geom_line(aes(y=BW))+<br/>  geom_point(aes(y=fit), color="red", alpha=0.5)+geom_line(aes(y=fit),color="red", alpha=0.5)+<br/>  geom_point(aes(y=fit.gls),color="blue", alpha=0.5)+geom_line(aes(y=fit.gls),color="blue", alpha=0.5)+<br/>  facet_wrap(~BOX)+<br/>  theme_bw()</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mg"><img src="../Images/a5a40bff0d8a8beaffdb48664778c33f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TiLn4zKL4cEwf1wiocztgQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">The log model with the spline effect of time fits better then a liner model using an autocorrelation matrix to model the error term.</figcaption></figure><p id="9fb6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了突出如何搜索有影响的观察，我使用了<strong class="iy hi"> fit8.1.lmer </strong>，因为独立的随机效应，影响。我似乎不能做嵌套的随机效果。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="a93d" class="kk kl hh kg b fi km kn l ko kp">inf.N&lt;-influence.ME::influence(fit8.lmer, group="n") <br/>plot(inf.N, which="cook", cutoff=4/length(unique(UniformityCOMPL$n))) <br/>sum(cooks.distance(inf.N, sort=TRUE)- 4/length(unique(UniformityCOMPL$n))&gt;0)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mh"><img src="../Images/6bfda650d8ba6b4ad516aba13d88b98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HGpa_6XLYG-PBCdPK09p8g.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">A couple but nothing to be worried about.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="07ce" class="kk kl hh kg b fi km kn l ko kp">inf.BOX&lt;-influence.ME::influence(fit8.lmer, group="BOX") <br/>plot(inf.BOX, which="cook", cutoff=4/length(unique(UniformityCOMPL$BOX))) <br/>sum(cooks.distance(inf.BOX, sort=TRUE)<br/>4/length(unique(UniformityCOMPL$BOX))&gt;0) </span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es mi"><img src="../Images/963aab1144591889c302b619d755a777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*9eJrXXywo-FN066eHM9Gzw.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx">Looking good.</figcaption></figure><p id="ace4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，<strong class="iy hi"> lme </strong>软件包的伟大之处，尤其是在寻找一致性时，是寻找方差-协方差矩阵，它能最好地帮助你对相关误差建模。您需要这样一个矩阵的事实已经告诉您，一致性可能是一个问题。</p><p id="173d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了评估异质性，您可以拟合异质性误差项协方差矩阵。如果这个模型比没有模型的预测数据更好，那么这就是异质性的一个暗示。</p><p id="9165" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们来看看伦敦金属交易所能提供什么。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="69e3" class="kk kl hh kg b fi km kn l ko kp">fit8.1.lme&lt;-lme(BWkg~1+ns(Time,2)+TT,<br/>                data=UniformityCOMPL,<br/>                random=~ns(Time,2)|BOX/n,<br/>                method="ML",<br/>                control=lmeControl(opt="optim",maxIter=1000000, msMaxIter = 10000))</span><span id="4736" class="kk kl hh kg b fi kq kn l ko kp">### Autocorrelation --&gt; dealing with issues of independence<br/>## Correlogram not realy suited for unequal time distances<br/>par(mfrow=c(3,2))<br/>plot(acf(resid(fit8.1.lme)))<br/>plot(pacf(resid(fit8.1.lme))) <br/>E1&lt;-residuals(fit8.1.lme, type="normalized")<br/>plot(E1) # actually looks quite ok</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mj"><img src="../Images/70df0e1e4830d722a2fe1fa96e3f487c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jCvH8qJ4QXVw08gPTqEFoA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">There for sure is a need to model the autocorrelation present in the data.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="f6af" class="kk kl hh kg b fi km kn l ko kp">fit8.lme.cor&lt;-lme(BWkg~1+ns(Time,2)+TT,<br/>                     data=UniformityCOMPL,<br/>                     random=~ns(Time,2)|BOX/n,<br/>                     correlation=corCAR1(form=~Time),<br/>                     method="REML",<br/>                     control=lmeControl(opt="optim",maxIter=100000000, msMaxIter = 1000000))<br/>summary(fit8.lme.cor) # phi = 0.8843306 <br/>AICctab(fit8.1.lme, fit8.lme.cor) <br/>par(mfrow=c(2,1))<br/>acf(residuals(fit8.lme.cor)) # almost gone<br/>acf(residuals(fit8.1.lme))</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es mi"><img src="../Images/fb5831a21b2b584cc31074630b405631.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*SLp5WPq0veb6vmqkvQpOEQ.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx">Including a covariance matrix on the error does decrease the autocorrelations, as you might expect.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="79bc" class="kk kl hh kg b fi km kn l ko kp"># corCompSymm   compound symmetry <br/># corSymm       general <br/># corAR1        autoregressive of order 1 <br/># corCAR1       continuous-time AR(1) <br/># corARMA       autoregressive-moving average <br/># corExp        exponential <br/># corGaus       Gaussian <br/># corLin        linear <br/># corRatio      rational quadratic <br/># corSpher      spherical</span><span id="1dad" class="kk kl hh kg b fi kq kn l ko kp">fit8.gls&lt;-gls(BWkg~ns(Time,2)+TT, data=UniformityCOMPL)<br/>vario&lt;-Variogram(fit8.gls,form=~Time, robust=TRUE, resType="pearson", maxDist = 37) # now it does work <br/>plot(vario, smooth=TRUE) # quite some autocorrelation</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mk"><img src="../Images/5f9e9f85c61dc1713baf69d4e003686f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XmiQEi_3J6JjTpsnebE4Sw.png"/></div></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="d996" class="kk kl hh kg b fi km kn l ko kp">fit.corAR1&lt;-gls(BWkg~ns(Time,2)+TT, correlation=corAR1(0.8, form=~Time|BOX/n), data=UniformityCOMPL)<br/>fit.corARMA&lt;-gls(BWkg~ns(Time,2)+TT, correlation=corARMA(c(0.8, 0.2), form=~Time|BOX/n, p=1,q=1), data=UniformityCOMPL)<br/>fit.corCAR1&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corCAR1(form=~Time|BOX/n), data=UniformityCOMPL)<br/>fit.corCompSymm&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corCompSymm(form=~Time), data=UniformityCOMPL)<br/>fit.corSymm&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corSymm(form=~1|BOX/n), data=UniformityCOMPL)</span><span id="6f73" class="kk kl hh kg b fi kq kn l ko kp">AIC(fit8.gls, fit.corAR1, fit.corARMA, fit.corCAR1, fit.corCompSymm,fit.corSymm)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es ml"><img src="../Images/1addbee10827cfe913ba6ae88757015a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*lI71lYVw7hr_KGOXF5KzyQ.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx"><strong class="bd md">fit.corSymm</strong> is best.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="f99d" class="kk kl hh kg b fi km kn l ko kp">plot(fit.corSymm) </span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mm"><img src="../Images/3935a34d7141fe85ae8d01dcac8b0623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwa_oO2SRO3ZpBFRvyyaWw.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Residuals are horrible — heterogenous as can be</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="b16c" class="kk kl hh kg b fi km kn l ko kp">rmse(fit8.gls); <br/>rmse(fit.corAR1); <br/>rmse(fit.corARMA); <br/>rmse(fit.corCAR1); <br/>rmse(fit.corCompSymm); <br/>rmse(fit.corSymm);<br/>rmse(fit8.lme.cor)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es mn"><img src="../Images/6b2161ef6f4710abacbcdb8660cf82c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*YB4hgQ3aa67GAfeyVRvLIg.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx">And it does not have the lowest RMSE. But then again, they are all pretty close so take your pick.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="4652" class="kk kl hh kg b fi km kn l ko kp">par(mfrow=c(3,2))<br/>qqp(resid(fit8.gls), main="fit8.gls") <br/>qqp(resid(fit.corAR1),main="fit.corAR1 ")<br/>qqp(resid(fit.corARMA), main="fit.corARMA")<br/>qqp(resid(fit.corCAR1 ), main="fit.corCAR1 ") <br/>qqp(resid(fit.corCompSymm), main="fit.corCompSymm")<br/>qqp(resid(fit.corSymm), main="fit.corSymm")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mo"><img src="../Images/b6ac8103bb8b04c3d820946319c8a247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xOOvj0p8EOj3XDHYifCyg.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">All these transformations do not lead to a satisfactory solution → no changes in normality of residuals</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="4aba" class="kk kl hh kg b fi km kn l ko kp">par(mfrow=c(3,2))<br/>plot(fitted(fit8.gls), resid(fit8.gls, type="normalized"),main="fit8.2.gls");abline(h=c(-2,0,2), lty=2, col="red")  <br/>plot(fitted(fit.corAR1), resid(fit.corAR1, type="normalized"),main="fit.corAR1");abline(h=c(-2,0,2), lty=2, col="red")  <br/>plot(fitted(fit.corARMA), resid(fit.corARMA, type="normalized"),main="fit.corARMA");abline(h=c(-2,0,2), lty=2, col="red")  <br/>plot(fitted(fit.corCAR1), resid(fit.corCAR1, type="normalized"),main="fit.corCAR1");abline(h=c(-2,0,2), lty=2, col="red")  <br/>plot(fitted(fit.corCompSymm), resid(fit.corCompSymm, type="normalized"),main="fit.corCompSymm");abline(h=c(-2,0,2), lty=2, col="red")  <br/>plot(fitted(fit.corSymm), resid(fit.corSymm, type="normalized"),main="fit.corSymm");abline(h=c(-2,0,2), lty=2, col="red") <br/>plot(fit.corSymm)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mp"><img src="../Images/ef5d93c0cc32e71e84c44c7095b09a7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C7ld4qyTg4hgDIuApFrnxQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">But the residuals do seem to be within the standard boundaries. So, now it makes sense why <strong class="bd md">fit.corSymm</strong> was the best model to chose from.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="a75a" class="kk kl hh kg b fi km kn l ko kp">xyplot(BWkg~Time|n, data = UniformityCOMPL, <br/>       strip = FALSE, aspect = "xy", pch = 16, cex=0.2, grid = TRUE,<br/>       panel = function(x, y, ..., fit, subscripts) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         ypred&lt;-fitted(fit.corAR1)[subscripts]<br/>         panel.lines(x, ypred, lty = 3, col = "red")<br/>         ypred2&lt;-fitted(fit.corARMA)[subscripts]<br/>         panel.lines(x, ypred2, lty = 4, col = "blue")<br/>         ypred3&lt;-fitted(fit.corCAR1)[subscripts]<br/>         panel.lines(x, ypred3, lty = 5, col = "green")<br/>         ypred4&lt;-fitted(fit.corCompSymm)[subscripts]<br/>         panel.lines(x, ypred4, lty = 6, col = "orange")<br/>         ypred5&lt;-fitted(fit.corSymm)[subscripts]<br/>         panel.lines(x, ypred5, lty = 7, col = "pink")<br/>         panel.abline(0, 0)<br/>       } )</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mq"><img src="../Images/dc39352b4c2fdaefc8e664b7c2aae6d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aMBbSplhQT5SqRUuuTg_0Q.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">XYplot showing the fit of the models for each chick included in the study.</figcaption></figure><p id="132b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们继续讨论更复杂的协方差矩阵。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="7ea4" class="kk kl hh kg b fi km kn l ko kp">fit.corSpher&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corSpher(form=~Time|BOX/n), data=UniformityCOMPL)<br/>fit.corSpatial&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corSpatial(form=~Time|BOX/n), data=UniformityCOMPL)<br/>fit.corRatio&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corRatio(form=~Time|BOX/n), data=UniformityCOMPL)<br/>fit.corExp&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corExp(form=~Time|BOX/n, nugget=TRUE), data=UniformityCOMPL)<br/>fit.corGaus&lt;-gls(BWkg~ns(Time,2)+TT,correlation=corGaus(form=~Time|BOX/n), data=UniformityCOMPL)</span><span id="6a98" class="kk kl hh kg b fi kq kn l ko kp">### Homogeneity of Variance<br/>vfIdent&lt;-varIdent(form=~1|as.factor(Time))<br/>vfPower&lt;-varPower(form=~Time|BOX)<br/>vfExp&lt;-varExp(form=~Time|BOX)<br/>vfExp2&lt;-varExp(form=~Time)<br/>vfConstPower&lt;-(form=~Time|BOX)<br/>vfComb&lt;-varComb()</span><span id="cea9" class="kk kl hh kg b fi kq kn l ko kp">fit_nlme_varIdent&lt;-lme(BWkg~ns(Time,2)+TT, # There were 29 warnings <br/>                      data=UniformityCOMPL,<br/>                      random=~ns(Time,2)|BOX/n,<br/>                      weights = vfIdent,<br/>                      method="REML",<br/>                      control=lmeControl(opt="optim", maxIter=1000000, msMaxIter = 10000))<br/>fit_nlme_varExp&lt;-lme(BWkg~ns(Time,2)+TT, # There were 50 or more warnings (use warnings() to see the first 50)<br/>                     random=~ns(Time,2)|BOX/n,<br/>                     weights=vfExp,<br/>                     method="REML",<br/>                     data=UniformityCOMPL,<br/>                     control=lmeControl(opt="optim", maxIter=1000000, msMaxIter = 10000))</span><span id="b6d1" class="kk kl hh kg b fi kq kn l ko kp">par(mfrow=c(3,1))<br/>qqp(resid(fit8.lmer), main="fit8.lmer") <br/>qqp(resid(fit_nlme_varIdent),main="fit_nlme_varIdent")<br/>qqp(resid(fit_nlme_varExp), main="fit_nlme_varExp")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mm"><img src="../Images/51a7d298bdd5da813337afcf8dbbdad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PBAO0sW9yPwT08Z82IUeRA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">It seems the lmer fit is the best which is kind of funny since no covariance matrix on the error is included in thet model. The rest has some very heavy tails.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="a1f0" class="kk kl hh kg b fi km kn l ko kp">par(mfrow=c(3,1))<br/>plot(fitted(fit8.1.lme), resid(fit8.1.lme, type="normalized"),main="fit8.1.lme"); abline(h=c(-2,0,2), lty=2, col="red") <br/>plot(fitted(fit_nlme_varIdent), resid(fit_nlme_varIdent, type="normalized"),main="fit_nlme_varIdent"); abline(h=c(-2,0,2), lty=2, col="red") <br/>plot(fitted(fit_nlme_varExp), resid(fit_nlme_varExp, type="normalized"),main="fit_nlme_varExp"); abline(h=c(-2,0,2), lty=2, col="red")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mr"><img src="../Images/4d76c841e8d306bc79ac4a1faa4adf78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gPCQaO57h0ruGngRMLcA6g.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">But Ilike the residuals from the <strong class="bd md">lme </strong>models much more than the <strong class="bd md">lmer </strong>model. The difference we are seeing is probably due to the <strong class="bd md">lmer </strong>having a more heavy random effect included whilst the <strong class="bd md">lme </strong>models have covariance matrices on the error.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="9d31" class="kk kl hh kg b fi km kn l ko kp">xyplot(BWkg~Time|n, data = UniformityCOMPL, <br/>       strip = FALSE, aspect = "xy", pch = 16, cex=0.2, grid = TRUE,<br/>       panel = function(x, y, ..., fit, subscripts) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         ypred&lt;-fitted(fit8.1.lme)[subscripts]<br/>         panel.lines(x, ypred, col = "red")<br/>         ypred2&lt;-fitted(fit_nlme_varIdent)[subscripts]<br/>         panel.lines(x, ypred2, col = "blue")<br/>         ypred3&lt;-fitted(fit_nlme_varExp)[subscripts] # predict the worse<br/>         panel.lines(x, ypred3, col = "green")<br/>         panel.abline(0, 0)<br/>       } )</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mq"><img src="../Images/ef18d4c41f7213ae553a7b703bfd8168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HwYq9TWJx-CoeG0xULKy5Q.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">And the prediction on the individual animals coming from the three lme models —<strong class="bd md">fit8.1.lm</strong>, <strong class="bd md">fit_nlme_varIdent</strong> and <strong class="bd md">fit_nlme_varExp</strong>.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="408b" class="kk kl hh kg b fi km kn l ko kp">fit.corSymm.vfExp2&lt;-gls(BWkg~ns(Time,2)+TT,<br/>                 weights=vfExp2,<br/>                 correlation=corSymm(form=~1|BOX/n), <br/>                 data=UniformityCOMPL)</span><span id="e125" class="kk kl hh kg b fi kq kn l ko kp">anova(fit.corSymm, fit.corSymm.vfExp2)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es ms"><img src="../Images/89476b744405a7886ff2a28bf64e785f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*Ok7bsFtlzTU2TgIIMp-EWA.png"/></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="a3dc" class="kk kl hh kg b fi km kn l ko kp">plot(fit.corSymm.vfExp2) <br/>qqnorm(resid(fit.corSymm.vfExp2)) </span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks mt ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/f68571acf87fb3f61e753bfdd7fd846d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*it48RsbWZqU2OOTg8Sb4zw.png"/></div></figure><figure class="lb ks mu ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/36652bb4febacb6f120cf8126e8cdc9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*Od0dgOhzSRelGtBWOEFYEw.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx mv di mw ln">Not really good.</figcaption></figure></div><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="8f32" class="kk kl hh kg b fi km kn l ko kp">AIC(fit.corSymm, fit.corSymm.vfExp2)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es mx"><img src="../Images/3353974938fcef82db9b73507765be8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*OkYlxe0mFd6kFZM_GiptHQ.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx">Although that model is preferred. It makes you wonder about the usefulness of such information metrics.</figcaption></figure><p id="d331" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你想更仔细地看看这种模型下的矩阵，看看吧。我刚拍了一张超大型矩阵的照片。像这样的协方差是异质的，因为我希望它对于盒子里的动物是不同的(<em class="my"> BOX/n </em>)。可能是过度杀戮。当然过度拟合，但无论如何预测模型不是我的意图。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="52e1" class="kk kl hh kg b fi km kn l ko kp">cs1&lt;-corSymm(form=~1|BOX/n)<br/>cs1CorSymm &lt;- Initialize(cs1, data = UniformityCOMPL)<br/>cs1CorSymm<br/>corMatrix(cs1CorSymm )</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mz"><img src="../Images/a73992f7e8bd6ae02e19d9009569c9ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZFEW9oF9Kvmtj5KTxg4rMA.png"/></div></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="a569" class="kk kl hh kg b fi km kn l ko kp">ar1&lt;-corCAR1(form=~Time|BOX/n)<br/>ar1&lt;-Initialize(ar1, data = UniformityCOMPL)<br/>ar1 # phi=0.2</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div class="er es na"><img src="../Images/d409861a086af17512c11e180934fd01.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*mthu1KMe4zoSoTMO0fKVcw.png"/></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="79ab" class="kk kl hh kg b fi km kn l ko kp">ARMA1&lt;-corARMA(c(0.8, 0.2), form=~Time|BOX/n, p=1,q=1)<br/>ARMA1&lt;-Initialize(ARMA1, data = UniformityCOMPL)<br/>corMatrix(ARMA1)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nb"><img src="../Images/06fc127d84013be462f335efbc1e4a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bflDtEjFN6svK0iyoaZRbg.png"/></div></div></figure><p id="8aed" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">也许我应该选择伽玛模型，而不是高斯模型。Gamma模型在建模方差方面非常出色，因为它们有一个零边界，并且在给定正确参数值的情况下，将大部分分布放在接近该数字的顶部。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="3027" class="kk kl hh kg b fi km kn l ko kp">fit8.2.glmer&lt;-glmer(BWkg~ns(Time,2)+TT+<br/>                      (ns(Time,2)|BOX),<br/>                    family=Gamma(link="inverse"),<br/>                    control = glmerControl(optimizer = "bobyqa", nAGQ = 10),<br/>                    data=UniformityCOMPL)<br/>plot(fit8.2.glmer)<br/>summary(fit8.2.glmer) # extreme correlations</span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks nc ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/27c6dc1f1de8e8d166ea688c05637f2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*093vntX5UUVXGs6irQiM6A.png"/></div></figure><figure class="lb ks nd ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/9a917fd65a1ee3e028fd6dd4d644c539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*5VGAH3WLQTy5woZ6NsyR9Q.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx ne di nf ln">Nope, not what I needed.</figcaption></figure></div><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="9139" class="kk kl hh kg b fi km kn l ko kp">g &lt;- fitdistr(UniformityCOMPL$BWkg, "gamma")<br/>qqp(resid(fit8.2.glmer), "gamma",shape = g$estimate[[1]], rate = g$estimate[[2]]) <br/>qqnorm(resid(fit8.2.glmer));qqline(resid(fit8.2.glmer)) <br/>bwplot(UniformityCOMPL$Time~resid(fit8.2.glmer)) </span><span id="f5f2" class="kk kl hh kg b fi kq kn l ko kp">UniformityCOMPL$BOXnum&lt;-as.numeric(UniformityCOMPL$BOX)</span></pre><div class="kb kc kd ke fd ab cb"><figure class="lb ks ly ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/82f5b145024a3f273b04a33ac380422a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*bJkzDsmy12usR9ayZJNzRA.png"/></div></figure><figure class="lb ks ly ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/89f401963b634fd3ff0be762d2276438.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*cIP7X-ex6cOItgAXUYm72A.png"/></div></figure><figure class="lb ks ly ld le lf lg paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/18e419f7799514e0d5f1951689eda021.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*W1ekvc4ISJ-ePkeLCXAKrw.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx lz di ma ln">Not all to be fitted via a Gamma distribution.</figcaption></figure></div><p id="b597" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">或许到最后，还是坚持fit_15.lmer模式就好了。毕竟，那是最重要的模型。让我们看看效果如何。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="02c0" class="kk kl hh kg b fi km kn l ko kp">#### MODEL EVALUATION ####<br/>fit_15.lmer&lt;-lmer(log(BW)~ns(Time,3)*TT+Room+(ns(Time,3)|Block/BOX/n),data=UniformityCOMPL) <br/>fit_15.lmer.aug &lt;- augment(fit_15.lmer.aug)<br/>myx&lt;-scale_x_continuous(breaks=c(0,2,4,7,21,37))<br/>g1&lt;-ggplot(fit_15.lmer.aug, aes(.fitted, .resid))+<br/>  geom_point()+<br/>  stat_smooth(method="loess")+<br/>  geom_hline(yintercept=0, col="red", linetype="dashed")+<br/>  xlab("Fitted values")+<br/>  ylab("Residuals")+<br/>  ggtitle("Fitted vs Residuals")+<br/>  theme_bw()+ theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span><span id="5d09" class="kk kl hh kg b fi kq kn l ko kp">g2&lt;-ggplot(fit_15.lmer.aug, aes(x=.resid))+<br/>  geom_histogram(aes(y=..density..),colour="black", fill="white")+<br/>  geom_density(alpha=.2, fill="#FF6666")+<br/>  xlab("Residuals")+<br/>  ylab("Density")+<br/>  ggtitle("Histogram Residuals")+<br/>  theme_bw()+<br/>theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())<br/>vec&lt;-resid(fit_15.lmer.aug); y &lt;- quantile(vec[!is.na(vec)], c(0.25, 0.75)); x &lt;- qnorm(c(0.25, 0.75)); slope &lt;- diff(y)/diff(x); int &lt;- y[1L] - slope * x[1L]</span><span id="d654" class="kk kl hh kg b fi kq kn l ko kp">g3&lt;-ggplot(fit_15.lmer.aug, aes(sample=.resid))+<br/>  geom_qq()+<br/>  geom_abline(slope=slope, intercept=int, col="red", lty=2, lwd=1)+<br/>  xlab("Theoretical")+<br/>  ylab("Empirical")+<br/>  ggtitle("QQ-PLot Residuals")+<br/>  theme_bw()+  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span><span id="134e" class="kk kl hh kg b fi kq kn l ko kp">g4&lt;-ggplot(UniformityCOMPL, aes(x=log(BW), y=fitted(fit_15.lmer), colour=log(BW)-fitted(fit_15.lmer)))+<br/>  geom_abline(intercept=0, slope=1, lty=2, col="black", lwd=1)+<br/>  geom_point()+<br/>  scale_colour_gradient2(low="red",mid="blue",high="red")+<br/>  labs(title = "Calibration", y="Predicted", x="Observed", colour="Difference")+<br/>  theme_bw()+  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span><span id="b392" class="kk kl hh kg b fi kq kn l ko kp">g5&lt;-ggplot(fit_15.lmer.aug, aes(as.factor(UniformityCOMPL$TT),.resid))+<br/>  geom_boxplot()+<br/>  geom_hline(yintercept=0, col="red", linetype="dashed")+<br/>  xlab("Treatment")+<br/>  ylab("Residuals")+<br/>  ggtitle("Residuals vs Treatment")+<br/>  theme_bw()+  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span><span id="1cd1" class="kk kl hh kg b fi kq kn l ko kp">g6&lt;-ggplot(fit_15.lmer.aug, aes(as.factor(UniformityCOMPL$Time),.resid, group=as.factor(UniformityCOMPL$Time)))+<br/>  geom_boxplot()+<br/>  geom_hline(yintercept=0, col="red", linetype="dashed")+<br/>  xlab("Time")+<br/>  ylab("Residuals")+<br/>  ggtitle("Residuals vs Time")+<br/>  theme_bw()+ theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span><span id="aa8f" class="kk kl hh kg b fi kq kn l ko kp">g7&lt;-ggplot(fit_15.lmer.aug, aes(as.factor(UniformityCOMPL$BOX),.resid, group=UniformityCOMPL$BOX))+<br/>  geom_boxplot()+<br/>  geom_hline(yintercept=0, col="red", linetype="dashed")+<br/>  xlab("Box")+<br/>  ylab("Residuals")+<br/>  ggtitle("Residuals vs Box")+ theme_bw()+theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span><span id="11a2" class="kk kl hh kg b fi kq kn l ko kp">g8&lt;-ggplot(fit_15.lmer.aug, aes(x=as.factor(UniformityCOMPL$n),y=.resid, group=UniformityCOMPL$n))+<br/>  geom_boxplot()+<br/>  geom_hline(yintercept=0, col="red", linetype="dashed")+<br/>  xlab("N")+<br/>  ylab("Residuals")+<br/>  ggtitle("Residuals vs N")+<br/>  theme_bw()+ theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())<br/>gh&lt;-grid.arrange(g1,g2,g3,g4,g5,g6,g7,g8,nrow=4,ncol=2,top=textGrob("Diagnostics Model",gp=gpar(cex=2)))</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ng"><img src="../Images/ab240c8c85732ff7df202c242222ad1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NW-fGctcN5z6ejqqhgbgw.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Looking good!</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="ccab" class="kk kl hh kg b fi km kn l ko kp">xyplot(BWkg~Time|n, data = UniformityCOMPL, <br/>       strip = FALSE, aspect = "xy", pch = 16, cex=0.2, grid = TRUE,<br/>       panel = function(x, y, ..., fit, subscripts) {<br/>         panel.grid()<br/>         panel.xyplot(x, y)<br/>         panel.lmline(x, y, lty = 2, col="black")<br/>         panel.loess(x, y, lty = 2, col="red")<br/>         ypred&lt;-exp(fitted(fit15.lmer))[subscripts]<br/>         panel.lines(x, ypred, col = "orange")<br/>                  panel.abline(0, 0)<br/>       },<br/>       xlab = "Time",  ylab = "BW (kg)",key=list(space="top",<br/>                                                 lines=list(col=c("black","red", "orange"), lwd=1),<br/>                                                 text=list(c("Linear Regression", "LOESS", "Mixed Model"), columns=1)))</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nh"><img src="../Images/89d76ae88d9935b3983202de6f2f45bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3MEcKizhkuxgXo3IWDUklg.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Looking good again!</figcaption></figure><p id="c6c9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于LSMEAN是一个横截面比较，我们并没有真正对误差项建模，因此不应从这样的模型中导出LSMEANS。我仍然可以告诉你如何比较r中的处理值。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="2738" class="kk kl hh kg b fi km kn l ko kp">UniformityCOMPL$fit&lt;-exp(fitted(fit15.lmer))<br/>theme_set(theme_bw())<br/>ggplot(UniformityCOMPL, aes(x=as.factor(Time), y=BW, colour=TT, group=TT))+<br/>  stat_summary(fun.y=mean,geom="line", lwd=3, alpha=0.5, color="black")+<br/>  stat_summary(aes(y=fit, colour=TT),fun.y=mean,geom="line", lwd=1)+<br/>  stat_summary(fun.y=mean,geom="point", lwd=3, alpha=0.5, color="black")+<br/>  stat_summary(aes(y=fit, colour=TT),fun.y=mean,geom="point", lwd=1)+<br/>  xlab("Time")+<br/>  facet_wrap(~TT, ncol=2)+<br/>theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank())</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ni"><img src="../Images/00c7d1094444326b5d4d7ac427a25a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pFHL4qDsPMhFQNMl4jxGrA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">Overall fit of the model is good. The mean values.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="ff81" class="kk kl hh kg b fi km kn l ko kp">lsmeans::lsmip(final.model, TT ~ Time,cov.reduce = FALSE) <br/>fit.lsm&lt;-lsmeans::lsmeans(final.model, ~TT|Time, cov.reduce=FALSE, mode="Kenward-Roger")<br/>pair.fitlsm&lt;-pairs(fit.lsm)<br/>summary(pair.fitlsm, type="response")<br/>plot(pair.fitlsm, intervals = TRUE, int.adjust = "none", comparisons = TRUE)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nj"><img src="../Images/c902267798ee8decd430f12f334e44ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kjCWhQXxeuaZzb4p-lO2dA.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">If a confidence interval (purple) does not contain zero it is significant.</figcaption></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="69a5" class="kk kl hh kg b fi km kn l ko kp">## Final model 2<br/>fit.lsm2&lt;-lsmeans::lsmeans(final.model2, ~TT|Time, cov.reduce=FALSE, mode="Kenward-Roger")<br/>pair.fitlsm2&lt;-pairs(fit.lsm2)<br/>plot(pair.fitlsm2, intervals = TRUE, int.adjust = "none", comparisons = TRUE)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nk"><img src="../Images/c9817627087937234471acd78d9b483f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nbRKWENX_Ruh5i8NHYGpmg.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx">As you can see, LSMEANS and thus comparisons between treatments are model dependent. Heavily so.</figcaption></figure><p id="76a4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以上的比较我不喜欢。它们是每次治疗比较的差异。偶然发现的可能性像这样呈指数增长，而且它没有向你展示不同治疗之间的差异实际上是如何随时间变化的。</p><p id="5e68" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了对此进行建模，我使用了一个名为final.model2的模型，并使用bootstrapping创建了一个显示随时间变化的分布图(正常比例、对数比例和比率)。代码很重，但情节应该是不言自明的。</p><p id="1597" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">尽情享受吧！</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="7f47" class="kk kl hh kg b fi km kn l ko kp">#### PREDICTION ####<br/>## Create new prediction dataframe<br/>#Expand dataframe to create predictions for timepoints in between day 0 and day 42 and expand to day 100 <br/>pdata&lt;-subset(UniformityCOMPL[,c(1:7)], Time==0)<br/>dim(pdata)<br/>pdata&lt;-as.data.frame(sapply(pdata, rep.int, times=38))<br/>pdata$id&lt;-NULL<br/>pdata&lt;-pdata[order(pdata$n),]<br/>row.names(pdata)&lt;-NULL<br/>pdata$Time&lt;-rep(c(0:37),320)<br/>pdata&lt;-as.data.frame(pdata)<br/>pdata$TT&lt;-as.factor(pdata$TT)<br/>pdata$BOX&lt;-as.factor(pdata$BOX)<br/>pdata$Room&lt;-as.factor(pdata$Room)<br/>pdata$Time&lt;-as.numeric(pdata$Time)<br/>pdata$n&lt;-as.numeric(pdata$n)<br/>str(pdata)</span><span id="56df" class="kk kl hh kg b fi kq kn l ko kp">### MODEL<br/>final.model2&lt;-lmer(log(BW)~ns(Time,3)*TT+Room+(ns(Time,3)|n),data=UniformityCOMPL)<br/>summary(final.model2)<br/>RMSE.merMod(final.model); RMSE.merMod(final.model2) # almost no difference in terms of residuals<br/>fixef(final.model)-fixef(final.model2) </span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nl"><img src="../Images/f54b5282b72f8cd7776f699028782b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Z8Kx_s23GFY-2ltkEwKUg.png"/></div></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="e01c" class="kk kl hh kg b fi km kn l ko kp">### BOOTSTRAP<br/>options(nwarnings = 10000) <br/>nc &lt;- detectCores()<br/>cl &lt;- makeCluster(rep("localhost", nc))</span><span id="bf4e" class="kk kl hh kg b fi kq kn l ko kp">mySumm &lt;- function(.) {<br/>  predict(., pdata,re.form=NULL, allow.new.levels=TRUE)<br/>}</span><span id="bcbe" class="kk kl hh kg b fi kq kn l ko kp">pred&lt;-bootMer(final.model, <br/>               mySumm, <br/>               nsim=5000, <br/>               use.u=FALSE, <br/>               type="parametric",<br/>               .progress="win")</span><span id="df6d" class="kk kl hh kg b fi kq kn l ko kp">pred2&lt;-bootMer(final.model2, <br/>              mySumm, <br/>              nsim=5000, <br/>              use.u=FALSE, <br/>              type="parametric",<br/>              .progress="win")</span><span id="0971" class="kk kl hh kg b fi kq kn l ko kp">## Bootstrap diagnostics on BootMer ouput<br/>png("Bootstrap fit2.png", widt=10, height=10, units = 'in', res = 600)<br/>plot(pred2)<br/>dev.off()<br/>attr(pred,"boot.fail.msgs")</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nm"><img src="../Images/e90316d942398d536303d7c18cb0f851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MYx7tryG_HWIEbrNVtFaRA.png"/></div></div></figure><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="5ad1" class="kk kl hh kg b fi km kn l ko kp">### Save bootstraps in dataframe <br/>bootstrapped&lt;-as.data.frame(pred2$t)<br/>bootstrapped&lt;-as.data.frame(t(bootstrapped))<br/>bootstrapped&lt;-cbind(bootstrapped,pdata[,c(4,7)]) # bind treatment and time<br/>write.csv(bootstrapped, "bootstrapped5000.csv")<br/>dim(bootstrapped)<br/>str(bootstrapped)<br/>colnames(bootstrapped)</span><span id="2cf9" class="kk kl hh kg b fi kq kn l ko kp">### CREATE RESULTS for AVERAGE BW DIFFERENCES BETWEEN TREATMENTS <br/>## ncol --&gt;number of timepoints<br/>## nrow --&gt;number of bootstraps <br/>T1.Mean.boot=matrix(ncol=38, nrow=5000)<br/>T2.Mean.boot=matrix(ncol=38, nrow=5000)<br/>T3.Mean.boot=matrix(ncol=38, nrow=5000)<br/>T4.Mean.boot=matrix(ncol=38, nrow=5000)<br/>for (j in 0:37){<br/>  for (i in 1:5000){<br/>    T1.Mean.boot[i,j+1]&lt;-mean(bootstrapped[,i][bootstrapped$TT==1&amp;bootstrapped$Time==j]) # j+1 needed if Time starts at zero<br/>    T2.Mean.boot[i,j+1]&lt;-mean(bootstrapped[,i][bootstrapped$TT==2&amp;bootstrapped$Time==j])<br/>    T3.Mean.boot[i,j+1]&lt;-mean(bootstrapped[,i][bootstrapped$TT==3&amp;bootstrapped$Time==j])<br/>    T4.Mean.boot[i,j+1]&lt;-mean(bootstrapped[,i][bootstrapped$TT==4&amp;bootstrapped$Time==j])<br/>  }<br/>}<br/>T1.Mean.boot&lt;-as.data.frame(T1.Mean.boot) # means for treatment 1 for each bootstrap sample and each timepoint<br/>T2.Mean.boot&lt;-as.data.frame(T2.Mean.boot) <br/>T3.Mean.boot&lt;-as.data.frame(T3.Mean.boot)<br/>T4.Mean.boot&lt;-as.data.frame(T4.Mean.boot)<br/>colnames(T1.Mean.boot)&lt;-seq(0,37,by=1)<br/>colnames(T2.Mean.boot)&lt;-seq(0,37,by=1)<br/>colnames(T3.Mean.boot)&lt;-seq(0,37,by=1)<br/>colnames(T4.Mean.boot)&lt;-seq(0,37,by=1)<br/>diffMEAN.T2T1.boot&lt;-as.data.frame(T2.Mean.boot-T1.Mean.boot) <br/>diffMEAN.T3T1.boot&lt;-as.data.frame(T3.Mean.boot-T1.Mean.boot)<br/>diffMEAN.T4T1.boot&lt;-as.data.frame(T4.Mean.boot-T1.Mean.boot)</span><span id="31f5" class="kk kl hh kg b fi kq kn l ko kp">### Create dataframe to plot differences per time-point<br/>## T2T1<br/>sumBoot &lt;- function(merBoot) {<br/>  return(<br/>    data.frame(fit = apply(diffMEAN.T2T1.boot, 2, function(x) as.numeric(quantile(x, probs=.5, na.rm=TRUE))),<br/>               lwr = apply(diffMEAN.T2T1.boot, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE))),<br/>               upr = apply(diffMEAN.T2T1.boot, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))))}<br/>diffMEAN.T2T1.dist&lt;-sumBoot(diffMEAN.T2T1.boot) # diff.dist$fit[1] equals median(diff.boot$1)<br/>library(data.table)<br/>diffMEAN.T2T1.dist&lt;-setDT(diffMEAN.T2T1.dist, keep.rownames = TRUE)[]<br/>diffMEAN.T2T1.dist&lt;-as.data.frame(diffMEAN.T2T1.dist)<br/>colnames(diffMEAN.T2T1.dist)[1]&lt;-"Day"<br/>colnames(diffMEAN.T2T1.dist)[2]&lt;-"Difference BW T2T1"<br/>colnames(diffMEAN.T2T1.dist)[3]&lt;-"LCI T2T1 BW"<br/>colnames(diffMEAN.T2T1.dist)[4]&lt;-"HCI T2T1 BW"<br/>diffMEAN.T2T1.dist$Day&lt;-as.numeric(diffMEAN.T2T1.dist$Day)<br/>diffMEAN.T2T1.dist$`Difference BW T2T1`&lt;-as.numeric(diffMEAN.T2T1.dist$`Difference BW T2T1`)<br/>diffMEAN.T2T1.dist$`LCI T2T1 BW`&lt;-as.numeric(diffMEAN.T2T1.dist$`LCI T2T1 BW`)<br/>diffMEAN.T2T1.dist$`HCI T2T1 BW`&lt;-as.numeric(diffMEAN.T2T1.dist$`HCI T2T1 BW`)</span><span id="c958" class="kk kl hh kg b fi kq kn l ko kp"># Histograms to diagnose bootstrapped samples<br/>par (mfrow=c(4,4))<br/>bootstraps&lt;-as.numeric(sample(colnames(diffMEAN.T2T1.boot),16))<br/>for (j in bootstraps){<br/>  h=hist(diffMEAN.T2T1.boot[,j],breaks=30,freq=FALSE,xlab="BW difference", main="", ylab="Probability") <br/>  abline(v=0, col="orange", lwd=2)<br/>  abline(v=as.numeric(quantile(diffMEAN.T2T1.boot[,j], probs=.5, na.rm=TRUE)),col="red", lwd=2)<br/>  abline(v=as.numeric(quantile(diffMEAN.T2T1.boot[,j], probs=.025, na.rm=TRUE)),col="red", lwd=2) # Lower bootstrapped percentile interval<br/>  abline(v=as.numeric(quantile(diffMEAN.T2T1.boot[,j], probs=.975, na.rm=TRUE)),col="red", lwd=2) # Upper bootstrapped percentile intervals<br/>  lines(density(diffMEAN.T2T1.boot[,j]), col="blue", lwd=2)<br/>  xfit&lt;-as.numeric(seq(min(diffMEAN.T2T1.boot[,j]),max(diffMEAN.T2T1.boot[,j]),length=length(diffMEAN.T2T1.boot[,j])))  <br/>  yfit&lt;-as.numeric(dnorm(xfit,mean=mean(diffMEAN.T2T1.boot[,j]),sd=sd(diffMEAN.T2T1.boot[,j]))) # correct if i use probability<br/>  lines(xfit, yfit, col="green", lwd=2)}</span><span id="7028" class="kk kl hh kg b fi kq kn l ko kp"># QQ-plots to diagnose bootstrapped samples<br/>par (mfrow=c(3,3))<br/>bootstraps&lt;-as.numeric(sample(colnames(diffMEAN.T2T1.boot),9))<br/>for (j in bootstraps){<br/>  qqp(diffMEAN.T2T1.boot[,j],ylab=NULL, xlab=NULL, lwd=1, cex=1) <br/>  }</span><span id="d67c" class="kk kl hh kg b fi kq kn l ko kp">## T3T1<br/>sumBoot &lt;- function(merBoot) {<br/>  return(<br/>    data.frame(fit = apply(diffMEAN.T3T1.boot, 2, function(x) as.numeric(quantile(x, probs=.5, na.rm=TRUE))),<br/>               lwr = apply(diffMEAN.T3T1.boot, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE))),<br/>               upr = apply(diffMEAN.T3T1.boot, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))))}<br/>diffMEAN.T3T1.dist&lt;-sumBoot(diffMEAN.T3T1.boot) # diff.dist$fit[1] equals median(diff.boot$1)<br/>library(data.table)<br/>diffMEAN.T3T1.dist&lt;-setDT(diffMEAN.T3T1.dist, keep.rownames = TRUE)[]<br/>diffMEAN.T3T1.dist&lt;-as.data.frame(diffMEAN.T3T1.dist)<br/>colnames(diffMEAN.T3T1.dist)[1]&lt;-"Day"<br/>colnames(diffMEAN.T3T1.dist)[2]&lt;-"Difference BW T3T1"<br/>colnames(diffMEAN.T3T1.dist)[3]&lt;-"LCI T3T1 BW"<br/>colnames(diffMEAN.T3T1.dist)[4]&lt;-"HCI T3T1 BW"<br/>diffMEAN.T3T1.dist$Day&lt;-as.numeric(diffMEAN.T3T1.dist$Day)<br/>diffMEAN.T3T1.dist$`Difference BW T3T1`&lt;-as.numeric(diffMEAN.T3T1.dist$`Difference BW T3T1`)<br/>diffMEAN.T3T1.dist$`LCI T3T1 BW`&lt;-as.numeric(diffMEAN.T3T1.dist$`LCI T3T1 BW`)<br/>diffMEAN.T3T1.dist$`HCI T3T1 BW`&lt;-as.numeric(diffMEAN.T3T1.dist$`HCI T3T1 BW`)</span><span id="ca8a" class="kk kl hh kg b fi kq kn l ko kp"># Histograms to diagnose bootstrapped samples<br/>par (mfrow=c(4,4))<br/>bootstraps&lt;-as.numeric(sample(colnames(diffMEAN.T3T1.boot),16))<br/>for (j in bootstraps){<br/>  #for (i in 1:length(bootstraps)){<br/>  h=hist(diffMEAN.T3T1.boot[,j],breaks=20,freq=FALSE, xlab="BW difference", main="", ylab="Probability") <br/>  abline(v=0, col="orange", lwd=2)<br/>  abline(v=as.numeric(quantile(diffMEAN.T3T1.boot[,j], probs=.5, na.rm=TRUE)),col="red", lwd=2)<br/>  abline(v=as.numeric(quantile(diffMEAN.T3T1.boot[,j], probs=.025, na.rm=TRUE)),col="red", lwd=2) # Lower bootstrapped percentile interval<br/>  abline(v=as.numeric(quantile(diffMEAN.T3T1.boot[,j], probs=.975, na.rm=TRUE)),col="red", lwd=2) # Upper bootstrapped percentile intervals<br/>  lines(density(diffMEAN.T3T1.boot[,j]), col="blue", lwd=2)<br/>  xfit&lt;-as.numeric(seq(min(diffMEAN.T3T1.boot[,j]),max(diffMEAN.T3T1.boot[,j]),length=length(diffMEAN.T3T1.boot[,j])))  <br/>  yfit&lt;-as.numeric(dnorm(xfit,mean=mean(diffMEAN.T3T1.boot[,j]),sd=sd(diffMEAN.T3T1.boot[,j]))) # correct if i use probability<br/>  lines(xfit, yfit, col="green", lwd=2)}</span><span id="eb9f" class="kk kl hh kg b fi kq kn l ko kp"># QQ-plots to diagnose bootstrapped samples<br/>par (mfrow=c(3,3))<br/>bootstraps&lt;-as.numeric(sample(colnames(diffMEAN.T3T1.boot),9))<br/>for (j in bootstraps){<br/>  qqp(diffMEAN.T3T1.boot[,j],ylab=NULL, xlab=NULL, lwd=1, cex=1) <br/>}</span><span id="0a0e" class="kk kl hh kg b fi kq kn l ko kp">## T4T1<br/>sumBoot &lt;- function(merBoot) {<br/>  return(<br/>    data.frame(fit = apply(diffMEAN.T4T1.boot, 2, function(x) as.numeric(quantile(x, probs=.5, na.rm=TRUE))),<br/>               lwr = apply(diffMEAN.T4T1.boot, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE))),<br/>               upr = apply(diffMEAN.T4T1.boot, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))))}<br/>diffMEAN.T4T1.dist&lt;-sumBoot(diffMEAN.T4T1.boot) # diff.dist$fit[1] equals median(diff.boot$1)<br/>library(data.table)<br/>diffMEAN.T4T1.dist&lt;-setDT(diffMEAN.T4T1.dist, keep.rownames = TRUE)[]<br/>diffMEAN.T4T1.dist&lt;-as.data.frame(diffMEAN.T4T1.dist)<br/>colnames(diffMEAN.T4T1.dist)[1]&lt;-"Day"<br/>colnames(diffMEAN.T4T1.dist)[2]&lt;-"Difference BW T4T1"<br/>colnames(diffMEAN.T4T1.dist)[3]&lt;-"LCI T4T1 BW"<br/>colnames(diffMEAN.T4T1.dist)[4]&lt;-"HCI T4T1 BW"<br/>diffMEAN.T4T1.dist$Day&lt;-as.numeric(diffMEAN.T4T1.dist$Day)<br/>diffMEAN.T4T1.dist$`Difference BW T4T1`&lt;-as.numeric(diffMEAN.T4T1.dist$`Difference BW T4T1`)<br/>diffMEAN.T4T1.dist$`LCI T4T1 BW`&lt;-as.numeric(diffMEAN.T4T1.dist$`LCI T4T1 BW`)<br/>diffMEAN.T4T1.dist$`HCI T4T1 BW`&lt;-as.numeric(diffMEAN.T4T1.dist$`HCI T4T1 BW`)</span><span id="ca90" class="kk kl hh kg b fi kq kn l ko kp"># Histograms to diagnose bootstrapped samples<br/>par (mfrow=c(4,4))<br/>bootstraps&lt;-as.numeric(sample(colnames(diffMEAN.T4T1.boot),16))<br/>for (j in bootstraps){<br/>  #for (i in 1:length(bootstraps)){<br/>  h=hist(diffMEAN.T4T1.boot[,j],breaks=20,freq=FALSE, xlab="BW difference", main="", ylab="Probability") <br/>  abline(v=0, col="orange", lwd=2)<br/>  abline(v=as.numeric(quantile(diffMEAN.T4T1.boot[,j], probs=.5, na.rm=TRUE)),col="red", lwd=2)<br/>  abline(v=as.numeric(quantile(diffMEAN.T4T1.boot[,j], probs=.025, na.rm=TRUE)),col="red", lwd=2) # Lower bootstrapped percentile interval<br/>  abline(v=as.numeric(quantile(diffMEAN.T4T1.boot[,j], probs=.975, na.rm=TRUE)),col="red", lwd=2) # Upper bootstrapped percentile intervals<br/>  lines(density(diffMEAN.T4T1.boot[,j]), col="blue", lwd=2)<br/>  xfit&lt;-as.numeric(seq(min(diffMEAN.T4T1.boot[,j]),max(diffMEAN.T2T1.boot[,j]),length=length(diffMEAN.T4T1.boot[,j])))  <br/>  yfit&lt;-as.numeric(dnorm(xfit,mean=mean(diffMEAN.T4T1.boot[,j]),sd=sd(diffMEAN.T4T1.boot[,j]))) # correct if i use probability<br/>  lines(xfit, yfit, col="green", lwd=2)}</span><span id="4946" class="kk kl hh kg b fi kq kn l ko kp"># QQ-plots to diagnose bootstrapped samples<br/>par (mfrow=c(3,3))<br/>bootstraps&lt;-as.numeric(sample(colnames(diffMEAN.T4T1.boot),9))<br/>for (j in bootstraps){<br/>  qqp(diffMEAN.T4T1.boot[,j],ylab=NULL, xlab=NULL, lwd=1, cex=1) <br/>}</span><span id="f053" class="kk kl hh kg b fi kq kn l ko kp">## Plot differences in BW between Treatment 2 &amp; Treatment 1 for each day <br/># Log scale<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks = seq(0, 37, by = 1))<br/>myy&lt;-scale_y_continuous(breaks = seq(-1,1,by=0.01))<br/>gBW_trans_T2T1&lt;-ggplot(diffMEAN.T2T1.dist, aes(x=Day, y=`Difference BW T2T1`))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=`LCI T2T1 BW`, ymax=`HCI T2T1 BW`), alpha=0.3, fill="orange")+<br/>  geom_hline(yintercept=0,colour="red", lwd=1, lty=2)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "BW Difference Treatment 2vs1 (log)", y="BW difference (grams)", x="Day")</span><span id="e4fd" class="kk kl hh kg b fi kq kn l ko kp"># Original scale<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks = seq(0, 37, by = 1))<br/>myy&lt;-scale_y_continuous(breaks = seq(-1,2,by=0.01))<br/>gBW_orig_T2T1&lt;-ggplot(diffMEAN.T2T1.dist, aes(x=Day, y=exp(`Difference BW T2T1`)))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=exp(`LCI T2T1 BW`), ymax=exp(`HCI T2T1 BW`)), alpha=0.3, fill="orange")+<br/>  geom_hline(yintercept=1,colour="red", lwd=1, lty=2)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "BW Ratio Treatment 2vs1 ", y="BW Ratio (grams)", x="Day")<br/>gBWT2T1&lt;-grid.arrange(gBW_trans_T2T1,gBW_orig_T2T1,nrow=2,ncol=1,top=textGrob("BW compared by treatment",gp=gpar(cex=2)))<br/>ggsave(gBWT2T1,filename = "BW Difference T2T1 .png", width=16, height=16, dpi=600)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nn"><img src="../Images/7ca6f2b746f89be68763d39cc50549a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UzSQ3uSNLaY9TZmo2I5o-w.png"/></div></div></figure><p id="9368" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">##绘制每天治疗3和治疗1之间的体重差异</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="73ad" class="kk kl hh kg b fi km kn l ko kp"><br/># Tranformed scale<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks = seq(0, 37, by = 1))<br/>myy&lt;-scale_y_continuous(breaks = seq(-1,1,by=0.01))<br/>gBW_trans_T3T1&lt;-ggplot(diffMEAN.T3T1.dist, aes(x=Day, y=`Difference BW T3T1`))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=`LCI T3T1 BW`, ymax=`HCI T3T1 BW`), alpha=0.3, fill="orange")+<br/>  geom_hline(yintercept=0,colour="red", lwd=1, lty=2)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "BW Difference Treatment 3vs1 (log)", y="BW difference (grams)", x="Day")<br/># Original scale<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks = seq(0, 37, by = 1))<br/>myy&lt;-scale_y_continuous(breaks = seq(-1,2,by=0.01))<br/>gBW_orig_T3T1&lt;-ggplot(diffMEAN.T3T1.dist, aes(x=Day, y=exp(`Difference BW T3T1`)))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=exp(`LCI T3T1 BW`), ymax=exp(`HCI T3T1 BW`)), alpha=0.3, fill="orange")+<br/>  geom_hline(yintercept=1,colour="red", lwd=1, lty=2)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "BW Ratio Treatment 3vs1 ", y="BW Ratio (grams)", x="Day")<br/>gBWT3T1&lt;-grid.arrange(gBW_trans_T3T1,gBW_orig_T3T1,nrow=2,ncol=1,top=textGrob("BW compared by treatment",gp=gpar(cex=2)))<br/>ggsave(gBWT3T1,filename = "BW Difference T3T1 .png", width=16, height=16, dpi=600)</span><span id="addf" class="kk kl hh kg b fi kq kn l ko kp">## Plot differences in BW between Treatment 4 &amp; Treatment 1 for each day <br/># Tranformed scale<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks = seq(0, 37, by = 1))<br/>myy&lt;-scale_y_continuous(breaks = seq(-1,1,by=0.01))<br/>gBW_trans_T4T1&lt;-ggplot(diffMEAN.T4T1.dist, aes(x=Day, y=`Difference BW T4T1`))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=`LCI T4T1 BW`, ymax=`HCI T4T1 BW`), alpha=0.3, fill="orange")+<br/>  geom_hline(yintercept=0,colour="red", lwd=1, lty=2)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "BW Difference Treatment 4vs1 (log)", y="BW difference (grams)", x="Day")<br/># Original scale<br/>theme_set(theme_bw())<br/>myx&lt;-scale_x_continuous(breaks = seq(0, 37, by = 1))<br/>myy&lt;-scale_y_continuous(breaks = seq(-1,2,by=0.01))<br/>gBW_orig_T4T1&lt;-ggplot(diffMEAN.T4T1.dist, aes(x=Day, y=exp(`Difference BW T4T1`)))+<br/>  myx+<br/>  myy+<br/>  geom_line(lwd=1)+<br/>  geom_ribbon(aes(ymin=exp(`LCI T4T1 BW`), ymax=exp(`HCI T4T1 BW`)), alpha=0.3, fill="orange")+<br/>  geom_hline(yintercept=1,colour="red", lwd=1, lty=2)+<br/>  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+<br/>  labs(title = "BW Ratio Treatment 4vs1 ", y="BW Ratio (grams)", x="Day")<br/>gBWT4T1&lt;-grid.arrange(gBW_trans_T4T1,gBW_orig_T4T1,nrow=2,ncol=1,top=textGrob("BW compared by treatment",gp=gpar(cex=2)))<br/>ggsave(gBWT4T1,filename = "BW Difference T4T1 .png", width=16, height=16, dpi=600)</span><span id="7483" class="kk kl hh kg b fi kq kn l ko kp">gBW_trans&lt;-grid.arrange(gBW_orig_T2T1,gBW_orig_T3T1,gBW_orig_T4T1,nrow=3,ncol=1,top=textGrob("BW compared by treatment",gp=gpar(cex=2)))<br/>ggsave(gBW_trans,filename = "BW Ratio all treatments.png", width=16, height=16, dpi=600)</span></pre><figure class="kb kc kd ke fd ks er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nn"><img src="../Images/ee0dee79d0c717fc7f470e3d84eca740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rACYSktErs2oV1toMRRTag.png"/></div></div></figure><div class="no np ez fb nq nr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ns ab dw"><div class="nt ab nu cl cj nv"><h2 class="bd hi fi z dy nw ea eb nx ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ny l"><h3 class="bd b fi z dy nw ea eb nx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nz l"><p class="bd b fp z dy nw ea eb nx ed ef dx translated">medium.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of kt nr"/></div></div></a></div></div></div>    
</body>
</html>
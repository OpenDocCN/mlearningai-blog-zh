# 多模态专家混合

> 原文：<https://medium.com/mlearning-ai/multimodal-mixture-of-experts-16076e8987c1?source=collection_archive---------4----------------------->

## 谷歌的 LIMoE 在图像分类方面具有最先进的性能，可以有效地扩展。

![](img/5dba6d175214be3934df3f43d17bc6e9.png)

Photo by [Austin Distel](https://unsplash.com/@austindistel?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

**简介**

LIMoE 是一个多模态图像图像分类器。它很少被激活。

*   **5.6B 参数，**每个令牌 675M 参数
*   **稀疏**ly-激活**混合专家【MoE】**模型
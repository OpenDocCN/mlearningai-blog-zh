<html>
<head>
<title>Inverse Problems with Unrolled Adversarial Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有展开的对立正则化的反问题</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/inverse-problems-with-unrolled-adversarial-regularization-85d8abc13f76?source=collection_archive---------3-----------------------#2022-02-18">https://medium.com/mlearning-ai/inverse-problems-with-unrolled-adversarial-regularization-85d8abc13f76?source=collection_archive---------3-----------------------#2022-02-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="a03a" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">算法展开的端到端重建符合计算机视觉的数据驱动正则化</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/3ba9f57f778241f43735efc09e2cc7b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P5bxAMeiZFMkyfxvwGCSRw.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@tylercaseyprod?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Tyler Casey</a> on <a class="ae jm" href="https://unsplash.com/s/photos/blur?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c74e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">逆问题普遍存在于成像应用中，其中人们试图从其不完整和有噪声的测量中恢复未知的模型参数。例如，这可以应用于照片去噪，以提取更高质量的信息。本帖中讨论的方法，展开对抗正则化(UAR)，旨在解决这个问题。在深入UAR之前，我们还介绍了算法展开，这是UAR的一个基本构件。</p><h1 id="a7a0" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">算法展开</h1><p id="b7a9" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">算法展开的动机是找到传统<strong class="jp hi">迭代算法</strong>和数据驱动深度<strong class="jp hi">神经网络</strong>之间的联系。基本思想是将算法中的每次迭代<strong class="jp hi">建模为网络中的一层<strong class="jp hi"/>，由此迭代算法可以建模为连接在一起的多个层。因此，穿过网络相当于执行迭代算法有限次。因此，算法参数将自然地由网络参数表示，并且被训练的网络可以被解释为参数优化的算法，有效地克服了大多数常规神经网络中缺乏可解释性的问题。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lg"><img src="../Images/241605d9b2489af8dfae73ffc605800c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NMSOmNGS8TiIhc29baZYvg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 1: A high-level overview of algorithm unrolling: given an iterative algorithm (left), a corresponding deep network (right) can be generated by cascading its iterations h. The iteration step h (left) is executed a number of times, resulting in the network layers h1, h2, … (right). Each iteration h depends on a set of algorithm parameters, which are transferred into the corresponding set of network parameters. Instead of determining these parameters through cross-validation or analytical derivations, we learn them from training datasets through end-to-end training. In this way, the resulting network could achieve better performance than the original iterative algorithm. In addition, the network layers naturally inherit interpretability from the iteration procedure. The learnable parameters are colored in blue. (Cited from the original paper)</figcaption></figure><h2 id="660a" class="lh kk hh bd kl li lj lk kp ll lm ln kt jw lo lp kv ka lq lr kx ke ls lt kz lu bi translated">学习迭代收缩和阈值算法</h2><p id="b93a" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">图2显示了算法展开思想的<strong class="jp hi">示例</strong>应用。传统的稀疏编码算法，迭代收缩和阈值算法(ISTA)，被展开并由深度神经网络表示。注意，展开算法通过不在迭代(即层)之间共享权重来修改原始方法，因此它被称为学习的ISTA，或LISTA。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lv"><img src="../Images/47b0a651e50826386485a7a6fd42de5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FTawdFWUyBvOLILKlB9e7g.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Figure 2: Illustration of LISTA: one iteration of ISTA executes a linear and then a non-linear operation and thus can be recast into a network layer; by stacking the layers together a deep network is formed. The network is subsequently trained using paired inputs and outputs by back-propagation to optimize the parameters. µ is a constant parameter that controls the step size of each iteration. The trained network, dubbed LISTA, is computationally more efficient compared with the original ISTA. The trainable parameters in the network are colored in blue. (Cited from the original paper)</figcaption></figure><h1 id="6caa" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">展开的对抗性正则化</h1><p id="d4d9" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">UAR考虑的逆问题可以用等式1来概括，其中正向算子<code class="du lw lx ly lz b">A</code>在没有噪声的情况下模拟测量过程，而<code class="du lw lx ly lz b">e</code>表示测量噪声。我们的目标是找到一个能够将测量值<code class="du lw lx ly lz b">y</code>转换成潜在信息<code class="du lw lx ly lz b">x</code>的估计器。这里面临的独特挑战是，在研究数据集中，<code class="du lw lx ly lz b">y</code>和<code class="du lw lx ly lz b">x</code>通常不会成对出现<strong class="jp hi">。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ma"><img src="../Images/12eca6057b62a4f1bcff5d21c578c765.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*BwREQ-Dv272Pve5dw2BaAA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx">Equation 1: Formulation of the inverse problem.</figcaption></figure><p id="57bb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这种情况下，由于训练样本与标签的不匹配，许多判别方法都无法应用。因此，笔者在生成模型文献中借鉴了直觉生成对抗网络(GAN)。更具体地说，UAR由一个从测量值<code class="du lw lx ly lz b">y</code>中重建潜在信息<code class="du lw lx ly lz b">x</code>的<strong class="jp hi">重建</strong>网络(生成器)和一个区分重建图像和地面事实的<strong class="jp hi">正则化</strong>网络(鉴别器)组成。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mb"><img src="../Images/3bfbdd3b25f1f28eebe62a14e6b9eaf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YsjErMIzAVMejpOoxjDcvg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Equation 2: Objective function for the reconstruction network. It consists of a reconstruction term, where the reconstructed image is compared with the input, and a regularization term, estimated by the regularization network on the reconstruction.</figcaption></figure><p id="92db" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">重建网络的训练目标如等式2所示。期望算子中的第一项对应于重建损失，计算为重建图像和输入图像之间的距离。第二项是给定重建图像的正则化损失。为了产生更好的重建，这两项都需要最小化。注意，这个目标根本没有利用地面真实，所以它可以仅用输入图像来训练。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mc"><img src="../Images/af845b4393d3dc615882800a9aadef85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GelaqQL6KoWXlTZPMwRv9Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Equation 3: Objective function for the regularization network. The two terms have different signs because we would like the regularizer to be able to distinguish ground truth from reconstruction.</figcaption></figure><p id="a1d1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">正则化网络负责区分重建和地面实况，因此如等式3所示，它最大化重建图像的损失值，同时最小化地面实况的损失值。</p><p id="4c21" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">尽管该框架在用于重建和正则化网络的架构中是通用的，但在[3]中使用了展开的生成器和正常的深度网络，因此在名称UAR中是“展开的”。此外，作者在[3]中为UAR提供了严谨的理论结果，我们认为非常值得一读。</p><h1 id="c0c8" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">结论</h1><p id="8f38" class="pw-post-body-paragraph jn jo hh jp b jq lb ii js jt lc il jv jw ld jy jz ka le kc kd ke lf kg kh ki ha bi translated">我们回顾了图像处理中逆问题的展开对抗正则化。它从GANs中汲取直觉，优雅地解决了不成对训练样本的问题(在某种程度上缺失数据)，并超越了该领域中最先进的方法。</p><div class="md me ez fb mf mg"><a href="https://github.com/Subhadip-1/unrolling_meets_data_driven_regularization" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">GitHub-Subhadip-1/unrolling _ meets _ data _ driven _ regulation:包含python脚本，用于…</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">包含python脚本，用于学习迭代展开重建以及数据驱动的…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">github.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu jg mg"/></div></div></a></div></div><div class="ab cl mv mw go mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ha hb hc hd he"><p id="8588" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[1]蒙加、维沙尔、李跃龙和约尼娜·c·埃尔达。"算法展开:用于信号和图像处理的可解释的、有效的深度学习."<em class="nc"> IEEE信号处理杂志</em>38.2(2021):18–44。</p><p id="92ed" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[2]格雷戈尔，凯罗尔和扬·勒昆。"学习稀疏编码的快速近似."<em class="nc">第27届国际机器学习会议论文集</em>。2010.</p><p id="56eb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">[3] Mukherjee，Subhadip，等人，“端到端重建满足逆问题的数据驱动正则化。”<em class="nc">神经信息处理系统进展</em> 34 (2021)。</p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="nd l mr ms mt mp mu jg mg"/></div></div></a></div><p id="cb43" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">🔵<a class="ae jm" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"> <strong class="jp hi">成为作家</strong> </a></p></div></div>    
</body>
</html>
# ä½¿ç”¨ OpenCV çš„æ–‡æ¡£æ‰«æä»ªâ€”â€”å¸¦æºä»£ç â€”â€”ç®€å•æ˜“è¡Œ

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/document-scanner-using-opencv-with-source-code-easiest-way-e0543e1f3a72?source=collection_archive---------3----------------------->

æ‰€ä»¥ï¼Œä¼™è®¡ä»¬ï¼Œåœ¨ä»Šå¤©çš„åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ OpenCV æ„å»ºä¸€ä¸ªéå¸¸ç®€å•è€Œå¼ºå¤§çš„æ–‡æ¡£æ‰«æä»ªã€‚è¿™æ˜¯æˆ‘æœ€å–œæ¬¢çš„é¡¹ç›®ä¹‹ä¸€ï¼Œå› ä¸ºå®ƒç®€å•è€Œå¼ºå¤§ã€‚æ‰€ä»¥æ²¡æœ‰ä»»ä½•è¿›ä¸€æ­¥çš„åŸå› ã€‚

**åœ¨è¿™é‡Œé˜…è¯»å¸¦æºä»£ç çš„æ•´ç¯‡æ–‡ç« â€”**[https://machine learning projects . net/document-scanner-using-opencv/](https://machinelearningprojects.net/document-scanner-using-opencv/)

![](img/ee9d089f4d836b9519c064c0bc558512.png)

# è®©æˆ‘ä»¬å¼€å§‹å§â€¦

## ä½¿ç”¨ OpenCV çš„æ–‡æ¡£æ‰«æä»ªçš„ä»£ç â€¦

```
import cv2
import imutils
from skimage.filters import threshold_local
from pyimagesearch.transform import four_point_transform
import numpy as np

img_path = 'b.jpg'
big_img = cv2.imread(img_path)
cv2.imshow('org img',big_img)
cv2.waitKey(0)

ratio = big_img.shape[0] / 500.0
org = big_img.copy()
img = imutils.resize(big_img, height = 500)
cv2.imshow('resizing',img)
cv2.waitKey(0)

gray_img = cv2.cvtColor(img.copy(),cv2.COLOR_BGR2GRAY)
blur_img = cv2.GaussianBlur(gray_img,(5,5),0)
edged_img = cv2.Canny(blur_img,75,200)
cv2.imshow('edged',edged_img)
cv2.waitKey(0)

cnts,_ = cv2.findContours(edged_img.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
cnts = sorted(cnts,key=cv2.contourArea,reverse=True)[:5]
for c in cnts:
    peri = cv2.arcLength(c,True)
    approx = cv2.approxPolyDP(c,0.02*peri,True)
    if len(approx)==4:
        doc = approx
        break

p=[]
for d in doc:
    tuple_point = tuple(d[0])
    cv2.circle(img,tuple_point,3,(0,0,255),4)
    p.append(tuple_point)
cv2.imshow('Corner points detected',img)
cv2.waitKey(0)

warped = four_point_transform(org, doc.reshape(4, 2) * ratio)
warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)
cv2.imshow("Warped", imutils.resize(warped, height = 650))
cv2.waitKey(0)

T = threshold_local(warped, 11, offset = 10, method = "gaussian")
warped = (warped > T).astype("uint8") * 255
cv2.imshow("Scanned", imutils.resize(warped, height = 650))
cv2.waitKey(0)
cv2.destroyAllWindows()
```

*   ç¬¬ 1â€“5 è¡Œâ€”å¯¼å…¥æ‰€éœ€çš„åº“ã€‚
*   ç¬¬ 7â€“10 è¡Œâ€”è¯»å–å¹¶æ˜¾ç¤ºè¾“å…¥å›¾åƒã€‚

![](img/5426a75b1885579161bba47ded5a2122.png)

*   ç¬¬ 13 è¡Œâ€”â€”é€šè¿‡å°†æˆ‘ä»¬çš„å›¾åƒé«˜åº¦é™¤ä»¥ 500 å¾—åˆ°æ¯”ç‡ã€‚æˆ‘ä»¬å°†åœ¨æµç¨‹ä¸­è¿›ä¸€æ­¥ä½¿ç”¨è¯¥æ¯”ç‡ã€‚
*   ç¬¬ 14 è¡Œâ€”åˆ¶ä½œåŸå§‹å›¾åƒçš„å‰¯æœ¬ã€‚
*   ç¬¬ 15â€“17 è¡Œâ€”è°ƒæ•´å›¾åƒå¤§å°ï¼Œé«˜åº¦è®¾ä¸º 500ï¼Œä¿æŒçºµæ¨ªæ¯”ä¸å˜ã€‚

![](img/800f63c40d5a42bdc2042bb8ccac6dd9.png)

*   ç¬¬ 20 è¡Œâ€”â€”è¿™é‡Œæˆ‘ä»¬å°† BGR å›¾åƒè½¬æ¢æˆç°åº¦å›¾åƒã€‚
*   ç¬¬ 21 è¡Œâ€”â€”è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨[é«˜æ–¯æ¨¡ç³Š](https://en.wikipedia.org/wiki/Gaussian_blur#:~:text=In%20image%20processing%2C%20a%20Gaussian,image%20noise%20and%20reduce%20detail.)æ¥å»é™¤å›¾åƒä¸­çš„é«˜æ–¯å™ªå£°ã€‚
*   ç¬¬ 22 è¡Œâ€”â€”åœ¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬ç®€å•åœ°ä½¿ç”¨ [Canny è¾¹ç¼˜æ£€æµ‹](https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html)åœ¨å›¾åƒä¸­æ‰¾åˆ°è¾¹ç¼˜ã€‚
*   ç¬¬ 23 -24 è¡Œâ€”æ˜¾ç¤ºå›¾åƒã€‚

![](img/ece5df57554e0dbfb7cb6089073425ac.png)

*   ç¬¬ 27 è¡Œâ€”æŸ¥æ‰¾å›¾åƒä¸­çš„æ‰€æœ‰è½®å»“
*   ç¬¬ 28 è¡Œ-æ ¹æ®ç­‰é«˜çº¿é¢ç§¯å¯¹ç­‰é«˜çº¿è¿›è¡Œé™åºæ’åºï¼Œåªå–å‰ 5 è¡Œã€‚
*   ç¬¬ 29â€“34 è¡Œâ€”éå†è½®å»“å¹¶ä½¿ç”¨ [cv2.approxPolyDP()](https://docs.opencv.org/4.5.2/d3/dc0/group__imgproc__shape.html#ga0012a5fdaea70b8a9970165d98722b4c) æ‰¾åˆ°å…·æœ‰ 4 æ¡è¾¹çš„è½®å»“ã€‚
*   ç¬¬ 37â€“43 è¡Œâ€”æˆ‘ä»¬åªæ˜¯åœ¨æ–‡æ¡£çš„è§’ä¸Šç”»ç‚¹/åœˆã€‚è¿™äº›æ˜¯æˆ‘ä»¬åœ¨è½®å»“æ£€æµ‹æ­¥éª¤ä¸­ä½¿ç”¨ [CHAIN_APPROX_SIMPLE](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html) æ–¹æ³•å¾—åˆ°çš„ç‚¹ã€‚

![](img/407f7a58e907e7142815214a93dd1e22.png)

*   ç¬¬ 46â€“49 è¡Œâ€”â€”æˆ‘ä»¬æ­£åœ¨å¯¹å›¾åƒåº”ç”¨[å››ç‚¹å˜æ¢](https://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/)ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å°†åªä»å›¾åƒä¸­æå–æ–‡æ¡£ã€‚æˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥è¯´ï¼Œæˆ‘ä»¬åªæƒ³æå–å››ä¸ªç‚¹ç»„æˆçš„çŸ©å½¢ã€‚

![](img/46294e22d18d26b1effb65f33a3cdfbf.png)

*   ç¬¬ 52â€“55 è¡Œâ€”å¯¹å›¾åƒè¿›è¡Œé˜ˆå€¼å¤„ç†ï¼Œç»™å®ƒä¸€ç§é»‘ç™½çš„æ„Ÿè§‰ã€‚

![](img/ee9d089f4d836b9519c064c0bc558512.png)

*   ç¬¬ 56 è¡Œâ€”é”€æ¯æ‰€æœ‰æ‰“å¼€çš„çª—å£ã€‚

å¦‚æœå¯¹ä½¿ç”¨ OpenCV çš„æ–‡æ¡£æ‰«æä»ªæœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·é€šè¿‡ç”µå­é‚®ä»¶æˆ– LinkedIn è”ç³»æˆ‘ã€‚

**å¦‚éœ€è¿›ä¸€æ­¥çš„ä»£ç è§£é‡Šå’Œæºä»£ç ï¼Œè¯·è®¿é—®æ­¤å¤„**â€”[https://machine learning projects . net/document-scanner-using-opencv/](https://machinelearningprojects.net/document-scanner-using-opencv/)

*è¿™å°±æ˜¯æˆ‘å†™ç»™è¿™ä¸ªåšå®¢çš„å…¨éƒ¨å†…å®¹ï¼Œæ„Ÿè°¢ä½ çš„é˜…è¯»ï¼Œæˆ‘å¸Œæœ›ä½ åœ¨é˜…è¯»å®Œè¿™ç¯‡æ–‡ç« åï¼Œèƒ½æœ‰æ‰€æ”¶è·ï¼Œç›´åˆ°ä¸‹ä¸€æ¬¡ğŸ‘‹â€¦*

***çœ‹æˆ‘ä»¥å‰çš„å¸–å­:*** [***äººè„¸åœ°æ ‡æ£€æµ‹ä½¿ç”¨ DLIB***](https://machinelearningprojects.net/face-landmarks-detection-using-dlib/)

**æŸ¥çœ‹æˆ‘çš„å…¶ä»–** [**æœºå™¨å­¦ä¹ é¡¹ç›®**](https://machinelearningprojects.net/machine-learning-projects/)**[**æ·±åº¦å­¦ä¹ é¡¹ç›®**](https://machinelearningprojects.net/deep-learning-projects/)**[**è®¡ç®—æœºè§†è§‰é¡¹ç›®**](https://machinelearningprojects.net/opencv-projects/)**[**NLP é¡¹ç›®**](https://machinelearningprojects.net/nlp-projects/)**[**çƒ§ç“¶é¡¹ç›®**](https://machinelearningprojects.net/flask-projects/) **at**********

****[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai æäº¤å»ºè®®

### å¦‚ä½•æˆä¸º Mlearning.ai ä¸Šçš„ä½œå®¶

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)****
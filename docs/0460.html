<html>
<head>
<title>Object Detection Explained: Fast R-CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">物体检测解释:快速R-CNN</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-detection-explained-fast-r-cnn-bc11e607411f?source=collection_archive---------1-----------------------#2021-04-25">https://medium.com/mlearning-ai/object-detection-explained-fast-r-cnn-bc11e607411f?source=collection_archive---------1-----------------------#2021-04-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/8da8a93565eb689b489ad7316985670b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qvb4C5ia2y-tkh3VOggSkw.jpeg"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx"><a class="ae hu" href="https://unsplash.com/@sharonmccutcheon" rel="noopener ugc nofollow" target="_blank">Sharon McCutcheon</a> via <a class="ae hu" href="https://unsplash.com/photos/56m4k0pYz3s" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="7b8f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">目标检测包括两个独立的任务，即分类和定位。R-CNN代表基于区域的卷积神经网络。R-CNN系列背后的关键概念是地区提案。区域建议用于定位图像中的对象。在接下来的博客中，我决定写一些在物体检测中使用的不同方法和架构。在这篇文章中，我将通过简要提及它与R-CNN的不同之处来展示更快的R-CNN。</p><p id="7c07" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hy">先前:</strong></p><p id="2864" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">美国有线电视新闻网:</p><div class="hg hh ez fb hi js"><a href="https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76" rel="noopener follow" target="_blank"><div class="jt ab dw"><div class="ju ab jv cl cj jw"><h2 class="bd hy fi z dy jx ea eb jy ed ef hw bi translated">物体探测解释:R-CNN</h2><div class="jz l"><h3 class="bd b fi z dy jx ea eb jy ed ef dx translated">基于区域的卷积神经网络</h3></div><div class="ka l"><p class="bd b fp z dy jx ea eb jy ed ef dx translated">towardsdatascience.com</p></div></div><div class="kb l"><div class="kc l kd ke kf kb kg ho js"/></div></div></a></div><h1 id="9ff9" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">RCNN的问题</h1><p id="04a1" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">先前引入的RCNN的问题是它的计算成本。就我们所记得的，我们通过一种算法获得我们的建议区域，例如选择性搜索，之后我们必须调整所有东西的大小并通过一个网络。因此，调整和传递每一个作物是RCNN的一个瓶颈。</p><h1 id="7d1b" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">工作细节</h1><figure class="ll lm ln lo fd hj er es paragraph-image"><div class="er es lk"><img src="../Images/8ff89d572a97e53cf27c25b94c2c9c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*-L54d0ZQvCBwEs8ATj8RyA.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Fast RCNN: Working Details. Source: <a class="ae hu" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2524.pdf</a>.</figcaption></figure><p id="be40" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">快速R-CNN网络将整个图像和一组对象提议作为输入。然而，我们仍然需要通过我们的算法传递图像；引入ROI池层是为了克服上述问题。</p><p id="8668" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，我们通过缩放我们的建议来获得ROI窗口，以便它与特征图的大小相匹配。为此，我们应该将原始值乘以<em class="lp">特征图尺寸/原始尺寸</em>。例如，假设图像尺寸为1056x640，特征地图尺寸缩小到66x40。在这种情况下，我们可以将建议的所有维度乘以1/16 (66/1056=1/16或40/640=1/16)。因此，在这种情况下，空间比例将为1/16。</p><p id="56a5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，RoI max pooling将h × w ROI窗口划分为h × w(例如7×7)的子窗口网格，每个子窗口的大小大约为h/H × w/W。最后，执行max-pooling以获得每个子窗口的最大值。与标准最大池化一样，池化独立应用于每个要素地图通道。</p><figure class="ll lm ln lo fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lq"><img src="../Images/486e6c2fd49ec739097f48b6d44715b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*neZIlIpkPwqHgSwH.gif"/></div></div><figcaption class="hq hr et er es hs ht bd b be z dx">ROI max pooling. Credits: <a class="ae hu" href="https://deepsense.ai/region-of-interest-pooling-explained/" rel="noopener ugc nofollow" target="_blank">https://deepsense.ai/region-of-interest-pooling-explained/</a></figcaption></figure><p id="5bf5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当我们从我们的特征地图中裁剪ROI时，我们通过我们的网络传递它们来预测我们的类并调整预测的边界框。</p><h1 id="4eb0" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">正面和反面的例子</h1><p id="05b2" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">在我们提取我们的区域提案之后，我们还必须为它们添加标签以便进行培训。因此，作者将IOU至少为0.5的所有提案标上任何基本事实边界框及其相应的类别。但是，IOU低于0.3的所有其他区域提案都被标记为背景。因此，其余的都被忽略了。</p><h1 id="8885" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">包围盒回归</h1><figure class="ll lm ln lo fd hj er es paragraph-image"><div class="er es lr"><img src="../Images/a7812f1b2161af04fc1471efdb442233.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/0*86wpBH6uAhtbnvbS.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Bounding-box regression. Source: <a class="ae hu" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2524.pdf.</a></figcaption></figure><p id="2076" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上图显示了CNN预测的三角洲。所以，x，y是中心坐标。而w、h分别是宽度和高度。最后，G和P分别代表地面实况包围盒和区域提议。值得注意的是，边界框丢失仅针对正样本进行计算。</p><h1 id="e758" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">多任务损失</h1><figure class="ll lm ln lo fd hj er es paragraph-image"><div class="er es ls"><img src="../Images/58c56944f7d5eb36aee4d3c3f148b333.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*JfIG7pC0V92VSP8taieFyg.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Multi-task loss. Source: <a class="ae hu" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2524.pdf</a>.</figcaption></figure><p id="0154" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">可以看出，回归损失仅针对阳性样本进行计算。本文中介绍的局域化损耗是平滑L1损耗，其形式如下:</p><figure class="ll lm ln lo fd hj er es paragraph-image"><div class="er es lt"><img src="../Images/1658ccf2ef16664818581e9c7ca5349c.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*xXrWmaUgg6sJLvNOhZw6Ag.png"/></div><figcaption class="hq hr et er es hs ht bd b be z dx">Smooth L1 loss. Source: <a class="ae hu" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2524.pdf</a>.</figcaption></figure><p id="6596" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中x是{x，y，w，h}的基本真实值和我们的预测值之间的差值之和。</p><p id="e103" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然而，分类损失是众所周知的交叉熵损失。</p><h1 id="028b" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">一些遗言</h1><p id="ad65" class="pw-post-body-paragraph iu iv hx iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr ha bi translated">可以看出，快速RCNN克服了与RCNN相关的一些问题。但是，它不再被使用的原因还有几个缺点。最大的缺点仍然是用于提议提取的选择性搜索算法。考虑到算法是在cpu上执行的，推理时间变得很慢。因此，我将写一些克服这些问题的其他算法，比如更快的RCNN。</p><h1 id="0e81" class="kh ki hx bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">原文:<a class="ae hu" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">快速R-CNN </a></h1></div></div>    
</body>
</html>
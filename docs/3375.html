<html>
<head>
<title>Object Detection using mobilenet SSD</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用mobilenet SSD进行对象检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/object-detection-using-mobilenet-ssd-e75b177567ee?source=collection_archive---------4-----------------------#2022-08-25">https://medium.com/mlearning-ai/object-detection-using-mobilenet-ssd-e75b177567ee?source=collection_archive---------4-----------------------#2022-08-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e10b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我将分享一种分步方法，使用mobilenet SSD模型和来自笔记本电脑的网络摄像头来构建一个简单的对象检测器，以识别特定的对象。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/b8cc068df590b85aaff643afe384e489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YA3-aFLGUev2Sgvj.jpeg"/></div></div></figure><p id="ff3a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">什么是mobilenet？</strong></p><p id="de47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Mobilenet是一种卷积神经网络，专为移动和嵌入式视觉应用而设计。它们不使用标准的卷积层，而是基于使用深度方向可分离卷积的流线型架构。使用这种架构，我们可以构建轻量级深度神经网络，这些网络对于移动和嵌入式设备具有低延迟(例如:jetson nano)。你可以在谷歌研究人员2017年的原始<a class="ae jo" href="https://arxiv.org/abs/1704.04861v1" rel="noopener ugc nofollow" target="_blank">论文</a>中了解更多关于网络架构的信息。对于深度方向可分卷积的更深入的解释，我也发现池-汪锋的这个<a class="ae jo" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">博客</a>很有帮助。</p><p id="e84b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如上所述，mobilenet的理想应用包括移动和嵌入式设备。但是，为了演示使用该网络进行物体检测，我们将使用一台笔记本电脑和内置摄像头。</p><p id="7cfc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">初始要求</strong></p><p id="9975" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个项目，我们不会从头开始训练mobilenet模型，而是使用预先训练的模型权重和模型定义。为此，我们需要先下载以下文件:</p><ul class=""><li id="db09" class="jp jq hh ig b ih ii il im ip jr it js ix jt jb ju jv jw jx bi translated"><a class="ae jo" href="https://github.com/djmv/MobilNet_SSD_opencv/blob/master/MobileNetSSD_deploy.prototxt" rel="noopener ugc nofollow" target="_blank"> Caffe prototxt文件</a>:模型定义存储在该文件中</li><li id="4098" class="jp jq hh ig b ih jy il jz ip ka it kb ix kc jb ju jv jw jx bi translated"><a class="ae jo" href="https://github.com/djmv/MobilNet_SSD_opencv/blob/master/MobileNetSSD_deploy.caffemodel" rel="noopener ugc nofollow" target="_blank"> Caffe模型文件</a>:预训练模型权重</li></ul><p id="9151" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kd">什么是Caffe？</em></p><blockquote class="ke kf kg"><p id="999b" class="ie if kd ig b ih ii ij ik il im in io kh iq ir is ki iu iv iw kj iy iz ja jb ha bi translated">Caffe(用于快速特征嵌入的卷积架构)是一个深度学习框架，用于创建图像分类和图像分割模型。最初，用户可以创建并保存他们的模型为纯文本PROTOTXT文件。在使用Caffe对模型进行训练和优化之后，程序将训练好的模型保存为CAFFEMODEL文件。</p></blockquote><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kk kl l"/></div><figcaption class="km kn et er es ko kp bd b be z dx">Initial set up</figcaption></figure><p id="6e50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将上述文件下载到我们的工作目录后，我们需要使用OpenCV DNN函数<code class="du kq kr ks kt b">cv2.dnn.readNetFromCaffe</code>加载Caffe模型。然后，我们定义训练网络的类别标签(即COCO标签)。我们的模型在21个对象类上训练，这些对象类作为字典传递，其中每个键代表类ID，相应的值是标签的名称。</p><p id="0eda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">设置摄像机</strong></p><p id="9563" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为在这个例子中，我们使用一个摄像机feed进行对象检测，所以我们从OpenCV库中实例化了一个<code class="du kq kr ks kt b">VideoCapture</code>类的对象。作为输入，<code class="du kq kr ks kt b">VideoCapture</code>类接收我们想要使用的设备的索引。如果我们有一个连接到计算机的摄像机，我们传递一个值0。</p><p id="2cfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">格式化输入</strong></p><p id="dcdb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们从相机帧中获取图像的高度和宽度，稍后将使用这些高度和宽度在检测到的对象周围绘制边界框。现在，我们需要使用<code class="du kq kr ks kt b">cv2.dnn.blobFromImage</code>函数将图像转换成一个斑点(这是一个4D NumPy数组对象——图像，通道，宽度，高度)。这是为模型输入准备所需格式的输入图像所必需的。要了解blob是什么以及<code class="du kq kr ks kt b">cv2.dnn.blobFromImage</code>函数如何工作的更多信息，请参考这个<a class="ae jo" href="https://pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/" rel="noopener ugc nofollow" target="_blank">博客</a>。该函数的输入参数取决于正在使用的模型。关于<code class="du kq kr ks kt b">cv2.dnn.blobFromImage</code>函数的mobilenet输入参数，请参考来自<a class="ae jo" href="https://docs.openvino.ai/latest/index.html" rel="noopener ugc nofollow" target="_blank"> OpenVINO </a>(一个用于部署AI推理的开源工具包)的这个<a class="ae jo" href="https://docs.openvino.ai/latest/omz_models_model_mobilenet_ssd.html?highlight=mobilenet" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kk kl l"/></div><figcaption class="km kn et er es ko kp bd b be z dx">Format input</figcaption></figure><p id="2d15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">物体检测和可视化</strong></p><p id="fe60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，blob对象被设置为<code class="du kq kr ks kt b">net</code>网络的输入，随后通过mobilenet网络向前传递。现在，我们循环检测——检测摘要是一个1，1，N，7格式的数组，其中N是检测到的边界框的数量。每个检测具有格式[ <code class="du kq kr ks kt b">image_id</code>、<code class="du kq kr ks kt b">label</code>、<code class="du kq kr ks kt b">conf</code>、<code class="du kq kr ks kt b">x_min</code>、<code class="du kq kr ks kt b">y_min</code>、<code class="du kq kr ks kt b">x_max</code>、<code class="du kq kr ks kt b">y_max</code> ]</p><pre class="jd je jf jg fd ku kt kv kw aw kx bi"><span id="23a5" class="ky kz hh kt b fi la lb l lc ld"><strong class="kt hi">image_id</strong>: ID of the image in the batch<br/><strong class="kt hi">label</strong>: predicted class ID<br/><strong class="kt hi">conf</strong>: confidence score of the predicted class<br/><strong class="kt hi">x_min</strong><strong class="kt hi">, </strong><strong class="kt hi">y_min: </strong>coordinates of the top left bounding box corner<br/><strong class="kt hi">x_max</strong><strong class="kt hi">, </strong><strong class="kt hi">y_max:</strong> <!-- -->coordinates of the bottom right bounding box corner<br/> <br/>Note: Coordinates are in normalized format, in range [0, 1])</span></pre><p id="7eb8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们从检测数组中的第三个元素<code class="du kq kr ks kt b">detections[0, 0, i, 2]</code>中提取被检测对象的置信度得分。如果检测到的类的置信度得分大于阈值置信度水平(以过滤掉弱预测)，我们从检测数组中的第二个元素<code class="du kq kr ks kt b">detections[0, 0, i, 1]</code>获得检测到的类的类id。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kk kl l"/></div><figcaption class="km kn et er es ko kp bd b be z dx">Object detection and visualization</figcaption></figure><p id="d97d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦检测到对象，我们现在尝试通过绘制一个边界框并添加该对象的标签来可视化它。检测阵列返回归一化的左上角和右下角坐标，这些坐标通过乘以从照相机捕获的帧的宽度和高度而被缩放到帧尺寸。然后，我们使用<code class="du kq kr ks kt b">cv2.rectangle</code>函数在检测到的对象周围绘制一个边界框。如果检测到的类id与<code class="du kq kr ks kt b">classNames</code>字典中提到的21个标签中的一个匹配，我们添加一个带有标签名称的文本，并在文本周围添加一个框。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kk kl l"/></div><figcaption class="km kn et er es ko kp bd b be z dx">Display image and close camera feed</figcaption></figure><p id="1026" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以从python终端运行我们的代码，它将打开一个相机提要，其中包含一个边界框和检测到的对象的文本标签，以及帧中的置信度得分。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es le"><img src="../Images/ca00d77fe3cf2937a6c6475b8c40dec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cnyqE45D6zIMZHSBe9X1ow.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">Camera feed</figcaption></figure><p id="e009" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们想关闭摄像头，只需按键盘上的任意键。</p><p id="dc8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参考资料:</p><ol class=""><li id="c67a" class="jp jq hh ig b ih ii il im ip jr it js ix jt jb lf jv jw jx bi translated"><a class="ae jo" href="https://pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/" rel="noopener ugc nofollow" target="_blank">https://pyimagesearch . com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/</a></li><li id="430f" class="jp jq hh ig b ih jy il jz ip ka it kb ix kc jb lf jv jw jx bi translated">【https://opencv-tutorial.readthedocs.io/en/latest/index.html T4】</li><li id="0de7" class="jp jq hh ig b ih jy il jz ip ka it kb ix kc jb lf jv jw jx bi translated"><a class="ae jo" href="https://ebenezertechs.com/mobilenet-ssd-using-opencv-3-4-1-deep-learning-module-python/" rel="noopener ugc nofollow" target="_blank">https://ebenezer techs . com/mobilenet-SSD-using-opencv-3-4-1-deep-learning-module-python/</a></li><li id="7cc4" class="jp jq hh ig b ih jy il jz ip ka it kb ix kc jb lf jv jw jx bi translated"><a class="ae jo" href="https://github.com/djmv/MobilNet_SSD_opencv" rel="noopener ugc nofollow" target="_blank">https://github.com/djmv/MobilNet_SSD_opencv</a></li></ol><div class="lg lh ez fb li lj"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lk ab dw"><div class="ll ab lm cl cj ln"><h2 class="bd hi fi z dy lo ea eb lp ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lq l"><h3 class="bd b fi z dy lo ea eb lp ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lr l"><p class="bd b fp z dy lo ea eb lp ed ef dx translated">medium.com</p></div></div><div class="ls l"><div class="lt l lu lv lw ls lx jm lj"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Introduction to Sampling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">取样介绍</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/sampling-3042ccdd4621?source=collection_archive---------4-----------------------#2021-03-04">https://medium.com/mlearning-ai/sampling-3042ccdd4621?source=collection_archive---------4-----------------------#2021-03-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6245" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">这是一种选择最好的艺术</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/b4d6f4e2936a4ad196078f5459c8ea35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zhgrg_Q5PmJ_9Fvp.jpg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@impatrickt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Patrick Tomasso</a> on <a class="ae jm" href="https://unsplash.com/s/photos/books?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5a83" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这篇博文中，我们将讨论采样及其相关组件。与贝叶斯、频率、分布等其他花哨的统计术语相比，这个主题通常不太重要。</p><p id="e340" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">采样这个话题很枯燥，需要用户付出特别的努力来阅读。我这篇博客的目的是以一种更直观的形式分享采样主题。</p><p id="6aab" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在机器学习中，采样指的是来自总体的数据子集，其中总体意味着任务可用的每一个可能的数据，这是无限的，因为在现实世界的任务中，我们不断地为模型收集数据以进行训练和验证。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es kj"><img src="../Images/0fa6317d15b16a6eabd89102b99c104e.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*c8IBR65UGCSY2lxPYXDekA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Sampling</strong></figcaption></figure><h2 id="b22a" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">取样类型</h2><ul class=""><li id="5f28" class="lf lg hh jp b jq lh jt li jw lj ka lk ke ll ki lm ln lo lp bi translated">非概率抽样</li><li id="03b1" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki lm ln lo lp bi translated">随机或概率抽样</li></ul><h2 id="e633" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">非概率抽样</h2><p id="b108" class="pw-post-body-paragraph jn jo hh jp b jq lh ii js jt li il jv jw lv jy jz ka lw kc kd ke lx kg kh ki ha bi translated">我们在这里选择的子集是基于个人或用户的，他们是不可能的。既然它基于用户或个人，它就带有<strong class="jp hi">偏差</strong>。有各种非概率抽样的例子如下</p><p id="3cd9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">方便的抽样:</strong>子集选择是基于可用性进行的。这样就方便了。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ly"><img src="../Images/cba5473eb8e498e228ae2218b71b70be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YFvND8R3GRrESM8fAQSrOQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Convenient Sampling</strong></figcaption></figure><p id="9734" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">滚雪球抽样:</strong>现有子集有助于寻找下一组子集。它从样本子集滚动到其他子集。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lz"><img src="../Images/d2e4d746b894b9b72bdfad5321b0705d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*sByuw1ut7gX35YIE5SGeag.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Snowball Sampling</strong></figcaption></figure><p id="c6a2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">判断取样:</strong>根据专家的建议进行子集选择，专家对任务的样本进行判断。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ma"><img src="../Images/25b2b34535fb11341a6cb130e382509a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hJo_eJVQZEr8Z9UI3V7Ivg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Judgement Sampling</strong></figcaption></figure><p id="6d43" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">配额抽样:</strong>子集选择按照预先确定的顺序从可用配额中进行，没有任何随机化。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mb"><img src="../Images/71ec5f4f8427c307967276ffdf3186f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*CJY1AlKdDUG5oJee6HD3HA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Quota Sampling</strong></figcaption></figure><p id="739c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">作为最大似然法的候选，我们可以认为在选择数据时有偏见对模型训练是不利的，但这是可用的最佳选择，因为最大似然法的数据是方便可用的，而不是随机生成的。</p><h2 id="e0a5" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">非概率抽样的实例</h2><ul class=""><li id="7a24" class="lf lg hh jp b jq lh jt li jw lj ka lk ke ll ki lm ln lo lp bi translated">在亚马逊上写评论，可以访问互联网或愿意写作的人被捕获为数据。</li><li id="28c2" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki lm ln lo lp bi translated">训练语言模型，维基百科或reddit数据的可用性，这不是互联网上所有可能的数据，选择偏差。</li><li id="97cc" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki lm ln lo lp bi translated">当前疾病的患者记录。</li></ul><h2 id="28f2" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">随机或概率抽样</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mc"><img src="../Images/12c7e913427d206b2f6b0d6c3a6e4db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*AhqGWYXH4PTyy-Eaic4ciA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Random or Probability Sampling</strong></figcaption></figure><p id="f632" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在随机抽样中，从总体中选择每个样本的概率相等。考虑一个吃角子老虎机，其中每个转轮代表一组项目或数字，假设每个转轮有10个项目，每个转轮中每个项目的机会是1/10，选择是随机进行的。</p><p id="3a4b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">实现上面的采样非常容易，但是考虑一下这样的情况，我们想要选择所有样本的10%。如果有一些稀有类只出现在0.1%的人口中，那么就有很大的机会完全漏掉这个稀有类中的样本。在这种选择过程中训练的模型可能认为稀有类是不可用的。</p><h2 id="f849" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">分层抽样</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es md"><img src="../Images/7e2c2754567603a6ed73c9186cbb5137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*8Nzh-JM0-8HqtjYCszWjBg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Stratified Sampling</strong></figcaption></figure><p id="641f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">假设我们有10个不同的类要预测，每个类都有一些代表该类的数据点。现在，当我们执行随机抽样时，比如从每门课中选择10%,我们不可能完全漏掉一门课。这被称为分层抽样。</p><p id="69c8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在分层抽样中，我们根据一些共同的联系对样本进行分组，并相应地进行选择。例如，我们可以根据性别分组，并从每个组中选择10%，保持样本的变化不变。每一组称为地层。</p><p id="8da7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">分层抽样的缺点是当我们不能从可用的样本中创建子组，或者一个样本可以属于多个子组。当您有一个多标签任务并且一个样本可以既是A类又是b类时，这是一个挑战。例如，在实体分类任务中，一个名称可能既是一个人又是一个地点。</p><h2 id="2559" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">加权抽样</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es me"><img src="../Images/e0f5e4d42bdc4a5109549a21fe755020.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*wSlExVcB_M7rFU9m8LGK6g.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Weighted Sampling</strong></figcaption></figure><p id="1722" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在加权抽样中，每个样本都有一个权重，这个权重决定了它被选中的概率。例如，如果您希望一个样本有30%的机会被选中，则赋予它权重0.3。这种方法允许你嵌入主题的专业知识。例如，如果您知道最近的数据对您的模型更有价值，您可以赋予最近的数据更大的权重。</p><p id="e18e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">当我们的可用数据来自与真实数据不同的分布时，这也是有帮助的。例如，在我们的数据中，红色样本仅占25%，蓝色样本占75%，但我们知道在现实世界中，红色和蓝色发生的概率相等，因此我们会给红色样本三倍于蓝色样本的权重。</p><h2 id="be0a" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">重要性抽样</h2><p id="1726" class="pw-post-body-paragraph jn jo hh jp b jq lh ii js jt li il jv jw lv jy jz ka lw kc kd ke lx kg kh ki ha bi translated">重要性抽样是一种用于估计特定分布性质的技术，它只具有从不同分布产生的样本，而没有感兴趣分布的样本。</p><p id="23e1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="mf">来自Wiki:重要性抽样是一种</em> <a class="ae jm" href="https://en.wikipedia.org/wiki/Variance_reduction" rel="noopener ugc nofollow" target="_blank"> <em class="mf">方差缩减</em> </a> <em class="mf">技术，可用于</em> <a class="ae jm" href="https://en.wikipedia.org/wiki/Monte_Carlo_method" rel="noopener ugc nofollow" target="_blank"> <em class="mf">蒙特卡罗方法</em> </a> <em class="mf">。重要性抽样背后的思想是，在一个</em> <a class="ae jm" href="https://en.wikipedia.org/wiki/Simulation" rel="noopener ugc nofollow" target="_blank"> <em class="mf">模拟</em> </a> <em class="mf">中，输入</em> <a class="ae jm" href="https://en.wikipedia.org/wiki/Random_variables" rel="noopener ugc nofollow" target="_blank"> <em class="mf">随机变量</em> </a> <em class="mf">的某些值比其他值对被估计的参数有更大的影响。如果这些“重要的”值通过更频繁的采样得到强调，那么</em> <a class="ae jm" href="https://en.wikipedia.org/wiki/Estimator" rel="noopener ugc nofollow" target="_blank"> <em class="mf">估计量</em> </a> <em class="mf">方差就可以减少。因此，重要性抽样的基本方法是选择一个“鼓励”重要值的分布。</em></p><p id="8ad8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">重要性抽样的挑战是找到鼓励重要值的分布。<a class="ae jm" href="https://jonathan-hui.medium.com/rl-importance-sampling-ebfb28b4a8c6" rel="noopener">重要抽样在RL中有广泛的应用</a></p><p id="1f4c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">深入探讨重要性抽样:<a class="ae jm" href="https://jonathan-hui.medium.com/rl-importance-sampling-ebfb28b4a8c6" rel="noopener"> RL —重要性抽样</a>(许宗盛)</p><h2 id="c655" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">储层取样</h2><p id="fd9b" class="pw-post-body-paragraph jn jo hh jp b jq lh ii js jt li il jv jw lv jy jz ka lw kc kd ke lx kg kh ki ha bi translated">储层取样之间的动机:假设我们看到一系列项目，一次一个。我们希望在内存中保存10个项目，并且希望从序列中随机选择它们。如果我们知道项目总数 <strong class="jp hi"> <em class="mf"> n </em> </strong> <em class="mf">并且可以任意访问项目，那么解决方法就很简单:在1和</em> <strong class="jp hi"> <em class="mf"> n </em> </strong> <em class="mf">之间选择10个不同的索引</em> <strong class="jp hi"> <em class="mf"> i </em> </strong> <em class="mf">和</em><strong class="jp hi"><em class="mf">n</em></strong><em class="mf">n，保留第</em><strong class="jp hi"/>【T6问题是我们并不总是事先知道确切的<strong class="jp hi"><em class="mf"/></strong><em class="mf">。</em></p><blockquote class="mg mh mi"><p id="59ee" class="jn jo mf jp b jq jr ii js jt ju il jv mj jx jy jz mk kb kc kd ml kf kg kh ki ha bi translated"><strong class="jp hi">这里的关键是我们想从一个未知的样本量n中随机选择k个项目，每个项目具有相同的概率</strong></p></blockquote><p id="c508" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">想象一下，我们必须从传入的tweet流中抽取k条tweet。你不知道有多少条推文，但你知道你无法将它们都放入内存，这意味着你不知道一条推文被选中的概率。你想:</p><ul class=""><li id="85fa" class="lf lg hh jp b jq jr jt ju jw mm ka mn ke mo ki lm ln lo lp bi translated">确保每条推文都有同等的被选中概率，</li><li id="4d3f" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki lm ln lo lp bi translated">您可以随时停止算法并获得所需的样本。</li></ul><p id="3f97" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">一个解决办法是油藏取样。算法是这样的:</p><ol class=""><li id="c7f3" class="lf lg hh jp b jq jr jt ju jw mm ka mn ke mo ki mp ln lo lp bi translated">首先将k元素放入容器中。</li><li id="9f2b" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki mp ln lo lp bi translated">对于每个输入的第I个元素，生成一个介于1和I之间的随机数j</li><li id="f89d" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki mp ln lo lp bi translated">如果1≤j≤k；用ith替换储层中的jth</li></ol><p id="0704" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">每个输入的第I个元素有(k / i)个概率在储层中。你也可以证明油藏中的每一个元素都有(k / i)的概率在那里。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mq"><img src="../Images/56de4ef31bd58183e9a7bd55838bd90c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpyrgwrxm5Hp5Ha-3WtvDg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx"><strong class="bd kk">Reservoir sampling</strong></figcaption></figure><pre class="ix iy iz ja fd mr ms mt mu aw mv bi"><span id="c518" class="kl km hh ms b fi mw mx l my mz">#Reservoir Sampling</span><span id="51fb" class="kl km hh ms b fi na mx l my mz"><strong class="ms hi">(* S has items to sample, R will contain the result *)<br/>ReservoirSample(S[1..n], R[1..k])<br/>  // fill the reservoir array<br/>  for i := 1 to k<br/>      R[i] := S[i]<br/><br/>  // replace elements with gradually decreasing probability<br/>  for i := k+1 to n<br/>    (* randomInteger(a, b) generates a uniform integer from the inclusive range {a, ..., b} *)<br/>    j := randomInteger(1, i)<br/>    if j &lt;= k<br/>        R[j] := S[i]</strong></span></pre><p id="abbd" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="mf">例如，我们将处理一个包含三个元素的流，如下所示:</em></p><ol class=""><li id="1f8a" class="lf lg hh jp b jq jr jt ju jw mm ka mn ke mo ki mp ln lo lp bi translated"><em class="mf">储存第一个元素。</em></li><li id="b191" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki mp ln lo lp bi translated"><em class="mf">以1/2的概率存储第二个元素。现在这两种元素在水库中的概率相等。</em></li><li id="af6b" class="lf lg hh jp b jq lq jt lr jw ls ka lt ke lu ki mp ln lo lp bi translated"><em class="mf">以1/3的概率存储第三个元素。前面的两个元素也有一个最终的概率(1/2)÷(2/3)= 1/3被选中。</em></li></ol></div><div class="ab cl nb nc go nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ha hb hc hd he"><p id="da89" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">感谢阅读。如果你喜欢阅读我的文章，请查看更多文章。</p><h2 id="f364" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">在<a class="ae jm" href="https://www.linkedin.com/in/mayur-jain-ds" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae jm" href="https://twitter.com/mayur__22" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上与我联系🐅 ✋</h2><h2 id="3453" class="kl km hh bd kk kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">参考</h2><ul class=""><li id="1fa9" class="lf lg hh jp b jq lh jt li jw lj ka lk ke ll ki lm ln lo lp bi translated"><strong class="jp hi"> CS 329S:机器学习系统设计</strong>由<a class="ae jm" href="https://huyenchip.com" rel="noopener ugc nofollow" target="_blank">芯片胡延</a>、<a class="ae jm" href="https://michaeljohncooper.com/" rel="noopener ugc nofollow" target="_blank">迈克尔·库帕</a></li></ul></div></div>    
</body>
</html>
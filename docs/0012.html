<html>
<head>
<title>Linear Regression in Statistics and Machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统计学和机器学习中的线性回归</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/linear-regression-in-statistics-and-machine-learning-5407b7de7a9e?source=collection_archive---------3-----------------------#2019-07-27">https://medium.com/mlearning-ai/linear-regression-in-statistics-and-machine-learning-5407b7de7a9e?source=collection_archive---------3-----------------------#2019-07-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7213" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在统计学中，<strong class="ig hi">线性回归</strong>是一种对标量响应(标签或因变量)和一个或多个探索变量(特征或响应或自变量)之间的关系进行建模的线性方法。一个解释变量的情况称为<strong class="ig hi">简单线性回归</strong>。对于一个以上的解释变量或响应，这个过程被称为<strong class="ig hi">多元线性回归</strong>。</p><p id="949e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在线性回归中，使用线性预测函数对关系进行建模，该预测函数的未知模型参数根据数据进行估计。这种模型被称为线性模型。</p><p id="22c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最常见的是，给定解释变量(响应或预测)值的响应的条件均值被假定为这些值的仿射函数；不太常见的是，使用条件中位数或其他分位数。与所有形式的回归分析一样，线性回归侧重于给定预测值时响应的条件概率分布。</p><h1 id="687f" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">线性回归假设</h1><p id="0975" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">线性回归模型可以由下面的等式表示</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kf"><img src="../Images/72e00fa2055c1c8529d7db83db68be89.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/0*4aKIIybZcUWhywhR.png"/></div></figure><ul class=""><li id="167c" class="kn ko hh ig b ih ii il im ip kp it kq ix kr jb ks kt ku kv bi translated"><em class="kw"> Y </em>是预测值</li><li id="50cf" class="kn ko hh ig b ih kx il ky ip kz it la ix lb jb ks kt ku kv bi translated">θ  ₀是偏差项。</li><li id="5699" class="kn ko hh ig b ih kx il ky ip kz it la ix lb jb ks kt ku kv bi translated"><em class="kw"> θ </em> ₁,…，<em class="kw"> θ </em> ₙ为模型参数</li><li id="3763" class="kn ko hh ig b ih kx il ky ip kz it la ix lb jb ks kt ku kv bi translated"><em class="kw"> x </em> ₁、<em class="kw"> x </em> ₂,…、<em class="kw"> x </em> ₙ为特征值。</li></ul><p id="832d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上述假设也可以表示为</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lc"><img src="../Images/4c59ec26a97e91b0a1197e649409cfbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:162/format:webp/0*YSM9mLBd1wHjFO07.png"/></div></figure><p id="3a6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在哪里</p><ul class=""><li id="6759" class="kn ko hh ig b ih ii il im ip kp it kq ix kr jb ks kt ku kv bi translated"><em class="kw"> θ </em>是模型的参数向量，包括偏差项<em class="kw"> θ </em> ₀</li><li id="cfd6" class="kn ko hh ig b ih kx il ky ip kz it la ix lb jb ks kt ku kv bi translated"><em class="kw"> x </em>是<em class="kw"> x </em> ₀ =1的特征向量</li></ul><h1 id="fc4a" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated"><strong class="ak">线性回归假设:</strong></h1><ol class=""><li id="be57" class="kn ko hh ig b ih ka il kb ip ld it le ix lf jb lg kt ku kv bi translated"><strong class="ig hi">外生性弱</strong>。这实质上意味着预测变量<em class="kw"> x </em>可以被视为固定值，而不是随机变量。例如，这意味着预测变量被假定为无误差的，也就是说，没有被测量误差污染。</li><li id="fafd" class="kn ko hh ig b ih kx il ky ip kz it la ix lb jb lg kt ku kv bi translated"><strong class="ig hi">线性度</strong>。这意味着响应变量的平均值是参数(回归系数)和预测变量的线性组合。响应和特征变量之间的关系应该是线性的。可以使用散点图测试线性假设。如下所示，第一张图表示线性相关变量，而第二张图和第三张图中的变量很可能是非线性的。因此，第一张图将使用线性回归给出更好的预测。</li></ol><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lh"><img src="../Images/1cbe9471d7fab2cc5432def91a937ad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*0_xvVU8spHBrYYT9TkaFpA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Linear and Nonlinear data</figcaption></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lm"><img src="../Images/c84b4ba702112cfea0a033a948909611.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*FZ_X5qXV1jk104Hv3av2jQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Example of <a class="ae ln" href="https://en.wikipedia.org/wiki/Simple_linear_regression" rel="noopener ugc nofollow" target="_blank">S</a>imple linear regression, which has one independent variable</figcaption></figure><p id="9088" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。很少或没有多重共线性</strong>:假设数据中很少或没有多重共线性。当要素(或独立变量)彼此不独立时，会出现多重共线性。</p><p id="dbf6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。很少或没有自相关</strong>:另一个假设是数据中很少或没有自相关。当残差不是相互独立的时，就会出现自相关。你可以参考<a class="ae ln" href="https://en.wikipedia.org/wiki/Autocorrelation#Regression_analysis" rel="noopener ugc nofollow" target="_blank">这里的</a>来深入了解这个话题。</p><p id="7f0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5。同方差</strong>:同方差描述了一种情况，其中误差项(即自变量和因变量之间关系中的“噪声”或随机扰动)在所有自变量的值上都是相同的。如下所示，图1具有同方差性，而图2具有异方差性。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lo"><img src="../Images/fc73781c82f9a48018df7081f75011a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/0*4Yi02k_817j2UEdQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Homoscedasticity and Heteroscedasticity</figcaption></figure><h2 id="34ae" class="lp jd hh bd je lq lr ls ji lt lu lv jm ip lw lx jq it ly lz ju ix ma mb jy mc bi translated">6.正规化</h2><p id="c33f" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">线性模型的扩展称为正则化方法。这些方法寻求最小化训练数据上模型的平方误差的总和(使用普通的最小二乘法),并且降低模型的复杂性(如模型中所有系数总和的数量或绝对大小)。</p><p id="bea6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归正则化过程的两个常见示例是:</p><ul class=""><li id="7179" class="kn ko hh ig b ih ii il im ip kp it kq ix kr jb ks kt ku kv bi translated"><a class="ae ln" href="https://en.wikipedia.org/wiki/Lasso_(statistics)" rel="noopener ugc nofollow" target="_blank">套索回归</a>:修改普通最小二乘法，使系数的绝对和最小化(称为L1正则化)。</li><li id="c7be" class="kn ko hh ig b ih kx il ky ip kz it la ix lb jb ks kt ku kv bi translated"><a class="ae ln" href="https://en.wikipedia.org/wiki/Tikhonov_regularization" rel="noopener ugc nofollow" target="_blank">岭回归</a>:修改普通最小二乘法，使系数的绝对平方和最小化(称为L2正则化)。</li></ul><p id="f541" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当输入值中存在共线性且普通最小二乘法会过度拟合训练数据时，这些方法非常有效。</p><h2 id="29e3" class="lp jd hh bd je lq lr ls ji lt lu lv jm ip lw lx jq it ly lz ju ix ma mb jy mc bi translated">7.梯度下降</h2><p id="db90" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">当有一个或多个输入时，您可以通过迭代最小化训练数据上的模型误差来使用优化系数值的过程。</p><p id="4e80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种操作称为梯度下降，从每个系数的随机值开始。计算每对输入和输出值的误差平方和。学习率被用作比例因子，并且系数朝着最小化误差的方向被更新。重复该过程，直到达到最小平方和误差，或者不可能进一步改进。</p><p id="4ee3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用这种方法时，您必须选择一个学习率(alpha)参数，该参数决定了在过程的每次迭代中要采取的改进步骤的大小。</p><p id="696f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">梯度下降通常使用线性回归模型来教授，因为它相对容易理解。实际上，当您的数据集无论是行数还是列数都非常大，可能无法容纳在内存中时，这是非常有用的。</p><h2 id="ac82" class="lp jd hh bd je lq lr ls ji lt lu lv jm ip lw lx jq it ly lz ju ix ma mb jy mc bi translated">8.<strong class="ak">去除噪声:</strong></h2><p id="6e3c" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">线性回归假设您的输入和输出变量没有噪声。考虑使用数据清理操作，以便更好地暴露和澄清数据中的信号。这对于输出变量非常重要，如果可能的话，您希望移除输出变量(y)中的异常值。</p><h2 id="d6e1" class="lp jd hh bd je lq lr ls ji lt lu lv jm ip lw lx jq it ly lz ju ix ma mb jy mc bi translated">9.<strong class="ak">高斯分布:</strong></h2><p id="9d19" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">如果输入和输出变量具有高斯分布，线性回归将做出更可靠的预测。对变量使用变换(如log或BoxCox)可能会有一些好处，使它们的分布看起来更像高斯分布。</p><h2 id="8410" class="lp jd hh bd je lq lr ls ji lt lu lv jm ip lw lx jq it ly lz ju ix ma mb jy mc bi translated">10.<strong class="ak">重新调整输入</strong>:</h2><p id="ef7b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">如果使用标准化或规范化重新调整输入变量，线性回归通常会做出更可靠的预测。</p><h1 id="fcef" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">评估模型的性能</h1><ol class=""><li id="64cc" class="kn ko hh ig b ih ka il kb ip ld it le ix lf jb lg kt ku kv bi translated"><strong class="ig hi"> RMSE和R得分或决定系数:</strong></li></ol><p id="f679" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用均方根误差(<strong class="ig hi"> RMSE </strong>)和决定系数(<strong class="ig hi"> R </strong>得分)来评估我们的模型。</p><p id="09ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> RMSE </strong>是残差平方和的平均值的平方根。</p><p id="5e6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> R </strong>得分或<strong class="ig hi">决定系数</strong>解释了通过使用最小二乘回归可以将因变量的总方差减少多少。</p><p id="c9de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。残差图:</strong></p><p id="44f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个线性回归模型都应该在所有残差图上进行验证。这种回归图直接引导我们从正确的方程形式开始。您可能也会对之前关于回归的文章感兴趣。</p><p id="1c94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">残差分析通常用图形来完成。下面是我们通常会看到的两类图表:</p><p id="82d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> a .分位数图:</strong>这种类型的图形是评估残差的分布是否正态。该图介于残差分位数的实际分布和完全正态分布残差之间。如果图形完全覆盖在对角线上，则残差是正态分布的。下图是近似正态分布残差的示意图。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es md"><img src="../Images/9501c0436cb923874ca5140c3bad1b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wFPq4IaSS4rueGMe.png"/></div></div></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mi"><img src="../Images/4febe06703c791eb1098f1bfa00fdd9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q-70diUcw51Or2DF7G1iBQ.png"/></div></div></figure><p id="f1b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b .散点图及其对残差的解释:</strong>这种类型的图表用于评估模型假设，如恒定方差和线性，并识别潜在的异常值。下面是完美残差分布的散点图。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mj"><img src="../Images/29649e76ea913f5c2557a2ed93c05fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*emJiodXqbpm-tWGspIFWVQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Scatter plot with perfect residual distribution</figcaption></figure><p id="40b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们试着想象一个方差不等的残差分布散点图。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mk"><img src="../Images/540fb8b0aa4d1af1b1edb1dba3954385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7NI-6qGezDjKOkhH.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Graph with residual normal distribution being clearly violated</figcaption></figure><p id="56fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果曲线是这样的，残差可以包含在水平带中(并且残差在带内或多或少以随机方式波动)，则没有明显的模型缺陷。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ml"><img src="../Images/d7856394ca85644d8de460a9ea65cabf.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*a6rwU9o_5A65Bz7J-419sA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Plot with no obvious model defects.</figcaption></figure><p id="eef4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该图是这样的，残差可以包含在一个向外开口的漏斗中，那么这种模式表明误差的方差不是常数，而是y的增函数。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mm"><img src="../Images/13528cbbd638e0022fc1472b0effde7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*f2AyNZ4ydc9mF6_hKvLaoQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">The variance of errors increasing with y</figcaption></figure><p id="df51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些图是这样的，残差可以容纳在一个向内打开的漏斗中，那么这种模式表明误差的方差不是常数，而是y的减函数。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mn"><img src="../Images/781589daa7cd1150e164fce4a05a91fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*OZMBQY7VwuV3QLSdWHc2cQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">The variance of errors decreasing with y</figcaption></figure><p id="ee99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果曲线是这样的，残差可以容纳在双弓形内，那么这样的模式指示误差的方差不是常数，而是y是0和1之间的比例。那么y可能是二项式分布。接近0.5的二项式比例的方差比接近0或1的更大。所以假设y和X之间的关系是非线性的。处理这种方差不等的通常方法是对解释变量、研究变量进行适当的变换，或者使用加权最小二乘法。在实践中，研究变量的变换通常被用来稳定方差。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mo"><img src="../Images/b7cff562ff82f0de336b348ba74d5096.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*JX-NepSHMcjD7pfian9V5g.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">inequality of variances</figcaption></figure><p id="6dfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果曲线是这样的，残差包含在曲线内，那么它表明非线性。y和X之间的假定关系是非线性的。这也可能意味着模型中需要一些其他的解释变量。例如，平方误差项可能是必要的。在这些情况下，解释变量和/或研究变量的转换也可能是有帮助的。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mp"><img src="../Images/d57f6a74a10a36965bf945ec62dbb2b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*7xssDoWfaEctPDWBv0pZ_A.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Non-Linear relationship with residuals and y</figcaption></figure><h1 id="4063" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated"><strong class="ak">线性回归应用:</strong></h1><p id="34e3" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">线性回归广泛应用于生物、行为和社会科学中，以描述变量之间可能的关系。它是这些学科中使用的最重要的工具之一。线性回归在机器学习等人工智能领域发挥着重要作用。线性回归算法由于其相对简单和众所周知的特性而成为基本的监督机器学习算法之一。</p><h1 id="29f2" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">优点和缺点:</h1><p id="4e81" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">线性回归的主要优点是它的简单性、可解释性、科学可接受性和广泛的可用性。线性回归是许多问题的首选方法。分析师可以将线性回归与变量记录、转换或分段等技术结合使用。</p><p id="a0c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它的主要缺点是许多现实世界的现象根本不符合线性模型的假设；在这些情况下，很难或不可能用线性回归产生有用的结果。</p><p id="8b37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归在统计软件包和商业智能工具中广泛使用。</p><p id="52b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过<a class="ae ln" href="https://www.linkedin.com/in/sureshhp/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>和<a class="ae ln" href="https://hpsuresh12345.medium.com/about" rel="noopener"> Medium </a>与我联系，获取新文章和博客。</p><p id="8b27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — * — — — * — — — * — — — * — — — * — — — * — — — * —</p><p id="3953" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kw">“培养学习的热情。如果你这样做了，你将永远不会停止成长</em></p><p id="1f8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — * — — — * — — — * — — — * — — — * — — — * — — — * —</p></div></div>    
</body>
</html>
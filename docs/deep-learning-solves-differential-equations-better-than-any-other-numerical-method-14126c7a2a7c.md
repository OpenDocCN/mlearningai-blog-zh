# Deep Learning å¯ä»¥è§£å†³å¾®åˆ†æ–¹ç¨‹(ç†è®ºå’Œ pytorch å®ç°)

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/deep-learning-solves-differential-equations-better-than-any-other-numerical-method-14126c7a2a7c?source=collection_archive---------0----------------------->

![](img/75463ea1416a551720415b444f84b89f.png)

å˜¿ï¼æ¬¢è¿é˜…è¯»å…¶ä»–æ•°å­¦æ–‡ç« ï¼åœ¨ä¹‹å‰çš„ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æè¿°äº†æˆ‘çš„è®ºæ–‡æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å—ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹å¯å‘çš„æ–¹æ³•ï¼Œå…¶åŠ¨æœºæ˜¯**å¦‚ä½•ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå¤–æ¨**ã€[https://seven t-Christina . media . com/a-ä¸åŒçš„æ–¹æ³•-å—ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹å¯å‘-ç¥ç»ç½‘ç»œå¤–æ¨-9766f846bd02](https://sevent-christina.medium.com/a-different-approach-inspired-by-neural-odes-extrapolation-of-neural-networks-9766f846bd02) ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€çœ‹ï¼æˆ‘ä½¿ç”¨çš„ä¸€ä¸ªéå¸¸æœ‰è¶£çš„æ–¹æ³•æ˜¯ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ±‚è§£ odeã€‚

# æ±‚è§£å¸¸å¾®åˆ†æ–¹ç¨‹å’Œåå¾®åˆ†æ–¹ç¨‹çš„äººå·¥ç¥ç»ç½‘ç»œ

è¿™ç§æ–¹æ³•æœ€æ—©æ˜¯ç”± A. Likasï¼ŒE. Lagaris å’Œ D. Fotiadis åœ¨è®ºæ–‡[https://www.cs.uoi.gr/~lagaris/papers/TNN-LLF.pdf](https://www.cs.uoi.gr/~lagaris/papers/TNN-LLF.pdf)ä¸­æå‡ºçš„ï¼Œè¿™æ˜¯ä¸€ç§å¯å‘äº†å¾ˆå¤šäººçš„å‰æ²¿æ–¹æ³•ã€‚å°¤å…¶æ˜¯ç°åœ¨å…³äº**ç§‘å­¦æœºå™¨å­¦ä¹ **çš„è¯é¢˜å·²ç»éå¸¸â€œçƒ­é—¨â€è€Œä¸”æˆ‘ä»¬æ‰‹ä¸­å·²ç»æœ‰äº†å¼ºå¤§çš„å·¥å…·æ¥å®ç°å’Œæµ‹è¯•ï¼Œè¿™ç¯‡è®ºæ–‡æ›´æ˜¯å¿…è¯»ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ç”¨ä¸€ä¸ªç®€å•çš„æ–¹æ³•æ¥è§£é‡Šå’Œå®ç°æœ¬æ–‡ï¼è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ä¸€ä¸‹è¿™ä¸ªæ–¹æ³•å§ï¼

# æ•°å­¦èƒŒæ™¯

åœ¨è¿™é‡Œï¼Œæˆ‘å°†ä»‹ç»ä¸€ä¸ªä¸€é˜¶å¸¸å¾®åˆ†æ–¹ç¨‹çš„ä¾‹å­ï¼Œç„¶è€Œï¼Œå®ƒä¹Ÿå¾ˆå®¹æ˜“å·¥ä½œä¸ºè¾ƒå¤§çš„ç§©åºå¸¸å¾®åˆ†æ–¹ç¨‹æˆ–åå¾®åˆ†æ–¹ç¨‹ã€‚

*   ***é€šç”¨:***

åœ¨æ•°å€¼åˆ†æä¸­ï¼Œæˆ‘ä»¬ç”¨ä»¥ä¸‹å½¢å¼è¡¨ç¤º ODE:

![](img/6c6280b032c14de3deb38727f620f4ca.png)

æ‰€ä»¥ï¼Œå¯¹äºä¸€é˜¶é¢‚æ­Œï¼Œæˆ‘ä»¬æœ‰

![](img/175ce89476c9161f92cd9930b57b69cf.png)

æˆ‘ä»¬å°†ç ”ç©¶æœ¬æ–‡çš„ç¤ºä¾‹ 2:

![](img/19d76bb2429d370e3c7d9408b5bcae2b.png)

è¯¥ä¸€é˜¶å¸¸å¾®åˆ†æ–¹ç¨‹çš„è§£æè§£ä¸º:

![](img/82ef040d8e67be4c3afa1eb1bec6d1b5.png)

*   ***æ¬§æ‹‰æ³•:***

æœ‰å¾ˆå¤šå·²çŸ¥çš„æ•°å€¼æ–¹æ³•æ¥è§£å†³ä¸€ä¸ªå¾®åˆ†æ–¹ç¨‹ã€‚æœ€æµè¡Œçš„æ˜¯æ¬§æ‹‰æ–¹æ³•ã€‚æ¬§æ‹‰çš„åŸºæœ¬æ€æƒ³æ˜¯æˆ‘ä»¬ä»¥å‡åŒ€çš„æ–¹å¼åœ¨ N ä¸ªç‚¹ä¸Šç¦»æ•£åŒºåŸŸ[Î±ï¼Œb]ï¼Œ

[a=t0ï¼Œt1ï¼Œt2ï¼Œt3ï¼Œâ€¦ tN=b]æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå…¬å¼æ‰¾åˆ°è§£ï¼Œæ¬§æ‹‰å…¬å¼æ˜¯:

![](img/4880d4883632f1d6ee4fbd548c6b5fa2.png)

åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åœ¨[0ï¼Œ5]=[Î±ï¼Œb]ä¸­æœ‰ tï¼Œæœ€åçš„å…¬å¼æ˜¯:

![](img/eaf95cd8b0ba5eb766ca4918fc08e0cc.png)![](img/6025c9a95ec11596a2ff3d1868bbffa7.png)![](img/a0bf28b28e4db5569a22d546deff2d1f.png)

ä¸Šé¢çš„ä¸€ä¸ªä¸¤åˆ†é’Ÿå®ç°æ–¹æ³•ç»™å‡ºäº†ä¸€ä¸ªé¢å¤–çš„å¥½ç»“æœï¼ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ›´å¤æ‚çš„å¾®åˆ†æ–¹ç¨‹ï¼Œæƒ…å†µå°±ä¸æ€»æ˜¯è¿™æ ·ã€‚å¹¸è¿çš„æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸€äº›æ–¹æ³•ï¼Œæ¯”å¦‚é¾™æ ¼åº“å¡”(Runge Kutta)æˆ–æ”¹è¿›çš„æ¬§æ‹‰(Euler)æ–¹æ³•ã€‚

# å»ºè®®çš„æ–¹æ³•

> **ç†è®ºä¸Š:æˆ‘ä»¬å‡è®¾ä¸€ä¸ªè¯•éªŒè§£ä¾èµ–äºä¸€ä¸ªç¥ç»ç½‘ç»œã€‚è¯¥ç¥ç»ç½‘ç»œå°†è¢«è®­ç»ƒæˆä½¿å¾—è¯•è§£é€‚åˆäº ode çš„åˆ†æè§£ã€‚**

*   æ ¹æ®æœ¬æ–‡çš„ç­‰å¼(11)ï¼Œå¯¹äºå…·ä½“çš„ä¾‹å­ï¼Œæˆ‘ä»¬æœ‰ä¸‹é¢çš„ y è¯•éªŒã€‚N(xï¼ŒÎ¸)æ˜¯è¦è®­ç»ƒçš„ç¥ç»ç½‘ç»œã€‚

![](img/69a801659fe99e9f353742e1aa2a76b9.png)

*   æŸå¤±å‡½æ•°:ç¥ç»ç½‘ç»œæ˜¯è¿ç»­å’Œå¯å¾®çš„å‡½æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªç¥ç»ç½‘ç»œçš„å¯¼æ•°ã€‚

![](img/f513297b300150542f51339a149fb80c.png)

> **å®ç°:å‡è®¾ N(tï¼Œtheta)æ˜¯ä¸€ä¸ªæ¶æ„ç®€å•çš„ç¥ç»ç½‘ç»œã€‚å®ƒæœ‰ä¸€ä¸ªè¾“å…¥å±‚ï¼Œä¸€ä¸ªç¥ç»å…ƒå¯¹åº”äº[aï¼Œb]çš„æ¯ä¸ªç‚¹ tiï¼Œä¸€ä¸ªéšè—å±‚æœ‰ 10 ä¸ªç¥ç»å…ƒï¼Œä¸€ä¸ªè¾“å‡ºå±‚æœ‰ä¸€ä¸ªç¥ç»å…ƒå¯¹åº”äºè¯•è§£ y(ti)ï¼Œæˆ‘ä»¬ä½¿ç”¨ sigmoid ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚**

![](img/1c24bfdea37951c68aa2df3071ce40cc.png)

I define the network and the derivative of the network by hand. Below is also the same network using the Sequential module of Pytorch and then use autograd package for the derivative. It is also very handy! I did it from scratch in order to dive deep into the paperâ€™s method! The derivative comes from formulas (5) and (6) in the paper.

![](img/8d2a7dd7cafe563393763a110205a645.png)

The definition of y trial, f function(the ode) and the loss function.

![](img/723c45b1cfc634ea41d40d16528ad849.png)

training of this simple Neural Network achieves great loss.

![](img/c3b523a2b9ada31ad860b3f267e98baa.png)

final result

> **å®æ–½äº²ç¬”ç­¾åã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ pytorch é¡ºåºæ¨¡å—ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨å®šä¹‰ç¥ç»ç½‘ç»œå’Œå¯¼æ•°ã€‚**

![](img/bb1f9b8f55a4ddcb6fa7056dc88e5ff2.png)

The result using Sequential module, autograd and Adam or BFGS optimizer is the same and also very fast ğŸ‘

# ç»“è®º

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è§£å†³ä¸€ä¸ªå¸¸å¾®åˆ†æ–¹ç¨‹æˆ–åå¾®åˆ†æ–¹ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå¿«è·å¾—å¾ˆå¥½çš„ç»“æœã€‚å¯¹äºæ›´é«˜é˜¶çš„å¸¸å¾®åˆ†æ–¹ç¨‹æˆ–åå¾®åˆ†æ–¹ç¨‹ï¼Œæƒ³æ³•æ˜¯ç›¸åŒçš„ï¼Œä½†åœ¨å®ç°ä¸­æœ‰äº›äº‹æƒ…å‘ç”Ÿäº†å˜åŒ–ã€‚

æ„Ÿè°¢æ‚¨çš„é˜…è¯»ï¼è”ç³»æˆ‘ä»¥è·å¾—è¯„è®ºå’Œæ›´å¤šè®¨è®º..:)

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai æäº¤å»ºè®®

### å¦‚ä½•æˆä¸º Mlearning.ai ä¸Šçš„ä½œå®¶

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
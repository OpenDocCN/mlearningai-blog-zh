# 误差度量

> 原文：<https://medium.com/mlearning-ai/error-metrics-19c566a7b37?source=collection_archive---------2----------------------->

大家好！！

欢迎阅读这篇关于误差度量或模型性能评估方法的文章。

误差度量，顾名思义，是量化模型性能的度量。它基本上是一个用于评估模型的指标，所以也称为评估指标。

接下来要问的问题是

*   **什么是评价？**

评价是我们根据价值做出的判断。

*   **为什么评价？**

任何评估都是必要的，以了解绩效看起来如何，它是否可以用来实现我们的目标，任何改变都可以改进。

*   **如何评价？**

模型的评估取决于目标变量、业务用例以及算法等因素。

*   **准确度:**正确的程度
*   **误差:**观测值与实际值之间的差异。也可以叫偏差。

让我们从我们最喜欢的**回归模型开始。**在回归的情况下，我们要找到所需输入的值。也就是说，我们有一个连续的目标特征。因此，我们的模型应该与我们的预测和现实之间的距离进行比较。作为回归模型，我们的目标是提供输出，使其接近现实。

现在，带着这个目标，我们现在明白了模型展示给我提供了低误差和良好的准确性。

*   **R 平方正:***拟合优度的度量。*它解释了在给定输入特征的情况下，模型能够在多大程度上解释目标特征。它采用从 **0 到 1** 的值。越接近 1，模型越好。例如，R = 0.72，意味着独立特征能够解释 72%的目标。换句话说，目标中 72%的可变性正在被解释为输入。这用于线性模型，如线性回归、套索回归等。
*   **调整后的 R-positive:**与 R 相同。不同之处在于，R 随着新功能的引入而增加，但调整后的 R 会受到新功能引入的影响。如果特征被证明是可解释的，它可以增加，但是当它不能改进模型时，它可以减少。与 R 类似，值的范围是从 0 到 1。该值越高，模型性能越好。
*   **MSE(均方误差)—负值**:回归线与数据点接近程度的度量。误差的平方降低了负号的复杂性。也就是说，我们有两个数据点，实际值为 10，模型预测值为 9 和 11。在这种情况下，有一个 1 和-1 的差，当求和时得到 0，导致说没有错误。但是当对这些值进行平方和求和时，我们得到的最终误差为 2，这是一个更加明智和合理的结果。它计算为每个值与实际值的偏差，然后平方，平均值被视为 mse。这些值可以在 0 和无穷大之间持续。值越低，模型越好。
*   **RMSE(均方根误差)—负**:它告诉我们最佳拟合线周围的数据有多集中。mse 的计算是相同的，但是最后，对该值应用了根。这些值可以在 0 和无穷大之间持续。值越低，模型越好。

*一个很常见的问题问 RMSE:* ***多小才算小？*** *我们所理解的就是越低越好的模式。那么，应该低多少才能认为模型表现良好呢？*

为了检查，我们可以归一化 RMSE 值，

归一化= RMSE /(最大目标值-最小目标值)

如果对于具有 500K 和 50K 的目标，RMSE 为 4500，则归一化后约为 0.01 (1%)，这表示误差非常低，但是在目标为 50K 和 5K 的相同情况下，归一化后为 0.1 (10%)，这更高。

*   **MAE(平均绝对误差)—负值:**这是预测值和实际值之间差异大小的度量。但是 mae 通常不被考虑，因为它不涉及误差，而只是差异幅度。这些值可以在 0 和无穷大之间持续，类似于 rmse。它越低，模型性能越好。
*   **MAPE(平均绝对百分比误差)—负值:**这衡量预测的准确性。它被计算为绝对误差与实际误差的平均值。该值越低，模型性能越好。一般来说，如果 mape ≤ 5%，则模型被认为是准确的，如果大于 10 且小于 25，仍在可接受的范围内，任何更高的都被认为是低性能。

关于**分类模型，**考虑一个类中的性能。对于分类模型，我们的目标是分类特征。里面的每个值称为一个类。我们的目标是尽可能多地预测类中的更正。

**混淆矩阵:**实际值与预测值的矩阵。它呈现所有的真阳性、真阴性、假阳性和假阴性。从这个矩阵中，我们可以计算模型性能。

```
+------------------+--------------------+--------------------+
|   n              |    predicted - yes |    predicted - no  |
+------------------+--------------------+--------------------+
|  actual - yes    |   true positive    |   false negative   |
|  actual - no     |  false positive    |    true negative   |
+------------------+--------------------+--------------------+
```

假设我们的目标是“是”，并有两类“是”和“否”:

1.  **真阳性(TP):** 实际值和预测值为“是”的情况
2.  **真阴性(TN):** 实际值和预测值为“否”的情况
3.  **假阳性(FP)** :当预测说‘是’，但实际是‘否’。它也被称为
4.  ***假阴性(FN)** :当预测说‘否’，但实际是‘是’。也称为*

*   ****准确性–阳性:**这是所有数据点上正确预测的总数。这些值介于 0 和 1 之间。该值越高，模型性能越好。如果类别在数据中平均分布(平衡数据)，或者当我们没有一个被赋予重要性的特定类别时，我们应该考虑准确性。**

**>准确度= (TN + TP) / (TN + TP + FP + FN)**

*   ****误分类率–负值:**这是错误预测的总数。也可以认为是 1 —精度。所以它越低，性能越好。**

**>错误分类率= 1 —准确度**

**>误分类率= (FN + FP) / (TN + TP + FP + FN)**

*   ****真阳性率:**真阳性占所有阳性的比率**

**> TPR = TP/(TP + FN)**

*   ****假阳性率:**假阳性占所有阴性的比率**

**> FPR = FP/(FP + TN)**

*   ****真阴性率:**真阴性占所有阴性的比率**

**> TNR = TN/(TN + FP)**

*   ****假阴性率:**假阴性对所有阳性的比率**

**> FNR = FN/(FN + TP)**

*   ****Precision–Positive:**衡量有多少预测是正确的，所有预测都是肯定的。每当数据不平衡时，我们会考虑使用精确度或召回率，或者两者都用，这取决于业务案例。因为它是正确性的度量，值越高，性能越好。**

**>精度= TP / (TP + FP)**

*   ****回忆–肯定:**对所有实际值中有多少被正确预测为肯定的度量。当我们的业务案例依赖于“是”的假设时，使用回忆。与 precison 类似，值越高，模型越好。**

**>召回= TP / (TP + FN)**

*   ****F1 得分–正:**这是精确度和召回率的调和平均值。为了考虑这两种情况，并找到共同点，使用 f1。这是一个准确性指标，因此值越大，模型越好。**

**精确度和召回率是有权衡的，所以如果我们提高召回率，我们就会降低精确度，反之亦然。**

**在我们的问题陈述是发现苹果是否中毒的情况下，我们很可能不会忽略任何中毒的情况。所以我们的机会是尽可能减少假阴性的数量。也就是说，减少任何我们说它没有中毒，而实际上是中毒的情况。这种情况下，我们需要寻找回忆。**

**如果问题陈述是为了发现是否可以考虑贷款给某个特定的客户。在这种情况下，我们失去好客户的机会是可以的，但是失去好的坏客户对企业是有害的。因此，考虑到这里的精度，将是一个很好的交易。**

**感谢您花时间阅读这篇文章。希望它能帮助你更好地理解并应用到你的模型中。**

**[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)**
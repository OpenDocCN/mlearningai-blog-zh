<html>
<head>
<title>“Benchmarking the Performance and Energy Efficiency of AI Accelerators for AI Training” summary</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“面向人工智能培训的人工智能加速器性能和能效基准测试”摘要</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/benchmarking-the-performance-and-energy-efficiency-of-ai-accelerators-for-ai-training-e3995c52aeb4?source=collection_archive---------7-----------------------#2022-04-17">https://medium.com/mlearning-ai/benchmarking-the-performance-and-energy-efficiency-of-ai-accelerators-for-ai-training-e3995c52aeb4?source=collection_archive---------7-----------------------#2022-04-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="6def" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="2fed" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">深度学习(DL)是随着使用GPU而兴起的。此外，各种公司已经发布了加速器，以获得更高的性能和能效。例如，谷歌张量处理单元(TPU)处理器可以被命名为。Yuxin et al. [ <strong class="je hi"> 1 </strong> ]为各种DL模型的训练描述了CPU、GPU和TPU处理器的特性。他们从架构上选择各种DL模型来构建代表性的基准测试套件。为此，他们在其基准套件中包括卷积神经网络(<strong class="je hi">CNN</strong>)、递归神经网络(<strong class="je hi"> RNNs </strong>)、<strong class="je hi"> Deep Speech 2 </strong>和<strong class="je hi"> Transformer </strong>。基于他们的观察，他们向社区提供了关于DL模型和可用处理器的见解。</p><h1 id="75ac" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">人工智能加速器</h1><p id="60b5" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">该论文的作者使用CPU、GPU和云TPU来描述DL培训工作。要了解更多关于CPU和GPU的知识，请查看<a class="ae ka" rel="noopener" href="/mlearning-ai/processors-cpu-gpu-fpga-accelerator-8bfc3a73333c">这篇文章</a>。作者提供了下表，其中总结了一些GPU的详细信息。然而，最近发布了更强大的GPU，如NVIDIA的<a class="ae ka" href="https://www.nvidia.com/en-us/data-center/a100/" rel="noopener ugc nofollow" target="_blank"> A100 </a>和<a class="ae ka" href="https://www.nvidia.com/en-us/data-center/h100/" rel="noopener ugc nofollow" target="_blank">H100</a>GPU(论文于2020年发表)。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kb"><img src="../Images/3d0ec6e401f3375e14045ed3fb0aa0fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_UKs1L6z1aK42kE3riGmA.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><h2 id="0f65" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">谷歌TPUs</h2><p id="d9af" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">TPU是由Google设计的针对机器学习应用的特定应用硬件(ASICs)。机器学习应用中的主要操作是矩阵乘法，并且TPU被设计成专门在硬件级快速执行矩阵乘法。下图显示了TPU v2和v3架构。对于TPU v4，关于其架构的信息较少。但是，谷歌声称它比TPU v3快两倍多。MXU单元是专门为矩阵运算设计的。它们在每个周期中执行16K乘累加(MAC)操作。此外，它们支持混合精度训练。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lf"><img src="../Images/d6f6ba203189abf39c91caec255cd8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hOmEAiOCaKtT2i1l.jpg"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<a class="ae ka" href="https://www.nextplatform.com/2021/05/21/google-hints-about-its-homegrown-tpuv4-ai-engines/" rel="noopener ugc nofollow" target="_blank">ref</a>]</figcaption></figure><p id="0db4" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">TPU有趣的地方在于它们支持bfloat16。bfloat代表大脑浮点。这是一种不同于IEEE标准的浮点数表示法。它的目标是提供比IEEE float16格式更宽的范围，因为它为指数分配了更多的位。下图显示了bfloat16和IEEE float16与IEEE float32的区别。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es ll"><img src="../Images/06337ee555d22262d287ce1452373f91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PzL-dFG8O083Qurk.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx"><a class="ae ka" href="https://cloud.google.com/tpu/docs/bfloat16" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/tpu/docs/bfloat16</a></figcaption></figure><h1 id="bd3c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">培训渠道</h1><h2 id="9e05" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">小批量随机梯度下降(SGD)</h2><p id="90d6" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">Mini-batch SGD是SGD方法的衍生，它将数据集分成多个批次，并迭代更新模型参数。下图显示了单次迭代期间的培训流程图。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lm"><img src="../Images/7052f878c2c48d0e52129adb5e170b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMX3VDTA-nJBCc-IJa0ZUw.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><h2 id="3653" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">混合精度(MP)训练</h2><p id="8fca" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">这种技术在训练期间使用低位浮点来进行向前和向后的计算，以减少所需的计算量。在该技术中，采用FP32主权重和损失缩放来避免FP16/bfloat16精度可能导致的不稳定性。下图演示了这种技术。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es ln"><img src="../Images/44fd6e086af0aa9e4c8747c58a8567e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cYfcOJ2HdWDIlMCV.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx"><a class="ae ka" href="https://developer.nvidia.com/blog/video-mixed-precision-techniques-tensor-cores-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/blog/video-mixed-precision-techniques-tensor-cores-deep-learning/</a></figcaption></figure><h1 id="857f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">论文的评估设置</h1><h2 id="5c09" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">基准</h2><p id="c0ba" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在<strong class="je hi"> 1 </strong>论文中，选择了两种基准来评估不同的处理器:<strong class="je hi">综合张量运算</strong>和<strong class="je hi"> DL模型</strong>。由于矩阵乘法(全连接(FC))和二维卷积(卷积神经网络(CNN))是两种主要的资源消耗运算，因此它们被选为具有三种不同大小(小、中、大)的合成张量运算，如下图所示，它们的大小需要浮点运算(FLOPS)。对于conv2d操作，在不同的批量下，输入和滤波器采用ResNet50 [ <strong class="je hi"> 2 </strong>。作者采用了DeepBench的CUDA C++代码，并对其进行了一些修改。在下图中，F、K和S指的是输入大小、内核大小和步长。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lo"><img src="../Images/5ca8a559ed6663ef160e2a48d1124d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGZK2EWtO2-DW5qdTPKY5Q.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">[<strong class="bd ig">1</strong>]</figcaption></figure><p id="3f47" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">考虑到全面性，本文从不同的架构中选择模型，如下表所示。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lp"><img src="../Images/604f91e14a1283e9f9d071eeb5e17079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ZzB4GYF0M49z9yST3iO_A.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><h2 id="0178" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">韵律学</h2><p id="b72a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">作者选择迭代花费的时间作为性能度量。对于能量度量，他们使用处理单个样本的能量成本。他们使用TensorFlow和PyTorch来监控性能，使用<strong class="je hi"> <em class="lq"> nvidia-smi </em> </strong>监控工具以2ms为步长进行功耗监控。</p><h1 id="1edb" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结果和讨论</h1><h2 id="c0f5" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">中央处理器（central processing units的缩写）</h2><p id="fe24" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">为了利用CPU的众核和单指令多指令多指令(T21指令)能力，多线程和高级向量是选项。通过增加合成基准的线程数量，可以观察到线性的改进。比较矩阵乘法和卷积核的结果表明<strong class="je hi">卷积运算有进一步改进的潜力，因为它们的低级运算不会造成内存瓶颈</strong>。</p><p id="7dd2" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">对于端到端训练，在Inception v3、ResNet50和vgg16卷积网络以及2层LSTM上，线程数量的增加会带来更高的性能。但是，对于Deep Speech 2，线程的最佳数量是8，数据预处理线程可能会缺少CPU资源，从而导致性能下降。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lr"><img src="../Images/7ab13f62ef6f310a39e11aecc6c174ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jLDCOZqbLm7t62EDycwJGw.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><h2 id="1d1d" class="kr if hh bd ig ks kt ku ik kv kw kx io jn ky kz is jr la lb iw jv lc ld ja le bi translated">GPU和TPU</h2><p id="2971" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在合成数据上，TPU v2显示了其优于GPU的优势，这是一个显而易见的事实，因为它们是专门为矩阵乘法而构建的。</p><p id="c70c" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">对于端到端培训，下图描述了FP32上的小批量和V100 GPU上的混合精度的影响。它表明批处理大小的增加通常会导致更高的性能和利用率，并且在ResNet50模型中对混合精度更有效。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es ls"><img src="../Images/4d8b60d4756a97dbc2e664e345749849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ko5RxgJw6t9RlFLHUXK8g.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><p id="f475" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">另一个有趣的观察结果是，虽然从FP32切换到混合精度导致ResNet50的性能提高了2倍，但是张量核心利用率约为9%。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lt"><img src="../Images/7acd45b08c9cccaa2e5363d397978fcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S8zBiemanDPRmdPQTPTYAw.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><p id="9464" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">TPU在性能上显示了相对于V100 GPU的优越性。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lu"><img src="../Images/93bab075dceaab6e39cfbeea1513e738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K97BTWRN2_fE7mbkZd16PQ.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><p id="09e6" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated">最后，他们在下图中比较了不同GPU的能效。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lv"><img src="../Images/3b54f4322de63bffca4c1b79a58fd772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90mI5LRLTDTqm0H09iEFoQ.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx">image credit [<strong class="bd ig">1</strong>]</figcaption></figure><h1 id="2663" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="fd48" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">王，等。、“<strong class="je hi">为人工智能训练对人工智能加速器的性能和能效进行基准测试，</strong>”，载于<em class="lq">第20届IEEE/ACM集群、云计算和互联网计算国际研讨会(</em><strong class="je hi"><em class="lq">cc grid</em></strong><em class="lq">)</em>，澳大利亚墨尔本，<strong class="je hi"> 2020 </strong>第744–751页。</p><p id="7b95" class="pw-post-body-paragraph jc jd hh je b jf lg jh ji jj lh jl jm jn li jp jq jr lj jt ju jv lk jx jy jz ha bi translated"><strong class="je hi"> 2 </strong>何，，等.<strong class="je hi">深度残差学习用于图像识别。</strong><em class="lq">IEEE计算机视觉与模式识别会议论文集</em>。<strong class="je hi"> 2016 </strong>。</p><div class="lw lx ez fb ly lz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ma ab dw"><div class="mb ab mc cl cj md"><h2 class="bd hi fi z dy me ea eb mf ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mg l"><h3 class="bd b fi z dy me ea eb mf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mh l"><p class="bd b fp z dy me ea eb mf ed ef dx translated">medium.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn kl lz"/></div></div></a></div></div></div>    
</body>
</html>
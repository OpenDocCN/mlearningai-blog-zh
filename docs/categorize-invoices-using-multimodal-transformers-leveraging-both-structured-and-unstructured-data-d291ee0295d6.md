# ä½¿ç”¨å¤šæ¨¡å¼è½¬æ¢å™¨å¯¹å‘ç¥¨è¿›è¡Œåˆ†ç±»:åˆ©ç”¨ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/categorize-invoices-using-multimodal-transformers-leveraging-both-structured-and-unstructured-data-d291ee0295d6?source=collection_archive---------0----------------------->

![](img/4557b1be6ec68f8ea27c47172f057710.png)

How to know the category of invoices automatically? (Source: [Unsplash](https://unsplash.com/photos/0rHxkbcvQAE))

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å¯¹æˆ‘ä»¬çš„â€œ**å¤šæ¨¡æ€â€æ•°æ®**çš„é¢„è®­ç»ƒ BERT æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æŒ‰ç…§ç±»åˆ«å¯¹å‘ç¥¨è¿›è¡Œ**å¤šç±»åˆ«åˆ†ç±»ã€‚**

1.  å•†ä¸šç†è§£
2.  å·¥ä½œç¯å¢ƒå‡†å¤‡
3.  æ•°æ®ç†è§£
4.  ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€å˜å‹å™¨ï¼Ÿ
5.  æ•°æ®å‡†å¤‡
6.  å»ºæ¨¡
7.  è¯„ä¼°ç»“æœ

# 1.å•†ä¸šç†è§£

é¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¿™ç¯‡æ–‡ç« çš„å•†ä¸šæ–¹é¢ã€‚

äº‹å®ä¸Šï¼Œåœ¨å¤§å¤šæ•°ç»„ç»‡ä¸­ï¼Œæ¯å¼ å‘ç¥¨éƒ½è¢«å½’å…¥ä¸€ä¸ªç‰¹å®šçš„ç±»åˆ«ã€‚å®é™…ä¸Šï¼Œå¦‚æœé›‡å‘˜å‘ç”Ÿäº†ç»´ä¿®æˆ–ç»´æŠ¤åŠå…¬å®¤è®¾æ–½æˆ–è®¾å¤‡çš„è´¹ç”¨ï¼Œè¿™äº›å‘ç¥¨å°†è¢«å½’å…¥â€œç»´ä¿®å’Œç»´æŠ¤â€ç±»åˆ«ã€‚

å› æ­¤ï¼Œè¯¥ç±»åˆ«æ˜¯åˆ›å»ºè´¹ç”¨æŠ¥å‘Šçš„é‡è¦ä¿¡æ¯ï¼Œä»¥ä¾¿ä¸ºå‘˜å·¥æŠ¥é”€ç¬¦åˆæ¡ä»¶çš„ä¸šåŠ¡è´¹ç”¨ï¼Œå¹¶è·Ÿè¸ªæ•´ä¸ªç»„ç»‡çš„è´¹ç”¨æˆ–ä¸ç‰¹å®šäº§å“ã€å®¢æˆ·æˆ–é¡¹ç›®ç›¸å…³çš„è´¹ç”¨ã€‚

å°½ç®¡å¯¹è´¹ç”¨è¿›è¡Œåˆ†ç±»æ˜¯ä¸€é¡¹éœ€è¦å®Œæˆçš„é‡è¦ä»»åŠ¡ï¼Œä½†æ˜¯æ‰‹åŠ¨è¿›è¡Œåˆ†ç±»æ˜¯ä¸€é¡¹çœŸæ­£çš„è´Ÿæ‹…ï¼Œå¹¶ä¸”ä¼šæµªè´¹æ—¶é—´å’Œèµ„æºã€‚å½“æˆ‘ä»¬éœ€è¦ä»å‘ç¥¨ä¸­æå–æ•°æ®(å¦‚æ—¥æœŸã€TTC é‡‘é¢ã€ç¨æ”¶å’Œå–æ–¹)æ—¶ï¼Œä¹Ÿä¼šå‡ºç°åŒæ ·çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œéšç€æ·±åº¦å­¦ä¹ æ¨¡å‹(å¦‚ Transformers)çš„æœ€æ–°è¿›å±•ï¼Œå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ä»¥æ»¡è¶³ç‰¹å®šçš„ä¸šåŠ¡éœ€æ±‚å˜å¾—æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´å®¹æ˜“ã€‚ä½ éœ€è¦çš„åªæ˜¯é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚

å¯¹äºå‘ç¥¨æå–ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ªæ³¨é‡Šå·¥å…·ï¼Œå®ƒæä¾› OCR æ³¨é‡Šæ¥è§£æå‘ç¥¨ä¸­çš„æ–‡æœ¬å’Œè¾¹ç•Œæ¡†ï¼Œå¹¶å…è®¸æœ¬åœ°æ ‡è®°ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘æ‰¾åˆ°äº†ä¸€ä¸ªåä¸º [UBIAI](https://ubiai.tools/) çš„å·¥å…·ï¼Œå®ƒå°†ä½¿ä½ èƒ½å¤Ÿç›´æ¥æ ‡è®°ä½ çš„å‘ç¥¨ï¼Œè¿˜å¯ä»¥è®­ç»ƒ LayoutLM ç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹è‡ªåŠ¨ä»å‘ç¥¨å›¾åƒä¸­æå–ä¿¡æ¯(å¦‚ä¸‹å›¾æ‰€ç¤º)ã€‚

![](img/46ccc95d8cfb9e7580734145520d4749.png)

UBIAIâ€™s OCR Annotation (Source: [UBIAI.tools](https://ubiai.tools/features/r1-ocr-annotation-feature))

é‰´äºä¸Šè¿°ä¿¡æ¯(æ—¥æœŸã€é‡‘é¢ _TTCã€ç¨æ¬¾â€¦â€¦)åœ¨å‘ç¥¨ä¸Šæ˜ç¡®æ³¨æ˜ï¼Œæˆ‘ä»¬ä½¿ç”¨ UBIAI æ³¨é‡Šå·¥å…·æå–è¿™äº›ä¿¡æ¯ï¼Œä½†å‘ç¥¨ä¸Šå¹¶æœªç›´æ¥æåŠç±»åˆ«ä¿¡æ¯ï¼Œå› æ­¤å¿…é¡»ä»æˆ‘ä»¬ä½¿ç”¨ UBIAI å·¥å…·æå–çš„æ•°æ®ä¸­æ¨æ–­(æ‰£é™¤)è¿™äº›ä¿¡æ¯ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»ä»‹ç»äº†ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼Œè®©æˆ‘ä»¬å‡†å¤‡å·¥ä½œç¯å¢ƒæ¥å®ç°æˆ‘ä»¬çš„å‘ç¥¨ç±»åˆ«åˆ†ç±»æ¨¡å‹ã€‚

# 2.å·¥ä½œç¯å¢ƒå‡†å¤‡

å¯¹äºæœ¬æ–‡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†[å…¬å¼€å¯ç”¨çš„æ•°æ®é›†](http://github.com/50gramx/guess-the-product/blob/master/train_set.csv)â€”â€”æˆ‘ä»¬å¯¹å…¶è¿›è¡Œäº†è½»å¾®çš„è°ƒæ•´å’Œè¡¥å……ä»¥é€‚åº”æˆ‘ä»¬çš„ä¸šåŠ¡éœ€æ±‚â€”â€”æ¥è®­ç»ƒæˆ‘ä»¬çš„å¤šæ¨¡å‹è½¬æ¢å™¨ã€‚

æˆ‘ä»¬ä½¿ç”¨ Google Colab ä½œä¸º python çš„ web IDEï¼Œå®ƒæ˜¯å…è´¹çš„ï¼Œæ‰€ä»¥ç»§ç»­åˆ›å»ºä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬ï¼Œä»¥æœ€ç®€å•çš„æ–¹å¼è·Ÿéšæˆ‘ä»¬ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥æˆ‘ä»¬å°†ä½¿ç”¨çš„åº“:

```
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.metrics import f1_score, matthews_corrcoef!pip install multimodal-transformers
from transformers import AutoTokenizer, AutoConfig, Trainer, EvalPrediction, set_seed
from transformers.training_args import TrainingArgumentsfrom multimodal_transformers.data import load_data_from_folder
from multimodal_transformers.model import TabularConfig
from multimodal_transformers.model import AutoModelWithTabular
```

ä¸è¦æ‹…å¿ƒå¯¼å…¥çš„æ•°é‡ï¼Œæˆ‘ä»¬ä¼šåœ¨ç›¸å…³çš„æ—¶å€™çœ‹åˆ°æ¯ä¸€ä¸ªçš„ä½¿ç”¨ã€‚ä½†æ˜¯ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­æ¥çœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®ã€‚

# 3.æ•°æ®ç†è§£

å¦‚ä¸Šæ‰€è¿°ï¼Œç±»åˆ«æ˜¯æˆ‘ä»¬å°†ä»å½“å‰å‘ç¥¨ä¿¡æ¯ä¸­æ¨æ–­å‡ºçš„ä¸€æ¡ä¿¡æ¯:

```
df = pd.read_csv('/content/categorized ocr_annotated_invoices.csv')
df.head()
```

![](img/4cadfaa86ce08d2b4ea8b80bffd71e6c.png)

The head (first 5 rows) of the df data frame

```
df.describe()
```

![](img/e7bb92732e50ace8e52f5062a3497cd2.png)

Descriptive statistics of df

```
df.info()
```

![](img/fcdff052d5971a095380ab2c2ca44625.png)

Summary info of df

æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬çš„æ•°æ®æ˜¯ä¸€ç»„å‘ç¥¨ï¼Œè¿™äº›å‘ç¥¨ç±»ä¼¼äº UBIAI æ³¨é‡Šå·¥å…·æ­£åœ¨å¤„ç†çš„å‘ç¥¨(æˆ‘ä»¬åªé€‰æ‹©äº†å‡ åˆ—è¿›è¡Œå¤„ç†)ï¼Œå®ƒä»¬ä»¥è¡¨æ ¼æ ¼å¼å‘ˆç°ï¼›æ¯è¡Œä»£è¡¨ä¸€å¼ å‘ç¥¨(è§‚å¯Ÿ)ã€‚æ¯åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å¾(é¢„æµ‹å€¼)ï¼Œä¾‹å¦‚*é‡‘é¢ _TTC* ã€*å¢å€¼ç¨ _ å¢å€¼ç¨*ã€*å–æ–¹ _IDã€*å’Œ*å‘ç¥¨ _ æè¿°*ã€‚æ•°æ®è¢«æ ‡è®°ï¼Œç›®æ ‡å˜é‡æ˜¯*ç±»åˆ« ID* ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬å°†åŸºäºå…¶ä»–ç‰¹å¾æ¥é¢„æµ‹ *Category_ID* ã€‚è®©æˆ‘ä»¬è®¡ç®—æ•°æ®é›†ä¸­å‡ºç°çš„ä¸åŒç±»åˆ«çš„æ•°é‡:

```
number_categories = df.Category_ID.nunique()print("We have ", number_categories, " classes, so it's a Multiclass Classification")
```

æˆ‘ä»¬æœ‰ 36 ä¸ªç±»ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªå¤šç±»åˆ†ç±»ã€‚

# 4.å¤šæ¨¡å¼å˜å‹å™¨

ä½¿ç”¨éç»“æ„åŒ–æ–‡æœ¬æ•°æ®çš„åŸºäº Transformer çš„æ¨¡å‹éå¸¸å¼ºå¤§ï¼Œå¾—åˆ°äº†å¹¿æ³›çš„è®¨è®ºï¼Œå¹¶ä¸”è¢«å¹¿æ³›ä½¿ç”¨ã€‚ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ**æˆ‘ä»¬ç¡®å®æœ‰æ–‡æœ¬æ•°æ®å‘ˆç°åœ¨ *Invoice_Description* åˆ—ä¸­ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿæœ‰æœ‰ä»·å€¼çš„ç»“æ„åŒ–æ•°æ®**ã€‚å¯¹äºå…·æœ‰ç»“æ„åŒ–æ•°æ®çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬æœ‰ *Seller_ID* ã€ *VAT_TVA* å’Œ *Amount_TTC* ï¼Œè¿™äº›ç‰¹æ€§ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¸¦æ¥äº†å•ä¸ªç‰¹æ€§æ— æ³•æä¾›çš„ä¿¡æ¯ã€‚

æˆ‘ä»¬ç§°è¿™äº›ä¸åŒçš„æ„ŸçŸ¥æ•°æ®çš„æ–¹å¼(éç»“æ„åŒ–æ–‡æœ¬ï¼Œç»“æ„åŒ–æ•°å­—æ•°æ®â€¦) **æ¨¡æ€**ã€‚å°†æ¥è‡ªå‡ ä¸ªæ¨¡æ€çš„ä¿¡æ¯ç»“åˆèµ·æ¥è¿›è¡Œé¢„æµ‹è¢«ç§°ä¸ºâ€œå¤šæ¨¡æ€èåˆâ€ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å†³å®šä½¿ç”¨[multimodal-transformers](https://github.com/georgian-io/Multimodal-Toolkit)åŒ…ï¼Œç”¨æœ€ç®€å•çš„è¯æ¥è¯´ï¼Œå®ƒå°†æ–‡æœ¬æ•°æ®ä¸Šçš„ transformer æ¨¡å‹çš„è¾“å‡ºä¸åˆ†ç±»å’Œæ•°å­—ç‰¹å¾ä¸­çš„ç»“æ„åŒ–æ•°æ®ç›¸ç»“åˆã€‚

# 5.æ•°æ®å‡†å¤‡

æ—¢ç„¶æˆ‘ä»¬å·²ç»ç†Ÿæ‚‰äº†æˆ‘ä»¬çš„ä¸šåŠ¡æ¡ˆä¾‹ã€æ•°æ®å±æ€§å’Œé€‚å½“çš„å·¥å…·ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹å‡†å¤‡æ•°æ®é›†äº†ã€‚

æˆ‘ä»¬å®šä¹‰äº†å­—å…¸ *column_info* ï¼Œå…¶ä¸­æˆ‘ä»¬å°†æŒ‡å®šå“ªäº›åˆ—åŒ…å«æ–‡æœ¬æ•°æ®ã€æ•°å­—æ•°æ®ã€åˆ†ç±»æ•°æ®å’Œç›®æ ‡å˜é‡:

```
column_info = {
'text_cols': ['Invoice_Description'],
'num_cols': ['VAT_TVA', 'Amount_TTC'],
'cat_cols': ['Seller_ID'],
'label_col': 'Category_ID',
# 'label_list': list(df.Category_ID.unique( ))
}
```

é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥å°†æ ‡ç­¾åˆ— *Category_ID* ç¼–ç ä¸º transformersã€‚Trainer ä¸å¤„ç†å®šæ€§æ ‡ç­¾åˆ—ï¼Œå®ƒå¸Œæœ›æ ‡ç­¾åˆ—åŒ…å«ä» 0 åˆ°ç±»åˆ«æ•°-1 çš„æ•´æ•°:

```
encoder = preprocessing.LabelEncoder( )df["Category_ID"] = encoder.fit_transform(df['Category_ID']).astype(int)
```

> æ³¨æ„:å¯¹ç‰¹å¾è¿›è¡Œç¼–ç æœ‰å¤šç§æ–¹å¼ï¼Œæˆ‘ä»¬è¿™é‡Œç”¨çš„æ˜¯ sk learn . preprocessing . labelen coder(ï¼è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨è¦ä½¿ç”¨æ­¤æ–¹æ³•å¯¹éæ ‡ç­¾ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œæ‚¨åº”è¯¥å°å¿ƒåœ¨ç»´åº¦ä¸­åˆ›å»ºé”™è¯¯åºå·é‡è¦æ€§çš„å¯èƒ½æ€§ï¼Œå› æ­¤æ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨ sk learn . preprocessing . onehotencoder)ã€‚

ä¸ºäº†å»ºç«‹ä¸€ä¸ªå¯é çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä¸åº”è¯¥ä½¿ç”¨ç›¸åŒçš„æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†:

```
train_df, validation_df, test_df = np.split(df.sample(frac = 1), [int(.8 * len(df)), int(.9 * len(df))])print('TRAIN DATA is ~80% :', len(train_df))
print('VALIDATION DATA is ~10% :', len(validation_df))
print('TEST DATA is ~10% :', len(test_df))train_df.to_csv('train.csv')
validation_df.to_csv('val.csv')
test_df.to_csv('test.csv')
```

![](img/e628a1697697c70f3a7197f6aad2249d.png)

Splitting the data

> æ³¨æ„:æˆ‘ä»¬å°† 3 å¥—ä¿å­˜åœ¨ csv æ–‡ä»¶ä¸­ï¼Œæ–‡ä»¶åå¿…é¡»ä¸º train.csvã€test.csv å’Œ val.csvï¼Œå¦åˆ™ multimodal _ transformers . data .**load _ data _ from _ folder**å‡½æ•°å°†æ— æ³•åŠ è½½å®ƒä»¬ã€‚

ç„¶åï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åŠ è½½åˆ° TorchTabularTextDataset ä¸­ï¼Œå®ƒå°†åŒ…æ‹¬ HuggingFace è½¬æ¢å™¨çš„æ–‡æœ¬è¾“å…¥ï¼Œä»¥åŠæˆ‘ä»¬æŒ‡å®šçš„åˆ†ç±»å’Œæ•°å­—ç‰¹å¾åˆ—ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆåŠ è½½æˆ‘ä»¬çš„ HuggingFace æ ‡è®°å™¨:

```
pretrained_model_name = 'bert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)train_dataset, validation_dataset, test_dataset = load_data_from_folder(folder_path = '.',
                       text_cols = column_info['text_cols'],
                       tokenizer = tokenizer,
                       label_col = column_info['label_col'],
                       # label_list = column_info['label_list'],
                       categorical_cols = column_info['cat_cols'],
                       numerical_cols = column_info['num_cols'],
                       sep_text_token_str = tokenizer.sep_token,
)
```

æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨é¢„è®­ç»ƒçš„ BERT åŸºç¡€æ¨¡å‹(æœªè£…ç®±)ï¼Œæ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œæ‚¨å¯ä»¥ä»[è¿™é‡Œ](https://huggingface.co/models)é€‰æ‹©å¦ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚

> æ³¨æ„:ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹(å¦‚ BERT)æ—¶ï¼Œä¸éœ€è¦è¿›è¡Œæ–‡æœ¬é¢„å¤„ç†ï¼Œå®ƒä½¿ç”¨å¥å­ä¸­çš„æ‰€æœ‰ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡ç‚¹ç¬¦å·å’Œåœç”¨è¯ã€‚

# 6.å»ºæ¨¡

ç°åœ¨æ¥ä¸‹æ¥è¦åšçš„äº‹æƒ…æ˜¯ç”¨è¡¨æ ¼æ¨¡å‹åŠ è½½æˆ‘ä»¬çš„è½¬æ¢å™¨ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬åœ¨ TabularConfig å¯¹è±¡ä¸­æŒ‡å®šæˆ‘ä»¬çš„è¡¨æ ¼é…ç½®ï¼Œåœ¨è¯¥å¯¹è±¡ä¸­ï¼Œæˆ‘ä»¬è¿˜æŒ‡å®šæˆ‘ä»¬å¸Œæœ›å¦‚ä½•å°†è¡¨æ ¼ç‰¹æ€§ä¸æ–‡æœ¬ç‰¹æ€§ç›¸ç»“åˆï¼Œå¹¶ä¸”æˆ‘ä»¬å°†ä½¿ç”¨åŠ æƒæ±‚å’Œæ–¹æ³•ã€‚

å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªé…ç½®å®šä¹‰ä¸º HuggingFace è½¬æ¢å™¨çš„ BertConfig å¯¹è±¡çš„ tabular_config æˆå‘˜å˜é‡ã€‚

ä¸€æ—¦æˆ‘ä»¬å®šä¹‰äº† model_configï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ hugging face multimodal _ transformers . model . automodelwithfatable .**from _ pre trained**æ–¹æ³•åŠ è½½æ¨¡å‹ã€‚

```
tabular_config = 
TabularConfig(
        num_labels = number_categories,
        cat_feat_dim = train_dataset.cat_feats.shape[1],
        numerical_feat_dim = train_dataset.numerical_feats.shape[1],
        combine_feat_method =     'weighted_feature_sum_on_transformer_cat_and_numerical_feats'
) model_config = AutoConfig.from_pretrained('bert-base-uncased')
model_config.tabular_config = tabular_config model = AutoModelWithTabular.from_pretrained('bert-base-uncased', config = model_config)
```

åŠ è½½æ¨¡å‹åï¼Œåœ¨å¯¹æˆ‘ä»¬çš„æ•°æ®è¿›è¡Œè®­ç»ƒä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€äº›ç›¸å…³çš„è¯„ä¼°æŒ‡æ ‡æ¥æä¾›å¯¹æ¨¡å‹æ€§èƒ½çš„æ·±å…¥äº†è§£ï¼Œå› æ­¤æˆ‘ä»¬å®šä¹‰äº†è¿”å›ç²¾åº¦ã€F1 åˆ†æ•°å’Œ Matthew ç›¸å…³ç³»æ•°çš„å‡½æ•°:

```
def calculate_classification_metrics(p: EvalPrediction): predicted_labels = np.argmax(p.predictions, axis = 1)
  expected_labels = p.label_ids accuracy = (predicted_labels == expected_labels).mean( )
  f1 = f1_score(y_true = expected_labels, y_pred = predicted_labels, average = 'micro') eval_result = {
         "acc": accuracy,
         "f1": f1,
         "mcc": matthews_corrcoef(expected_labels, predicted_labels)
  } return eval_result
```

æ­¤æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå› æ­¤åªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ğŸ‰ï¼š

1.  åœ¨è®­ç»ƒå‚æ•°ä¸­å®šä¹‰è®­ç»ƒè¶…å‚æ•°ã€‚
2.  å°†æˆ‘ä»¬çš„è®­ç»ƒå‚æ•°ä»¥åŠæˆ‘ä»¬çš„æ•°æ®é›†ã€æ¨¡å‹å’Œè¯„ä¼°å‡½æ•°ä¼ é€’ç»™åŸ¹è®­å¸ˆã€‚
3.  è°ƒç”¨ train()æ¥å¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
training_args = TrainingArguments(output_dir = "./UBIAI/model_out",
                                  logging_dir = "./UBIAI/run_logs",
                                  overwrite_output_dir = True,
                                  do_train = True,
                                  do_eval = True,
                                  per_device_train_batch_size = 32,
                                  num_train_epochs = 1,
                                  evaluate_during_training = True,
                                  logging_steps = 5,
                                  eval_steps = 54)
set_seed(training_args.seed)trainer = Trainer(model = model,
                 args = training_args,
                 train_dataset = train_dataset,
                 eval_dataset = validation_dataset,
                 compute_metrics = calculate_classification_metrics) trainer.train( )
```

![](img/7cad9e2b3b47ab58463647d5632d37da.png)

trainer.train( )

# 7.ä¼°ä»·

è®­ç»ƒå®Œæ¨¡å‹åï¼Œè®©æˆ‘ä»¬çœ‹çœ‹éªŒè¯æŒ‡æ ‡:

```
# Load the TensorBoard notebook extension
%load_ext tensorboard
%tensorboard --logdir ./UBIAI/run_logs --port=6006
```

![](img/6401e5a2aca58b7389f1e890b4940396.png)

Training validation metrics

ä½œä¸ºæ¨¡å‹é¢„æµ‹çš„å®é™…æ¼”ç¤ºï¼Œæˆ‘ä»¬ç°åœ¨å°†å¯¹ä¸€äº›æ–°å‘ç¥¨è¿è¡Œé¢„æµ‹ï¼Œè¿™äº›å‘ç¥¨ä¸æ˜¯ç”¨äºå¾®è°ƒæ¨¡å‹çš„è®­ç»ƒé›†æˆ–éªŒè¯é›†çš„ä¸€éƒ¨åˆ†:

```
# Save our model
trainer.save_model ("./UBIAI/model_out") # Load it
model = AutoModelWithTabular.from_pretrained("./UBIAI/model_out", local_files_only=True)trainer = Trainer(model=model) # Predict with it
y_predicted = [list(i).index(max(i)) for i in trainer.predict(test_dataset).predictions]print("â¡ï¸Predicted categories for the test data set:", y_predicted)# Evaluate the prediction
precision = sum(1 for x,y in zip(y_predicted,test_dataset.labels) if x == y) / float(len(y_predicted))print("ğŸ¥³ Our model is able to predict the invoice category with an accuracy score of", round(precision*100), "%")
```

![](img/527c321ba4e91011099062733bfa41c7.png)

Post-training prediction test results

> æ³¨æ„:è®©æˆ‘ä»¬è®°ä½ 3 ä¸ªæ•°æ®é›†çš„ç”¨é€”:
> 
> ***-****train _ dataset*ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œè®©å®ƒå­¦ä¹ æ•°æ®ä¸­çš„éšè—æ¨¡å¼ã€‚
> 
> ***-****validation _ dataset*ç”¨äºéªŒè¯æˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒæ—¶çš„è¡¨ç°ã€‚
> 
> **-** test_dataset ç”¨äºå®Œæˆè®­ç»ƒåå¯¹æ¨¡å‹è¿›è¡Œæµ‹è¯•ã€‚

# ç»“è®º

é€šè¿‡å¤„ç†åŒ…å«ç»“æ„åŒ–æ•°æ®(Amount_TTCâ€¦)å’Œéç»“æ„åŒ–æ•°æ®(Invoice_Description)çš„å¸¦æ³¨é‡Šçš„å‘ç¥¨ï¼Œæˆ‘ä»¬èƒ½å¤ŸåŠ è½½ä¸€ä¸ªåˆ©ç”¨æ–‡æœ¬å’Œç»“æ„åŒ–æ•°æ®çš„è¡¨æ ¼æ¨¡å‹çš„è½¬æ¢å™¨ï¼Œæ ¹æ®æˆ‘ä»¬çš„æ•°æ®å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿä»¥å¤§çº¦ 95%çš„ç²¾åº¦é¢„æµ‹å‘ç¥¨çš„ç±»åˆ«ã€‚

> *é“¾æ¥åˆ° Colab* [*ç¬”è®°æœ¬*](https://colab.research.google.com/drive/1gx_f0mth2PzPbzt8geSpOJEqJUJnXzPp?usp=sharing) *ã€‚(*æ‰€æœ‰éæ¥æºè§†è§‰å‡æ¥è‡ªæ­¤å¤„æˆªå›¾ *)*
> 
> *å¦‚æœä½ æœ‰å…´è¶£äº†è§£* ***å¦‚ä½•ä»éç»“æ„åŒ–æ•°æ®(å›¾ç‰‡ã€æ–‡æ¡£â€¦â€¦)****ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯(æ—¥æœŸã€é‡‘é¢ _ TTCâ€¦â€¦)ï¼Œå¯ä»¥è€ƒè™‘é˜…è¯»æ¥è‡ª UBIAI* *çš„* [*è¿™ç¯‡æ–‡ç« ã€‚*](https://ubiai.tools/blog/article/Fine_tuning_LayoutLM)

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai æäº¤å»ºè®®

### å¦‚ä½•æˆä¸º Mlearning.ai ä¸Šçš„ä½œå®¶

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
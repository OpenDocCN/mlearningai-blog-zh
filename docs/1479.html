<html>
<head>
<title>Brain Tumor Segmentation using Deep Learning models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习模型的脑肿瘤分割</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/brain-tumor-segmentation-using-deep-learning-models-5047984b53c0?source=collection_archive---------1-----------------------#2021-12-24">https://medium.com/mlearning-ai/brain-tumor-segmentation-using-deep-learning-models-5047984b53c0?source=collection_archive---------1-----------------------#2021-12-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="ab05" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">一种使用脑部MRI分割肿瘤的深度学习方法。</p></blockquote><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/9d3bc27c6d2cef0716ebe749b9bc7bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5n4MHs1cGh6RrZJs.jpg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx"><strong class="bd jw">Source </strong>— <a class="ae jx" href="https://health.clevelandclinic.org/what-are-the-actual-warning-signs-of-a-brain-tumor/" rel="noopener ugc nofollow" target="_blank">Cleveland clinic</a></figcaption></figure><blockquote class="jy"><p id="343a" class="jz ka hh bd kb kc kd ke kf kg kh jf dx translated"><strong class="ak">摘要— </strong>用于脑肿瘤分割的精确自动算法具有改进疾病诊断、治疗计划以及实现大规模病理学研究的潜力。本文介绍了两个深度学习模型的实现，这两个模型用于使用Kaggle上的数据集中可用的图像来分割脑肿瘤。</p></blockquote><h1 id="48d6" class="ki kj hh bd jw kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">介绍</h1><p id="f7bf" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">仅在美国，据估计2015年将诊断出23，000例脑癌新病例。<a class="ae jx" href="http://www.sciencedirect.com.dtulibrary.remotexs.in/science/article/pii/S1361841516300330#fn0001" rel="noopener ugc nofollow" target="_blank"> 1 </a>虽然神经胶质瘤是最常见的脑肿瘤，但在预期寿命为几年的患者中，神经胶质瘤的侵袭性较低(即低级别)，在预期寿命至多为2年的患者中，神经胶质瘤的侵袭性较高(即高级别)。</p><p id="6f45" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">虽然外科手术是脑瘤最常见的治疗方法，但放射和化学疗法可以用来减缓不能用物理方法切除的肿瘤的生长。磁共振成像(MRI)提供大脑的详细图像，并且是用于诊断脑肿瘤的最常见的测试之一。更重要的是，从MR图像中分割脑肿瘤可以对改进诊断、生长率预测和治疗计划产生重大影响。</p><p id="b0a6" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">脑肿瘤影像分析的最终目的是提取患者特异性的重要临床信息及其诊断特征。嵌入在多维图像数据中的这种信息可以在疾病已经被检测和定位之后指导和监控干预，最终导致疾病的临床诊断、分期和治疗的知识。</p><h1 id="9cfa" class="ki kj hh bd jw kk kl km kn ko kp kq kr ks ln ku kv kw lo ky kz la lp lc ld le bi translated">了解数据集</h1><p id="9adb" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">本文所指的数据集摘自kaggle，<a class="ae jx" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" rel="noopener ugc nofollow" target="_blank">《脑MRI分割》</a>。</p><p id="a71a" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">它最初是从癌症成像档案馆的110名患者那里收集的。数据集包含110个文件夹，每个文件夹对应一名患者。每个文件夹都包含磁共振图像及其遮罩。总共有3929个图像和掩模对，每个患者平均有35.71个MR图像。为了增加图像的数量，使用以下参数进行数据扩充— <em class="ij"> rotation_range=0.2，width_shift_range=0.05，height_shift_range=0.05，shear_range=0.05，zoom_range=0.05，horizontal_flip=True，fill _ mode =‘nearest’。</em></p><p id="e1fd" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">为了测试这些模型，完整的数据集被分成两部分——按70:30的比例进行训练和测试。</p><h1 id="d649" class="ki kj hh bd jw kk kl km kn ko kp kq kr ks ln ku kv kw lo ky kz la lp lc ld le bi translated">深度学习模型</h1><p id="688e" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">在数据集上实现两个深度学习模型来分割肿瘤。</p><h2 id="e1fa" class="lq kj hh bd jw lr ls lt kn lu lv lw kr lh lx ly kv lj lz ma kz ll mb mc ld md bi translated">UNet</h2><p id="3536" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">UNET由Olaf Ronneberger等人开发，用于生物医学图像分割。该架构包含两条路径，收缩路径也称为编码器，用于捕获图像中的上下文。编码器只是一个传统的卷积和最大池层堆栈。编码器路径之后是解码器路径或对称扩展路径，用于使用转置卷积实现精确定位。因此，它是一个端到端的完全卷积网络(FCN)，即它只包含卷积层，不包含任何密集层，因此它可以接受任何大小的图像。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es me"><img src="../Images/a918464e1ac736be471df5eef308a03d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fxO2KqzbUHzVwuOU.png"/></div></figure><p id="3115" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">培养</p><p id="d9c4" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">为了训练用于分割的UNet模型，将256×256×3的图像作为输入馈送到模型中。训练在35个时期进行，批次大小为32。</p><h2 id="a70d" class="lq kj hh bd jw lr ls lt kn lu lv lw kr lh lx ly kv lj lz ma kz ll mb mc ld md bi translated">Linknet</h2><p id="a06d" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">LinkNet是一种<em class="ij">轻型</em>深度神经网络架构，旨在执行语义分割，可用于自动驾驶车辆、增强现实等任务。</p><p id="6f9c" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">在每个下采样块之后，Linknet架构试图有效地与解码器共享由编码器学习的信息。这被证明比在解码器中使用汇集索引或仅在解码器中使用完全卷积网络要好。这种特征转发技术不仅给了我们良好的精度值，而且使我们能够在解码器中具有较少的参数。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mf"><img src="../Images/95e5ac056ef00f8c0085f170d5f39ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*Ch3s-hgbZqgtrLkmzJUG-Q.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Linknet Architecture</figcaption></figure><p id="179a" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated"><strong class="ik hi">编码器和解码器— </strong>在所示的编码器和解码器块中，可以使用<strong class="ik hi"> <em class="ij"> n = 64x2^i </em> </strong>来计算每层的输入和输出特征图，其中<strong class="ik hi"> <em class="ij"> i </em> </strong>块索引。第一编码器块不执行步进卷积，并且每个卷积层之后是批量归一化和作为非线性的ReLU。编码器架构与ResNet-18相同</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mg"><img src="../Images/c003526c93f4bcd36a21a6b21fd849c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*Dq3X-YZSmZMPeb61MA5qxw.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Encoder Decoder blocks</figcaption></figure><p id="f033" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">培养</p><p id="65c2" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">为了训练用于分割的Linknet模型，将256×256×3的图像作为输入输入到模型中。训练在35个时期进行，批次大小为32。</p><h1 id="87fb" class="ki kj hh bd jw kk kl km kn ko kp kq kr ks ln ku kv kw lo ky kz la lp lc ld le bi translated">评估结果</h1><p id="cda8" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">上面提到的两个模型都是在相同的条件下训练和测试的。为最小验证损失设置了回调。</p><p id="f757" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">对于UNet模型，最佳权重给出了0.084的验证损失和99.90%的准确度。下图显示了模型的训练和测试数据的对数损失与历元的关系。最佳权重在图中标记为十字。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mh"><img src="../Images/90d408d59d806fb0cc8de418e48050ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*Al2zVq4kge7fZyTJlK5klQ.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">UNet model results</figcaption></figure><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mi"><img src="../Images/6a5c7de463b802839538aacea93be6bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZadSQVs-EWWs9HXnx4T7cQ.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">Predictions of UNet model</figcaption></figure><p id="4452" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is lh iu iv iw lj iy iz ja ll jc jd je jf ha bi translated">对于Linknet模型，最佳权重给出了0.070的验证损失和99.74%的准确度。下图显示了模型的训练和测试数据的对数损失与历元的关系。最佳权重在图中标记为十字。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mj"><img src="../Images/9954f6699520b234e20af691cf7dfa37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*YSVtBpTqSmS-EL_aHy4v-w.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Linknet model results</figcaption></figure><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mk"><img src="../Images/880c5cdb17bbf0f96a50c7a731c0fdaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*rA-UZjbM8TF6j_3_xq3Q3Q.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Predictions of Linknet model</figcaption></figure><h1 id="131c" class="ki kj hh bd jw kk kl km kn ko kp kq kr ks ln ku kv kw lo ky kz la lp lc ld le bi translated">观察</h1><p id="693c" class="pw-post-body-paragraph ih ii hh ik b il lf in io ip lg ir is lh li iv iw lj lk iz ja ll lm jd je jf ha bi translated">观察到，对于MR图像中的肿瘤分割，Linknet能够产生比UNet模型更少的损失。尽管Linknet不太准确。总的来说，可以看出，这两种模型在医学成像中工作良好，可以在更大的数据集上进行测试，因此可以在医学科学领域中实施，以帮助专家分割肿瘤，并进一步帮助更快地治疗癌症患者。这项研究还可以在其他身体部位的磁共振图像上实施，以检测肿瘤。</p><h1 id="9cc4" class="ki kj hh bd jw kk kl km kn ko kp kq kr ks ln ku kv kw lo ky kz la lp lc ld le bi translated">参考</h1><ol class=""><li id="6949" class="ml mm hh ik b il lf ip lg lh mn lj mo ll mp jf mq mr ms mt bi translated"><a class="ae jx" href="http://doi.org.dtulibrary.remotexs.in/10.1016/j.media.2016.05.004" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.media.2016.05.004</a></li><li id="4164" class="ml mm hh ik b il mu ip mv lh mw lj mx ll my jf mq mr ms mt bi translated">【https://doi.org/10.1016/j.mri.2013.05.002 T2】号</li><li id="9257" class="ml mm hh ik b il mu ip mv lh mw lj mx ll my jf mq mr ms mt bi translated">【https://arxiv.org/abs/1505.04597 T4】</li><li id="cdb7" class="ml mm hh ik b il mu ip mv lh mw lj mx ll my jf mq mr ms mt bi translated"><a class="ae jx" href="https://doi.org/10.1109/VCIP.2017.8305148" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1109/VCIP.2017.8305148</a></li><li id="8fc0" class="ml mm hh ik b il mu ip mv lh mw lj mx ll my jf mq mr ms mt bi translated"><a class="ae jx" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation</a></li></ol><div class="mz na ez fb nb nc"><a href="https://github.com/sakshamchecker/BrainTumorSegmentation" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">GitHub-sakshamchecker/脑瘤分割</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">github.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq jq nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">medium.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq jq nc"/></div></div></a></div></div></div>    
</body>
</html>
# 如果你的人工智能是功利主义者

> 原文：<https://medium.com/mlearning-ai/if-your-ai-was-a-utilitarian-318b1980e549?source=collection_archive---------2----------------------->

> 功利主义——“选择能为最大多数人带来最大利益的结果”

![](img/4cc4faaa21b4c9bbbdd35dd358051c2b.png)

Photo by [Luke Lung](https://unsplash.com/@lukelung1991?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

作为主持人，

(一)你会只做一道大多数人喜欢的菜，而少数客人不喜欢吗？或者(ii)你会做更多种类的菜肴，让所有的客人都满意，尽管这可能意味着你作为主人要付出更多的努力和成本？

如果你的机器人厨师是一个功利主义者，并负责规划派对菜单，它会选择选项(I)。

我们生活的世界是由金钱储蓄和功利主义驱动的，功利主义是商业决策背后的流行推理之一。

关于人工智能将如何解决经典的手推车问题或器官捐献者困境([https://www.youtube.com/watch?v=yg16u_bzjPE](https://www.youtube.com/watch?v=yg16u_bzjPE))的研究和思考不断涌现。然而，这些讨论大多仅限于学术界。在与我们互动的小型和大型系统中注入人工智能的速度比人们所说的“超级舰队爆炸”还要快。以惊人的速度，提取了大量的数据并产生了见解。人们不禁要问，生成这些见解的算法是否对周围发生的事情敏感，并根据“好”和“包容性”做出决策。

我们或算法如何决定什么是“好”，这是一个从人类文明开始以来最伟大的哲学家一直在思考的话题。

在机器人陪审团的情况下，它的认知能力足以对相对简单的案件做出判断，算法会反映编写代码的数据科学家的哲学/思想/信仰，或推动需求的业务经理的哲学/思想/信仰，还是一些共同的“好”哲学，或明确定义期望的法律框架？

让我们看看更多功利主义的例子。

一个雇佣机器人算法被训练来雇佣人。目标 1 是通过在线考试测试技能，根据候选人的回答调整问题的难度和权重，以便找到最适合该工作的人。它还接受了第二个目标的培训，以最大限度地实现目标，以便尽可能多的职位可以使用这种人工智能驱动的招聘软件来实现。如果没有正确调整目标 2 的权重，算法可能会通过将在线测试问题调整为更简单的问题而变得功利。这将最大限度地满足目标 2 的候选人到工作的映射，但是将导致劳动力质量差。

一个莫扎特机器人，如果只训练一个月的关于在音乐会上演奏的作品和门票销售的数据，可能只会建议和演奏有限数量的曲子。它将无法欣赏多样性的美，以及音乐家需要如何试验新的曲调和作品来保持创造力以及观众的兴趣。

数据集的多样性对于让你的人工智能真正具有认知能力至关重要。做人意味着冒着暂时的困难或损失的风险去尝试新事物。功利主义的心态可能导致在短期获利的假设下生活变得世俗。

根据数据，从长远来看，有道德和创新的公司更有利可图。现在需要与数据科学团队就“伦理”和“人类价值”展开对话。

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
<html>
<head>
<title>Neural Data Augmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经数据增强</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/neural-data-augmentation-2330318e8430?source=collection_archive---------4-----------------------#2021-02-12">https://medium.com/mlearning-ai/neural-data-augmentation-2330318e8430?source=collection_archive---------4-----------------------#2021-02-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="68a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇博客文章展示了谷歌最近发表的关于使用文本到文本转换转换器(<a class="ae jc" href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" rel="noopener ugc nofollow" target="_blank"> T5 </a>)模型的神经数据增强的研究工作。数据扩充是每个领域都需要的东西，无论是NLP、计算机视觉还是任何其他领域。数据，如果大量可用或可以大量生成，将总是有助于深度学习模型更好地学习模式，并在看不见的数据集上进行推广。此外，数据扩充是一种针对有偏差或不平衡数据的流行解决方案，可以通过复制示例或使用试探法来合成新示例来实现。</p><p id="deb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近，谷歌发表了这篇题为:<strong class="ig hi"> <em class="jd">“通过示例外推法增强神经数据”(</em></strong><a class="ae jc" href="https://arxiv.org/pdf/2102.01335.pdf" rel="noopener ugc nofollow" target="_blank">【https://arxiv.org/pdf/2102.01335.pdf】</a><strong class="ig hi"><em class="jd">)</em></strong>的论文，该论文讲述了如何为数据的欠表示切片生成合成示例，并显示出比其他技术更好的性能，如对欠表示数据切片进行上采样或任何其他关系提取(<a class="ae jc" href="https://github.com/thunlp/FewRel" rel="noopener ugc nofollow" target="_blank"> FewRel </a>)和意图分类/槽填充任务(<a class="ae jc" href="https://archive.ics.uci.edu/ml/datasets/CLINC150" rel="noopener ugc nofollow" target="_blank"> CLINC150 </a>和<a class="ae jc" href="https://paperswithcode.com/dataset/snips" rel="noopener ugc nofollow" target="_blank">酷！！在深入研究更多理论之前，让我们先看看下面的图片。</a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/20f06d6b3ed3cc8c7e9d95369dcb0589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6HNkzhxfaSoJTlBhk16b7Q.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Figure 1 from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.</figcaption></figure><p id="b9e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">查看上图，我们将对这种方法如何进行有一个完整的了解，并训练seq2seq模型，以便为代表不足的切片生成数据。好的，首先，我们要找到数据中未被充分代表的切片，首先，什么是数据切片？。根据这篇论文，一个片段可以是共享一个给定标签的所有例子的集合，或者是特定语言中的所有例子，或者是具有特定句法结构的所有例子。</p><p id="7967" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">他们称之为示例外推法(Ex2)的模型没有对数据如何切片做出任何假设，完全由从业者以暴露重要但未被充分表示的切片的方式对数据进行切片，然后Ex2可以将这些切片作为数据扩充的目标。因此，端到端流程的流程如下:</p><ol class=""><li id="84c3" class="ju jv hh ig b ih ii il im ip jw it jx ix jy jb jz ka kb kc bi translated">将数据集分成切片。</li><li id="80db" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated">使用这些切片中的数据训练一个示例外推器。</li><li id="f9b1" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated">使用示例外推器为数据集的欠表示切片生成新的合成数据。</li><li id="aab1" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated">在合成数据和真实数据的联合上训练模型。</li></ol><h2 id="0e7e" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">任务制定</h2><p id="c1cf" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">由于代表性不足的切片每个只有几个例子，所以本文将它们称为少炮切片<strong class="ig hi">(记为F) </strong>，并对这些切片进行数据扩充。数据的剩余切片被称为多次拍摄切片<strong class="ig hi">(表示为M) </strong>，这些切片具有足够的数据，并且不会接收数据增强。示例外推器(Ex2)仅用<strong class="ig hi"> M </strong>训练，并用于推断<strong class="ig hi"> F </strong>中的新示例，尽管在训练期间从未见过F中的任何示例。这是一个非常酷的想法:)。此外，术语<strong class="ig hi">“少数镜头”</strong>在这里意味着任务中的数据片段只有很少的例子。<strong class="ig hi">“少数镜头”</strong>的另一个概念表明整个任务的例子很少，这超出了本文的范围。</p><p id="02ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设一个从业者定义了S个切片函数的列表，其中每个函数slice_s(e)是一个布尔函数，指示示例是否属于slice_s(可能与其他切片函数重叠)。所以总体看起来是这样的:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es li"><img src="../Images/23dddb5dae064526e95b3bca5baa8482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*esQa16kOKQS_a2v1_Mcvnw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Defining slices over Dataset for Training seq2seq model (above figure from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.)</figcaption></figure><h2 id="6bc4" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">培训程序</h2><p id="5e90" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">T5变压器模型在包含许多示例的用<strong class="ig hi"> M </strong>表示的切片上的训练过程可以通过以下片段来理解:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lj"><img src="../Images/61b8b7f19036e3cffce408b7e5cd3a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KOAERVbuKNuG3xEvwR9FmA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Training objective formulation for T5 model training (above figure from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.)</figcaption></figure><blockquote class="lk ll lm"><p id="9bf7" class="ie if jd ig b ih ii ij ik il im in io ln iq ir is lo iu iv iw lp iy iz ja jb ha bi translated">为了优化上述目标，训练过程迭代所有训练切片<strong class="ig hi"> (s∈M) </strong>，以及每个切片中的每个示例<strong class="ig hi"> (e^∗) </strong>。对于每个示例，该过程从同一切片中抽取K个其他示例(<strong class="ig hi"> e_1:K) </strong>，不包括<strong class="ig hi">e _∫</strong>本身。训练程序然后优化作为输出的<strong class="ig hi">e _∫</strong>的对数似然，给定<strong class="ig hi"> e_1:K </strong>作为输入。</p></blockquote><h2 id="164b" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">使用的模型</h2><p id="e0ca" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">作者使用了T5 transformer模型，这是一个在大型文本语料库上预先训练好的<strong class="ig hi">T</strong>ext-<strong class="ig hi">T</strong>o-<strong class="ig hi">T</strong>ext<strong class="ig hi">T</strong>transformer模型。这种预训练为网络提供了大量的世界知识，这对于模型在给定示例之外进行推断的能力至关重要。你可以从这个<a class="ae jc" href="https://towardsdatascience.com/t5-text-to-text-transfer-transformer-643f89e8905e" rel="noopener" target="_blank">博客</a>和官方<a class="ae jc" href="https://arxiv.org/pdf/1910.10683.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中读到更多关于T5的内容。</p><h2 id="29fc" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">对标准基准数据集的评估</h2><p id="2fe2" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">作者使用标准任务评估了他们的策略，如分类、槽填充、与相应标准基准数据集的关系提取。他们将他们的模型与<strong class="ig hi">基线技术</strong>和另一种称为<strong class="ig hi">上采样</strong>的数据增强策略进行了比较(来自“少镜头”切片的样本被上采样以匹配多镜头切片的中值频率，从而消除不平衡并改善训练。)的一些结果如下:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lq"><img src="../Images/39b6519818b7deb5efc1b5308c091da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ywado4u1PR0nBtMZF9-Nrg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae jc" href="https://archive.ics.uci.edu/ml/datasets/CLINC150" rel="noopener ugc nofollow" target="_blank">CLINC150</a> Dataset(above figure from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.)</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/391bb089832f55fbf592576e61f2c925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*he94fi2hpml-P6be9cRJOg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae jc" href="https://paperswithcode.com/dataset/snips" rel="noopener ugc nofollow" target="_blank">SNIPS</a> Dataset (above figure from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.)</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ls"><img src="../Images/c83418582a66c5b4c090c0f6eefb8a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I105KFb-QqWPvRlRXEsbrQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx"><a class="ae jc" href="https://github.com/thunlp/FewRel" rel="noopener ugc nofollow" target="_blank">Few-rel</a> Dataset (above figure from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.)</figcaption></figure><h2 id="bf50" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated"><strong class="ak">使用Ex2 </strong>生成的示例</h2><p id="cce7" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">作者展示了Ex2在CLINC150数据集上训练后产生的一些例子。此外，在论文中，他们将他们训练以生成少数镜头切片示例的模型称为<strong class="ig hi">教师模型</strong>，使用实际数据和增强数据训练的下游模型称为<strong class="ig hi">学生模型</strong>。这类似于蒸馏，其中已经训练的较大的教师模型用于训练较小的学生模型，或者其中“教师”用于标记将由“学生”消费的大量未标记的输入(x)。Ex2方法类似，除了教师不标记预先存在的x，而是合成全新的(x，y)对。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lt"><img src="../Images/be79e2e5273909b5c65e6c9e59e3296c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BnfCp6x7onhrXo2AvqheqQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Table 9 from “Neural Data Augmentation via Example Extrapolation” by Kenton Lee et al.</figcaption></figure><h2 id="b11a" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated">结论</h2><p id="649a" class="pw-post-body-paragraph ie if hh ig b ih ld ij ik il le in io ip lf ir is it lg iv iw ix lh iz ja jb ha bi translated">这篇名为“<strong class="ig hi"> <em class="jd">通过示例外推法进行神经数据扩充</em> </strong>”的论文提出了一种非常新颖的想法，即使用已经在非常大的语料库上预先训练好并且其中存在世界知识的神经模型来进行数据扩充。此外，这些模型能够很好地概括新的/看不见的示例，并生成遵循类似分布的新示例，该分布对应于数据的少数镜头切片中的示例分布。这种技术显示了对基线和标准方法的改进，以进行数据扩充，如上采样。</p><h2 id="fe9a" class="ki kj hh bd kk kl km kn ko kp kq kr ks ip kt ku kv it kw kx ky ix kz la lb lc bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="e8f5" class="ju jv hh ig b ih ld il le ip lu it lv ix lw jb jz ka kb kc bi translated"><a class="ae jc" href="https://arxiv.org/pdf/2102.01335.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2102.01335.pdf</a>(<strong class="ig hi"><em class="jd">通过示例外推的神经数据增强</em> </strong>)</li><li id="17f4" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><a class="ae jc" href="https://arxiv.org/pdf/1910.10683.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1910.10683.pdf</a>(<strong class="ig hi"><em class="jd">T5纸</em> </strong>)</li><li id="6ec1" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><a class="ae jc" href="https://towardsdatascience.com/t5-text-to-text-transfer-transformer-643f89e8905e" rel="noopener" target="_blank">https://towards data science . com/t5-text-to-text-transfer-transformer-643 f89e 8905 e</a></li></ol></div></div>    
</body>
</html>
# 神经符号/混合人工智能或者只是对 AGI 的深度学习？

> 原文：<https://medium.com/mlearning-ai/neuro-symbolic-hybrid-ai-or-just-deep-learning-towards-agi-aa3d20a24247?source=collection_archive---------1----------------------->

加里·马库斯([加里·马库斯](https://medium.com/u/d7e74ac84d28?source=post_page-----aa3d20a24247--------------------------------))可能是拥有更多先天能力的人工智能或需要将人工智能与象征性能力混合(更符合经典人工智能或 GOFAI)以实现 AGI 的最强有力的倡导者。他认为深度学习还不够。这也被称为神经符号或混合人工智能。

相反，Yann Lecun ( [Yann LeCun](https://medium.com/u/586743efc8fb?source=post_page-----aa3d20a24247--------------------------------) )更喜欢更简单的方法。他的观点一直是，系统可以自己学习尽可能多的东西，并尽可能避免监管或控制人工智能模型的更高层次的约束。

自从神经网络爆炸以来，辩论就一直在进行，我建议在 Marcus 和 LeCun 之间进行一些对抗，以便有更多的背景(一场精彩的面对面[在这里](https://www.youtube.com/watch?v=aCCotxqxFsk))。

**深度学习本身是否能够解决 AGI 面临的所有挑战**正如 Geoffrey Hinton 在这里所说的？

目前，我认为所有部署的人工智能解决方案都以这样或那样的方式混合在一起。任何实现的人工智能解决方案几乎肯定都是由一个传统软件管理的，无论是用户界面、一些高级逻辑、小细节或调整，还是补充必要演绎部分的复杂算法。

众所周知，**归纳是机器学习**的精髓，**演绎是传统软件**的精髓。几乎在任何当前的解决方案中都结合了这两者。

**但这不是辩论**。争论在于深度学习是否能够对现在以符号和演绎方式覆盖的问题做出反应，例如推理和规划问题(特别是强化学习)。争论在于深度学习是否能够操纵符号、符号推理，并支持备受讨论的“常识”，这种常识允许人类为不同的问题提供如此多的解决方案。

每个人在这个时候都可以有自己特定的观点，因为这个问题还没有一个明确的解决方案。

勒村概述了他的建议，关于如何解决 AGI 在这个角色[这里](https://openreview.net/pdf?id=BZ5a1r-kVsf)(必读)和[这里](https://www.noemamag.com/what-ai-can-tell-us-about-intelligence/)一个更容易阅读的工作。

加里·马库斯在这里讨论了它[。](https://www.noemamag.com/deep-learning-alone-isnt-getting-us-to-human-like-ai/)

也许我对 Yann LeCun 的工作的钦佩不允许我客观，但我发现他的推理更坚实，他的工作更正式和更有基础，比 Gary Marcus 的更少模糊和缺乏明确的解决方案。

加里·马库斯给我的感觉是防守一个更容易的位置。总是处于一种舒服的持续对立中，甚至在推文中用可笑的、完全没有必要的例子嘲讽深度学习(即使是为了一个可能的解决方案的显而易见性)。

有必要吗，马库斯？真的吗？

加里·马库斯也对勒村表现出令人恼火的痴迷，他甚至责备勒村在他的一些作品中没有引用他的名字。还有他不断提到他的书，比如《代数思维》、《重启》。AI’等。，在我看来是纯粹的营销和自我的过剩。

我们希望，时间会让他们各得其所，并对这场辩论给出答案。

[](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb) [## Mlearning.ai 提交建议

### 如何成为 Mlearning.ai 上的作家

medium.com](/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb)
<html>
<head>
<title>Learning XOR with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch学习异或</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/learning-xor-with-pytorch-c1c11d67ba8e?source=collection_archive---------2-----------------------#2021-05-08">https://medium.com/mlearning-ai/learning-xor-with-pytorch-c1c11d67ba8e?source=collection_archive---------2-----------------------#2021-05-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="afe8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个神经网络示例的重新创建，用于预测伊恩·古德菲勒、约舒阿·本吉奥和亚伦·库维尔在深度学习书中发现的XOR值。</p><p id="2c15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是XOR真值表:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/6358bc3f2324b19ac429d6da3fd5c4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/0*xsUuc9E3fPPm96AZ"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Source: <a class="ae jo" href="https://community.anaplan.com/t5/Idea-Exchange/Add-XOR-formula/idi-p/61192" rel="noopener ugc nofollow" target="_blank">https://community.anaplan.com/t5/Idea-Exchange/Add-XOR-formula/idi-p/61192</a></figcaption></figure><p id="b98f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们希望根据两个输入A和b来预测输出。</p><p id="5654" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">起初，对于这样一个简单的任务，通过更新感知器的权重和偏差来训练它似乎是一个好主意。然而，XOR不是非线性函数，因此感知器本身无法学习如何预测这一点。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/7b62f4853b086c600e5cfeb6fbe7f05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*5X1GJDSxSlIEaweA2fTfeQ.png"/></div></figure><p id="6960" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以上是没有激活功能的单个感知器的等式。它取输入向量的转置，将其与权重向量相乘，并加上偏差向量。在这种情况下，输入向量是[0，0]、[0，1]、[1，0]或[1，1]。单独地，这个基本感知器，不管权重和偏差是什么，都不能准确地预测XOR输出，因为它是线性函数，而XOR不是。</p><p id="ce1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是PyTorch中单个感知的代码:</p><pre class="jd je jf jg fd jq jr js jt aw ju bi"><span id="5150" class="jv jw hh jr b fi jx jy l jz ka"># import libraries <br/>import torch <br/>import torch.nn as nn  </span><span id="e00f" class="jv jw hh jr b fi kb jy l jz ka"># define perceptron<br/>linear = nn.Linear(2, 1)  </span><span id="8471" class="jv jw hh jr b fi kb jy l jz ka">model_params = list(linear.parameters())  # returns weights and biases</span><span id="aa85" class="jv jw hh jr b fi kb jy l jz ka">print('Perceptron Weights : ', model_params[0][0].data.numpy()) print('Perceptron Bias :', model_params[1].data.numpy())  </span><span id="c3bd" class="jv jw hh jr b fi kb jy l jz ka">&gt;&gt; Perceptron Weights: [0.6110505, 0.20031671]    <br/>   Perceptron Bias: [-0.48146275]</span></pre><p id="f0ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，权重和偏差是随机分配的。</p><p id="18ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个感知器的输出很简单:([1。, 0.](转置)* [0.6110505，0.20031671])+[-0.48146275]= 0.1296</p><p id="cbd6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决单个感知器是线性的这个问题，我们需要给网络增加另一层。这个额外的层被称为sigmoid函数。sigmoid函数是一个非线性激活函数:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kc"><img src="../Images/58c697684c44610c78d93c4677a4d1a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*JZZLSMpvpf-WjFyB.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx">Source: <a class="ae jo" href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html</a></figcaption></figure><p id="a0c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果在这个函数中输入0，如上图所示，输出将是0.5。代码示例如下所示:</p><pre class="jd je jf jg fd jq jr js jt aw ju bi"><span id="67e4" class="jv jw hh jr b fi jx jy l jz ka">import torch.nn.functional as F</span><span id="13a3" class="jv jw hh jr b fi kb jy l jz ka">print(F.sigmoid(torch.tensor([0])))  </span><span id="907d" class="jv jw hh jr b fi kb jy l jz ka">&gt;&gt; tensor([0.500])</span></pre><p id="946d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上面的代码中，导入了包含sigmoid函数的PyTorch库“functional”。值为0的张量被传递给sigmoid函数，输出被打印出来。输出为0.5。</p><p id="924c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在sigmoid激活函数之后，将添加另一个感知器作为最终层。这为数据创建了3层，每个感知器总共有2个权重和2个偏差:</p><pre class="jd je jf jg fd jq jr js jt aw ju bi"><span id="0b38" class="jv jw hh jr b fi jx jy l jz ka">class XOR(nn.Module):</span><span id="5aae" class="jv jw hh jr b fi kb jy l jz ka">    def __init__(self):</span><span id="644a" class="jv jw hh jr b fi kb jy l jz ka">        super(XOR, self).__init__()</span><span id="48e3" class="jv jw hh jr b fi kb jy l jz ka">        self.linear = nn.Linear(2, 2)</span><span id="da0c" class="jv jw hh jr b fi kb jy l jz ka">        self.Sigmoid = nn.Sigmoid()</span><span id="c697" class="jv jw hh jr b fi kb jy l jz ka">        self.linear2 = nn.Linear(2, 1)<br/></span><span id="6b8f" class="jv jw hh jr b fi kb jy l jz ka">    def forward(self, input):</span><span id="f9c8" class="jv jw hh jr b fi kb jy l jz ka">        x = self.linear(input)</span><span id="3606" class="jv jw hh jr b fi kb jy l jz ka">        sig = self.Sigmoid(x)</span><span id="e70a" class="jv jw hh jr b fi kb jy l jz ka">        yh = self.linear2(sig)</span><span id="c31d" class="jv jw hh jr b fi kb jy l jz ka">        return yh</span></pre><p id="7571" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的代码定义了一个张量大小为2 x 2的模型，输入到第一层。然后，第一个线性层输出大小为2 x 2的张量，该张量被传递给sigmoid函数。该sigmoid函数的输出也是一个2×2张量，然后被传递到第二线性层，该层输出大小为1的张量。</p><p id="43de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了训练模型，大量的训练样本将被传递到网络中。网络将用随机权重和偏差初始化。在每个训练示例通过网络后，它将输出一个值，该值是在给定输入(x)的情况下对输出(yhat)的预测。该预测将与实际值(1或0)进行比较。</p><p id="0262" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预测产量和实际产量之间的比较将在成本函数中进行。用于此的成本函数将是均方误差成本函数:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kd"><img src="../Images/19680197957f51981e4b0fdaffa5dbb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*hhQ85ytzk0YTHufSsvi5ow.png"/></div></figure><p id="b92e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该函数简单地取实际值和预测值之间的平方差的平均值。</p><p id="f1e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算均方误差后，将使用成本函数的梯度更新权重和偏差，以更接近局部或全局最小值。优化的目的是最小化成本函数。当成本函数为0时，意味着所有预测值都与实际值相同。</p><p id="525d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是培训代码:</p><p id="ea7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个模型的完整代码可以在<a class="ae jo" href="https://colab.research.google.com/drive/1sKJfB5YAfAUD9PU-SNDGlMdKa9M7yCcH?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><pre class="jd je jf jg fd jq jr js jt aw ju bi"><span id="4df3" class="jv jw hh jr b fi jx jy l jz ka">xor_network = XOR()<br/>epochs = 1000 <br/>mseloss = nn.MSELoss() <br/>optimizer = torch.optim.Adam(xor_network.parameters(), lr = 0.03) all_losses = [] <br/>current_loss = 0 <br/>plot_every = 50 <br/> <br/>for epoch in range(epochs): <br/>   <br/>    # input training example and return the prediction   <br/>    yhat = xor_network.forward(Xs)<br/>    <br/>    # calculate MSE loss   <br/>    loss = mseloss(yhat, y)<br/>      <br/>    # backpropogate through the loss gradiants   <br/>    loss.backward()<br/>    <br/>    # update model weights   <br/>    optimizer.step()<br/>    <br/>    # remove current gradients for next iteration   <br/>    optimizer.zero_grad() <br/>   <br/>    # append to loss   <br/>    current_loss += loss  <br/> <br/>    if epoch % plot_every == 0:       <br/>        all_losses.append(current_loss / plot_every)       <br/>        current_loss = 0 <br/>     <br/>    # print progress   <br/>    if epoch % 500 == 0:     <br/>        print(f'Epoch: {epoch} completed')</span></pre><p id="6fa6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个模型的完整代码可以在<a class="ae jo" href="https://colab.research.google.com/drive/1sKJfB5YAfAUD9PU-SNDGlMdKa9M7yCcH?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="88f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在正常情况下，成本函数为0意味着对训练数据的高偏差，这将是一个问题。然而，对于只有两个可能的输入和输出被用作例子的小真值表来说，这不是问题。点击阅读更多关于减少偏差<a class="ae jo" href="https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="749d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有许多其他的神经网络结构可以被训练来预测XOR，这只是一个简单的例子。</p><p id="f467" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我的博客中查看更多信息。</p></div></div>    
</body>
</html>
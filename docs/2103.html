<html>
<head>
<title>Reducing offensive content in NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">减少自然语言处理中的不良内容</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/reducing-offensive-content-in-nlp-92368ce35282?source=collection_archive---------3-----------------------#2022-03-08">https://medium.com/mlearning-ai/reducing-offensive-content-in-nlp-92368ce35282?source=collection_archive---------3-----------------------#2022-03-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="cd9f" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">NLP模型，如GPT-3或地鼠，有时会产生令人不快的内容。这限制了它们在现实生活中的使用。Red Teaming (RT)减少了NLP模型的有害输出，而无需昂贵的人工注释。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/a0908f265cc9567201b41a394e0945c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EIts7RXk7W_ewwqN"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@jannerboy62?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nick Fewings</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c478" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">NLP模型旨在与真实的人互动。GPT-3和地鼠是最先进的自然语言处理模型。然而，它们有时都会产生有害的内容。</p><p id="ec3f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在现实生活中，这种有偏见的模型是有风险的。一个坏演员可以使用这些NLP系统来产生有毒的语音。</p><p id="9477" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">有害内容可能从有毒言论或政治观点到分享个人信息或刻板印象。</p><p id="3c6d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">有多种选择可以降低这些风险。我们将首先讨论人在回路中的方法。然后，我们将讨论红色团队方法。</p><p id="dafb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">回路中的人类</strong></p><p id="9727" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">从NLP模型中获得人类反馈是有好处的。人们不喜欢依赖黑盒算法。</p><p id="bef0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然而理解NLP模型是复杂的。Gopher模型吸收10.5 TB的文本。没有人能够检查如此大的数据集。我们既不能理解它的2800亿个模型参数。然而，我们能够审查它的输出是否令人不快。</p><p id="4cf0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">人工注释是有用的。我们可以用它来检测有害的输出。我们可以雇人来检查NLP模型的输出。如果他们检测到有害输出，我们可以将其排除。</p><p id="2332" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然而雇佣人来做这项工作是很昂贵的。OpenAI要求用户提供关于NLP输出的反馈。除了人类注释者之外，OpenAI还雇佣了其他人来审查模型输出。这样就打开了人工注释的自动化部分。</p><p id="6070" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这种方法的缺点仍然是可伸缩性差。该方法仅检查少量可能的NLP模型输出。</p><p id="8eba" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然而，有害的定义可能会随着时间的推移而改变。因此，我们更喜欢一种方法，我们可以随着时间的推移进行升级，并将其扩展到更大的数据集。</p><p id="c5df" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">分类算法优于人工注释。我们可以向分类器提供无限量的NLP输出。我们将能够选择更多的进攻输出。它将进一步改进分类器。这增加了检测到的攻击性输出的数量。</p><p id="ff60" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">因此，我们将识别新的攻击性内容类别。让我们详细回顾一下这样的系统。</p><p id="eb13" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">红队</strong></p><p id="6bbc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">Red Teaming (RT)是一种修复NLP模型等系统的对抗方法。基本思想是用NLP模型创建恶意输出。然后，我们排除这些恶意输出。</p><p id="d826" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们一步步回顾这个过程。</p><p id="8a1a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们首先创建一个rt分类器来检测有害的输出。创建分类器有多种方式。我们可能有明确定义的数据集，其中的类别已经分为攻击性和非攻击性内容。然而，最理想的是，分类器将学会自己分离这些类别。</p><p id="6a71" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">接下来的步骤是使用我们的NLP模型生成输出。例如，我们使用GPT-3或地鼠模型生成文本。</p><p id="61ab" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">RT分类器将这些输出分类为有害和无害。</p><p id="666f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果我们检测到攻击性输出，我们可以使用两种方法将其排除。我们可以在没有这些有害例子的情况下训练我们的NLP模型。这样，NLP模型将不包括这样的数据。我们可以选择将此类攻击性内容添加到模型黑名单中。这样，在生成输出时，我们将不会使用它们。</p><p id="9f86" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">RT并不意味着取代人类的判断。然而，该方法是在人类反馈之前发现有害内容的预防性方法。这在帮助使NLP模型更难以以错误的方式使用方面特别有用。</p><p id="1709" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">最后更新2022年3月</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><p id="e0df" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">来源:</p><p id="8611" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><a class="ae jm" href="https://arxiv.org/pdf/2202.03286.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">佩雷兹等人2022年2月</strong> </a></p><p id="eee2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><a class="ae jm" href="https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">欧阳等人2022年1月。</strong> </a></p><div class="kq kr ez fb ks kt"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ku ab dw"><div class="kv ab kw cl cj kx"><h2 class="bd hi fi z dy ky ea eb kz ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="la l"><h3 class="bd b fi z dy ky ea eb kz ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lb l"><p class="bd b fp z dy ky ea eb kz ed ef dx translated">medium.com</p></div></div><div class="lc l"><div class="ld l le lf lg lc lh jg kt"/></div></div></a></div></div></div>    
</body>
</html>
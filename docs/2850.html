<html>
<head>
<title>Survey of Contrastive Learning in Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉中的对比学习综述</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/survey-of-contrastive-learning-in-computer-vision-89ff6fea277c?source=collection_archive---------3-----------------------#2022-06-18">https://medium.com/mlearning-ai/survey-of-contrastive-learning-in-computer-vision-89ff6fea277c?source=collection_archive---------3-----------------------#2022-06-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a35f535b88370dddfe67097d18e21746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7IMtWo0uQAOwUbU4KOPOEA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://ai.googleblog.com/2021/06/extending-contrastive-learning-to.html" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="aef4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是一篇综述计算机视觉领域对比学习的调查文章。这个帖子是看完这个<a class="ae it" href="https://www.bilibili.com/video/BV19S4y1M7hm/?spm_id_from=pageDriver&amp;vd_source=a3fd8cc7c926eda8f2bc99817b7c1c4e" rel="noopener ugc nofollow" target="_blank">视频</a>后的一个简单总结。我会相应总结几篇著名的CV对比学习论文。这个帖子只会对每篇论文做一个大概的介绍。详细的阅读和分析将在后面。</p><p id="6001" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，请允许我简单介绍一下对比学习。对比学习的目标是学习这样一种嵌入空间，其中相似的样本数据(图像/文本)保持彼此靠近，而不相似的样本数据则远离。对比学习是最强大和最流行的<a class="ae it" href="https://en.wikipedia.org/wiki/Self-supervised_learning" rel="noopener ugc nofollow" target="_blank">自我监督学习</a>方法之一。</p><p id="7f2f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对比学习在近2-3年非常流行。对比学习在对比学习中的发展阶段如下:</p><h1 id="0252" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">第一阶段的不同方法</h1><p id="a00c" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在这一阶段，发表了许多不同的方法。模型，损失函数和借口任务已经确定。这一阶段有几篇著名的论文:</p><blockquote class="kv kw kx"><p id="3343" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">通过非参数实例级辨别的无监督特征学习</p></blockquote><p id="f156" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:【https://arxiv.org/abs/1805.01978 T4】</p><p id="e728" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将这个模型称为InstDisc，这是它的标题中最后两个字的缩写。如果说《MoCo》是对比学习中的一部里程碑式的作品，那么《英特迪斯克》可以说是巨人的肩膀。InstDisc定义了借口任务:实例判断任务。与此同时，许多其他的对比学习论文直接效仿了本文的实验。</p><p id="2fd8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">托词任务(实例辨别任务):InstDisc将类的监督发挥到了极致，这样模型就能够学习能够辨别个体数据的特征表示。</p><p id="f3bd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型:InstDisc利用主干CNN将每个图像编码成特征嵌入。所有这些嵌入都分布在一个128D的单位球面上(128维，L2归一化)。</p><p id="e595" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">阳性和阴性数据:对于一个批次中的每个样本，阳性数据是其本身(包括补充数据)。负数据是从内存库中随机抽取的(文中的4096)。在每一批训练之后，该批数据的嵌入将替换记忆库中相应的旧嵌入。本文还采用近似正则化方法，用动量更新嵌入(在记忆体内)。</p><p id="76e2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">损失:采用非参数的softmax和NCE损失来训练模型。</p><p id="7697" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总结:</p><ol class=""><li id="f727" class="lc ld hh iw b ix iy jb jc jf le jj lf jn lg jr lh li lj lk bi translated">提出了实例判定任务</li><li id="ee7e" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">收养NCE损失</li><li id="0242" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">采用另一种数据结构(存储体)来存储学习到的嵌入</li></ol><blockquote class="kv kw kx"><p id="a055" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">基于不变和扩展实例特征的无监督嵌入学习</p></blockquote><p id="7968" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:<a class="ae it" href="https://arxiv.org/abs/1904.03436" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1904.03436</a></p><p id="986b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们称这个模型为InvaSpread。</p><p id="dd8a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">借口任务:实例判断任务</p><p id="38c5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型:主干CNN将图像投射到低维子空间</p><p id="f895" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正面和负面数据:对于批次中的每个数据，获得一个增强图像。这是积极的数据。所有其他批次数据及其增强图像都是负面数据。这意味着，对于m的批量大小，每个图像将具有1个正数据(扩充的)和(2m-2)个负数据来计算损失函数。</p><p id="94b9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">损失:NCE损失</p><p id="58d1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总结:</p><p id="87c5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">与InstDisc相比，这里没有内存条来提供负样本。所有阴性样本都来自批次数据(及其扩充数据)。因此，InvaSpread能够进行端到端的训练。</p><p id="27d1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">InvaSpread的训练批量为256，只能贡献510个阴性样本。因此它的性能不如SimCLR，尽管它们有相似的训练程序。此外，InvaSpread没有像SimCLR那样使用非常强大的数据处理技术，最终也缺少MLP应用层。然而，InvaSpread可以被视为SimCLR的前身</p><blockquote class="kv kw kx"><p id="72fe" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">对比预测编码的表征学习</p></blockquote><p id="2176" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:【https://arxiv.org/abs/1807.03748 T2】</p><p id="378e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文提出了一种通用的表征学习方法，无论输入是音频、图像、文本，甚至是强化学习。事实上，这种方法将语言模型推广到不同类型的输入，而不仅仅是文本。</p><p id="9623" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型:序列输入将被输入到编码器模型中。然后，返回的要素将输入到自动回归模型(RNN/LSTM)。这个自回归模型的输出是上下文表示。这个上下文表示向量包含了上下文的信息，如果足够强大的话，可以用来预测未来。</p><p id="baf8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正负数据:真正的未来数据是正的数据。所有其他数据都可以被视为负面数据</p><p id="5825" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">借口任务:未来预测任务。这是一代人的任务之一。如果输入是文本序列，这种方法实际上就要训练一个语言模型。</p><blockquote class="kv kw kx"><p id="10e5" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">对比多视图编码</p></blockquote><p id="a9b0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:【https://arxiv.org/abs/1906.05849 T4】</p><p id="28c5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正面和负面数据:不同观点的数据可以被视为正面数据。如果数据的不同视图都是图像，这些视图可以被认为是不同的增强技术(？).Multiview不仅限于图像视图，它还可以扩展到图像的语音描述和文本描述。这张纸实际上是以前的夹子。</p><h1 id="a22c" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">MoCo和西姆克莱尔</h1><p id="2266" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">现在到了21世纪20年代，出现了两种非常流行的对比学习方法</p><blockquote class="kv kw kx"><p id="9cce" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">无监督视觉表征学习的动量对比</p></blockquote><p id="547f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:<a class="ae it" href="https://arxiv.org/abs/1911.05722" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1911.05722</a></p><p id="a612" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文将以往的对比学习方法归纳为一个字典查找问题。MoCo提出了对比学习的两个组成部分:队列和动量编码器</p><p id="23ca" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">型号:</p><p id="df9b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">MoCo认为，对比学习是学习一个编码器来执行字典查找:在字典中，关键字是学习图像的特征，值是相应的实例。因此，在这种设置中，对比学习是学习可以将编码的查询(增强图像)匹配到编码的关键字(图像特征)的编码器。</p><p id="3680" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，MoCo建立了一个基于队列的动态字典。密钥由动量更新编码器编码(确保缓慢更新)。</p><p id="4b57" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正面和负面数据:</p><p id="52fc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">假设特征维数为C，字典大小为K，批次大小为N。正数据是该批次中的图像，其将被编码为N*C。负数据是当前字典中的数据，其大小为K*C。对于每个图像，MoCo应用两种不同的扩充技术来生成两个扩充数据。因此，正对数是从这两个扩充数据中计算出来的。负逻辑是在一个扩充数据和字典中的关键字之间计算的。在每次批量训练之后，当前小批的关键嵌入将被排入字典，并且最早的小批将被出队。与此同时，关键网络将进行动态更新。</p><p id="44a9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">损失函数:InfoNCE</p><p id="08ff" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总结:</p><p id="07fa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">MoCo遵循与InstDisc非常相似的模型和实验设置。与InstDisc相比，MoCo有两项改进:</p><ol class=""><li id="9ca4" class="lc ld hh iw b ix iy jb jc jf le jj lf jn lg jr lh li lj lk bi translated">基于队列的字典:与InstDisc中的记忆库相比，MoCo利用该字典存储负样本，保证了批量训练时有大量的负样本。</li><li id="cdf7" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">动量编码器。同时，MoCo利用动量技术更新关键编码器。这确保了字典中的键嵌入都来自相似的键编码器(成为有效的负样本)</li></ol><blockquote class="kv kw kx"><p id="101d" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">视觉表征对比学习的简单框架</p></blockquote><p id="02d0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:【https://arxiv.org/abs/2002.05709 T2】</p><p id="a360" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是计算机视觉中真正简单的对比学习技术。</p><p id="9d2c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正面和负面数据:与之前的对比学习一样，SimCLR利用不同的增强技术来获得每个输入的增强示例对。因此，对于N个例子的小批量，它将产生2N个数据点。正对是显而易见的(来自同一图像的增强数据对)。SimCLR将其他2(N-1)个扩充示例视为反例。(为什么不和原始图像也进行比较呢？)</p><p id="50be" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">损失函数:InfoNCE</p><p id="3622" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">模型:在训练阶段，SimCLR采用两个主要部分:表示编码器和可学习的非线性转换层(MLP)。这种非线性变换层的引入大大提高了学习表示的质量。在后面的下游任务中，这个转换层将被扔掉。只有编码器用于线性评估/微调。</p><p id="d351" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总结:</p><p id="4dd1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">非线性变换层的引入太棒了。在SimCLR中已经使用和评估了许多不同的增强技术。SimCLR还进行了非常详细的消融实验，以评估这些增强技术的不同组合的性能。</p><blockquote class="kv kw kx"><p id="0bab" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">动量对比学习的改进基线(MoCo-v2)</p></blockquote><p id="b53f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">与MoCo的区别:</p><ol class=""><li id="c918" class="lc ld hh iw b ix iy jb jc jf le jj lf jn lg jr lh li lj lk bi translated">使用MLP投影头(类似于SimCLR)</li><li id="0727" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">更多增强技术</li><li id="7315" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">采用余弦学习率计划</li><li id="d80c" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">更多时代</li></ol><p id="5347" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">相对于SimCLR，MoCo-vs对我们来说更有研究友好性(因为外部字典)，哈哈。随着批量大小为256，MoCo-v2已经可以达到SOTA结果。这样的设置下，我们使用8个v100 GPUs就可以在53小时内完成训练。</p><blockquote class="kv kw kx"><p id="72df" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">大型自监督模型是强半监督学习(SimCLR-v2)</p></blockquote><p id="9b58" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">提议的半静态学习框架:</p><ol class=""><li id="0dd6" class="lc ld hh iw b ix iy jb jc jf le jj lf jn lg jr lh li lj lk bi translated">训练表示编码器(SimCLR-v2)</li><li id="6500" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">使用带有标签的少量数据点微调模型。这样可以得到一个v1的模型。</li><li id="9eeb" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">使用v1模型预测未分类数据。将这些伪标签与真实标签数据混合，训练v2模型</li></ol><p id="b125" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">与SimCLR相比:</p><ol class=""><li id="f2db" class="lc ld hh iw b ix iy jb jc jf le jj lf jn lg jr lh li lj lk bi translated">放大模型:152层ResNet-50(4x)，并使用选择性内核</li><li id="f94b" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">增加非线性网络的容量(采用双层MLP)</li><li id="12c3" class="lc ld hh iw b ix ll jb lm jf ln jj lo jn lp jr lh li lj lk bi translated">采用动量编码器，不会带来很大的改善。SimCLR已经有非常大的批量(许多阴性样本)</li></ol><p id="f17c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">SimCLR和SimCLR-v2都只在分类任务中测试，而MoCo的相关工作在几个下游任务中测试。</p><blockquote class="kv kw kx"><p id="a97b" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">基于对比聚类分配的视觉特征无监督学习</p></blockquote><p id="dedd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">SwAV将阳性数据与聚类中心进行比较。也采用多作物技术(这是相当强大的)</p><h1 id="4376" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">没有阴性样本</h1><p id="dbbd" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在这个阶段，对比学习不利用负样本进行学习(非常有效……)。就我所见，没有非常有力的解释说明为什么这能起作用…为什么模型训练没有崩溃？</p><blockquote class="kv kw kx"><p id="2a0a" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">激发你自己的潜能一种自我监督学习的新方法(BYOL)</p></blockquote><p id="5242" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:<a class="ae it" href="https://arxiv.org/abs/2006.07733" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2006.07733</a></p><p id="7157" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于在训练中只考虑正面数据，所以模型对于每个输入只能输出相同的数据。那么损失将为0。这是模型训练(模型折叠)的简短解决方案。通过引入负数据，学习后的模型可以输出相似图像的相似嵌入和不同图像的不同嵌入。这是来自我们的共同认识。</p><p id="5157" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">BYOL在训练中没有使用任何负面数据。BYOL利用一个视图的特征来预测另一个视图的特征。BYOL将对比学习从匹配问题转化为预测问题…</p><p id="f782" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里有一个intertesting博客(部分)解释为什么BYOL不需要负样本:<a class="ae it" href="https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/" rel="noopener ugc nofollow" target="_blank">https://generallyintelligent . ai/blog/2020-08-24-理解-自我监督-对比-学习/ </a>。它提到负面信息隐藏在批量标准化中。</p><p id="c6d9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">https://arxiv.org/abs/2010.10241的作者BYOL很快发表了另一篇论文来回应这个帖子:<a class="ae it" href="https://arxiv.org/abs/2010.10241" rel="noopener ugc nofollow" target="_blank"/>。在这里，BYOL利用另一组正常化也可以工作。然而，很难说这是一个好的解释…</p><blockquote class="kv kw kx"><p id="932d" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">探索简单暹罗表示学习(SimSiam)</p></blockquote><p id="a042" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:<a class="ae it" href="https://arxiv.org/abs/2011.10566" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2011.10566</a></p><p id="c56d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">利用训练过程中的停止梯度，SimSiam可以是一种类似期望最大化(EM)的算法。停止渐变将整个参数分成两组。训练过程也分为两个阶段。</p><h1 id="3c56" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">基于变压器的模型</h1><blockquote class="kv kw kx"><p id="0558" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">训练自我监督视觉转换者的实证研究(MoCo-v3)</p></blockquote><p id="81f7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:<a class="ae it" href="https://arxiv.org/abs/2104.02057" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2104.02057</a></p><p id="33f4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">实际上，这是一个通用的对比学习架构。它不仅可以使用视觉变压器，还可以利用CNN。该结构可被视为辛暹+ MoCo-v2</p><p id="6429" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文还提到了自我监督学习的不稳定性，以及采取何种措施使其更加稳定。作者查看了每一层的梯度，并观察了训练曲线中出现“下降”时的尖峰梯度。第一层(面片投影)中的梯度峰值出现得更早。因此，作者采用了一个固定的随机补丁投影层，以克服这种不稳定性时，训练与视觉变压器。</p><blockquote class="kv kw kx"><p id="c621" class="iu iv ky iw b ix iy iz ja jb jc jd je kz jg jh ji la jk jl jm lb jo jp jq jr ha bi translated">自监督视觉变压器(DINO)的新兴特性</p></blockquote><p id="f5b3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">论文链接:<a class="ae it" href="https://arxiv.org/abs/2104.14294" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2104.14294</a></p><p id="f6bb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">自监督学习中的视觉转换器可以学习非常好的无监督对象分割，甚至比监督对象分割更好。</p><div class="lq lr ez fb ls lt"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lu ab dw"><div class="lv ab lw cl cj lx"><h2 class="bd hi fi z dy ly ea eb lz ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ma l"><h3 class="bd b fi z dy ly ea eb lz ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mb l"><p class="bd b fp z dy ly ea eb lz ed ef dx translated">medium.com</p></div></div><div class="mc l"><div class="md l me mf mg mc mh in lt"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Detecting objects with YOLOv5, OpenCV, Python and C++</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用YOLOv5，OpenCV，Python和C++检测对象</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/detecting-objects-with-yolov5-opencv-python-and-c-c7cf13d1483c?source=collection_archive---------0-----------------------#2022-01-23">https://medium.com/mlearning-ai/detecting-objects-with-yolov5-opencv-python-and-c-c7cf13d1483c?source=collection_archive---------0-----------------------#2022-01-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/0490c1d524782fda601d8c564ab65ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cESGIJse1Rlmf6kMGyR_6w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.malinhapronta.com.br/2016/03/29/que-tal-levar-as-criancas-para-participar-de-uma-corrida-de-rua/" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="cdf5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">人们常常认为计算机视觉是一个很难理解的课题，也很难运行。事实上，不久前，编写计算机视觉应用程序是一项高度专业化的任务，需要对机器学习有深入的了解，并对底层计算机基础设施有深刻的理解，才能实现最低限度的可接受性能。</p><p id="6b4d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">今天，这不再是事实。或者至少对于被称为“物体检测”的一系列计算机视觉任务来说不是这样。在这里我们要讨论今天性能最高的物体检测器之一:<a class="ae it" href="https://ultralytics.com/yolov5" rel="noopener ugc nofollow" target="_blank"> Ultralytics YOLO v5 </a></p><p id="8b76" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本文中，我将展示如何轻松使用YOLO V5——最先进的对象检测引擎——来识别图像中的元素。作为案例研究，我们将使用OpenCV、Python和C++来加载和调用我们的YOLO v5模型。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es js"><img src="../Images/71f845159a413509e1aa31afaae50692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tqZRomltDxWLeurjR2BuAA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Canindé Araras (<a class="ae it" href="https://www.passaro.org/arara-do-caninde/" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><h2 id="526a" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">什么是对象检测</h2><p id="e8e4" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">目标检测是最重要的计算机视觉任务之一。简而言之，给定一幅图像，物体探测器会发现:</p><ul class=""><li id="9cc7" class="kx ky hh iw b ix iy jb jc jf kz jj la jn lb jr lc ld le lf bi translated">图像中的对象</li><li id="2df6" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">他们的类型(通常称为<strong class="iw hi">类</strong></li><li id="5a35" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">代表图像中物体坐标的<strong class="iw hi">边界框</strong>。</li></ul><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ll"><img src="../Images/19d56c1f381a891beeae15c5ca4675c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oCnHxOeXJmsJKgPW2Q7v6w.png"/></div></div></figure><p id="2225" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于每个对象，对象检测算法分配一个<strong class="iw hi">置信度</strong>值，表示该检测的可信度。</p><h2 id="90b6" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">物体探测器如何知道如何探测物体？</h2><p id="318c" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">像YOLOv5这样的物体探测器经过<strong class="iw hi">训练</strong>来探测物体。这种训练包括使用一组图像和相应的注释来调整模型，并使其学习如何检测对象。</p><p id="25c4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这种训练的结果是一个模型文件。YOLOv5有一组先前使用<a class="ae it" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> MS COCO数据集</a>训练的模型。这些预先构建的模型能够探测到人、汽车、自行车、狗、猫、飞机、船等物体</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lm"><img src="../Images/ef92815dab280cc7fd87b758a3371ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YegWYtk-l52y7QDnAcM_qQ.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">object detection using MS COCO <a class="ae it" href="https://www.researchgate.net/publication/335865923_Mini-YOLOv3_Real-Time_Object_Detector_for_Embedded_Applications" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="3e37" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以自己训练YOLOv5，以便教会它探测其他类型的物体。事实上，训练YOLOv5非常容易。这个话题在<a class="ae it" rel="noopener" href="/mlearning-ai/training-yolov5-custom-dataset-with-ease-e4f6272148ad">另一个故事中有所涉及。</a></p><h2 id="51d0" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">在这里使用YOLOv5的总体情况</h2><p id="bc66" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">基本上，我们的程序执行4个简单的步骤:</p><ul class=""><li id="ac6e" class="kx ky hh iw b ix iy jb jc jf kz jj la jn lb jr lc ld le lf bi translated">加载YOLOv5模型</li><li id="945b" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">输入图像以获得预测</li><li id="99fa" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">展开输出以获得每个对象的类和边界框</li><li id="5d14" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">使用输出来修饰图像</li></ul><p id="39a2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们开始吧！</p><h2 id="4ca5" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">步骤1 —加载YOLOv5模型</h2><p id="f9a8" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">这一步由一行代码组成，用于导入模型</p><p id="c7d1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Python:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="5561" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在C++中:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="f429" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您可能想知道什么是文件<em class="lp"> yolov5s.onnx </em>以及在哪里可以找到它。</p><p id="a2cc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lp"> yolov5s.onnx </em>是OpenCV可识别格式的模型文件。原始文件<em class="lp"> yolov5s.pt </em>，可以在<a class="ae it" href="https://github.com/ultralytics/yolov5/releases" rel="noopener ugc nofollow" target="_blank"> YOLOv5 github库</a>中找到。</p><p id="ba36" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了让OpenCV读取模型文件，有必要将其转换为<em class="lp"> ONNX </em>格式。这就是为什么我们在这里使用<em class="lp"> yolov5s.onnx </em>的原因。</p><p id="0bc9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">按照这里的说明可以很容易地将YOLOv5模型转换成不同的格式<a class="ae it" href="https://github.com/ultralytics/yolov5/issues/251" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="372e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了您的方便，您可以在这里下载我的yolov5s.onnx。</p><h2 id="e84a" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">步骤2-输入图像以获得预测</h2><p id="5311" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">YOLOv5等待具有以下规格的输入图像:</p><ul class=""><li id="0b75" class="kx ky hh iw b ix iy jb jc jf kz jj la jn lb jr lc ld le lf bi translated">RGB格式</li><li id="740c" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">[0，1[</li><li id="f58c" class="kx ky hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">尺寸640x640</li></ul><p id="3982" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，在调用YOLOv5模型之前，我们需要将任意图像格式化为这些规格。这就是<em class="lp"> format_yolov5 </em>该做的事情:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="684b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lp"> format_yolov5 </em>的C++代码为<em class="lp"> : </em></p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="e416" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">注意，默认情况下，OpenCV加载彩色图像作为BGR。对源图像进行处理以获得平方图像的过程如下所示:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/da5615fbca6c1fc2c86992ea55d6984c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*sTYqFCLBmOZ9RXLGeSBjqQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">formatting an arbitrary size image to be squared</figcaption></figure><p id="0c59" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一旦图像被格式化，调用模型就简单了，如下所示:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="ebe1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">或者在C++中:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="9fa5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这一步中，我们程序99%的CPU使用率都是很高的。现在，让我们看看如何使用<code class="du lr ls lt lu b">output</code>结果。</p><h2 id="39df" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">步骤3-展开输出</h2><p id="bfa4" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">在前面的步骤中，YOLOv5执行了对象检测，返回了在<code class="du lr ls lt lu b">output</code> 2D数组中找到的所有检测结果。下图显示了该数据的结构:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/703c6a5f44c849b5e192900c72cd31bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*TTIjlngab-d7QN7NWtF6Gg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">structure of prediction result</figcaption></figure><p id="85f4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个数组有25，200个位置，每个位置是一个85长度的1D数组。每个1D阵列保存一次探测的数据。该数组的前4个位置是边界框矩形的<code class="du lr ls lt lu b">xywh</code>坐标。第五个位置是该检测的置信水平。第6到第85个元素是每个类的分数。下面的代码显示了如何从2D数组中打开数据:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="91c7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当然，并非25，200次检测中的每一次都是实际检测。我们使用某个阈值，通过<code class="du lr ls lt lu b">if confidence &gt; 0.4:</code>测试剔除低置信度检测。</p><p id="d9d0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">值得注意的是，YOLOv5认为输入图像是640x640。因此，有必要将<code class="du lr ls lt lu b">xywh</code>坐标重新缩放至实际输入尺寸:</p><pre class="jt ju jv jw fd lw lu lx ly aw lz bi"><span id="08a2" class="jx jy hh lu b fi ma mb l mc md">x, y, w, h = row[0], row[1], row[2], row[3]<br/>left = int((x - 0.5 * w) * x_factor)                                             top = int((y - 0.5 * h) * y_factor)                                             width = int(w * x_factor)                                             height = int(h * y_factor)                                             box = [left, top, width, height]                                             boxes.append(box)</span></pre><p id="de27" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们还使用了<code class="du lr ls lt lu b">cv2.minMaxLoc</code>来查找每个检测中得分最高的类id。</p><p id="beab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">即使过滤低水平置信度检测，前面的代码也会生成重复的框:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es me"><img src="../Images/703afba8e90a550f2304e332bfad3bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*iqBx-vh_nxCaiwfnUPnzGA.png"/></div></figure><p id="1b7b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当然，这种重叠是不希望的。为了避免这种情况，通常使用<strong class="iw hi">非最大抑制</strong> (NMS)算法来消除重叠/重复检测:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/2ecebde4ec8848ef6b5f975f6accbec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*FjjeM73CciJdO-h3PHcxUQ.png"/></div></figure><p id="4a6d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">用NMS剪枝解开预测的C++代码如下:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><h2 id="200e" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">步骤4—打印生成的图像</h2><p id="c8d9" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">我们工作中最困难的部分已经完成。现在，让我们使用得到的预测来打印带有检测结果的图像:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="e310" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个代码里没有火箭科学。我们只是使用OpenCV函数来打印检测到的盒子和类标签。</p><h2 id="7a8d" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">附加(但重要)主题:CUDA</h2><p id="71c4" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">运行计算机视觉需要大量的处理时间。通常，即使强大的CPU也不足以提供实时对象检测。</p><p id="c23f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">装有NVIDIA卡的计算机可以通过使用一种称为CUDA的技术，使用其GPU来处理代码。幸运的是，在我们的案例研究中使用CUDA非常简单。基本上，要求模型使用它:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="e040" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">或者使用C++:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="24de" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你没有带NVIDIA卡的电脑，代码会自动切换回CPU模式。如果你有一台装有NVIDIA卡的电脑，但代码不能在GPU上运行，也许你需要重新<a class="ae it" href="https://www.pyimagesearch.com/2016/07/11/compiling-opencv-with-cuda-support/" rel="noopener ugc nofollow" target="_blank">安装支持CUDA的OpenCV</a>。</p><p id="f600" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，将YOLOv5与CUDA结合使用，我们可以实现实时性能:</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="mg lo l"/></div></figure><h2 id="784c" class="jx jy hh bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">完整代码</h2><p id="97cb" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr ha bi translated">这里使用的完整代码可以在这个<a class="ae it" href="https://github.com/doleron/yolov5-opencv-cpp-python" rel="noopener ugc nofollow" target="_blank"> github库</a>中找到。</p><div class="mh mi ez fb mj mk"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">medium.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my in mk"/></div></div></a></div></div></div>    
</body>
</html>
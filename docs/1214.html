<html>
<head>
<title>Use Case: Wildfire Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用例:野火检测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/use-case-wildfire-detection-62e727d04ac7?source=collection_archive---------2-----------------------#2021-10-28">https://medium.com/mlearning-ai/use-case-wildfire-detection-62e727d04ac7?source=collection_archive---------2-----------------------#2021-10-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/092ec0f80deb22293ff2815f3a05294d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mteg8nNse3EHs8NQJLJo4w.jpeg"/></div></div></figure><p id="7624" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">每年，由于野火蔓延，数百万公顷的森林消失。然而，使用图像识别，当局现在可以从高速公路或建筑物上的摄像机拍摄的实时图像中识别野火。</p><p id="c139" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">受到使用深度学习来帮助拯救环境的潜力的启发，我们在<a class="ae jn" href="https://www.perceptilabs.com/" rel="noopener ugc nofollow" target="_blank"> PerceptiLabs </a>中建立了一个图像识别模型，可以分析场景图像来检测火灾。政府或环保组织可能会使用这种模型在火势蔓延太远之前向消防队员发出警报。</p><p id="1a50" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">数据集</strong></p><p id="df4d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了训练我们的模型，我们在<a class="ae jn" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上使用了来自<a class="ae jn" href="https://www.kaggle.com/brsdincer/wildfire-detection-image-data" rel="noopener ugc nofollow" target="_blank">野火探测图像数据</a>的图像。该数据集包括1900个250x250像素。jpg文件，其中一些如图1所示:</p><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es jo"><img src="../Images/7dad254aa9204baa18f05097b8ec5305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/0*h5hqRh3OmbEOs2OC"/></div></figure><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es jt"><img src="../Images/db4ae1ccc1df4bf7aac2b0a97046a698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/0*wLD7cqOfhVTVfDRp"/></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Figure 1: Examples of images from the dataset.</em></figcaption></figure><p id="6666" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了对这些图像进行分类，我们设计了两个分类标签:<strong class="ir hi"> fire </strong>和<strong class="ir hi"> no_fire </strong>，并创建了一个. csv文件将它们与每个图像文件相关联，以便使用PerceptiLabs的<a class="ae jn" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>加载数据。下面是一个部分的例子。csv文件看起来:</p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jz"><img src="../Images/58413677ede148b12a908c7482dab384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w2o0_BaMlQL-OoUER4Fy3Q.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Example of the .csv file to load data into PerceptiLabs that maps the image files to their classification labels.</em></figcaption></figure><p id="6e95" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">型号总结</strong></p><p id="2bb9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于我们的模型，我们构建了一个CNN模型，包括以下<a class="ae jn" href="https://docs.perceptilabs.com/perceptilabs/references/components" rel="noopener ugc nofollow" target="_blank">组件</a>:</p><p id="9480" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">组件0:重新缩放，63 x 63，输入:输入组件，输出:组件6</p><p id="83e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">组件1:卷积，激活= <a class="ae jn" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，特征映射=8，Patch_size=4，Batch_Norm=Yes，输入:输入组件，输出:组件2和组件4</p><p id="8f35" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">分量2:卷积，激活= <a class="ae jn" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，特征映射=16，输入:分量1，输出:分量3</p><p id="e93a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">组件3:重新缩放，125x125，输入:组件2，输出:组件4，组件4:合并，运算=串联，-1</p><p id="377f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">输入:组件3和组件1，输出:组件5，组件5:卷积，激活=ReLU，特征映射=32，面片大小=3，输入:组件4，输出:组件6，组件6:合并，运算=连接，-1，输入:组件5和组件0，输出:组件7</p><p id="8eb1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">组件7:卷积，激活=ReLU，特征映射=64，面片大小=3，输入:组件6，输出:到组件8</p><p id="572d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">组件8:密集，激活=LeakyReLU，神经元=512，输入:组件7，输出:组件9</p><p id="289a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">组件9:密集，激活=Softmax，神经元=2，输入:组件8，输出:输出</p><p id="84b7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如下图2所示，该模型本质上是一个小型的<a class="ae jn" href="https://blog.perceptilabs.com/guide-to-using-unets-for-image-segmentation/" rel="noopener ugc nofollow" target="_blank"> U-Net </a>变体，具有标准U-Net所具有的跳过连接的类似优势。通过这种架构，我们将<em class="ka">收缩</em>路径中的图像卷积并汇集到特征地图中，同时使用跳过连接将信息传递到<em class="ka">扩展</em>路径。然后，扩展路径将特征信息与空间信息结合在一起，然后使用全连接层(密集组件)进行二元分类，分为<strong class="ir hi"> fire </strong>和<strong class="ir hi"> no_fire </strong>。</p><p id="deae" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图2显示了感知实验室中模型的拓扑结构:</p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kb"><img src="../Images/6cb17d6e117a6c57b7283e1c370d8fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zRgLQczC903ATTzF"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Figure 2: Topology of the model in PerceptiLabs.</em></figcaption></figure><p id="526a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">训练和结果</strong></p><p id="5e99" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">我们使用<a class="ae jn" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20a%20replacement%20optimization,sparse%20gradients%20on%20noisy%20problems." rel="noopener ugc nofollow" target="_blank"> ADAM </a>优化器、0.001的学习率和交叉熵<a class="ae jn" href="https://blog.perceptilabs.com/choosing-and-customizing-loss-functions-for-image-processing/" rel="noopener ugc nofollow" target="_blank">损失</a>函数，在三个时期</strong>分批训练模型，每批32个。平均训练时间约为269.73秒，<strong class="ir hi">我们实现了97.82%的训练准确率和96.05%的验证准确率:</strong></p><p id="babc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图3显示了PerceptiLabs的统计视图:</p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kb"><img src="../Images/3e6bde0774cb94035ad650872029bb2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rbgNNUxoMX1TzonV"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Figure 3: PerceptiLabs’ Statistics View during training.</em></figcaption></figure><p id="492a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下面的图4和图5显示了各时期的精度和损耗:</p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kc"><img src="../Images/889b6f8533098aa4b67f4d09e80b8672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*777-n_P4-GsCKuHs"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Figure 4: Accuracy during training and validation.</em></figcaption></figure><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kc"><img src="../Images/5669215fc5e17b499e141167d4fee0dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*J_RbzBrbpY8AE5GS"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Figure 5: Loss during training and validation.</em></figcaption></figure><p id="2f68" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在图4中，我们可以看到，训练和验证的准确性开始时相对较高，并且以大约相同的速度增加。在图5中，训练损失开始时很高，验证损失开始时很低，但是到第二个时期时两者都差不多。</p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kd"><img src="../Images/25e26d19340e73252f3ec2c904fb75a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AKG91KzATuYcU0hz"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx"><em class="jy">Figure 6: Classification metrics and confusion matrix.</em></figcaption></figure><p id="b8ef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图6中的混淆矩阵显示了两个非常相似的蓝色阴影，表明该模型几乎总是正确地测试所有样本。<strong class="ir hi">标签度量表</strong>通过显示以下各项的接近97%的标准化值证实了这一点:<strong class="ir hi">分类准确度</strong>(每个类别的准确度对所有类别进行平均)<strong class="ir hi">精确度</strong>(正面预测的准确度)，以及<strong class="ir hi">召回</strong>(找到的正面的百分比(即，没有被错误分类为负面而不是正面)<strong class="ir hi">前K个分类准确度</strong>(前K个预测类别中正确类别的频率)的100%。</p><p id="e1b4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">垂直应用</strong></p><p id="e634" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">像这样的模型可以用作分析不同类型的环境图像以检测异常的基础。通过将这个模型用于<a class="ae jn" href="https://blog.perceptilabs.com/when-to-use-transfer-learning-in-image-processing/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>，你可以潜在地开发出检测其他类型问题的模型，例如洪水、侵蚀或泥石流。它还可以被修改为处理其他数据类型，如卫星图像，以检测未经授权的森林砍伐，水位上升或冰山融化。</p><p id="0183" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">自己试试吧！</strong></p><p id="973f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们已经在<a class="ae jn" href="https://github.com/PerceptiLabs/Wildfire-Detection" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上提供了你自己尝试它所需要的一切。</p><p id="a218" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用PerceptiLabs，您可以通过<a class="ae jn" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>快速加载这些数据，并使用上面的设置构建一个这样的模型，而无需编写任何代码。或者，使用我们已经包含的<strong class="ir hi"> model.json </strong>文件将我们的模型直接导入到PerceptiLabs中(需要PerceptiLabs 0.12.0或更高版本)。无论哪种方式，您都可以立即开始运行！</p><p id="ac53" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，您可以轻松地切换到不同的数据集，对新数据进行训练，和/或使用新的组件和连接调整模型的拓扑。然后，只需点击几下鼠标就可以导出训练好的模型，之后，模型文件就可以由您的应用程序托管，用于现实世界的推理。</p><p id="c56f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">总结</strong></p><p id="4dec" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个用例是一个例子，说明图像识别如何用于检测危险的环境条件。如果你想建立一个类似这样的深度学习模型，<a class="ae jn" href="https://docs.perceptilabs.com/perceptilabs/getting-started/quickstart-guide" rel="noopener ugc nofollow" target="_blank">运行PerceptiLabs </a>并在<a class="ae jn" href="https://github.com/PerceptiLabs/Wildfire-Detection" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上查看我们为这个用例创建的回购。对于另一个环境用例，请务必查看使用图像识别的<a class="ae jn" href="https://blog.perceptilabs.com/use-case-automated-weather-analysis-using-image-recognition/" rel="noopener ugc nofollow" target="_blank">自动天气分析</a>。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Introduction to object detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对象检测简介</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/introduction-to-object-detection-8be574b82d5c?source=collection_archive---------2-----------------------#2022-05-09">https://medium.com/mlearning-ai/introduction-to-object-detection-8be574b82d5c?source=collection_archive---------2-----------------------#2022-05-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f06f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di">在</span>机器学习中，得益于计算机视觉，计算机能够“识别”物体。但你有没有问过自己，在给定的场景中，计算机是如何识别和定位物体的？。在这篇文章中，我们旨在回答这个问题。我们走吧…！😎</p><h2 id="0466" class="jl jm hh bd jn jo jp jq jr js jt ju jv ip jw jx jy it jz ka kb ix kc kd ke kf bi translated">什么是计算机视觉？</h2><p id="7a0f" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip ki ir is it kj iv iw ix kk iz ja jb ha bi translated">计算机视觉(CV)是人工智能的一个领域，试图让计算机从图像和视频中提取信息。在CV领域，有许多不同的任务，例如:图像分类、语义分割、对象检测、实例分割等。这里我们将介绍给定图像中单个目标的目标检测任务。</p></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><h2 id="1804" class="jl jm hh bd jn jo jp jq jr js jt ju jv ip jw jx jy it jz ka kb ix kc kd ke kf bi translated">目标检测</h2><p id="ae07" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip ki ir is it kj iv iw ix kk iz ja jb ha bi translated">一般来说，对象检测试图回答以下问题:</p><p id="bd01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">【什么】</strong>物体在一个图像中，“<strong class="ig hi"/>它们在哪里？</p><ul class=""><li id="6d91" class="ks kt hh ig b ih ii il im ip ku it kv ix kw jb kx ky kz la bi translated">“什么”意味着分类，即在给定图像中标记每个对象；</li><li id="a3ff" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">“其中”意味着边界框，指的是在给定图像中定位对象的位置。</li></ul><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lg"><img src="../Images/f1ed2cb284ac76219ed6bbe992f7844b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iNtDA8-SIs0Gf29xeRNfFA.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx">Figure1: Made in canvas</figcaption></figure><p id="df02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，对于给定的输入(图像、视频)，对象检测器旨在预测每个对象的边界框和标签。</p><p id="d44b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，考虑我们想要检测给定图像中的单个对象，如图x所示。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lw"><img src="../Images/0946de71a73f211c7d63ecccfd92b8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lfcvPKICCEtcNYLgtMLt9Q.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx">Figure2 : <a class="ae lx" href="https://project.inria.fr/bigvisdata/files/2020/01/cs231n_2019_lecture12_detection.pdf" rel="noopener ugc nofollow" target="_blank">Detecting a single object</a></figcaption></figure><ul class=""><li id="1bc8" class="ks kt hh ig b ih ii il im ip ku it kv ix kw jb kx ky kz la bi translated">为了提取特征，输入图像将通过卷积神经网络(CNN)。这个特征提取器可以是一个相关的模型，如<a class="ae lx" href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html" rel="noopener ugc nofollow" target="_blank">亚历克斯网</a>、<a class="ae lx" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> VGG网</a>等。</li><li id="4cce" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">CNN过程的输出馈入一个完全连接的层以获得我们的最终特征向量，从这里任务被分成两部分；第一部分是分类器(例如:带有softmax、SVM、随机森林的线性图层),用于将这些向量分类为已知类别之一，第二部分是回归器，用于预测与分类对象相关联的边界框的坐标。在第二种情况下，模型的输出是图像中定位对象的X，Y坐标、宽度(W)和高度(H)。</li><li id="815c" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">现在我们可以看到，目标检测需要一个多任务损失来实现分类和定位。</li></ul><p id="9a5e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> a .分类损失</strong></p><p id="7571" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当处理分类任务时，我们使用交叉熵损失，如下式所定义。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es ly"><img src="../Images/937b8e3447001aa4ba4662cd4b7feb0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zZELZfpKHjR3dxqPcfOSg.png"/></div></div></figure><p id="53e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一般来说，查看混淆矩阵也有助于了解我们的模型的行为以及该模型更擅长预测哪些类别，这些信息也可用于计算指标，即准确度、精确度和召回率。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lz"><img src="../Images/4e35aabcd855eda84dd82a2f16eca3ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XFCW1qr0PzFohIPD1i_zdg.png"/></div></div></figure><p id="94c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b .回归损失</strong></p><p id="d975" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了测量预测的边界框离它们的基本事实有多远，我们可以使用L1范数或L2范数(称为MSE损失)作为我们的损失函数。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es ma"><img src="../Images/7e0b66f43732b6f943bd9946d7a18749.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*8ieszC217o-MFfA6FHMxAw.png"/></div></figure><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es mb"><img src="../Images/b7a2685e0378d349ddf10a1d8077e1b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*_isgJOGrIRvW3tahZVOWzw.png"/></div></figure><p id="746a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中y_hat是边界框的预测坐标，y是地面真实坐标。</p><p id="b408" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一个在许多对象检测模型中广泛使用的回归损失函数是并集上的交集(IoU) [1]，也称为Jaccard指数，IoU比较两个任意框之间的相似性。根据定义，它计算两个边界框的重叠部分，并将其除以它们的并集。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es mc"><img src="../Images/251078ba7740380cdd286f69edd5ae2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYgpXFKu-ZUY8DM68J_bAg.jpeg"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx">Figure4: <a class="ae lx" href="https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles/overview/evaluation" rel="noopener ugc nofollow" target="_blank">IoU</a></figcaption></figure><p id="3170" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">检测器的最终损失是分类损失和回归损失的<strong class="ig hi">加权和</strong>。执行加权求和的想法是控制每个损失的大小(一个损失可能比另一个损失的大小更大)，因此较大的损失不会在总损失中占主导地位。</p><p id="b0e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">图片可以有多个对象！在这种情况下，我们如何在单个图像中识别和定位多个对象？</strong></p><p id="f20e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">迄今为止，已经使用了几种方法；其中有<a class="ae lx" href="https://ieeexplore.ieee.org/abstract/document/655647" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">滑动窗口</strong></a><a class="ae lx" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">R-CNN</strong></a>(使用选择性搜索)<a class="ae lx" href="https://arxiv.org/abs/1504.08083" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">快速R-CNN</strong></a><a class="ae lx" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">更快R-CNN </strong> </a>。</p><h1 id="5769" class="md jm hh bd jn me mf mg jr mh mi mj jv mk ml mm jy mn mo mp kb mq mr ms ke mt bi translated">结论</h1><p id="4f23" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip ki ir is it kj iv iw ix kk iz ja jb ha bi translated">在这篇文章的最后，我们简要介绍了对象检测模型的架构，以及它如何在给定的输入图像中处理单个对象。在我们的下一篇文章中，我们将简要介绍Mask-RCNN的工作原理，并使用Detectron2展示它的应用。</p><p id="2c40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢阅读，并希望它是有见地的😉。</p></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><p id="db43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献:</strong></p><p id="b808" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]:于，江，杨，王，曹，黄，2016年10月。Unitbox:一种先进的目标探测网络。第24届ACM多媒体国际会议论文集(第516-520页)。</p><div class="mv mw ez fb mx my"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">medium.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm lq my"/></div></div></a></div></div></div>    
</body>
</html>
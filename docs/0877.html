<html>
<head>
<title>Use Case: Retinal OCT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用例:视网膜OCT</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/use-case-retinal-oct-24cc75e314fc?source=collection_archive---------3-----------------------#2021-08-10">https://medium.com/mlearning-ai/use-case-retinal-oct-24cc75e314fc?source=collection_archive---------3-----------------------#2021-08-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/3490ca7abfca7fdfbacba64c0b4fc8a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jlUOBN-Y5mk8lQ54KssbtA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://unsplash.com/photos/G1iYCeCW2EI" rel="noopener ugc nofollow" target="_blank">Image Source</a>.</figcaption></figure><p id="868c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">人眼是一个复杂的感觉器官，它对光做出反应，为我们提供观察周围世界的视野。保护我们的眼睛是我们整体医疗保健的一个重要方面。然而，我们的眼睛容易受到一些疾病的影响，其中一些疾病可以归因于其他疾病，甚至只是因为衰老。</p><p id="dd99" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">医疗从业者用来检测这些问题的一种方法是<a class="ae it" href="https://www.aao.org/eye-health/treatments/what-is-optical-coherence-tomography" rel="noopener ugc nofollow" target="_blank">光学相干断层扫描</a> (OCT)。OCT涉及使用光波构建视网膜的横截面图像，允许从业者绘制和测量视网膜的各层。每年都有数百万次这样的扫描，对它们进行分析需要大量的时间。</p><p id="afc5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">随着(机器学习)ML在医疗保健中的使用越来越多，我们开始在<a class="ae it" href="https://www.perceptilabs.com/" rel="noopener ugc nofollow" target="_blank">感知实验室</a>中建立一个图像识别模型，该模型可以分析视网膜OCT图像，以自动分析这些扫描。像这样的模型可以帮助医生、研究人员和其他医疗从业者更快、更准确地诊断眼病。</p><p id="f2b1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">数据集</strong></p><p id="fd15" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了训练我们的模型，我们使用了来自<a class="ae it" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上<a class="ae it" href="https://www.kaggle.com/paultimothymooney/kermany2018" rel="noopener ugc nofollow" target="_blank">视网膜OCT图像</a>数据集的图像。原始数据集超过80，000个。不同分辨率的jpeg图像分为四类。一个分类代表<em class="js">正常的</em> OCT扫描(即未检测到疾病)，其他分类是三种疾病的OCT扫描:<em class="js">脉络膜新生血管</em>(CNV)<em class="js">糖尿病性黄斑水肿</em> (DME)，以及<em class="js">玻璃疣</em>(即早期老年性黄斑变性(AMD)中存在多个玻璃疣)。</p><p id="f1f3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">原始数据集是不平衡的，CNV的图像超过44.6%，正常的图像为31.5%，DME的图像为13.6%，而Drusen的图像为10.3%。为了消除训练过程中的潜在偏差，我们使用每个分类的4000个图像的子集制作了一个平衡数据集。</p><p id="db07" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">图1显示了该数据集中的一些示例图像:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jt"><img src="../Images/2ff5b4ab4d59ad26cfa4301e3620054e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0Jc6t-_ncl91ZUEi"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jy">Figure 1: Examples of images from the dataset — </em><a class="ae it" href="https://www.kaggle.com/paultimothymooney/kermany2018" rel="noopener ugc nofollow" target="_blank"><em class="jy">Image Source</em></a><em class="jy">.</em></figcaption></figure><p id="7a93" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了将分类映射到图像，我们创建了一个. csv文件，该文件将每个图像文件与适当的分类标签(<em class="js"> CNV </em>、<em class="js"> DME </em>、<em class="js">德鲁森</em>和<em class="js">普通</em>)相关联，以便使用PerceptiLabs的<a class="ae it" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>加载数据。下面是一个部分的例子。csv文件看起来:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jz"><img src="../Images/afb38513999b9b6ed4947d7c94ed2eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5SV_NK8RQ5RrQ3g3O--ebw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jy">Example of the .csv file to load data into PerceptiLabs that maps the image files to their classification labels.</em></figcaption></figure><p id="768c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">型号总结</strong></p><p id="1c79" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的模型由四个<a class="ae it" href="https://docs.perceptilabs.com/perceptilabs/references/components" rel="noopener ugc nofollow" target="_blank">组件</a>组成:</p><p id="9ec4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">组件1:合并，来自同一输入源的三个输入。</p><p id="c28e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">组件2: <a class="ae it" href="https://keras.io/api/applications/mobilenet/" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>，include_top=false，pretrained=imagenet</p><p id="c49c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">成分3:密集，激活= <a class="ae it" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，神经元=128</p><p id="ea32" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">组件4:密集，激活= <a class="ae it" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，神经元=4</p><p id="72f7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该模型通过MobileNetV2和合并组件使用迁移学习将灰度图像转换为RGB。这是MobileNet的一个要求，因为它使用的是一个预训练模型，该模型的权重是固定的，其第一个卷积层是根据三个通道(RGB)的输入进行训练的。图2显示了感知实验室中模型的拓扑结构:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ka"><img src="../Images/a6e5b4a47b03d3855b66e783748c3e83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WjBkMiGSQei1sdK1"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jy">Figure 2: Topology of the model in PerceptiLabs — </em><a class="ae it" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"><em class="jy">Image Source</em></a><em class="jy">.</em></figcaption></figure><p id="33f8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">培训和结果</strong></p><p id="8137" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">我们使用<a class="ae it" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20a%20replacement%20optimization,sparse%20gradients%20on%20noisy%20problems." rel="noopener ugc nofollow" target="_blank"> ADAM </a>优化器、0.001的学习率和交叉熵<a class="ae it" href="https://blog.perceptilabs.com/choosing-and-customizing-loss-functions-for-image-processing/" rel="noopener ugc nofollow" target="_blank">损失</a>函数，在10个时期</strong>中分批训练模型，每批32个。在大约11.5分钟的训练时间内，<strong class="iw hi">我们实现了95.78%的训练准确率和83.69%的验证准确率</strong>。</p><p id="7ebf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">图3显示了训练期间PerceptiLabs的统计视图:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kb"><img src="../Images/2ca3e75eccc1a86a9ae4a62d535439bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_dfsYtTd2lt5LK6y"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jy">Figure 3: PerceptiLabs’ Statistics View during training — </em><a class="ae it" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"><em class="jy">Image Source</em></a><em class="jy">.</em></figcaption></figure><p id="3a7d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面的图4和图5显示了训练期间10个时期的准确度和损失:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kc"><img src="../Images/c6333309740afd4f34fb8db9a3b73230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yzn9rqH2C2j94No9"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jy">Figure 4: Accuracy during training — </em><a class="ae it" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"><em class="jy">Image Source</em></a><em class="jy">.</em></figcaption></figure><figure class="ju jv jw jx fd ii er es paragraph-image"><div class="er es kd"><img src="../Images/1eba111517df41dcf245bba54cadb659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/0*Tpg5e8cPsA_bV1CW"/></div><figcaption class="ip iq et er es ir is bd b be z dx"><em class="jy">Figure 5: Loss during training — </em><a class="ae it" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"><em class="jy">Image Source</em></a><em class="jy">.</em></figcaption></figure><p id="5680" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在图4中，我们可以看到，训练和验证的准确性都是从大约79%到80%开始的。训练精度继续攀升，在第七个历元左右稳定下来，而验证精度始终没有什么提高。有趣的是，训练损失(如图5所示)在第一个时期下降最多，然后在整个训练过程中稳步下降，同时经历了几次短暂的小幅上升。另一方面，确认损失保持相当稳定，直到大约第五个时期，在第五个时期，确认损失缓慢增加，直到最后一个时期结束。</p><p id="56e8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">垂直应用</strong></p><p id="def1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">像这样的模型可以被需要检测视网膜疾病的医疗从业者和研究人员使用。该模型可用于分析大量图像，标记需要进一步关注的病例。该模型本身也可以用作<a class="ae it" href="https://blog.perceptilabs.com/when-to-use-transfer-learning-in-image-processing/" rel="noopener ugc nofollow" target="_blank">转移学习</a>的基础，以创建用于从其他类型的医学扫描中检测疾病的附加模型。</p><p id="75ef" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">总结</strong></p><p id="bcd3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该使用案例展示了图像识别在医疗保健领域的应用。如果你想建立一个类似这样的深度学习模型，<a class="ae it" href="https://docs.perceptilabs.com/perceptilabs/getting-started/quickstart-guide" rel="noopener ugc nofollow" target="_blank">运行PerceptiLabs </a>并在<a class="ae it" href="https://github.com/PerceptiLabs/RetinalOCT" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上查看我们为这个用例创建的回购。另外，请务必查看我们的另一个与眼睛相关的用例:<a class="ae it" href="https://blog.perceptilabs.com/use-case-ocular-disease-recognition/" rel="noopener ugc nofollow" target="_blank">眼病识别</a>。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Simple Linear Regression — GRE Admission Predictor from scratch in python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单线性回归python中从头开始的GRE录取预测</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/linear-regression-gre-admission-predictor-801b0cfee409?source=collection_archive---------4-----------------------#2022-01-12">https://medium.com/mlearning-ai/linear-regression-gre-admission-predictor-801b0cfee409?source=collection_archive---------4-----------------------#2022-01-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="7218" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">简介</strong></h1><p id="20ca" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">线性回归是一种回归分析形式，它使用y = (m*x) + c公式，这是一个斜率截距公式，其中m =斜率，x =自变量，y =因变量，c是常数。这是一种预测分析，然而，线性回归的问题是它只有一个因变量和一个自变量。</p><p id="c1d5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">总是x轴是自变量，y轴是因变量。我们需要检查数据集，看数据集中的任何两列之间是否存在任何关联，以检查我们是否可以应用线性回归模型。</p><ul class=""><li id="e9e1" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated">获取Github的完整代码:<a class="ae ko" href="https://github.com/durveshshah/Machine-Learning/blob/main/Linear%20Regression%20using%20Dataset.ipynb" rel="noopener ugc nofollow" target="_blank">https://Github . com/durveshshah/Machine-Learning/blob/main/Linear % 20 regression % 20 using % 20 dataset . ipynb</a></li></ul><p id="e705" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi"> GRE录取预测器</strong></p><p id="5454" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在我们的案例中，有许多不同的栏目，但我决定将GRE分数和录取机会作为我们的主要特征。你可以选择任意两列。对于多元线性回归，我们需要两个或更多的自变量。</p><p id="e18e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">下一步是数据清理，所以我只检查了空值和缺失值。我做的下一步是给每个列标题添加一个下划线，以便更容易阅读我们的数据集。</p><p id="8735" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">最后，通过使用公式y = (m*x) + c，我画出了预测线和图表，你可以在下面的图片中看到。</p><figure class="kp kq kr ks fd kt"><div class="bz dy l di"><div class="ku kv l"/></div></figure><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kw"><img src="../Images/2b1722217f5fc81958d28cd22818b22b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cNeimi9ULAXRphz4oKGPlw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Dataframe</figcaption></figure><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lh"><img src="../Images/714cf2065e7c6a7b274c8526c1ed91f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*mX7xsziUS1vDMFaPyDQdvw.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Final Dataframe</figcaption></figure><h1 id="14d8" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">输出—已解释</h1><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es li"><img src="../Images/91879f00d0bd91962526791f0e90548a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8AAW3cednYcmpG97fp7ZAg.png"/></div></figure><h1 id="b610" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">R平方的概念</strong></h1><p id="b393" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">r平方是数据点与拟合预测线接近程度的实际比例。</p><p id="ce8e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">r平方始终介于0和1之间，其中0表示模型完全不适合，1表示模型100%适合。r平方值越高，模型越有可能准确。</p><p id="7ece" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在我的例子中，训练集的R平方值是0.6857609801903284，相当于<strong class="je hi">68.57%</strong>，根据我们的数据集，这相对来说还不错。这也很大程度上取决于我们的数据集。测试集的R平方值为0.5910844839999462，相当于<strong class="je hi"> 59.10 %。</strong></p><p id="565b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">不要忘记在Github上关注我，并支持新的和额外的内容。</p><p id="ac33" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">Github简介:<a class="ae ko" href="https://github.com/durveshshah" rel="noopener ugc nofollow" target="_blank">https://github.com/durveshshah</a></p><p id="188c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">谢谢你</p><div class="lj lk ez fb ll lm"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ln ab dw"><div class="lo ab lp cl cj lq"><h2 class="bd hi fi z dy lr ea eb ls ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lt l"><h3 class="bd b fi z dy lr ea eb ls ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lu l"><p class="bd b fp z dy lr ea eb ls ed ef dx translated">medium.com</p></div></div><div class="lv l"><div class="lw l lx ly lz lv ma lb lm"/></div></div></a></div><p id="540c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">🟠 <a class="ae ko" href="https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb" rel="noopener"> <strong class="je hi">成为作家</strong> </a></p></div></div>    
</body>
</html>
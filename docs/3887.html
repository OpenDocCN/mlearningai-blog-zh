<html>
<head>
<title>ML Algorithm: Logistic Regression for a Base Model.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML算法:基础模型的逻辑回归。</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/ml-algorithm-logistic-regression-for-a-base-model-35ca5f5029e4?source=collection_archive---------5-----------------------#2022-11-03">https://medium.com/mlearning-ai/ml-algorithm-logistic-regression-for-a-base-model-35ca5f5029e4?source=collection_archive---------5-----------------------#2022-11-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/01383c9311dabac685f199e4518f9e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kT4InkJvVScXnwOu"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/ja/@geromebruneau?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Gérôme Bruneau</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="0f56" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通常现实世界中有监督的机器学习问题是分类问题而不是回归问题，这里我们需要预测的<strong class="iw hi"><em class="js"/></strong>的定性值通常称为<strong class="iw hi"> <em class="js">类别</em> </strong>或<strong class="iw hi"> <em class="js">类别</em> </strong>。比如:预测一个客户是会<em class="js">流失</em>还是<em class="js">而不是</em>，或者我们需要发现一个肿瘤是<em class="js">恶性</em>还是<em class="js">良性</em>的问题。</p><p id="4bab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">回归算法预测数字输出值，而分类算法预测给定实例所属的特定类。预测分类响应值的过程被称为<strong class="iw hi"> <em class="js">分类</em></strong>；</p><p id="aed7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="js">逻辑回归</em>被认为是分类问题中基础模型的首选之一。在本文中，您将学习逻辑回归的基础知识，为什么它被命名为回归，以及它的数学实现和一个案例研究的例子。</p><p id="66b6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在学习逻辑回归算法之前，让我们先了解为什么我们需要另一种算法来进行预测，以及为什么我们不能使用线性回归。</p><p id="6a02" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们考虑一个机器学习的经典例子；iris-flower数据集，其中我们需要使用<strong class="iw hi"> <em class="js">线性回归</em> </strong>算法来预测三个物种(<em class="js"> Iris-setosa、Iris-virginica、Iris-versicolor </em>)中的<strong class="iw hi"> <em class="js"> iris-flower </em> </strong>的类别。</p><p id="9c4f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">线性回归算法假设<em class="js">响应变量</em> <strong class="iw hi"> Y </strong>是一个数值。因此，让我们将分类变量Y值转换成数值响应值，如<em class="js">鸢尾属的<em class="js"> 1 </em>，鸢尾属的<em class="js">2</em>，鸢尾属的</em>和<em class="js"> 3 </em>。</p><p id="6558" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在对数据训练模型之后，该算法以这样的方式学习Y值之间的关系，即Iris-setosa和Iris-virginica之间的差异与Iris-virginica和Iris-versicolor之间的差异相同。但在现实中，没有这样的排序，人们可以选择任何其他数值，这将导致一个具有新关系的新模型，它可能预测不同的测试数据预测值集。</p><p id="17ac" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果响应变量值中存在自然排序(例如低、中和高)，那么用具有相同间隙的有序数据对其进行编码将是合理的，但大多数情况下，这是不实际的。</p><p id="1f69" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">用于二元分类(仅用于两类，如真/假或1/0)。例如，如果我们需要预测客户是否会流失，那么我们可以忽略y是离散值的事实来处理分类问题，并使用我们的线性回归算法来预测给定X值的输出y。</p><p id="5a92" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以预测，如果y &gt;= 0.5，客户会流失；如果y小于0.5，客户不会流失。但是有时输出很难解释，因为预测值可能大于1或小于0。但实际上y必须在0和1之间。</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jt"><img src="../Images/c292a8b44f3df97ca4a698c5c4e6bedd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_srRW_em2o-7jUhRrkKUw.png"/></div></div></figure><h1 id="e822" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">表现</h1><p id="873b" class="pw-post-body-paragraph iu iv hh iw b ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn la jp jq jr ha bi translated">为了避免这个问题，我们必须使用一个函数，该函数对于x的所有值产生范围为0和1的输出。为此，我们使用一个<strong class="iw hi"> <em class="js"> logit函数</em> </strong>或<strong class="iw hi"> <em class="js"> sigmoid函数</em> </strong>，将其应用于线性回归模型函数。</p><p id="acd8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">线性回归的假设函数表示为</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/0315eacde6a411d8fd29650b2295f4e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*TCem33qgZPLyhxCN4Zjlow.png"/></div></figure><p id="97c7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，<code class="du lc ld le lf b">theta</code>表示模型的参数，<code class="du lc ld le lf b">x</code>是输入向量。</p><p id="c6c1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">logit函数表示如下:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div class="er es lg"><img src="../Images/846c7e38ab6d4b56e411b8efee3331b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*CpWdzb_xMwrxCu6eVXm1yw.png"/></div></figure><p id="7a60" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div class="er es lh"><img src="../Images/63a66cb8a61be8d8be33895d87e32e06.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*qLWicvT0wrDymyMCpCg_xg.png"/></div></figure><p id="fa17" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在线性回归函数上应用logit函数，我们得到了逻辑函数的表示:</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div class="er es li"><img src="../Images/3fc6d17ee749c769f8917fc5add59b58.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*oo3QjgC7fchbnc2Xcfd5Yg.png"/></div></figure><p id="7a97" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是<em class="js">逻辑回归</em>模型的表示。通过计算给定输入X的θ值，我们可以计算假设函数的值，然后通过将logit函数应用于我们的假设，我们可以决定给定实例的类。</p><p id="5f63" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">logit函数不产生实际输出(对于二元分类，实际输出是1或0 ),而是计算每个类的概率。</p><figure class="ju jv jw jx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lj"><img src="../Images/809f8db34154f1f4a71659ab3bb63d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGqKUV6O4i8niiuUy2KOdQ.png"/></div></div></figure><p id="f92a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果小于0.5，则标签通常为0或负数；否则，如果它大于0.5，则输出标签为1或正。(这是针对二元分类的)</p><h1 id="b829" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">估价</h1><p id="661b" class="pw-post-body-paragraph iu iv hh iw b ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn la jp jq jr ha bi translated">逻辑回归的成本函数取决于数据点的实际类别。如前所述，函数的输出是类的概率。假设对于类别为1的数据点，logit函数的输出为0.75，则该情况的误差或损失为0.25<em class="js">(1–0.75)</em>。但是如果该数据点属于类别0，那么误差是0.75。</p><p id="0daf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在多类分类中，我们计算每个类的概率，每次选择一个类作为正(1)类，而其他类是负(0)类，然后计算假设。</p><h1 id="dd92" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">逻辑回归的假设</h1><ul class=""><li id="b355" class="lk ll hh iw b ix kw jb kx jf lm jj ln jn lo jr lp lq lr ls bi translated">逻辑回归假设因变量<code class="du lc ld le lf b">y</code>本质上必须是绝对的。</li><li id="2aa2" class="lk ll hh iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated">它假设独立要素之间不存在多重共线性。</li></ul><h1 id="733c" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">线性回归和逻辑回归有什么区别？</h1><p id="c55c" class="pw-post-body-paragraph iu iv hh iw b ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn la jp jq jr ha bi translated">除了对这些算法的因变量<code class="du lc ld le lf b">y</code>的假设。这两种回归模型的主要区别在于</p><ul class=""><li id="7e46" class="lk ll hh iw b ix iy jb jc jf ly jj lz jn ma jr lp lq lr ls bi translated">线性回归的输出是具有单个全局最小值的凸函数，而逻辑回归函数的输出是具有多个局部最小值的非凸函数。</li><li id="a518" class="lk ll hh iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated">逻辑回归预测特定产出的概率，而线性回归预测实际产出。</li></ul><h1 id="69c4" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">逻辑回归的类型</h1><ul class=""><li id="6583" class="lk ll hh iw b ix kw jb kx jf lm jj ln jn lo jr lp lq lr ls bi translated"><strong class="iw hi"> <em class="js">二项式logistic回归</em> </strong> —在二项式Logistic回归中，只有两种可能的结果，例如，1或0，真或假等。</li><li id="ed6e" class="lk ll hh iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated"><strong class="iw hi"> <em class="js">多标逻辑回归</em> </strong> —在多标逻辑回归中，有两种以上可能的无序结果。例如，鸢尾属花卉品种鸢尾、海滨鸢尾和杂色鸢尾。</li><li id="5e90" class="lk ll hh iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated"><strong class="iw hi"> <em class="js">有序逻辑回归</em> </strong> —在有序逻辑回归中，有两个以上可能的有序结果，例如，低、中或高。</li></ul><h1 id="5ec1" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">使用Scikit-learn实现</h1><p id="06e1" class="pw-post-body-paragraph iu iv hh iw b ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn la jp jq jr ha bi translated">让我们使用流行的用于机器学习算法的Python库<em class="js"> scikit-learn </em>来实现逻辑回归算法。</p><p id="4390" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于我们的分类示例，我们将使用流失预测数据，您可以从Kaggle下载该数据集。</p><p id="ba96" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的目标是使用scikit-learn库建立一个逻辑回归模型来预测客户是否会流失。这里，用于训练模型的数据是预处理数据。</p><p id="2a74" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">准备好整个数据集后的第一步是将数据分成训练集和测试集，也可以分成验证集。因此，该模型可以通过在训练数据集上对其进行训练、在验证数据集上进行评估和调整，以及在测试数据集上检查其性能来学习。</p><p id="33c5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们首先导入必要的库，并使用<code class="du lc ld le lf b">read_csv</code>函数将数据读入熊猫的数据框。</p><pre class="ju jv jw jx fd mb lf mc md aw me bi"><span id="0254" class="mf jz hh lf b fi mg mh l mi mj"># Importing libraries<br/>import pandas as pd<br/>import numpy as np<br/><br/>from sklearn.model_selection import train_test_split<br/>from sklearn.feature_extraction import DictVectorizer<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import roc_auc_score<br/><br/># Load the data<br/>df = pd.read_csv("data.csv")</span></pre><p id="5495" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们将数据分成训练集和测试集。我们将使用一个占整个数据集30%的测试集。</p><pre class="ju jv jw jx fd mb lf mc md aw me bi"><span id="5285" class="mf jz hh lf b fi mg mh l mi mj"># Split the data<br/>df_train, df_test = train_test_split(df, test_size=0.3, random_state=1)<br/><br/># shape<br/>print("Training shape:: ", df_train.shape)<br/>print("Testing shape:: ", df_test.shape)</span><span id="967b" class="mf jz hh lf b fi mk mh l mi mj">## Ouput<br/>Training shape:: (4930, 21)<br/>Testing shape:: (2113, 21)</span></pre><p id="7be3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从输出中，我们可以看到我们的训练数据集有4930个训练示例或数据点，而测试数据集有2113个示例。下一步，我们将转换数据，并在训练数据集上训练一个<strong class="iw hi"> <em class="js">逻辑回归</em> </strong>模型。</p><pre class="ju jv jw jx fd mb lf mc md aw me bi"><span id="ac03" class="mf jz hh lf b fi mg mh l mi mj"># create y_train and y_test<br/>y_train = df_train['churn']<br/>y_test = df_test['churn']</span><span id="f2cc" class="mf jz hh lf b fi mk mh l mi mj"># delete `churn` attribute from data<br/>del df_train['churn']<br/>del df_test['churn']</span><span id="604d" class="mf jz hh lf b fi mk mh l mi mj">train_dict = df_train.to_dict(orient='records')<br/>test_dict = df_test.to_dict(orient='records')</span><span id="9217" class="mf jz hh lf b fi mk mh l mi mj"># Data transformation<br/>dv = DictVectorizer(sparse=False)<br/>X_train = dv.fit_transform(train_dict)<br/>X_test = dv.transform(test_dict)</span><span id="f96b" class="mf jz hh lf b fi mk mh l mi mj"># Train the model<br/>clf = LogisticRegression(max_iter=1000, solver='liblinear')<br/>clf.fit(X_train, y_train)</span><span id="3edd" class="mf jz hh lf b fi mk mh l mi mj"># Prediction<br/>y_preds = clf.predict_proba(X_train)<br/>print(y_preds[0])</span><span id="b36a" class="mf jz hh lf b fi mk mh l mi mj">## Output - [0.8218741 0.1781259]</span></pre><p id="393e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这些是训练集中第一个实例的预测概率。<code class="du lc ld le lf b">predict_proba</code>分类器的功能将返回每一类的概率。因为这是一个二进制分类问题，所以上面的输出分别代表了第一个<code class="du lc ld le lf b">train</code>集合的<code class="du lc ld le lf b">class 0</code>和<code class="du lc ld le lf b">class 1</code>的概率数组。</p><p id="bc71" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面的代码将选择第1类的概率，因为我们想要预测客户流失率。</p><pre class="ju jv jw jx fd mb lf mc md aw me bi"><span id="f750" class="mf jz hh lf b fi mg mh l mi mj"># Model evaluation<br/>y_preds = clf.predict_proba(X_train)[:, 1]<br/>auc = roc_auc_score(y_train, y_preds)<br/>print("Train score:: %.3f" % auc)</span><span id="2ef4" class="mf jz hh lf b fi mk mh l mi mj">y_preds = clf.predict_proba(X_test)[:, 1]<br/>auc = roc_auc_score(y_test, y_preds)<br/>print("Test score:: %.3f" % auc)</span><span id="bdb0" class="mf jz hh lf b fi mk mh l mi mj">## Output - <br/>Train score:: 0.845<br/>Test score:: 0.858</span></pre><p id="8ce0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从上面的准确度得分，我们可以说我们的逻辑回归模型将以85%的准确度预测客户是否会流失。</p><p id="c593" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="js">在本文中，我们通过一个客户流失预测的例子学习了用于分类的逻辑回归算法，并简要介绍了数学解释。即使逻辑回归是来自线性回归的假设函数和logit函数的组合。逻辑回归的成本函数的评估不同于线性回归。可以在这里</em>  详细学习逻辑回归 <a class="ae it" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hi"> <em class="js"/></strong></a></p><p id="a6e0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="js">我希望这篇简介能帮助你理解逻辑回归算法的一些基本概念。</em></p><p id="0d09" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">感谢您的阅读！</strong></p><div class="ml mm ez fb mn mo"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hi fi z dy mt ea eb mu ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">medium.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc in mo"/></div></div></a></div></div></div>    
</body>
</html>
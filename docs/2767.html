<html>
<head>
<title>KNN from scratch — Easy Peasy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的KNN——很容易</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/knn-from-scratch-easy-peasy-6c119ae2f582?source=collection_archive---------1-----------------------#2022-06-08">https://medium.com/mlearning-ai/knn-from-scratch-easy-peasy-6c119ae2f582?source=collection_archive---------1-----------------------#2022-06-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/0a1cec9fc3d570c3497ae9d9cd9490e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*roo5bwS1FlrfZBxl"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@danielkcheung?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Daniel K Cheung</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8e17" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这篇文章将带你在绝对python中轻松地完成KNN的工作。绝对的python是我就是喜欢python的一种很好的说法。<strong class="iw hi"> <em class="js"> #Java烂透了。</em>T3】</strong></p><p id="bd8a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我已经在下面的链接中讨论了KNN的工作、算法、属性、假设等等:</p><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/@priyanshsoni761/k-nearest-neighbors-knn-1606989b7ee0"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">去KNN的一站</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">最近的邻居？这些邻居有多近？嗯，希望他们不要咬人！</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="kg l kh ki kj kf kk in jw"/></div></div></a></div><p id="c9f7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">大纲— </strong></p><ol class=""><li id="b1a3" class="kl km hh iw b ix iy jb jc jf kn jj ko jn kp jr kq kr ks kt bi translated"><a class="ae it" rel="noopener" href="/p/6c119ae2f582#bb35">算法步骤</a></li><li id="8480" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr kq kr ks kt bi translated"><a class="ae it" rel="noopener" href="/p/6c119ae2f582#4735">带代码块的算法步骤</a></li><li id="c304" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr kq kr ks kt bi translated"><a class="ae it" rel="noopener" href="/p/6c119ae2f582#14fc">完整代码</a></li></ol></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><h1 id="bb35" class="lg lh hh bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">1.KNN算法</h1><p id="5142" class="pw-post-body-paragraph iu iv hh iw b ix me iz ja jb mf jd je jf mg jh ji jj mh jl jm jn mi jp jq jr ha bi translated">如果你不熟悉KNN的工作背景，请参考上面提到的链接。仅仅10分钟的读数。</p><p id="f2a7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于那些知道的人来说，算法相当简单:</p><ul class=""><li id="a4e2" class="kl km hh iw b ix iy jb jc jf kn jj ko jn kp jr mj kr ks kt bi translated">对于训练数据集中的每个点，<strong class="iw hi">计算其与测试点</strong><strong class="iw hi"/>的距离(欧几里德距离是最常用的)</li><li id="08a8" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated"><strong class="iw hi">将这些距离</strong>存储在有序字典/列表中</li><li id="8caa" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated"><strong class="iw hi">排序</strong>按数值的升序排列距离</li><li id="3e3d" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated"><strong class="iw hi">从列表中选择前K个点</strong>(K-最接近测试数据)</li><li id="b506" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">基于问题类型(回归/分类)，从这些k-最近点做出适当的预测</li></ul><h1 id="4735" class="lg lh hh bd li lj mk ll lm ln ml lp lq lr mm lt lu lv mn lx ly lz mo mb mc md bi translated">2.带代码的算法步骤</h1><p id="e659" class="pw-post-body-paragraph iu iv hh iw b ix me iz ja jb mf jd je jf mg jh ji jj mh jl jm jn mi jp jq jr ha bi translated">我们的代码目标是实现3个功能:</p><ol class=""><li id="58aa" class="kl km hh iw b ix iy jb jc jf kn jj ko jn kp jr kq kr ks kt bi translated"><strong class="iw hi">eulidaindistance—</strong>用于计算并返回测试点和训练点之间的欧几里德距离</li><li id="dfec" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr kq kr ks kt bi translated"><strong class="iw hi">拟合— </strong>用于将训练数据拟合到我们的模型</li><li id="2904" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr kq kr ks kt bi translated"><strong class="iw hi">预测— </strong>用于预测给定测试点的输出类别。</li></ol><p id="97c9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> <em class="js">数据集:</em> </strong>假设我们有著名的虹膜数据集，有4个数字特征，我们要输出花所属的类。所以数据集头看起来像这样:</p><figure class="mq mr ms mt fd ii er es paragraph-image"><div class="er es mp"><img src="../Images/04dd883662c9d6bad683370b5ebd3b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*Y9dZNIUn_YJ3VWLogOFzMA.png"/></div></figure><p id="a4d4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，该数据集的训练点将类似于:<strong class="iw hi"> [5.1，3.5，1.4，0.2，Setosa] </strong> <br/>类似地，该数据集的测试点将类似于:<strong class="iw hi">【4.7，2.9，1.8，0.5】</strong></p><p id="6267" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，每个训练点和测试点实例将分别具有5个和4个特征。</p><ul class=""><li id="7a9c" class="kl km hh iw b ix iy jb jc jf kn jj ko jn kp jr mj kr ks kt bi translated"><strong class="iw hi">欧几里德距离<br/> </strong>我们会做一个函数，计算一个测试点<strong class="iw hi"><em class="js">【testPt】</em></strong>和一个训练点<strong class="iw hi"><em class="js">【train pt】之间的欧几里德距离。</em> </strong>这个距离将是测试点的每个特征与训练点的相应特征的欧几里德距离之和。<br/>通过分配“__”，该函数将成为私有函数。这意味着它不能在类外使用。</li></ul><figure class="mq mr ms mt fd ii"><div class="bz dy l di"><div class="mu mv l"/></div></figure><ul class=""><li id="8d74" class="kl km hh iw b ix iy jb jc jf kn jj ko jn kp jr mj kr ks kt bi translated"><strong class="iw hi">拟合<br/> </strong>我们将创建一个函数，将训练数据<strong class="iw hi"> <em class="js"> (X_train，y_train) </em> </strong>分配给我们的模型。由于KNN是一个懒惰的学习者，训练数据只是被存储，在训练期间不执行任何操作。欧几里德距离和最近邻的计算是在测试期间测试点进入时进行的。因此<strong class="iw hi"> <em class="js"> fit </em> </strong>方法只是将训练数据存储到一些同名的变量中，然后在预测过程中使用。</li></ul><figure class="mq mr ms mt fd ii"><div class="bz dy l di"><div class="mu mv l"/></div></figure><ul class=""><li id="381d" class="kl km hh iw b ix iy jb jc jf kn jj ko jn kp jr mj kr ks kt bi translated"><strong class="iw hi">预测<br/> </strong>我们将创建一个函数，该函数将预测传递给它的每个测试点(X_test)的标签。创建这样一个预测函数的步骤如下。为了更好地理解，请逐步参考代码:</li><li id="84b5" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">迭代X_test中的每一点。我们迭代索引。</li><li id="839e" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">迭代X_train中的每一点。仅索引。现在对于每个测试点，我们迭代所有的训练点。</li><li id="0f10" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">对于一个测试点，我们找到每个训练点的欧几里德距离。我们将这个距离存储在字典/映射中，用关键字作为训练点索引，用值作为欧几里德距离。</li><li id="c4e2" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">这个循环帮助我们对每个测试点重复上面的步骤。</li><li id="45cb" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">现在，我们根据欧几里德距离的值对字典进行升序排序。因此，对于特定的测试点，最近的邻居将出现在字典的开始处。</li><li id="75dc" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">然后，我们通过从字典中选择前k个值来获得特定测试点的k个最近邻。这些将是训练点索引值，因为我们在循环中迭代索引。</li><li id="cdd6" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">现在我们生成对应于这些k个最近邻居的标签。这是通过为k个最近的训练点索引中的每一个从y_train获得y_label的值来完成的。</li><li id="e020" class="kl km hh iw b ix ku jb kv jf kw jj kx jn ky jr mj kr ks kt bi translated">然后，我们将为每个k个最近的训练点生成的标签的模式存储到另一个字典中，将关键字作为测试点，将值作为输出(标签的模式)。</li></ul><figure class="mq mr ms mt fd ii"><div class="bz dy l di"><div class="mu mv l"/></div></figure><h1 id="14fc" class="lg lh hh bd li lj mk ll lm ln ml lp lq lr mm lt lu lv mn lx ly lz mo mb mc md bi translated">3.KNN的完整代码</h1><p id="bd5e" class="pw-post-body-paragraph iu iv hh iw b ix me iz ja jb mf jd je jf mg jh ji jj mh jl jm jn mi jp jq jr ha bi translated">下面是将上述所有代码块组合成一个类的更通用和可用的版本:</p><figure class="mq mr ms mt fd ii"><div class="bz dy l di"><div class="mu mv l"/></div></figure><p id="0938" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">回归问题的代码是类似的。我们只需从y_train中获取距离特定测试点最近的每k个训练点的值。然后我们取这些值的平均值。该平均值将是该特定测试点的输出值。</p></div><div class="ab cl kz la go lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="ha hb hc hd he"><p id="80ab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="js">~塔达斯！</em></p><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hi fi z dy kb ea eb kc ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="mw l kh ki kj kf kk in jw"/></div></div></a></div></div></div>    
</body>
</html>
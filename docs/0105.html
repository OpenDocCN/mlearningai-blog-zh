<html>
<head>
<title>Fashion Item Classification and Recommendation System with NLP Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于自然语言处理技术的时尚商品分类和推荐系统</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/fashion-item-classification-and-recommendation-system-with-nlp-techniques-c1cfd4eecc98?source=collection_archive---------0-----------------------#2021-02-06">https://medium.com/mlearning-ai/fashion-item-classification-and-recommendation-system-with-nlp-techniques-c1cfd4eecc98?source=collection_archive---------0-----------------------#2021-02-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/5b96b60516bd09fda25eb9ef34472e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5mNpFaDGIeYtkCYucRu5cA.jpeg"/></div></div></figure><p id="61b1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这个项目中，我们将使用从多个在线零售网站提取的数据，通过利用<strong class="ir hi">自然语言处理(NLP) </strong>技术来构建物品属性工具和装备推荐系统。</p><p id="bae7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">整个项目将分为两个部分:</p><ol class=""><li id="9dfe" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">产品属性预测</li><li id="37c2" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">服装推荐</li></ol><p id="063b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">完整代码请参考<a class="ae kb" href="https://github.com/rachelsung/ThreadTogether-Fashion-Item-Classification-and-Recommendation-System" rel="noopener ugc nofollow" target="_blank">https://github . com/Rachel sung/thread together-Fashion-Item-class ification-and-Recommendation-System</a></p><h1 id="31d1" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">第1部分:产品属性预测</h1><h2 id="3408" class="la kd hh bd ke lb lc ld ki le lf lg km ja lh li kq je lj lk ku ji ll lm ky ln bi translated"><strong class="ak"> A .数据预处理</strong></h2><p id="4ffd" class="pw-post-body-paragraph ip iq hh ir b is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">原始数据集包含产品信息，包括品牌、产品名称、描述、品牌类别和产品详细信息。</p><p id="8dbf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以下是我们处理原始数据集的步骤:</p><p id="60ec" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">a.将所有列组合成一个字符串，以便进一步处理。</p><p id="11fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">b.删除停用词:</p><ul class=""><li id="8ce0" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lt jt ju jv bi translated">标记我们之前创建的字符串并返回一个列表</li><li id="f24c" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lt jt ju jv bi translated">删除停用词</li><li id="62e1" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lt jt ju jv bi translated">删除“未知”，因为在原始数据集中，有些产品信息是未知的。</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="f0ec" class="la kd hh lz b fi md me l mf mg"><strong class="lz hi">def</strong> remove_stopwords(input_data):<br/>    <em class="mh">'''Tokenize string.</em><br/><em class="mh">        Returns a list.'''</em><br/><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">pandas</strong> <strong class="lz hi">as</strong> <strong class="lz hi">pd</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">numpy</strong> <strong class="lz hi">as</strong> <strong class="lz hi">np</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">os</strong><br/>    <strong class="lz hi">from</strong> <strong class="lz hi">collections</strong> <strong class="lz hi">import</strong> Counter<br/>    <strong class="lz hi">import</strong> <strong class="lz hi">nltk</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">warnings</strong><br/>    warnings.filterwarnings("ignore")<br/>    <br/>    <em class="mh"># combine all columns - call combin_col() function</em><br/>    data2 = combine_col(input_data)<br/><br/>    <em class="mh"># remove_stopwords</em><br/>    <strong class="lz hi">from</strong> <strong class="lz hi">nltk.corpus</strong> <strong class="lz hi">import</strong> stopwords<br/>    <strong class="lz hi">import</strong> <strong class="lz hi">nltk</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">re</strong><br/><br/>    regex_word_tokenize = nltk.RegexpTokenizer(r"(\w+['-]?[a-zA-Z']*[a-z]|[0-9]+-*[0-9]*)")<br/>    nltk_stopwords = list((set(stopwords.words('english'))))<br/><br/><br/>    nltk_stopwords.append('unknown')<br/><br/>    result2 = []<br/>    <strong class="lz hi">for</strong> line <strong class="lz hi">in</strong> data2['combined_data']:<br/>        filtered_words = []<br/>        <strong class="lz hi">if</strong> isinstance(line, str):<br/>            line = re.sub(r'\d+\+*[\- ]*[\-]*',' ',line)<br/>            <strong class="lz hi">for</strong> word <strong class="lz hi">in</strong> regex_word_tokenize.tokenize(line):<br/>                <strong class="lz hi">if</strong> word.isdigit() == <strong class="lz hi">False</strong>:<br/>                    <strong class="lz hi">if</strong> word.lower() <strong class="lz hi">not</strong> <strong class="lz hi">in</strong> nltk_stopwords:<br/>                        filtered_words.append(word.lower())<br/>            result2.append(" ".join(filtered_words))<br/>        <strong class="lz hi">else</strong>:<br/>            result2.append(np.nan)<br/>    data2['rm_sw'] = result2<br/>    <strong class="lz hi">return</strong> data2</span></pre><ul class=""><li id="ac23" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lt jt ju jv bi translated">词汇词条化</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="5194" class="la kd hh lz b fi md me l mf mg"><strong class="lz hi">def</strong> lemmatize_word(input_data):<br/>    <strong class="lz hi">import</strong> <strong class="lz hi">pandas</strong> <strong class="lz hi">as</strong> <strong class="lz hi">pd</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">numpy</strong> <strong class="lz hi">as</strong> <strong class="lz hi">np</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">os</strong><br/>    <strong class="lz hi">from</strong> <strong class="lz hi">collections</strong> <strong class="lz hi">import</strong> Counter<br/>    <strong class="lz hi">import</strong> <strong class="lz hi">nltk</strong><br/>    <strong class="lz hi">import</strong> <strong class="lz hi">warnings</strong><br/>    warnings.filterwarnings("ignore")<br/>    <br/>    d1 = remove_stopwords(input_data)<br/><br/>    <strong class="lz hi">from</strong> <strong class="lz hi">nltk.stem</strong> <strong class="lz hi">import</strong> WordNetLemmatizer<br/>    <strong class="lz hi">from</strong> <strong class="lz hi">nltk.corpus</strong> <strong class="lz hi">import</strong> stopwords<br/>    nltk_stopwords = list((set(stopwords.words('english'))))<br/>    regex_word_tokenize = nltk.RegexpTokenizer(r"(\w+['-]?[a-zA-Z']*[a-z]|[0-9]+-*[0-9]*)")<br/>    lemmatizer = WordNetLemmatizer()<br/><br/>    result3 = []<br/>    <strong class="lz hi">for</strong> i <strong class="lz hi">in</strong> range(len(d1['rm_sw'])):<br/>        lemmatized = []<br/>        <strong class="lz hi">if</strong> isinstance(d1['rm_sw'].iloc[i],str):<br/>            <strong class="lz hi">for</strong> word <strong class="lz hi">in</strong> regex_word_tokenize.tokenize(d1['rm_sw'].iloc[i]):<br/>                lemmatized.append(lemmatizer.lemmatize(word))<br/>            result3.append(" ".join(lemmatized))<br/>        <strong class="lz hi">else</strong>:<br/>            result3.append(d1['rm_sw'].iloc[i])<br/>    d1['lemmatized'] = result3<br/>    d1['final'] = d1['lemmatized'] + " " + d1['brand']<br/>    d1['final_list'] = d1['final'].str.split()<br/>    <strong class="lz hi">return</strong> d1</span></pre><ul class=""><li id="86f8" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lt jt ju jv bi translated">进行一次热编码去重复:对于所有属性化数据(训练数据)，每个属性都进行一次热编码和去重复，这是针对训练模型的。</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="aadd" class="la kd hh lz b fi md me l mf mg">LOL = [] <em class="mh">#LOL List of Lists, to store each of the 5 dataframes</em></span><span id="041f" class="la kd hh lz b fi mi me l mf mg"><strong class="lz hi">for</strong> cat <strong class="lz hi">in</strong> chosen_cats:<br/>    sub = fulldata[fulldata['attribute_name'] == cat] <em class="mh">#gather "sub" set of rows that contain a category (i.e. selecting all rows that have a 'style' in their attribute name)</em></span><span id="d321" class="la kd hh lz b fi mi me l mf mg">    x = pd.get_dummies(sub['attribute_value']) <em class="mh">#create one-hot encoding for a given subset of data </em></span><span id="4d35" class="la kd hh lz b fi mi me l mf mg">    merged = sub.merge(x,how='left',on=sub.index) <em class="mh">#merge the one-hot encoding with the category</em></span><span id="27a3" class="la kd hh lz b fi mi me l mf mg">    LOL.append(merged)</span><span id="c3bc" class="la kd hh lz b fi mi me l mf mg"><em class="mh">#gather the unique tags for each of the 5 attributes</em></span><span id="a78e" class="la kd hh lz b fi mi me l mf mg">styles = fulldata[fulldata['attribute_name'] == 'style']['attribute_value'].unique()</span><span id="8efd" class="la kd hh lz b fi mi me l mf mg">embels = fulldata[fulldata['attribute_name'] == 'embellishment']['attribute_value'].unique()</span><span id="7949" class="la kd hh lz b fi mi me l mf mg">occasi = fulldata[fulldata['attribute_name'] == 'occasion']['attribute_value'].unique()</span><span id="fab6" class="la kd hh lz b fi mi me l mf mg">catego = fulldata[fulldata['attribute_name'] == 'category']['attribute_value'].unique()</span><span id="094d" class="la kd hh lz b fi mi me l mf mg">drycle = fulldata[fulldata['attribute_name'] == 'dry_clean_only']['attribute_value'].unique()</span></pre><h2 id="bf21" class="la kd hh bd ke lb lc ld ki le lf lg km ja lh li kq je lj lk ku ji ll lm ky ln bi translated">B.单词嵌入</h2><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="d9a7" class="la kd hh lz b fi md me l mf mg"><strong class="lz hi">from</strong> <strong class="lz hi">sklearn.feature_extraction.text</strong> <strong class="lz hi">import</strong> TfidfVectorizer<br/><br/>unique_prod_doc = output_data['final'].drop_duplicates(keep = 'first')<br/>corpus = list(unique_prod_doc.values)<br/>vectorizer = TfidfVectorizer()<br/>vectorizer.fit(corpus)<br/>training_tfidf_vectors = vectorizer.transform(list(output_data['final']))</span></pre><h2 id="4981" class="la kd hh bd ke lb lc ld ki le lf lg km ja lh li kq je lj lk ku ji ll lm ky ln bi translated">C.模型结构</h2><p id="b7ee" class="pw-post-body-paragraph ip iq hh ir b is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">我们最初构建了4种不同的模型，包括:</p><ul class=""><li id="3d30" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lt jt ju jv bi translated">递归神经网络(RNN):使用手套嵌入的递归神经网络模型具有85.3%的预测准确度。</li><li id="62f7" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lt jt ju jv bi translated">物流回归:预测准确率83.1%。</li><li id="a986" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lt jt ju jv bi translated">深度学习神经网络:预测准确率84.2%。</li><li id="31d5" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lt jt ju jv bi translated">物流和决策树组合:预测准确率为86.8%。</li></ul><p id="ac07" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以下是物流和决策树组合的代码，这是最终选择的模型。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="db66" class="la kd hh lz b fi md me l mf mg"><em class="mh"># TFIDF</em><strong class="lz hi"><br/>from</strong> <strong class="lz hi">sklearn.feature_extraction.text</strong> <strong class="lz hi">import</strong> TfidfVectorizer<br/><br/>unique_prod_doc = output_data['final'].drop_duplicates(keep = 'first')<br/>corpus = list(unique_prod_doc.values)<br/>vectorizer = TfidfVectorizer()<br/>vectorizer.fit(corpus)<br/>training_tfidf_vectors = vectorizer.transform(list(output_data['final']))</span><span id="064d" class="la kd hh lz b fi mi me l mf mg"><em class="mh"># Build model</em> <br/><strong class="lz hi">from</strong> <strong class="lz hi">sklearn</strong> <strong class="lz hi">import</strong> preprocessing, linear_model <br/><strong class="lz hi">from</strong> <strong class="lz hi">sklearn.model_selection</strong> <strong class="lz hi">import</strong> train_test_split <br/><strong class="lz hi">from</strong> <strong class="lz hi">sklearn.linear_model</strong> <strong class="lz hi">import</strong> LogisticRegression <br/><strong class="lz hi">from</strong> <strong class="lz hi">sklearn.tree</strong> <strong class="lz hi">import</strong> DecisionTreeClassifier  <br/><strong class="lz hi">from</strong> <strong class="lz hi">sklearn.metrics</strong> <strong class="lz hi">import</strong> classification_report, confusion_matrix, roc_curve, roc_auc_score, auc, classification_report  </span><span id="67c1" class="la kd hh lz b fi mi me l mf mg">to_predict = lemmatize_word(data) </span><span id="82d5" class="la kd hh lz b fi mi me l mf mg">to_predict['vectorized_doc'] = list(vectorizer.transform(to_predict['final']).toarray()) </span><span id="6b29" class="la kd hh lz b fi mi me l mf mg">to_predict_df = to_predict</span></pre><h2 id="1b18" class="la kd hh bd ke lb lc ld ki le lf lg km ja lh li kq je lj lk ku ji ll lm ky ln bi translated">D.预言；预测；预告</h2><p id="8810" class="pw-post-body-paragraph ip iq hh ir b is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">使用选择的模型预测未预测数据集的5个属性(“<em class="mh">干洗</em>”、“<em class="mh">类别</em>”、“<em class="mh">修饰</em>”、“<em class="mh">风格</em>”、“<em class="mh">场合</em>”)，并提供excel文件作为我们的输出。</p><h1 id="73d0" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">第2部分:服装推荐</h1><p id="de5e" class="pw-post-body-paragraph ip iq hh ir b is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">在这一部分中，我们的目标是构建一个推荐系统，它可以根据提供的输入(产品id或产品描述)提供服装组合。输出将是与输入相关的所有推荐服装。</p><h2 id="8bc6" class="la kd hh bd ke lb lc ld ki le lf lg km ja lh li kq je lj lk ku ji ll lm ky ln bi translated">A.数据预处理</h2><p id="2e6b" class="pw-post-body-paragraph ip iq hh ir b is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">这些方法与第1部分基本相同，因此我们在这一部分不再讨论。</p><h2 id="5bae" class="la kd hh bd ke lb lc ld ki le lf lg km ja lh li kq je lj lk ku ji ll lm ky ln bi translated">B.推荐模型构建</h2><p id="7d6b" class="pw-post-body-paragraph ip iq hh ir b is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">我们假设有2种输入数据，一种是产品id，另一种是产品描述。因此，对于每种输入数据，我们将使用不同的方法来获得建议。</p><p id="7778" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">a.输入:产品Id</p><p id="1830" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于这种输入，我们使用了<strong class="ir hi"> Fuzzy Wuzzy: </strong></p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="01f8" class="la kd hh lz b fi md me l mf mg">def recommend_id(test):<br/>    '''Searches user's inputted product id and returns the recommended outfit. '''<br/>    <br/>    # List of all product id<br/>    strOptions =list(set(df['product_id'].to_list()))<br/>    <br/>    # Str2match = user input<br/>    str2Match = test<br/>    <br/>    # Use fuzzywuzzy's process.extract() to get similarity ratio of the most similar product id to user input<br/>    Ratios = process.extract(str2Match,strOptions)<br/>    <br/>    # Most similar product id to the user input<br/>    highest = process.extractOne(str2Match,strOptions)<br/>    <br/>    # Product id of the most smilar<br/>    final_prod=highest[0]<br/>    <br/>    # Top few of outfit code of the most similar products to user input<br/>    outfit_code=df.loc[df['product_id']==final_prod]['outfit_id'].to_list()<br/>    <br/>    # Get the top one of the outfit code<br/>    outfit_code=outfit_code[0]<br/>    <br/>    # Return outfit<br/>    final_result=df[df["outfit_id"] == outfit_code]<br/>    <br/>    return final_result</span></pre><p id="de77" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">b.输入:产品描述</p><p id="d769" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于这种输入，我们使用<strong class="ir hi"> TFIDF </strong></p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="71fd" class="la kd hh lz b fi md me l mf mg">def recommend_description(test):<br/>    '''Searches user's inputted product description and returns the recommended outfit. '''<br/>    <br/>    test = test.lower()<br/>    data = list(df.new_column)<br/>    d = []<br/>    for words in data:<br/>        words = str(words)<br/>        d.append(words)<br/>    <br/>    # creating test_model and dictionary<br/>    test_model = [[word for word in clean(words)] for words in d]<br/>    dictionary = corpora.Dictionary(test_model,prune_at=2000000)<br/>    <br/>    # constructing corpus<br/>    corpus_model= [dictionary.doc2bow(test) for test in test_model]<br/>    tfidf_model = models.TfidfModel(corpus_model)<br/>    <br/>    # constructing tfidf based on processed corpus<br/>    corpus_tfidf = tfidf_model[corpus_model]<br/>    <br/>    # creating the bag of words and calculating tfidf<br/>    test_bow = dictionary.doc2bow([word for word in word_tokenize(test)])<br/>    test_tfidf = tfidf_model[test_bow]<br/>    <br/>    # calculating similarities between test and original data<br/>    index = similarities.MatrixSimilarity(corpus_tfidf)<br/>    sims = pd.DataFrame(index[test_tfidf])<br/>    sims.columns = ["similaritie"]<br/>    sims["information"] = data<br/>    sims = sims[sims["similaritie"] &lt;= 0.98]<br/>    sims = sims.sort_values(by="similaritie", ascending=False).head(1)<br/>    <br/>    # get the product's id with the highest similarity<br/>    target_product = list(sims["information"])[0]<br/>    <br/>    # get the outfit id of the target product<br/>    outfitid = list(df[[v == target_product for v in df['new_column'].tolist()]].outfit_id)[0]<br/>    <br/>    # return all products with the same outfit id<br/>    target = df[df["outfit_id"] == outfitid]<br/><br/>    return target</span></pre><p id="8713" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">C.为了方便起见，最后一步是将模型组织成一个函数。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="939f" class="la kd hh lz b fi md me l mf mg">def get_recommendation(input_str):<br/>    if test[0].isdigit(): <br/>        result = recommend_id(test)<br/>        result_short = result[['outfit_item_type','product_full_name','product_id']]<br/>    else:<br/>        result = recommend_description(test)<br/>        result_short = result[['outfit_item_type','product_full_name','product_id']]<br/>    for i in result_short.index:<br/>        print(f'\t{result_short.loc[i][0]} : {result_short.loc[i][1]} ({result_short.loc[i][2]})')<br/><br/>def more_rec_details(input_str):<br/>    if input_str.lower().startswith('y'):<br/>        if test[0].isdigit(): <br/>            result = recommend_id(test)<br/>        else:<br/>            result = recommend_description(test)<br/>        return result[['product_full_name','brand','outfit_item_type','product_id','details','description']]</span></pre><p id="c7ce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="mh">试试吧，马上获得你的装备推荐！</em>😄</strong></p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="63d7" class="la kd hh lz b fi md me l mf mg">test = input("Enter your content (product_id or product descriptions/details): \n")<br/>get_recommendation(test)<br/><br/>more_details = input("\n\nDo you want more details on the outfit (y/n): \n")<br/>more_rec_details(more_details)</span></pre></div></div>    
</body>
</html>
<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/building-a-recommender-system-cb7fe0770?source=collection_archive---------1-----------------------#2021-04-22">https://medium.com/mlearning-ai/building-a-recommender-system-cb7fe0770?source=collection_archive---------1-----------------------#2021-04-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><p id="18f1" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie"> <em class="if">【构建推荐系统(针对书籍)</em> </strong></p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es ig"><img src="../Images/21147fd712d622f1a2fc5c888d6a8553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*payW1dcWZ_whdOE5M0V3lA.jpeg"/></div><figcaption class="io ip et er es iq ir bd b be z dx"><a class="ae is" href="https://towardsdatascience.com/build-your-own-recommender-system-within-5-minutes-30dd40388fbf" rel="noopener" target="_blank">Meet Nandu</a></figcaption></figure><p id="fc1e" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">如果你在亚马逊上寻找一本关于投资/金融的书，结果得到了哈利波特，会发生什么？糟糕的比赛，对吗？</p><p id="3571" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">你和你的朋友交谈，他建议把你的问题张贴在subreddit r/booksugestions上。这里的一个问题是，大多数处于相同位置的人都得不到相关的答案，必须等待一段时间，或者根本得不到答案。</p><p id="65c1" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们无时无刻不在询问关于我们感兴趣的产品的问题，但我们是否总能收到相关的回答？如果在键入您的问题时，我们得到了我们感兴趣的特定主题、单词或产品，会发生什么？还是贴出来之后，我们收到相关回答的通知？很酷，对吧？</p><p id="bea4" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">作为一个数据科学家，我们来建立一个图书推荐系统。更具体地说，当有人在subreddit r/booksuggestions上键入/请求推荐时，我们可以推荐其他人读过/推荐过的书或类似的书吗？</p><p id="6856" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">使用自然语言处理和神经网络，让我们建立一个图书推荐系统。</p><p id="28d7" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie">第1部分:数据收集和清理</strong></p><p id="8a29" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们的工作分为两部分:我先通过api.pushshift.io收集清理subreddit帖子；其次，我对数据进行探索和建模。收集的数据是从2010年7月25日到2021年3月30日。这相当于109，122个帖子，相当于大约3，700万个字符。根据我们所做的分析类型(Tokenizer、TFIDF计数矢量器…)，这可能会很快占用我们所有的内存。Google Collab-Pro上一个更高级的硬件加速器(GPU或TPU)有高RAM(27GB到32GB之间)多次崩溃。下面是我用来访问、下载和合并1，092批帖子的代码截图。在这一部分，我使用Pandas、Os、Requests和Re库。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es it"><img src="../Images/c7ab84fa0793048a702cd4cb599f1616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*3X2rYkCYqhdTDUM79AIZaA.png"/></div></figure><p id="7e8c" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">将数据放入数据框后，我们过滤想要处理的列，并创建一个新列(文本)，其中包含标题(“title”)和注释(“selftext”)。任何没有注释和标题的行将会有缺失值(NaN ),我们需要解决这个问题。以下是输出:</p><figure class="ih ii ij ik fd il er es paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="er es iu"><img src="../Images/974ee65682e99ac66ee15860ca47c65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQWjrvUL7kvYZsxrUsNdjA.png"/></div></div><figcaption class="io ip et er es iq ir bd b be z dx">Data frame of subreddit posts</figcaption></figure><p id="fef2" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">从那里，我们准备开始清理我们的文本。重要的是要知道没有放之四海而皆准的方法。关键是看一些帖子，发现什么规律。例如，我们有许多换行符转义序列(" \n ")。通过删除它，我们可以在我们的文章中发现更多的实体(864多本书)。另一方面，通过消除文本数据中出现的特殊字符(只保留数字和字母)，我们检测到的实体更少(少了3，041本书)。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es iz"><img src="../Images/8f9a0e289b8f9d2e1a13718e888080e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*cgR1vqABonVcJSR95t0NuQ.png"/></div><figcaption class="io ip et er es iq ir bd b be z dx">Our text after cleaning</figcaption></figure></div><div class="ab cl ja jb go jc" role="separator"><span class="jd bw bk je jf jg"/><span class="jd bw bk je jf jg"/><span class="jd bw bk je jf"/></div><div class="ha hb hc hd he"><p id="87c7" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie">第二部分:探索性数据分析和建模</strong></p><p id="8e4f" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">第二部分涉及使用NLTK、Gensim和spaCy库来处理和理解我们拥有的大量文本。在这一部分中，文本的整洁程度决定了我们得到的结果。现在，让我们使用我们的数据来创建令牌，每个帖子中使用的单词向量，然后标记它们。这是一篇文章中实体检测的原始标记。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="er es jh"><img src="../Images/e873873c73e647c587d5870710fc6986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8B1NGsmJGLPlEZyf5Yl4vw.png"/></div></div><figcaption class="io ip et er es iq ir bd b be z dx">Identity detection</figcaption></figure><p id="9ade" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">一旦我们有了每个实体，我们就可以过滤出书籍，并统计它们在每个帖子中的出现次数。斯帕西将书籍定义为“艺术品”，如下所示。需要注意的一点是分类错误。一些实体被错误分类，特别是在书籍、人员和组织(公司、代理、机构)之间。我们可以想象包含其他实体的实体之间的模糊界限。例如，芭芭拉·金索尔弗的《毒木圣经》被分成了两本书:《毒木圣经》和《圣经》。这里识别实体的一个好模式是使用大写字母。每当一个大写字母的单词跟在另一个单词后面，中间没有任何标点符号，那么这个单词序列应该是同一个实体的一部分。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es ji"><img src="../Images/7e9dcc07d38073e074d575b8895ec4ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*_JwDhRjdAGndy9LG3iJZxQ.png"/></div><figcaption class="io ip et er es iq ir bd b be z dx">Summary of spaCy’s entity types (Source: SpaCy)</figcaption></figure><p id="652f" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">以下是我们的十大书籍:</p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es jj"><img src="../Images/7c69b744da3bec8d5c18922a438a6843.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*uRmH14C2gVaOS_DM-Kswhw.png"/></div><figcaption class="io ip et er es iq ir bd b be z dx">Top 10 books with their count</figcaption></figure><p id="dbd9" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">不到13%的帖子提到了书籍。然而，让我们把这些作为我们推荐者的基础。为此，我们使用Word2Vec的连续跳格模型，这是一个两层神经网络，它接受一个单词向量(我们创建的令牌),并返回上下文单词作为输出。这是我们训练模型理解文本结构和内容语言并开发词汇的地方——换句话说，通过查看单词在每个句子中的位置和出现次数来理解单词之间的关系。相似的词往往更频繁地出现在相同的词周围。因此，当单词被表示为向量时，如果它们相似，它们要么指向相同的方向(要么不指向相同的方向)。衡量这种相似性的一种常用技术是余弦相似性得分，其范围从0到1，测量向量之间的角度(在本例中，是每个句子中的单词)。角度越小，单词越相似，余弦相似度得分越高。如果你想了解更多，这里有一个关于余弦相似性分数的极好资源。</p><p id="b884" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">现在让我们通过键入“圣经”来查询我们的模型作为示例:</p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es jk"><img src="../Images/b46ec722ed8413086c8ea3bec0001fcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*RPgzTXO0JbkjaXNaXVfGsA.png"/></div></figure><p id="526c" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">与“圣经”最相似的词是“古兰经”，我们的余弦相似度得分是0.76。</p><p id="e2e8" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">由于我们87%的帖子不包含任何书籍，让我们使用我们新训练的模型向那些个人推荐一些书籍。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="er es jl"><img src="../Images/9c4efb6bbac5d40e149cd3ac29cb9937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o1OuIJ99CxzPKUrpDoS5Qg.png"/></div></div><figcaption class="io ip et er es iq ir bd b be z dx">Creating a function that takes in words and returns three books</figcaption></figure><p id="c3ac" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">让我们用一个没有任何书籍的帖子来测试我们的模型。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="er es jm"><img src="../Images/053cd3938356fd85d06575e624b33ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrfD2JeUohRBw9qMSPO9PQ.png"/></div></div><figcaption class="io ip et er es iq ir bd b be z dx">Input and Output of our model</figcaption></figure><p id="4e2a" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们的模型返回的图书“阴阳魔界”、“仪式”和“牙齿”的得分分别为0.989369、0.988831和0.988466。</p><p id="d7f5" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie">结论&amp;建议</strong></p><p id="c7f4" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">好消息！我们已经成功地制作了我们的第一个推荐系统。主要要点是:</p><ul class=""><li id="a5c3" class="jn jo hh hi b hj hk hn ho hr jp hv jq hz jr id js jt ju jv bi translated"><strong class="hi ie">该模型确实能够基于具有高相似性分数(大于0.98)的上下文推荐书籍</strong></li><li id="18b2" class="jn jo hh hi b hj jw hn jx hr jy hv jz hz ka id js jt ju jv bi translated"><strong class="hi ie">小心预处理方法(如何清理数据)</strong></li></ul><p id="4bdd" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们模型的一些用例是:</p><ul class=""><li id="b788" class="jn jo hh hi b hj hk hn ho hr jp hv jq hz jr id js jt ju jv bi translated"><strong class="hi ie">对询问给出相关回答(推荐网飞电影或Youtube视频)</strong></li><li id="80f4" class="jn jo hh hi b hj jw hn jx hr jy hv jz hz ka id js jt ju jv bi translated"><strong class="hi ie">围绕相关主题提示对话</strong></li></ul><p id="9802" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">这项工作的扩展可以是使用机器学习中的其他技术和具有不同参数的神经网络(例如，具有更多层的神经网络)，以使我们的模型对于其他酷项目来说更加复杂。如果你有任何建议或意见，请告诉我。</p><p id="6a7d" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">源代码可以在我的<a class="ae is" href="https://github.com/Ronald-Asseko/nlp_to_build_books_recommender" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。其他消息来源包括<a class="ae is" href="https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da" rel="noopener" target="_blank">苏珊·李</a>和<a class="ae is" rel="noopener" href="/@rajat.jain1/natural-language-extraction-using-spacy-on-a-set-of-novels-88b159d68686">拉杰特·贾恩</a>。</p></div></div>    
</body>
</html>
# æ·±å…¥åŒ»å­¦æˆåƒ:X å°„çº¿å›¾åƒå¢å¼º

> åŸæ–‡ï¼š<https://medium.com/mlearning-ai/dive-into-medical-imaging-image-augmentation-approach-4cfad0f306e3?source=collection_archive---------0----------------------->

åœ¨æˆ‘ç ”ç©¶ç”Ÿæ¶¯çš„æ—©æœŸï¼Œæˆ‘å¿…é¡»ä¸ºåŸºäºäººå·¥æ™ºèƒ½(AI)çš„åŒ»å­¦æˆåƒç ”ç©¶åšå‡ºé‡å¤§è´¡çŒ®ï¼Œä»é‚£æ—¶èµ·ï¼Œæˆ‘çš„åŒ»å­¦æˆåƒä¹‹æ—…å¼€å§‹äº†ã€‚æœ¬æ–‡å°†è®¨è®ºåŒ»å­¦å›¾åƒå¢å¼ºçš„ç†è®ºå’Œå®é™…å®ç°ã€‚

**æ¢ç´¢è¿™ç¯‡æ–‡ç« åä½ ä¼šçŸ¥é“ä»€ä¹ˆï¼Ÿ**

*   ç”¨äºåŒ»å­¦æˆåƒçš„äººå·¥æ™ºèƒ½
*   åŒ»å­¦å›¾åƒå¢å¼ºèƒŒåçš„ç†è®º
*   æ–°å† è‚ºç‚å›¾åƒæ•°æ®é›†ä¸Šçš„å®é™…å®ç°

![](img/8912c4e36d163912b683718fa8d2b6ea.png)![](img/f9cc3d90371d03febe15754e6593ea46.png)

**Figure 1: Sample dataset for experimenting (Covid-19 based medical image data)**

> è®©æˆ‘ä»¬æ·±å…¥æ•°æ®é©±åŠ¨çš„ä¸–ç•Œ

æœ‰äº†ç§‘æŠ€çš„å…´èµ·ï¼Œå·¥ç§ä¹Ÿåœ¨ä¸æ–­å˜åŒ–ï¼›ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœæˆ‘ä»¬çœ‹çš„ç¨å¾®å¥½ä¸€ç‚¹ï¼Œå°±ä¼šè§‚å¯Ÿåˆ°äººå·¥æ™ºèƒ½çš„åº”ç”¨è¶Šæ¥è¶Šæ— å¤„ä¸åœ¨ã€‚

åš *ä½ çŸ¥é“ç°åœ¨çš„ç”µè„‘æœ‰å¤šå¼ºå¤§å—ï¼Ÿ*ğŸ¤¨ ğŸ¤¨ ğŸ¤¨

è®¡ç®—æœºç°åœ¨æ­£æˆä¸ºä¸€ç§å¼ºæœ‰åŠ›çš„æ­¦å™¨ï¼Œå®ƒåœ¨åŒ»ç–—é¢†åŸŸæœ‰æ½œåœ¨çš„åº”ç”¨ã€‚åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸçš„ç ”ç©¶ä¸­ï¼Œå·²ç»å‘ç°äº†å‡ ç§é«˜çº§ç®—æ³•ï¼Œå¯ä»¥è¯»å–ç¡¬å›¾åƒï¼Œå¦‚ X å°„çº¿ã€CT æ‰«æç­‰ã€‚æˆ‘ä»¬ä¸å¿…è¿‡äºä¾èµ–åŒ»ç”Ÿï¼Œå› ä¸ºäººå·¥æ™ºèƒ½çš„åº”ç”¨ä½¿æˆ‘ä»¬çš„ç”Ÿæ´»å˜å¾—æ›´åŠ è½»æ¾ã€‚å…ˆè¯´åŒ»å­¦å½±åƒçš„ AIã€‚

> **ç”¨äºåŒ»å­¦æˆåƒçš„äººå·¥æ™ºèƒ½**

äººå·¥æ™ºèƒ½(AI)åœ¨è¯Šæ–­åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨æ­£åœ¨ç»å†å½»åº•çš„è€ƒè™‘ã€‚ä¾‹å¦‚ï¼Œè®¡ç®—æœºè¾…åŠ©ç®—æ³•å¯ä»¥æ£€æŸ¥ x å°„çº¿å’Œå…¶ä»–å›¾åƒä¸­æŒ‡ç¤ºè‚ºç‚çš„ä¸é€æ˜è¿¹è±¡ï¼Œç„¶åæé†’åŒ»ç”Ÿæ½œåœ¨çš„è¯Šæ–­ï¼Œä»¥ä¾¿åœ¨æ€€ç–‘æœ‰æ°”èƒ¸æ—¶æ›´å¿«åœ°è¿›è¡Œæ²»ç–—ï¼Œäººå·¥æ™ºèƒ½å¯ä»¥å¸®åŠ©è¯†åˆ«é«˜é£é™©ä¸ªä½“ï¼Œç‰¹åˆ«æ˜¯åœ¨æ”¾å°„ç§‘åŒ»ç”Ÿä¸åœ¨åœºçš„æƒ…å†µä¸‹ã€‚

> åŒ»å­¦å›¾åƒå¢å¼ºèƒŒåçš„ç†è®º

ä¸ºäº†æ·±å…¥ç ”ç©¶å›¾åƒå¢å¼ºï¼Œéœ€è¦äº†è§£æˆ‘ä»¬åœ¨å¤„ç†åŒ»å­¦å›¾åƒæ•°æ®æ—¶å¯èƒ½ä¼šé‡åˆ°çš„æŒ‘æˆ˜ã€‚æ›´ç®€å•åœ°è¯´ï¼ŒæŸ¥æ‰¾åŒ»å­¦å›¾åƒæ•°æ®ç›¸å¯¹å›°éš¾ï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯è®¿é—®æ€§æ˜¯ä¸€ä¸ªéå¸¸å€¼å¾—å…³æ³¨çš„é—®é¢˜ã€‚å…¶æ¬¡ï¼Œè·å–å¤§é‡çš„æ•°æ®é›†æ˜¯ç›¸å½“å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºè¿™ç§ç±»å‹çš„æ•æ„Ÿæ•°æ®é€šå¸¸ä¸å…¬å¼€ã€‚æœºå™¨å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®æ‰èƒ½å·¥ä½œï¼Œè¿™å½“ç„¶æ²¡é”™ï¼›å¦åˆ™ï¼Œåˆ›å»ºå¥å£®çš„æ¨¡å‹å˜å¾—éå¸¸å›°éš¾ï¼Œå¹¶ä¸”å¦‚æœåŒ»å­¦å›¾åƒæ•°æ®æ˜¯è¿™ç§æƒ…å†µï¼Œé‚£ä¹ˆæ•°æ®å¤§å°å¿…é¡»å¢åŠ ã€‚å‡è®¾ä½ æœ‰ 1000 ä¸ªå›¾åƒæ•°æ®ï¼Œä½†ä¸çŸ¥ä½•æ•…å¦‚æœèƒ½æˆåŠŸæ‰©å±•åˆ° 2000 ä¸ªæ ·æœ¬ï¼Œé‚£å°±æ›´æœ‰æ„æ€äº†å§ï¼Ÿ

**æ‰€ä»¥ï¼Œå›¾åƒå¢å¼ºå°±æ˜¯è¿™æ ·ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡å®ƒä½ å¯ä»¥å¢åŠ ä½ çš„æ•°æ®æ ·æœ¬ï¼›é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ å°†èƒ½å¤Ÿæœ‰æ•ˆåœ°è®­ç»ƒä½ çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚**

è¦ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•è·å¾—å‡†ç¡®çš„ç»“æœï¼Œéœ€è¦å¤§é‡çš„æ•°æ®ã€‚å¯ä»¥é€šè¿‡å„ç§æ–¹å¼æ¥æ‰©å……å›¾åƒï¼Œä»¥æ‰©å¤§æ•°æ®é›†å’Œæ ·æœ¬å¤§å°ã€‚åœ¨å¤„ç†å…³é”®åŒ»å­¦å›¾åƒæ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¯é çš„ç­–ç•¥ï¼Œå› ä¸ºåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå¦‚æœæ•°æ®é‡ä¸è¶³ï¼Œæ¨¡å‹çš„å‡†ç¡®æ€§ä¸ä¼šæé«˜ã€‚é™¤äº†å‡å°‘è¿‡åº¦æ‹Ÿåˆï¼Œå¢å¼ºè¿˜å¯ä»¥æé«˜æ‚¨æå‡ºçš„æ¨¡å‹çš„ç²¾åº¦ã€‚

> æ–°å† è‚ºç‚å›¾åƒæ•°æ®é›†ä¸Šçš„å®é™…å®ç°

**æ­¥éª¤ 01:å…‹éš†æ–°å† è‚ºç‚å›¾åƒæ•°æ®é›†**

```
!git clone https://github.com/casperbh96/COVID-19-Detection.git dataset
```

**æ­¥éª¤ 02:å¯¼å…¥åŸºæœ¬åº“**

```
import pandas as pdimport matplotlib.pyplot as plt%matplotlib inlineimport numpy as npimport cv2, timeimport tensorflow as tftf.__version__
```

**æ­¥éª¤ 03:åŠ è½½æ–°å† è‚ºç‚æ•°æ®é›†**

```
covid_path = 'dataset/covid_dataset.csv'covid_image_path = 'dataset/covid_adjusted/'normal_path = 'dataset/normal_xray_dataset.csv'normal_image_path = 'dataset/normal_dataset/'covid_df = pd.read_csv(covid_path, usecols=['filename', 'finding'])normal_df = pd.read_csv(normal_path, usecols=['filename', 'finding'])normal_df = normal_df.head(99)covid_df.head()
```

ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ‰§è¡Œä¸€äº›é¢å¤–çš„å·¥ä½œ

```
covid_images = []covid_labels = []for index, row in covid_df.iterrows():filename = row['filename']label = row['finding']path = covid_image_path + filenameimage = cv2.imread(path)image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)covid_images.append(image)covid_labels.append(label)normal_images = []normal_labels = []for index, row in normal_df.iterrows():filename = row['filename']label = row['finding']path = normal_image_path + filename# temporary fix while we preprocess ALL the imagesif filename == '4c268764-b5e5-4417-85a3-da52916984d8.jpg':breakimage = cv2.imread(path)image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)normal_images.append(image)normal_labels.append(label)# normalize to interval of [0,1]covid_images = np.array(covid_images) / 255# normalize to interval of [0,1]normal_images = np.array(normal_images) / 255
```

**æ­¥éª¤ 04:æˆ‘ä»¬å¿…é¡»åˆ›å»ºä¸€ä¸ªå¯è§†åŒ–å›¾åƒçš„å‡½æ•°**

```
def plot_images(images, title):nrows, ncols = 3, 8figsize = [10, 6]fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, facecolor=(1, 1, 1))for i, axi in enumerate(ax.flat):axi.imshow(images[i])axi.set_axis_off()plt.suptitle(title, fontsize=24)plt.tight_layout(pad=0.2, rect=[0, 0, 1, 0.9])plt.show()plot_images(covid_images, 'Positive COVID-19 Cases')plot_images(normal_images, 'Negative COVID-19 Cases')
```

**æ‰§è¡Œæ­¥éª¤ 04 åï¼Œæ‚¨å°†ä¼šçœ‹åˆ°ä»¥ä¸‹å›¾åƒâ†’**

![](img/8912c4e36d163912b683718fa8d2b6ea.png)![](img/f9cc3d90371d03febe15754e6593ea46.png)

**Figure 2: Negative and Positive Covid-19 cases images**

**æ­¥éª¤ 05:å°†æ•°æ®é›†åˆ†æˆæµ‹è¯•å’Œè®­ç»ƒ**

```
from sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import LabelBinarizerfrom tensorflow.keras.utils import to_categorical# split into training and testingcovid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(covid_images, covid_labels, test_size=0.2)normal_x_train, normal_x_test, normal_y_train, normal_y_test = train_test_split(normal_images, normal_labels, test_size=0.2)X_train = np.concatenate((normal_x_train, covid_x_train), axis=0)X_test = np.concatenate((normal_x_test, covid_x_test), axis=0)y_train = np.concatenate((normal_y_train, covid_y_train), axis=0)y_test = np.concatenate((normal_y_test, covid_y_test), axis=0)# make labels into categories - either 0 or 1y_train = LabelBinarizer().fit_transform(y_train)y_train = to_categorical(y_train)y_test = LabelBinarizer().fit_transform(y_test)y_test = to_categorical(y_test)
```

**æ­¥éª¤ 06:** åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€äº›å‡½æ•°æ¥å¢å¼ºæˆ‘ä»¬çš„æ–°å† è‚ºç‚å›¾åƒã€‚å¦‚ä½ æ‰€çŸ¥ï¼Œåœ¨å›¾åƒå¢å¼ºæ–¹é¢å¯ä»¥æ‰¾åˆ°å‡ ç§ä¼ ç»Ÿçš„æ–¹æ³•ã€‚å°½ç®¡å¦‚æ­¤ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œå¯¹æ¯”åº¦ï¼Œé¥±å’Œåº¦ï¼Œä¸Šä¸‹ç¿»è½¬å’Œæ—‹è½¬å·²ç»è¢«è€ƒè™‘ï¼Œå› ä¸ºè¿™äº›æ˜¯æœ€å¸¸ç”¨çš„æ–¹æ³•ã€‚

**æ–¹æ³• 01:å¯¹æ¯”**

```
X_train_contrast = []for x in X_train:contrast = tf.image.adjust_contrast( x, 2 ) #It takes two parameter: Images and constrast_factor.#Images:Images to adjust. At least 3-D.#Constrast_factor:A float multiplier for adjusting contrast.X_train_contrast.append(contrast.numpy())plot_images(X_train_contrast, 'Adjusted Contrast')
```

**æ‰§è¡Œæ–¹æ³• 01 åï¼Œæ‚¨å°†è§‚å¯Ÿåˆ°ä»¥ä¸‹å›¾åƒâ†’**

![](img/0c314ee39518a39e479e2bfbff91fb88.png)

**Figure 3: Applying the image augmentation approach, e.g. Contrast**

æ–¹æ³• 02:é¥±å’Œåº¦

```
X_train_saturation = []for x in X_train:saturation = tf.image.adjust_saturation( x, 3 )X_train_saturation.append(saturation.numpy())plot_images(X_train_saturation, 'Adjusted Saturation')
```

**æ‰§è¡Œæ–¹æ³• 02 åï¼Œæ‚¨å°†è§‚å¯Ÿåˆ°ä»¥ä¸‹å›¾åƒâ†’**

![](img/0c314ee39518a39e479e2bfbff91fb88.png)

**Figure 4: Performing the image augmentation approach, e.g. Saturation**

**æ–¹æ³• 03:ä¸Šä¸‹ç¿»è½¬**

```
X_train_flipped_up_down = []for x in X_train:flipped = tf.image.flip_up_down(x)X_train_flipped_up_down.append(flipped.numpy())plot_images(X_train_flipped_up_down, 'Flipped Up Down')
```

![](img/7e201c657370af0319519f4a20106113.png)

**Figure 5: Visualizing the augmented images, e.g. Flipped up-down**

**æ–¹æ³• 04:** åº”ç”¨æ—‹è½¬æŠ€æœ¯ã€‚è¿™é‡Œæˆ‘è€ƒè™‘è¿‡ 45 åº¦ï¼Œ135 åº¦ï¼Œ225 åº¦ï¼Œ315 åº¦ã€‚

```
import tensorflow_addons as tfafrom math import radiansX_train_rot_45_deg = []X_train_rot_135_deg = []X_train_rot_225_deg = []X_train_rot_315_deg = []for x in X_train:deg_45 = tfa.image.transform_ops.rotate(image, radians(45))deg_135 = tfa.image.transform_ops.rotate(image, radians(135))deg_225 = tfa.image.transform_ops.rotate(image, radians(225))deg_315 = tfa.image.transform_ops.rotate(image, radians(315))X_train_rot_45_deg.append(deg_45)X_train_rot_135_deg.append(deg_135)X_train_rot_225_deg.append(deg_225)X_train_rot_315_deg.append(deg_315)plot_images(X_train_rot_45_deg, 'Rotated 45 Degrees')plot_images(X_train_rot_135_deg, 'Rotated 135 Degrees')plot_images(X_train_rot_225_deg, 'Rotated 225 Degrees')plot_images(X_train_rot_315_deg, 'Rotated 315 Degrees')
```

![](img/775cb1eeb6519ccd3dee611c04ed1309.png)![](img/1a7c016efb471527b9d51d5cf3fface4.png)![](img/969de850e9b638418c58a714cafebbd3.png)![](img/9a392e203953c4aee778f5eb0ef90080.png)

**Figure 6: Visualizing the augmented images, e.g. Rotated 135 degrees, 45 degrees, 225 degrees and 315 degrees**

æ€»ä¹‹ï¼Œæœ¬æ–‡å±•ç¤ºäº†åŒ»å­¦å›¾åƒå¢å¼ºèƒŒåçš„ç†è®ºå’Œå®é™…å®ç°ã€‚ä¸ºäº†è¿›è¡Œå®éªŒï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æ–°å† è‚ºç‚å›¾åƒæ•°æ®é›†ï¼Œå¹¶è§£é‡Šäº†å¦‚ä½•å¢å¼ºåŒ»å­¦å›¾åƒã€‚æˆ‘åšä¿¡è¿™ç¯‡æ–‡ç« ä¸­æä¾›çš„ä¿¡æ¯å¯¹é‚£äº›æƒ³åœ¨åŒ»ç–—ä¿å¥è¡Œä¸šå¼€å§‹å·¥ä½œçš„äººéå¸¸æœ‰å¸®åŠ©ã€‚

**ä»æˆ‘çš„ Github åº“æ‰¾åˆ°æºä»£ç :**

[](https://github.com/eliashossain001/Medium/blob/main/ImageAugmentation.ipynb) [## Medium/image augmentation . ipynb at main eliashossain 001/Medium

### ç”Ÿç‰©åŒ»å­¦æˆåƒæ–¹é¢çš„å®éªŒæºä»£ç 

github.com](https://github.com/eliashossain001/Medium/blob/main/ImageAugmentation.ipynb) 

**å‚è€ƒæ–‡çŒ®**

1.  Shortenï¼Œc .ï¼Œ& Khoshgoftaarï¼ŒT. M. (2019 å¹´)ã€‚é¢å‘æ·±åº¦å­¦ä¹ çš„å›¾åƒæ•°æ®å¢å¼ºç»¼è¿°ã€‚*å¤§æ•°æ®æ‚å¿—*ï¼Œ *6* (1)ï¼Œ1â€“48ã€‚
2.  n . s . punn å’Œ s . Agarwal(2021 å¹´)ã€‚ä½¿ç”¨å¾®è°ƒæ·±åº¦ç¥ç»ç½‘ç»œåˆ©ç”¨æœ‰é™çš„åå‰èƒ¸éƒ¨ X å°„çº¿å›¾åƒè‡ªåŠ¨è¯Šæ–­æ–°å† è‚ºç‚ã€‚*åº”ç”¨æ™ºèƒ½*ï¼Œ *51* (5)ï¼Œ2689â€“2702ã€‚

**åˆ°â†’** æ‰¾æˆ‘

https://www.researchgate.net/profile/Elias-Hossain-2

é¢†è‹±:[https://www.linkedin.com/in/elias-hossain-b70678160/](https://www.linkedin.com/in/elias-hossain-b70678160/)
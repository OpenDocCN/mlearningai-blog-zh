<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/how-to-handle-missing-values-1de64471b958?source=collection_archive---------1-----------------------#2022-01-21">https://medium.com/mlearning-ai/how-to-handle-missing-values-1de64471b958?source=collection_archive---------1-----------------------#2022-01-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="eebb" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">处理缺失值的技术:</h2><figure class="if ig ih ii fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ie"><img src="../Images/69a99c67b9835db53333a2d9081cefed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iqWS1JpZz-vJOzxv"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@emilymorter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Emily Morter</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="3426" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">缺失数据的类型</h2><p id="1111" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1- <strong class="ix jq">完全随机缺失(MCAR): </strong></p><p id="81c6" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated">完全随机失踪(MCAR)完全随机失踪非常简单。它的意思是:数据点丢失的倾向是完全随机的。数据点是否缺失与数据集中的任何值(缺失或观察值)之间没有关系</p><p id="7c1f" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated"><strong class="ix jq"> 2-非随机失踪(MNAR): </strong></p><p id="9a1a" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated">也称为不可忽略的无响应数据是既不是马尔也不是MCAR的数据(即缺少的变量值与它缺少的原因有关)。</p><p id="1eec" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated"><strong class="ix jq"> 3-随机失踪(3月):</strong></p><p id="4b20" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated">意味着数据点丢失的倾向与丢失的数据无关，但与一些观察到的数据有关。是否有人回答了您调查中的第13个问题与缺失值无关，但它与其他变量的值有关。</p><div class="jw jx ez fb jy jz"><a href="https://www-users.york.ac.uk/~mb55/intro/typemiss4.htm" rel="noopener  ugc nofollow" target="_blank"><div class="ka ab dw"><div class="kb ab kc cl cj kd"><h2 class="bd jq fi z dy ke ea eb kf ed ef kg bi translated">缺失数据的类型</h2><div class="kh l"><h3 class="bd b fi z dy ke ea eb kf ed ef dx translated">医学统计学导论，第四版。我希望这个主题本身也是有用的…</h3></div><div class="ki l"><p class="bd b fp z dy ke ea eb kf ed ef dx translated">www-users.york.ac.uk</p></div></div></div></a></div><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="8672" class="hf hg hh kk b fi ko kp l kq kr">import pandas as pd<br/>import numpy as np</span><span id="2180" class="hf hg hh kk b fi ks kp l kq kr">df = pd.read_csv("train.csv")<br/>df</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/d9b2003205f1b6d6c9619af38ecaf92d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_WkTBjj4-6FJkeoknD9-rg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="a8a5" class="hf hg hh kk b fi ko kp l kq kr">df.isnull().sum()   #Tells How many null values are there in every column</span><span id="7b73" class="hf hg hh kk b fi ks kp l kq kr">PassengerId      0<br/>Survived         0<br/>Pclass           0<br/>Name             0<br/>Sex              0<br/>Age            177<br/>SibSp            0<br/>Parch            0<br/>Ticket           0<br/>Fare             0<br/>Cabin          687<br/>Embarked         2<br/>dtype: int64</span><span id="1af5" class="hf hg hh kk b fi ks kp l kq kr">df[df['Embarked'].isnull()]    #Show the data where there is missing values in "Embarked" column</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/e59c00a8e76a616122dc89aa562d0410.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CoAJKu8JjqNpP35UdI48xw.png"/></div></figure><h2 id="54c6" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">2-非随机缺失数据(MNAR):系统缺失数据</h2><p id="ebd1" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">在数据集中，丢失的数据与丢失或观察到的任何其他值之间存在关系。</p><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="a7c8" class="hf hg hh kk b fi ko kp l kq kr">#Making an other column 'Cabin_null' and it is initialized with values 0,1 when there is a null value in 'Cabin' column<br/><br/>df['Cabin_null'] = np.where(df['Cabin'].isnull(),1,0) <br/>df['Cabin_null']</span><span id="521b" class="hf hg hh kk b fi ks kp l kq kr">0      1<br/>1      0<br/>2      1<br/>3      0<br/>4      1<br/>      ..<br/>886    1<br/>887    0<br/>888    1<br/>889    0<br/>890    1<br/>Name: Cabin_null, Length: 891, dtype: int32</span><span id="fe87" class="hf hg hh kk b fi ks kp l kq kr">#Find the percentage of null values<br/><br/>df['Cabin_null'].mean()</span><span id="2c15" class="hf hg hh kk b fi ks kp l kq kr">0.7710437710437711</span><span id="f61f" class="hf hg hh kk b fi ks kp l kq kr">df.columns</span><span id="7fc2" class="hf hg hh kk b fi ks kp l kq kr">Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',<br/>       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Cabin_null'],<br/>      dtype='object')</span><span id="51bd" class="hf hg hh kk b fi ks kp l kq kr">#It's means that where values in "Cabin_null" are missing. Most of them are not servived(0) that's why there percentage is higher<br/># and where mean is less, so they are survived(1).<br/><br/>df.groupby(['Survived'])['Cabin_null'].mean()</span><span id="9b50" class="hf hg hh kk b fi ks kp l kq kr">Survived<br/>0    0.876138<br/>1    0.602339<br/>Name: Cabin_null, dtype: float64</span></pre><h2 id="b2a4" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">3-随机缺失(MAR)</h2><p id="f7d5" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">比如:男人隐藏他们的薪水，女人隐藏他们的年龄</p><h2 id="953d" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">处理缺失值的所有技术</h2><p id="6994" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-均值/中值/众数替换2-随机样本插补3-捕捉具有新特征的NAN值4-分布终点插补5-任意插补6-常见类别插补</p><h2 id="6148" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">均值/中值/众数插补</h2><p id="5c35" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">什么时候应用这个？均值/中位数插补假设数据完全随机缺失(MAR)。我们通过将NaN替换为最频繁出现的变量来解决这个问题。为了克服离群值，我们使用媒体或模式。</p><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="e76f" class="hf hg hh kk b fi ko kp l kq kr">df = pd.read_csv('train.csv', usecols = ['Age', 'Fare', 'Survived'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/14b471d0d026698482e72956fc0ecbc2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ocWZIXGOgnmqM9ACCrO0Yw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="7c8c" class="hf hg hh kk b fi ko kp l kq kr"># Percentage of missing values<br/>df.isnull().mean()</span><span id="366a" class="hf hg hh kk b fi ks kp l kq kr">Survived    0.000000<br/>Age         0.198653<br/>Fare        0.000000<br/>dtype: float64</span><span id="f0f2" class="hf hg hh kk b fi ks kp l kq kr"># We make a function to impute nan values and give parameters, dataset, column name, median.<br/># in 2nd line we make a new column and fill it with median where there is a nan values in the each column like age,fare,survived<br/><br/>def impute_nan(df, variable, median):<br/>    df[variable+"_median"] = df[variable].fillna(median)</span><span id="2dc8" class="hf hg hh kk b fi ks kp l kq kr">median = df.Age.median()<br/>median</span><span id="25fa" class="hf hg hh kk b fi ks kp l kq kr">28.0</span><span id="f99d" class="hf hg hh kk b fi ks kp l kq kr">impute_nan(df, 'Age', median) #Function call<br/>df.head()                #Now we get column "Age_median" and here all null values of Age is convert to median</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/e512d18f29c7772d4836d84ace7a63ab.png" data-original-src="https://miro.medium.com/v2/format:webp/1*GyYW6Zp7S7FpfrI_IqP1Yg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="8bb1" class="hf hg hh kk b fi ko kp l kq kr">print(df['Age'].std())<br/>print(df['Age_median'].std())    #Standard Deviatipon of 'Age_median' column is less because we handle missing value</span><span id="36ec" class="hf hg hh kk b fi ks kp l kq kr">14.526497332334044<br/>13.019696550973194</span><span id="26c2" class="hf hg hh kk b fi ks kp l kq kr">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="c6ec" class="hf hg hh kk b fi ks kp l kq kr">fig = plt.figure()<br/>ax = fig.add_subplot(111)<br/>df['Age'].plot(kind = 'kde', ax = ax)<br/>df['Age_median'].plot(kind = 'kde', ax = ax, color = 'red')<br/>lines, labels = ax.get_legend_handles_labels()<br/>ax.legend(lines, labels, loc = 'best')</span><span id="56fd" class="hf hg hh kk b fi ks kp l kq kr">&lt;matplotlib.legend.Legend at 0x187d01af8e0&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/e92d65f72cb4d579158fe13b7a2006bb.png" data-original-src="https://miro.medium.com/v2/format:webp/1*iuoPcJH3mVFbw8iYLyb_XQ.png"/></div></figure><h2 id="c378" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">平均值/中值的缺点</h2><p id="620c" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-影响相关性2-原始方差的变化或失真</p><h2 id="2ca8" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">平均值/中值的缺点</h2><p id="f206" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-易于实施2-获得完整数据集的更快方法</p><h2 id="5342" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">2随机样本插补</h2><p id="f717" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">它从数据集中随机抽取观察值，并使用该观察值替换丢失的值。</p><p id="cf54" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated">应该在什么时候使用？当数据完全随机丢失时(MCAR)。</p><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="da19" class="hf hg hh kk b fi ko kp l kq kr">import pandas as pd<br/>import numpy as np</span><span id="2e67" class="hf hg hh kk b fi ks kp l kq kr">df = pd.read_csv('train.csv', usecols = ['Age', 'Fare', 'Survived'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/14b471d0d026698482e72956fc0ecbc2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ocWZIXGOgnmqM9ACCrO0Yw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="0923" class="hf hg hh kk b fi ko kp l kq kr">df.isnull().sum()</span><span id="28ee" class="hf hg hh kk b fi ks kp l kq kr">Survived      0<br/>Age         177<br/>Fare          0<br/>dtype: int64</span><span id="1671" class="hf hg hh kk b fi ks kp l kq kr">#Check percentage of missing values<br/>df.isnull().mean()</span><span id="b603" class="hf hg hh kk b fi ks kp l kq kr">Survived    0.000000<br/>Age         0.198653<br/>Fare        0.000000<br/>dtype: float64</span><span id="2826" class="hf hg hh kk b fi ks kp l kq kr">df['Age'].isnull().sum()</span><span id="6ed0" class="hf hg hh kk b fi ks kp l kq kr">177</span><span id="fa6b" class="hf hg hh kk b fi ks kp l kq kr">#First we are dropping nan values from Age column, then we are picking samples of present or real values and replace<br/>#them with 177 null values and with random state = 0. Sample values will remain same. it will not change everytime<br/><br/>df['Age'].dropna().sample(df['Age'].isnull().sum(), random_state = 0)</span><span id="f528" class="hf hg hh kk b fi ks kp l kq kr">423    28.00<br/>177    50.00<br/>305     0.92<br/>292    36.00<br/>889    26.00<br/>       ...  <br/>539    22.00<br/>267    25.00<br/>352    15.00<br/>99     34.00<br/>689    15.00<br/>Name: Age, Length: 177, dtype: float64</span><span id="5b29" class="hf hg hh kk b fi ks kp l kq kr">#Getting indexes where there are null values<br/><br/>df[df['Age'].isnull()].index</span><span id="fdcf" class="hf hg hh kk b fi ks kp l kq kr">Int64Index([  5,  17,  19,  26,  28,  29,  31,  32,  36,  42,<br/>            ...<br/>            832, 837, 839, 846, 849, 859, 863, 868, 878, 888],<br/>           dtype='int64', length=177)</span><span id="6aec" class="hf hg hh kk b fi ks kp l kq kr">#Create a function to replace tha nan values with random observation<br/><br/>def impute_nan(df, variable, median):<br/>    df[variable+'_median'] = df[variable].fillna(median)<br/>    df[variable+'_random'] = df[variable]<br/>    <br/>    #It will consists of random samples through which we fill nan values<br/>    random_smpl = df[variable].dropna().sample(df[variable].isnull().sum(), random_state = 0)<br/>    <br/>    #Pandas need to have same index in order to merge dataset<br/>    random_smpl.index = df[df[variable].isnull()].index<br/>    df.loc[df[variable].isnull(), variable+'_random'] = random_smpl</span><span id="4a81" class="hf hg hh kk b fi ks kp l kq kr">median = df['Age'].median()<br/>median</span><span id="03a8" class="hf hg hh kk b fi ks kp l kq kr">28.0</span><span id="b59a" class="hf hg hh kk b fi ks kp l kq kr">impute_nan(df, 'Age', median)</span><span id="42fb" class="hf hg hh kk b fi ks kp l kq kr">df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/80acab79d00515d677cca400a437b11a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*FxbZROfCJnS08mi5P4ZMQg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="a432" class="hf hg hh kk b fi ko kp l kq kr">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="1816" class="hf hg hh kk b fi ks kp l kq kr">fig = plt.figure()<br/>ax = fig.add_subplot(111)<br/>df['Age'].plot(kind = 'kde', ax = ax)<br/>df.Age_random.plot(kind = 'kde', ax = ax, color = 'yellow')<br/>lines, labels = ax.get_legend_handles_labels()<br/>ax.legend(lines, labels, loc = 'best')</span><span id="abc1" class="hf hg hh kk b fi ks kp l kq kr">&lt;matplotlib.legend.Legend at 0x187dc0dcd30&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/9f881e447af7cb84c2790420a1152c5c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*STfglDEX7j-pKc7tS2RStQ.png"/></div></figure><h2 id="a119" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">优势</h2><p id="008d" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-方差失真较小</p><h2 id="2fa2" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">3-使用新功能捕获NaN值</h2><p id="714c" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">当数据不是完全随机丢失时，这种方法很有效</p><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="67ac" class="hf hg hh kk b fi ko kp l kq kr">df = pd.read_csv('train.csv', usecols = ['Age', 'Survived', 'Fare'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/14b471d0d026698482e72956fc0ecbc2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ocWZIXGOgnmqM9ACCrO0Yw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="15ae" class="hf hg hh kk b fi ko kp l kq kr">df['Age_NaN'] = np.where(df['Age'].isnull(),1, 0)  <br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/523893f4612aafaa2fc763bfa7767713.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-MmKMGoQI1Ly5tQ0dgF3mw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="dfc0" class="hf hg hh kk b fi ko kp l kq kr">df.Age.median()</span><span id="351d" class="hf hg hh kk b fi ks kp l kq kr">28.0</span><span id="4549" class="hf hg hh kk b fi ks kp l kq kr">df['Age'].fillna(df.Age.median(), inplace = True)<br/>df.head(50)</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/2f018fcfdf587779eb259139616c1583.png" data-original-src="https://miro.medium.com/v2/format:webp/1*eSd3qKw4h9VsXxG57qK9XQ.png"/></div></figure><h2 id="b5ce" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">优势</h2><p id="d160" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-易于实施2-抓住缺失值的重要性</p><h2 id="4759" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">不足之处</h2><p id="5e14" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-创建附加功能(维数灾难)</p><h2 id="c1b2" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">3-分布终点插补</h2><p id="0047" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">获取偏离3个标准偏差的数据</p><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="5976" class="hf hg hh kk b fi ko kp l kq kr">import pandas as pd<br/>import numpy as np</span><span id="afce" class="hf hg hh kk b fi ks kp l kq kr">df = pd.read_csv('train.csv', usecols = ['Age', 'Fare', 'Survived'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/14b471d0d026698482e72956fc0ecbc2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ocWZIXGOgnmqM9ACCrO0Yw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="4cc9" class="hf hg hh kk b fi ko kp l kq kr">df.Age.hist(bins = 50)</span><span id="ad11" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/a833aa3d9b4606b450667c67e95c559f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*MDEA5-IOfoD3kkV9h4Ez7w.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="d05a" class="hf hg hh kk b fi ko kp l kq kr">#Pick right end of distribution of data to replace all NaN Values<br/><br/>extreme = df.Age.mean()+3*df.Age.std()   <br/>extreme</span><span id="28e9" class="hf hg hh kk b fi ks kp l kq kr">73.27860964406095</span><span id="b6c0" class="hf hg hh kk b fi ks kp l kq kr">import seaborn as sns<br/>sns.boxplot('Age', data = df)   #From this we get outliers</span><span id="a045" class="hf hg hh kk b fi ks kp l kq kr">c:\python39\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.<br/>  warnings.warn(<br/><br/><br/><br/><br/><br/>&lt;AxesSubplot:xlabel='Age'&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/2c4dc621ba1bf795945443742ef5d6fe.png" data-original-src="https://miro.medium.com/v2/format:webp/1*3D5-uxUsf0vTLNFz8RNikA.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="b979" class="hf hg hh kk b fi ko kp l kq kr">def impute_NaN(df, median, extreme, variable):<br/>    df[variable+"_end_distribution"] = df[variable].fillna(extreme)<br/>    df[variable].fillna(median, inplace = True) <br/><br/>#Becaue we want to compute 'Age' and 'Age_end_distribution_imputstion'</span><span id="56f7" class="hf hg hh kk b fi ks kp l kq kr">impute_NaN(df, df.Age.median(), extreme, 'Age')</span><span id="f1ad" class="hf hg hh kk b fi ks kp l kq kr">df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/d61a2b74a4cdac53c69ddba4c84e16f4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Rg9Mx1UDJIyJW92jiIA4AQ.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="c972" class="hf hg hh kk b fi ko kp l kq kr">df['Age'].hist(bins = 50)     #Because we give median value in nan values in feature 'Age'</span><span id="284f" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/2ada9e4209f1b108a7fa54b6ae6cdea9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*rI8wvOqDkEulrP5-4O7Jyg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="c97f" class="hf hg hh kk b fi ko kp l kq kr">df['Age_end_distribution'].hist(bins=50)</span><span id="23cf" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/870f09ad7e50674f613d012e28bce334.png" data-original-src="https://miro.medium.com/v2/format:webp/1*18XC8aX-vGvee0TXNMwY9w.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="f555" class="hf hg hh kk b fi ko kp l kq kr">sns.boxplot('Age_end_distribution', data = df) <br/><br/>#Now in box plot we see that there is no outlierrs by usinng end of distribution</span><span id="3240" class="hf hg hh kk b fi ks kp l kq kr">c:\python39\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.<br/>  warnings.warn(<br/><br/><br/><br/><br/><br/>&lt;AxesSubplot:xlabel='Age_end_distribution'&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/82e343d63291a7e06f5ae334c391ad7c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*3c_q0vIYSL_xMZzVR91kFg.png"/></div></figure><h2 id="e6ef" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">优势:</h2><p id="4ba7" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">1-异常值通过使用末端分布捕获</p><h1 id="8c3c" class="ku hg hh bd hi kv kw kx hm ky kz la hq lb lc ld hu le lf lg hy lh li lj ic lk bi translated">任意值插补</h1><p id="6a0f" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">它包括用任意值替换每个特性的NaN值，任意值应该是不同的</p><p id="9fe9" class="pw-post-body-paragraph iv iw hh ix b iy jr ja jb jc js je jf hr jt jh ji hv ju jk jl hz jv jn jo jp ha bi translated">什么是任意值？这里，我们取最后一个异常值，也可以取最小的异常值。2-用于查看缺失值的重要性3-</p><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="a667" class="hf hg hh kk b fi ko kp l kq kr">import pandas as pd<br/>import numpy as np</span><span id="0c1c" class="hf hg hh kk b fi ks kp l kq kr">df = pd.read_csv('train.csv', usecols= ['Age', 'Survived', 'Fare'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/14b471d0d026698482e72956fc0ecbc2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ocWZIXGOgnmqM9ACCrO0Yw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="4d12" class="hf hg hh kk b fi ko kp l kq kr">def impute_NaN(df, variable):<br/>    df[variable+'Zeros'] = df[variable].fillna(0)<br/>    df[variable+'Hundreds'] = df[variable].fillna(100)</span><span id="96bc" class="hf hg hh kk b fi ks kp l kq kr">impute_NaN(df, 'Age')</span><span id="4e6c" class="hf hg hh kk b fi ks kp l kq kr">df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/5b88e0ecc1f77748ac2c9da6179ff1ed.png" data-original-src="https://miro.medium.com/v2/format:webp/1*roq6jJ-HpsijFGrY5y72Vg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="c3d8" class="hf hg hh kk b fi ko kp l kq kr">df['Age'].hist(bins = 50)</span><span id="b9bf" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/a833aa3d9b4606b450667c67e95c559f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*MDEA5-IOfoD3kkV9h4Ez7w.png"/></div></figure><h2 id="b783" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">如何处理分类缺失值</h2><h2 id="d053" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">1-频繁类别插补</h2><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="d685" class="hf hg hh kk b fi ko kp l kq kr">import pandas as pd</span><span id="4f62" class="hf hg hh kk b fi ks kp l kq kr">df.columns</span><span id="4c69" class="hf hg hh kk b fi ks kp l kq kr">Index(['Survived', 'Age', 'Fare', 'AgeZeros', 'AgeHundreds'], dtype='object')</span><span id="3ec0" class="hf hg hh kk b fi ks kp l kq kr">df = pd.read_csv('house.csv', usecols = ['BsmtQual', 'FireplaceQu', 'GarageType', 'SalePrice'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/a6e18a3431da064195e056da4ba91fe8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*eDx5qXWXXXUOt52rc-vNkQ.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="283e" class="hf hg hh kk b fi ko kp l kq kr">df.isnull().mean()</span><span id="17b0" class="hf hg hh kk b fi ks kp l kq kr">BsmtQual       0.025342<br/>FireplaceQu    0.472603<br/>GarageType     0.055479<br/>SalePrice      0.000000<br/>dtype: float64</span><span id="2335" class="hf hg hh kk b fi ks kp l kq kr">df.isnull().mean().sort_values(ascending = True)</span><span id="65c2" class="hf hg hh kk b fi ks kp l kq kr">SalePrice      0.000000<br/>BsmtQual       0.025342<br/>GarageType     0.055479<br/>FireplaceQu    0.472603<br/>dtype: float64</span><span id="2bba" class="hf hg hh kk b fi ks kp l kq kr">df.isnull().sum()<br/><br/>#As we seen that BsmtQual abd GarageType has less nan values so we replace it with more frequent tcategories</span><span id="caee" class="hf hg hh kk b fi ks kp l kq kr">BsmtQual        37<br/>FireplaceQu    690<br/>GarageType      81<br/>SalePrice        0<br/>dtype: int64</span><span id="2107" class="hf hg hh kk b fi ks kp l kq kr">#To find maximum number of frequent features<br/><br/>df.groupby(['BsmtQual'])['BsmtQual'].count()</span><span id="faba" class="hf hg hh kk b fi ks kp l kq kr">BsmtQual<br/>Ex    121<br/>Fa     35<br/>Gd    618<br/>TA    649<br/>Name: BsmtQual, dtype: int64</span><span id="c349" class="hf hg hh kk b fi ks kp l kq kr">df.groupby(['BsmtQual'])['BsmtQual'].count().sort_values(ascending = False).plot.bar()</span><span id="69f7" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:xlabel='BsmtQual'&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/2d90fb5dc4d5d21cdfe61cdbbfc88ce1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*njFHxmydTyAT7esp82DRjg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="7e4c" class="hf hg hh kk b fi ko kp l kq kr">df['BsmtQual'].value_counts()     #Method to get most frequent category</span><span id="6a43" class="hf hg hh kk b fi ks kp l kq kr">TA    649<br/>Gd    618<br/>Ex    121<br/>Fa     35<br/>Name: BsmtQual, dtype: int64</span><span id="8984" class="hf hg hh kk b fi ks kp l kq kr">df['BsmtQual'].value_counts().sort_values(ascending = False).plot.bar()</span><span id="fdc1" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/70bc32f2828c9ac6a5b2bcd0273d5f5c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*FUpXTDwSj9xx4JRme0YHaw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="b5ed" class="hf hg hh kk b fi ko kp l kq kr">df.groupby(['GarageType'])['GarageType'].count()    #Code to get categories which is most frequenting</span><span id="dc24" class="hf hg hh kk b fi ks kp l kq kr">GarageType<br/>2Types       6<br/>Attchd     870<br/>Basment     19<br/>BuiltIn     88<br/>CarPort      9<br/>Detchd     387<br/>Name: GarageType, dtype: int64</span><span id="88ad" class="hf hg hh kk b fi ks kp l kq kr">df.groupby(['GarageType'])['GarageType'].count().sort_values(ascending = False).plot.bar()</span><span id="7af5" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:xlabel='GarageType'&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/8434e1daf814d8b5e51bdf294b58893a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*gIV5bzSciMSPtgKAV_eO5w.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="9c50" class="hf hg hh kk b fi ko kp l kq kr">df['GarageType'].value_counts().plot.bar()</span><span id="0816" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/5c3a3f13d6e8298a5a39a55a16bfe12d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Su5gwQfOxQ6Td7AygFPwCg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="90d3" class="hf hg hh kk b fi ko kp l kq kr">df['FireplaceQu'].mode()[0]    #Code to get most frequent category</span><span id="beab" class="hf hg hh kk b fi ks kp l kq kr">'Gd'</span><span id="0f50" class="hf hg hh kk b fi ks kp l kq kr">df['FireplaceQu'].value_counts()   # You can also get most frequent category by this code</span><span id="6242" class="hf hg hh kk b fi ks kp l kq kr">Gd    380<br/>TA    313<br/>Fa     33<br/>Ex     24<br/>Po     20<br/>Name: FireplaceQu, dtype: int64</span><span id="3727" class="hf hg hh kk b fi ks kp l kq kr">df['BsmtQual'].value_counts().index[0]    #Another method to get most frequent category</span><span id="0e95" class="hf hg hh kk b fi ks kp l kq kr">'TA'</span><span id="3341" class="hf hg hh kk b fi ks kp l kq kr">df['FireplaceQu'].value_counts().plot.bar()</span><span id="5577" class="hf hg hh kk b fi ks kp l kq kr">&lt;AxesSubplot:&gt;</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/cd503eabb5414f6b55cb3d30483c5c00.png" data-original-src="https://miro.medium.com/v2/format:webp/1*x7RXz-Bzz77NFyLdNgVNhg.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="23b7" class="hf hg hh kk b fi ko kp l kq kr">#### Replacing functions<br/>def impute_NaN(df, variable):<br/>    mst_frequent = df[variable].value_counts().index[0]<br/>    df[variable].fillna(mst_frequent, inplace = True)</span><span id="2f1d" class="hf hg hh kk b fi ks kp l kq kr">for features in ['BsmtQual', 'FireplaceQu', 'GarageType']:<br/>    impute_NaN(df, features)</span><span id="bd8e" class="hf hg hh kk b fi ks kp l kq kr">df.isnull().mean()</span><span id="b5a4" class="hf hg hh kk b fi ks kp l kq kr">BsmtQual       0.0<br/>FireplaceQu    0.0<br/>GarageType     0.0<br/>SalePrice      0.0<br/>dtype: float64</span></pre><h2 id="cb64" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">不足之处</h2><p id="79ee" class="pw-post-body-paragraph iv iw hh ix b iy iz ja jb jc jd je jf hr jg jh ji hv jj jk jl hz jm jn jo jp ha bi translated">当您有高缺失值时，就不应该使用这种技术。因为这将扭曲最常见类别与因变量之间的关系</p><h1 id="ee8a" class="ku hg hh bd hi kv kw kx hm ky kz la hq lb lc ld hu le lf lg hy lh li lj ic lk bi translated">2-添加变量以捕获NaN</h1><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="6b2a" class="hf hg hh kk b fi ko kp l kq kr">df = pd.read_csv('house.csv', usecols = ['BsmtQual', 'FireplaceQu', 'GarageType', 'SalePrice'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/a6e18a3431da064195e056da4ba91fe8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*eDx5qXWXXXUOt52rc-vNkQ.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="7cb6" class="hf hg hh kk b fi ko kp l kq kr">import numpy as np<br/>#Capturing the importance of null values<br/><br/>df['BsmtQual_var'] = np.where(df['BsmtQual'].isnull(), 1, 0)  <br/>df</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/76da1dac40266fa23d5a02ec6fb89605.png" data-original-src="https://miro.medium.com/v2/format:webp/1*7AIktUhCCPROymlIa43tiQ.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="dd55" class="hf hg hh kk b fi ko kp l kq kr">frequent = df['BsmtQual'].mode()[0]    #getting Most frequent  category</span><span id="8876" class="hf hg hh kk b fi ks kp l kq kr">df['BsmtQual'].fillna(frequent, inplace = True)    #replacing most frequent item to null valuees in 'BsmtQual'<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/08b6470576774de7ada98ab75d231794.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_v5NMyy8a55iX_emMShEVw.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="3078" class="hf hg hh kk b fi ko kp l kq kr">df['FireplaceQu_var'] = np.where(df['FireplaceQu'].isnull(),1, 0)<br/>frequent = df['FireplaceQu'].mode()[0]<br/>df['FireplaceQu'].fillna(frequent, inplace = True)</span><span id="8e86" class="hf hg hh kk b fi ks kp l kq kr">df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/0801defcf04a9bc127448c1196873c06.png" data-original-src="https://miro.medium.com/v2/format:webp/1*jeVToeOJ4mOYB7zFxd6hmQ.png"/></div></figure><h2 id="82da" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">如果你有更频繁的类别，我们只是用一个新的类别来代替NAN</h2><h2 id="ea29" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">优势</h2><h2 id="0517" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">1-如果我们有许多空值，那么我们必须使用这种技术</h2><h2 id="998b" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">缺点:</h2><h2 id="386a" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">1-许多功能将会出现</h2><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="5b32" class="hf hg hh kk b fi ko kp l kq kr">df = pd.read_csv('house.csv', usecols = ['BsmtQual', 'FireplaceQu', 'GarageType', 'SalePrice'])<br/>df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/a6e18a3431da064195e056da4ba91fe8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*eDx5qXWXXXUOt52rc-vNkQ.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="c0a5" class="hf hg hh kk b fi ko kp l kq kr">def impute_NaN(df, variable):<br/>    df[variable+'_var2'] = np.where(df[variable].isnull(),'Missing', df[variable])</span><span id="d07b" class="hf hg hh kk b fi ks kp l kq kr">for feature in ['BsmtQual', 'FireplaceQu', 'GarageType']:<br/>    impute_NaN(df, feature)</span><span id="89f6" class="hf hg hh kk b fi ks kp l kq kr">df.head()</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/1a2fb08cc980572f583044c344e32163.png" data-original-src="https://miro.medium.com/v2/format:webp/1*5OSVTA12sIXlhHGGLfKS4g.png"/></div></figure><pre class="if ig ih ii fd kj kk kl km aw kn bi"><span id="cfc9" class="hf hg hh kk b fi ko kp l kq kr">#Most use technique to replace nan with new category<br/><br/>df = df.drop(['BsmtQual', 'FireplaceQu', 'GarageType'], axis = 1)</span><span id="9ed0" class="hf hg hh kk b fi ks kp l kq kr">df</span></pre><figure class="if ig ih ii fd ij er es paragraph-image"><div class="ab fe cl kt"><img src="../Images/021e7c60ab9a3c134adddbb2fa7fab09.png" data-original-src="https://miro.medium.com/v2/format:webp/1*XwWnBVMP9btnWJSygn3XmQ.png"/></div></figure><div class="jw jx ez fb jy jz"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ka ab dw"><div class="kb ab kc cl cj kd"><h2 class="bd jq fi z dy ke ea eb kf ed ef kg bi translated">Mlearning.ai提交建议</h2><div class="kh l"><h3 class="bd b fi z dy ke ea eb kf ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ki l"><p class="bd b fp z dy ke ea eb kf ed ef dx translated">medium.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq io jz"/></div></div></a></div></div></div>    
</body>
</html>
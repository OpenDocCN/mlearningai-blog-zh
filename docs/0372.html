<html>
<head>
<title>Custom Vision “compact” models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">定制视觉“紧凑型”模型</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/custom-vision-compact-models-62ac5a2e2687?source=collection_archive---------3-----------------------#2021-03-31">https://medium.com/mlearning-ai/custom-vision-compact-models-62ac5a2e2687?source=collection_archive---------3-----------------------#2021-03-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="39f9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">正如我在上一篇文章中所承诺的，我们现在将重点关注定制视觉“紧凑型”模型。它们是什么？用例？与标准型号相比，它们的性能如何？</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jj"><img src="../Images/f7cfc227624669d91f94d45ecbb8b85f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SoC0UMMUGRDOmf6y"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Photo by <a class="ae jz" href="https://unsplash.com/@jamie452?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jamie Street</a> on <a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="e493" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">紧凑的世界</h1><p id="6df9" class="pw-post-body-paragraph il im hh in b io ky iq ir is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ha bi translated">一个非常有趣的定制视觉功能是可以导出一个简化版本的模型，在Azure环境之外的小型(IoT)设备或手机上运行。</p><p id="2d61" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当安装在设备中时，它将允许在没有互联网连接的情况下获得快速推断(因为它不需要访问外部API)。因此，应用程序可以提供实时功能和/或离线支持。</p><h1 id="2d06" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">它是如何工作的</h1><p id="69ff" class="pw-post-body-paragraph il im hh in b io ky iq ir is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ha bi translated">在Custom Vision中使用紧凑模型与我们习惯使用其他模型类型没有什么不同。事实上，这是完全一样的，除了我们需要考虑的几个细节:</p><ul class=""><li id="5932" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated">创建新模型时选择“紧凑”,每个域都有一个轻量级版本。不要担心，您可以稍后设置这个选项，这样您就可以在重新训练模型后导出它。</li></ul><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es lm"><img src="../Images/572f58f2c9f6d38c2324c13a561a61c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/0*oMkYeNHAvckL6pTp.png"/></div></figure><ul class=""><li id="1f95" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated">按照标准机制上传图像、标记和训练模型。</li><li id="a5fc" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">当您对结果满意时，从选项卡“Performance”中导出模型。似乎微软在构建这一功能时感觉很慷慨，因此您将能够导出模型，以便在大量不同格式的环境中使用，包括TensorFlow等知名的开源平台。</li><li id="3912" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">从那时起，这个模型就是你的了，你想怎么做就怎么做。您可以使用更多图像在本地重新训练它(这样您就不必在自定义视觉中支付额外的时间)或在外部系统中运行它。</li></ul><h1 id="3496" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">测试模型</h1><p id="9f2c" class="pw-post-body-paragraph il im hh in b io ky iq ir is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ha bi translated">但是一切都是有代价的，所以我们将测试我们模型的独立格式的性能，以识别室内图像，并将其与我们上一篇文章中进行的调查中获得的结果进行比较。</p><p id="4557" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了遵循完全相同的步骤，我们再次运行我们的脚本，用2500幅图像来训练模型。经过2次迭代后，该模型呈现以下行为:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ls"><img src="../Images/dd3cbfbb615f65ab4c1185dd0f5d67f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zUxQ-PsKMxjfxUMP.png"/></div></div></figure><p id="aecb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">其显示了相对于标准模型(<strong class="in hi">精度</strong> : 85.6%、<strong class="in hi">召回</strong> : 79.5%和<strong class="in hi"> AP </strong> : 89.9%)在AP、精度以及特别是召回值方面的显著下降。这是我们从一个简化的实例中所期待的。</p><p id="a0db" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，让我们检查模型的性能，并通过使用单独的验证数据集检索API推理来模拟它在生产环境中的工作方式…</p><ul class=""><li id="58f2" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated">总计:500</li><li id="6785" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">正确预测:285</li><li id="9ea2" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">失败的预测:215</li><li id="45ee" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">精度:0.571</li><li id="0ab6" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">回忆:0.57</li><li id="f9ed" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">平均预测时间:0.29秒</li></ul><p id="6af7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">…可以与之前的结果相比较…</p><ul class=""><li id="f2ad" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated">总计:500</li><li id="0bdd" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">正确预测:363</li><li id="f204" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">失败的预测:137次</li><li id="250a" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">精度:0.75</li><li id="55a9" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">回忆:0.73</li><li id="019f" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated">平均预测时间:0.53秒</li></ul><p id="0321" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">正如可以观察到的，精度和召回指标显示了额外的损失。另一方面，平均预测时间大大减少了(当模型安装在设备上时，这种差异甚至会更显著，从而节省了网络延迟时间)。</p><p id="4a49" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这些值是否足够将取决于您的应用程序的要求，但请记住，此时可以遵循不同的策略来改善结果(如使用更大的数据集训练模型或预处理图像以找到最佳图像配置)。</p><h1 id="7309" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">使用导出的模型</h1><p id="dceb" class="pw-post-body-paragraph il im hh in b io ky iq ir is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ha bi translated">最后，我们将探讨Tensorflow导出模型的格式。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es lt"><img src="../Images/8028886254f82b2f85043f79cba423c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gPtx15aqQxXj7ftd.png"/></div></div></figure><p id="1d49" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下载文件夹的内容由同一级别的4个文件组成:</p><ul class=""><li id="7e61" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated"><strong class="in hi"> cvexport.manifest </strong> —包含与自定义视觉项目和下载文件夹相关的信息。</li></ul><pre class="jk jl jm jn fd lu lv lw lx aw ly bi"><span id="5b7b" class="lz kb hh lv b fi ma mb l mc md">{<br/>  "DomainType": "Classification",<br/>  "Platform": "TensorFlow",<br/>  "Flavor": "TensorFlowSavedModel",<br/>  "ExporterVersion": "2.0",<br/>  "ExportedDate": "2020-11-13T12:02:17.8476449Z",<br/>  "IterationId": "xx-xxx-xxx-xxx",<br/>  "ModelFileName": "saved_model.pb",<br/>  "LabelFileName": "labels.txt",<br/>  "MetadataPropsFileName": "metadata_properties.json",<br/>  "SchemaVersion": "1.0"<br/>}</span></pre><ul class=""><li id="c84f" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated"><strong class="in hi"> labels.txt </strong> —包含分类标签(在我们的例子中是不同室内场景类别的列表)。</li><li id="8702" class="ld le hh in b io ln is lo iw lp ja lq je lr ji li lj lk ll bi translated"><strong class="in hi">metadata _ properties . JSON</strong>—包含与模型的训练和预处理相关的信息。</li></ul><pre class="jk jl jm jn fd lu lv lw lx aw ly bi"><span id="6e48" class="lz kb hh lv b fi ma mb l mc md">{<br/>    "CustomVision.Metadata.AdditionalModelInfo": "Additional information about the model",<br/>    "CustomVision.Metadata.Version": "1.1",<br/>    "CustomVision.Postprocess.Method": "ClassificationMultiClass",<br/>    "CustomVision.Postprocess.Yolo.Biases": "null",<br/>    "CustomVision.Postprocess.Yolo.NmsThreshold": "null",<br/>    "CustomVision.Preprocess.CropHeight": "0",<br/>    "CustomVision.Preprocess.CropMethod": "FullImageShorterSide",<br/>    "CustomVision.Preprocess.CropWidth": "0",<br/>    "CustomVision.Preprocess.MaxDimension": "0",<br/>    "CustomVision.Preprocess.MaxScale": "0",<br/>    "CustomVision.Preprocess.MinDimension": "0",<br/>    "CustomVision.Preprocess.MinScale": "0",<br/>    "CustomVision.Preprocess.NormalizeMean": "[0.0, 0.0, 0.0]",<br/>    "CustomVision.Preprocess.NormalizeStd": "[1.0, 1.0, 1.0]",<br/>    "CustomVision.Preprocess.ResizeMethod": "ByShorterSideAlign32",<br/>    "CustomVision.Preprocess.TargetHeight": "224",<br/>    "CustomVision.Preprocess.TargetWidth": "224",<br/>    "Image.BitmapPixelFormat": "Rgb8",<br/>    "Image.ColorSpaceGamma": "SRGB",<br/>    "Image.NominalPixelRange": "Normalized_0_1"<br/>}</span></pre><ul class=""><li id="4910" class="ld le hh in b io ip is it iw lf ja lg je lh ji li lj lk ll bi translated"><strong class="in hi"> model.pb </strong> —标准Tensorflow protobuf格式的训练模型。在本教程中，可以找到如何运行它来执行分类推理。<strong class="in hi">重要提示</strong>:该教程可能有点过时，该型号似乎接受224X224图像，而不是256X256。</li></ul><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ls"><img src="../Images/ac25061d62efa570852914f0a17aacc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hD3DsLxF5uAOauN5.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx">Structure of the model graph when explored with TensorBoard</figcaption></figure><p id="03ea" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们的大小。pb模型为5.2MB，对于存储在资源有限的小工具中来说，这似乎是一个合理的大小。</p><h1 id="b8f6" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">结论</h1><p id="9b2c" class="pw-post-body-paragraph il im hh in b io ky iq ir is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ha bi translated">即使有些限制，我认为当计划在小型独立设备中使用时，紧凑型是一个非常有趣的选择，可能没有互联网接入。我的建议是:试一试，和他们一起玩，看看他们的能力是否适合你的下一个项目。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="39f5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="me">最初发布于:</em><a class="ae jz" href="https://cleverstuff.ai/article/custom-vision-compact-models" rel="noopener ugc nofollow" target="_blank"><em class="me">https://cleverstuff.ai/article/custom-vision-compact-models</em></a></p></div></div>    
</body>
</html>
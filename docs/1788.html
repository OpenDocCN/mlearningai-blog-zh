<html>
<head>
<title>Read Papers With Me: Bootstrap Your Own Latent: A New Approach To Self-Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">和我一起阅读论文:引导你自己的潜能:自我监督学习的新方法</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/read-paper-with-me-bootstrap-your-own-latent-a-new-approach-to-self-supervised-learning-e6580ce8dae5?source=collection_archive---------3-----------------------#2022-01-29">https://medium.com/mlearning-ai/read-paper-with-me-bootstrap-your-own-latent-a-new-approach-to-self-supervised-learning-e6580ce8dae5?source=collection_archive---------3-----------------------#2022-01-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="d58a" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">自我监督学习方法——BYOL的解读</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/2809661caea5fca60fb04ad0ac075b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EwArOBmDMX1KpXL6Tpln1A.png"/></div></div></figure><ul class=""><li id="7e22" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">这篇博客介绍了<em class="ka"/><a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ka">引导你自己的潜在</em>【BYOL】</a>方法，这是一种由DeepMind和伦敦帝国提出的自我监督学习方法</li></ul></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><p id="65ac" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><strong class="jk hi">看一眼纸:</strong></p><ul class=""><li id="bd30" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">BYOL包含两个架构相同但参数不同的网络。</li><li id="0ee4" class="ji jj hh jk b jl kw jn kx jp ky jr kz jt la jv jw jx jy jz bi translated">BYOL不需要负对，而大多数对比学习方法都需要负对，例如<a class="ae kb" href="https://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank"> SimCLR </a></li></ul></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><p id="6701" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><strong class="jk hi">背景:</strong></p><p id="5a13" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><a class="ae kb" href="https://towardsdatascience.com/understanding-contrastive-learning-d5b19fd96607#:~:text=Contrastive%20learning%20is%20a%20machine,points%20are%20similar%20or%20different%20.&amp;text=In%20essence%2C%20contrastive%20learning%20allows,to%20do%20the%20same%20thing." rel="noopener" target="_blank">对比学习(CL) </a>目前在自我监督学习方面取得了最先进的成绩。在对比学习中，来自相同图像的视图被称为正对视图，而来自不同图像的视图被称为负对视图。</p><p id="ea42" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">然而，可以有无限多的负对，CL需要大量负对以确保其性能。这项工作因此提出了一个新的框架，称为BYOL，以消除对负对的需要。</p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><p id="9fde" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><strong class="jk hi">方法:</strong></p><ol class=""><li id="dfca" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv lb jx jy jz bi translated">概观</li></ol><p id="93fd" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">在这个框架中有两个网络。一个名为在线模型，另一个名为目标模型。在线模型用θ参数化，目标模型用ξ参数化。两个模型具有动态行为:</p><ul class=""><li id="092f" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">目标模型通过计算θ的<a class="ae kb" href="https://en.wikipedia.org/wiki/Moving_average" rel="noopener ugc nofollow" target="_blank">指数移动平均(EMA) </a>来更新其参数ξ。</li><li id="cdbd" class="ji jj hh jk b jl kw jn kx jp ky jr kz jt la jv jw jx jy jz bi translated">在线模型通过学习目标模型的参数ξ来更新其参数θ。</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lc"><img src="../Images/7b1f5750b2da8c42dd40c9e02b5073c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJZkb3CzBchEjci9Ltbg6Q.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">The dynamics between the online and target models. Image from the author.</figcaption></figure><p id="6f62" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">2.参数更新</p><p id="26d4" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">我将在下面详细解释每个更新的方式:</p><ul class=""><li id="8264" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">ξ由θ更新:这是通过计算指数移动平均线(EMA)完成的，定义如下:</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lh"><img src="../Images/400a0e188f08068ef5c2b1648f9bde19.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*I-8I9MoLo0mWClIAhIcx0Q.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">The formula of Exponential Moving Average (EMA). τ is a target decay rate and τ ∈ [0,1]. Suppose Compared with getting a plain average of θ over a certain time series, EMA assigned larger weights to more recent θ. This can be seen in the fact that if you expand the ξ on the right side, τ becomes τⁿ (n is the timestep). As τ is less one, τⁿ will become smaller, meaning its importance is decaying. Image from the <a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure><ul class=""><li id="7dd4" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">θ由ξ更新:这是通过优化目标函数来实现的。目标函数是归一化预测q_θ_bar和目标z′_ξ_ bar之间的均方误差:</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es li"><img src="../Images/2b3197d0f7dc1ca014e69f53089f04cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*VZb5NkWHyGDKxmKo1DRHeg.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Image from the <a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure><ul class=""><li id="db9d" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">q_θ_bar是q_θ的<a class="ae kb" href="https://mathworld.wolfram.com/L2-Norm.html" rel="noopener ugc nofollow" target="_blank"> L2归一化</a>;</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lj"><img src="../Images/8e1833e3bb67cea70ee9bc94e4cbb4fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*_mBpwSPXM6bDA4300-QY6Q.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Image from the <a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure><ul class=""><li id="60f0" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">z'_ξ_bar是z'_ξ的L2归一化:</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lk"><img src="../Images/c9d6eb06ac0628cbaf4328488db7dcd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*p9wO4K-o4MSZGpZaz3KAcQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Image from the <a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure><p id="6268" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">3.目标z'_ξ的构造和q_θ的预测</p><p id="e403" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">这是这个方法的核心部分。在线模型中，有三个阶段:编码器f_θ、投影器g_θ和预测器q_θ。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ll"><img src="../Images/9a38d474156c0e6fd79c6bb41006fa02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rXKcAigRajsZnIvaIsmb7w.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">The online model is made from an encoder, a projector, and a predictor. The online model predicts the projection from the target via the objective function mentioned above. sg stands for stop gradient, meaning that the gradient does NOT backpropagate in the target model because the target model is updated using EMA. After training, everything except f_θ is discarded. Image adapted from the <a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure><p id="611b" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">整个结构很可能建立在<a class="ae kb" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> SimCLR </a>框架之上，所以我将简单介绍一下。在SimCLR中，输入图像被t和t’变换以生成两个增强视图，然后通过编码器f(⋅和投影仪g(⋅以获得投影表示。然后，将zᵢ和zⱼ的投影表示进行对比，以最大化它们的协议，这被发现比直接最大化hᵢ和hⱼ之间的协议导致更好的性能。通过使用来自不同输入图像的视图来构建负像对。关于<a class="ae kb" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> SimCLR </a>论文的更多细节。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lm"><img src="../Images/72b15f8ffc113f17bc77e04c09ff8152.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*pF-SHPGDWxyMeA1aWLm2LQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Overview of the <a class="ae kb" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">SimCLR</a> framework</figcaption></figure><p id="3c5e" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">然而，不同之处在于，在BYOL，通过不同的编码器f_θ和f_ξ生成两个视图。这两种架构相同，但参数不同。此外，在BYOL，有一个预测和目标网络。正如你所看到的，在BYOL，不需要消极的一对。</p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><p id="ae21" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><strong class="jk hi">成绩:</strong></p><p id="cbb7" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">BYOL模型优于SimCLR。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ln"><img src="../Images/2d599cb5b11af8b7c8cd8072d91e9c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*12kNCDgZA8KonND3ea_FDw.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Image from the <a class="ae kb" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><p id="b66b" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><strong class="jk hi">结论:</strong></p><p id="9cdd" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">BYOL提供了一种新的不需要负对的自我监督学习方法。</p><p id="bbbb" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated">BYOL有两种型号，结构相同，但参数不同。在线模型通过优化目标函数来更新其参数。目标模型通过计算指数移动平均值来更新其参数。</p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><p id="f8c1" class="pw-post-body-paragraph kj kk hh jk b jl jm ii kl jn jo il km jp kn ko kp jr kq kr ks jt kt ku kv jv ha bi translated"><strong class="jk hi">个人备注:</strong></p><ol class=""><li id="1ab9" class="ji jj hh jk b jl jm jn jo jp jq jr js jt ju jv lb jx jy jz bi translated">构建足够多的否定对是保证对比学习效果的重要步骤。否则，可能会出现名为<a class="ae kb" href="https://arxiv.org/abs/2110.09348" rel="noopener ugc nofollow" target="_blank">折叠表示</a>的问题。这项工作为不使用负对的自我监督学习开辟了一条新的途径。</li><li id="84fa" class="ji jj hh jk b jl kw jn kx jp ky jr kz jt la jv lb jx jy jz bi translated">EMA用来考虑之前的θ，偏向新的θ。这种技术已经在其他方法中使用，例如<a class="ae kb" href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c" rel="noopener" target="_blank"> Adam </a>优化器。原始论文还对EMA的τ进行了烧蚀研究。</li></ol><div class="lo lp ez fb lq lr"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hi fi z dy lw ea eb lx ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">medium.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf jg lr"/></div></div></a></div></div></div>    
</body>
</html>
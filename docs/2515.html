<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/step-by-step-linear-regression-a-holistic-view-9bb26265de1?source=collection_archive---------2-----------------------#2022-05-13">https://medium.com/mlearning-ai/step-by-step-linear-regression-a-holistic-view-9bb26265de1?source=collection_archive---------2-----------------------#2022-05-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="4aa9" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">线性回归简介</h2><p id="31fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io hr ip iq ir hv is it iu hz iv iw ix iy ha bi translated">线性回归可以被视为一种基本算法，在它开始在计算机上编码之前，已经在纸上使用了很长时间。许多计量经济学学生在学习中会遇到这种算法。这是一个<strong class="ig iz">监督机器学习</strong>算法的例子。</p><p id="9a57" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz">监督学习算法</strong> <br/>监督学习算法是这样一种算法，其中我们拥有训练数据集的特征和结果，并且我们使用测试数据集的特征来生成测试数据集的结果变量。</p><p id="9498" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">您可能对可以通过线性回归解决的多个问题感兴趣:</p><ul class=""><li id="0c2f" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">如果你以v·m/s的初速度扔球，球会飞多远(牛顿之前可能需要)</li><li id="42c3" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">根据客户的年龄，可能需要多少保险费</li><li id="6649" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">如果您为某个特定的应用程序添加功能#1、2、3 … n，会产生多少利润</li></ul><p id="4662" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz">回归背后的数学原理</strong> <br/>我们将讨论回归模型所需的步骤，但在此之前，让我们了解回归模型背后的一些数学原理。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/c8e4049bb928c0ca7e146a77add1b044.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*OP6oghwdI57_kM8bk5f--Q.png"/></div></div></figure><p id="6477" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们通常有n个相关的数据点，我们希望对其进行预测。(请记住，我们试图统计估计这些参数β0和β1的值，而不是试图求解这些方程以获得精确值(请记住，有2个变量和n个方程，这些方程同意单一解的概率非常低)。</p><p id="b84b" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">因此，我们有:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kf"><img src="../Images/eb5af3c69c0085daaf323cb1162a9b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*FbId8A2-eVSt9ydPZSI6Kg.png"/></div></figure><p id="2218" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">如果我们重写这个等式，我们会得到一个等式:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kg"><img src="../Images/82e9482e1cddc0edc78237af9b4ea53c.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*rUhjCAChLChrdyhIh3SHFQ.png"/></div></figure><p id="74c6" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">现在，我们试图找到β1和β0的值，它们使$\epsilon$参数的值总体上(统计上)最小化。<br/>同样，我们计算<strong class="ig iz">平方和误差</strong>(或平方和误差)的值，也称为SSE。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kh"><img src="../Images/b633a661fccb131e66b1674de26c75fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*jnXvcJoAQhfRf8CkuRWy-w.png"/></div></figure><p id="9438" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">同一个等式可以外推到多个变量。如同</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ki"><img src="../Images/918051d8d0a00fdb1a1ff063c091c916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*PwTX-649GZUzW2tHvn5ICw.png"/></div></figure><p id="afc3" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz">收集数据</strong> <br/>线性回归模型和任何模型的第一步都是收集数据。这里我们将使用Kaggle上提供的保险成本数据集。可以在这里下载。</p><div class="kj kk ez fb kl km"><a href="https://www.kaggle.com/datasets/mirichoi0218/insurance?select=insurance.csv" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd iz fi z dy kr ea eb ks ed ef kt bi translated">医疗费用个人数据集</h2><div class="ku l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">利用线性回归进行保险预测</h3></div><div class="kv l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">www.kaggle.com</p></div></div><div class="kw l"><div class="kx l ky kz la kw lb kd km"/></div></div></a></div><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="b799" class="hf hg hh ld b fi lh li l lj lk">import pandas as pd<br/>insurance_cost = pd.read_csv("Insurance_Cost.csv")</span><span id="292a" class="hf hg hh ld b fi ll li l lj lk">insurance_cost.info()</span><span id="4c75" class="hf hg hh ld b fi ll li l lj lk">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 1338 entries, 0 to 1337<br/>Data columns (total 7 columns):<br/> #   Column    Non-Null Count  Dtype  <br/>---  ------    --------------  -----  <br/> 0   age       1338 non-null   int64  <br/> 1   sex       1338 non-null   object <br/> 2   bmi       1338 non-null   float64<br/> 3   children  1338 non-null   int64  <br/> 4   smoker    1338 non-null   object <br/> 5   region    1338 non-null   object <br/> 6   charges   1338 non-null   float64<br/>dtypes: float64(2), int64(2), object(3)<br/>memory usage: 73.3+ KB</span></pre><p id="91b6" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">从上表可以推断出以下内容:</p><ul class=""><li id="7926" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">所有数据点都是完整的(否则至少有一个变量会有不同的非空计数)</li><li id="a596" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">有4个数字变量:年龄，身体质量指数，孩子，费用</li><li id="5b62" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">有3个分类变量:性别、吸烟者、地区<br/>我们可以对数据进行一些预处理，我们现在就来。<br/>此外，该数据集需要详细的EDA，我们将单独介绍。</li></ul><p id="7d72" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz">处理分类变量</strong> <br/>正如您在上面看到的，线性回归方程不能接受分类变量，它只期望数值变量。然而，我们可以通过编码将分类变量转换成数值变量。<br/>编码无非是为每一级分类变量定义0或1。<br/>让我们从数据集中选取一些例子:</p><ul class=""><li id="0d19" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated"><strong class="ig iz">性别有两个等级</strong>——M和F我们可以将其编码为二进制变量0代表男性，1代表女性</li><li id="da05" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">吸烟者又将有两个级别</strong> — Y或N，可转换成二进制变量</li><li id="c14e" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">区域有点复杂，我们将为每个区域部署0/1<br/>让我们更详细地了解一下。</li></ul><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="7dcf" class="hf hg hh ld b fi lh li l lj lk">insurance_cost['smoker'].unique() ##Giving two levels of unique points</span><span id="d476" class="hf hg hh ld b fi ll li l lj lk">array(['yes', 'no'], dtype=object)</span><span id="43b5" class="hf hg hh ld b fi ll li l lj lk">insurance_cost['sex'].unique() ##Giving two levels of unique points</span><span id="448b" class="hf hg hh ld b fi ll li l lj lk">array(['female', 'male'], dtype=object)</span><span id="f469" class="hf hg hh ld b fi ll li l lj lk">insurance_cost['region'].unique() ##Giving 4 levels of unique points</span><span id="e53d" class="hf hg hh ld b fi ll li l lj lk">array(['southwest', 'southeast', 'northwest', 'northeast'], dtype=object)</span><span id="3679" class="hf hg hh ld b fi ll li l lj lk">pd.get_dummies(insurance_cost['region'])</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/58feef9c472216db4eead6065c84dc9a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*X6ojEH44_NTYVAyr4RmYAQ.png"/></div></figure><p id="42ab" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">对于其他变量，有一个更容易(也更快)的方法。我们可以使用<code class="du ln lo lp ld b">np.where</code>功能。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="3b2c" class="hf hg hh ld b fi lh li l lj lk">import numpy as np<br/>insurance_cost['smoker']=np.where(insurance_cost['smoker']== 'yes',1,0)<br/>insurance_cost['sex'] = np.where(insurance_cost['sex']=='female',1,0)<br/>#Works very similar to the if-else condition in excel</span></pre><p id="b32a" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">让我们列出数据中的预测变量(X变量),以了解将影响我们结果的变量列表。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="c125" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised= pd.get_dummies(insurance_cost,columns = ['region'],drop_first = True)</span></pre><p id="51d2" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">这里我们使用<code class="du ln lo lp ld b">drop_first = True</code>,因为对于K个变量，我们想要创建K-1个虚拟变量。<br/>因此，本质上，我们从K = K-1 <br/>中减少分类变量的数量，因为对于模型，可以理解，如果这些变量中没有一个为真，则另一个值将为真。线性回归模型的一个基本要求是变量应该相互独立。</p><p id="d119" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">如果需要，我们也可以涵盖线性回归模型的证明。在此之前，让我们先提取特征(预测变量或x变量)。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="a5a9" class="hf hg hh ld b fi lh li l lj lk">Charges = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])</span></pre><p id="f693" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们已经创建了Y变量数据集，现在我们需要选择X变量数据集。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="a427" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised.columns<br/>X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']</span><span id="4cb2" class="hf hg hh ld b fi ll li l lj lk">##You might have to install statsmodels package using !pip install statsmodels<br/>import statsmodels.api as sm</span><span id="2382" class="hf hg hh ld b fi ll li l lj lk">Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])</span><span id="842a" class="hf hg hh ld b fi ll li l lj lk">type(Y_var)</span><span id="438e" class="hf hg hh ld b fi ll li l lj lk">pandas.core.frame.DataFrame</span><span id="e815" class="hf hg hh ld b fi ll li l lj lk">X_variables.head()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/c4998cbdc097aa77e807c3c5223daf76.png" data-original-src="https://miro.medium.com/v2/format:webp/1*GPCCA2HX_3q74IfmOA_44w.png"/></div></figure><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="8bc0" class="hf hg hh ld b fi lh li l lj lk">Y_var</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/b96f66e0d72f6927da6e5ffd4341bf83.png" data-original-src="https://miro.medium.com/v2/format:webp/1*E-1mp5zAvVunrWuZ42zPjg.png"/></div></figure><p id="8f13" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">现在让我们将数据分成测试和训练集，因为我们将从<code class="du ln lo lp ld b">sklearn.model_selection</code>库中导入<code class="du ln lo lp ld b">train_test_split</code>包。<br/> <code class="du ln lo lp ld b">sklearn</code>大概是机器学习最有名的包了。<br/>我们还增加了一个常数....<code class="du ln lo lp ld b">CHECK WHY DO YOU ADD CONSTANT</code></p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="302e" class="hf hg hh ld b fi lh li l lj lk">from sklearn.model_selection import train_test_split<br/>import statsmodels.api as sm<br/>X_variables = sm.add_constant(X_variables)</span><span id="7b1b" class="hf hg hh ld b fi ll li l lj lk">train_X, test_X, train_y, test_y = train_test_split(X_variables,Y_var,<br/>                                                   train_size = 0.80,<br/>                                                   random_state = 121)</span><span id="3561" class="hf hg hh ld b fi ll li l lj lk">model_1 = sm.OLS(train_y,train_X).fit()</span><span id="5879" class="hf hg hh ld b fi ll li l lj lk">model_1.summary2()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lq"><img src="../Images/c2fd70441201d0b7479814c18d42713d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpo2a5LylwWnCrNAzCatgg.png"/></div></div></figure><p id="1d10" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">模型验证的第一步 <br/>我们已经创建了第一个模型。现在，我们需要了解这些结果，让我们看看这些结果意味着什么，我们的第一步是什么。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lr"><img src="../Images/005a045ea76f40392e52e5fe5f6c101b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZAIV5eS48hbImXw7Cdp5Q.jpeg"/></div></div></figure><p id="5f42" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">这里我们主要关注中间的表(紫色的元素)。其余要素如下:</p><ul class=""><li id="b47d" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated"><strong class="ig iz">黄色&amp;蓝色元素</strong>:这些是对模型的描述</li><li id="959e" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">红色元素</strong>:最关键，用于模型的良好性。这个模型预测得有多好</li><li id="3964" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">黑色元素</strong>:用于测试模型遵循OLS(普通最小二乘法)统计假设的程度</li><li id="846e" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">紫色元素</strong>:用于决定模型使用的自变量</li></ul><p id="a82f" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz">选择最重要的特征</strong>:在选择模型的特征时，我们进行一个简单的假设检验:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ls"><img src="../Images/65ba37566f6a9ef2aa3ded57e210d186.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*4zXxoJyJRStp6OiMzkW-Ng.png"/></div></figure><p id="dfb3" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">如果你还记得假设检验的前提，当p值&lt; 0.05 then we reject the null hypothesis at a significance level of 5%. Now this means if any of the variable has P-Value &lt; 0.05 means as per above test its cooeficient is <strong class="ig iz">不等于</strong>零时，因此应该出现在我们的检验框架中。同样，如果任何变量的P值&gt;为0.05，我们可以得出结论，该变量的系数为零，因此可以排除。</p><p id="0014" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们选择具有最高P值的变量将其移除，然后查看对模型的影响，然后选择下一个最高P值的变量(在新模型中),继续这样做，直到所有变量都具有P值&lt; 0.05.</p><p id="36d9" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">This is called <strong class="ig iz">向后消除</strong></p><p id="13d9" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">这里我们看到与<code class="du ln lo lp ld b">region North-west</code>相关的P值是最高的，我们移除该变量并再次运行模型。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="caac" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'region_northwest']<br/>insurance_cost_revised.head()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/fea6b382bae54270f8a7e03a79e81827.png" data-original-src="https://miro.medium.com/v2/format:webp/1*fHGSsNbYRq3Mhe_1sS909w.png"/></div></figure><p id="b5b5" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">让我们经受这样的考验:</p><ul class=""><li id="3cac" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">X_Variables和Y_variables的分割(你可以通过在X和Y变量上运行下面的步骤来避免这一步，但是我故意不这样做，稍后会解释)</li><li id="6b15" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">添加常数项</li><li id="2714" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">在测试和训练中拆分数据</li><li id="14fd" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">运行OLS模型</li></ul><p id="8c94" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">又来了！！！</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="adc3" class="hf hg hh ld b fi lh li l lj lk">X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']<br/>Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])<br/>from sklearn.model_selection import train_test_split<br/>import statsmodels.api as sm<br/>X_variables = sm.add_constant(X_variables)<br/>print(Y_var.head())<br/>print(X_variables.head())</span><span id="bb88" class="hf hg hh ld b fi ll li l lj lk">charges<br/>0  16884.92400<br/>1   1725.55230<br/>2   4449.46200<br/>3  21984.47061<br/>4   3866.85520<br/>   const  age  sex     bmi  children  smoker  region_southeast  \<br/>0    1.0   19    1  27.900         0       1                 0   <br/>1    1.0   18    0  33.770         1       0                 1   <br/>2    1.0   28    0  33.000         3       0                 1   <br/>3    1.0   33    0  22.705         0       0                 0   <br/>4    1.0   32    0  28.880         0       0                 0   <br/><br/>   region_southwest  <br/>0                 1  <br/>1                 0  <br/>2                 0  <br/>3                 0  <br/>4                 0</span><span id="8efc" class="hf hg hh ld b fi ll li l lj lk">train_X, test_X, train_y, test_y = train_test_split(X_variables,Y_var,<br/>                                                   train_size = 0.80,<br/>                                                   random_state = 121)</span><span id="3fd7" class="hf hg hh ld b fi ll li l lj lk">model_2 = sm.OLS(train_y,train_X).fit()<br/>model_2.summary2()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lt"><img src="../Images/9496e2002e4971eb2c6479786366ca8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c55gdlpOF_Y6fYaxV38AaQ.png"/></div></div></figure><p id="6bb3" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">模型中的变化很小，现在让我们运行模型，去掉具有最高P值的<code class="du ln lo lp ld b">sex</code>变量。我们将一次完成整个事情，而不是代码的单独部分。记住我们的<code class="du ln lo lp ld b">insurance_cost_revised</code>已经没有<code class="du ln lo lp ld b">region_northwest</code>了，因为我们已经在第一步中删除了它。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="2f68" class="hf hg hh ld b fi lh li l lj lk">#Removing the sex variable<br/>insurance_cost_revised = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'sex']<br/>print(insurance_cost_revised.head())<br/><br/>#Splitting of X and Y variables<br/>X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']<br/>Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])<br/>from sklearn.model_selection import train_test_split<br/>import statsmodels.api as sm<br/>X_variables = sm.add_constant(X_variables)<br/>print(Y_var.head())<br/>print(X_variables.head())<br/><br/>#Splitting of test and train cases<br/>train_X, test_X, train_y, test_y = train_test_split(X_variables,Y_var,<br/>                                                   train_size = 0.80,<br/>                                                   random_state = 121)<br/>#Running the model<br/>model_3 = sm.OLS(train_y,train_X).fit()<br/>model_3.summary2()</span><span id="232d" class="hf hg hh ld b fi ll li l lj lk"><br/>OUTPUT<br/>age     bmi  children  smoker      charges  region_southeast  \<br/>0   19  27.900         0       1  16884.92400                 0   <br/>1   18  33.770         1       0   1725.55230                 1   <br/>2   28  33.000         3       0   4449.46200                 1   <br/>3   33  22.705         0       0  21984.47061                 0   <br/>4   32  28.880         0       0   3866.85520                 0   <br/><br/>   region_southwest  <br/>0                 1  <br/>1                 0  <br/>2                 0  <br/>3                 0  <br/>4                 0  <br/>       charges<br/>0  16884.92400<br/>1   1725.55230<br/>2   4449.46200<br/>3  21984.47061<br/>4   3866.85520<br/>   const  age     bmi  children  smoker  region_southeast  region_southwest<br/>0    1.0   19  27.900         0       1                 0                 1<br/>1    1.0   18  33.770         1       0                 1                 0<br/>2    1.0   28  33.000         3       0                 1                 0<br/>3    1.0   33  22.705         0       0                 0                 0<br/>4    1.0   32  28.880         0       0                 0                 0</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lu"><img src="../Images/9d32b8af3b3c1d966f9c42f90e20ddc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eH_2O6G6i192rHN2rB7u_A.png"/></div></div></figure><p id="c28a" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们看到<code class="du ln lo lp ld b">adjusted R-squared</code>从0.745到0.746有一个小的提高。让我们对P &gt;为0.05的最后一个变量(即<code class="du ln lo lp ld b">region_southwest</code>)重复上述步骤，并运行模型</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="7208" class="hf hg hh ld b fi lh li l lj lk">#Removing the region_southwest variable<br/>insurance_cost_revised = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'region_southwest']<br/>print(insurance_cost_revised.head())<br/><br/>#Splitting of X and Y variables<br/>X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']<br/>Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])<br/>from sklearn.model_selection import train_test_split<br/>import statsmodels.api as sm<br/>X_variables = sm.add_constant(X_variables)<br/>print(Y_var.head())<br/>print(X_variables.head())<br/><br/>#Splitting of test and train cases<br/>train_X, test_X, train_y, test_y = train_test_split(X_variables,Y_var,<br/>                                                   train_size = 0.80,<br/>                                                   random_state = 121)<br/>#Running the model<br/>model_4 = sm.OLS(train_y,train_X).fit()<br/>model_4.summary2()</span><span id="9ad2" class="hf hg hh ld b fi ll li l lj lk">OUTPUT<br/>age     bmi  children  smoker      charges  region_southeast<br/>0   19  27.900         0       1  16884.92400                 0<br/>1   18  33.770         1       0   1725.55230                 1<br/>2   28  33.000         3       0   4449.46200                 1<br/>3   33  22.705         0       0  21984.47061                 0<br/>4   32  28.880         0       0   3866.85520                 0<br/>       charges<br/>0  16884.92400<br/>1   1725.55230<br/>2   4449.46200<br/>3  21984.47061<br/>4   3866.85520<br/>   const  age     bmi  children  smoker  region_southeast<br/>0    1.0   19  27.900         0       1                 0<br/>1    1.0   18  33.770         1       0                 1<br/>2    1.0   28  33.000         3       0                 1<br/>3    1.0   33  22.705         0       0                 0<br/>4    1.0   32  28.880         0       0                 0</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lv"><img src="../Images/0d518eabe953ae657fb006e9bdc016d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQP7m0a8i4_x16R7wZcN7g.png"/></div></div></figure><p id="a433" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">现在我们看到一个有趣的问题，我们的<code class="du ln lo lp ld b">adjusted R-squared</code>已经消失了，我们又得到一个变量<code class="du ln lo lp ld b">region_southeast</code>作为P &gt;为0.05的变量。让我们再做一遍所有的步骤。移除变量后<code class="du ln lo lp ld b">region_southeast</code></p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="3b2a" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'region_southeast']<br/>print(insurance_cost_revised.head())<br/><br/><br/>X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']<br/>X_variables = sm.add_constant(X_variables)<br/>Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])<br/>print(Y_var.head())<br/>print(X_variables.head())<br/><br/>train_X,test_X,train_y,test_y = train_test_split(X_variables,<br/>                                                Y_var,<br/>                                                train_size = 0.80,<br/>                                                random_state = 121)<br/><br/>model_5 = sm.OLS(train_y,train_X).fit()<br/>model_5.summary2()</span><span id="7496" class="hf hg hh ld b fi ll li l lj lk">OUTPUT<br/>age     bmi  children  smoker      charges<br/>0   19  27.900         0       1  16884.92400<br/>1   18  33.770         1       0   1725.55230<br/>2   28  33.000         3       0   4449.46200<br/>3   33  22.705         0       0  21984.47061<br/>4   32  28.880         0       0   3866.85520<br/>       charges<br/>0  16884.92400<br/>1   1725.55230<br/>2   4449.46200<br/>3  21984.47061<br/>4   3866.85520<br/>   const  age     bmi  children  smoker<br/>0    1.0   19  27.900         0       1<br/>1    1.0   18  33.770         1       0<br/>2    1.0   28  33.000         3       0<br/>3    1.0   33  22.705         0       0<br/>4    1.0   32  28.880         0       0</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lw"><img src="../Images/6d0cdd3ca9f036d0097c3e64e763c0e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UyHN7AHRCEGkROeDw9sLdw.png"/></div></div></figure><p id="eeb6" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">现在，我们已经解决了与模型的P值相关的所有问题，并选择了最重要的特征:</p><ul class=""><li id="df99" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">年龄</li><li id="ed1a" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">身体质量指数</li><li id="12d7" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">儿童</li><li id="64b4" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">吸烟者</li></ul><h2 id="6403" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">从统计假设角度对模型的评价和改进</h2><p id="8d41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io hr ip iq ir hv is it iu hz iv iw ix iy ha bi translated">我们需要从OLS(普通最小二乘法)的数学假设的准确性的角度来评估我们的模型。我们将进行的一些检查包括:</p><ul class=""><li id="6665" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated"><strong class="ig iz">残差的正态分布</strong>(残差即预测值—实际值应呈正态分布)</li><li id="f13f" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">异常值分析</strong>(移除特定观察值后，因变量的变化程度)</li><li id="5920" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">自相关</strong>(自变量之间没有相关性)</li><li id="23d4" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><strong class="ig iz">同方差</strong>(指误差项的方差相同)</li></ul><p id="5923" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们将进行一些测试，并根据测试结果修改我们的模型。这将是我们模型微调的最后一步。</p><p id="841a" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz"> <em class="lx">残差的正态分布</em> </strong></p><p id="6d36" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">在OLS框架中，假设残差是正态分布的。这源于中心极限定理和假设检验理论。如果残差不是正态分布的，意味着样本是<strong class="ig iz">而不是</strong>随机的，因此我们不能使用假设检验框架来确定哪些变量是重要的，哪些是不重要的。<br/>然而，这种非正态性的假设不需要很强，残差变量的近似正态分布在现实世界中是有效的。</p><p id="174c" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">点击此处了解更多关于假设检验的信息:</p><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/@muditbits/2020-02-hypothesis-testing-a3a428d2b07c"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd iz fi z dy kr ea eb ks ed ef kt bi translated">2020 _ 02 _假设检验</h2><div class="kv l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kw l"><div class="ly l ky kz la kw lb kd km"/></div></div></a></div></div><div class="ab cl lz ma go mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ha hb hc hd he"><p id="4a26" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">为了检查正态性，我们绘制了残差与完美正态分布的PP图。如果残差位于完美正态图的线上，我们可以说我们的残差是正态的(或接近正态)。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="68f8" class="hf hg hh ld b fi lh li l lj lk">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>insurance_data_resid = model_5.resid<br/>probplot = sm.ProbPlot(insurance_data_resid)<br/>plt.figure(figsize = (8,6))<br/>probplot.ppplot(line = '45')<br/>plt.title('Normal PP Plot of Regression Standardized Residuals')<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/a54f1defd9bf7dfa18a39914a7b21c49.png" data-original-src="https://miro.medium.com/v2/format:webp/1*PQ3Sbf-EV6lm5T4hm7ASOQ.png"/></div></figure><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="e660" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised['charges'].hist()<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/df2cdd9490af7bbb6d2f5a84a609f774.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kxEfu0_9C1mclWKsWZFeNQ.png"/></div></figure><p id="7cbf" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们看到charges变量非常倾斜，因此我们可以将变量转换为log，然后再试一次。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="2c2c" class="hf hg hh ld b fi lh li l lj lk">Y_var = np.log(Y_var)<br/>Y_var.hist()<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/8de254a258a5ba3316b8dd52a3a01a68.png" data-original-src="https://miro.medium.com/v2/format:webp/1*DWPiO8Kwy9-l9Iju3FzzvQ.png"/></div></figure><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="72c5" class="hf hg hh ld b fi lh li l lj lk">train_X,test_X,train_y,test_y = train_test_split(X_variables,<br/>                                                Y_var,<br/>                                                train_size = 0.80,<br/>                                                random_state = 121)<br/><br/>model_6 = sm.OLS(train_y,train_X).fit()<br/>model_6.summary2()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mg"><img src="../Images/920581406d080a547aeec915c2db5979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOeZ0aLAkKOptIHekB5_eA.png"/></div></div></figure><p id="f8a3" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">这次试验不仅解决了非正常剩余的问题，还带来了以下好处:</p><ul class=""><li id="1088" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">降低了AIC和BIC的值，这意味着模型的预测能力有所提高</li><li id="ed01" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">将调整后的R平方从第一个模型中的0.745增加到0.758</li><li id="d820" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">降低了条件数的值，从而降低了共线性(尽管还有其他更好的测试)</li></ul><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="5f53" class="hf hg hh ld b fi lh li l lj lk">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>insurance_data_resid = model_6.resid<br/>probplot = sm.ProbPlot(insurance_data_resid)<br/>plt.figure(figsize = (8,6))<br/>probplot.ppplot(line = '45')<br/>plt.title('Normal PP Plot of Regression Standardized Residuals')<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/67122038fa03e002f7b0c3e6033ece7a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*EngiaROih8kLiYbLeWs0Dg.png"/></div></figure><p id="ee59" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们比原始模型好得多，残差几乎呈正态分布，调整后的R平方从0.745提高到0.758</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="ae0e" class="hf hg hh ld b fi lh li l lj lk">plt.figure(figsize = (10,7))<br/>sns.heatmap(insurance_cost_revised.corr(),annot = True)</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/df0ef6a69d413e251308e9cdc67f444c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*I0LdIaawLTRy6qMDP4OyDg.png"/></div></figure><p id="9655" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">上图显示了与费用和其他数值变量的相关性。正如我们的模型所预测的那样(最高的$\beta$值),吸烟与保险费的相关性最高。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="f0b0" class="hf hg hh ld b fi lh li l lj lk">pred = model_6.predict(test_X)<br/>from sklearn.metrics import r2_score<br/>print("R2 Score",r2_score(test_y,pred))</span><span id="c9a0" class="hf hg hh ld b fi ll li l lj lk">OUTPUT<br/>R2 Score 0.7735003467233176</span></pre><p id="b045" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz"> <em class="lx">同质性检验:</em> </strong></p><p id="615e" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">同方差度量剩余变量的分布，这意味着剩余变量的方差不会随着因变量的值的增加而增加很多。这可以通过检查拟合变量的残差图来完成，如果形状是一个倒漏斗，意味着方差增加(异方差)。<br/>同样的另一个测试是<strong class="ig iz">杜宾·沃森</strong>它应该在1 &amp; 2之间，我们可以在我们模型的汇总结果中看到同样的它的值是1.945。</p><p id="429d" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们可以通过改变自变量(取对数或标准化变量)来消除异方差性(与同方差性相反)。我们希望德宾沃森接近于零，不出现倒漏斗。</p><p id="e895" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">执行同质性测试的另一个测试是<code class="du ln lo lp ld b">white's</code>测试。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="00c7" class="hf hg hh ld b fi lh li l lj lk">def standardized(vals):<br/>    return((vals-vals.mean())/vals.std())<br/><br/>plt.scatter(standardized(model_6.fittedvalues),standardized(model_6.resid))<br/>plt.xlabel('Fitted Values')<br/>plt.ylabel('Residual')<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/c1f14a9d3db785a4ae5ed200bc544cfc.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6SPop7gvlSPqKCJqQwcPWw.png"/></div></figure><p id="f5aa" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们看到有一个明显的异质迹象。但是，如果我们需要进一步改进，我们可以采取以下方法:</p><ul class=""><li id="a2b9" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">变换X变量</li><li id="481e" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">转换Y变量(我们在获取日志时已经完成了)</li></ul><p id="0271" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">我们将使用怀特检验来证实我们的异方差假设。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="5384" class="hf hg hh ld b fi lh li l lj lk">from statsmodels.stats.diagnostic import het_white<br/>white_test = het_white(model_6.resid,model_6.model.exog)<br/>labels = ['Test Statistics','Test Statistics p-Value','F-Statistics','F-Test p-value']<br/>#print(dict(zip(labels,white_test)))<br/>print(pd.DataFrame(dict(zip(labels,white_test)).items(),columns = ['Test Label','Test Value']))</span><span id="2e7a" class="hf hg hh ld b fi ll li l lj lk"><br/>OUTPUT</span><span id="71a3" class="hf hg hh ld b fi ll li l lj lk">Test Label    Test Value<br/>0          Test Statistics  1.149814e+02<br/>1  Test Statistics p-Value  1.965648e-18<br/>2             F-Statistics  9.779939e+00<br/>3           F-Test p-value  1.485640e-19</span></pre><p id="06bc" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">在上面的测试中，两个P值都是&lt; 0.05 means that we have to reject null hypothesis of Homoscedasticity and therefore there is a presence of Hetroscedasticity. We can attempt to transfer the input variables and see if it causes any benefit.</p><p id="afd9" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">Meanwhile we will also plot our Prediction against the actual Y Values to see the distribution. Also, we can see the value of R-Square from the prediction is 0.773 which is close to the actual model means our model is doing a good work on the actual prediction as well.</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="5487" class="hf hg hh ld b fi lh li l lj lk">pred = model_6.predict(test_X)<br/>from sklearn.metrics import r2_score<br/>print("R2 Score",r2_score(test_y,pred))<br/>plt.scatter(test_y,pred)<br/>plt.xlabel('Y_Test')<br/>plt.ylabel('Y_Predicted')<br/>plt.show()</span><span id="3175" class="hf hg hh ld b fi ll li l lj lk">OUTPUT</span><span id="6910" class="hf hg hh ld b fi ll li l lj lk">R2 Score 0.7735003467233176</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/ea12f410da110253b48a42db17c15d8d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*BWPnxuEEBWN8WETZPnnO1w.png"/></div></figure><p id="6223" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">Attempt to remove Hetroscedasticity by altering independent variables</p><p id="20fc" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">We will try to change variables one-by-one and see if there is any impact in the hetroscadesticity.</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="f86a" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised[['bmi','age']].hist()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/aad521c5ea804da8ae47fde7de242677.png" data-original-src="https://miro.medium.com/v2/format:webp/1*20-tI528uFhUsnMoioFYPA.png"/></div></figure><p id="4272" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">Let us standardize age variable or all of the input variables. You can comment the relevant section to see the output.</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="11c9" class="hf hg hh ld b fi lh li l lj lk">X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']<br/>X_variables = sm.add_constant(X_variables)<br/>X_variables['bmi'] = np.log(X_variables['bmi'])<br/>X_variables['age'] = np.log(X_variables['age'])<br/>X_variables['children'] = standardized(X_variables['children'])<br/>X_variables['smoker'] = standardized(X_variables['smoker'])<br/><br/>Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])<br/>Y_var = np.log(Y_var)<br/>print(Y_var.head())<br/>print(X_variables.head())<br/><br/>train_X,test_X,train_y,test_y = train_test_split(X_variables,<br/>                                                Y_var,<br/>                                                train_size = 0.80,<br/>                                                random_state = 121)<br/><br/>model_7 = sm.OLS(train_y,train_X).fit()<br/>model_7.summary2()</span><span id="6c18" class="hf hg hh ld b fi ll li l lj lk">OUTPUT<br/>charges<br/>0  9.734176<br/>1  7.453302<br/>2  8.400538<br/>3  9.998092<br/>4  8.260197<br/>   const       age       bmi  children    smoker<br/>0    1.0  2.944439  3.328627 -0.908274  1.969850<br/>1    1.0  2.890372  3.519573 -0.078738 -0.507273<br/>2    1.0  3.332205  3.496508  1.580335 -0.507273<br/>3    1.0  3.496508  3.122585 -0.908274 -0.507273<br/>4    1.0  3.465736  3.363149 -0.908274 -0.507273</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mh"><img src="../Images/fdcefdc0aa14da7b448ee5d398767dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1C9B41__1C6R6ApSYblGxg.png"/></div></div></figure><p id="9db1" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">We have achieved the highest value of R-Squared yet let us do the test for Homoscadisticity and normality of residuals again. <br/>,虽然尚待评估同异方差，但我们已经获得了更高的R平方值，为0.761，这是一件好事。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="53f1" class="hf hg hh ld b fi lh li l lj lk">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>insurance_data_resid = model_7.resid<br/>probplot = sm.ProbPlot(insurance_data_resid)<br/>plt.figure(figsize = (8,6))<br/>probplot.ppplot(line = '45')<br/>plt.title('Normal PP Plot of Regression Standardized Residuals')<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/2e961fdb74c0a8b059b0a6e01ee47230.png" data-original-src="https://miro.medium.com/v2/format:webp/1*M1Nj8D1CApfHnAzEWRpB_g.png"/></div></figure><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="d9a8" class="hf hg hh ld b fi lh li l lj lk">plt.scatter(standardized(model_7.fittedvalues),standardized(model_7.resid))<br/>plt.xlabel('Fitted Values')<br/>plt.ylabel('Residual')<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/4aff3683bfb36e197414169fdc37604f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*GspbE5pPpAhBTQkIDqOchw.png"/></div></figure><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="6e74" class="hf hg hh ld b fi lh li l lj lk">from statsmodels.stats.diagnostic import het_white<br/>white_test = het_white(model_7.resid,model_7.model.exog)<br/>labels = ['Test Statistics','Test Statistics p-Value','F-Statistics','F-Test p-value']<br/>#print(dict(zip(labels,white_test)))<br/>print(pd.DataFrame(dict(zip(labels,white_test)).items(),columns = ['Test Label','Test Value']))</span><span id="0f19" class="hf hg hh ld b fi ll li l lj lk">OUTPUT</span><span id="8499" class="hf hg hh ld b fi ll li l lj lk">Test Label    Test Value<br/>0          Test Statistics  1.048361e+02<br/>1  Test Statistics p-Value  1.906163e-16<br/>2             F-Statistics  8.823286e+00<br/>3           F-Test p-value  2.391576e-17</span></pre><p id="8bd8" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">正如我们在上表中看到的，p值小于0.05，这意味着我们必须拒绝存在同质性的零假设。这意味着存在异方差性。所以我们无法从数据中去除异方差性。因此，我们将使用具有改进的R平方值的Model_7运行。</p><p id="aab7" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">让我们测试预测的Y值，以了解模型的准确性。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="6da9" class="hf hg hh ld b fi lh li l lj lk">pred = model_7.predict(test_X)<br/>from sklearn.metrics import r2_score<br/>print("R2 Score",r2_score(test_y,pred))<br/>plt.scatter(test_y,pred)<br/>plt.xlabel('Y_Test')<br/>plt.ylabel('Y_Predicted')<br/>plt.show()</span><span id="4f33" class="hf hg hh ld b fi ll li l lj lk">OUTPUT<br/>R2 Score 0.7682519851617251</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/ad1b87e66aad99c069c7548fd129e8e1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*js4hfNXXxcWPo5SkXQHMDA.png"/></div></figure><p id="bd0c" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">这降低了预测值的R-Square值，因此我们可以继续使用<strong class="ig iz">模型_6作为最终模型</strong>。我们将运行修改后的模型，以便训练和测试变量采用正确的形式。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="4966" class="hf hg hh ld b fi lh li l lj lk">insurance_cost_revised = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'region_southeast']<br/>print(insurance_cost_revised.head())<br/><br/><br/>X_variables = insurance_cost_revised.loc[:,insurance_cost_revised.columns != 'charges']<br/>X_variables = sm.add_constant(X_variables)<br/>Y_var = pd.DataFrame(insurance_cost_revised['charges'],columns = ['charges'])<br/>print(Y_var.head())<br/>print(X_variables.head())<br/>train_X,test_X,train_y,test_y = train_test_split(X_variables,<br/>                                                Y_var,<br/>                                                train_size = 0.80,<br/>                                                random_state = 121)<br/><br/>model_6 = sm.OLS(train_y,train_X).fit()<br/>model_6.summary2()</span><span id="c855" class="hf hg hh ld b fi ll li l lj lk">age     bmi  children  smoker      charges<br/>0   19  27.900         0       1  16884.92400<br/>1   18  33.770         1       0   1725.55230<br/>2   28  33.000         3       0   4449.46200<br/>3   33  22.705         0       0  21984.47061<br/>4   32  28.880         0       0   3866.85520<br/>       charges<br/>0  16884.92400<br/>1   1725.55230<br/>2   4449.46200<br/>3  21984.47061<br/>4   3866.85520<br/>   const  age     bmi  children  smoker<br/>0    1.0   19  27.900         0       1<br/>1    1.0   18  33.770         1       0<br/>2    1.0   28  33.000         3       0<br/>3    1.0   33  22.705         0       0<br/>4    1.0   32  28.880         0       0</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mi"><img src="../Images/b34da0d6d35ec9d28eb67db5eba9add2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sij11agYqS71EFsBCKuGLQ.png"/></div></div></figure><p id="885d" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><strong class="ig iz"> <em class="lx">多重共线性测试</em> </strong></p><p id="ff85" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">要测试多重共线性，我们可以检查VIF来检查多重共线性VIF值&gt; 4表示多重共线性。<br/>此外，上述模型6中的条件数显示，多重共线性已从条件数= 316降低。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="f61c" class="hf hg hh ld b fi lh li l lj lk">from statsmodels.stats.outliers_influence import variance_inflation_factor<br/>def get_vif_factors(X):<br/>    X_matrix = np.matrix(X_variables)<br/>    vif = [variance_inflation_factor(X_matrix,i) for i in range(X_matrix.shape[1])]<br/>    vif_factors = pd.DataFrame()<br/>    vif_factors['column'] = X_variables.columns<br/>    vif_factors['VIF'] = vif<br/>    return vif_factors</span><span id="1a44" class="hf hg hh ld b fi ll li l lj lk">vif_factors  = get_vif_factors(X_variables)<br/>vif_factors</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/a7483a70936c9dff9e79ddc7767daf33.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CjhxDfBi_hhNN9EAHuzEwA.png"/></div></figure><p id="33a1" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">任何关键行项目的标识</p><p id="7374" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">如果有任何高度有影响力的观察，我们的模型可能会被数据点扭曲。我们通过以下方式进行检查:</p><ul class=""><li id="87b4" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">杠杆图</li><li id="4bcb" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">厨师距离</li></ul><p id="18b9" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">杠杆图上非常大的圆圈意味着非常有影响力的数据点(我们可能必须删除它们)。类似地，库克距离&gt; 1意味着存在有影响的数据点。我们在以下几个部分进行这两项测试。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="7107" class="hf hg hh ld b fi lh li l lj lk">from statsmodels.graphics.regressionplots import influence_plot<br/>fig,ax = plt.subplots(figsize = (10,10))<br/>influence_plot(model_7,ax = ax)<br/>plt.title("Figure - Leverage Values vs Residual")<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/d5f949893fd90ec07a389114c475350c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kmSyIata23gsfpi7HYE_NA.png"/></div></figure><p id="ec93" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">计算厨师的距离</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="1afc" class="hf hg hh ld b fi lh li l lj lk">insurance_influence = model_7.get_influence()<br/>(c,p) = insurance_influence.cooks_distance<br/>plt.stem(np.arange(len(train_X)),<br/>        np.round(c,3),<br/>        markerfmt = ',')<br/>plt.title('Cooks Distance for Insurance Data')<br/>plt.xlabel('Row Index')<br/>plt.ylabel('Cooks Distance')<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/96852dad35bba5e9f567294ad410a547.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ID6hq6o1aIuftKC7QDgIjQ.png"/></div></figure><h2 id="4eaa" class="hf hg hh bd hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id bi translated">总结</h2><p id="1b6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io hr ip iq ir hv is it iu hz iv iw ix iy ha bi translated">总而言之，我们遵循以下步骤来创建线性回归模型:</p><ul class=""><li id="210f" class="jf jg hh ig b ih ja il jb hr jh hv ji hz jj iy jk jl jm jn bi translated">下载数据</li><li id="441f" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">对数据执行EDA(本笔记本中未涉及)</li><li id="584a" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">准备数据</li><li id="f50f" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">将分类变量转换为虚拟变量(每个分类变量中K个类别级别的K-1)</li><li id="94bc" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">运行模型，并尝试使用反向消除法移除不重要的变量</li><li id="c83c" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated">测试模型基于测试变量和训练变量的模型的R平方</li><li id="509c" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><em class="lx">统计模型假设检验</em></li><li id="079f" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><em class="lx">残差分布</em></li><li id="3b92" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><em class="lx">同方差</em></li><li id="60ae" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><em class="lx">多重共线性</em></li><li id="4629" class="jf jg hh ig b ih jo il jp hr jq hv jr hz js iy jk jl jm jn bi translated"><em class="lx">识别和消除关键观察值</em></li></ul><p id="4048" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">虽然创建模型是第一步，但通过测试假设得出正确的模型是非常关键的。</p><p id="3ec6" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated">这是我在这个平台上发表的第二篇文章，希望得到你的诚实反馈。</p><p id="acb5" class="pw-post-body-paragraph ie if hh ig b ih ja ij ik il jb in io hr jc iq ir hv jd it iu hz je iw ix iy ha bi translated"><em class="lx">希望这有所帮助。如果以上步骤/观察结果有任何错误，请通过评论告诉我。图像来自python数据，其余图像由手工创建。</em></p><div class="kj kk ez fb kl km"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd iz fi z dy kr ea eb ks ed ef kt bi translated">Mlearning.ai提交建议</h2><div class="ku l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="kv l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">medium.com</p></div></div><div class="kw l"><div class="mj l ky kz la kw lb kd km"/></div></div></a></div></div></div>    
</body>
</html>
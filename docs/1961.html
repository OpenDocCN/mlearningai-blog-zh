<html>
<head>
<title>Chronological language model logic</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时序语言模型逻辑</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/chronological-language-model-logic-bd590d49911f?source=collection_archive---------10-----------------------#2022-02-15">https://medium.com/mlearning-ai/chronological-language-model-logic-bd590d49911f?source=collection_archive---------10-----------------------#2022-02-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="36a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一组研究人员最近发表了<a class="ae jc" href="https://arxiv.org/abs/2202.03829" rel="noopener ugc nofollow" target="_blank"> TimeLMs </a>，这是一篇论文和一系列对2020年和2021年每个季度的推文进行训练的模型。这篇论文很有说服力，用一个漂亮的渐变表格说明了语言模型在训练后是如何老化的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/2ef899294649c0824c675df5bd2374e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzAO-lXvR9sF4kzKn6prxw.png"/></div></div></figure><p id="6fbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">“最新的语言模型”是我<a class="ae jc" rel="noopener" href="/swlh/patching-pre-trained-language-models-28ed6ea8b0bc?source=user_profile---------52-------------------------------">在2020年</a>写的一个话题，有类似的covid时代的例子，但在2021年未能进入BigScience，尽管我的想法是模糊地“修补”模型。这篇论文是这个领域最好的论文之一(也值得注意:<a class="ae jc" href="https://arxiv.org/abs/2102.01951" rel="noopener ugc nofollow" target="_blank">注意差距:评估神经语言模型中的时间概括</a>和<a class="ae jc" href="https://arxiv.org/abs/2111.12790" rel="noopener ugc nofollow" target="_blank">时间对语言处理任务的预训练模型的影响</a>)。</p><h1 id="7712" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">TimeLMs是如何持续改进的？</h1><p id="7161" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">TimeLMs的概念是捕捉随时间演变的语言(本文中显示的一个非covid示例是‘Squid Game’取代了其他的‘Game’短语)。这是最新的(12/2021) TimeLM模型在最近的推文中胜过03/2020模型的原因吗？</p><p id="364c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者表明，最新模型在03/2020验证集<em class="ks">上的表现也略好于在其他03/2020推文中训练的模型</em>。作者将此归因于:“<strong class="ig hi">更新的模型也在更多时间段内根据更多数据进行训练</strong>”。实验设计中的这一怪癖使得证明时间变化变得困难。</p><p id="e02d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我分叉了TimeLM代码<a class="ae jc" href="https://github.com/mapmeld/timelms" rel="noopener ugc nofollow" target="_blank">以使用非学术Twitter API </a>，下载了一小组02/2022的推文，并针对每个时间顺序模型进行了测试。仅仅从这个小样本中，我很高兴地测量出每一个更接近现在的模型在伪困惑(PPPL)方面的改进。<br/>接下来，我针对AOC回复的数据集运行了每个TimeLM模型，这些数据集是我在2019年 春季<strong class="ig hi"> <em class="ks">从Twitter上收集的。我仍然看到每个新型号的改进——大约一半的效果，但它确实存在。</em></strong></p><p id="6a14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除了论文中提到的改变语言和训练数据集的因素，我还担心推特会衰落T2。当研究人员使用API下载“旧”推文时，他们只获得了今天可见的推文。季度基准测试与这个问题无关，因为训练集和验证集同样会衰减。但如果这一理论是正确的，那么旧的和新的推文流对于“旧的”TimeLM模型来说都将非常困难，如果我们对它们进行过滤的话，就像2019年或当今的例子一样。</p><h1 id="062e" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">如果你能看到我:消失的推文</h1><p id="0076" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">我决定测量隐藏的推文(删除、暂停、私有化等)与平均值相比，在时间上是否有更大的变化。幸运的是，AOC回复数据集有大量有毒的、隐藏的推文和账户。</p><p id="e3be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我使用一个脚本将110万条推文分成95条一批，并发送到Twitter <code class="du kt ku kv kw b">/statuses/lookup.json</code>端点。当API响应缺少id时，我们可以将它们放在“隐藏”类别中。大约<strong class="ig hi"> 40% </strong>的推文已经无法访问，这是如此重要的一部分，以至于我担心它无法与原文区分开来。Twitter对我进行了速率限制，在TimeLM重复数据删除和其他预处理之后，我留下了大约10k隐藏的和大约16k可见的推文。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/6e254bc08a4274f012b911ac39040df8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rtg2084h3mbRLNUgi3YQ1g.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx">the AOC datasets have a higher PPPL and less steep drop; since-deleted Tweets track the norm</figcaption></figure><ul class=""><li id="f226" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">隐藏的推文从略高于完整数据集的PPPL开始。<strong class="ig hi">预测质量从可见到隐藏的变化类似于使用2-3个季度前的模型</strong>。</li><li id="5372" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">隐藏的推文不太容易预测，但<strong class="ig hi">这种差距是一致的</strong>并且最新的(12/2021)模型没有显示出任何优势。</li><li id="2579" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">删除的或有害的推文可能在训练中代表性不足，并且被TimeLM模型预测不足，但是<strong class="ig hi">不会</strong>以某种方式删除导致这些模型中的时间变化。</li><li id="3575" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">我没有做太多的调查，但如果我们使用AOC数据集作为基线，有证据表明，最近季度模型的改进只有1/3到1/2来自于额外数据或时间的培训。</li></ul><div class="lq lr ez fb ls lt"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lu ab dw"><div class="lv ab lw cl cj lx"><h2 class="bd hi fi z dy ly ea eb lz ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ma l"><h3 class="bd b fi z dy ly ea eb lz ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="mb l"><p class="bd b fp z dy ly ea eb lz ed ef dx translated">medium.com</p></div></div><div class="mc l"><div class="md l me mf mg mc mh jn lt"/></div></div></a></div><p id="9be7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">🔵<a class="ae jc" rel="noopener" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"> <strong class="ig hi">成为作家</strong> </a></p></div></div>    
</body>
</html>
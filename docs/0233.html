<html>
<head>
<title>LDA(latent Dirichlet association) for non-statisticians.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非统计人员潜在狄利克雷协会。</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/lda-latent-dirichlet-association-for-non-statisticians-b72cb1bed181?source=collection_archive---------6-----------------------#2021-03-07">https://medium.com/mlearning-ai/lda-latent-dirichlet-association-for-non-statisticians-b72cb1bed181?source=collection_archive---------6-----------------------#2021-03-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1b5f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一开始就很难理解。我找到了一个很好的研究来源，在这里我重新翻译成一个更简单的故事版本。</p><p id="6d63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">只有当你从LDA文章的数学中迷失之后，你才能更好地理解我的文章。我将有目的地不使用任何单一的公式。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="8b2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，暂时忘记下面的图形描述。只有在你了解了LDA的全部情况后，才能阅读图表。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es jj"><img src="../Images/899aa6f3d7c9e44b3e462c78e8f1c481.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/0*SDv9mu4qITil65Fy.png"/></div></figure><p id="b3cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，让我们来看看这个故事。</p><ol class=""><li id="5f5d" class="jm jn hh ig b ih ii il im ip jo it jp ix jq jb jr js jt ju bi translated">LDA是模型方法。与深度学习不同，这里我们有模型。<strong class="ig hi">一个统计模型。</strong></li><li id="e6b7" class="jm jn hh ig b ih jv il jw ip jx it jy ix jz jb jr js jt ju bi translated">这个模型是一种在假想世界中生成(或创建)文档的引擎。(这不是真实的文件，但我们的真实文件类似于这些假设的文件)</li><li id="723c" class="jm jn hh ig b ih jv il jw ip jx it jy ix jz jb jr js jt ju bi translated">就像其他统计模型一样。我们在这里也假设一个分布。这不是正态分布。<strong class="ig hi"> <em class="ka">确切地说，这里我们需要知道狄利克雷分布</em> </strong>(我们不需要知道数学背景)。</li><li id="0713" class="jm jn hh ig b ih jv il jw ip jx it jy ix jz jb jr js jt ju bi translated">狄利克雷分布本身是另一个分布的样本。所以无论何时你从狄利克雷分布中抽取样本，你都会得到一个分布。这个分布是多项式分布。多项式分布只是二项式分布的一个多版本。(即骰子采样)</li><li id="348a" class="jm jn hh ig b ih jv il jw ip jx it jy ix jz jb jr js jt ju bi translated">现在，让我们回到我们的模型。我们的模型(或引擎)生成包含许多单词的文档。每个文档都与某个主题(或多个主题)相关联。通过多项式分布，我们只知道文档与哪些主题相关联。</li><li id="da1d" class="jm jn hh ig b ih jv il jw ip jx it jy ix jz jb jr js jt ju bi translated">这个多项式分布是狄利克雷分布的一个例子。</li></ol><blockquote class="kb kc kd"><p id="802f" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">我想现在我们需要休息一下。让我们来看看。每个文档都与具有概率分布(概率质量函数)的特定主题相关联。因为我们观察的是文档中的一个单词词汇表，所以我们只能为每个单词关联主题。因此，我们对文档中的每个单词都进行这一过程。这就是为什么我们需要一个使用狄利克雷分布的抽样过程。我们从狄利克雷分布中抽取多项式分布样本以获得另一个样本(单词),直到我们到达文档的末尾。</p></blockquote><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es kh"><img src="../Images/c05e103dff30fd7efa353f5be339681b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9aXiGYKKEEaSCCuLdQv1hQ.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx">Screenshot from the link above</figcaption></figure><p id="b596" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">7.我们从给定主题为单词的每个位置创建或生成单词的方式是完全相同的。我们需要这个词的另一个多项式分布样本。我们再次从狄利克雷分布得到这个分布。暂时忘记alpha和gamma参数。请记住，我们需要主题和单词的两个样本分布，因为LDA是一个两步过程。</p><p id="e203" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">8.最后，从生成单词的过程中使用两个步骤来创建假设文档。只有当我们有一个好的模型时，这个文档才有意义(<strong class="ig hi">虽然这个假设的文档不是制造人类可读的句子，但是文档里面的单词让人们猜测主题是什么</strong></p><p id="d698" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">9.现在！我们将推断狄利克雷分布的每个参数(α，γ),使得这个狄利克雷分布为主题和单词采样出一个体面的多项式分布，其类似于我们的真实单词文档(语料库)</p><p id="4497" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个推论涉及到MCMC或VEM过程(参考视频链接)</p><p id="5e26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">10.最后，我们现在可以使用我们的模型计算给定文档中带有该单词(真实单词句子)的主题的概率。(我们的模型由两个狄利克雷分布组成。)</p><p id="483a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">—如果你不熟悉贝叶斯推断，这部分就有点棘手了。记住，我们需要计算给定文档中所有单词的主题比例的概率。</p><p id="fcd4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Tada！</p><p id="2361" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以回到图(随处可见的图形模型)，现在试着读一下。</p></div></div>    
</body>
</html>
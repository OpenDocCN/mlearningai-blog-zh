<html>
<head>
<title>Ensemble Learning: Bagging, boosting and stacking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成学习:打包、提升和堆叠</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/ensemble-learning-bagging-boosting-and-stacking-fad5cc8d7c2c?source=collection_archive---------4-----------------------#2022-06-14">https://medium.com/mlearning-ai/ensemble-learning-bagging-boosting-and-stacking-fad5cc8d7c2c?source=collection_archive---------4-----------------------#2022-06-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/b7fe7762792989c58a4934306e000865.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*405RSWmJxVaiwoQC"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@wylly_suhendra?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Wylly Suhendra</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="iu iv iw"><p id="b45a" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">”<strong class="ja hi"> <em class="hh">光靠我们能做的就这么少；我们一起可以做很多事情。</em></strong>”—海伦·凯勒</p></blockquote><p id="64b2" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">在机器学习中，在处理任何算法时，偏差和方差的权衡是每个从业者关注的关键问题之一。为了解决这个问题，他们可以利用一些基于<strong class="ja hi"> <em class="iz">集成学习</em> </strong>的技术。它基于“群体的智慧”理论，该理论假设一个多样化的独立个体群体的集体意见比一个专家的意见更好。</p><p id="27f3" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">什么是合奏技法？</strong></p><blockquote class="iu iv iw"><p id="9ea4" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">集成技术是使用多个学习算法或模型来产生一个最佳预测模型以获得更好预测性能的方法。</p></blockquote><p id="8e93" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">集成学习是一种机器学习技术，其中几个模型被组合起来以建立更强大的模型。集成主要用于提高模型的性能。这些技术是当今使用的一些最有用的机器学习技术，因为它们以相对较低的成本展示了很高的性能水平。</p><p id="3b09" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">合奏技法有哪些类型？</strong></p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es jz"><img src="../Images/c5ec86f2fd9b2962a9cd25e5bc2a63c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*MsgHjIyqkQzvFdGSpTUXxg.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 1. Types of Ensemble Techniques |Image by author</figcaption></figure><p id="4faf" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">什么是套袋技术？</strong></p><p id="79c6" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">Bagging是一种方法，其中多个同质机器学习模型(例如，所有决策树)的结果被组合以获得一般化的结果。</p><p id="e9f5" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">但是，当我们试图在同一组数据上创建所有模型，然后将它们组合在一起时，会发生什么呢？会有用吗？这些模型很有可能给出相同的结果，因为它们得到了相同的输入。接下来是<strong class="ja hi"> Bootstrapping技术</strong>，这是一种随机采样技术，我们通过替换来创建原始数据集的子集。在统计学中，带替换的随机抽样称为bootstrapping。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ke"><img src="../Images/06b6816930b0c31b44ee6216a1d50d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZ8GiRJCoLwx6gYP7yZ6Mw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 2. Example of Bootstrapping |Image by author</figcaption></figure><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kf"><img src="../Images/552b30c30746cc93fbcfc5472153ca29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hfTtItzNtMYMrBWSpnhJiA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 3. Bagging Technique |Image by author</figcaption></figure><p id="c87f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">在这些子集的每一个上创建一个基础模型(弱模型)。这些模型将并行运行，并且相互独立。通过组合来自所有模型的预测来构建元分类器或回归量，从而做出最终预测。在回归的情况下，它采用所有模型的平均值，对于分类问题，它采用投票方法。</p><p id="ea17" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">什么是助推？</strong></p><p id="b23c" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">在bagging中，我们假设所有的基础模型都会给出正确的结果或预测。当一个基础模型错误地预测了一个数据点，然后是下一个(可能是所有的)，会发生什么？将基础模型的所有预测结合起来有用吗？好吧，在这种情况下，助推来拯救我们。</p><blockquote class="iu iv iw"><p id="79ba" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">Boosting是一种顺序技术，其中每个后续模型都通过关注前一个模型所犯的错误来尝试提高模型的稳定性。后续模型依赖于前一个模型。</p></blockquote><p id="da80" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">术语“增强”指的是将多个弱学习者结合起来形成强学习者的一系列算法。</p><p id="98ce" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">让我们考虑垃圾邮件识别的例子。这里，为了识别邮件是否是垃圾邮件，通常使用以下标准:</p><p id="4bc2" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">我</strong>。如果邮件包含受感染的附件或可疑链接，那么它就是垃圾邮件。</p><p id="27cb" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi"> ii </strong>。如果邮件只有一张图片(促销)，那就是垃圾邮件。</p><p id="3575" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">三世</strong>。如果它包含像“你赢得了xxxxx的奖金”这样的句子，它就是垃圾邮件</p><p id="d09f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">四</strong>。如果它的来源已知，那么它就不是垃圾邮件。</p><p id="1873" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi"> v </strong>。来自已知来源的邮件，不是垃圾邮件。</p><p id="d68e" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">为了将电子邮件分类为垃圾邮件或非垃圾邮件，我们定义了上述规则。单独来看，这些规则不足以将一封电子邮件划分为“垃圾邮件”或“非垃圾邮件”。因此，这些规则被称为弱学习者。为了将弱学习者转化为强学习者，我们将使用以下方法结合每个弱学习者的预测:</p><p id="387c" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">a.使用平均值/加权平均值</p><p id="ec55" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">b.考虑预测有较高的票数。</p><p id="7e57" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">例如，我们定义了五个弱学习者。在这五种垃圾邮件中，3种被认为是垃圾邮件，2种被认为不是垃圾邮件。在这种情况下，我们会将该邮件归类为垃圾邮件，因为我们对垃圾邮件的投票率较高。</p><p id="1e01" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">升压是一种迭代和连续的方法。它在每次迭代后自适应地改变训练数据的分布。</p><p id="2ba3" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">升压步骤:</strong></p><ol class=""><li id="c1c8" class="kg kh hh ja b jb jc jf jg jw ki jx kj jy kk jv kl km kn ko bi translated">从原始数据集创建一个子集。</li><li id="7ca1" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated">最初，所有的数据点被赋予相等的权重，即所有的数据点被认为对于随机采样是同样可能的。</li><li id="6e11" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated">在随机采样的子集上训练基本模型。</li><li id="45b6" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated">使用实际值和预测值计算误差。</li></ol><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es ku"><img src="../Images/bcd802aec32c99836450c23331923d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*iLqAEFx5Jq7dX8tFhfAdlA.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 4. Example of classification in Boosting |Image by author</figcaption></figure><p id="2425" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">5.被错误预测的观察值被给予较高的权重。(这里，三个错误分类的红星点将被赋予更高的权重)。由于这些观察值的权重较高，因此将在下一次模型训练的下一次数据采样中首先选取这些观察值，然后根据需要随机选取其余的观察值。</p><p id="91c5" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">6.将创建另一个模型，并对数据集进行预测。(这个模型试图纠正前一个模型的错误)。</p><p id="85b4" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">7.类似地，将使用更新的权重创建多个模型，每个模型都校正前一个模型的误差。</p><p id="3709" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">8.当弱学习者的所有训练过程都完成后，就组合在一起形成了强学习者。最终模型(强学习者)是所有模型(弱学习者)的加权平均值。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kv"><img src="../Images/9968d4faf619f4770db64c9c6117a0a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tm6O44oc_x8QlAZJz1Ewpw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 5. Boosting Technique |Image by author</figcaption></figure><p id="2f4f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">什么是堆叠手法？</strong></p><p id="57bb" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">堆叠是一种集成学习技术，它使用来自多个模型(例如决策树、KNN或SVM)的预测来构建新模型。该模型用于对测试集进行预测。</p><p id="cdb7" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">简单堆叠集成学习技术的步骤如下:</p><ol class=""><li id="9609" class="kg kh hh ja b jb jc jf jg jw ki jx kj jy kk jv kl km kn ko bi translated">列车组分为10个部分。</li></ol><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es kw"><img src="../Images/406bbd6217a67510212b25e35438f2c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*ubgv5OOlBrUZWds2fhR19A.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 6. Image by author</figcaption></figure><p id="87ae" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">2.基础模型(假设决策树)适用于9个部分，并对第10个部分进行预测。对列车组的每个部分都要这样做。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/013295c77233a0217e91869c7fa103a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*vIJQ6dNNocDhUiKGoKrWfA.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 7. Image by author</figcaption></figure><p id="66a8" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">3.基础模型(在这种情况下，决策树)然后适合整个训练数据集。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/8ba469601062167a9909b605059febad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*htTmpUfW1LLTOrVjxPFLiw.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 8. Image by author</figcaption></figure><p id="b71e" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">4.对另一个基本模型(比如说KNN)重复步骤2到4，从而得到训练集和测试集的另一组预测。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ky"><img src="../Images/6a57f8845672a33d3278705a63c44646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhUEB5FY5a9ghkOUrk-GWA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 9. Image by author</figcaption></figure><p id="f118" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">5.来自训练集的预测被用作建立新模型的特征。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es kz"><img src="../Images/075150bbda99cb92db1a7a9c32f782ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*uUv_4uMaPqe94O7p2DROuQ.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Fig 10. Image by author</figcaption></figure><p id="26c0" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">6.该模型用于对测试预测集进行最终预测。</p><p id="68c0" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi">装袋和增压的区别:</strong></p><ul class=""><li id="bf69" class="kg kh hh ja b jb jc jf jg jw ki jx kj jy kk jv la km kn ko bi translated">Bagging的目的是减少差异，而不是偏见。但是，增强试图减少偏差，而不是方差。</li><li id="7f1c" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv la km kn ko bi translated">Bagging试图解决过拟合问题。就其本身而言，增压无助于避免过度拟合；其实这个技术本身就面临这个问题。</li><li id="d62a" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv la km kn ko bi translated">在装袋的情况下，每个模型都是独立构建的。但是在boosting的情况下，每个新模型都会受到先前构建的模型的性能的影响。</li><li id="2e26" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv la km kn ko bi translated">在bagging中，不同的训练数据子集被随机抽取，替换来自整个训练数据集。但是，在boosting的情况下，每个新的子集都包含被之前的模型错误分类的元素。</li><li id="221a" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv la km kn ko bi translated">如果分类器不稳定(高方差)，那么我们应该应用bagging。然而，如果分类器稳定且简单(高偏差)，我们应该使用boosting。</li></ul><p id="8c4c" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated"><strong class="ja hi"> <em class="iz">今天就到这里。希望你喜欢这篇文章。快乐阅读！！！</em> </strong></p><div class="lb lc ez fb ld le"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd hi fi z dy lj ea eb lk ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">medium.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls in le"/></div></div></a></div></div></div>    
</body>
</html>
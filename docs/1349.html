<html>
<head>
<title>OSS &amp; NCR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OSS &amp; NCR</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/oss-ncr-c16f69627715?source=collection_archive---------0-----------------------#2021-11-28">https://medium.com/mlearning-ai/oss-ncr-c16f69627715?source=collection_archive---------0-----------------------#2021-11-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="29ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">针对不平衡数据集的另一个有趣的欠采样技术</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/ce2eeb00f9297af9d49dcc2b3d4bbe65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bLU7Wq5ACUieRNm3AJocCw.jpeg"/></div></div></figure><p id="d6cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">大家好，我们又像承诺的那样，讨论了一个来自数据科学领域的有趣话题。</p><p id="3708" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">今天，我们将研究针对欠采样不平衡数据集的保留和删除方法的组合。</p><p id="c5fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单侧选择(OSS)是另一种欠采样技术，结合了Tomek链接和压缩(CNN)规则。</p><p id="f92e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">托梅克链接</strong>是在多数类中被移除的类边界上的模糊点，并且<strong class="ig hi"> CNN </strong>方法被用于从远离决策边界的多数类中移除冗余的例子。</p><p id="643b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该方法首先由Miroslav Kubat和Stan Matwin在1997年发表的题为“<a class="ae jo" href="https://sci2s.ugr.es/keel/pdf/algorithm/congreso/kubat97addressing.pdf" rel="noopener ugc nofollow" target="_blank">解决不平衡训练集的诅咒:单边选择</a>”的论文中提出</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="2ebb" class="ju jv hh jq b fi jw jx l jy jz">#One-Sided Selection<br/>from collections import Counter<br/>from sklearn.datasets import make_classification<br/>from imblearn.under_sampling import OneSidedSelection<br/>from matplotlib import pyplot<br/>from numpy import where</span><span id="c935" class="ju jv hh jq b fi ka jx l jy jz">#define dataset<br/>X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)</span><span id="b63a" class="ju jv hh jq b fi ka jx l jy jz">#summarize class distribution<br/>counter = Counter(y)<br/>print(counter)</span><span id="5bb6" class="ju jv hh jq b fi ka jx l jy jz">#define the undersampling method<br/>undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)</span><span id="919e" class="ju jv hh jq b fi ka jx l jy jz">#transform the dataset<br/>X, y = undersample.fit_resample(X, y)</span><span id="68d1" class="ju jv hh jq b fi ka jx l jy jz">#summarize the new class distribution<br/>counter = Counter(y)<br/>print(counter)</span><span id="7ebc" class="ju jv hh jq b fi ka jx l jy jz">#plot<br/>for label, _ in counter.items():<br/>row_ix = where(y == label)[0]</span><span id="4e36" class="ju jv hh jq b fi ka jx l jy jz">pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))<br/>pyplot.legend()<br/>pyplot.show()</span></pre><p id="f569" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样！</p><p id="4ee3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们来看看什么是NCR</p><p id="ee84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> NCR代表邻域清理</strong>规则一种欠采样技术，结合了CNN来去除冗余数据和ENN来去除噪声或模糊数据。</p><p id="783e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里的重点不是改善类分布的平衡，而是保留在多数类中的数据的质量(明确性)。</p><p id="081c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法包括首先从少数群体中选择所有的例子。然后，使用ENN规则识别并移除多数类中的所有模糊数据。最后，使用CNN的一步版本，其中多数类中那些相对于存储错误分类的剩余数据被移除，但是仅当多数类中的数据数量大于少数类大小的一半时。</p><pre class="jd je jf jg fd jp jq jr js aw jt bi"><span id="df3a" class="ju jv hh jq b fi jw jx l jy jz">#neighborhood cleaning rule</span><span id="38a0" class="ju jv hh jq b fi ka jx l jy jz">from collections import Counter<br/>from sklearn.datasets import make_classification<br/>from imblearn.under_sampling import NeighbourhoodCleaningRule<br/>from matplotlib import pyplot<br/>from numpy import where</span><span id="32ca" class="ju jv hh jq b fi ka jx l jy jz">#define dataset<br/>X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)</span><span id="cb74" class="ju jv hh jq b fi ka jx l jy jz">#summarize class distribution<br/>counter = Counter(y)<br/>print(counter)</span><span id="94f5" class="ju jv hh jq b fi ka jx l jy jz">#define the undersampling method<br/>undersample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)</span><span id="9e6d" class="ju jv hh jq b fi ka jx l jy jz">#transform the dataset<br/>X, y = undersample.fit_resample(X, y)</span><span id="35a1" class="ju jv hh jq b fi ka jx l jy jz">#summarize the new class distribution<br/>counter = Counter(y)<br/>print(counter)</span><span id="a8b6" class="ju jv hh jq b fi ka jx l jy jz">#scatter plot of examples by class label</span><span id="318d" class="ju jv hh jq b fi ka jx l jy jz">for label, _ in counter.items():<br/>  row_ix = where(y == label)[0]<br/>  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))<br/>pyplot.legend()<br/>pyplot.show()</span></pre><p id="86b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样。</p><p id="df90" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望你喜欢它，如果你想了解更多细节，你可以谷歌一下OSS&amp;NCR——欠采样技术或者你可以访问机器学习大师网站。T13】</p><p id="b6b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，我会尽我所能带来更多数据科学的新方法。</p><p id="538d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您希望探索更多关于数据科学的新方法，请关注我的其他文章。</p><p id="1a62" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我的一些另类网络存在<a class="ae jo" href="https://www.facebook.com/rupakroybob" rel="noopener ugc nofollow" target="_blank">脸书</a>、<a class="ae jo" href="https://www.instagram.com/bobrupak/" rel="noopener ugc nofollow" target="_blank"> Instagram </a>、<a class="ae jo" href="https://www.udemy.com/course/ai-master-class" rel="noopener ugc nofollow" target="_blank"> Udemy </a>、Blogger、Issuu等等。</p><p id="c752" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">也可以在Quora @上找到<a class="ae jo" href="https://www.quora.com/profile/Rupak-Bob-Roy" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/profile/Rupak-Bob-Roy</a></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kc"><img src="../Images/83e41b92e06a7fc4330ed4b12fa1bb34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gfPIy2ojh9kAO9_6-I_EBA.jpeg"/></div></div><figcaption class="kd ke et er es kf kg bd b be z dx"><a class="ae jo" href="https://www.quora.com/profile/Rupak-Bob-Roy" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/profile/Rupak-Bob-Roy</a></figcaption></figure><h1 id="aa09" class="kh jv hh bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">祝你愉快。</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/4dc68161d36061a1ccb474947424e2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aiqkR_3uDH4o15MWKRQzjg.jpeg"/></div></div></figure><div class="le lf ez fb lg lh"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="li ab dw"><div class="lj ab lk cl cj ll"><h2 class="bd hi fi z dy lm ea eb ln ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="lo l"><h3 class="bd b fi z dy lm ea eb ln ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="lp l"><p class="bd b fp z dy lm ea eb ln ed ef dx translated">medium.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv jm lh"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>MNIST Classification using Custom CNN Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用定制CNN模型的MNIST分类</h1>
<blockquote>原文：<a href="https://medium.com/mlearning-ai/mnist-classification-using-custom-cnn-model-15202e25cab5?source=collection_archive---------1-----------------------#2022-06-28">https://medium.com/mlearning-ai/mnist-classification-using-custom-cnn-model-15202e25cab5?source=collection_archive---------1-----------------------#2022-06-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="086f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> MNIST </strong> ( <em class="jc">修改后的国家标准与技术研究院)</em>数据集是一个手写数字的大型数据库，常用于训练各种手写分类模型。</p><blockquote class="jd je jf"><p id="53b5" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">源代码</em> </strong></p></blockquote><div class="jj jk ez fb jl jm"><a href="https://www.kaggle.com/code/javaclll/mnist-handwriting-classification-using-custom-cnn/data" rel="noopener  ugc nofollow" target="_blank"><div class="jn ab dw"><div class="jo ab jp cl cj jq"><h2 class="bd hi fi z dy jr ea eb js ed ef hg bi translated">使用自定义CNN的MNIST笔迹分类</h2><div class="jt l"><h3 class="bd b fi z dy jr ea eb js ed ef dx translated">完全由numpy从头开始编写|使用CSV格式的MNIST数据</h3></div><div class="ju l"><p class="bd b fp z dy jr ea eb js ed ef dx translated">www.kaggle.com</p></div></div><div class="jv l"><div class="jw l jx jy jz jv ka kb jm"/></div></div></a></div><p id="d905" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个为MNIST笔迹分类设计的定制模型并不基于任何机器学习框架，而是完全使用numpy <strong class="ig hi"> </strong>从头开始编写。它遵循卷积神经网络(CNN)深度学习模型的结构，该模型由三个主要部分组成:一个<em class="jc">卷积层</em>，随后是一个<em class="jc">汇集层</em>，其结果被馈送到一个<em class="jc">完全连接的</em> <em class="jc">层</em>，该层<em class="jc"> </em>在其输出上使用Softmax回归激活函数来将一个<strong class="ig hi"> 28x28像素</strong>输入的手写图像准确地分类到一个<strong class="ig hi"> 10位数<strong class="ig hi">中</strong></strong></p><blockquote class="jd je jf"><p id="b95a" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">卷积层</em> </strong></p></blockquote><p id="a4e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积层使用过滤器从输入的28x28像素图像中提取显著特征，并将其转换为26x26像素特征图。该模型使用的滤波器也称为内核，是一个3×3矩阵，如下图1所示。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/ac3fae12eb75f2fcb5389b852d723e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*aH12pOj_pt-5AUiWctXntw.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx"><em class="kn">fig 1 : Kernel / Filter used for Convolution layer</em></figcaption></figure><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Convolution Layer Code Snippet</figcaption></figure><blockquote class="jd je jf"><p id="7535" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">汇集层</em> </strong></p></blockquote><p id="facc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">池层用于将输入数据的大小减少为更易于管理和使用的数据，而不会显著损失功能。此模型的池层接受26x26像素的图像作为输入，并使用平均池算法输出13x13像素的图像。</p><p id="3e4e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">即使训练或预测模型的输入大小被减少到原始大小的一半，该模型也能很好地工作，因为在回旋层中使用了使用核的特征提取过程。因此，尽管全连接层的输入特征的数量从784减少到169，但是模型的功能仍然依赖于显著特征，从而产生可靠的模型。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Pooling Layer Code Snippet</figcaption></figure><blockquote class="jd je jf"><p id="93cc" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">数据可视化</em> </strong></p></blockquote><p id="89dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">原始图像数据<em class="jc">(图2.1) </em>各层产生的输出如图<em class="jc">图2.2和图2.3 </em>所示。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kq"><img src="../Images/8966274358f6be49e5f3027d5dd126d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*kbb00_Q36HiZIBFgrr-LRw.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">fig 2.1 : 28x28 Pixel Original Data from MNIST Dataset</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kr"><img src="../Images/c7b6de16fe47f14627765414d5b6a4ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*MDqcRSc08r0HGWjna35IEg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">fig 2.2 : 26x26 Pixel Feature Map ( Result of Convolution Layer after Kernel )</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ks"><img src="../Images/836be29b2b094bece72d323bed7ae9fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*CznOCVbyjO-oOWEe4IP3tg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">fig 2.3 : 13x13 Pixel Result of Pooling Layer</figcaption></figure><blockquote class="jd je jf"><p id="b7f8" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">全连接层</em> </strong></p></blockquote><p id="7ddc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">全连接层接受13x13 (169)个特征的输入[池层的输出]，具有两个隐藏层，每个隐藏层具有4个节点，并且由具有10个节点的输出层组成，10个节点表示10个数字中的一个。此外，输出层使用多类逻辑回归算法<em class="jc"> (Softmax回归激活函数)</em>，该算法提供了一种预测十个类的离散概率分布的方法。这意味着概率最大的节点是美联储数据最有可能的结果。</p><p id="e39f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，两个内部隐藏层使用简单的非线性sigmoid函数来激活，因为这有助于模型精确地设计用于分类的非线性边界，同时还降低了对内部层采用多类激活的复杂度(这将类似于已经采用的多个sigmoid函数)。</p><p id="fc0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">初始化</strong></p><p id="3e3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">全连接层模型包含一个<strong class="ig hi"> <em class="jc">初始化</em> </strong>函数，该函数可用于定制隐藏层(隐藏层的数量和每个层的节点数量)。对于这个项目，这个函数被用来初始化两个隐藏层，每个层有4个节点。</p><p id="40c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，该层还便于使用<strong class="ig hi"><em class="jc">initialize parameter</em></strong>函数为前一层中的每个节点随机生成数据，从而为当前层的每个节点分配权重和偏差。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Initialization of Layers and Parameters</figcaption></figure><p id="223b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">向前传球</strong></p><p id="70f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在向前传递期间，权重和偏差用于计算模型的预期结果。为此，输入层随机生成的权重和偏差用于计算第一个隐藏层中每个节点的输出(z)值。该输出通过sigmoid激活功能激活。对第一隐藏层重复类似的过程，产生第二隐藏层的激活输出。</p><p id="f2cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是，对于最终分类的输出图层，该过程略有修改。与之前类似，我们将权重和偏差应用于第二个隐藏层，并为输出层的每个节点找到10个类输出。然后，代替Sigmoid函数，我们使用多类Softmax回归激活函数来生成十个类的概率分布。这将为这些输出节点中的每一个分配成为实际结果的可能性，然后可以将其与目标输出进行比较，以找到模型的差异。</p><p id="eb14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">前向过程重复多次，每次都使用后向过程中获得的新调整的参数，以减少模型的差异。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kt"><img src="../Images/04b1d88439394bd79fd682f6b77c55e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*YsKz6Q1fB2-GTAD3qsCfDg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Softmax Regression Activation Function</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ku"><img src="../Images/f508835b8521d3a857dc2fe465e190b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*ybuQwO-fVbSLCv-yD4Pi7g.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Sigmoid Activation Function</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kv"><img src="../Images/25e82ff48d7d43f2b1cfb2736b4a9233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*k7QRng9NonrQbh-vwT7eSQ.png"/></div></figure><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Forward Pass Code Snippet</figcaption></figure><p id="2db1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">向后传球</strong></p><p id="4bc1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于后向通道，目标是最小化损失函数。为此，计算损失函数相对于权重和偏差的导数。这将导致两个方向向量[一个用于权重，另一个用于偏差]，其中损失函数趋向于最小值。这个过程被称为梯度下降。</p><p id="ffa6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于相关模型有多层计算，梯度下降过程以相反的顺序发生。首先，计算损失函数相对于激活输出的梯度。接着是损失函数相对于未激活输出的梯度，然后是损失函数相对于权重和偏差的梯度计算，如下所示。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kw"><img src="../Images/272ef4c6ae2836358c58903dffaf2ead.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*a2swvnop5MuYdYFLKociNg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Loss Function for Softmax Regression Function</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kx"><img src="../Images/3aa2daa769c43ec0127034af089f08cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*2dMeezmgL50hZU8wJOXFOw.png"/></div></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ky"><img src="../Images/ba4e798f5e132973fbcc3ce0f328a899.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*Vd65mGy5lh4zxd7_3aQlTA.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Derivative of the Loss Function w.r.t the Activated Outputs</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kz"><img src="../Images/daa12b5f497c80349cbea540fe885c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*vPvSqGWa5DWPeiIGhW28ig.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Derivative of the Loss Function w.r.t the Inactivated Outputs</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es la"><img src="../Images/06e48061c3575ad5f92a5a823df3cecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*SnoMRvbrNTECQ0KUPwYz7Q.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Derivative of the Loss Function w.r.t the weights</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lb"><img src="../Images/4b6da3c3c2496bf00c01ec1b6b86aa04.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*Xv9d2pjgia3Tk-Ewm0OF8Q.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Derivative of the Loss Function w.r.t the weights</figcaption></figure><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lc"><img src="../Images/6b2f88f67d95664cdf23821cdbfb66da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*_qlM2NSQJ_8crpIIWcZs2w.png"/></div></figure><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Backward Pass Model Code Snippet</figcaption></figure><p id="9eaf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参数更新</strong></p><p id="eb51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦获得了使损失最小化的权重和偏差的方向，这两个参数就通过在计算的方向上移动某个因子来更新，该因子称为学习率。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Parameter Update Code Snippet</figcaption></figure><blockquote class="jd je jf"><p id="f081" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"><em class="hh"/></strong></p></blockquote><p id="5af4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有了正向和反向模型，就可以导出一个完整的模型。完整的模型在所有训练数据上重复向前和向后传递一定数量的迭代，并调整权重和偏差以降低模型的总成本。</p><p id="2c6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练完成后，该模型将返回最终训练的参数，这些参数已被调整以预测28×28像素手写数字图像的结果。</p><figure class="kd ke kf kg fd kh"><div class="bz dy l di"><div class="ko kp l"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Final Model Code Snippet</figcaption></figure><blockquote class="jd je jf"><p id="93e5" class="ie if jc ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">结论</em> </strong></p></blockquote><p id="4ef2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型使用60，000个训练数据集来调整权重和偏差参数，并使用10，000个测试数据集来测试外部数据的准确性。</p><p id="b58e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">链接模型被训练40，000次迭代，大约70分钟，最终成本为0.569387。在测试数据集上的结果准确率为83.38%，在训练数据集上的结果准确率为83.182%。</p><p id="d2c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，在获得这一结果之前，使用20，000次迭代以相同的初始参数对模型进行了38分钟的训练，其结果是精度约为78.31%(训练)和78.38%(测试)，成本为0.710538。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><p id="03cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">资源:</strong></p><ol class=""><li id="b307" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated"><a class="ae lt" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">http://yann.lecun.com/exdb/mnist/</a></li><li id="3c6b" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated"><a class="ae lt" href="https://www.ics.uci.edu/~pjsadows/notes.pdf" rel="noopener ugc nofollow" target="_blank">https://www.ics.uci.edu/~pjsadows/notes.pdf</a></li><li id="6768" class="lk ll hh ig b ih lu il lv ip lw it lx ix ly jb lp lq lr ls bi translated"><a class="ae lt" href="https://www.kaggle.com/code/javaclll/mnist-handwriting-classification-using-custom-cnn/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/code/javaclll/mnist-handscription-class ification-using-custom-CNN/data</a></li></ol><div class="jj jk ez fb jl jm"><a rel="noopener follow" target="_blank" href="/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><div class="jn ab dw"><div class="jo ab jp cl cj jq"><h2 class="bd hi fi z dy jr ea eb js ed ef hg bi translated">Mlearning.ai提交建议</h2><div class="jt l"><h3 class="bd b fi z dy jr ea eb js ed ef dx translated">如何成为Mlearning.ai上的作家</h3></div><div class="ju l"><p class="bd b fp z dy jr ea eb js ed ef dx translated">medium.com</p></div></div><div class="jv l"><div class="lz l jx jy jz jv ka kb jm"/></div></div></a></div></div></div>    
</body>
</html>